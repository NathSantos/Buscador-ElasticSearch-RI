{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.25294"}, {"@name": "filename", "#text": "9954_Disserta%c3%a7%c3%a3o.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "Universidade de Aveiro Departamento de Geociencias\nSJ 2017\nFabio Gon\u00e7alves Correia\tControlo de Qualidade de dados de S\u00edsmica de Muito Alta Resolu\u00e7\u00e3o em Tempo Real Quality Control of Ultra High Resolution Seismic data acquisition in Real-Time\nUniversidade de Aveiro Departamento de Geociencias\nSJ 2017\nF\u00e1bio Gon\u00e7alves Correia\nControlo de Qualidade de dados de S\u00edsmica de Muito Alta Resolu\u00e7\u00e3o em Tempo Real\nQuality Control of Ultra High Resolution Seismic data acquisition in Real-Time\nDisserta\u00e7\u00e3o apresentada a Universidade de Aveiro para cumprimento dos requisitos necessarios a obten\u00e7ao do grau de Mestre em Engenharia Geol\u00f3gica, realizada sob a orienta\u00e7ao cient\u00edfica do Doutor Henrique Duarte, Diretor do Departamento de Geof\u00edsica Marinha da GeoSurveys, e do Professor Doutor Lu\u00eds Menezes Pinheiro, Professor Associado do Departamento de Geoci\u00eancias da Universidade de Aveiro.\no j\u00fari\nPresidente\tProf. Doutor Jorge Manuel Pessoa Gir\u00e3o Medina Professor Auxiliar do Departamento de Geoci\u00eancias da Universidade de Aveiro\nArguente\tProf. Doutor Leonardo Azevedo Professor Auxiliar do Departamento de Engenharia Civil Arquitectura e Georrecur- sos do Instituto Superior T\u00e9cnico, Universidade de Lisboa\nOrientador\tProf. Doutor Lu\u00eds Fuentefria Menezes Pinheiro Professor Associado do Departamento de Geoci\u00eaencias da Universidade de Aveiro\nagradecimentos\tGostaria de come\u00e7ar por agradecer aos meus orientadores, Prof. Lu\u00eds Menezes e Dr. Henrique Duarte, por todo o apoio que me deram ao longo da elabora\u00e7\u00e3o desta tese e por todas as conversas e sugest\u00f5es que enriqueceram a minha formacao, acad\u00e9mica e profissional. Agradeco tamb\u00e9m, que por mais atarefados que estivessem, demonstraram sempre preocupac\u00e7\u00f5ao e disponibilidade para ajudar. Quero agradecer ao Dan Herold e a equipa da Parallel Geoscience pela licenca do software SPW e pela colaborac\u00e3o nos testes do SPW. Um especial obrigado ao Dr. Leonardo Azevedo e ao Dr. Omar Benazzouz, por me ajudarem nos testes do software e por esclarecerem todas as d\u00edvidas que foram surgindo ao longo do trabalho. Aos colegas e amigos da GeoSurveys, por toda a ajuda e por todos os bons momentos por eles proporcionados. Agradeco tambem a C\u00edntia Pereira pelo companheirismo e ajuda ao longo da elabora\u00e7ca\u00e3o da tese. Um especial obrigado a Prof. Beatriz Aguado, por toda a motivac\u00e7a\u00e3o e sabedoria que me transmitiu ao longo de todo o percurso acad\u00e9emico. A todos os amigos que me acompanharam todos estes anos. Pelos caf\u00e9es, surpresas, viagens e conversas. Agradec\u00e7o por estarem sempre ao meu lado. Aos meus pais, a quem tudo devo pelo apoio dado e pelo enorme esforc\u00e7o que fizeram. Ao meu irm\u00e3o, pela disponibilidade em ajudar e pelos conselhos dados. Por fim, um agradecimento especial a In\u00eas Ferreira, por todos os desabafos, paci\u00eancia, compreensao e por estar sempre presente.\npalavras-chave\tUHRS, GeoSurveys, Hornsea Project One, S\u00edsmica de Reflex\u00e3o 3D Multicanal, SPW, Controlo de Qualidade, QC, Compara\u00e7\u00e3o Espetral, Raz\u00e3o Sinal Ru\u00eddo\nresumo\tA aquisi\u00e7ao de grandes volumes de dados durante uma campanha s\u00edsmica exige, necessariamente, mais tempo para o controlo de qualidade (QC). No entanto, o tempo de QC n\u00e3ao pode ser extendido devido a limita\u00e7c\u00e3oes do tempo de operac\u00e3o, tendo de ser feito mais npido, o que pode comprometer a qualidade. A alternativa, alocar mais pessoas e recursos para QC e melhorar a eficiencia, leva a aumentos de custo e a necessidade de maiores embarca\u00e7\u00f5es. Alem disso, o QC tradicional requer tempo de analise apos a aquisi\u00e7\u00e3o, atrasando a desmobilizac\u00e3o da embarcac\u00e3o, aumentando assim os custos da aquisi\u00e7\u00e3o. A solu\u00e7ao proposta passou pelo desenvolvimento de um QC automatico em tempo real eficiente, testando a Comparac\u00e3o Espetral e o Atributo Raz\u00e3o Sinal-Ru\u00eddo - ferramentas desenvolvidas no software SPW, usado para processamento de dados s\u00edsmicos. Usando este software foi testada a dete\u00e7\u00e3o e identificac\u00e3o de dados de fraca qualidade atraves das ferramentas de QC automaticas e os seus par\u00e2metros ajustados para incluir pelo menos todos os maus registos encontrados manualmente. Foi tambem feita a detec\u00e3o e identificac\u00e7a\u00e3o de varios problemas encontrados durante uma campanha de aquisic\u00e3o, tais como fortes ondula\u00e7\u00f5es e respetiva direc\u00e3o, o ru\u00eddo de esteira provocado pelas helices da embarca\u00e7\u00e3o e consequente Trouser's Effect e mau funcionamento das fontes ou dos recetores. A detec\u00e3o antecipada destes problemas pode permitir a sua resolu\u00e7ca\u00e3o atempada, n\u00e3ao comprometendo a aquisi\u00e7c\u00e3ao dos dados. Foram feitos varios relatorios para descrever problemas encontrados durante os testes de versoes beta do software SPW e os mesmos reportados a equipa da Parallel Geoscience, que atualizou o software de forma a preencher os requisitos necessarios ao bom funcionamento do QC em tempo real. Estas atualiza\u00e7\u00f5es permitiram o correto mapeamento dos headers dos ficheiros, otimizac\u00e3o da velocidade de analise das ferramentas automaticas e correc\u00e3o de erros em processamento dos dados em multi-thread, para evitar atrasos entre o QC em tempo real e a aquisic\u00e3o dos dados, adapta\u00e7\u00e3o das ferramentas \u00e0 leitura de um numero variavel de assinaturas das fontes, otimizac\u00e3o dos limites de memoria grafica e corre\u00e7ao de valores an\u00f3malos de semelhan\u00e7a espetral. Algumas atualizacoes foram feitas atraves da simulacao da aquisic\u00e3o de dados na empresa, de forma a efetuar alguns ajustes e posteriormente serem feitos testes numa campanha futura. A parametriza\u00e7ao destas ferramentas foi alcancada, assegurando-se assim a correta detecao automatica dos varios problemas encontrados durante a campanha de aquisto usada para os testes, o que levara a reduc\u00e3o do tempo gasto na fase de QC a bordo e ao aumento da sua eficacia.\nacknowledgments\tI would like to start by thanking my supervisors, Prof. Luis Menezes and Dr. Henrique Duarte, for all the support they gave me during this thesis elaboration and for all the conversations and suggestions that strengthened my academic and professional formation. I also would like to thank that, no matter how busy they were, they always found a way to be available to help. I want to thank Dan Herold and his Parallel Geoscience team for the software dongle and for the SPW tests. A special thanks to Leonardo Azevedo and Omar Benazzouz for helping me during the software testing and for always answer all my doubts. To all my colleagues and friends from GeoSurveys, for all their help and for all the good moments spent with them. I also thank Cintia Pereira for the companionship and help during the thesis elaboration. A special thanks to Prof. Beatriz Aguado, for all the motivation and knowledge through all the academic course. To all my friends that helped me during all these years. For the coffee breaks, surprises, trips and conversations. I thank them for always being by my side. To my parents, to whom I owe everything for the support given and for the enormous effort they have made. To my brother, for always being available to help and for his advices. Finally, a special thanks to Ines Ferreira, for all the conversations, patience, comprehension and for always being by my side.\nkeywords\tUHRS, GeoSurveys, Hornsea Project One, 3D Multichannel Seismic Reflection, SPW, Quality Control, QC, Spectral Comparison, Signal to Noise Ratio\nabstract\tThe acquisition of larger volumes of seismic data during a survey requires, necessarily, more time for quality control (QC). Despite this, QC cannot be extended due operational time constraints and must be done faster, compromising its efficiency and consequently the data quality. The alternative, to allocate more people and resources for QC to improve efficiency, leads to prohibitive higher costs and larger vessel requirements. Therefore, traditional QC methods for large data require extended standby times after data acquisition, before the vessel can be demobilized, increasing the cost of survey. The solution tested here consisted on the development of an efficient RealTime QC by testing Spectral Comparison and Signal to Noise Ratio Attribute (tools developed for the SPW seismic processing software). The detection and identification of bad data by the automatic QC tools was made and the parameters adapted to include at least all manual QC flags. Also, the detection and identification of common problems during acquisition, such strong wave motion and its direction, strong propeller\u2019s wash, trouser's effect and malfunction in sources or receivers were carried out. The premature detection of these problems will allow to solve them soon enough to not compromise the data acquisition. Several problem reports from beta tests of SPW were transmitted to the Parallel Geoscience team, to be used as a reference to update the software and fulfil Real-Time QC requirements. These updates brought the correct mapping of data headers in files, optimization of data analysis speed along with multi-thread processing debug, to assure it will be running fast enough to avoid delays between acquisition and Real-Time QC, software design to read a variable number of source signatures, optimization of graphic memory limits and debugging of anomalous spectral semblance values. Some updates resulted from a data acquisition simulation that was set up in the office, to make some adjustments to be later tested on an upcoming survey. The parameterization of these tools was finally achieved, assuring the correct detection of all major issues found during the survey, what will eventually lead to the reduction of time needed for QC stage on board, as also to the improvement of its efficiency.\nContents\nAgradecimentos\nResumo\nAcknowledgments\nAbstract\nList of Figures\tv\nList of Tables\tix\n1\tIntroduction\t1\n1.1\tNature and scope of the thesis ......................................... 1\n1.2\tGeoSurveys - Geophysical Consultants Ltd................................ 1\n1.3\tObjectives.............................................................. 3\n1.4\tData and Methodology.................................................... 3\n1.5\tStructure of this Thesis ............................................... 4\n2\tScientific Context of the Study Area\t7\n2.1\tThe Hornsea Offshore Windfarm........................................... 7\n2.2\tThe North Sea Basin..................................................... 8\n2.3\tGeological and Tectonic Evolution....................................... 9\n2.3.1\tPaleozoic........................................................ 9\n2.3.2\tMesozoic ....................................................... 10\n2.3.3\tCenozoic ....................................................... 11\n2.4\tLithostratigraphy of the Quaternary.................................... 11\n2.4.1\tCrag Group...................................................... 12\n2.4.2\tSouthern North Sea Deltaic Group................................ 13\n2.4.3\tDunwich Group...................................................... 14\n2.4.4\tCalifornia Glacigenic\tGroup........................................ 15\n2.5\tNorth\tSea Main Glaciations.............................................. 18\n2.5.1\tElsterian Glaciation............................................... 19\n2.5.2\tSaalian Glaciation................................................. 20\n2.5.3\tWeichselian Glaciation............................................. 20\n3\tThe Marine Seismic Reflection Method\t23\n3.1\tPrinciples................................................................ 23\n3.2\tMultichannel Seismic Reflection Data ..................................... 25\n3.3\t2D and 3D Seismic Surveys................................................. 29\n3.4\tBasic Seismic Data Processing\tFlows....................................... 32\n3.5\tSeismic Data Interpretation............................................... 36\n4\tData and Methodology\t37\n4.1\tData...................................................................... 37\n4.1.1\tHornsea Project One Survey Operations.............................. 37\nData Acquisition................................................... 38\nSeismic Data Quality Control....................................... 39\nRe-acquisition..................................................... 47\n4.1.2\tSeismic Data Processing............................................ 49\n4.1.3\tSeismic Data Interpretation........................................ 51\n4.2\tReal-Time Quality Control\t.............................................. 54\n4.2.1\tSoftware Beta Tests................................................ 54\n4.2.2\tSpectral Comparison................................................ 55\n4.2.3\tSignal to Noise Ratio\tAttribute.................................... 60\n5\tResults and Discussion\t65\n5.1\tManual QC................................................................. 65\n5.2\tReal-Time QC ............................................................. 66\n5.2.1\tSoftware Beta Tests................................................ 66\n5.2.2\tSpectral Comparison................................................ 67\n5.2.3\tSignal to Noise Ratio\tAttribute.................................... 76\n5.2.4\tNon-detected \u201dbad\u201d record ......................................... 81\n5.2.5\tReal-Time QC\tVS\tTraditional QC................................. 82\n5.2.6\tField Tests ................................................... 84\n5.3\tSeismic Data Interpretation............................................ 84\n6\tConclusions\t89\n6.1\tSummary of Results..................................................... 89\n6.2\tConcluding Remarks..................................................... 90\n6.3\tFuture Work ........................................................... 91\nReferences\t93\niv\nList of Figures\n2.1\tUnited Kingdom Offshore Regional Areas and Hornsea Project One location\n(Adapted from Stoker et al., 2011 and About Hornsea Project One, 2017). . .\t7\n2.2\tNorth Sea Area (from: http://www.worldatlas.com).............................. 8\n2.3\tDistribution of Lower-Middle Pleistocene (pre-Anglian) groups on the UK continental shelf (Stoker et al., 2011)........................................ 13\n2.4\tDistribution of Middle Pleistocene-Holocene glacigenic groups on the UK continental shelf (Stoker et al., 2011)........................................ 18\n2.5\tStratigraphic diagram of the Pleistocene facies units of North Sea, their correlation with Stoker et al., 2011 groups and glacial events (Adapted from Graham\net al., 2011................................................................ 19\n3.1\tRepresentation of the First Fresnel Zone. (modified from: Kearey and Brooks,\n1991). ..................................................................... 25\n3.2\tDiagram of a multichannel marine acquisition geometry, with multi-fold coverage (In Ribeiro, 2011 and modified from McQuillin et al., 1984)........... 26\n3.3\tShock wave emits out from an electrical spark discharge in a fluid (From: Heigl\net al., 2013)............................................................... 27\n3.4\tSchematic representation of a streamer configuration (In Ribeiro, 2011 and\nmodified from Telford et al., 1990)......................................... 28\n3.5\tRepresentation of a 3D seismic data acquisition. (Source:\nhttp://www.bulwarkservices.com/services/marine-acquisition-system).......... 31\n3.6\tRay paths of Ghosts and Seabed Multiples (modified from Hatton et al.,1986).\t34\n3.7\tSorted seismic traces by CMP and NMO correction (modified from:\nhttps://commons.wikimedia.org/wiki/File:NMO_Correction.png)................. 34\n3.8\tBefore and after stack. The amplitude of the reflection is enhanced, leading to\nan increase of the signal-to-noise ratio (modified from: http://www.glossary.oilfield.slb.com/Terms/s/stack.aspx).................... 35\n4.1\tBibby Tethra vessel.......................................................... 38\n4.2\tSources and streamers geometry (upper view) (Source: GeoSurveys project\nreport)..................................................................... 38\n4.3\tAcquisition Geometry scheme (Source: GeoSurveys project report).............. 39\n4.4\tOffline Quality Control/Quality Analysis processing workflow. In yellow: processing datasets created; in blue: numbered from 1 to 5 - QC workflow steps. 40\n4.5\tSpectral comparison between Vessel Noise and\tdata acquired................... 42\n4.6\tExample of Tugging Noise observed in the data................................ 42\n4.7\tExample of DC Noise observed in the data..................................... 43\n4.8\tExample of Burst Noise observed in the data.................................. 44\n4.9\tElectrical induction visible on the near channels of the 4th streamer (CH 73-75)\nin Source 0 (vertical scale in ms).......................................... 44\n4.10\tExample of a recorded sparker wavelet firing for both sources (a); with the corresponding frequency spectrum (b) (Source 0 in green; Source 1 in orange). 45\n4.11\tLine acquired on bad weather. Vertical motion can be noticed along the\nstreamers registry. ........................................................ 46\n4.12\tHigh vessel speed during the acquisition in the beginning of the seismic line (until FFID 49500 approximately). Cable depth (cm) is represented in blue\nline and cable heave (cm) in pink line...................................... 46\n4.13\tTrouser\u2019s effect due to strong propeller wash of the vessel (purple represents\ndepths around 0 meters and red represents higher depths).................... 47\n4.14\tStatistical graphics showing the kilometres (a) and percentage (b) of the difference between the estimated line plan and the acquired data. ............. 48\n4.15\tProcessing flow applied to the seismic profiles............................. 49\n4.16\tNon-migrated section of the processed data.................................. 51\n4.17\tMigrated section of the processed data...................................... 52\n4.18\tEnvelope data type, calculated based on the migrated data................... 52\n4.19\tParaphase data type, calculated based on the migrated data.................. 53\n4.20\tConnection between SPW device and Multi-trace............................... 55\n4.21\tProcessing flow for the Real Time Display................................... 56\n4.22\tTCP/IP Input parameters..................................................... 57\n4.23\tSpectral Comparison parameters.............................................. 58\n4.24\tExtracted wavelet for both sources (a); Frequency Spectrum of source signa-\nture: Source 0 in blue; Source 1 in green.................................... 59\n4.25\tReal Time Data Quality Analysis parameters.................................. 60\n4.26\tProcessing flow used to test Signal to Noise Ratio Attribute. .............. 62\n4.27\tSignal to Noise Ratio Attribute parameters.................................. 63\n4.28\tParameters of Real Time Data Quality Analysis Map. ......................... 64\n5.1\tFrequency spectrum of a missed shot record, compared with both sources sig-\nnature....................................................................... 65\n5.2\tAppearance of dead FFID\u2019s blue vertical lines (horizontal axis represented by\nFFID and vertical represented by Channel number). ........................... 68\n5.3\tConsecutive missed shots detected in Spectral Comparison (horizontal axis rep-\nresented by FFID and vertical represented by Channel number) (a); Schematic representation of missed triggers in Source 0 (b). .......................... 69\n5.4\t\u201dDead\u201d channel detected in Spectral Comparison - Channel 52, horizontal blue\nline (horizontal axis represented by FFID and vertical represented by Channel number)...................................................................... 70\n5.5\tLinear loss of spectral semblance visible specially between channels 25-48 and\nFFID 100-190 (horizontal axis represented by FFID and vertical represented by Channel number)........................................................... 70\n5.6\t(a) Frequency spectrum of channels 25-48 (a); Frequency spectrum of all chan-\nnels (b)..................................................................... 71\n5.7\tStrong wave motion moving against the streamer............................... 71\n5.8\t(a) Missed record in an entire streamer, inside the black box: Channels 25-\n48 (horizontal axis represented by FFID and vertical represented by Channel number); (b) Record with missing streamer; (c) Example of a record with all streamers, for comparison purposes. ......................................... 72\n5.9\t(a) Spectral Comparison Attribute Map detecting weak channels (blue dots);\n(b)\tWeak channels record; (c) Example of a good record with no channel issues. 73\n5.10\tStrong propeller wash affecting mainly the middle streamers................. 74\n5.11\tStrong propeller wash effect detected in near-offset channels of Streamers 2\nand 3 - Channels 25-30 and 49-55 respectively (horizontal axis represented by\nFFID and vertical represented by Channel number). ........................... 74\n5.12\tFirst 500 records of a seismic line from HOW 3D project (a) no filtered data;\n(b) low-cut filtered data....................................................... 77\n5.13\tComparison of S/N ratio values between two different lines...................... 78\n5.14\tReal Time Statistics map of the three S/N ratio parameterizations, with flagged\ntraces (in red). ............................................................... 81\n5.15\tNon detected \u201dbad\u201d record no signal after 90ms.................................. 82\n5.16\tReal-Time QC display during the field tests (strong propeller\u2019s wash orange\narrows; wave motion effect white arrows; bad shot red vertical line; weak channel white horizontal line). ................................................ 84\n5.17\tInterpreted seismostratigraphic units after interpolation in one of the four wind\nturbine generator areas of block B27H27, calibrated wih geotechnical information. Red lines show a preliminary interpretation based only on geotechnical data............................................................................ 85\n5.18\tDepth slice around 42 meters depth, showing glacial striations.................. 86\n5.19\t3D Seismic block of one of the wind turbine generator areas and its horizons. 87\nList of Tables\n2.1\tTimescale of the Cenozoic and relation with Groups described by Stoker et al,\n2011......................................................................... 12\n2.2\tProposed formations of the California Glacigenic Group (Adapted from Stoker\net al., 2011)................................................................. 15\n4.1\tEstablished horizons for interpretation, with each lithostratigraphy\u2019s matching\ncolor......................................................................... 54\n5.1\tNumber of shot records and traces per line: before and after Spectral Com-\nparison tool (minimum\tof 80% of spectral semblance)........................ 75\n5.2\tNumber of flagged records and traces with Manual QC and Spectral Com-\nparison tool. \"Equivalent Traces\u201d is the number of flagged records times 96\n(number of channels).......................................................... 76\n5.3\tSignal to Noise ratio in missed shots comparison between filtered and no\nfiltered data................................................................. 76\n5.4\tEstablished minimum S/N ratio for every line and % of flagged records. ...\t79\n5.5\tComparison between two different established minimum S/N ratio................ 80\nx\nChapter 1\nIntroduction\n1.1\tNature and scope of the thesis\nThis thesis presents some of the results of the work carried out during the internship at GeoSurveys, in Aveiro, linked to the development of a Real-Time Quality Control automatic procedure, for fulfilment of the requirements for a master\u2019s degree in Geological Engineering, branch of Geological Resources, at Geosciences Department of the University of Aveiro.\nThe development work was carried out under the supervision of Prof. Luis Menezes Pinheiro, from the Geosciences Department of the University of Aveiro, and Dr. Henrique Duarte, Director of the Marine Department of GeoSurveys. This project also had the support of the Parallel Geoscience team, as concerns the SPW software development.\n1.2\tGeoSurveys - Geophysical Consultants Ltd.\nBased in Aveiro, GeoSurveys - Geophysical Consultants Ltd. was established in 1999 from an ambitious project, designed for Geophysics Prospecting and Earth Sciences.\nAccording to the market needs, GeoSurveys specializes itself in Geophysics Prospecting and Geology (onshore and offshore) in several application domains, such as Groundwater Resources, Geophysics Planning and Project Management, Environmental Impact, Archaeology and Patrimony, Geotechnical and Civil Engineering, Mining Exploration, estimation of Risk of Natural Disasters and Oil Exploration.\nThanks to continuous investments in hiring and training of specialized human resources as well the purchase and development of latest generation technology, GeoSurveys has been consolidating in a sustained manner its position, to be today, leader in the national market and have a prestigious position in worldwide market due its unique application techniques.\nIn recent years, the company\u2019s strategy has been expanded and consolidated itself in international markets, with special attention in the \u2019\u2019emerging economies\u201d. With this bet, GeoSurveys has achieved and accomplished projects in a large number of countries, such as Qatar, Turkey, Ireland, Denmark, Iceland, the Netherlands, Angola, Mozambique, Cape Green Islands, Sao Tome and Principe, Guinea Bissau, Cameroon, Malawi, Ecuador, Peru, Brazil, USA, Venezuela, China, Vietnam, Singapore and India.\nRelated to offshore services, GeoSurveys has a full suite of geophysical solutions for offshore surveying. It provides a distinct and high quality data services in several applications as Geohazard surveys, site and route surveys, environmental surveys and deep-water field developments. The company is highly experienced in the acquisition, processing, modeling and interpretation of:\n\u2022\tSingle and Multichannel reflection seismic;\n\u2022\tBathymetry with single and multibeam echo sounder;\n\u2022\tSide scan sonar for seafloor mapping;\n\u2022\tMagnetometry;\n\u2022\tSea bottom sampling with piston-corer, gravity corer and vibro-corer.\nGeophysical methods used by GeoSurveys in offshore have a major role to play in mapping stratigraphy, determining the thickness of superficial deposits and depth to engineering bedrock, establishing weathering profiles, the study of particular erosional and structural features and the detection of voids and buried objects and infrastructures.\nGeoSurveys is divided in three departments: Financial Department leaded by Francisco Sobral; Marine Geophysics Department leaded by Henrique Duarte and the Land Geophysics Department leaded by Carlos Grangeia. The CEO is Helder Hermosilha. Each department includes multidisciplinary teams constituted by geophysicists, geologists and geological engineers.\n1.3\tObjectives\nNowadays, the acquisition of larger volumes of seismic data during a survey requires more time for the manual QC stage. Despite this, due the time limitation during data acquisition, QC cannot be extended and must be done faster, compromising its efficiency and consequently the data quality. Alternatively, more people can be involved in the QC stage to improve QC efficiency, but leading to higher costs. In addition to the large data volumes, there is also the standby during the data acquisition, since QC can only start after the end of the acquisition, leading to more time needed on board as also delaying the subsequent data processing.\nTo not compromise the time schedules and QC efficiency, the main objective of this thesis consists on the testing of beta versions of real-time QC tools developed for the SPW seismic acquisition and processing software (from Parallel Geoscience Corporation), in order to detect gaps and bugs, to be reported to the Parallel Geoscience team to do the software design. Another objective is the development of a procedure that can guarantee the correct operation of the recently developed Spectral Comparison and Signal to Noise Ratio Attribute tools to be used during a marine seismic survey.\nBesides the parameterization and testing of the Real-Time QC procedure, another major objective consisted in the acquisition of experience in the service provider business area, which was undoubtedly achieved. All the period as a trainee allowed a clear understanding of how a geophysics company works, and also to learn the ultimate market strategies along with innovative data processing that is not available elsewhere. New seismic concepts were also acquired during the participation in some of the company projects, from data processing to data interpretation.\n1.4\tData and Methodology\nThe Dataset used for this work consisted on a group of eleven lines (raw data) from a 3D UHRS (Ultra High Resolution Seismic) data block named B27H27, with a total length of approximately 122km. The 3D seismic data, owned by DONG Energy, were acquired by GeoSurveys and GeoMarine in the Southern North Sea, 120km off the Yorkshire coast.\nThe data were acquired with a record length of 150ms. The acquisition was carried out by GeoMarine, while GeoSurveys was responsible for the data QC and processing.\nBeta tests of the SPW new routines were carried out in order to identify and report the various detected problems, such as software bugs, and optimize the existing tools, software design and propose the inclusion of any missing tools. These reports were transmitted to Parallel Geoscience and were used as a basis to proceed to software updates related with RealTime QC. Along with reports, a simulation of the acquisition was prepared and mounted to correctly adapt the software to the equipment used on board and with this assure the correct operation of the developed tool, while the data is being acquired.\nData acquired in a previous survey was used to test two SPW tools - Spectral Comparison and Signal to Noise Ratio Attribute. The traditional QC procedure used on that survey was used for comparison with the new one. On both tools, the raw data of block B27H27 was used for testing. The detection and identification of bad data by the automatic QC tools was made and the parameters adjusted in order to adapt them to detect at least all the bad data detected by the traditional QC. Using the tools displays, the detection of problems found during the survey was made, along with the identification of their cause, so as to list as many as possible of these problems and maximize the information provided by the automatic tools.\nThe final processed data was interpreted based on the client requirements and compared with the geological setting of the study area.\n1.5\tStructure of this Thesis\nThe present thesis is divided into six chapters. The first chapter gives a brief introduction to the reader of the scope of this work, main objectives of the thesis, Dataset and Methodology and also a reference to GeoSurveys - Geophysical Consultants Ltd.\nChapter two describes the geographical and geological setting of the study area.\nThe third chapter introduces the seismic reflection method, focusing on the marine acquisition. The basic principles and the importance of acquire 2D and 3D seismic data are referred, followed by a basic seismic data processing to familiarize the reader to some\nimportant steps of seismic processing; it finishes with a highlight of the importance of the seismic data interpretation.\nChapter four (Data and Methodology) starts with the description of the traditional QC analysis of the seismic data on board, as also an explanation of when and why it is necessary to repeat acquisition in some areas. This is followed by a description of how beta tests were done and a brief explanation of how the real-time acquisition was simulated, followed by a detailed methodology of Real-Time QC tested tools - Spectral Comparison and Signal to Noise Ratio Attribute. This chapter also includes a brief explanation of the seismic processing provided by GeoSurveys and the seismic interpretation required by the client.\nThe fifth chapter (Results and Discussion) describes the problems reported to Parallel Geoscience that led to the new SPW updates, as also the results obtained by applying the parameters described in chapter four. The bad data detected with the new Real-Time QC are listed and their causes identified, along with the identification of typical acquisition problems, to assure that these tools will cover and improve the current data analysis. A short discussion about the interpretation done in the data is included in the end of this chapter.\nThe final chapter of this thesis presents a brief summary of the results obtained, followed by the main conclusions and a suggestion of future work that can be done to improve the developed tools.\n6\nChapter 2\nScientific Context of the Study\nArea\n2.1\tThe Hornsea Offshore Windfarm\nThe area investigated is located in the Southern North Sea (Figure 2.1), 120km off\nthe Yorkshire coast. The Hornsea Windfarm Project One is an offshore windfarm project proposed by DONG Energy. It has an area of approximately 407km2 and it is expected to\nhave 174 wind turbines (each 7MW), making this project the world largest offshore windfarm,\nwith a 1.2 gigawatt capacity. It is expected to be completed by 2020 (About Hornsea Project\nOne, 2017).\n\nHornsea Project One\nNORTHERN) ^Ireland 6\n| 1\tNorthern North Sea\n2 [Hebrides and West Shetland shelves\n| 3\tMoray Firth\n4 Malin-Hebrides Sea\n| 5 [central North Sea\nj 6 Irish Sea\n7\t[southern North Sea\n8\t[cardigan Bay and the Bristol Channel\nI g | Western English Channel and _______ISW Approaches\n[ 10 ^English Channel\nA [Faroe-Shetland Basin\nB Rockall Basin in press\nFigure 2.1: United Kingdom Offshore Regional Areas and Hornsea Project One location (Adapted from Stoker et al., 2011 and About Hornsea Project One, 2017).\n2.2\tThe North Sea Basin\nThe North Sea is an epicontinental sea located between the British, Scandinavian and Northern Europe sectors, connected to the North Atlantic to the north and the English Channel to the south (Figure 2.2). Along the Norwegian coast, in the eastern margin of the North Sea, the depth can reach over 700 meters; however, the water depth in rest of the North Sea averages about 100 meters, with a slight depth increase towards the north, in direction of the Atlantic margin (Lamb et al., 2016).\nr t\u00ed roc\n(Den)\nNorwegian\nSea . -\tf\nNorway\tn\nSweden\nNorth\nEngland\nFrance\njAttantic Ocean\nShetland fsf\u00farlcfs . (UK)\n140 km\n\"Luxembourg\n* Netherlands Germany\nAmsterdam\nDenmark . Copenhagen\nLondon r\t*\nCardiff\nBelgufm\nBrussels\nFigure 2.2: North Sea Area (from: http://www.worldatlas.com/aatlas/infopage/northsea.htm).\nThis shelf area has experienced a long and complex geological history until its present-day structural configuration (Glennie and Underhill, 1998; Zanella and Coward, 2003).\nFrom the viewpoint of basin development, different stages can be distinguished in the evolution of the North Sea. This area started by being affected by the Caledonian Orogeny (Cambrian-Silurian), followed by Variscan Orogeny, which resulted in the collision of the North American-Greenland and the North-West European continental masses, from Devonian to Carboniferous (Wilson, 1966). A major event called the Permo-Triassic intracratonic stage\nappeared in the North Sea basin in the Permian. This event separated the Northern North Sea Basin from the Southern North Sea Basin (Gallagher, 1988).\nThe rifting episode during the JurassicEarly Cretaceous is characterized by differential thermal subsidence and by an accompanying progressive transgression of the sea (Ziegler, 1978). Rifting in the North Sea ceased when the axis of extension shifted to the north-west of Britain, leaving an aborted rift controlling subsidence patterns in the North Sea. Towards the eastern British coastline, the Quaternary sediments are gradually thinner (Cameron and Holmes, 1999).\n2.3\tGeological and Tectonic Evolution\nAs the study area is included in the Southern North Sea (Figure 2.1), a more detailed description of this area is included in this section, with special attention for the Quaternary geology, since the majority of the Ultra High Resolution Seismic (UHRS) data generally only provides information on the near surface Quaternary topmost geology.\n2.3.1\tPaleozoic\nThe Southern North Sea Basin suffered several episodes of basinal subsidence. This has been caused by single episodes of uplift and broad erosion during the late Silurian (Caledonian Unconformity), about 420-410 million years ago, Late Carboniferous (Variscan Unconformity) about 300-290 million years ago, Late Jurassic (Cimmerian Unconformity) about 160-140 million years ago, Late Cretaceous about 97-66 million years ago and at several times during the mid-Cenozoic (Cameron and Holmes, 1999). Sediments from the Lower Paleozoic are likely to be several kilometers thick beneath most or all the southern North Sea. These sediments were softly deformed and intruded by granite plutons during the Caledonian Orogeny of Late Silurian to Early Devonian, about 420 - 390 million years ago (Balson et al., 2001).\nAs a consequence of the Caledonian orogeny, most of the Southern North Sea remained an upland area of net erosion (the difference in sediment mass before and after an event) during the Devonian about 410-360 million years ago. The crustal extension was initiated early in the Carboniferous after approximately 360 million years ago, following which up to\n4000 meters of deep-water or deltaic sediments were deposited within the graben areas. Most of the granite batholiths evidenced from their geophysical signatures may lie beneath early Carboniferous horsts (Cameron and Holmes, 1999). Approximately 325 million years ago, rifting had effectively ceased and a phase of thermal subsidence began.\nThe Variscan orogeny, around 360 million years ago, affected the southern North Sea Basin. During the period from 300-290 million years ago, the Carboniferous rocks were softly folded and faulted. Between 310-270 million years ago, the differential regional uplift from Late Carboniferous to Early Permian was accompanied by peneplanation (formation of low-relief areas) as a result of the erosion of more than 1500 meters of Carboniferous strata from parts of the Southern North Sea Basin (Balson et al., 2001).\nAfter the Variscan Orogeny, the southern North Sea Basin began to subside again during the Permian, and more than 2700 meters of Permo-Triassic strata (covering an age range of about 290-210 million years) were deposited, including red beds and a thick, cyclical, evaporite succession (Balson et al., 2001).\n2.3.2\tMesozoic\nDuring the Late Triassic and Early Jurassic, there has been some reactivation of Variscan basement faults due to the subsidence of the Sole Pit Basin - an area that suffered differential uplift as well as differential subsidence, located in the western half of the Southern North Sea Basin (Glennie and Boegner, 1981). These tectonic movements originated the earliest mid-Triassic halokinesis (movement of salt bodies) of the Upper Permian salts. Fully marine conditions were then re-established in the southern North Sea at the end of the Triassic. Subsequently, during earlymid Jurassic, differential subsidence of the Sole Pit Basin was accentuated by the development of growth faults along its western margin. In the Middle Jurassic, extensive dome uplift occurred in the central North Sea and resulted in an erosional unconformity. More than 1000 meters of Jurassic and Triassic strata were eroded from the Cleaver Bank High (sand bank located off the west coast of the Netherlands) (Glennie, 1986). During the Late Jurassic there was a widespread pulse of diapirism (Glennie and Underhill, 1998). Lower Cretaceous sediments are typically less than 200 meters thick, but reach up to 1000 meters in local zones of growth faulting, associated with sinistral fault movement (Kirby and Swallow, 1987). During the Late Cretaceous, the Cleaver Bank High became established\nas the main depocenter (area where the maximum deposition occurs) and accumulated more than 1000 meters of Upper Cretaceous chalk (Balson et al., 2001).\n2.3.3\tCenozoic\nThe Cenozoic shows multiple events of basin inversion, subsidence, uplift and erosion throughout the period, affecting many basins in Northwestern Europe (Ziegler, 1992; White and Lovell, 1997; Huuse, 2002; Stoker et al., 2005; Anell et al., 2010; Goledowski et al., 2012). This has been attributed to strike-slip reactivation of basement faults. (Glennie and Boegner, 1981).\nCenozoic subsidence in the North Sea has been dominated by broad synclinal downwarping towards a depositional axis that extends from the Viking Graben, through the Central Graben towards the Netherlands. Many of the basement faults in the Southern North Sea were reactivated by dextral strike-slipe faults during Oligocene to Miocene times which caused further major halokinesis (Glennie and Boegner, 1981). Most of the salt pillows north of 54\u00b0 North were initiated in mid-Cenozoic times, and Glennie (1986) related contemporaneous inversion of the Sole Pit Basin to Alpine earth movements. There are very few Miocene sediments, and only local outliers of Pliocene deposits. Rapid subsidence became more extensive early in the Quaternary resulting in the preservation of more than 600 meters of Pleistocene progradational delta deposits and glacigenic deposits (Balson et al., 2001).\n2.4\tLithostratigraphy of the Quaternary\nThe Quaternary lithostratigraphical framework of the Southern North Sea can be subdivided in four groups, as described below. These groups have been defined by Stoker et al., 2011, based on various scientific publications, and they were defined by several criteria, such the physical separation between groups, lateral lithological gradation and source region. Table 2.1 allows an easier understanding for the reader to follow the evolution of each group through time.\n2.4.1\tCrag Group\nThe Crag Group has been defined in eastern England as a group of shallow-water marine and estuarine sands, gravels, silts and clays deposited on the south-west flank of the North Sea Basin (Figure 2.3) (McMillan et al., 2005). These sands are characteristically dark green from glauconite, but can change to orange or reddish brown when exposed to air. The gravels in the lower part of the group are almost entirely of flint except at the base of the Red Crag Formation where phosphatic mudstone pebbles predominate. The only offshore formation assigned to the Crag Group is the Red Crag Formation, which is correlated with the onshore formation of the same name. The Red Crag Formation is a high-energy shallow-marine deposit of glauconitic sediment, which occurs at or near the sea bed off the coast of East Anglia (Balson and Cameron, 1985). The Red Crag Formation might range in age from Late Pliocene to Early Pleistocene, dated to 3.22.4 Ma, based on the presence of the planktonic foraminiferid Neogloboquadrina atlantica (Berggren) (Funnell, 1988). The formation has a marked unconformity on Paleogene or Neogene formations and is unconformably overlain by deposits of the Southern North Sea Deltaic Group, that may be, at least in part, correlated to the Westkapelle Ground Formation of the Southern North Sea Deltaic Group (Cameron et al., 1992).\nHebrides Margin Group\nWest Shetland Margin Group\nZulu Group\nDunwich Group\nSouthern North Sea Deltaic Group\n-------- Crag Group, offshore\n(buried below Southern North \u2014\u20141 Sea Deltaic and Dunwich groups)\nDemetae Group\nH Unassigned\nMedian line\n\u2014200\u2014 Bathymetric contour (metres)\nFigure 2.3: Distribution of Lower-Middle Pleistocene (pre-Anglian) groups on the UK continental shelf (Stoker et al., 2011).\n2.4.2\tSouthern North Sea Deltaic Group\nThe Southern North Sea Deltaic Group is related to a thick succession of marine deltaic formations, including delta front and prodelta deposits, formed by sediments derived from south eastern England and the Netherlands that are preserved in the Southern North Sea. To the north, these deposits pass transitionally into the more basinal Zulu Group (Figure\n2.3)\t(Stoker et al., 2011). Initially these deltas prograded into the North Sea from Britain in the west and from the European mainland in the east, until eventually the two deltas merged and progradation became generally northward. Deltaic deposition in the southern North Sea area might have started in the Pre-Ludhamian. During the LudhamianPastonian\ninterval, influx from the European mainland eventually overwhelmed the British supply and the European delta overstepped the British delta and caused the shallowing of the Southern Bight waters by extending the delta plain of the Netherlands. The combination of the two delta fronts occurred in earliest Beestonian (Eburonian) times, when the direction of advance tended northwards (Cameron et al., 1992). The whole of the group is of Early Pleistocene age. The base of the Southern North Sea Deltaic Group lies at the Gauss/Matuyama magnetic polarity reversal and the top is close to the Matuyama/Brunhes reversal (Stoker et al., 2011).\nThe Southern North Sea Deltaic Group is defined regarding nine constituent formations: the Westkapelle Ground, Crane, Smith\u2019s Knoll, Ijmuiden Ground, Winterton Shoal, Markham\u2019s Hole, Outer Silver Pit, Aurora and Batavier formations (Stoker et al., 2011). All of these, with the exception of the Crane Formation, were deposited in prodelta or delta front environments. These formations succeed each other northwards as the delta prograded into the basin. The Crane Formation was deposited seaward of the delta front and is gradually overstepped by the prograding delta deposits. The base of the Southern North Sea Deltaic Group mostly overlies the Red Crag Formation, though the latter may be partly correlated with the Westkapelle Ground Formation; the top deltaic group is diachronous with the Yarmouth Roads Formation, that is assigned to the Dunwich Group (Cameron et al., 1992).\n2.4.3\tDunwich Group\nThe Dunwich Group has been defined in eastern England (Figure 2.3) as fluvial gravels with subsidiary clays and silts (McMillan et al., 2005). The group includes fluvial terrace sequences of rivers that were either destroyed by or significantly modified by the overriding ice sheets that deposited the California Glacigenic Group. The pebble contents of these various gravels can be used to demonstrate the exposing history of the source areas of the sediments. Offshore delta plain sediments were deposited by the rivers as they flowed northwards across the deposits of the Southern North Sea Deltaic Group, and are predicted to pass laterally into the upper part of the Zulu Group (Stoker et al., 2011).\nThe only offshore formation assigned to the Dunwich Group is the Yarmouth Roads Formation. The base is highly diachronous being older in the south (Beestonian/Waalian), and becoming less easily definable towards the center of the basin, where it is locally contemporaneous with the fully marine formations of the Southern North Sea Deltaic Group. The formation was deposited prior to the Anglian (Middle Pleistocene Glaciation) (Cameron and\nHolmes, 1999) and is unconformably overlain by the California Glacigenic Group.\n2.4.4\tCalifornia Glacigenic Group\nThe California Glacigenic Group is established for all glacigenic formations in the southern North Sea region (Figure 2.4). The group consists of 16 formations (Table 2.2); although these are predominantly of glacigenic derivation, the occurrence of several interbedded marine interglacial units, of regional extent, contrasts with the laterally equivalent Reaper Glacigenic Group to the north. There is a change in the nomenclature between the central and southern North Sea, in part as a consequence of the mapping history of the region, but it might also reflect genuine differences across the region due to the interaction of ice derived from the UK mainland with the ice that derived from Scandinavia and mainland Europe. Ice streams obtained from south-east Scotland and northeast England, with southerly flow lines, interacted with ice derived from the Netherlands and Denmark to control the southern sector of the North Sea ice-sheet. Consequently, the northern boundary of this group, separating it from the Reaper Glacigenic Group, is defined by a combination of ice-flow separation, icesheet derivation and the northern limit of extensive interdigitating interglacial units. Despite these criteria, the accurate location of the boundary remains ambiguous, and it is likely that formations in this transitional zone may interdigitate between groups (Stoker et al., 2011).\nTable 2.2: Proposed formations of the California Glacigenic Group (Adapted from Stoker et al., 2011).\nSwarte Bank Formation\nThe base of the California Glacigenic Group is marked by the Swarte Bank Formation, which may be discontinuous and infills a fan-like array of palaeovalleys up to 12 kilometers wide and 450 meters deep that are incised into the Early to Mid Pleistocene deltaic and fluviatile formations (Southern North Sea Deltaic Group and Dunwich Group) and pre-Pleistocene strata, especially off East Anglia (Stoker et al., 2011). The valleys are believed to have been incised by subglacial processes during a major ice advance into the southern North Sea area during Anglian times. The infilling of the valleys started with stiff glacial diamictons and glaciofluvial sand, overlain by glaciolacustrine muds and culminating with marine interglacial sediments of the Sand Hole and Egmond Ground formations (see below). The age of the infilling deposits therefore spans late Anglian to earliest Hoxnian (Stoker et al., 2011).\nCleaver Bank and Tea Kettle Hole Formations\nThe Cleaver Bank and Tea Kettle Hole formations occur close to the center of the southern North Sea and they are both of Wolstonian. The Cleaver Bank Formation is a partly marine proglacial diamicton (glacial till) with clasts derived from the east and an arctic dinoflagellate assemblage (common organism in aquatic ecosystems) (Cameron et al., 1992), but also includes glaciolacustrine and glaciofluvial facies. It passes eastwards into a subglacial till which extends westwards into the southern North Sea from the Netherlands (Joon et al., 1990). The Tea Kettle Hole Formation is approximately contemporaneous with the Cleaver Bank Formation, and consists of discontinuous deposits of periglacial Aeolian sands. These units are covered by the interglacial Eem Formation (Stoker et al., 2011).\nGlacigenic Units - Well Ground, Bolders Bank, Dogger Bank, Botney Cut, Twente, Sunderland Ground and Hirundo Formations\nThe youngest suite of glacigenic units consists of seven formations: the Well Ground, Bolders Bank, Dogger Bank, Botney Cut, Twente, Sunderland Ground and Hirundo formations, which are all Devensian (Stoker et al., 2011). Periglacial, fluvial deposits include the Well Ground Formation. The Bolders Bank Formation is a widespread deposit of diamicton believed to have been deposited by a lobe of ice which moved down the east coast of England. The Bolders Bank Formation interfingers with proglacial water lain sediments of the Dogger\nBank Formation. Subglacial valleys were incised into older Pleistocene sediments and have partially been infilled by the diamictons of the Botney Cut Formation. The Twente Formation represents periglacial wind-blown sands deposited near the ice margin. Late-stage infilling of troughs as the ice retreated westwards occurred with the glaciolacustrine to glaciomarine sediments of the Sunderland Ground and Hirundo formations (Stoker et al., 2011).\nInterglacial Units Sand Hole, Egmond Ground, Eem, Brown Bank, Elbow and Southern Bight Formations\nMarine interglacial units are represented by six constituent formations: the Sand Hole and Egmond Ground formations are Hoxnian; the Eem and Brown Bank formations are Ipswichian to Early Devensian; and the Elbow and Southern Bight formations are Holocene (Stoker et al., 2011). The Sand Hole Formation is confined to an area around the modern Inner Silver Pit. In contrast, the Egmond Ground Formation occurs widely and may infill the uppermost portions of Anglian subglacial valleys overlying the Swarte Bank or earlier deltaic formations such as those of the Dunwich Group. A stratigraphical break due to the fall in sea level during Wolstonian times separates these formations from those of the next marine incursion during Ipswichian times. The Eem Formation rests unconformably on the Egmond Ground Formation and is overlain by a marginal marine deposit, the Brown Bank Formation, which may have been deposited as sea levels fell during Early Devensian times (Cameron and Holmes, 1999). A further stratigraphical break separates these formations from the deposits of the postglacial return of marine conditions into the southern North Sea. The Elbow Formation was deposited in shallow water intertidal or coastal environments and commonly includes a freshwater basal peat which, depending on location, may be latest Devensian in age. As fully open marine conditions became established the Elbow Formation was overlain unconformably by the deposits of the Southern Bight Formation, which contains several diachronous members. These members include transgressive deposits that formed around 8000 years ago and the modern mobile marine sediments, such as those found within sandwaves or sandbanks in the southern North Sea (Stoker et al., 2011).\nO R WAY\nIRISH SEA\nCELTIC SEA\nIORTHERN. IRELAND '\nQuaternary undivided\nQuaternary undivided\n/ ENGLISH CHANNEL Quaternary undivided: restricted to palaeovalleys\nFigure 2.4: Distribution of Middle Pleistocene-Holocene glacigenic groups on the UK continental shelf (Stoker et al., 2011).\nShetla Islam\n\t\t|\t_L\\-4\t\t\t\t\n1\t\t\t\tX X-\nA\tIORTH SEA\t\t\t\n\u2014200\u2014 Bathymetric contour (metres)\n2.5\tNorth Sea Main Glaciations\nIce sheets have transgressed into the North Sea on important stages of the Quaternary, contributing to the episodic erosion and infill of the basin. Although there are nu\nmerous glaciations before the so-called Elsterian glaciation, traditional models of North Sea Pleistocene glaciations suggest three major glacial episodes during the last 500.000 years: Elsterian, Saalian and Weichselian glaciations (Graham et al., 2011). Correlation between these events, formations and groups described by (Stoker et al., 2011) can be seen in Figure\n2.5.\nFigure 2.5: Stratigraphic diagram of the Pleistocene facies units of North Sea, their correlation with Stoker et al., 2011 groups and glacial events (Adapted from Graham et al., 2011).\n2.5.1\tElsterian Glaciation\nThe Elsterian glaciation occurred in the transition of Dunwich to Californian group and was probably the most extensive glaciation in the North Sea Pleistocene glacial history (Graham et al., 2011), marking a major switch in North Sea sedimentation from non-glacial to predominantly glacial deposition (Cameron et al., 1987).\nMorphologically, the evidence of Elsterian is restricted to subglacial tunnel valleys.\nThe geometry of tunnel valleys found in the central North Sea is attributed to the action of episodic meltwater erosion and its complexity suggests that the ice sheet was actively eroding and re-eroding its bed during this stage (Graham et al., 2011).\nIn the southern North Sea, buried channels contain tills and sediments derived from subglacial meltwater of probably Elsterian age, that can be assigned to the Swart Bank Formation (base of Californian Group) (Balson and Cameron, 1985). Recent detailed mi-cromoprhological, provenance and sedimentary analyses have interpreted the Swarte Bank Formation as a sublacial till, corroboring an Elsterian age for this formation (Davies, 2008).\n2.5.2\tSaalian Glaciation\nEhlers (1990) suggested that in the central North Sea region, the Saalian glaciation can be subdivided in two phases. The earliest phase (till early Saalian age) suggests the British ice-sheet occupation of the North Sea, in order to explain a south-easterly ice-sheet flow onshore (Rappol et al., 1989). The later Saalian comprises a single glacial erosion surface that can be traced through large parts of the North Sea (Cameron et al., 1987; Ehlers, 1990; Laban, 1995; Holmes, 1997). This erosion surface is overlain by glacigenic sediments, including till and glacimarine deposits within the Fisher, Coal Pit and Ferder formations, in the central and northern North Sea (Stoker et al., 1985; Cameron et al., 1987; Sejrup et al., 1987; Holmes, 1997). In the southern North Sea the late Saalian Glaciation can be assigned to the Eem Formation (Figure 2.5).\nTunnel valleys of supposed Saalian age are common across the North Sea (Cameron et al., 1987; Wingfield, 1989; Huuse and Lykke-Andersen, 2000). Graham et al. (2007) also described localized patches of sub-ice-stream bedforms (MSGLs Mega-scale Glacial Lineations) that occurs on an erosion surface at the base of the Coal Pit Formation (in central and northern North Sea), which are thought to range from late Saalian to Weichselian ages.\n2.5.3\tWeichselian Glaciation\nAt least two phases can be identified for Weichselian ice-sheet growth: one in the early Weichselian other during the Late Weichselian (Carr et al., 2006; Graham et al., 2007).\nInfilled tunnel valleys provide primary evidence for glaciation, with correlates with the Early Weichselian. In 3D seismic data from the central North Sea, Graham (2007) described well-preserved morphological evidence for paleo-ice stream activity, and inferred extensive glaciation, which may correspond to this glacial phase. Graham (2007) was able to map at least four separate suites of MSGLs, corresponding to paleo-ice stream bed signatures, within the Coal Pit Formation.\nWith the last deglaciation, the connection between North Sea and the English Channel was established between 9 and 7 kyr ago, and the North Sea only existed as a full marine basin as recently as 6 kyr. Therefore, the Southern North Sea has been exposed as a periglacial plain until the Early Holocene.\n22\nChapter 3\nThe Marine Seismic Reflection\nMethod\nSeismic reflection data obtained during a survey are records of artificially induced seismic waves, following their travelling through the subsurface and reflection at the various interfaces, providing a clear and detailed image of its geology. Seismic methods are widely applied to map the subsurface regional geology, the geometry of layered sedimentary sequences and in the search of oil and gas. Ultra-High Resolution Seismics (UHRS) which usually consists on denser data acquired with wider frequency bands above 500Hz up to 5kHz, can be used to study the near-surface geology for the geotechnical investigation of foundation conditions, essential for the construction of an offshore windfarm.\nSeismic reflection surveying can be done onshore (land) and/or offshore (marine environments), single channel or multi-channel, in 2D, 3D or 4D, and is probably the most important and used geophysical method due its wide range of applications.\n3.1\tPrinciples\nIn the seismic reflection method, the information about the subsurface geology is obtained from an incident wave, that can be split at the interface between two media with different acoustic properties into a reflected energy and a refracted portion, that continues to propagate downward with a different angle, according to the Snell\u2019s Law (Equation 3.1).\nsin (\u00a9i) _ V1\t(31)\nsin (\u00a9r) V2\t( )\nwhere Oi is the incident angle, Or is the refracted angle and Vi and Vi are the velocities of the seismic waves in the two different media.\nThe travel time is called TWT (Two-way-time) and is defined by the time taken for the seismic waves to travel from the source to an interface between two distinct layers, and then the time the wave takes to reach the receiver, allowing the calculation of the attitude and location of geological interfaces. The distinction between layers is related to the different density (p) and seismic wave velocity (V), resulting different acoustic impedances (Z - equals to the density times the seismic wave velocity). The contrast of acoustic impedance is called Reflection Coefficient (RC - Equation 3.2 valid for normal incidence).\nRC _ p2V2 \u2014 PiVi _ Z2 \u2014 Zi\nP2V2 + pi Vi\tZ2 + Zi\n(3.2)\nSeismic resolution is an essential parameter for a good quality seismic data. The frequency of waves transmitted by the source depends on the type of seismic source, leading to different frequency bands used in the survey. Depending onf the purpose of the survey different frequency bands can be used to acquire seismic reflection data, and this happens because higher frequencies are are more rapidly absorbed with depth, while lower frequencies propagate deeper. Higher frequencies have higher resolution but a low penetration, making these higher frequency bands to be more used for near-surface studies.\nVertical Resolution\nSeismic resolution is a measure of how large an individual object need to be to make it detectable with seismic data. The vertical resolution increases with higher frequencies. Frequency is expressed as number of cycles per second (1 cycle per second _ 1 Hertz), so the more cycles per second the sharper is the wave, and therefore the better the resolution. The vertical resolution is derived from the wavelength of the sound-wave and the layers can be distinguished when their thickness is larger than 4 of wavelength (A) (Equation 3.3; V is the seismic wave velocity in the layer and f is the frequency).\n(3.3)\nHorizontal Resolution\nThe sound wave sent out from the source moves in three dimensions and spreads out over an even larger area the further away it gets from the source. The horizontal resolution is mainly derived from the Fresnel Zone (Figure 3.1), the part of a reflector iluminated by the seismic wavefront at a certain depth.\nFigure 3.1: Representation of the First Fresnel Zone. (modified from: Kearey and Brooks, 1991).\nThe radius of the first Fresnel Zone depends on the seismic velocity (V), the depth of the target (t, in TWT) and the frequency of the seismic signal (f) (Equation 3.4; Sheriff and Geldart, 1995). With increasing velocities, increasing travel-time and decreasing signal frequency, the Fresnel Zone (FR) increases and consequently the horizontal resolution decreases.\nFR _V\n(3.4)\n3.2\tMultichannel Seismic Reflection Data\nThe quality of the seismic signal recorded are affected by different properties, such the field conditions during the acquisition, the type of seismic method used, the design of the source and receivers (interval between receivers and offset between the source and first receiver) and the field analysis and Quality Control (QC) on board.\nA multichannel seismic survey aims to get a multi-fold coverage, where the reflections\nfrom each point along the reflector are recorded in more than one seismic trace, for different shots (Figure 3.2). By using multiple sources, multiple receivers per trace and summing the common reflection point traces, a significant improvement of the signal to noise ratio can be achieved (McQuillin et al., 1984).\n\nShot point \u2022'''\nStrata\n. CMP 1 2 3 4 5 6 7 8\nCommon Midpoint (CMP) Position\nt.\n24\t25\t26\t27\t28 29\t30\t31\n\u2022s -------e-\n-----\nSt \u2014e------\n\u00bba e-------\nShot number&lt;/>\nHyirophone sections numbered 1 to 48 >-\nizt\n18\t19\t20\t21\t22\n3456\t789\t10\n\u2014\u2018-1-(-1-1-1-1-i\u2014\n3466\t789\t10\t11\nj-,-,-#-\u00a3-\u00a3-,-,-,\n4\t5\t6\t7\t8\t9\t10 .11\n18\t19\t20\t21\t22\t2:\n14\t25\t26 27 28 29\t30 31\t32\t48\nJ-------,------1-----j------------,------1-----1------- y, * ,\nDistance along ship's course -\n12\t3\t4\t5\t6\t7\t8\n*&lt;-\u2022-*-*---\u2018-*\u2014\n1\t23456789\nFigure 3.2: Diagram of a multichannel marine acquisition geometry, with multi-fold coverage (In Ribeiro, 2011 and modified from McQuillin et al., 1984).\nSeismic Sources\nDepending on the objective of the survey and on the resolution and depth that is required, different seismic sources can be used.\nThe most used sources in conventional oil industry seismic reflection surveys are airguns. These are devices that release a high-pressure bubble of compressed air underwater that acts as a source of energy to generate the acoustic wave. The dominant frequency of a pulse generated by an airgun is controlled by the air pressure, the size of the lower chamber\nof the device (that contains the compressed air) and by the depth of operation (McQuillin and Ardus, 1977). As the airguns work around 30-100 Hz (low frequency band) high depths can be penetrated by the signal, but the resolution of this source is lower than other higher resolution sources that use higher frequency bands. For that reason, this source is very important in the oil industry but not for geotechnical studies, where the main purpose of use of seismic is high resolution at relatively shallow depths.\nFor offshore geotechnics, higher band frequency sources are essential, such as for example Sparkers, the type of seismic source that was used in the Hornsea Offshore Windfarm survey studied in this thesis.\nThe sparker is a relatively high powered acoustic source, that consists of two closely spaced electrodes arrays immersed on a conducting fluid; these are connected to a capacitor (power supply) and a switch, to open and close the power supply to the capacitor. Discharging the capacitor creates a voltage between the electrodes high enough to cause dielectric breakdown (an abrupt increase in the electric current) of the fluid in between. During this breakdown, the fluid becomes first ionized and a current starts to flow between the electrodes (Figure 3.3). As this happens extremely fast, the observer usually sees a short spark between the electrodes, producing heat, which almost instantaneously vaporizes the surrounding water and a vapor bubble of high pressure and temperature is formed (Heigl et al., 2013).\nThe vapor bubble formed, immediately begins to force outwards the fluid around and generates a pressure shock wave. The collapsing bubbles produce a high frequency signal (up to 5 kHz).\nFigure 3.3: Shock wave emits out from an electrical spark discharge in a fluid (From: Heigl et al., 2013).\nReceivers\nIn a survey carried at sea, the receivers used are hydrophones. Within the hydrophone, a piezoelectric transducer produces an electrical signal in response to the pressure change, caused by the passage through the surrounding water of the seismic pressure waves (Dobrin and Savit, 1988).\nTo receive and record the seismic reflected waves, a streamer (long hydrophone cable) is used. The streamer is a neoprene tube where hydrophones are places by groups in regular intervals with different lengths, depending on the survey purpose. The streamer is filled with liquid lighter than water (e.g. kerosene) to make it neutrally buoyant (Sheriff and Geldart, 1995). A streamer is divided in several functional parts (Figure 3.4). The first component connects the vessel and the first group of hydrophones. This ensures the minimum interference from the vessel\u2019s movement in the streamer (Pereira, 2009). Hydrophones are arranged in sections called \u2019\u2019live sections\u201d and in each section, can be implemented with twenty or more hydrophones spaced approximately 1m. In terms of seismic processing, the signals received at each hydrophone inside the same section are summed up and this is considered as a single receiver group (or channel). This technique improves the signal-to-noise ratio but when there is a great component of noise acquired with the signal, it can damage the quality of the data (Alfaro et al., 2007).\nThe \u2019dead sections\u201d (Figure 3.4), or sections without hydrophones, are placed between live sections to give the desired length and configuration to the streamer. After the last live section, there is a buoy equipped with positioning system tools that can communicate with the vessel (Figure 3.4). The buoy is used both to calculate the positioning of the streamer and to reduce the drift of the streamer due to water currents (Pereira, 2009).\nFigure 3.4: Schematic representation of a streamer configuration (In Ribeiro, 2011 and modified from Telford et al., 1990).\nIn seismic surveying, to minimize the noise generated due to the vibration of the cable and the vessel\u2019s movement, McQuillin et al. (1984) suggests several methods to reduce these effects:\n\u2022\tShip motion is decoupled from the streamer by using an elastic non-active lead-in section; this absorbs the ship\u2019s heave motion allowing the cable to be towed at a constant speed through the water;\n\u2022\tStreamer depths controller \u2019\u2019birds\u201d - are used to maintain a constant depth along the length of the streamer;\n\u2022\tLead-in sections to the cable can be \u2019smoothed\u201d (rubber or tissue strips can be attached to it) to reduce noise induced by tugging;\n\u2022\tInstead of single crystal element hydrophones, dual crystal element hydrophones are used which have very low sensitivity to horizontal accelerations, one of the main sources of noise problems.\n3.3\t2D and 3D Seismic Surveys\n2D Seismic Data\nTwo-dimensional marine seismic data are normally acquired along spaced straight lines at distances from each other that usually range from hundreds of meters to several kilometers. In marine seismic surveys, a single seismic vessel is normally used with one airgun array, or another seismic source, and a single streamer. Theoretically the content of the 2D seismic data has only information about the subsurface vertically below the acquisition path. However, the received signal has contributions of reflections from points outside the acquisition path. In terms of comparison, two-dimensional seismic sections can be considered as cross-sections of a seismic volume (Yilmaz, 2001a).\nNowadays, and due their low cost, high efficiency and good imaging capacity, 2D seismic surveys are the first exploration method used in offshore. However, for a more detailed study, the use of a 3D seismic survey may be required to clarify and adequately image with high detail in 3D specific locations detected in the previous 2D surveys.\n3D Seismic Data\nThe acquisition of three-dimensional seismic data started in 1976 (Sheriff and Geldart, 1995) and rapidly increased its importance for the petroleum industry due to its high vertical\nand lateral resolution even for great depths (Gomes and Alves, 2007). 3D seismic acquisition has been used in the last decades in the hydrocarbon industry but has had limited application in near surface engineering surveys (Muller et al., 2009).\n3D seismic is distinguished from 2D seismic by the acquisition of multiple closely spaced lines that provides regular data that allows 3D data migration during processing. Three-dimensional surveys provide seismic data volumes (often simplistically called cubes), making it possible to follow seismic events in 3D along the survey. The results of these surveys are used to detail the contours of exploration fields and plan further development. The number of times a CMP, or bin in 3D, is sampled represents the fold of the data inside a bin - a small square area that is treated as a single reflection point in 3D data processing. To synthesize, while in 2D the seismic data is sorted into common-midpoint gathers, in 3D seismic data requires binning the record data into common-cell gathers (Yilmaz, 2001a). Underestimating the need for a sufficiently detailed seismic exploration at this stage can result in serious economic mistakes in field development planning (Tissen, 2012). This way, according to Volkhard and Florian (2017), in an offshore windfarm survey, a 3D model can provide:\n\u2022\tComprehensive overview of the study area\n\u2022\tFocused planning of sites (site optimization based on geological conditions at a very early stage)\n\u2022\tOptimized planning of expensive coring / Cone penetration tests\n\u2022\tHigh flexibility throughout the entire planning phase, e.g., when offshore wind turbine locations are changed at a later stage\n\u2022\tRisk mitigation\n\u2022\tNo additional geophysical surveys required subsequently\n\u2022\tEasy and instantaneous generation of subsoil profiles at any position in the windfarm\nSeismic Surveys\nIn conventional 3D seismic surveys, the data is acquired by a single vessel, sailing in straight parallel lines by regular intervals between the lines, with multiple streamers and a variable number of sources (Figure 3.5).\nIf well planned, the traditional acquisition geometry (1 source and straight parallel lines) is enough to obtain a reasonable imaging of the subsurface for almost geological environments. However, despite imaging limitations depending on the geological context and the objective of the survey, different geometries can be used, such wide-azimuth. This method is quite identical to the traditional method, but with at least two seismic sources. The Wide-azimuth acquisition technique provides a general increase in coverage for all azimuth-offsets when compared to the traditional acquisition system.\nFigure 3.5: Representation of a 3D seismic data acquisition. (Source: http://www.bulwarkservices.com/services/marine-acquisition-system).\nQC During the data acquisition\nDuring the surveys, problems related with the acquisition system, such as source and receiver positioning errors, malfunction of the source (miss shots, different source signature than expected) or dead channels may surge. For that reason, the quality-control (QC) of the data that has just been acquired is essential to detect those problems as soon as possible. This way, the costs of the survey can be reduced, avoiding the need of long travel distances to re-acquire a seismic line that was not correctly acquired for some reason, and also allows an improvement of the data quality.\nAlthough this is a most important step during the acquisition, the time of reaction to detect an issue may still too long and it can be too late to solve the problem on time to reduce the costs of the survey. To solve that, Real-Time QC can be used to detect any issue during the seismic gathering.\n3.4\tBasic Seismic Data Processing Flows\nStandard seismic processing flows are fully implemented and well known in the industry with the goal to increase the vertical resolution, improve the signal-to-noise ratio of the data and display the seismic events in their correct spatial position, to obtain a better imaging of the desired geological information contained in the seismic data (McQuillin et al., 1984; Dobrin and Savit, 1988; Kearey and Brooks, 1991; Yilmaz, 2001a,b). For a suitable and organized file format for processing purposes, the conventional standard for seismic files is SEG-Y (Yilmaz, 2001a).\nAccording to Yilmaz (2001a), there are three primary stages in seismic data processing. Each one is aimed at improving seismic resolution the ability to separate two distinct events that are very close together, either spatially or temporally:\n\u2022\tDeconvolution is performed along the time axis to increase temporal resolution by compressing the basic seismic wavelet to approximately a spike and suppressing reverberating waves.\n\u2022\tStacking compresses the offset dimension, thus reducing seismic data volume to the plane of the zero-offset seismic section and increasing the signal-to-noise ratio.\n\u2022\tMigration is commonly performed on the stacked section (which is assumed to be equivalent to a zero-offset section) to increase lateral resolution by collapsing diffractions and moving dipping events to their supposedly true subsurface positions.\nSecondary processes are also implemented at certain processing stages to condition the data and improve the performance of deconvolution, stacking, and migration. For example, when typical noise filters are applied, deconvolution and velocity analysis may be improved. Residual statics corrections also improve velocity analysis and, hence, the quality of the stacked section.\nA simple processing flow for seismic data is composed of a preprocessing stage, which includes: demultiplexing (sorting the data into organized and usable data per shot gathers), trace editing, spherical divergence and geometry corrections, and a processing flow which normally includes: deconvolution, common midpoint sorting (CMP), velocity analysis, normal\nmoveout correction (NMO), CMP stack and migration. In 3D seismic data, common reflection points are designated as \u2019\u2019bins\u201d, corresponding to small 2D areas, instead of common midpoints (Yilmaz, 2001a).\nIn the preprocessing stage, trace editing consists on the correction or removing of noise or polarity reversed traces. Most of the times, the marine data is affected by very low frequency noise due to swell and to movements of the streamer. This noise is easily removed with the application of low-cut filters. However, if these effects are still observed in some traces even after low-cut filtering, the common practice is to delete those traces, as otherwise they will decrease the signal-to-noise ratio of the seismic data (Yilmaz, 2001a).\nAmplitude corrections are performed in order to correct the amplitude decay with time/depth due to spherical divergence and energy dissipation in Earth. The spherical divergence correction is a spatially averaged velocity function which is applied to compensate the effects of the wavefront divergence. A gain function may also be used to compensate the attenuation losses.\nThe seismic data is adjusted with the geometry acquisition used in the field, to correct the position of shots and receivers. Many types of processing problems arise at later stages due to the wrong geometry application, and as result the stacked profiles can be brutally degraded (Yilmaz, 2001a).\nDeconvolution consists in an inverse filtering technique used to compress the wavelet shape in the data, recover the high frequencies and attenuate certain events as multiples: events that occur in seismic data, when a seismic event has incurred more than one reflection in its travel path and are produced when the signal does not take a direct path from the source to the geologic event (Yilmaz, 2001a). There are two main classes of multiples: long-path and short-path multiples (Sheriff and Geldart, 1995). ). A long-path multiple is one whose travel path is long compared with primary reflections (seabed multiples for example) (Figure 3.6). A short-path multiple arrives soon after the associated primary reflection and can interfere with the original event; these are sometimes designated ghosts. Near-surface multiples and ghosts are short-path multiples, originated by the deep tow of the seismic source/receivers (Figure 3.6), producing a high amplitude pulse of negative polarity.\nAfter the use of deconvolution, vertical resolution is substantially increased (Yilmaz, 2001a).\nFigure 3.6: Ray paths of Ghosts and Seabed Multiples (modified from Hatton et al.,1986).\nVelocity analysis is performed on selected CMP gathers or group of gathers (supergathers). The velocity model is then created and used to correct the normal moveout (NMO) of the CMP gathers. This correction removes the source-receiver offset effect in a non-dipping seismic reflector, assuming that the reflection travel-time follows a hyperbolic trajectory. The greater the offset between the source and the receiver, the larger is the delay observed. In the NMO correction, seismic events corresponding to seismic reflections are flattened across the offset range in order to remove the offset delay effect (Figure 3.7), so they can be summed (Yilmaz, 2001a).\nS6 S5 S4 S3 S2 Si\tRi R2\tR3\tR4 R5\tR&amp;\nW\"\t--\t'\tt\ti\t4\t4\t~\n' 1 'x\t-\t\\ s\t\\ X\tX\t\\\t' \u2022\"* X\tx \\ I\t\u2022 ' / '\ns \\ I\t!\t/\t/\tx\n* /\tx\tX\t\\\t\\ V1P1\tV V\tX \\ X x x\t\\ \\ \\\t. I f\t' !;/\n\"V Y'V\t11 '\t''\tSn = Source\n\u2022s\u00bb. x'\tRn = Receiver\nV2P2\t\nBefore NMO Correction\tAfter NMO Correction\nFigure 3.7: Sorted seismic traces by CMP and NMO correction (modified from: https://commons.wikimedia.org/wiki/File:NMO_Correction.png).\nAfter the NMO correction, the seismic traces that correspond to the same reflection point (CMP) are stacked/summed (Figure 3.8). With this process, random noise will tend to be attenuated. While the random noise tends to cancel itself, the signal is summed up, leading to a significant increase of signal-to-noise ratio.\nStacked\nN M O Corrected traces\tTrace\nFigure 3.8: Before and after stack. The amplitude of the reflection is enhanced, leading to an increase of the signal-to-noise ratio (modified from: http://www.glossary.oilfield.slb.com/Terms/s/stack.aspx).\nThe last step of the traditional processing flow is post-stack migration. Assuming a realistic velocity model, the migration process will move the dipping events into their true positions, collapsing diffractions and increasing the spatial resolution of the data. This process can also be applied before stack (pre-stack migration). The pre-stack migration is applied in the offset trace domain instead the CMP domain and is necessary in cases where there is an abrupt variation of lateral velocities, but is highly time-consuming and requires a heavy computation process, meaning that is an expensive migration (Yilmaz, 2001a).\nAn extra step is necessary for the 3D processing: the 3D Regularization. The purpose of this step is to make uniform distribution of offsets by interpolating offset bin volumes, creating a seismic block itself.\nAlthough Quality Control is not technically part of the processing flow, it is one of the most important steps during the seismic processing, in order to assure the quality of the data in each process and detect issues that can compromise the quality of the final seismic data.\n3.5\tSeismic Data Interpretation\nSeismic data interpretation is an exhaustive data analysis process that can be complemented with the geological information associated with the seismic volume. If well correlated with external information it can create a reliable geological model (Yilmaz, 2001a). The interpreter must combine the various components of the data set (3D seismic cube, 2D lines and well log data) in order to recognize seismic patterns that can give important information about depositional environments and the structural geology of the area.\nA careful and deep interpretation of 3D seismic data allows accurately mapping geological features, thereby characterizing the respective depositional systems in the survey area. UHRS, due its higher resolution, allows the interpretation of small objects such boulders, an important step to decrease the probability of failed foundation implementations for offshore geotechnical engineering. A careful interpretation of geological features in the seismic data is therefore a key for the success in high resolution seismic studies for foundations of offshore structures.\nChapter 4\nData and Methodology\nDuring a seismic survey, the QC of the acquired data frequently represents a procedure in which a large amount of time is invested, even more with the continuous increasing size of the data in most recent surveys. In order to reduce the time consumption on this stage as well as to avoid the need to allocate more people and resources, a Real-Time QC automatic tool was designed and tested. This tool was tested in the Hornsea Offshore Windfarm Project One data, acquired in the Southern North Sea (See Section 2.1). The traditional QC procedure applied during the seismic survey is described below, so as to be later compared with the Real-Time QC results obtained in the scope of this work.\n4.1\tData\n4.1.1\tHornsea Project One Survey Operations\nThe survey operations took place from 25th of July till the 11th of September 2016, on board of MV Bibby Tethra vessel, (Figure 4.1), a 27.50m long catamaran, in the Hornsea Project One Offshore Windfarm, East of England. The aim of the survey was to acquire UHRS 3D data and MBES (Multibeam echosounder, used to acquire bathymetry) over the location of 58 boxes (WTG\u2019s - Wind Turbine Generator) of 100x100m with a target depth of 20m and 4 boxes (Substations) of 100x100m with a target depth of 70m, as also information of the corridors between the boxes, according to the survey plan.\nAlong with the acquisition, the QC and on board processing provided by GeoSurveys was developed in order to meet the project objectives, mainly focusing on the equipment positioning, source heave, streamer depth and full seismic coverage on Wind Turbine Generators and Substations areas.\nData Acquisition\nDuring the survey period (49 days), approximately 1600km of 3D prime line were acquired, including line turns and reruns/infills (lines that were reacquired due to system recording problems or in areas with low seismic data coverage), leading to over 2200km of data recorded (composed by 35% of reruns/infills).\nFigure 4.1: Bibby Tethra vessel.\nFor the acquisition, two sparkers were used, with a nominal distance between the two sources of 16m. The streamers used were 4 Geo-Sense with 24 channels each, with an active group length of 36m. Group intervals varied, with 1m for channels 1-12 and 2m for channels 13-24. The streamers were placed between the two sources, with a nominal distance between them of 4m, and 2m from the sources (Figure 4.2). Two single element reference hydrophones were also used, for source signature purposes.\nFigure 4.2: Sources and streamers geometry (upper view) (Source: GeoSurveys project report).\nThe streamers were balanced to create a slanted configuration. This way, the acquisition was done with the head at 30cm below surface and the tail approximately 1m (Figure\n4.3). By using a slanted streamer, the receiver registry varies with offset as the cable depth varies from near to far offsets. This method allows a better deghosting than a non-slanted streamer, increasing subsequently the signal-to-noise ratio. Before the acquisition, tests were carried out to measure the quality of the streamer balancing.\nFigure 4.3: Acquisition Geometry scheme (Source: GeoSurveys project report).\nIn order to have a precise positioning, a GNSS (Global Navigation Satellite System) positioning was provided. The device was able to perform the position with an accuracy of 0.08m XY and 1.5m in Z axis. A secondary GNSS positioning was provided to deliver a submeter DGPS accuracy, after the necessary positioning corrections. Beacons were installed on the sources and on lead and tail buoys of every streamer.\nSeismic Data Quality Control\nTo assure that the data are successfully processed, and to guarantee at least the minimum data quality necessary to produce the final result, the acquired data went through a strict quality control of the signal quality, to finally confirm if the coverage has the minimum required (Figure 4.4).\nThe offshore Quality Analysis/Quality Control workflow consisted on the following\ntasks:\n1.\tVerification of the converted SEG-Y files;\n2.\tNoise analysis;\n3.\tSignature verification;\n4.\tShot and trace gather analysis to verify source and streamer group integrity;\n5.\t5. Verification of the seismic coverage on the Wind Turbine Generator areas (WTG) and Substation areas (OSS) after a brute stack version (an initial stacked version of the data without the full processing flow applied) and upload to an interpretation package.\nFigure 4.4: Offline Quality Control/Quality Analysis processing workflow. In yellow: processing datasets created; in blue: numbered from 1 to 5 - QC workflow steps.\nVerification of the converted SEGYs\nAfter the acquisition of each seismic profile, the multi-trace files were merged and converted into a single SEG-Y file. Once the conversion was completed the next procedure was to verify if:\n\u2022\tConversion was done properly, without corrupting the file;\n\u2022\tNumber of FFIDs (Field File Identification Number) was corrected;\n\u2022\tThere were bad shots that were need to be deleted;\n\u2022\tData were considered good, marginal or bad for processing.\nNoise Analysis\nThe seismic data were analyzed in shot and trace domains to identify potential noise patterns, so as to later establish ways to suppress their presence in the sub-bottom profile. Typical noises recognized include:\n\u2022\tVessel Operation Noise\n\u2022\tTugging noise\n\u2022\tDC Noise\n\u2022\tElectrical Induction\n\u2022\tBurst noise\nVessel Operation Noise\nRotating propellers of the vessel generate low frequency noise. Cavitation can also create noise, occurring when a propeller operates outside its design window, generating noise in the data (Elboth and Hermansen, 2009).\nThe vessel operation noise was acquired before the data acquisition of every line (and also after the acquisition). Spectra were calculated for each source and compared with the vessel noise. As seen in Figure 4.5, the noise is limited to low-frequency bands. As such, it can easily be removed without a negative impact on the signal, due their different frequency bandwidth.\nFigure 4.5: Spectral comparison between Vessel Noise and data acquired.\nTugging Noise\nTugging noise (Figure 4.6)is caused by sudden movements of the vessel due to wave motion, as also due the vibrations or strumming from the lead-in cables. This noise is most visible in the first channels on a streamer, and is characterized by large amplitudes in a narrow low frequency band (Elboth and Hermansen, 2009). As this is a \"linear\u201d noise, can be removed with a F-K filter, but, as this noise is a low frequency noise and does not overlay the signal, it can also be removed with a low-cut Butterworth filter (the reader is advised to consult Seismic Data Analysis by Yilmaz, for a detailed information about noise filtering specifications).\nFigure 4.6: Example of Tugging Noise observed in the data.\nDC Noise\nDC bias, or DC offset, is the term referred to a direct current voltage. This is a very low frequency noise that can be easily detected in the raw data, characterized by high amplitude vertical bands along the whole data (Figure 4.7). The DC removal is one of the first steps in data processing.\nFigure 4.7: Example of DC Noise observed in the data.\nBurst Noise\nSeismic data often contain traces that are dominated by noise that can be caused by the streamer surfacing (Figure 4.8). This way, in order to increase Signal to Noise Ratio, burst noise/spikes should be removed. They can be removed by comparing the amplitudes of each trace to those traces that are nearby, rejecting the outliers.\nFigure 4.8: Example of Burst Noise observed in the data.\nElectrical Induction Noise\nNoise caused due the proximity between the streamer and sparkers, affecting mainly the first channels of each streamer (Figure 4.9).\nFigure 4.9: Electrical induction visualized on the near channels of the 4th streamer (CH 73-75) in Source 0 (vertical scale in ms).\nSignature Verification\nThe spectral response of the data was analyzed based on the wavelet derived from a seabed reflection stack and compared with the reference hydrophone records, in order to assess the recorded signal stability.\nIn the final processed data delivered to the client an extracted signature from the data was used. Nevertheless, in a real-time on board QC, the signature used must be the one that is created before the acquisition.\nA reference wavelet and a spectral analysis were calculated, displaying main frequencies between 0 and 5000Hz (Figure 4.10b).\nFigure 4.10: Example of a recorded sparker wavelet firing for both sources (a); with the corresponding frequency spectrum (b) (Source 0 in green; Source 1 in orange).\nSource and streamer group integrity\nStreamers integrity can vary depending on the sea conditions, wave motion, vessel navigation, surface currents, acquisition velocity, positioning precision and minor modifications of the system geometry during equipment recovery and deployment operations. These conditions may have a negative impact in the quality of the final seismic data, such as intensification of ghost or multiples, making it harder to apply the deghosting and multiple attenuation.\nThe most evident effects during the survey were vertical motion of the streamer due to bad weather (Figure 4.11) and those associated with acquisition velocity (Figure 4.12).\nFigure 4.11: Line acquired on bad weather. Vertical motion can be noticed along the streamers registry.\nFigure 4.12: High vessel speed during the acquisition in the beginning of the seismic line (until FFID 49500 approximately). Cable depth (cm) is represented in blue line and cable heave (cm) in pink line.\nTrouser\u2019s effect (caused by strong propeller wash of the vessel) is also evident (Figure 4.13). Trouser\u2019s effect is detected when seeing the movement of streamers. In Figure 4.13, the theoretical disposition of channels in a slanted acquisition would be a gradual change between purple (near channels of streamers) and red (last channels). In the figure below streamers are in general in a slanted position, but not completely linear, and the depths are completely different between streamers, especially in streamer 1 and 2, where most of streamer has depths around 0 meters (most blue color). This problem also generates changes of offsets between streamers.\n75\n50)\n25 f z ;\n&lt;:\nx -\nO :\n15000\t17600\t20000\t22S00\t26000\t27600\t50000\t32600\t36000\t37600\t40000\t42600\t46000\nFFID\nFigure 4.13: Trouser's effect due to strong propeller wash of the vessel (purple represents depths around 0 meters and red represents higher depths).\nCoverage Verification\nAfter seismic data QC, deconvolution, geometry assignment, statics correction and bad shots elimination steps were done so as to later verify the coverage, and check if there were gaps in the data. The parameters for geometry assignment on board were a CDP binning of 2m, for this stage, and above 12 of CDP fold to consider a sufficient covered seismic dataset (for the final processing, different grids of 1m and 0.5m bin were used, depending on the block processed in the office). If there were any seismic data gaps that 3D regularization would not be able to fill, with special attention inside WTG (Wind Turbine Generator) and OSS (Offshore Substation) areas, series of infill had to be planned onboard to improve the full coverage of the seismic volume.\nRe-acquisition\nBefore beginning the campaign a survey plan was defined, in order to establish the expected navigation line length necessary to properly cover the whole area. According to the plan, the survey area would be covered with approximately 1640km, in ideal acquisition and data results.\nDuring the survey, however, due to equipment malfunction or bad weather, some lines have been aborted and needed to be repeated.\nWith the lines acquisition concluded and bad/dead traces removed, through the fold analysis, it was verified that it was necessary to re-acquire data in particular areas, to fill the empty gaps and grant a good representation of the subsurface data. Some of the uncovered\nareas that needed to be filled in were related with acquisition issues (like navigation or bad weather), others were related with the kill of bad records during the QC. Only after killing the bad traces it is possible to recognize the real coverage within the acquired data. This means that after the seismic line acquisition, only after a certain period of time (enough to pass data through QC stage) is it possible to discriminate areas where re-acquisition is needed. Some processing is also needed before this decision, to know if the interpolation used to build the block is acceptable for the available data; otherwise the acquisition of new lines needs definitely to go forward.\nFigure 4.14 shows the acquired and the expected line length, as also the Prime lines and Infill/Rerun percentage of the total data acquired for each seismic block.\nFigure 4.14: Statistical graphics showing the kilometres (a) and percentage (b) of the difference between the estimated line plan and the acquired data.\n4.1.2\tSeismic Data Processing\nAlmost 200km length (including reruns/infills) of UHRS data were processed using RadexPro software, to build the block B27H27. The processing flow applied (Figure 4.15) was designed by GeoSurveys with the final objective of improving the seismic section resolution and overall signal quality. It is expected that in future surveys, the seismic input of the processing flow corresponds to the seismic output obtained after the Real-Time QC tested here, as long as a correct flag of the data is granted. Due to confidentiality reasons and as the main objective is not directly affected by the processing flow applied, some of the processing details are not fully developed here.\nFigure 4.15: Processing flow applied to the seismic profiles.\nNoise Filtering\nThe noise patterns verified during the Survey Operations QC (see Section 4.1.1 - Noise Analysis) were removed by applying different filters, such Bandpass filters (mainly to cut low-frequency noise) F-K filtering or DC Removal, depending on the type of noise (the reader is advised to consult Seismic Data Analysis by Yilmaz, for further information about noise filtering specifications).\nPre-stack signature deconvolution\nTwo different source signatures were created for the source configuration and used to deconvolve the seismic data-set trace by trace, for each signature. These signatures were modeled and stacked using an average seabed reflection resulted from a selection of 200 traces from 10 different lines.\n3D CMP Binning\nThis is a method identical to the Crooked Line binning used in 2D seismic profiles, but applied for 3D data. The data area is divided into regularly spaced rectangular bins and the middle point coordinates calculated. During the processing, different binning grids were applied. A first grid binning with 1 meter was applied during the UHRS Statics stage, while a 0.5 meters binning grid was applied afterwards.\nUHRS Statics Correction\nThe residual static correction procedure was applied to compensate the vertical motions of the towed equipment. This correction can be divided into three major components: Receiver Statics, Source Statics and Swell Statics. Tidal corrections were also applied to the data, to remove the sea level variations caused by tides.\nInteractive Velocity Analysis and NMO Correction\nSupergathers (formed by combining several CMP's, to enhance continuous reflectors) were generated every 400 inlines comprising 3 inlines and every 200 crosslines, comprising also 3 crosslines. The velocities were picked using the Interactive Velocity Analysis (IVA) tool in RadexPro, to be later used in the NMO Corrections, function that will shift every sample back to the true \u2019\u2019zero-offset\u201d time.\nAmplitude Corrections\nSpherical Divergence and dB/sec amplitude recovery corrections were applied to the data to compensate respectively the loss of amplitudes due the spherical wave front spreading and attenuate the amplitude decay with time. Spherical divergence correction was applied before the NMO Correction, while a established value of 300 dB/sec was applied after the migration.\nMultiple Attenuation\nThe multiples were attenuated by using the Zero-Offset DeMultiple (pre-stack) tool provided by RadexPro, based on the subtraction between the data with a model of multiples created.\n3D Regularization and CMP Stack\nWith the 3D Regularization (process of introducing additional information) it is expected to get an uniform distribution of offsets, by interpolating offset bin volumes. After it, CMP Stack was performed.\n3D Kirchhoff Migration\nWith the Interactive Velocity Analysis obtained previously (RMS velocities), the true geometry of primary reflections was recovered.\n4.1.3\tSeismic Data Interpretation\nA Kingdom Suite project was created in order to include all the seismic data of WTG (Wind Turbine Generator) areas of the block B27H27 along with the area that connects these WTG's.\nDifferent seismic data types were imported into Kingdom Suite Project:\n\u2022 Non-migrated amplitude seismic data\nUsed to detect diffraction events (caused by diffracted energy resulted from abrupt changes in seismic impedance) and find anomalous bodies such as boulders, important in marine geotechnical structures (Figure 4.16).\nFigure 4.16: Non-migrated section of the processed data.\n\u2022 Migrated amplitude seismic data\nUsed to collapse diffractions and also increase spatial resolution (Figure 4.17).\nFigure 4.17: Migrated section of the processed data.\n\u2022 Envelope seismic data calculated based on the migrated data\nThe Envelope seismic attribute has only positive amplitudes, highlighting \u2019packages\u201d of amplitudes (enhance higher impedance contrasts and attenuate the lower ones). This method is also used to detect boulders (Figure 4.18).\nFigure 4.18: Envelope data type, calculated based on the migrated data.\n\u2022 Paraphase seismic data calculated based on the migrated data\nTool provided by Kingdom Suite, identical to instantaneous phase, used to clarify continuities of seismostratigraphic events (Figure 4.19).\nFigure 4.19: Paraphase data type, calculated based on the migrated data.\nAlong with these seismic data types, the project also included CPT (Cone Penetration Test) analysis provided by the client, in order to complement and calibrate the seismic data and make a correct correlation between the field and seismic data. GeoSurveys further made a soil classification based on the provided CPT data to find a good match with the seismic data.\nThe seabed horizon was picked in whole block (using an automatic picking tool), while the geological interpretation was carried inside the Wind Turbine Generator areas and with a 21m depth below seabed (depth defined by the client).\nThe horizons were first established by GeoSurveys based on existent published data and its correlation with the survey area, in order to identify the main horizons, defining this way, the horizons displayed on Table 4.1. Some of the horizons are internal features of a main stratigraphy, due to the evident existence of different stages inside some of the formations, as the case of Bolders Bank formation, Swarte Bank formation or the Holocene. The criteria to decide which formation must be picked on the seismic data was explained in GeoSurveys to all the personnel involved in the project, in order to standardize the criteria and avoid completely different interpretations between different interpreters.\nHolocene Sand Dunes Base Internal feature 1\n=\tCobbles layer\n\tHolocene\n\tBotney Cut\n\tBolders Bank internal horizon 3\n\tBolders Bank internal horizon 2\n-\tBolders Bank internal horizon 1\n\tBolders Bank Base\n\tLacustrine Eem internal feature 1\n\tLacustrine Eem Base\n\tMarine Eem Base\n\tEgmond Ground\n\tSwarteBank internal horizon 1\n\tSwarte Bank\n4.2\tReal-Time Quality Control\nIt is well known that in order to have good quality seismic data, an efficient quality control of the data must be done, besides a good seismic processing. Thus, to achieve a better quality control without compromising the schedules by spending more time with QC, new tests were done in the scope of this work, to test and establish an automatic Real-Time QC stage, to be used as long as the data is being acquired.\nSeveral software beta tests in SPW were done to assure a stable operation by the Real-Time QC tools, along with the development of a procedure that will work correctly.\n4.2.1\tSoftware Beta Tests\nDifferent tests were done in multiple SPW beta versions, to analyse the correct operation of Spectral Comparison and Signal to Noise Ratio Attribute tools used for this purpose, and described below. The problems found (from software bugs to gaps that must be included in SPW and improvement suggestions on the existent functionalities) during the beta tests were reported to the Parallel Geoscience team, that made several updates on SPW based on these reports.\nAlong with the beta tests on the QC tools, a simulation of the acquisition during a survey was also done, to assure the adaptation of the software with the equipment used on board. The device used to record the data (Multi-trace - a multi-channel recording system built by GeoMarine - Figure 4.20a) was connected in the same way that is connected in a real acquisition, but without connection to a real source and receiver. The multi-trace was connected to a device with the software used to gather the data (GeoRecorder - Figure 4.20b) through a router used as a plug splitter for the Ethernet connection. At the same time connected to the same router, another device, this one with SPW (Figure 4.20c), was tested to be able to receive the data that the GeoRecorder is receiving, with no negative impact to the normal data gathering. The data is stored as an usual raw data (SEG-Y format) (Figure 4.20b) while another copy of the same data is stored with the flagged traces/records that did not pass QC test (Figure 4.20c).\nFigure 4.20: Connection between SPW device and Multi-trace.\n4.2.2\tSpectral Comparison\nThe Spectral Comparison tool allows comparing the amplitude spectrum of each single trace of the seismic data against a reference amplitude spectrum.\nThe spectral comparison is based on the semblance ratio between each seismic trace and the reference spectra, as if both amplitude spectra were overlapped and then measured their semblance. In SPW, this measure of spectral semblance is calculated by Equation 4.1:\nSemblance =\t[F(f) + G(f)]2\t(4 1)\nbemoianee 2 *\t(f)2 + G(f)2]\t(4.1)\nwhere G(f) is the amplitude spectrum of the input seismic trace and F(f) is the amplitude spectrum of the reference data.\nThe flow used to calculate the spectral semblance and flag traces is shown in Figure 4.21.\nFigure 4.21: Processing flow for the Real Time Display.\nTo get the data that is being acquired in real-time, a TCP/IP Data Input is needed (Figure 4.21). This parameter, by using the same IP address that multi-trace is using, will be able to receive the data in real-time in parallel, with no impact to the normal acquisition system. In case there is a need to fill some header, it is possible to select in SPW the required parameter to replace the headers from Sample Format, Sample Interval, Number of Samples and Number of Channels (Figure 4.22). If the Overwrite dataset parameters is not selected, the data output will have the raw data original headers for these parameters. Notice that to test the Spectral Comparison parameter, a SEG-Y input was used instead the TCP/IP Data Input.\n\u00bf2 TCPIP Input Field Data\nX\nTCP/ IP address\n169.254.33.44\n\u00ae Input from Georesource system\nGeosource parameters\n0 Overwrite daUset perimeters Sample Format flurnber of Samples\t2 c \u00a12000\tSample Interval (ms) Number of Channels\tliu 1 |24_\nConnection timeout (ms)\t3000\tNumber of shots to skip Data read delay (ms)\tF\t1 \u00a1100\nSrloca parameters\nApply surface geometry\nApply VSP geometry\nOutput SEGY files containing geometry\nPerform vibrosets correlation\nOutput correlated SEGY files\nSum common shot records\nFigure 4.22: TCP/IP Input parameters.\nThe seismic data traces can be compared with four different parameters provided by SPW (Figure 4.23):\n1.\tOne signature per dataset from auxiliary seismic file\nWith this option, the spectrum of each seismic trace is always compared against the spectrum of a fixed auxiliary seismic file. By default, the reference signature trace is always the first trace of the auxiliary record. Despite this, an update now allows to choose the number of traces to compare, depending on the number of sources. This way, each trace will be used to compare with the right source data. To use this, it is needed to use the option Match signature based on trace header.\n2.\tMatch signature based on trace header\nThe same calculation method used in One signature per dataset from auxiliary seismic file, but reads the trace with the source number to correlate the right source with the right data.\n3.\tOne signature per record from input data file\nIn this case, the spectrum of the current seismic trace is compared against the spectrum estimated from a changing seismic trace corresponding to a given channel number from record to record.\n4.\tCompare to average of prior traces in dataset\nBy selecting this option the spectrum of the current seismic trace is compared against the mean spectrum estimated from a moving window built from the n previous seismic traces;\n5.\tCalculate spectral semblance on receiver line basis\nThis parameter allows defining a time window (in milliseconds) on each trace to calculate the frequency spectrum to be used to compare with the whole record data.\nSignature comparison input\nO One signature per dataset from auxiliary seismic file\nO One signature per record from input data file\nInput channel number 5^\n@ Match ignatixe based on trace header\nSelect header location for source number User defined 9\tT\nO Mean signature per record from input data file\nMinimum channel number 1\nMaximum channel number 96\nO Compare to average of prior traces in dataset\nNumber of prior traces in roling window\t\u00a121\nO Calculate spectral semblance on receiver line bads\nStart time fix signature analysis (ms) [9.5\nEnd time for signature analyse (ms) 115.0\nFiltering\n0 Apply low-cut filter\nLow-cut corner frequency (Hz) \u00a1100 Low-cut roloff rate (dB/oct) 23\nQ Apply high-cut filter\nHigh tut owner frequency (Hz) 72\nHigh-cut roloff rate (dB/oct) 18\nAttribute\nSelect output header location for spectral semblance\tUser defined 1\tT\nSelect output header location for quality flag\tUser defined 2\tT\nSpectral semblance cutoff (percent) \u00a180.00\nStart time for analyse (ms) \u00a10.0\t~| End tome for analysts (ms) | L50.0\nAudio alarm\nPercent (%) limit of failed traces 1100.0\t~| Volume test\nLow\t|\tHigh\nAlarm volume\nAlarm Browse... C:AJsers/Usef/Docijments/spw/waming.mp3\nReport file\nFile Browse...\tSpectraKompareReport.txt\nD Append to existing file\tQ Display report in separate window\n\u25a0*\u2019\nFigure 4.23: Spectral Comparison parameters.\nFor the Spectral Comparison of the data, the first parameter described above was used, and Match signature based on trace header was tested when it was available. The signature file used for comparison was the one extracted from the data. This extraction was modelled and stacked using an average seabed reflection, resulted from a selection of 200 traces from 10 different lines. A distinct signature was calculated for each source, as shown in Figure 4.24.\nFigure 4.24: Extracted wavelet for both sources (a); Frequency Spectrum of source signature: Source 0 in blue; Source 1 in green.\nAlthough the extracted signature was mainly used for comparison purpose (to use the same signature that was used to process data), the signature that will be used in real-time is the one acquired before the survey, during the sea trials. In the mid-term, the objective passes to use the signature that is provided by the reference hydrophone, with some barriers that are needed to overcome, such source signature stabilization, to grant that a bad record signature will not be used for QC.\nTo plot the information calculated by the Spectral Comparison step, the Real-Time Data Quality Analysis (Figure 4.25) was used. In this case, it generates a real-time map using as horizontal axis the header value of Field File and as a vertical axis the header value of each Channel number. The map is coloured by the values defined under the header filled with the spectral semblance that was calculated. The colour bar can be changed, and the final map (.baf file) can also be accessed after the acquisition. A different header will be filled with values 0 and 1, with 0 meaning the trace is over the minimum semblance value established, while 1 are the flagged traces, under the minimum value that were considered as bad traces.\nTrace header containing horizontal coordnate\t\nTrace header Field file\t\nHorizontal range 0 Manually set horizontal range C Set range from SPS file(s)\tSelect file\nHorizontal axis mm.\tHorizontal axis max.\nI1'0\t1\t250.0\nTrace header coo taring attrtoute for dspiay\nTrace header User defined 1\nDtspiay tab\t\n0 Add dsplay to a tab\tUTKjue tab name Spectral Comparison\nMap scale\nO Scale to fit view\nHeight (pixels) 960 O Scale to fit dimesions\nWidth (pixels) 1200\nO Scale to fit horizontal\n(\u2022) Scale to fit vertical\nMap title\nTrace header containing ver bcal coordinate\nTrace header Chyme!\t-\nVertical range\t\ni 1 Manual y set vertical range\t\n\u25a1 Set range from SPS fiie(s)\tSelect file\nVertical axis mn\tVertical axis max\nl\u00b0\u00b0\t\u20141\t[*'<>\t1\nMap outputs\nOutput rap He name:\tb:^JhessA>2_SPW_Pro)ecWW3O_FC/Survev/$CJIter.baf\t\u00abeBrowse...\nFigure 4.25: Real Time Data Quality Analysis parameters.\nCancel\nIn order to ensure the Spectral Comparison parameter will flag the right traces, a first manual QC analysis was done, to register some of the bad traces and compare with the Spectral Comparison flags, to see if they are covered by the automatic tool.\n4.2.3\tSignal to Noise Ratio Attribute\nIn signal processing, noise is a general term for unwanted and, in general, unknown register that the signal may suffer during the acquisition (Tuzlukov, 2002). This term means that the register carries no useful information. For this reason, noise reduction is necessary to recover the intended signal.\nSignal to Noise Ratio is defined as the ratio of the average power of the RMS (Root Mean Square) amplitudes within a signal window, divided by the average power of the RMS amplitudes obtained over a noise window (Equation 4.2). The root mean square is defined as the square root of mean square value.\n2\nwhere As is the RMS amplitude in the signal window and An is the RMS amplitude in the noise window.\nThe Signal to Noise Attribute processing step allows the calculation of the signal-to-noise ratio of input data, calculating the signal to noise ratio for every record, based on three different approximations:\nS/Np\nower\n(4.3)\nS/Nrms\nAs\nAn\n(4.4)\nS/NAbsolute\nE|As|\nE|A\u201e|\n(4.5)\nIn general, S/Npower > S/Nrms > S/NAbsolute-\nThe flow used to calculate the spectral semblance and flag traces is shown in Figure 4.26. The same TCP/IP Data Input that was used before is also used for this parameter. Tests were made with a SEG-Y input. This step, differing from the Spectral Comparison, does not have a Butterworth filtering coupled in the Signal to Noise Ratio Attribute. In this case, it was necessary to add a previous step to introduce a low-cut filter and remove the influence of the low frequency noise, stronger in the near offset channels. This way, some traces that have more noise than the others, but still with enough signal content, will not be removed unnecessarily. In spite of this, the filtering will be implemented into the final data and not only for the signal to noise ratio calculation. To solve this, an identical implementation of an internal filter like the one that Spectral Comparison has, maybe a necessary step to be implemented at a later stage in SPW.\nFigure 4.26: Processing flow used to test Signal to Noise Ratio Attribute.\nAs referred before, this attribute will allow the calculation of the signal to noise ratio based on three different approximations.\nThere are four different parameterization methods available to use for this calculation: Specify Windows; Use auxiliary noise record; Compare S/N ratio in the frequency domain; Specify Velocity. The parameters for this processing step (Figure 4.27) allow the user to define the signal and noise windows using the time and channel numbers. This can be specified by using:\n1.\tSpecify Window\nSpecified manually from the input seismic, based on an interval time and channel number ranges\n2.\tUse auxiliary noise record\nUsing an auxiliary noise record while using the input seismic for the signal window\n3.\tSpecify Velocity\nThis option needs the definition of the time interval for both signal and noise windows based on a specific user-defined velocity.\n4.\tCompare S/N ratio in the frequency domain\nDiffering from the other options, this option allows the calculation of signal to noise ratio based on the frequency content, instead on the amplitude content. The user can\ndefine the signal and noise windows based on an interval and channel number range. A given record is considered dead/live based on the overlap of both spectra within the minimum and maximum frequencies defined by the user.\nFigure 4.27: Signal to Noise Ratio Attribute parameters.\nFor this attribute, the main parameterization method used was the Use of an Auxiliary Noise Record. As a noise file is always acquired before the acquisition of every line, the most suitable parameter to use is the one that compares the data with an auxiliary noise record, providing a more \"realistic\u201d noise that exists in the field during the survey.\nThis attribute allows changing the calculation method from a record basis to a trace by trace calculation, but apparently, the calculation and flag done by SPW is always done on a record basis.\nOne of the hardest parameters to assign a value is the Minimum S/N ratio, used to flag bad traces. This value will depend on many things, such the Butterworth filter applied, problems with source or noise file.\nDepending on the low-cut filter used, small changes on the filter parameters will also lead to changes on S/N ratio (they may not be too different, but the flagged traces can change with it); a malfunction in the source during a line acquisition will also make the average S/N ratio be completely different comparing with other lines; different noise files to be used as a reference will also have different content; the data itself will have different content, leading\nto a non-comparable S/N ratio value between lines. To sum up, an X value of S/N ratio can be considered as good record in a line, while in another line, the same X value can be related to a bad record. For that reason, a few statistics were calculated to find a pattern related to this.\nThe results of this attribute will have six different headers: two for each different approximation of S/N Ratio, where one has the ratio value and the other has the flagged record. An output .txt file is made available with these six header values.\nTo plot the information calculated by Signal to Noise Ratio Attribute, Real Time Quality Analysis Statistics Map (Figure 4.28) was used. It generates a real time map with three bar charts (each one for each S/N ratio approximation) with the information of dead/live records based on the minimum S/N ratio that was defined.\nHorizontal range\n0 Manualy set horizontal range\nO Set range from SPS file(s)\nHorizontal axis mn.\nSelect file\nHorizontal axis max.\nTrace header containing attribute for display\nS/N rabo average power header User defined 4\nS/N rabo average RMS header User defined 5\nSAI rabo average absolute header User defined 6\nMap outputs\nOutput map file name:\nDrsplay tab\nFigure 4.28: Parameters of Real Time Data Quality Analysis Map.\nChapter 5\nResults and Discussion\n5.1\tManual QC\nThe most commonly detected bad records during the manual QC stage (analysis done in shot gather domain) are missed shots. These records (corresponding spectrum in light blue in Figure 5.1 are represented without any relevant information (only by noise), causing them to have a completely different frequency spectrum compared with the normal trace signature (Figure 5.1). Considering the line P001, for example, records such 1, 266, 7184, 7186 and 7188 (Figures 5.2 and 5.3) were identified as missed shots, totalizing 17 records flagged (one of them related with a low signal content another with signal cut below 90ms, while the rest are missed shots). No malfunction of any channel (dead channel) was detected. For the line P002, 20 records, all those related with missed shots, were flagged.\nFigure 5.1: Frequency spectrum of a missed shot record, compared with both sources signature.\nOne of the major difficulties verified during manual QC is the detection of weak records, and also to distinguish a single weak channel in the middle of the data. For this reason, manual QC is based on record analysis instead trace analysis.\n5.2\tReal-Time QC\n5.2.1\tSoftware Beta Tests\nSeveral problems were detected in the tests and reported to the Parallel Geoscience team; all these were successfully solved:\n\u2022\tHeaders mapping - No record or wrong byte position of some essential headers for seismic processing, such as source and receiver coordinates or source number headers;\n\u2022\tReal-Time QC processing speed - Reports based on delays between the data acquisition and real-time QC results, to ensure that QC and acquisition are finished at the same time;\n\u2022\tMulti-thread processing - Used to increase the processing speed of SPW, with several bugs/crashes detected during QC tools tests;\n\u2022\tGraphic memory limits - Multiple tests made with real-time displays and reports done based on the size of the content that crashed the software as also the display associated. To solve this problem, Parallel Geoscience built a \"scrolled\u201d window display with a user defined displayed content (n number of FFID\u2019s);\n\u2022\tSpectral Comparison tool limited to one signature trace - Due this limitation, was not possible to include two signature traces, each one to be compared with the right source. It is now possible to use multiple signature traces;\n\u2022\tAnomalous Semblance values - Semblance values were detected to be above 1 in some tested versions.\nDue to time limitation and the priority settled for the Spectral Comparison tool stabilization, Signal to Noise Ratio did not pass through significant updates. Still, some reports were done for this tool, such the suggestion of adding an \u201dinner\u201d bandpass filter like the on\nexistent in Spectral Comparison. Some improvements related with the tool parameterization based on its analysis (section 5.2.3) were also reported will possibly be applied in a future SPW version.\n5.2.2\tSpectral Comparison\nDue to the fact that the seismic data had not been processed (since Real-Time QC is working during the acquisition), a low-cut filter must be active to calculate the spectral semblance without the influence of the low frequency noise. This way, a good record will have a spectrum more identical to the signature spectrum. The filtering applied on this step will not affect the output data, as the filter is just temporarily applied for the semblance calculation. The typical noise identified in Noise Analysis (Section 4.1.1) can also be verified in real-time in a parallel display in shot gather domain, along with a Spectral Comparison display.\nThe minimum spectral semblance value established was 80%. This value was chosen because it is high enough to flag bad shot records and low enough to not remove records that still good for data processing. The value applied was obtained based on multiple \u201dtrial and error\u201d tests until the pretended records were flagged, without flagging good records. Due the limited period of time, statistical analysis between different semblance ratios and records flagged on each value was not done. As mentioned before (section 4.2.2), the main parameterization applied for tests was One signature per dataset from auxiliary seismic file. The use of the signature file is a more reliable calculation method. All other methods are more susceptible to the influence of bad records, such the calculation of the average prior traces that is influenced by the presence of bad traces, or defining a signature for every record based on a single channel if the picked channel is \u201ddead\u201d (no data recorded), or even if there was a missed shot, a bad reference will be used to calculate the semblance of all other traces.\nIn Figure 5.2, in blue vertical lines, it is visible a constant low spectral semblance value for all channels of the records 1 and 266, which are related with missed shots.\nFigure 5.2: Appearance of dead FFID's blue vertical lines (horizontal axis represented by FFID and vertical represented by Channel number).\nOn the next example (Figure 5.3) three consecutive cases of missed shots from one of the sources can be identified (during the survey operations, the two sources were triggered alternatively). This display shows a plausible capacity to enhance problems with sources during the acquisition. In this case, the source started to operate correctly again, but if the miss shots persisted it could mean that the source was inoperative, and the perception of this problem could take more time trough common QC methods.\nFigure 5.3: Consecutive missed shots detected in Spectral Comparison (horizontal axis represented by FFID and vertical represented by Channel number) (a); Schematic representation of missed triggers in Source 0 (b).\nThe provided data did not have any situation of a dead channel. Due this fact, simulation tests of a dead channel were simulated to analyze how the Spectral Comparison will work in a dead channel situation. The simulation consisted on selecting a specific channel and spoil the data along this channel. This way, it is predictable that the spectral semblance will be reduced. The channel chosen for this test was channel 52.\nIn the Figure 5.4 is noticeable the presence of the \u201ddead\u201d channel 52, represented by the horizontal blue line (color associated low spectral semblance on the color bar used). This test confirms that this attribute will operate correctly if a situation like this happens.\n312\t335\n0.98421\n0.57302\nFigure 5.4: \u201dDead\u201d channel detected in Spectral Comparison - Channel 52, horizontal blue line (horizontal axis represented by FFID and vertical represented by Channel number).\nA linear loss of spectral semblance is visible in Figure 5.5. This is most visible in the second streamer (Channels 25-48). As this decrease of spectral semblance is happening from the near offset channels to the far offset ones, what is causing this is moving through this direction along the streamer.\nFigure 5.5: Linear loss of spectral semblance visible specially between channels 25-48 and FFID 100-190 (horizontal axis represented by FFID and vertical represented by Channel number).\nComparing frequency content between this streamer channels with all channels (Figure\n5.6), it is possible to observe that there is a low-frequency noise between 10 and 40Hz.\nFigure 5.6: Frequency spectrum of channels 25-48 (a); Frequency spectrum of all channels (b).\nAs a low-frequency noise is causing this linear loss of spectral semblance, a possible reason for this may be a stronger wave motion affecting mainly the second streamer, but is also probable that the strong propeller wash of the vessel was the cause (Figure 5.7).\nFigure 5.7: Strong wave motion moving against the streamer.\nAn unusual problem related with data recording on board is associated with missed records of entire streamers (Figure 5.8). This blank register in an entire streamer, despite the fact that it does not happen very often, is important to be detected and understand why it is happening, since it causes the loss of a whole group of 24 channels. As this is not a problem related with the shooting the other streamers are visible for the same shot, meaning it is not a problem related with the source the most likely cause for this issue can be related with hardware problems, specifically with the multi-trace associated with this streamer.\n(a)\nField file - 15745\tField file - 15747\nFigure 5.8: (a) Missed record in an entire streamer, inside the black box: Channels 25-48 (horizontal axis represented by FFID and vertical represented by Channel number); (b) Record with missing streamer; (c) Example of a record with all streamers, for comparison purposes.\n67\t78\t89 96\no\nA problem that was not detected during the manual QC, and is almost impossible to manually detect in most cases, is related with the weakening of some channels. In Figure 5.9a, the blue dispersed dots are weak channels (also visible in Figure 5.9b). These channels have been flagged, but all other ones that are working correctly in the same record will be kept. In the same figure is also visible a linear loss of semblance from the far-offset channels to the near-offset ones. This effect is probably be related with the strong wave motion moving to the opposite direction, comparing with the example verified in Figure 5.5.\n(a)\nField file - 69994\tField file - 69690\n1\t1223344556\t67\t78\t8996\t1\t12\t2334\t4556\t67\t78\t8996\nFigure 5.9: (a) Spectral Comparison Attribute Map detecting weak channels (blue dots); (b) Weak channels record; (c) Example of a good record with no channel issues.\nOne of the most common problems found during this survey acquisition is related with the strong propeller wash of the vessel. This phenomenon is more common in the near-offset channels of the middle streamers, due to its proximity to the stern of the vessel (Figure 5.10). The strong propeller wash of the vessel can also cause the Trouser\u2019s Effect, separating the streamers and letting them with a non parallel direction comparing with the vessel direction.\nStreamer 4\nStreamer 1\nFigure 5.10: Strong propeller wash affecting mainly the middle streamers.\nAs this problem has been reported for some of the lines acquired, an empirical analysis\nwas made in order to check if Spectral Comparison can easily detect this phenomenon. With this analysis, it was confirmed that the tested tool can detect this problem, represented by the gradual loss of semblance ratio spreading through the near-offset channels of streamers 2 and 3 (middle streamers) (Figure 5.11). This problem can also be verified for streamers 1\nand 4, but with a much lower intensity, since the semblance values for the near offset chanels\non these streamers did not have significant reductions.\n0.98495\n0.14403\n0.69689\nFigure 5.11: Strong propeller wash effect detected in near-offset channels of Streamers 2 and 3 -Channels 25-30 and 49-55 respectively (horizontal axis represented by FFID and vertical represented by Channel number).\nTo see the impact of Spectral Comparison tool, statistics comparing before and after tool application (deleting all the flagged traces) were done(Table 5.1). The percentage of lost traces is lower for all lines, comparing with the percentage of lost records. This confirms that this tool is flagging individual traces, something that manually is imperceptible and cannot be done.\nTable 5.1: Number of shot records and traces per line: before and after Spectral Comparison tool (minimum of 80% of spectral semblance).\nLine\tInput\t\tOutput\t\tDifference (%)\t\n\tShot Records\tTraces\tShot Records\tTraces\t\t\nP001\t31814\t3054048\t31790\t3036876\t-0.075\t-0.562\nP002\t37626\t3611952\t37603\t3586836\t-0.061\t-0.695\nP003\t63811\t6125592\t63777\t6090273\t-0.053\t-0.577\nP004\t35565\t3413904\t35551\t3402140\t-0.039\t-0.345\nPOOS\t37847\t3633144\t37827\t3609864\t-0.053\t-0.641\nP006\t62457\t5995752\t62423\t5972919\t-0.054\t-0.381\nP007\t44537\t4275168\t44509\t4226621\t-0.063\t-1.136\nP008\t28004\t2688168\t27990\t2678540\t-0.050\t-0.358\nP009\t68587\t6583512\t68518\t6335965\t-0.101\t-3.760\nP010\t41440\t3977928\t41417\t3957406\t-0.056\t-0.516\nP011\t28927\t2776824\t28911\t2768778\t-0.055\t-0.290\nFor a better comparison with Manual QC, Table 5.2 shows the number of flagged records and correspondent number of traces with Manual QC, and with the Spectral Comparison tool. For comparison purposes, the number of flagged traces in manual QC was calculated based on the number of flagged records multiplied by the number of channels (96), while the number of flagged traces by Spectral Comparison has its equivalent value based on the number of records (also multiplied by 96) and its real number of flagged traces.\nIt must be mentioned that all the shot records flagged in manual QC were also flagged with Spectral Comparison, except one - see section 5.2.4. Besides that one, Spectral Comparison detected a few more bad records that escaped the manual QC, but, the most noticeable difference is related with the number of bad traces that were detected. This number is related with single traces in some \u2019\u2019good\u201d shot records that were considered bad, a humanly impossible task for large datasets.\nIf the number of traces flagged by Spectral Comparison were converted to number of Records it would be equivalent to 179 and 261 flagged records, for line P001 and P002 respectively.\nTable 5.2: Number of flagged records and traces with Manual QC and Spectral Comparison tool. \u2019Equivalent Traces\u201d is the number of flagged records times 96 (number of channels).\n5.2.3\tSignal to Noise Ratio Attribute\nTo establish the minimum S/N ratio value a statistical comparison of the first 1000 records of the same line between a record with a low-cut filter applied and another without any filter was carried out.\nFrom the previous tests FFID 1 and 266 were already recognized as missed shots, only represented by noise content. This means, that for these two records a S/N ratio close to 0 is expected, because there is no signal content.\nThe ratio used for analysis was the S/N Average Power (Equation 4.3). With this approximation, higher values were obtained for FFID 1 and 266 for the non-filtered data, while in the low-cut filtered data a value really close to 0 was obtained (Table 5.3). With this test, it can be confirmed the importance of the implementation of a low-cut filter for S/N ratio approximations.\nTable 5.3: Signal to Noise ratio in missed shots comparison between filtered and no filtered data.\nFFID\tS/N Ratio (No Filter)\tS/N Ratio (Filtered)\n1\t1.004741\t0.065417\n266\t1.050762\t0.081749\nS/N ratio change is more evident on these records, but the modification of the ratio value is visible in whole line (see for example Figure 5.12, representing the first 500 records).\nThe higher values of S/N ratio still have almost the same value between the two tests, while lower values had a higher loss of S/N ratio in a gradual way (Figure 5.12).\nBasing on the low-cut filtered content, a few measures were done to find a trend base value to use as a minimum S/N ratio.\nAnalysing the Figure 5.12b, it is possible to observe a trending minimum value around\n1.3\tS/N ratio, where almost all values settle.\nS/N Ratio (filtered)\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\n\n0\t100\t200\t300\t400\t500\nFFID\nFigure 5.12: First 500 records of a seismic line from HOW 3D project (a) no filtered data; (b) low-cut filtered data.\nAs expected, different lines with different noise files used for comparison have completely different S/N Ratio average values (Figure 5.13), what means that a base value of 1.3 ratio can be applied to line P001, but not to line P002.\nFigure 5.13: Comparison of S/N ratio values between two different lines.\nFor that reason, it was necessary to find a calculation method for every line in order to automatize this QC parameter and also use the same criteria for all lines, despite the different values.\nWith the objective to find a common pattern that could embrace all the data, a sample of 1000 records of each line was analysed. A few parameters, such minimum, maximum and average values were calculated.\nAfter the analysis, a ratio value of 45% of average S/N ratio values of each line was decided to be used as a reference value to adapt to all lines (Table 5.4). This value was established after \u2019\u2019trial and error\u201d tests with different values, with the 45% of the average value getting closer to the manually established minimum S/N ratio for each line. The criteria used to consider a minimum S/N ratio value as suitable was analysing the records that were flagged and that should have not been flagged, and then the reference value was decreased until those records would be considered as good data, while the real bad records would still be flagged.\nAs each line has a completely different behaviour between them, this value does not match perfectly for every line, producing some lines with records that should have been considered as marginal (not good records, but good enough to not be flagged and to be used for processing) being flagged, but a lower minimum S/N ratio would include some bad records for other lines.\nTable 5.4: Established minimum S/N ratio for every line and % of flagged records.\nDespite the calculated common pattern to automatize the minimum ratio, some lines with a more unstable S/N ratio can be negatively affected by the use of the average of the data. To try to solve this instability of some lines ratio, another calculation method was tested. This new method will read the n lowest ratios and then use their average as the minimum ratio. In this case, as 1000 records were analysed, the average of the 10 lowest ratio\nvalues were used for the minimum S/N ratio calculation (the more records used, the higher will be minimum ratio, what may possibly flag marginal records).\nComparing both calculations (Table 5.5), it is visible that the results are quite similar, but the new calculation has a lower value in general. The two lines that had the most noticeable difference had some of the problems solved:\n\u2022\tP007 - this was the line with the highest % of flagged records, due to its discrepancy between maximum and minimum S/N Ratio values, leading to the flag of some marginal records that should not be flagged;\n\u2022\tP008 - this is the more unstable line in terms of finding, graphically, a base value for the data. It has the most significant difference between both minimum S/N Ratio calculation methods. Nevertheless, the % of flagged records did not have a significant change.\nTable 5.5: Comparison between two different established minimum S/N ratio.\nLine\tAverage S/N Ratio\t45% of Average\t\tAverage of the 10 lowest values\t\n\t\tS/N Ratio\t% of Flag\tS/N Ratio\t% of Flag\nP001\t2,38\t1,07\t0.2\t0,99\t0.2\nP002\t1,08\t0,49\t0.1\t0,45\t0.1\nP003\t3,20\t1,44\t0.2\t1,47\t0.2\nP004\t2,22\t1,00\t0.2\t1,22\t0.2\nP005\t2,27\t1,02\t0.5\t0,79\t0.3\nP006\t1,79\t0,80\t0.7\t0,71\t0.3\nP007\t7,69\t3,46\t1.2\t2,65\t0.2\nPOOS\t2,12\t0,95\t0.6\t0,57\t0.5\nPOOS\t2,67\t1,20\t0.8\t0,99\t0.3\nP010\t3,36\t1,51\t0.7\t1,34\t0.2\nP011\t2,78\t1,25\t0.6\t0,99\t0.2\nAlthough this last method works better than the first one (it has values closer to the manual established minimum S/N ratio values, generally), there is still a gap that may cause problems to the average of the 10 lowest values. In case there are more than 10 bad records in the analysed section, some of these records will not be flagged, since some of them will have a higher value than the average calculated. To calculate this value, it is necessary to\nhave part of the line acquired. The solution is to create in SPW, a tool that after x records are acquired, calculates the average of the lowest n values, and only after that it starts to flag traces. As an example, after 200 records, the average of the 10 lowest values is calculated and used automatically as the minimum S/N ratio. This way, there is no need to manually insert a minimum ratio value, and probably a wrong value, as there is no way to know beforehand how the line ratio will behave.\nBy using the Real Time Quality Analysis Statistics Map three bars are displayed in real time, each one related with each type of S/N ratio approximation. As the calculation for the minimum S/N ratio value is being done based on the Average Power, visually, the other approximations give a wrong information, which means the only one that is needed to be analysed is the Average Power bar (Figure 5.14).\nFigure 5.14: Real Time Statistics map of the three S/N ratio parameterizations, with flagged traces (in red).\n5.2.4\tNon-detected \u201dbad\u201d record\nOnly one record that was manually considered as bad was not flagged. The classification of \u201dbad\u201d record in this case differs to the other flagged records, since in this case the record still good in terms of spectral semblance and S/N Ratio. Frequency Spectrum is identical and there is no relevant noise. This issue is related with a record that has been cut after the first 90ms (Figure 5.15). The occurrence of more records like this one could influence a \u201dfalse\u201d final good coverage of the area. However, this phenomenon rarely occurs.\nFigure 5.15: Non detected \u201dbad\u201d record no signal after 90ms.\n5.2.5\tReal-Time QC VS Traditional QC\nIn summary, by analysing the five steps that must be verified on board during the Quality Control stage, along with the flagging of bad records (Section 4.1.1), it can be confirmed that:\n\u2022 The Verification of the converted SEG-Ys, which is done at the end of the line acquisition, can be more easily verified with the Real-Time QC tool. This method will keep a single file at the end of acquisition, skipping the need to merge all the acquisition\nfiles (that are divided by 1Gb files), leading to a faster confirmation of the number of FFIDs (Field File Identification Number). Detection of bad shots and also rating the data as good, bad or marginal is automatically done based on Spectral Comparison results;\n\u2022\tAs the data acquisition is being followed and quality controlled in real time, the typical noise can be immediately recognized in the data, allowing the user to prepare sooner adequate methods (noise filters) to suppress the typical noise;\n\u2022\tThe Signature Verification step can be skipped, since the signature that is used for processing is not the one received by the reference hydrophones, but the one obtained during sea trials stage (tests done before the survey). However, the Real-Time QC tool can be easily adapted to use the reference hydrophones records as a signature reference for Spectral Comparison, if needed. This option may consist in a future Real-Time QC adaptation, but with a problem related with stability of the signature provided by the reference hydrophones, with probable occurrences of bad signature traces that should not be used as a good reference;\n\u2022\tSource and streamer group integrity can be done in real time, through the detection of missed shots or even dead/weak channels. The impact of a stronger wave motion can also be detected in the Spectral Comparison display, as also the strong propeller\u2019s wash that can cause the Trouser\u2019s effect. Although it cannot directly detect acquisition velocity changes, they can be indirectly detected based on the strong propellers wash presence and its intensity. Spectral Comparison cannot identify possible minor modifications of the system geometry, that may intensify ghosts or multiples;\n\u2022\tAlthough the Coverage Verification is not a part of QC stage, it can be done faster. The standby time spent for traditional QC after the acquisition does not exist anymore, saving several hours and allowing the user to start a trim seismic processing right after the acquisition, based on deconvolution, geometry assignment and statics correction. All the bad records are already flagged and ready to be removed, to have a more accurate coverage of the area.\n5.2.6\tField Tests\nNew Spectral Comparison tool tests were done in a real acquisition for another project, also in the North Sea. Along with the offshore updates other problems were detected, directly related with the spectral semblance calculation method. That bug caused the semblance calculation to give high semblance values for noisy data and low semblance values for good data, making the data flag untrustworthy. This problem is expected to be solved in the latest SPW version.\nAlthough it was not possible to correctly flag bad data in that case, the semblance patterns were still detected by the real-time display, allowing the user to recognize problems during the acquisition, such strong propeller's wash, wave motion effect, bad shots or weak channels (Figure 5.16).\nwave motion effect white arrows; bad shot red vertical line; weak channel white horizontal line).\n5.3\tSeismic Data Interpretation\nAfter all the QC and adequate processing of the 3D volume dataset for the study case, a brief interpretation of the seismic data is presented below, for a better full understanding of the potential of the acquisition of Ultra High Resolution 3D seismic data in complex areas such as the one under study. Comparing with the Quaternary stratigraphy described in Chapter 2 with the final 3D seismic volume obtained, it can be noticed that all the formations that were interpreted (Table 4.1) belong to the Californian Glacigenic Group. Some of the minor\nformations described in Chapter 2 could not be interpreted. Not all seismic blocks and Wind\nTurbine Generator areas had all the formations listed on Table 4.1\nAmong the four Wind Turbine Generator areas (WTG) that belong to block B27H27, the interpreted data shown will be referred to a single WTG, since the horizons interpreted are the same between these four WTG's. The horizons interpreted on this area (Figure 5.17) are Swarte Bank and its internal (pink and soft pink), Eem formation (Marine - brown; Lacustrine - orange), Bolders Bank and its formations (green and softer greens respectively) and the Holocene. After the manual horizon picking stage, an interpolation for each horizon was made in order to fill the horizon to the whole wind turbine generator areas.\nBolders Bank Internal 2\nBolders Bank Formation\nLacustrine Eem Base\nBolders Bank Internal 1\nSwarte Bank Internal\nSwarte Bank Formation\nFigure 5.17: Interpreted seismostratigraphic units after interpolation in one of the four wind turbine generator areas of block B27H27, calibrated wih geotechnical information. Red lines show a preliminary interpretation based only on geotechnical data.\n\nThe Swarte Bank (pink formation) is the oldest formation visible on the first 21 meters below the sea bed. In this case, this formation was picked based on the continuity that came from other blocks. The Swarte Bank internal is a reflector with high acoustic impedance\nvisible between Swarte Bank base and Marine Eemian base. The Eeemian is divided by two major stages, marked by the existence of two well-marked reflectors: one associated with a marine stage, where is visible in some of CPT\u2019s (Cone Penetration Tests data) the presence of sandy to silty material, while the lacustrine stage is more related with silty to clay material, characterized by a more homogeneous level (fewer presence of significant acoustic impedance contrasts in this layer. This layer is being affected by the upper layer: the Bolders Bank formation, formed by the movement of ice sheets.\nThe Bolders bank formation, as described in Chapter 2, is a widespread deposit of diamicton (poorly sorted material that can have size ranges that goes from clay to boulders size) believed to be deposited by the movement of ice sheets that moved down to the east coast of England. Around 42 meters below the sea bottom, with a depth slice view, some scratches can be seen in the southeastern direction (Figure 5.18). These scratches are related with glacial striations resulted by the movement of a glacier. Multiple stages of these movements are seen and marked as internal horizons of Bolders Bank formation.\nFigure 5.18: Depth slice around 42 meters depth, showing glacial striations.\nThe Holocene (Figure 5.17 - blue horizon) is characterized by the most recent main formation that was interpreted. With the complement of CPT data, it was possible to easily make the correlation between this horizon and related reflectors, mainly characterized by sand deposits, probably associated with Elbow and Southern Bight formations.\nAll interpreted horizons in the seismic data from this case study can be found in the\nFigure 5.19.\npi\nHolocene Sand Dunes\nBolders Bank Internal 3\nBolders Bank Internal 2 b35\nBolders Bank Internal 1'\nI\nBolders Bank Formation ^Lacustrine Eem Base Marine Eem Base / _\tI\n[Swarte Bank Interna Ip-45 Swarte Bank Formation \\\tMio\n\\ /\np 55\nFigure 5.19: 3D Seismic block of one of the wind turbine generator areas and its horizons.\n88\nChapter 6\nConclusions\n6.1\tSummary of Results\nWith the aim to contribute to the implementation of an efficient and cost-effective automatic QC solution for 3D ultra-high resolution multichannel seismic reflection data in real time during acquisition, a case study was fully investigated with manual QC and extensive testing was carried out to benchmark the performance of the automatic algorithms used and to better parameterize them. Extensive performance analysis and error reporting were conducted during beta tests of the QC implementation in SPW and new updates based on these reports were done by Parallel Geoscience, leading to a correct mapping of data headers by the real-time input, optimization of data analysis speed along with multi-thread processing debug, software design to read a variable number of source signatures, optimization of graphic memory limits and debugging of anomalous spectral semblance values.\nAll records, except one, that were manually flagged as bad records were detected by the Real-Time automatic QC, as well as a large number of many other bad records and traces that were not detected by the traditional QC. Most of the data that were flagged with Spectral Comparison tool are bad traces, imperceptible during a manual QC stage. Source shot problems, dead/weak channels, strong wave motion and its direction, strong propeller\u2019s wash, and registry problems with multi-trace - all these types of problems were detected by Spectral Comparison tool.\nThe Signal to Noise Ratio Attribute has also identified records that were not manually\ndetected. This tool is harder to implement as a fully automatic tool, since the calculation of Signal to Noise Ratio is using different auxiliary noise files for each line, leading to different values for the minimum signal to noise ratio to consider data as good. Graphically, this method only distinguishes a good from a bad record, unlike the Spectral Comparison display, where several problems can be verified.\nOnly one record was not detected by the Real-Time QC tools. The problem consists on empty data below 90ms. This record cannot be considered as a failure of the Real-Time QC, since this trace has a good spectral semblance, as also good signal content (in the first 90ms). This is a problem that rarely occurs, but nevertheless should also be tackled in future work.\n6.2\tConcluding Remarks\nIt is considered that the objectives of the development of Real-Time automatic QC were fully achieved. With this new tool, the data is ready right after the line acquisition, saving many hours spent during traditional QC, which could only start after the line was fully acquired. Situations where more people had to join at QC stage to not compromise schedules can also be avoided with the new tool. Furthermore, the QC is also more efficient, since it is almost impossible to manually detect all problems within an acceptable time in large seismic data, and also detect problems on single traces.\nComparing both tested tools, it is easily observed that Spectral Comparison is a more complete tool in terms of information given and has an easier parameterization, while the Signal to Noise Ratio Attribute does not give further information beyond the flagged records. It has also a lower reliability due to the calculation method of the minimum accepted signal to noise ratio, that may not be the most accurate to be used for a parameterization.\nBy assuring a good performance of this new automatic real-time QC method, a significant cost reduction of the survey is expected, with a significant reduction of the vessel operation time. QC efficiency has also been improved due the automatic component that, based on a correct calculation and parameterization method, will flag all bad traces, leading to a better final data quality since the noise content is sharply removed. This data improvement brings the possibility to do a more detailed interpretation, along with a more\nprecise and complete mapping of hazards that may have impact in the construction planning of marine structures, such bridge foundations or, in this case, the mapping of wind turbine implementation areas as also the inter array cables installation (cables through where the energy is transported), avoiding extra costs above hundreds of thousands of euros in failed implementations.\nIn terms of project management, with the Real-Time QC will be possible to improve QC efficiency, time schedules and reduce the costs without any trade-off, meaning this is a must have tool to be in the vanguard of the seismic processing data industry.\n6.3\tFuture Work\nIn order to further improve the work developed in the scope of this thesis, suggestions of future work include:\n\u2022\tto build a better method for the calculation of signal to noise ratio minimum value. Since the objective of Real-Time QC is to \"automatize\u201d and reduce as much as possible the time spent on QC, and in order to standardize the method, a better and a more reliable calculation method for this value is a must problem to solve.\n\u2022\tto create a new colour bar for Spectral Comparison map, for an easier distinction of the flagged traces, maintaining a gradual bar to allow the detection of several acquisition problems related with the gradual loss of spectral semblance.\n\u2022\tto develop or improve tools to be able to detect cut records (section 5.2.4). This phenomenon is not yet covered by the Real-Time QC developed. One possibilities could be to calculate the spectral content of records in time intervals, allowing the detection of intervals without signal content.\n\u2022\tto complement Real-Time QC with an automatic near real-time trim processing (a preliminary processing), that will allow to calculate the real coverage of the data, leading to faster decisions about vessel mobilizations to reacquire data on these areas. A new Flex Binning parameterization is being developed to optimize the coverage of the area by filling the empty seismic data gaps, that will reduce the need of acquiring infill/rerun lines.\n92\nReferences\nAbout Hornsea Project One. URL: http://www.hornseaprojectone.co.uk (Accessed: 6 March 2017) .\nAlfaro, J. C., Corcoran, C., Davies, K., Hampson, G., Hill, D., Howard, M., Kapoor, J., Moldoveanu, N., and Kragh, E. (2007). Reducing Exploration Risk. Oilfield Review, pages 26-43.\nAnell, I., Thybo, H., and Stratford, W. (2010). Relating Cenozoic North Sea sediments to topography in southern Norway: The interplay between tectonics and climate. Earth and Planetary Science Letters.\nBalson, P., Butcher, A., Holmes, R., Johnson, H., Lewis, M., Musson, R., Henni, D. P., Jones,\nS.,\tLeppage, P., and Tuggey, G. (2001). North Sea Geology. Technical report.\nBalson, P. and Cameron, T. (1985). Quaternary mapping offshore East Anglia. Modern Geology, 9:221-239.\nCameron, T., Crosby, A., Balson, P., Jeffery, D., Lott, G., Bulat, J., and Harrison, D. (1992). United Kingdom Offshore regional report: The geology of the southern North Sea. HMSO, London.\nCameron, T. and Holmes, R. (1999). The Continental Shelf. In A revised correlation of Quaternary deposits in the British Isles, pages 125-139. Geological Society of London, London.\nCameron, T., Stoker, M., and Long, D. (1987). The history of Quaternary sedimentation in the UK sector of the North Sea Basin. Geological Society, 144:43-58.\nCarr, S. J., Holmes, R., van der Meer, J. J. M., and Rose, J. (2006). The Last Glacial\nMaximum in the North Sea Basin: Micromorphological evidence of extensive glaciation. Journal of Quaternary Science, 21(2):131-153.\nDavies, B. J. (2008). British and Fennoscandian ice-sheet interactions during the Quaternary. Durham theses, Durham University, page 265.\nDobrin, M. and Savit, C. (1988). Introduction to Geophysical Prospecting. McGraw-Hill.\nEhlers, J. (1990). Reconstructing the dynamics of the North-west European Pleistocene ice sheets. Quaternary Science Reviews, 9(1):71-83.\nElboth, T. and Hermansen, D. (2009). Attenuation of noise in marine seismic data.\nFunnell, B. (1988). Foraminifera in the Late Tertiary and Early Quaternary Crags of East Anglia. In The PiloceneMiddle Pleistocene of East Anglia, pages 50-52. Quaternary Research Association.\nGallagher, L. (1988). Tertiary Calcareous Nannofossils from the Central and Southern North Sea Basins, and biostratigraphical application. PhD thesis, University College of London.\nGlennie, K. and Boegner, P. (1981). Sole Pit Inversion tectonics. In Petroleum geology of North-West Europe, pages 110-120. Heyden and Sons, London.\nGlennie, K. and Underhill, J. (1998). Origin, development and evolution of structural styles.\nGlennie, K. W. (1986). Development of N.W. Europe\u2019s Southern Permian Gas Basin. Geological Society, London, Special Publications, 23(1):3-22.\nGoledowski, B., Nielsen, S. B., and Clausen, O. R. (2012). Patterns of Cenozoic sediment flux from western Scandinavia. Basin Research, 24:377-400.\nGomes, J. S. and Alves, F. B. (2007). O Universo da Ind\u00fastria Petrol\u00edfera - Da Pesquisa a Refina\u00e7\u00e3o. Funda\u00e7\u00e3o Calouste Gulbenkian.\nGraham, A., Lonergan, L., and Stoker, M. S. (2007). Evidence for Late Pleistocene ice stream activity in the Witch Ground Basin, central North Sea, from 3D seismic reflection data. Quaternary Science Reviews, 26(5-6):627-643.\nGraham, A. G. C., Stoker, M. S., Lonergan, L., Bradwell, T., and Stewart, M. A. (2011). Chapter 21 - The Pleistocene Glaciations of the North Sea Basin. In Developments in Quaternary Sciences, volume Volume 15, pages 261-278.\nHatton, L., Worthington, M. H., and Makin, J. (1986). Seismic Data Processing - Theory and Practice. Wiley-Blackwell.\nHeigl, W. M., Radtke, R. P., Stokes, R. H., and Glowka, D. A. (2013). A low-frequency downhole sparker for borehole seismic applications. CSEG Recorder.\nHolmes, R. (1997). NoQuaternary Stratigraphy: The Offshore Record. In Gordon, J., editor, Reflections on the Ice Age in Scotland, pages 72-94. Scottish Natural Heritage, Glasgow.\nHuuse, M. (2002). Cenozoic uplift and denudation of southern Norway: insights from the North Sea Basin. Geological Society, London, Special Publications, 196:209-233.\nHuuse, M. and Lykke-Andersen, H. (2000). Overdeepened Quaternary valleys in the eastern Danish North Sea: Morphology and origin.\nJoon, B., Laban, C., and Van Der Meer, J. (1990). The Saalian glaciation in the Dutch part of the North Sea. Geologie en Mijnbouw, 69:151-158.\nKearey, P. and Brooks, M. (1991). An Introduction to Geophysical Exploration. Blackwell Science.\nKirby, G. A. and Swallow, P. W. (1987). Tectonism and sedimentation in the Flamborough Head region of north-east England. Yorkshire Geological Society, pages 301-309.\nLaban, C. (1995). The Pleistocene glaciations in the Dutch Sector of the North Sea. PhD thesis, Universiteit van Amsterdam.\nLamb, R. M., Huuse, M., and Stewart, M. (2016). Early Quaternary sedimentary processes and palaeoenvironments in the central North Sea.\nMcMillan, A. A., Hamblin, R. J., and Merritt, J. W. (2005). An overview of the lithostrati-graphical framework for the Quaternary and Neogene deposits of Great Britain (Onshore). Technical report, British Geological Survey.\nMcQuillin, R. and Ardus, D. A. (1977). Exploration of the Geology of Shelf Seas. Graham &amp; Trotman.\nMcQuillin, R., Bacon, M., and Barclay, W. (1984). An Introduction to Seismic Interpretation. Graham &amp; Trotman.\nMuller, C., Woelz, S., Ersoy, Y., Boyce, J., Jokisch, T., Wendt, G., and Rabbel, W. (2009). Ultra-high-resolution marine 2D3D seismic investigation of the Liman Tepe/Karantina Island archaeological site (urloa/Turkey). Journal of Applied Geophysics, pages 124-134.\nPereira, L. A. (2009). Seismic Attributes in Hydrocarbon Reservoirs Characterization. PhD thesis, University of Aveiro.\nRappol, M., Haldorsen, S., Jorgensen, P., Meer, J. V., and Stoltenberg, H. (1989). Composition and origin of petrographically stratified thick till in the northern Netherlands and a Saalian glaciation model for the North Sea Basin. Medelingen van de Werkgroep Tertiair en Kwartair Geologie, 26:31-64.\nRibeiro, T. (2011). Multichannel Seismic Investigation of the Gran Burato area, off W Galicia. PhD thesis, University of Aveiro.\nSejrup, H. P., Aarseth, I., Ellingsen, K. L., Reither, E., Jansen, E., L0vlie, R., Bent, A., Brigham-Grette, J., Larsen, E., and Stoker, M. (1987). Quaternary stratigraphy of the Fladen area, central North Sea: a multidisciplinary study. Journal of Quaternary Science, 2:35-58.\nSheriff, R. E. (1996). Understanding the Fresnel Zone. Geophysical Corner.\nSheriff, R. E. and Geldart, L. P. (1995). Exploration Seismology. Cambridge University Press, Cambridge.\nSheriff, R. E. and Matisoff, B. S. (1991). Encyclopedic Dictionary of Applied Geophysics. Geophysical References Series.\nStoker, M. S., Balson, P. S., Long, D., and Tappin, D. R. (2011). An overview of the lithos-tratigraphical framework for the Quaternary deposits on the United Kingdom continental shelf. Technical report, British Geological Survey.\nStoker, M. S., Long, D., and Fyfe, J. A. (1985). A revised Quaternary stratigraphy for the central North Sea. HMSO, London.\nStoker, M. S., Praeg, D., and Hjelstuen, B. O. (2005). Neogene stratigraphy and the sedimentary and oceanographic development of the NW European Atlantic Margin. Marine and Petroleum Geology, 22:977-1005.\nTelford, W. M., Geldart, L. P., and Sheriff, R. E. (1990). Applided Geophysics. Cambridge University Press, Cambridge.\nTissen, A. (2012). Relevance of Seismic Surveys in the Exploration and Development of Oil-and Gas Fields. Oil and Gas Vertical, 10.\nTuzlukov, V. (2002). Signal processing noise. CRC Press.\nVolkhard, S. and Florian, M. Geophysical Site Investigation for Offshore Wind Farm Development. Technical report, Fraunhofer.\nWhite, N. and Lovell, B. (1997). Measuring the pulse of a plume with the sedimentary record. Nature, 387:888-891.\nWilson, J. T. (1966). Did the Atlantic close and then re-open? Nature, pages 676-681.\nWingfield, R. T. R. (1989). Glacial incisions indicating Middle and Upper PIeistocene ice limits off Britain. Terra Nova, 1(6):538-548.\nYilmaz, O. (2001a). Seismic Data Analysis: Processing, Inversion, and Interpretation of Seismic Data., volume Vol.1.\nYilmaz, O. (2001b). Seismic Data Analysis: Processing, Inversion, and Interpretation of Seismic Data., volume Vol.2.\nZanella, E. and Coward, M. (2003). Structural framework. In Evans, D., Graham, C., Atmour, A., and Bathurst, P., editors, The Millenium Atlas: Petroleum Geology of the Central and Northern North Sea, pages 45-59.\nZiegler, P. A. (1978). North Sea rift and basin development. In Ramberg, I. B., editor, Techtonics and Geophysics of Continental Rifts, pages 471-472. Nature.\nZiegler, P. A. (1992). North Sea rift system. Tectonophysics, 208(1-3):55-75."}]}}}