{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.23139"}, {"@name": "filename", "#text": "7217_FGV%20-Giovanni_Parravicini.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "FUNDA\u00c7\u00c3O GETULIO VARGAS \nESCOLA DE ECONOMIA DE S\u00c3O PAULO \n\n \n\n \n\n \n\n \n\nGIOVANNI PARRAVICINI \n\n \n\n \n \n \n \n \n \n \n \n\nA FACTOR AUGMENTED VECTOR AUTOREGRESSIVE MODEL AND A STACKED DE-\nNOISING AUTO-ENCODERS FORECAST COMBINATION TO PREDICT THE PRICE OF OIL. \n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nS\u00c3O PAULO \n2019 \n\n\n\n \n \n\nFUNDA\u00c7\u00c3O GETULIO VARGAS \nESCOLA DE ECONOMIA DE S\u00c3O PAULO \n\n \n \n \n\n \n\nGIOVANNI PARRAVICINI \n\n \n\n \n\nA FACTOR AUGMENTED VECTOR AUTOREGRESSIVE MODEL AND A STACKED DE-\nNOISING AUTO-ENCODERS FORECAST COMBINATION TO PREDICT THE PRICE OF OIL. \n \n \n \n \n \n \n \n \n\n \n\n \n \n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n \n \n \n \n \n\nS\u00c3O PAULO \n2019 \n\nDisserta\u00e7\u00e3o apresentada \u00e0 Escola de \nEconomia de S\u00e3o Paulo da Funda\u00e7\u00e3o \nGetulio Vargas, como requisito para \nobten\u00e7\u00e3o do t\u00edtulo de Mestre Profissional em \nEconomia. \n \nCampo do Conhecimento: \nInternational Master in Finance \n \n\nOrientador Prof. Dr. Pedro Luiz Valls Pereira \n\n \n\n  \n\n\n\n \n \n\n \n \n \n \n \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\n  \nParravicini, Giovanni. \n     A Factor Augmented Vector Autoregressive model and a Stacked De-noising \nAuto-encoders forecast combination to predict the price of oil / Giovanni Parravicini.  \n- 2019. \n     42 f. \n  \n     Orientador: Pedro L. Valls Pereira. \n     Disserta\u00e7\u00e3o (mestrado profissional MPFE) \u2013 Funda\u00e7\u00e3o Getulio Vargas, Escola de \nEconomia de S\u00e3o Paulo. \n  \n     1. Modelos econom\u00e9tricos. 2. Aprendizado do computador. 3. Teoria da \ninforma\u00e7\u00e3o em economia. 4. Petr\u00f3leo - Pre\u00e7os. I. Pereira, Pedro L. Valls. II. \nDisserta\u00e7\u00e3o (mestrado profissional MPFE) \u2013 Escola de Economia de S\u00e3o Paulo. III. \nFunda\u00e7\u00e3o Getulio Vargas. IV. T\u00edtulo. \n  \n  \n\nCDU 330.115::665.61 \n  \n\n  \nFicha Catalogr\u00e1fica elaborada por: Isabele Oliveira dos Santos Garcia CRB SP-010191/O \nBiblioteca Karl A. Boedecker da Funda\u00e7\u00e3o Getulio Vargas - SP \n\n \n\n\n\n \n \n\nGIOVANNI PARRAVICINI \n \n\n \n\n \n\n \n\nA FACTOR AUGMENTED VECTOR AUTOREGRESSIVE MODEL AND A STACKED DE-\nNOISING AUTO-ENCODERS FORECAST COMBINATION TO PREDICT THE PRICE OF OIL. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\nDisserta\u00e7\u00e3o apresentada \u00e0 Escola de \nEconomia de S\u00e3o Paulo da Funda\u00e7\u00e3o \nGetulio Vargas, como requisito para \nobten\u00e7\u00e3o do t\u00edtulo de Mestre Profissional \nem Economia. \n \nCampo do Conhecimento: \nInternational Master in Finance \n \n \n \nData de Aprova\u00e7\u00e3o: \n24/01/2019. \n \n \nBanca Examinadora: \n \n \n_________________________________ \nProf. Dr. Pedro Luiz Valls Pereira \n \n \n_________________________________ \nProf. Dr. Franco Francesco \n \n_________________________________ \nProf. Dr. Maria Antonieta Ejarque de \nCunha e S\u00e1 \n \n\n\n\n \n \n\nACKNOWLEDGMENT \n \n\nI would like to express my special thanks of gratitude to my Professors who gave me the \n\ngolden opportunity to do this wonderful project on this topic, which also helped me in doing a \n\nlot of Research.  Secondly I would also like to thank my parents, friends and Sophia who \n\nhelped me a lot in finalizing this project within the limited time frame. \n\n  \n\n\n\n \n \n\nRESUMO \n \n\nA disserta\u00e7\u00e3o a seguir tem como objetivo mostrar os benef\u00edcios de uma combina\u00e7\u00e3o de \n\nprevis\u00e3o entre uma metodo econom\u00e9trico e um de Deep Learning. De um lado, um Factor \n\nAugmented Vector Autoregressive (FAVAR) com identifica\u00e7\u00e3o naming variables seguindo \n\nStock e Watson (2016); do outro lado, um Stacked De-noising Auto-encoders (SDAE-B), \n\nseguido por Zhao, Li e Yu (2017), \u00e9 implementado. De janeiro de 2010 a Setembro de 2018, \n\n281 s\u00e9ries mensais s\u00e3o usadas para prever o pre\u00e7o do West Texas Intermediate (WTI). O \n\ndesempenho do modelo \u00e9 analisado pelo Root Mean Squared Error (RMSE), Mean Absolute \n\nPercentage Error (MAPE) e Directional Accuracy (DA). A combina\u00e7\u00e3o se beneficia da alta \n\nprecis\u00e3o do SDAE-B e dos recursos de interpreta\u00e7\u00e3o do FAVAR por meio das Impulse \n\nResponse Functions (IRFs) e da Forecast Error Variance Decomposition (FEVD). \n\n \n\nKEY WORDS:  \n\nFAVAR, Auto-encoders, combina\u00e7\u00e3o de previs\u00e3o, SDAE, WTI, petroleo, previs\u00e3o   \n\n\n\n \n \n\nABSTRACT \n \n\nThe following dissertation aims to show the benefits of a forecast combination between an \n\neconometric and a deep learning approach. On one side, a Factor Augmented Vector \n\nAutoregressive Model (FAVAR) with naming variables identification following Stock and \n\nWatson (2016)1; on the other side, a Stacked De-noising Auto-Encoder with Bagging (SDAE-\n\nB) following Zhao, Li and Yu (2017)2 are implemented. From January 2010 to September 2018 \n\nTwo-hundred-eighty-one monthly series are used to predict the price of the West Texas \n\nIntermediate (WTI). The model performance is analysed by Root Mean Squared Error (RMSE), \n\nMean Absolute Percentage Error (MAPE) and Directional Accuracy (DA). The combination \n\nbenefits from both SDAE-B\u2019s high accuracy and FAVAR\u2019s interpretation features through \n\nimpulse response functions (IRFs) and forecast error variance decomposition (FEVD).  \n\n \n\nKEY WORDS:  \n\nFAVAR, Auto-encoders, forecast combination, SDAE, WTI, crude oil, forecast   \n\n                                                \n1 Stock, J.H. and Watson, M.W., 2016. Dynamic factor models, factor-augmented vector autoregressions, and structural \nvector autoregressions in macroeconomics. In Handbook of macroeconomics (Vol. 2, pp. 415-525). Elsevier. \n2 Zhao, Y., Li, J. and Yu, L., 2017. A deep learning ensemble approach for crude oil price forecasting. Energy \nEconomics, 66, pp.9-16. \n\n\n\n \n \n\nTABLE OF CONTENTS \n\t\n\nCHAPTER 1\t..................................................................................................................................\t9\t\n\nCHAPTER 2\t................................................................................................................................\t14\t\n\nCHAPTER 3\t................................................................................................................................\t27\t\n\nCHAPTER 4\t................................................................................................................................\t34\t\n\nBIBLIOGRAPHY\t........................................................................................................................\t35\t\n\nAPPENDIX\t..................................................................................................................................\t40\t\n  \n\n\n\n  9 \n \n\nCHAPTER 1 \n\nChapter 1: Introduction \n\nThe influential statistician George E. P. Box warned: \u201cAll models are wrong, but some are \n\nuseful\". The author believes that in forecasting exercises perfection doesn\u2019t exist, generally \n\nspeaking, due to complexity, in our world. Although empirical evidence proven human \n\nbehaviours to be flawed, or in other words irrational, Economics courageously tries to explain \n\nthem. Such process is all but easy, and Economists, although improving, are far from a \n\nunanimous model that describe accurately the laws of supply and demand disruptions through \n\ntime. \n\nForecasting is not a recent science. Its roots stem from our innate ability that one exploits \n\nunconsciously when thinking about the future. Luckily, the science has evolved enough to take \n\na certain distance from who claim to predict the future by reading the hand\u2019s palm. The idea of \n\nmodelling nature and social\u2019s behaviours comes later with new advances: Mathematics and \n\nmore recently Statistics and Economics. In this sense, improvements, as for describing the law \n\nof nature as deterministic, have to wait more than a millennium to appear. Adam Smith (1776)3 \n\ndefined \u201cPolitical Economics\u201d as \u201can inquiry into the nature and causes of the wealth of \n\nnations\u201d Before it was renamed \u201cEconomics\u201d by Alfred Marshall in the 19th century.  \n\nTechnology has a clear feed-forward impact in the innovation process. The more the \n\ntechnological advancement, the higher the rate of subsequent innovations. Big steps have been \n\ntaken in the past 100 years since Economists tried to describe our society by given linear \n\nequations. An example of such advances, strictly connected to both the models I will present in \n\nthis paper, are Big Data or as Economists tends to define it: \u201cData rich environments\u201d. As \n\nmentioned before, technology causes technology growth, and indeed a clear exponential pattern \n\n                                                \n3 Smith, A., 1817. An Inquiry into the Nature and Causes of the Wealth of Nations (Vol. 2).  \n\n\n\n  10 \n \n\ncan be traced out on the amount of data available every year as pointed out in the recent report \n\nby McKinsey. The quality and quantity of information have opened room for new techniques \n\nand computational power that previously were though inaccessible due to hardware or software \n\nconstraints. \n\nThe paper combines two innovative approaches that make use of Big Data in the compelling \n\nexercise of forecasting the oil price. On one side the author proposes an Econometric approach \n\nin a Data-rich environment based on State Space modelling literature, precisely a Factor \n\nAugmented Vector Autoregressive model (FAVAR) that follows Stock and Watson (2016)1. \n\nThis model has been widely used in Macroeconomics since its introduction by Bernanke, \n\nBoivin and Eliasz (2005)4 mainly for the important advantages in structural analysis; on the \n\nother hand, the author evaluates a novel Deep Learning ensemble approach called Stacked De-\n\nnoising Auto-encoders with Bagging (SDAE-B) proposed for the first time by Zhao, Li, Yu \n\n(2017)2 , who were able to show the model\u2019s superior out of sample forecasting accuracy \n\ncompared to other frequently used Big Data approaches. This paper follows the procedures of \n\nthe two mentioned papers unless otherwise stated.  \n\nThe eventual combination would produce a model that exploits both structural analysis \n\ninterpretation properties, addressing policy makers\u2019 concerns, and exceptional forecasting \n\naccuracy deriving from the pattern recognition noise-filtering of the auto-encoders. Both \n\nmodels, in a sense, complement each other. The FAVAR reaches a good forecasting accuracy, \n\nbut it\u2019s not the main power of the model. Using the Econometric approach, one can expect to \n\nidentify the structural shocks, obtain the impulse response functions (IRFs) and the forecast \n\nerror variance decomposition (FEVD). On the other hand, the Big Data approach, produces \n\nhigh accuracy forecasting but, as its \u201cblack box\u201d nickname suggests, it doesn\u2019t allow the \n\neconometrician to understand the underlying structural dynamics.  \n\n                                                \n4 Bernanke, B.S., Boivin, J. and Eliasz, P., 2005. Measuring the effects of monetary policy: a factor-augmented vector \nautoregressive (FAVAR) approach. The Quarterly journal of economics, 120(1), pp.387-422.\t\n\n\n\n  11 \n \n\nAlthough one Econometrician may prefer a model instead of another, because of personal \n\nopinion and beliefs - after all forecasting is more art than a precise science - predictive model \n\ncombinations \n\nhave been proven successfully in the literature (Diebold and Pauly, 19875; Makridakis, 19896; \n\nDe Gooijer and Hyndman, 20067; Pesaran and Pick, 20118). The author uses a simple mean \n\nforecast combination. Bayesian averaging is also taken into consideration, but shown only if it \n\nsuggests statistical significant improvements.  \n\nThe oil price has been covered extensively recently by the media due to geopolitical tensions \n\nand price instability; but its volatility has been central to macro-economists since the 70s when \n\nthe OPEC and the Middle East wars revolutionized the industry landscape. As frequently \n\nunderlined in the literature, although the 80s were a relatively calm period, excluding the Iraqi \n\nattacks to Kuwait, since the twentieth century began, the oil price literally ranged from \n\n$30/barrel to $140/barrel causing not infrequent socio-economic consequences for policy \n\nmakers. For an in depth historical digression see Baumeister and Kilian (2016)9, who \n\nexhaustively analyse the past 40 years of oil price data. The past unmanageable volatility gave \n\nbirth to an increasing number of documents and papers attempting to reproduce supply and \n\ndemand\u2019s dynamics. After the recent amount of scientific literature production is taken into \n\nconsideration, one may argue that an unanimous consensus is far from being reached. \n\nNevertheless, important results have been achieved, for instance, the fact that supply explains \n\nsignificantly less variance of oil prices than demand at quarterly and annual data. This is \n\nsomewhat counterintuitive given the focus of media on global supply.  \n\n                                                \n5 Diebold, F.X. and Pauly, P., 1987. Structural change and the combination of forecasts. Journal of Forecasting, 6(1), pp.21-\n40. \n6 Makridakis, S., 1989. Why combining works?. International Journal of Forecasting, 5(4), pp.601-603. \n7 De Gooijer, J.G. and Hyndman, R.J., 2006. 25 years of time series forecasting. International journal of forecasting, 22(3), \npp.443-473. \n8 Pesaran, M.H. and Pick, A., 2011. Forecast combination across estimation windows. Journal of Business &amp; Economic \nStatistics, 29(2), pp.307-318. \n9 Baumeister, C. and Kilian, L., 2016. Forty years of oil price fluctuations: Why the price of oil may still surprise us. Journal \nof Economic Perspectives, 30(1), pp.139-60. \n\n\n\n  12 \n \n\nAlthough the aim of the following dissertation isn\u2019t a deep dive into the energy market, some \n\nwords regarding the importance of oil price are needed. Oil represents, followed by coffee, \n\nnatural gas and gold, the most traded commodity in the financial markets (OECD, 2018). Crude \n\nOil products assume different names according to its sweet-bitter or light-heavy composition. \n\nIn US the production has been recently disrupted by the introduction of \u201cShale Oil\u201d which \n\nrevolutionized the timing of extraction. No matter what the commodity is called or where it is \n\nproduced, it plays an important role for politic relationships and economies since the industrial \n\nrevolution (Zou, Zhao, Zhang and Ziong, 2016)10. Even if developed economies are looking \n\ninto renewable energies to meet the climate goals established by the global summit held in Paris \n\nin 2017, for many oil producer developing countries the switch may last longer due to their \n\neconomic dependency. As a matter of fact there is a long list of countries which massively \n\ndepends on Oil revenue: Kuwait, Libya, Saudi Arabia, Iraq, Angola, Oman, Azerbaijan, \n\nVenezuela, Chad, Brunei to name a few (World Bank, 2018). One may expect an increase in \n\ndiversification from oil price exposure given the past decades instability, instead Ross (1999)11, \n\nby reviewing the literature and analysing the recent data, reveals a heterogeneity of measures \n\nacross regions, underlying for instance a failure to act from North and sub-Saharan Africa oil \n\nproducer countries versus non-oil producers. Venezuela\u2019s dramatic condition, as of mid-2018, \n\nadds one more example to the black-list of the oil-dependent countries that by failing to act and \n\ninnovate, projected the country in currency corrections and hyperinflationary environments, \n\nultimately culminating in bankruptcies. \n\nThe Directional Accuracy (DA), Root Mean Square Error (RMSE) and Mean Absolute \n\nPercentage Error (MAPE) are compared in order to access forecasting accuracy for both \n\nmodels. These measures reflect the most popular performance measurement in the recent \n\n                                                \n10 Zou, C., Zhao, Q., Zhang, G. and Xiong, B., 2016. Energy revolution: From a fossil energy era to a new energy \nera. Natural Gas Industry B, 3(1), pp.1-11. \n11 Ross, M.L., 1999. The political economy of the resource curse. World politics, 51(2), pp.297-322. \n\n\n\n  13 \n \n\nliterature from Diebold and Mariano (2002)12, Mostafa and El Masry (2016)13, Yu et al (2016)14 \n\nand Zhao, Li, Yu (2017)2.  \n\n                                                \n12 Diebold, F.X. and Mariano, R.S., 2002. Comparing predictive accuracy. Journal of Business &amp; economic statistics, 20(1), \npp.134-144. \n13 Mostafa, M.M. and El-Masry, A.A., 2016. Oil price forecasting using gene expression programming and artificial neural \nnetworks. Economic Modelling, 54, pp.40-53. \n14 Yu, L., Dai, W. and Tang, L., 2016. A novel decomposition ensemble model with extended extreme learning machine for \ncrude oil price forecasting. Engineering Applications of Artificial Intelligence, 47, pp.110-121.\t\n\n\n\n  14 \n \n\nChapter 2 \n\nChapter 2: Dataset \n\nDespite following previous literature, this paper brings new variations and innovations. \n\nMotivated by the empirical evidence on low supply importance for oil price\u2019s variation (Juvenal \n\nand Petrella, 201115, 201516), the model overweight real demand features by including variables \n\nconcerning the top twenty countries in terms of gross domestic product price purchasing parity \n\n(GDP PPP). Additionally, the dataset is oriented toward the US Economy. The reason is that \n\nthe WTI is produced and consumed more in US than it is exported abroad, hence the price is \n\nmostly exposed to domestic fluctuations. Nevertheless, price co-movement is common between \n\noil&amp;gas commodities and therefore the motivation for introducing the countries that would \n\nimpact global real demand the most. Moreover, after careful literature research and comparison, \n\nthe dataset is extended to about 281 monthly variables, compared to the 139 quarterly used in \n\nStock and Watson (2016)1 and the 198 monthly used in Zhao, Li, Yu (2017)2. The series are \n\ntemporarily trimmed on January 2010 and extended to September 2018. Overall, the variables \n\naggregate into 13 dimensions: \u201cIndustrial Production\u201d, \u201cEmployment\u201d, \u201cOrders, Inventories \n\nand Sales\u201d, \u201cHousing activities\u201d, \u201cGeneral Prices\u201d, \u201cIncome\u201d, \u201cProductivity and Earnings\u201d, \n\n\u201cRates\u201d, \u201cMoney and Credit\u201d, \u201cExchange Rates\u201d, \u201cActivity\u201d, \u201cAssets Prices\u201d and finally \u201cOil \n\nrelated variables\u201d. Moreover, when possible, these 13 categories are further split between USA \n\nand Global. When such division is available, \u201cUSA\u201d refers to variables related to the US \n\neconomy only, whereas \u201cGlobal\u201d refers to variables related to the top 20 global economies \n\nranked by gross domestic product adjusted for price purchasing parity. One may argue that \n\nmore variables don\u2019t necessarily improve performance. The statement is valid and nor the \n\n                                                \n15 Juvenal, L. and Petrella, I., 2011. Speculation in the oil market, Federal Reserve Bank of St (No. 2001). Louis, Working \nPaper. \n16 Juvenal, L. and Petrella, I., 2015. Speculation in the oil market. Journal of Applied Econometrics, 30(4), pp.621-649. \n\n\n\n  15 \n \n\nFAVAR neither the SDAE-B are exempt from this rule, and indeed both models address the \n\nissue: the former by dimensionality reduction and the latter by feature selection algorithm. \n\n \n\nInitially, around 380 variables are identified and downloaded from Bloomberg and FRED \n\ndatabase according to the literature mentioned in this paper. The identification of the thirteen \n\ngroups of variables follows more Stock and Watson (2016)1 implementation rather than Zhao, \n\nLi, Yu (2017)2. In this step, thirty-six variables are removed due to inconsistencies and missing \n\ndata; while seventeen variables, where the missing data accounted for not over 10% of the \n\noverall number of observation, are linearly interpolated according to the growth of the series. \n\nThe time coverage of the series goes from January 2010 to September 2018 for a total of 105 \n\ndata points. \n\nIn order to capture real demand, the nominal series are deflated by the CPI core inflation in \n\ndecimal form re-indexed at the beginning of the observation period as in Stock and Watson \n\n(2016)1. As the paper aims to reflect real demand, the object then becomes to remove any part \n\nof the variable\u2019s change that is attributable to price movements, arriving at a real, or inflation \n\nadjusted, indicator. \n\nThe series are furthermore converted to be covariance-stationary and such transformation is \n\ntested by the popular Advanced Dickey-Fuller (ADF) and Phillip-Perron (PP) tests (Dickey and \n\nFuller, 197917, Phillip and Perron, 198818). The logic behind the integration is set to a threshold \n\nconfidence level of 0.05. Specifically, if the ADF\u2019s or the PP\u2019s p-value are larger than 0.05, a \n\ntransformation is applied. The test is repeated, and if one of the two tests\u2019 critical values are \n\nstill larger than the threshold, an additional transformation is carried out. This process is \n\n                                                \n17 Dickey, D.A. and Fuller, W.A., 1979. Distribution of the estimators for autoregressive time series with a unit root. Journal \nof the American statistical association, 74(366a), pp.427-431. \n18 Phillips, P.C. and Perron, P., 1988. Testing for a unit root in time series regression. Biometrika, 75(2), pp.335-346.\t\n\n\n\n  16 \n \n\ncomputed by further differentiation until all series are covariance stationary. No series required \n\nmore than two differentiations.   \n\nTo conclude the pre-processing of the information, as in Stock and Watson (2016)1 and Zhao, \n\nLi, Yu (2017)2, the dataset is standardized. This step is necessary for both models and in \n\nparticular for the FAVAR, where one of the first steps is a principal component analysis (PCA), \n\nwhich is the non-parametric approach alternative, suggested instead of the computationally \n\ninefficient Gibbs Sampling. There is a debate in the literature on whether one method should \n\nbe preferred instead of the other, but given that none of the two methods has been proven being \n\nsuperior, the two-step approach, the PCA, is preferred due to its simplicity (Stock and Watson \n\n20161). In the standardization step the series is demeaned and divided by the standard deviation, \n\nguaranteeing a range of variation that on average lies between minus three and plus three. \n\nTherefore, each series has mean equal zero and standard deviation equal to one. \n\nThe series subject to these transformations are shown in the appendix. The choice of the series \n\nhas been made to allow both models to bring value to the analysis. Most variables represent the \n\ndriving forces of oil price and were taken combining multiple datasets including Zagaglia \n\n(2010)19, Naser (2016)20 and Stock and Watson (2016)1. It is worth mentioning that the series \n\nfor US economy had a greater weight than the other country\u2019s economies. This is due to the \n\nfact that the West Texas Intermediate is produced and consumed in US and more subject to US \n\neconomy swings. Nevertheless, a new introduction is carried on within the features. In \n\nparticular the top twenty countries for GDP PPP are selected among the whole population of \n\ncountries. The reason, as mentioned early in the paper, is that demand has historically played a \n\nmore important role than supply in driving oil prices in the long run (Juvenal and Petrella, \n\n                                                \n19 Zagaglia, P., 2010. Macroeconomic factors and oil futures prices: a data-rich model. Energy Economics, 32(2), pp.409-\n417. \n20 Naser, H., 2016. Estimating and forecasting the real prices of crude oil: A data rich model using a dynamic model \naveraging (DMA) approach. Energy Economics, 56, pp.75-87.\t\n\n\n\n  17 \n \n\n201115, 201516, Kilian and L\u00fctkepohl, 201721 and Stock and Watson, 20161). Of these twenty \n\ncountries, whenever available, the following variables, according to the fourteen dimensions \n\nare added: industrial production, employment, general prices, interest rates, exchange rates, \n\nasset indicators and oil related variables. \n\n \n\nChapter 2: Factor Augmented Vector Autoregressive Model \n\nThe Factor Augmented Vector Auto-regressive (FAVAR) model was proposed the first time \n\nby Bernanke, Boivin and Eliaz (2005)4. Their scope was to disentangle the monetary shocks. A \n\nrecent version can be found in Namini (2018)22. After this successful paper, the model has been \n\nextended to study policy uncertainty, oil prices, pass through inflation effect and fiscal policy \n\n(Belke, Osowski, 201723, Pr\u00fcser and Schl\u00f6sser, 201724; Zagaglia, 201019, Lombardi 201225, \n\nAastveit, 201326, Ratti and Vespignani, 201627 and Stock and Watson, 20161; Ribon 201128, \n\nConflitti and Luciani, 201729; Roulleau-Pasdeloup, 201130). The amount of literature has grown \n\nso massively that more than one literature reviews and in-depth identification procedures have \n\nbeen recently presented: Barhoumi, Darn\u00e9 and Ferrara (2013)31, Stock and Watson (2016)1, and \n\nKilian and L\u00fctkepohl (2017)21. This paper focus on extensions related to oil prices. Generally \n\nspeaking the FAVAR is a Dynamic Factor Model (DFM) of which one or more factors are \n\n                                                \n21 Kilian, L. and L\u00fctkepohl, H., 2017. Structural vector autoregressive analysis. Cambridge University Press. \n22 Siami-Namini, S., 2018. The Effect of Monetary Policy Shocks on the Real Economy: A FAVAR Approach. Res J Econ 2: \n1. of, 9, p.2. \n23 Belke, A. and Osowski, T., 2017. International effects of euro area versus US policy uncertainty: A FAVAR approach (No. \n689). Ruhr Economic Papers. \n24 Pr\u00fcser, J. and Schl\u00f6sser, A., 2017. The effects of economic policy uncertainty on European economies: Evidence from a \nTVP-FAVAR (No. 708). Ruhr Economic Papers. \n25 Lombardi, M.J., Osbat, C. and Schnatz, B., 2012. Global commodity cycles and linkages: a FAVAR approach. Empirical \nEconomics, 43(2), pp.651-670. \n26 Aastveit, K.A., Natvik, G.J.J. and Sola, S., 2013. Economic uncertainty and the effectiveness of monetary policy. \n27 Ratti, R.A. and Vespignani, J.L., 2016. Oil prices and global factor macroeconomic variables. Energy Economics, 59, \npp.198-212. \n28 Ribon, S., 2011. Augmented, V.A.R. Research Department Bank of Israel. \n29 Conflitti, C. and Luciani, M., 2017. Oil price pass-through into core inflation. \n30 Roulleau-Pasdeloup, J. and Doz, C., 2011. The dynamic effects of fiscal policy: a FAVAR approach (No. dumas-\n00650820).\t\n31 Barhoumi, K., Darn\u00e9, O. and Ferrara, L., 2013. Testing the number of factors: An empirical assessment for a forecasting \npurpose. Oxford Bulletin of Economics and Statistics, 75(1), pp.64-79. \n\n\n\n  18 \n \n\nobservable. Although still growing, since its creation in Geweke (1977)32 extensive researches \n\nhave been made on DFM after Marcellino et al (2000)33 and Stock and Watson (2002)34 \n\ndemystified its characteristics. The model is mainly used in Economics and has grown in \n\npopularity because of the increasing amount of data. As pointed out by Stock and Watson \n\n(2016)1, the model performs better in data rich environments than simple Vector Auto-\n\nregressions (VAR), and the peculiarity, is that most of the useful feature for structural analysis \n\nof VARs can be extended to FAVARs.  \n\nInitially DFMs were used for monitoring economic activity. Nowadays they are also used for \n\nnow-casting and forecasting. These three functions reflect the main ability of the model: \n\nsummarizing large amount of data in few factors. These factors can be estimated using both a \n\nparametric (for instance Gibbs sampling) and a non-parametric two steps approach (Principal \n\nComponent Analysis). The Principal Component Analysis (or PCA) estimates the factors more \n\nefficiently than other methods (in terms of computational power required) obtaining non-\n\ninferior results and therefore is more frequent in the literature (Marcellino, 2017)35. The \n\nimplementation is described later on, but for the moment,  it is enough to think about the factors \n\nas the orthogonal unit eigenvectors that minimize the squared distances of the multi-\n\ndimensional matrix representing the dataset.  \n\nThe process of structural analysis works in FAVARs as well as in VARs, although some \n\nidentification supplements are required. Kilian and L\u00fctkepohl (2017)21, Gallegati et al (2016)36, \n\nStock and Watson (2016)1 debate extensively regarding these properties. In particular, \n\ndepending on the objective of the study and the identification procedure, two or three additional \n\n                                                \n32 Geweke, J., 1977. The dynamic factor analysis of economic time series. Latent variables in socio-economic models. \n33 Marcellino, M., Stock, J.H. and Watson, M.W., 2000. A dynamic factor analysis of the EMU. manuscript, http://www. \nigier. uni-bocconi. it/whos. php. \n34 Stock, J.H. and Watson, M.W., 2002. Forecasting using principal components from a large number of predictors. Journal \nof the American statistical association, 97(460), pp.1167-1179.\t\n35 Marcellino, M., 2017. An Introduction to Factor Modelling. \n36 Gallegati, M., Ramsey, J.B. and Semmler, W., 2016. AE-FSI. Dynamic Modeling, Empirical Macroeconomics, and \nFinance: Essays in Honor of Willi Semmler, p.195. \n\n\n\n  19 \n \n\nrestrictions are needed. The above-mentioned papers describe exhaustively the variations for \n\nall the methodologies. Another important step is the selection of the number of factors. For \n\nindexing purpose, Stock and Watson (2016)1, shows that it is better to choose an additional \n\nfactor, than incurring in the so called omitted variable bias. For forecasting and now-casting, \n\nalso due to overfitting issues, the choice is more tedious and can be conducted graphically \n\nthrough the scree plot or analytically through the information criteria. Even if one may use the \n\nsame information criteria depicted in VARs\u2019 lag selection process, Bai and Ng (2002)37 and \n\nAmenguel and Watson (2007)38 developed an ad hoc test that is frequently used in the literature \n\nsuggested by Stock and Watson (2016)1.  \n\nStock and Watson (2016)1 proposes a 207 variables quarterly data from 1984Q1 to 2014Q4 of \n\nwhich only 139 variables are used to estimate the factors. All the variables are transformed to \n\nbe integrated of order zero and de-trended. After analysing the IC criteria, the number of factors \n\nis set to 8 because, as they say, \u201cit is important that the factor innovations span the space of the \n\nstructural shocks and the higher factors capture variation\u201d. Although the series are available \n\nfrom 1959Q1, due to the parameter instability found in the data the model is produced as \n\nmentioned before since 1984Q1. Approaches such as in Mumtaz, Zabczyk and Ellis (2011)39, \n\nEickmeier, Lemke and Marcellino (2015)40 solves the issue by building a time varying FAVAR \n\n(TV-FAVAR).  \n\nThe dynamic factor models (DFMs) are expressed either in static or dynamic form. Hereafter \n\nthe static form is used. The state space model representation of a static (stacked) FAVAR is as \n\nfollow: \n\n                                                \n37 Bai, J. and Ng, S., 2002. Determining the number of factors in approximate factor models. Econometrica, 70(1), pp.191-\n221. \n38 Amengual, D. and Watson, M.W., 2007. Consistent estimation of the number of dynamic factors in a large N and T \npanel. Journal of Business &amp; Economic Statistics, 25(1), pp.91-96. \n39 Mumtaz, H., Zabczyk, P. and Ellis, C., 2011. What lies beneath? A time-varying FAVAR model for the UK transmission \nmechanism. \n40 Eickmeier, S., Lemke, W. and Marcellino, M., 2015. Classical time varying factor-augmented vector auto-regressive \nmodels\u2014estimation, forecasting and structural analysis. Journal of the Royal Statistical Society: Series A (Statistics in \nSociety), 178(3), pp.493-533. \n\n\n\n  20 \n \n\n ?\" = ??\" + ?\"                    (1) \n\n?\" = ?(L)?\" + ??\"                (2) \n\nWhere the observed equation (1) equals the ??1 vector\t\t?\"of known time series with the sum \n\nof the common component ??\" and the idiosyncratic disturbances ?\". If this latter element is \n\nuncorrelated with the factors innovations at all leads and lags then the DFM is called exact \n\nDFM. Generally speaking this is a strong assumption and ?\" is modelled as an autoregressive \n\nprocess as in equation (3). Each ?4\"in this case is i.i.d. and the model is called non-exact DFM. \n\n?4\" = ?4 ? ?4\"78 + ?4\"            (3) \n\nThe common component is the dot product of the matrix ? = (?:,?8 \u2026,?=) where ?>is ??? \n\nand the matrix ?\" = (?\"A,?\"7>A ,\u2026,?\"7=A )? where\t?\" is a ??1 of static factors. Equation (2) is the \n\nvector autoregressive model expressed in canonical form by stacking the ? static factors. The \n\nnumber of static factors ?, is by construction typically greater than the number of dynamic \n\nfactors ?, and can be assessed by a combination of a-priori knowledge, visual inspection of a \n\nscree plot, and the use of information criteria (IC). The scree plot in particular shows the \n\nvariance explained by factors, while the IC, such as Bai and Ng (2002)41 and Amenguel and \n\nWatson (2007)42, provide a penalty function that measures the cost/benefit introduction of an \n\nadditional factor. Finally, ? =\t[?>\t0>G(H7>)]? and ?\", as it was ?\", are assumed to be Gaussian. \n\nUpon standardization of the data, the two-step factor estimation begins with the first set of \n\nrestrictions on the observation equation (1). As opposed to the Principal Component \n\nNormalization used in Bernanke, Boivin and Eliaz (2005)4, the normalization used in this \n\ndissertation, called Named factor normalization (NFN), follows Stock and Watson (2016)1. The \n\nNFN is used because in line with the scope of this dissertation, that is, to exploit the structural \n\n                                                \n41 Bai, J. and Ng, S., 2002. Determining the number of factors in approximate factor models. Econometrica, 70(1), pp.191-\n221. \n42 Amengual, D. and Watson, M.W., 2007. Consistent estimation of the number of dynamic factors in a large N and T \npanel. Journal of Business &amp; Economic Statistics, 25(1), pp.91-96. \n\n\n\n  21 \n \n\nanalysis features of the FAVAR. Moreover, this normalization, allows for contemporaneous \n\ncorrelation of the principal components and take the form: \n\n?JK = \t\n?H\n\n?HL8:NJK\n\t          (4) \n\nSince the VAR form is untouched and unrestricted, two more identification procedures need to \n\nbe done on the observation equation (1) in order to identify the structural shocks and broadcast \n\nthem from equation (2) to equation (1) on the individual series of the array\t?\". The identification \n\nprocedures are not all needed for forecasting, but are mainly computed to make sure that the \n\nestimated factors are identified and their space spanned is identified. For forecasting purposes, \n\nthe normalization is enough to identify the space spanned by the factors while the factors \n\nthemselves are left unidentified. Without these techniques, one would not able to reconcile the \n\nImpulse Response Functions and Forecast Error Variance Decomposition with the identified \n\nshocks.  \n\nAfter these theoretical assumptions are converted into mathematical restrictions on the \n\nobservation equation, a principal component (PCA) algorithm runs on all (or on an arbitrary \n\nnumber) of the standardized series inside the array \t?\". The PCA is a linear dimensionality \n\nreduction that uses a Singular Value Decomposition (SVD) of the data to project it to a lower \n\ndimensional space. This technique brings the 281th dimensions into some pre-determined \n\nnumber of factors that corresponds to the principal components of the spectral decomposition \n\nranked by variance explained of the dataset from which the factors are extracted. \n\nOnce the factors are identified and estimated, by reconstructing equation (2), a selected variable \n\ncan be forecast in two different ways. The most frequent method is to project the factors and \n\nthen recall the individual desired variable from the dataset \t?\" as follow: \n\n? ?4\"|\t?\",?\"?\"78,?\"78,\u2026 = ?4\nK ? ?\" + ?4(?)?4\"             (5) \n\nWhere ?4\nK = ?4? ? ? ?4(?)?4 and ?\" equation (5) represents the matrix of the current values \n\nof the stacked vector of factors. Given a selected variable to forecast,\t?4\", an alternative \n\n\n\n  22 \n \n\napproach is to extract the factors from a dataset excluding the variable of interest. This method \n\nallows to directly forecast the variable with the factors in a VAR process without recalling it \n\nfrom the observation equation: \n\n?\" = ? + ?8?\"78 + ?W?\"7W+. . .?=?\"7= + ?\"                                 (6) \n\nWhere ?\" =\t(?4,?8 \u2026?H)?, ?=are the estimated variable coefficients and ?\" the idiosyncratic \n\nshocks. For this VAR process, the h-step ahead forecast is as follow: \n\n?YLZ|Y = ? + ?8?YLZ78|Y+. . .+?=?\"LZ7=|Y                                   (7) \n\nOne important caveat of the second procedure to forecast is that the element of the matrix ?\" \n\nmust be orthogonal. In order for the vectors to be orthogonal, the dot product should be \n\napproximately zero. Such adjustment can be implemented by the modified Gram Schmidt \n\nprocess (Bj\u00f6rck, \u00c5., 1967)43 as follow: \n\n?\\\n(8) = ?\\ ?\t\t???? a(?\\)\n? ? ?\n\n?\\\n(\\78) = ?\\\n\n(\\7W) ? \t????\ncda\n(?\\\n\n\\7W )\n                                   (8) \n\nwhere ?8 \u2026?\\ are a definite, linearly independent set of vectors in space and ?8 \u2026?\\ are the \n\ngenerated orthogonal set that spans the same k-dimensional subspace. The above process, is the \n\nmodified version of the Gram-Schmidt process, that generates ? not only orthogonal to ?\\\n(\\78), \n\nbut also against any errors introduced in computation of ?\\\n(\\78). \n\nChapter 2: Stacked De-noising Auto-encoders with Bagging \n\nAlthough the SDAE-B proposed by Zhao, Li, Yu (2017)2 is fairly recent, it follows a longer \n\ntrial of Machine and Deep Learning attempts to forecast energy prices (more on this later). \n\nStacked De-noising Auto-encoders with Bagging is the full name of the hybrid used on 198 \n\nmonthly series to forecast the West Texas Intermediate (WTI) price. A hybrid is a combination \n\nof two statistical techniques, in this case, of a deep learning approach (SDAE) and an ensemble \n\n                                                \n43 Bj\u00f6rck, \u00c5., 1967. Solving linear least squares problems by Gram-Schmidt orthogonalization. BIT Numerical \nMathematics, 7(1), pp.1-21. \n\n\n\n  23 \n \n\nlearning approach (Bagging). The paper\u2019s conclusions, that motivated this research, confirmed \n\nstatistical effectiveness of this model over other Big Data comparable approaches.  \n\nThe model comes from the need to describe the price of oil dependency to multi-factors and \n\nnot only to supply and demand or even purely past values. Namely, the model is exposed to \n\n198 variables grouped in five categories: supply and demand, substitution effect from other \n\nsource of energy (natural gas, coal, renewable energies\u2026), financial markets, economic growth, \n\ntechnology and irregular events (Zhao, Li, Yu, 2017)2.  \n\nAmong the pure machine learning algorithms that tried similar exercises in the literature we \n\nfind:  genetic algorithms (Kaboudan, 2001)44, neural networks (Moshiri and Foroutan, 2006)45, \n\nsupport vector machine (Xie et al 2006)46, semi supervised learning (Greenwood-Nimmo et al, \n\n2013)47, gene expression programming (Mostafa and el Masry, 2016)13. Among the hybrid \n\nmachine learning algorithms in the literature we find: NARX (Godarzi et al, 2014)48, ANFIS \n\n(Ghaffari and Zare, 2009)49, combination of NN and GA (Chiroma et al, 2015)50, IBL (Gabralla \n\net al, 2013)51, ensemble models that first decompose oil price series into components and then \n\ncombine the forecast by NNs (Xiong et al, 201352, Yu et al, 200853, Yu et al, 201614). \n\nThere are two essential components of a hybrid structure: on one hand the model is fitted on a \n\ntraining sample and the result is used to forecast a test sample. On the other hand, there is an \n\n                                                \n44 Kaboudan, M.A., 2001. Compumetric forecasting of crude oil prices. In Evolutionary Computation, 2001. Proceedings of \nthe 2001 Congress on (Vol. 1, pp. 283-287). IEEE. \n45 Moshiri, S. and Foroutan, F., 2006. Forecasting nonlinear crude oil futures prices. The Energy Journal, pp.81-95. \n46 Xie, W., Yu, L., Xu, S. and Wang, S., 2006, May. A new method for crude oil price forecasting based on support vector \nmachines. In International Conference on Computational Science (pp. 444-451). Springer, Berlin, Heidelberg. \n47 Greenwood-Nimmo, M. and Shin, Y., 2013. Taxation and the asymmetric adjustment of selected retail energy prices in the \nUK. Economics Letters, 121(3), pp.411-416. \n48 Godarzi, A.A., Amiri, R.M., Talaei, A. and Jamasb, T., 2014. Predicting oil price movements: A dynamic Artificial Neural \nNetwork approach. Energy Policy, 68, pp.371-382. \n49 Ghaffari, A. and Zare, S., 2009. A novel algorithm for prediction of crude oil price variation based on soft \ncomputing. Energy Economics, 31(4), pp.531-536. \n50 Chiroma, H., Abdulkareem, S. and Herawan, T., 2015. Evolutionary Neural Network model for West Texas Intermediate \ncrude oil price prediction. Applied Energy, 142, pp.266-273. \n51 Gabralla, L.A., Jammazi, R. and Abraham, A., 2013, August. Oil price prediction using ensemble machine learning. \nIn Computing, Electrical and Electronics Engineering (ICCEEE), 2013 International Conference on (pp. 674-679). IEEE. \n52 Xiong, T., Bao, Y. and Hu, Z., 2013. Beyond one-step-ahead forecasting: evaluation of alternative multi-step-ahead \nforecasting models for crude oil prices. Energy Economics, 40, pp.405-415. \n53 Yu, L., Wang, S. and Lai, K.K., 2008. Forecasting crude oil price with an EMD-based neural network ensemble learning \nparadigm. Energy Economics, 30(5), pp.2623-2635. \n\n\n\n  24 \n \n\nadditional technique used for enhancing the forecasting ability of the entire model. Regarding \n\nthe latter three popular tools are used in the literature above: Bagging, Boosting and Stacking. \n\nIn particular Bagging decreases the model\u2019s variance; Boosting decreases the model\u2019s bias; and \n\nStacking increases the predictive force of the classifier.  \n\nTo understand better the stacked de-noising auto-encoders with Bagging the model is broken \n\ndown into its components. An auto-encoder is a one hidden layer neural network where its input \n\nand output size are equal. The deterministic function connecting the inputs to the output is \n\ndescribed in the implementation paragraph. De-noising is the action of cleaning partially \n\ncorrupted input through AE and, as emphasised in Vincent at al (2010)54, is important for the \n\nextraction of useful features when minimizing the average reconstruction error in the loss \n\nfunction. Multiple levels of DAE are stacked one on another to improve the information \n\nreconstruction ability of the classifier (SDAE). In this step, the parameters are tuned by popular \n\nalgorithms like the gradient descent. Finally, the ensemble component is combined. Bagging, \n\nor bootstrapping aggregation (Breiman, 1996)55 is a powerful tool frequently used in the \n\nliterature for forecasting that take an average over predictions from all the trained base models. \n\nThe main intuition behind using Auto-encoder is that the network learns the latent variables \n\nfrom the raw features while retaining the capability to produce the raw input back from the \n\nlatent features. Hence, it predicts back the raw features, the input. This is in contrast with the \n\npopular neural network (ANN) that tries to predict the labels, whereas in our case the model \n\npredicts the input only at the output. The loss is based on the performance between raw input \n\nand predicted input (at the output layer). By minimizing the loss function the raw input is \n\nreconstructed. To this process, if a noise is added to the raw input, the process takes the name \n\nof \u201cDe-noising\u201d. De-noising is sometimes substituted in the literature by \u201cSparsity\u201d Auto-\n\n                                                \n54 Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y. and Manzagol, P.A., 2010. Stacked denoising autoencoders: Learning \nuseful representations in a deep network with a local denoising criterion. Journal of machine learning research, 11(Dec), \npp.3371-3408. \n55 Breiman, L., 1996. Bagging predictors. Machine learning, 24(2), pp.123-140. \n\n\n\n  25 \n \n\nencoders as in Moussavi-Khalkhali Jamshidi (2016)56. Once the core model is structured, \n\nStacking the process is a powerful tool used to increase the predictive power of the model. The \n\nidea, as the word suggests, is that the reconstructed input, at the output layer, is passed to a \n\nsuperior Auto-encoder and processed. Each Auto-encoder is structured as the previous, but the \n\ncorrupted input within each level is different, therefore no level is the same. On top of the last \n\n? + 1 Auto-encoder, a simple algorithm is added to connect the output to the supervised cost \n\nfunction. For detailed graphical representation Vincent et al (2010)51 is the standard in the \n\nliterature. To better understand the mathematical process behind the model, a graphical \n\nrepresentation taken from Zhao, Li, Yu (2017)2 is depicted below: \n\nFigure 1 SDAE-B. Source: Y. Zhao, J. Li, L. Yu (2017) \n\n \n\nIn practice, the sample is divided into training and test with an 80-20% ratio as in Yu et al, \n\n(2008)50. To be consistent with the FAVAR, the model is applied over the same sample. In \n\nparticular the dataset is stationary according to ADF and PP tests; It is standardized and the \n\nvariables are ordered by names following the Stock and Watson (2016)1 naming variable \n\nidentification. This latter manipulation doesn\u2019t alter the performance of the deep-learning \n\n                                                \n56 Moussavi-Khalkhali, A. and Jamshidi, M., 2016, December. Constructing a Deep Regression Model Utilizing Cascaded \nSparse Autoencoders and Stochastic Gradient Descent. In Machine Learning and Applications (ICMLA), 2016 15th IEEE \nInternational Conference on (pp. 559-564). IEEE. \n\n\n\n  26 \n \n\nmodel by any means. The West Texas Intermediate is extracted from the dataset and chosen as \n\nthe target variable.  \n\nFor simplicity, a one hidden layer NN is built as main structure of the AE where the input equals \n\nthe output. The input X maps to output Y following the determinist function:  \n\n ? = ?g ? = ?i(?? + ?)           (9) \n\nWhere the parameters are ? and ?, respectively a ??? weight matrix and a bias vector. \n\nThe output Y is sub-sequentially mapped to vector ?, following the equation: \n\n ? = ?gA ? = ?o(??? + ??)        (10) \n\nwhere the parameters ?? and ?? are the corresponding ??? weight matrix and bias vector as \n\nbefore. Each parameter is optimized to minimize the average reconstruction error by following \n\nthe equation: \n\n??,?A? = arg??? 8\nN\n\n? ?4,?4N4x8 = arg???\n8\nN\n\t ?(?4,?g(?g(?4)))\n\nN\n4x8    (11) \n\nWhere the loss function ? would be the traditional squared error function ? ?,? = |? ? ?|W. \n\nFinally, Bootstrapping aggregation is implemented (Bagging). A set of K training samples is \n\nfed to K SDAE models generating K predictions that are aggregate by averaging at the end of \n\nthe process. \n\n \n\n  \n\n\n\n  27 \n \n\nChapter 3 \n\nChapter 3: FAVAR and SDAE-B implementation \n\nThe FAVAR is implemented by applying the naming factor normalization. In the Identified \n\nFAVAR, five unobserved factors are estimated on 69 selected variables according to Bai and \n\nNg (2002)57 and Amenguel and Watson (2007)58 following Stock and Watson (2016)1 \n\nimplementation and identification restrictions. The modified Gram-Schmidt algorithm is \n\ncarried on in order to orthogonalise the factors to the West Texas Intermediate by rotating their \n\nspace around the latter variable (hence, without changing its elements). After this \n\ntransformation, the factors are once again controlled for stationarity according to the popular \n\nAdvanced Dickey-Fuller (ADF) and Phillip-Perron (PP) tests (Dickey and Fuller, 197959, \n\nPhillip and Perron, 198860). The construction of the Identified FAVAR continued with the \n\nimplementation of equation (2) as a VAR on 6 variables and eight lags. The number of lags has \n\nbeen assigned by Akaike Information Criterion. The performance of the fitted model on the test \n\nsample is shown in Figure 2. \n\n                                                \n57 Bai, J. and Ng, S., 2002. Determining the number of factors in approximate factor models. Econometrica, 70(1), pp.191-\n221. \n58 Amengual, D. and Watson, M.W., 2007. Consistent estimation of the number of dynamic factors in a large N and T \npanel. Journal of Business &amp; Economic Statistics, 25(1), pp.91-96. \n59 Dickey, D.A. and Fuller, W.A., 1979. Distribution of the estimators for autoregressive time series with a unit root. Journal \nof the American statistical association, 74(366a), pp.427-431. \n60 Phillips, P.C. and Perron, P., 1988. Testing for a unit root in time series regression. Biometrika, 75(2), pp.335-346.\t\n\n\n\n  28 \n \n\nFigure 2 Identified FAVAR forecast performance visualization \n\n \n\nThe implementation of the popular Deep Neural Network (DNN) requires two steps, as it is a \n\nhybrid combination itself between two different methods: the Stacked De-noising Auto-\n\nencoders and the Bagging. 80% of the observations from 2010-01-31 to 2016-12-31 are \n\nextracted as training sample. As the bootstrapping aggregation process requires, during the first \n\nphase ? sets of replicas of the training sample are reproduced. On each ? set a SDAE is fitted. \n\nThe SDAE is literally obtained by stacking several De-noising Auto-encoders. The hidden layer \n\nof the first DAE at layer one becomes the input of the DAE at the next layer and so on for ? \n\ntimes. The first layer DAE gets as input the input of the SDAE, and the hidden layer of the last \n\nDAE represents the output. All this process is reproduced in Matlab2018 using the function \n\nSDAEB() available in the Machine Learning package. The forecast performance of the \n\nalgorithm on the test sample is reproduced in Figure 3 below. \n\n\n\n  29 \n \n\nFigure 3 SDAE-B forecast performance visualization \n\n \n\nWithout digressing too far from the scope of the dissertation, as we are discussing the \n\nimplementation phase of the models, in Figure 4, is reported the FEVD from the Identified \n\nFAVAR first equation relative to the WTI. For policy making such representation may be \n\nrelevant as a tool of structural analysis because shows the contribute of the WTI series to the \n\noverall variance of the model at 2, 4, 6, 8, 10 and 12 months. In other words, it shows the \n\namount of information that the WTI contributes to the other variables in the auto-regression. \n\nExogenous shocks to the WTI explains small forecast error variance of all factors till 12 months. \n\nGiven that the factors are extracted from a dataset representing mostly the US economy, the \n\nresults in Figure 4 are relevant when addressing policy issues. \n\n \n\nChapter 3: Performance Evaluation \n\nThe Directional Accuracy (DA), Root Mean Square Error (RMSE) and Mean Absolute \n\nPercentage Error (MAPE) are compared in order to access forecasting accuracy for both \n\nmodels. These measures reflect the most popular performance measurement in the recent \n\nliterature from Diebold and \n\n \n\n\n\n  30 \n \n\n \n\n \n\nMariano (2002)61, Mostafa and El Masry (2016)62, Yu et al (2016)63 and Zhao, Li, Yu (2017)2. \n\nThe measurement equations are proposed in equation (12), (13) and (14). Where ?\" = 1 if \n\n(?\"L8 ? ?\")(?\"L8 ? ?\") ? 0 or ?\" = 0 otherwise and N is the size of the prediction. The \n\n                                                \n61 Diebold, F.X. and Mariano, R.S., 2002. Comparing predictive accuracy. Journal of Business &amp; economic statistics, 20(1), \npp.134-144. \n62 Mostafa, M.M. and El-Masry, A.A., 2016. Oil price forecasting using gene expression programming and artificial neural \nnetworks. Economic Modelling, 54, pp.40-53. \n63 Yu, L., Dai, W. and Tang, L., 2016. A novel decomposition ensemble model with extended extreme learning machine for \ncrude oil price forecasting. Engineering Applications of Artificial Intelligence, 47, pp.110-121.\t\n\nFigure 4 Forecast Error Variance Decomposition of the Identified FAVAR \n\n\n\n  31 \n \n\nforecast performance between the Identified FAVAR and the SDAE-B are summarized in the \n\ntable 2. The table shows, as expected, the superior accuracy of the SDAE-B compared to the \n\nIdentified FAVAR. The DA is equal for both models, although this should be tested on a greater \n\nsample size. As a matter of fact, \n\nthe sample is only 20% of the 105 \n\nobservations. \n\n(12) \n\n \n\n(13)                                   \n\n \n\n(14) \n\n \n\nTable 1 Forecast performance of Identified FAVAR and SDAE-B \n\n RMSE DA MAPE \nIdentified FAVAR 0.087 0.714 1.581 \n\nSDAE-B 0.051 0.714 0.971 \n \n\nFigure 5 Identified FAVAR vs SDAE-B forecast performance visualization \n\n \n\n  \n\n\n\n  32 \n \n\nChapter 3: Forecast combination \n\nThe next exercise is to combine the two techniques. In doing so, Bates and Granger (1969)64 is \n\nthe standard discussion in the literature. Fancy combination has not yet proven superior results \n\ncompared to simple averages in out of sample forecasting. Two combination methods are \n\nproposed. The first represents the na\u00efve simple average forecast and the second is a weighted \n\nforecast based on the Root Mean Squared Error (RMSE). Although the first method gives 50% \n\nweight to both techniques, the second method ensure more significance to the SDAE-B \n\nassigning around 65% of the weight. The visual result is shown in figure 6 and the performances \n\nare measured and summarized in table 3. \n\nFigure 6 Simple Average and RMSE Weighted Average forecast combination \n\n \n\nFigure 6 shows the original series of the West Texas Intermediate (blue line) and the two models \n\nin light orange and light green. The Simple Average and the RMSE Weighted Average \n\ncombination are in red and violet respectively. The benefit of the model combinations pop up \n\nimmediately even with the simplest of the averages. This once again confirms Bates and \n\n                                                \n\n64 Bates, J. M. and Granger, C. W. (1969). The combination of forecasts. Or, pages 451\u2013468.  \n\n\n\n  33 \n \n\nGranger (1969)64 who suggest that such result could imply that combining more than just two \n\ntechniques may also be beneficial. \n\nTable 2 Simple Average and RMSE Weighted Average forecast combination \n\n RMSE DA MAPE \nIdentified FAVAR 0.087 0.714 1.581 \n\nSDAE-B 0.051 0.714 0.971 \nSimple Average 0.064 0.714 1.035 \n\nRMSE Weighted \nAvg \n\n0.058 0.714 0.877 \n\n \n\nTable 3 confirms what the visualization suggests and further shows the performance \n\nquantitatively. The MAPE from the RMSE Weighted Average combination is even superior to \n\nthe best model. The DA as expected is constant, given that both original models achieve the \n\nsame score.  \n\n\n\n  34 \n \n\nChapter 4 \n\nChapter 4: Conclusions \n\nThe following dissertation shows the benefit of a forecast combination between an econometric \n\nand a deep neural network approach. The two models implemented are a Factor Augmented \n\nVector Autoregressive Model and a Stacked De-noising Auto-encoder with Bagging, the fit \n\nperformance on the test sample is represented in Figure 2 and 3 respectively. Both techniques \n\nare fairly recent in the literature and represent important achievements in forecasting. On one \n\nside, the FAVAR exploits structural analysis features such as Impulse Response Functions and \n\nForecast Error Variance Decomposition; on the other side the SDAE-B is able to forecast \n\naccurately. One example of structural analysis visualization is depicted in Figure 4. Both \n\nmodels achieve a Directional Accuracy of 71.4%. The SDAE-B is superior in terms of Root \n\nMean Squared Error and Mean Absolute Percentage Error compared to the FAVAR. The two \n\nforecast combinations proposed are the Simple Average and the RMSE Weighted Average \n\nwhere the model with the highest RMSE is penalized. In this latter, 65% of the relative forecast \n\nimportance is assigned to the SDAE-B. The weighted combination shown in Figure 6 is the \n\nbest combination among the two, achieving a RMSE of 0.058, DA of 0.714 and a MAPE \n\nsuperior also to the SDAE-B at about 0.877. Further challenges and interesting discussions may \n\narise by comparing the forecast performance of an unidentified versus an identified FAVAR or \n\neven analysing different identification and their implications for forecasting accuracy. Clearly, \n\nextending the sample size would only be beneficial in confirming the results obtained in this \n\ndocument; finally, as proposed by Bates and Granger (1969)64, it would be interesting to \n\ncombine more than two models and try alternatives weights. \n\n  \n\n\n\n  35 \n \n\nBIBLIOGRAPHY \n \nAastveit, K.A., Natvik, G.J.J. and Sola, S., 2013. Economic uncertainty and the effectiveness \nof monetary policy. \n \nAl-Mudhaf, A. and Goodwin, T.H., 1993. Oil shocks and oil stocks: evidence from the \n1970s. Applied Economics, 25(2), pp.181-190. \n \nAlexeev, M. and Conrad, R., 2009. The elusive curse of oil. The Review of Economics and \nStatistics, 91(3), pp.586-598. \n \nAmengual, D. and Watson, M.W., 2007. Consistent estimation of the number of dynamic \nfactors in a large N and T panel. Journal of Business &amp; Economic Statistics, 25(1), pp.91-96. \n \nBai, J. and Ng, S., 2002. Determining the number of factors in approximate factor \nmodels. Econometrica, 70(1), pp.191-221. \n \nBarhoumi, K., Darn\u00e9, O. and Ferrara, L., 2013. Testing the number of factors: An empirical \nassessment for a forecasting purpose. Oxford Bulletin of Economics and Statistics,75(1), \npp.64-79. \n\nBates, J. M. and Granger, C. W. (1969). The combination of forecasts. Or, pages 451\u2013468.  \n\nBaumeister, C. and Kilian, L., 2016. Forty years of oil price fluctuations: Why the price of \noil may still surprise us. Journal of Economic Perspectives, 30(1), pp.139-60. \n \nBelke, A. and Osowski, T., 2017. International effects of euro area versus US policy \nuncertainty: A FAVAR approach (No. 689). Ruhr Economic Papers. \n \nBernanke, B.S., Boivin, J. and Eliasz, P., 2005. Measuring the effects of monetary policy: a \nfactor-augmented vector autoregressive (FAVAR) approach. The Quarterly journal of \neconomics, 120(1), pp.387-422. \n \nBj\u00f6rck, \u00c5., 1967. Solving linear least squares problems by Gram-Schmidt \northogonalization. BIT Numerical Mathematics, 7(1), pp.1-21. \n \nBreiman, L., 1996. Bagging predictors. Machine learning, 24(2), pp.123-140. \n \nChiroma, H., Abdulkareem, S. and Herawan, T., 2015. Evolutionary Neural Network model \nfor West Texas Intermediate crude oil price prediction. Applied Energy, 142, pp.266-273. \n \nConflitti, C. and Luciani, M., 2017. Oil price pass-through into core inflation. \n \nCostantini, M. and Pappalardo, C., 2008. Combination of forecast methods using \nencompassing tests: An algorithm-based procedure (No. 228). Reihe \u00d6konomie/Economics \nSeries, Institut f\u00fcr H\u00f6here Studien (IHS). \n \nDe Gooijer, J.G. and Hyndman, R.J., 2006. 25 years of time series forecasting. International \njournal of forecasting, 22(3), pp.443-473. \n \n\n\n\n  36 \n \n\nDiebold, F.X. and Mariano, R.S., 2002. Comparing predictive accuracy. Journal of Business \n&amp; economic statistics, 20(1), pp.134-144. \nDiebold, F.X. and Pauly, P., 1987. Structural change and the combination of \nforecasts. Journal of Forecasting, 6(1), pp.21-40. \n \nDickey, D.A. and Fuller, W.A., 1979. Distribution of the estimators for autoregressive time \nseries with a unit root. Journal of the American statistical association, 74(366a), pp.427-431. \n \nEickmeier, S., Lemke, W. and Marcellino, M., 2015. Classical time varying factor-\naugmented vector auto-regressive models\u2014estimation, forecasting and structural \nanalysis. Journal of the Royal Statistical Society: Series A (Statistics in Society), 178(3), \npp.493-533. \n \nGabralla, L.A., Jammazi, R. and Abraham, A., 2013, August. Oil price prediction using \nensemble machine learning. In Computing, Electrical and Electronics Engineering \n(ICCEEE), 2013 International Conference on (pp. 674-679). IEEE. \n \nGallegati, M., Ramsey, J.B. and Semmler, W., 2016. AE-FSI. Dynamic Modeling, Empirical \nMacroeconomics, and Finance: Essays in Honor of Willi Semmler, p.195. \n \nGeweke, J., 1977. The dynamic factor analysis of economic time series. Latent variables in \nsocio-economic models. \n \nGhaffari, A. and Zare, S., 2009. A novel algorithm for prediction of crude oil price variation \nbased on soft computing. Energy Economics, 31(4), pp.531-536. \n \nGodarzi, A.A., Amiri, R.M., Talaei, A. and Jamasb, T., 2014. Predicting oil price movements: \nA dynamic Artificial Neural Network approach. Energy Policy, 68, pp.371-382. \n \nGreenwood-Nimmo, M. and Shin, Y., 2013. Taxation and the asymmetric adjustment of \nselected retail energy prices in the UK. Economics Letters, 121(3), pp.411-416. \n \nHenke, N., Bughin, J., Chui, M., Manyika, J., Saleh, T., Wiseman, B. and Sethupathy, G., \n2016. The age of analytics: Competing in a data-driven world. McKinsey Global Institute, 4. \n \nHenke, N., Bughin, J., Chui, M., Manyika, J., Saleh, T., Wiseman, B. and Sethupathy, G., \n2016. The age of analytics: Competing in a data-driven world. McKinsey Global Institute, 4. \n \nhttp://www.oecd.org/publications/international-trade-by-commodity-statistics-\n22195076.htm \n \nhttps://www.worldbank.org \n \nJuvenal, L. and Petrella, I., 2011. Speculation in the oil market, Federal Reserve Bank of \nSt (No. 2001). Louis, Working Paper. \n \nJuvenal, L. and Petrella, I., 2015. Speculation in the oil market. Journal of Applied \nEconometrics, 30(4), pp.621-649. \n \n\n\n\n  37 \n \n\nk, L., 2013. Testing the number of factors: An empirical assessment for a forecasting \npurpose. Oxford Bulletin of Economics and Statistics, 75(1), pp.64-79. \n \nKaboudan, M.A., 2001. Compumetric forecasting of crude oil prices. In Evolutionary \nComputation, 2001. Proceedings of the 2001 Congress on (Vol. 1, pp. 283-287). IEEE. \n \nKilian, L. and L\u00fctkepohl, H., 2017. Structural vector autoregressive analysis. Cambridge \nUniversity Press. \n \nLombardi, M.J., Osbat, C. and Schnatz, B., 2012. Global commodity cycles and linkages: a \nFAVAR approach. Empirical Economics, 43(2), pp.651-670. \n \nMakridakis, S., 1989. Why combining works?. International Journal of Forecasting, 5(4), \npp.601-603. \n \nMarcellino, M., 2017. An Introduction to Factor Modelling. \n \nMarcellino, M., Stock, J.H. and Watson, M.W., 2000. A dynamic factor analysis of the \nEMU. manuscript, http://www. igier. uni-bocconi. it/whos. php. \n \nMirmirani, S. and Cheng Li, H., 2004. A comparison of VAR and neural networks with \ngenetic algorithm in forecasting price of oil. In Applications of Artificial Intelligence in \nFinance and Economics (pp. 203-223). Emerald Group Publishing Limited. \n \nMoshiri, S. and Foroutan, F., 2006. Forecasting nonlinear crude oil futures prices. The Energy \nJournal, pp.81-95. \n \nMostafa, M.M. and El-Masry, A.A., 2016. Oil price forecasting using gene expression \nprogramming and artificial neural networks. Economic Modelling, 54, pp.40-53. \n \nMoussavi-Khalkhali, A. and Jamshidi, M., 2016, December. Constructing a Deep Regression \nModel Utilizing Cascaded Sparse Autoencoders and Stochastic Gradient Descent. \nIn Machine Learning and Applications (ICMLA), 2016 15th IEEE International Conference \non (pp. 559-564). IEEE. \n \nMumtaz, H., Zabczyk, P. and Ellis, C., 2011. What lies beneath? A time-varying FAVAR \nmodel for the UK transmission mechanism. \n \nNaser, H., 2016. Estimating and forecasting the real prices of crude oil: A data rich model \nusing a dynamic model averaging (DMA) approach. Energy Economics, 56, pp.75-87. \n \nPesaran, M.H. and Pick, A., 2011. Forecast combination across estimation windows. Journal \nof Business &amp; Economic Statistics, 29(2), pp.307-318. \n \nPhillips, P.C. and Perron, P., 1988. Testing for a unit root in time series \nregression. Biometrika, 75(2), pp.335-346. \n \nPr\u00fcser, J. and Schl\u00f6sser, A., 2017. The effects of economic policy uncertainty on European \neconomies: Evidence from a TVP-FAVAR (No. 708). Ruhr Economic Papers. \n \n\n\n\n  38 \n \n\nRatti, R.A. and Vespignani, J.L., 2016. Oil prices and global factor macroeconomic \nvariables. Energy Economics, 59, pp.198-212. \n \nRibon, S., Augmented, V.A.R. 2011. Research Department Bank of Israel. \n \nRoss, M.L., 1999. The political economy of the resource curse. World politics, 51(2), pp.297-\n322. \n \nRoulleau-Pasdeloup, J. and Doz, C., 2011. The dynamic effects of fiscal policy: a FAVAR \napproach (No. dumas-00650820). \n \nShin, H., Hou, T., Park, K., Park, C.K. and Choi, S., 2013. Prediction of movement direction \nin crude oil prices based on semi-supervised learning. Decision Support Systems, 55(1), \npp.348-358. \n \nSiami-Namini, S., 2018. The Effect of Monetary Policy Shocks on the Real Economy: A \nFAVAR Approach. Res J Econ 2: 1. of, 9, p.2. \n \nSmith, A., 1817. An Inquiry into the Nature and Causes of the Wealth of Nations (Vol. 2). \n????? ???????. \n \nSOOD, V. and BAPNA, I., Factors Affecting Price Discovery In Crude Oil: A Literature \nReview. ISSN 2026-691X EDITORIAL BOARD. \n \nStock, J.H. and Watson, M.W., 2002. Forecasting using principal components from a large \nnumber of predictors. Journal of the American statistical association, 97(460), pp.1167-\n1179. \n \nStock, J.H. and Watson, M.W., 2016. Dynamic factor models, factor-augmented vector \nautoregressions, and structural vector autoregressions in macroeconomics. In Handbook of \nmacroeconomics (Vol. 2, pp. 415-525). Elsevier. \n \nVincent, P., Larochelle, H., Lajoie, I., Bengio, Y. and Manzagol, P.A., 2010. Stacked \ndenoising autoencoders: Learning useful representations in a deep network with a local \ndenoising criterion. Journal of machine learning research, 11(Dec), pp.3371-3408. \n \nXie, W., Yu, L., Xu, S. and Wang, S., 2006, May. A new method for crude oil price \nforecasting based on support vector machines. In International Conference on Computational \nScience (pp. 444-451). Springer, Berlin, Heidelberg. \n \nXiong, T., Bao, Y. and Hu, Z., 2013. Beyond one-step-ahead forecasting: evaluation of \nalternative multi-step-ahead forecasting models for crude oil prices. Energy Economics, 40, \npp.405-415. \n \nYu, L., Wang, S. and Lai, K.K., 2008. Forecasting crude oil price with an EMD-based neural \nnetwork ensemble learning paradigm. Energy Economics, 30(5), pp.2623-2635. \n \nYu, L., Zhao, Y. and Tang, L., 2014. A compressed sensing based AI learning paradigm for \ncrude oil price forecasting. Energy Economics, 46, pp.236-245. \n \n\n\n\n  39 \n \n\nYu, L., Dai, W. and Tang, L., 2016. A novel decomposition ensemble model with extended \nextreme learning machine for crude oil price forecasting. Engineering Applications of \nArtificial Intelligence, 47, pp.110-121. \n \nZagaglia, P., 2010. Macroeconomic factors and oil futures prices: a data-rich model. Energy \nEconomics, 32(2), pp.409-417. \n \nZhao, Y., Li, J. and Yu, L., 2017. A deep learning ensemble approach for crude oil price \nforecasting. Energy Economics, 66, pp.9-16. \n \nZou, C., Zhao, Q., Zhang, G. and Xiong, B., 2016. Energy revolution: From a fossil energy \nera to a new energy era. Natural Gas Industry B, 3(1), pp.1-11. \n\n \n  \n\n\n\n  40 \n \n\nAPPENDIX \n \nOverall, the variables aggregate into 13 dimensions: \u201cIndustrial Production\u201d, \u201cEmployment\u201d, \n\n\u201cOrders, Inventories and Sales\u201d, \u201cHousing activities\u201d, \u201cGeneral Prices\u201d, \u201cIncome\u201d, \n\n\u201cProductivity and Earnings\u201d, \u201cRates\u201d, \u201cMoney and Credit\u201d, \u201cExchange Rates\u201d, \u201cActivity\u201d, \n\n\u201cAssets Prices\u201d and finally \u201cOil related variables\u201d. Moreover, when possible, these 13 \n\ncategories are further split between USA and Global. When such division is available, \u201cUSA\u201d \n\nrefers to variables related to the US economy only, whereas \u201cGlobal\u201d refers to variables related \n\nto the top 20 global economies ranked by gross domestic product adjusted for price purchasing \n\nparity. \n\n \nTABLE APPENDIX: DATA SERIES \n\nName Description \n\n1a Industrial Production, USA \n\nIPDurGooMat Industrial Production: Durable Materials SA \n\nIPNDuGooMat Industrial Production: nondurable Materials \n\nIPDurConsGoo Industrial Production: Durable Consumer Goods \n\nIPAuto IP: Automotive products \n\nIPNDurConsGod Industrial Production: Nondurable Consumer Goods \n\nIPBusEquip Industrial Production: Business Equipment \n\nCapUtiTot US Capacity Utilization Special Aggregates Excluding High Tech Total Industry \n\n1b Industrial Production, Global \n\nIP_CHN IMF China Industrial Production                                                  \n\nIP_IND  Production in Total Manufacturing for India \n\nIP_JPN Production in Total Manufacturing for Japan \n\nIP_GER Production in Total Manufacturing for Germany \n\nIP_RUS Production in Total Manufacturing for Russian Federation \n\nIP_IDN Production in Total Manufacturing for Indonesia \n\nIP_BRA Production in Total Manufacturing for Brazil \n\nIP_GBN UK Industrial Production                 \n\nIP_FRA Production in Total Manufacturing for France \n\nIP_MXN Production of Total Construction in Mexico \n\nIP_ITA Production in Total Manufacturing for Italy \n\nIP_TUR Production in Total Manufacturing for Turkey \n\nIP_KOR Production in Total Manufacturing for Korea \n\nIP_ESP Production in Total Manufacturing for Spain \n\nIP_CAN IMF Canada Industrial Production SA                                              \n\nIP_THA Production in Total Manufacturing for Thailand \n\n2a. Employment, USA \n\nNFP_MLO US Employees on Nonfarm Payrolls Natural Resources &amp; Mining SA                   \n\n\n\n  41 \n \n\nNFP_CST US Employees On Nonfarm Payrolls By Industry Construction SA                     \n\nNFP_DUR Employees on Nonfarm payroll by Industry Durable Goods SA                        \n\nNFP_NDU Employees on Nonfarm payroll by Industry Nondurable Goods SA                     \n\nNFP_WSL US Employees On Nonfarm Payrolls By Industry Wholesale Trade SA                  \n\nNFP_RET US Employees On Nonfarm Payrolls By Industry Retail Trade Total SA               \n\nNFP_TRW Employees on Nonfarm payroll by Industry Transportation &amp; Warehousing SA         \n\nNFP_INF US Employees on Nonfarm Payrolls Information SA                                  \n\nNFP_FIN US Employees On Nonfarm Payrolls By Industry Finance Insurance Real Estate SA    \n\nNFP_EDH US Employees on Nonfarm Payrolls Education &amp; Health Services SA                  \n\nNFP_LEH US Employees on Nonfarm Payrolls Leisure &amp; Hospitality SA                        \n\nNFP_GOS US Employees on Nonfarm Payrolls State Govt SA                                   \n\nNFP_GOL US Employees on Nonfarm Payrolls Local Govt SA                                   \n\nNLF_CNIP US Civilian Noninstitutional Population Total NSA                              \n\nNLF_CLF US Employment Civilian Labor Force Total in Labor Force SA Household Survey      \n\nNLF_DJB Not in LF and don`t want a job now \n\nNLF_WJB US Civilians Not in Labor Force But Currently Want a Job NSA                     \n\nNLF_WMA US Unemployed &amp; Discouraged &amp; Margin as # Labor Force &amp; Margin NSA               \n\nNLF_WDI US Number of Discouraged Workers NSA                                             \n\nUN_ERS US Employment Part Time for Economic Reasons SA                                  \n\nUN_NERS US Employment Part Time Workers Noneconomic Reasons SA                           \n\nUN_NTMR Number Of Unemployed Not On Temporary Layoff SA                                  \n\nUN_JBL US Unemployment Job Leavers Total SA                                             \n\nUN_5WE US Unemployment Duration Less Than 5 Weeks SA                                    \n\nUN_15W US Unemployment Duration Over 15 Weeks SA                                        \n\nUN_27W US Unemployment Duration 27 Weeks and Over SA                                    \n\nOVR_MNF US Average Weekly Hours All Employees Manufacturing Overtime Hours SA            \n\nOVR_DUR US Average Weekly Hours All Employees Durables Gds Overtime Hours SA             \n\nUNMP_USA   U-3 US Unemployment Rate Total in Labor Force Seasonally Adjusted                \n\n2b. Employment, Global \n\nUNMP_JPN Japan Unemployment Rate SA                                                       \n\nUNMP_DEU Germany Total Civilian Unemployment                                              \n\nUNMP_RUS Unemployment Rate Russia                                                        \n\nUNMP_BRA Unemployment Rate Brazil \n\nUNMP_GBR Unemployment Rate UK \n\nUNMP_FRA Unemployment Rate France \n\nUNMP_MEX Unemployment Rate Mexico \n\nUNMP_ITA Unemployment Rate Italy \n\nUNMP_TUR Unemployment Rate Turkey \n\nUNMP_KOR Unemployment Rate South Korea \n\nUNMP_ESP Unemployment Rate Spain \n\nUNMP_CAN Unemployment Rate Canada \n\nUNMP_THA Unemployment Rate Thailand \n\nUNMP_AUS Unemployment Rate Australia \n\n3. Orders, Inventories and Sales, USA \n\nPMI_NOR ISM Manufacturing Report on Business New Orders SA                               \n\nPMI_PRD ISM Manufacturing Report on Business Production SA                               \n\n\n\n  42 \n \n\nPMI_EMP ISM Manufacturing Report on Business Employment SA                               \n\nPMI_DEL ISM Manufacturing Report on Business Supplier Deliveries SA                      \n\nPMI_BIN ISM Manufacturing Report on Business Inventories NSA                             \n\nPMI_CIN ISM Manufacturing Report on Business Customers' Inventories NSA                  \n\nPMI_PRC ISM Manufacturing Report on Business Prices Index NSA deflated                            \n\nPMI_BCK ISM Manufacturing Report on Business Backlog of Orders NSA                       \n\nPMI_BX ISM Manufacturing Report on Business Export Orders SA                            \n\nPMI_BM ISM Manufacturing Report on Business Imports SA                                  \n\nSL_TOT Adjusted Retail &amp; Food Services Sales Total SA                                   \n\nSL_XMV Adjusted Retail Sales Less Motor Vehicle and Parts Dealers SA                      \n\nSL_XMG Adjusted Retail Sales Less Autos and Gas Stations SA                             \n\nSL_SB Adjusted Retail Sales Food Services and Drinking Places SA                         \n\nSL_ECO E-COMMERCE SALES QUARTERLY                                                       \n\n4. Housing Activity, USA \n\nHstartsNE US New Privately Owned Housing Units Started Northeast 1 Unit Structure SAAR     \n\nHstartsMW US New Privately Owned Housing Units Started Midwest 1 Unit Structure SAAR       \n\nHstartsS US New Privately Owned Housing Units Started South 1 Unit Structure SAAR         \n\nHstartsW US New Privately Owned Housing Units Started West 1 Unit Structure SAAR          \n\nPermitsN US New Privately Owned Housing Auth by Building Permits Northeast 1 Unit SAAR    \n\nPermitsMW US New Privately Owned Housing Auth by Building Permits Midwest 1 Unit SAAR      \n\nPermitsS US New Privately Owned Housing Auth by Building Permits South 1 Unit SAAR        \n\nPermitsW US New Privately Owned Housing Auth by Building Permits West 1 Units SAAR        \n\n5a. General Prices, USA \n\nPCE_DEF PCE DEF Index \n\nPPI_FGF PPI final demand for foods \n\nPPI_ENE PPI final demand for energy \n\nPPI_LOG PPI logging \n\nPPI_MNF PPI total mining utilities and manufacturing \n\nPPI_CON PPI construction \n\nPPI_TRD PPI trade \n\nPPI_TRS PPI transportation and warehousing \n\nCPSFFOOD Food \n\nCPUPENER Energy \n\nCPUPENCM Energy Commodities \n\nCPSHFOCB Fuel Oil and Other Fuels \n\nCPIQFUOS Fuel oil \n\nCPIQPKFS Propane, Kerosene, and Firewood \n\nCPSTMTFL Motor fuel \n\nCPSTGAS Gasoline All Types \n\nCPIQGURS Unleaded Regular Gasoline \n\nCPIQGUMS Gasoline, Unleaded Midgrade \n\nCPIQGUPS Gasoline, Unleaded Premium \n\nCPIQOMFS Other Motor Fuels \n\nCPSHGE Energy Services \n\nCPIQELS Electricity \n\nCPIQUPGS Utility (Piped) Gas Service \n\n\n\n  43 \n \n\nCPUPAXFE All Items Less Food and Energy Rebased at 31/01/10 \n\nCPCATOT Commodities \n\nCPSSTOT Services \n\nCPCADUR Durables \n\nCPUPNOND Nondurables \n\nCPSHTOT Housing \n\nCPUETOT Education and Communication \n\nCPSRTOT Recreation \n\nCPSFTOT Food and beverages \n\nCPIQALFS Apparel Less Footwear \n\nCPSHFU Fuels and Utilities \n\nCPUMTOT Medical care \n\nCPSTTOT Transportation \n\nCPIQUPTS Utilities and Public Transportation \n\nCPSHHHFO Household Furnishings and Operations \n\nCPUOTOT Other goods and services \n\nCPI_USA Consumer price index usa \n\n5b. General Prices, Global \n\n CPI_CHN China CPI Total at Constant Price 1978=100                                       \n\n CPI_IND consumer price index india \n\n CPI_JPN consumer price index japan \n\n CPI_DEU consumer price index germany \n\n CPI_RUS consumer price index russia \n\n CPI_IDN consumer price index indonesia \n\n CPI_BRA FGV Brazil IGP-M CPI IPC-M                                                       \n\n CPI_GBN consumer price index uk \n\n CPI_FRA consumer price index france \n\n CPI_MXN consumer price index mexico \n\n CPI_ITA consumer price index ita \n\n CPI_TUR consumer price index turkey \n\n CPI_KOR consumer price index south korea \n\nCPI_ESP consumer price index spain \n\n CPI_CAN consumer price index canada \n\n CPI_THA consumer price index thailand \n\n CPI_SAU consumer price index australia \n\n6. Income, USA \n\nPI_PI US Personal Income SAAR Deflated \n\nPI_WSD Personal Income Wage &amp; Salary Disbursements SAAR Deflated                                 \n\nPI_DIV Personal Income Personal Dividend Income SA Deflated                 \n\nPI_INT Personal Income Personal Interest Income SA Deflated                                     \n\nPI_TPP Personal Income Transfer Payments to Persons SA Deflated                                  \n\nDISP_INC US Disposable Personal Income Nominal Dollars SAAR Deflated                               \n\nPCE$ Personal Consumption Expenditures (current $) Deflated \n\nPCE_DUR US Personal Consumption Expenditures Durable Goods Nominal Dollars SAAR Deflated \n\nPCE_NDU US Personal Consumption Expenditures Non Durable Goods Nominal Dollars SAAR Deflated \n\nPCE_SRV US Personal Consumption Expenditures Services Nominal Dollars SAAR Deflated \n\n\n\n  44 \n \n\nSAVING Personal Savings Deflated \n\nSAV_RATE US Personal Saving as a % of Disposable Personal Income                          \n\nDUR%PCE US Durable Goods Spending as a % PCE Current Dollars SAAR                        \n\nNDU%PCE US Nondurable Good Spending as a % PCE Current Dollars SAAR                      \n\nSRV%PCE US Service Spending as a % PCE Current Dollars SAAR                              \n\n7. Productivity and Earnings, USA \n\nERP_PRV Average hourly earnings Deflated \n\nERP_MLO Mining and Logging Deflated \n\nERP_CST Construction Deflated \n\nERP_DUR Manufacturing Durable goods Deflated \n\nERP_NDU Manufacturing Non durable goods Deflated \n\nERP_WSL Wholesale Trade Deflated \n\nERP_RET Retail Trade Deflated \n\nERP_TRW Transportation and warehousing Deflated \n\nERP_INF Information Deflated \n\nERP_FIN Financial Activities Deflated \n\nERP_PRB Professional and Business Services Deflated \n\nERP_EDH Education and Health Services Deflated \n\nERP_TTU Trade, Transportation, and Utilities Deflated \n\n8. Rates, USA \n\nFFR US Federal Funds Effective Rate                   \n\nTB3 IMF US Treasury Bill 3 Month Rate                                                \n\nBAA_G10 US Corporate BAA 10 Year Spread \n\nMRG_G10 US Bloomberg Fannie to Govt Spread 10 Year \n\nTB24_TB6 Treasury Spreads 2 Year - 6 month \n\nG10_TB3 Treasury Spreads 10 Year - 3 month \n\nTED_SPD Ted Spread \n\n9. Money and Credit, USA \n\nM1 Federal Reserve United States Money Supply M1 SA Deflated                                 \n\nM2 Federal Reserve United States Money Supply M2 SA Deflated                                \n\nLOA_LEA US Commercial Bank Assets Loans &amp; Leases Commercial &amp; Industrial SA Deflated             \n\nREV_CRE Revolving Consumer Credit Owned and Securitized SA Flow Deflated \n\nCOS_CRE Total Consumer Credit Owned and Securitized SA Flow Deflated                            \n\nCOS_AUT Federal Reserve Consumer Credit Commercial Bank Rate 48 Month New Car Deflated            \n\n10. Exchange Rates, Global \n\nEURUSD EURUSD Spot Exchange Rate - Price of 1 EUR in USD \n\nUSDCNH  USDCNH Spot Exchange Rate - Price of 1 USD in CNH \n\nUSDINR  USDINR Spot Exchange Rate - Price of 1 USD in INR \n\nUSDJPY  USDJPY Spot Exchange Rate - Price of 1 USD in JPY \n\nUSDZAR  USDZAR Spot Exchange Rate - Price of 1 USD in ZAR \n\nUSDIDR  USDIDR Spot Exchange Rate - Price of 1 USD in IDR \n\nUSDBRL USDBRL Spot Exchange Rate - Price of 1 USD in BRL \n\nGBPUSD GBPUSD Spot Exchange Rate - Price of 1 GBP in USD \n\nUSDMXN USDMXN Spot Exchange Rate - Price of 1 USD in MXN \n\nUSDTRY USDTRY Spot Exchange Rate - Price of 1 USD in TRY \n\nUSDKRW USDKRW Spot Exchange Rate - Price of 1 USD in KRW \n\n\n\n  45 \n \n\nUSDCAD USDCAD Spot Exchange Rate - Price of 1 USD in CAD \n\nUSDTHB USDTHB Spot Exchange Rate - Price of 1 USD in THB \n\nAUDUSD AUDUSD Spot Exchange Rate - Price of 1 AUD in USD \n\nUSDSAR USDSAR Spot Exchange Rate - Price of 1 USD in SAR \n\nUSDCHF USDCHF Spot Exchange Rate - Price of 1 USD in CHF \n\n11. Activity, Global \n\nSTE_65 IISI World Total Steel Production Data-Currently 65 countries \n\nSTE_EU World Steel Association Crude Steel Production Data/European Union \n\nKILIAN Kilian Global Economic Activity Index \n\nWEATHER Average (\u00b0F) in Alabama \n\n12. Asset Prices, Global \n\nSP100 S&amp;P Global 100 Index \n\nMSCIW MSCI World Index \n\nDJIA Dow Jones Industrial Average \n\nNIKKEI Nikkei 225 \n\nFTSE100 FTSE 100 Index \n\nSHANGHAIEXC Shanghai Stock Exchange Composite Index \n\nSENSEX S&amp;P BSE SENSEX Index \n\nHANGSENG Hong Kong Hang Seng Index \n\nIBOVESPA Ibovespa Brasil Sao Paulo Stock Exchange Index \n\nTSXEXC S&amp;P/TSX Composite Index \n\nCAC40 CAC 40 Index \n\nDAX Deutsche Boerse AG German Stock Index DAX \n\nFTSEMIB FTSE MIB Index \n\nMOEX MOEX Russia Index \n\nKOSPI Korea Stock Exchange KOSPI Index \n\nIBEX35 IBEX 35 Index \n\nSETEXC Stock Exchange of Thailand SET Index \n\nAUSEXC Australian Stock Exchange All Ordinaries Index \n\nVOL Chicago Board Options Exchange OEX Volatility Index \n\nSHILLER20 S&amp;P CoreLogic Case-Shiller 20-City Composite Home Price SA Index Deflated                \n\nSHILLER10 S&amp;P CoreLogic Case-Shiller 10-City Composite Home Price SA Index Deflated                \n\nGOLD IMF UK USD per Ounce of Gold End of Period Deflated                                      \n\n13. Oil related variables, Global \n\nGASOLINE Gasoline All Types                                                               \n\nEXP_OPEC Exports by Selected Countries SA OPEC Deflated                                           \n\nIMP_CIF_OPEC General Imports of Crude Oil OPEC Total CIF Value in thousand of Dlr NSA Deflated        \n\nIMP_CUS_OPEC General Imports of Crude Oil OPEC Total Customs Value in thousand of Dollars NSA Deflated \n\nIMP_TOT_OPEC General Imports of Crude Oil OPEC Total Qty in Thousands of Barrels NSA          \n\nIMP_TOT_NOPE General Imports of Crude Oil from Non-OPEC CIF Value in thousand of Dlr NSA  Deflated    \n\nIMP_CUS_NOPE General Imports of Crude Oil from Non-OPEC Customs Value in thousand of Dlr NSA Deflated \n\nIMP_TOT_NOPE1 General Imports of Crude Oil from Non-OPEC Qty in Thousands of Barrels NSA       \n\nSUPPLY_NOPE International Crude Oil and Liquid Fuels Supply Non OPEC \n\nNAT_GAS Natural gas Deflated \n\nWTI West Texas Intermediate Spot \n\nBRENT Brent Deflated \n\n\n\n  46 \n \n\nWTIBRENT_SPRDF Bloomberg Fair Value Price/NYMEX WTI Futures minus ICE Brent Futures Month 1 \n\nWTIBRENT_SPRDS Bloomberg Fair Value Price/WTI-Brent Crude Oil Spread Monthly \n\nDOES_OPEC DOE Monthly OPEC Total Crude Oil (excluding condensates) Supply \n\nDOEC_OPEC_TOT DOE Monthly OPEC Total Crude Oil Production Capacity \n\nDOEC_OPEC_EXC DOE Monthly OPEC Total Surplus Crude Oil Production Capacity \n\nBLB_Y_OPEC Bloomberg Total OPEC Crude Oil Production Output Data \n\nEI_OPEC_PROD Energy Intelligence Group OPEC Crude Oil Production Data \n\nEI_ROW_Q Energy Intelligence Group Oil Products Non-OECD Rest of World Demand Data \n\nEI_OECD_Q Energy Intelligence Group OECD Oil Products Demand Data \n\nEI_OIL_Q Energy Intelligence Group Oil Product Demand Data \n\nBH_OPEC_RIG Baker Hughes OPEC Countries Oil And Gas Rotary Rig Count Data \n\nBH_NOPE_RIG Baker Hughes Non-OPEC Countries Oil And Gas Rotary Rig Count Data \n\nBH_US_RIG Baker Hughes U.S. Oil And Gas Rotary Rig Count Data \n\nBH_CAN_RIG Baker Hughes Canadian Oil And Gas Rotary Rig Count Data \n\nBH_LATAM_RIG Baker Hughes Latin America Oil And Gas Rotary Rig Count Data \n\nBH_MDE_RIG Baker Hughes Middle East Oil And Gas Rotary Rig Count Data \n\nBH_FEAST_RIG Baker Hughes Far East Oil And Gas Rotary Rig Count Data \n\nBH_EU_RIG Baker Hughes Europe Oil And Gas Rotary Rig Count Data \n\nBH_AFR_RIG Baker Hughes Africa Oil And Gas Rotary Rig Count Data \n\nEIA_AME_STOCK International Energy Agency OECD Americas Industry Crude Oil Stocks \n\nEIA_EU_STOCK International Energy Agency OECD Europe Industry Crude Oil Stocks \n\nEIA_PAC_STOCK International Energy Agency OECD Pacific Industry Crude Oil Stocks \n\nEIA_AME_Y International Energy Agency Americas Industry Total Product Stocks \n\nEIA_EU_Y International Energy Agency Europe Industry Total Product Stocks \n\nEIA_PAC_Y International Energy Agency Pacific Industry Total Product Stocks \n\nDOES_48_Y DOE Crude Oil Lower 48 States Production Data \n\nGAS_Y Natural Gas Production Estimates - Lower 48 \n\nST_Y_FRCST DOE Short Term Outlook Total Crude Oil Production Forecast Monthly \n\nST_GAS_Y United States Short Term Energy Outlook Dry Natural Gas Production \n\nST_COAL_Y United States Short Term Energy Outlook Coal Production \n\nST_OIL_P United States Short Term Energy Outlook Energy Prices Crude Oil Deflated \n\nST_GAS_P United States Short Term Energy Outlook Natural Gas Henry Hub Deflated \n\nST_COAL_P United States Short Term Energy Outlook Energy Prices Coal Deflated \n\nIMP_PAD1 DOE PSM PADD 1 Imports of Crude Oil \n\nIMP_PAD2 DOE PSM PADD 2 Imports of Crude Oil \n\nIMP_PAD3 DOE PSM PADD 3 Imports of Crude Oil \n\nIMP_PAD4 DOE PSM PADD 4 Imports of Crude Oil \n\nIMP_PAD5 DOE PSM PADD 5 Imports of Crude Oil \n\nEXP_PAD2 DOE US PADD II Exports of Crude Oil \n\nWTI_futures West Texas Intermediate Futures"}]}}}