{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.09465"}, {"@name": "filename", "#text": "14451_001082104.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNIVERSIDADE FEDERAL DO RIO GRANDE DO SUL\nESCOLA DE ENGENHARIA\nDEPARTAMENTO DE ENGENHARIA EL\u00c9TRICA\nVIN\u00cdCIUS GUILHERME M\u00dcLLER\nPREVIS\u00c3O DO \u00cdNDICE BOVESPA UTILIZANDO REDES NEURAIS\nPREVIS\u00c3O DO \u00cdNDICE BOVESPA UTILIZANDO REDES NEURAIS\nMonografia apresentada para a obten\u00e7\u00e3o do grau de Bacharel em Engenharia El\u00e9trica na Universidade Federal do Rio Grande do Sul.\nORIENTADOR: PROF. DR. ALEXANDRE BALBINOT\nPREVIS\u00c3O DO \u00cdNDICE BOVESPA UTILIZANDO REDES NEURAIS\nEsta monografia foi analisada e julgada adequada para a obten\u00e7\u00e3o do t\u00edtulo de Bacharel em Engenharia El\u00e9trica e aprovada em sua forma final pelo Orientador e pela Banca Examinadora proposta pelo Orientador.\nOrientador: Prof. Dr. Alexandre Balbinot\nCoordenador: Prof. Dr. Alberto Bastos do Canto Filho\nAprovado em:\t/\t/\nBANCA EXAMINADORA:\nProf. Dr. Alexandre Balbinot - UFRGS - DELET________________________________\nProfa. Dra. Leia B. Bagesteiro - UFRGS - DELET______________________________\nMe. Vin\u00edcius Cene - UFRGS - PPGEE___________________________________________\nRESUMO\nA previs\u00e3o do mercado de a\u00e7\u00f5es tem sido um tema de grande interesse no campo das finan\u00e7as, da engenharia e da matem\u00e1tica devido ao seu potencial de ganho financeiro. No entanto, a previs\u00e3o do pre\u00e7o das a\u00e7\u00f5es \u00e9 altamente complexa, pois as s\u00e9ries financeiras possuem altos n\u00edveis de ru\u00eddo, s\u00e3o din\u00e2micas, n\u00e3o-lineares e ca\u00f3ticas por natureza. Al\u00e9m disso existem muitos fatores como eventos pol\u00edticos, condi\u00e7\u00f5es econ\u00f4micas, expectativas dos investidores e outros fatores ambientais que podem influenciar no pre\u00e7o das a\u00e7\u00f5es. O objetivo deste estudo foi desenvolver uma Rede Neural Feedforward para prever as tend\u00eancias do \u00cdndice Bovespa em um horizonte de tempo de uma semana. Foram calculadas 220 diferentes caracter\u00edsticas consistindo em indicadores t\u00e9cnicos, volatilidade e nas cota\u00e7\u00f5es do d\u00f3lar, do petr\u00f3leo, do ouro, assim como das a\u00e7\u00f5es que comp\u00f5em o \u00edndice. As caracter\u00edsticas foram ranqueadas utilizando-se como modelo um Gradient Boosting de \u00c1rvores de Decis\u00e3o em um algoritmo Recursive Feature Elimination. Foram implementadas diferentes redes possuindo diferentes n\u00fameros de neur\u00f4nios e quantidades variadas das caracter\u00edsticas mais bem classificadas. Foi poss\u00edvel obter uma taxa de acertos de 58,63% para o conjunto de valida\u00e7\u00e3o e 58,13% para o conjunto de teste para a rede utilizando as 40 caracter\u00edsticas mais bem classificadas pelo ranking. Utilizando-se todas as 220 entradas pr\u00e9-selecionadas a rede obteve uma taxa de acertos de 51,39%, evidenciando a import\u00e2ncia da sele\u00e7\u00e3o de caracter\u00edsticas para esse problema.\nPalavras-chave: Previs\u00e3o do Mercado Financeiro. Redes Neurais. S\u00e9ries Financeiras. Recursive Feature Elimination. Gradient Boosting.\nABSTRACT\nStock market forecasting has been a subject of great interest in the field of finance, engineering and mathematics because of its potential for financial gain. However, stock price prediction is highly complex since financial series have high levels of noise, are dynamic, non-linear and chaotic by nature. In addition, there are many factors such as political events, economic conditions, investor expectations and other environmental factors that may influence stock prices. The objective of this study was to develop a Feedforward Neural Network to predict trends of the Bovespa Index over a one-week time horizon. Different characteristics were calculated, consisting of technical indicators, volatility and the dollar, oil and gold prices, as well as the stocks that make up the index. The features were ranked using a Gradient Boosting of Decision Trees in a Recursive Feature Elimination algorithm. Different networks with different numbers of neurons and varying amounts of the best classified features were implemented. It was possible to obtain an accuracy rate of 58.63% for the validation set and 58.13% for the test set for the network using the 40 best classified features in the ranking. Using all the 220 pre-selected features, the network obtained an accuracy rate of 51.39%, evidencing the importance of the feature selection on this problem.\nKeywords: Stock Market forecasting. Neural Networks. Financial Time Series. Recursive Feature Elimination. Gradient Boosting.\nLISTA DE ILUSTRA\u00c7\u00d5ES\nFigura 1 - Bandas de Bollinger...............................................14\nFigura 2 - Estrutura do neur\u00f4nio artificial..................................15\nFigura 3 - Representa\u00e7\u00e3o de uma rede neural MLP..............................17\nFigura 4 - Tipos de tarefas..................................................20\nFigura 5 - \u00c1rvores de Decis\u00e3o................................................21\nFigura 6 - \u00cdndice Bovespa e taxa de retorno de 5 dias........................29\nFigura 7 - Histograma da taxa de retorno.....................................29\nFigura 8 - C\u00e1lculo das caracter\u00edsticas.......................................31\nFigura 9 - M\u00e9dia M\u00f3vel Simples (20 dias) do \u00cdndice Bovespa...................32\nFigura 10 - M\u00e9dia M\u00f3vel Simples (20 dias) do \u00cdndice Bovespa..................33\nFigura 11 - Taxa de Varia\u00e7\u00e3o (10 dias).......................................33\nFigura 12 - Volume e raz\u00e3o entre m\u00e9dias m\u00f3veis...............................34\nFigura 13 - Desvio padr\u00e3o (20 dias)..........................................35\nFigura 14 - Rela\u00e7\u00e3o entre os pre\u00e7os m\u00e1ximo e m\u00ednimo (10 dias)................36\nFigura 15 - Rela\u00e7\u00e3o entre os pre\u00e7os de fechamento e de abertura (10\tdias)....37\nFigura 16 - Rela\u00e7\u00e3o entre os pre\u00e7os de abertura e de fechamento do per\u00edodo anterior\n(10 dias)....................................................................37\nFigura 17 - Taxa de Varia\u00e7\u00e3o (10 dias) da cota\u00e7\u00e3o do D\u00f3lar/Real..............38\nFigura 18 - Taxa de Varia\u00e7\u00e3o (10 dias) da cota\u00e7\u00e3o do Petr\u00f3leo................38\nFigura 19 - Taxa de Varia\u00e7\u00e3o (10 dias) da cota\u00e7\u00e3o do Ouro....................39\nFigura 20 - Algoritmo de ranqueamento das caracter\u00edsticas....................40\nFigura 21 - N\u00famero de neur\u00f4nios dos modelos em cada camada...................42\nFigura 22 - Valida\u00e7\u00e3o cruzada k folds........................................43\nFigura 23 - Taxa de acertos dos conjuntos de treinamento e de valida\u00e7\u00e3o......44\nFigura 24 - Custo dos conjuntos de treinamento e de valida\u00e7\u00e3o................44\nFigura 25 - Taxa de acertos do conjunto de valida\u00e7\u00e3o.........................48\nFigura 26 - Taxa de acertos do conjunto de testes............................50\nFigura 27 - Taxa de acertos para os dados de teste do algoritmo XGBoost......51\nLISTA DE TABELAS\nTabela 1 - Fun\u00e7\u00f5es de ativa\u00e7\u00e3o e suas caracter\u00edsticas................................17\nTabela 2 - Divis\u00e3o de classes........................................................30\nTabela 3 - Ranking de caracter\u00edsticas................................................46\nTabela 4 - Taxa de acertos de valida\u00e7\u00e3o com 10 caracter\u00edsticas.......................47\nTabela 5 - Taxa de acertos de valida\u00e7\u00e3o com 20 caracter\u00edsticas.......................47\nTabela 6 - Taxa de acertos de valida\u00e7\u00e3o com 30 caracter\u00edsticas.......................47\nTabela 7 - Taxa de acertos de valida\u00e7\u00e3o com 40 caracter\u00edsticas.......................48\nTabela 8 - Taxa de acertos de valida\u00e7\u00e3o com 50 caracter\u00edsticas.......................48\nTabela 9 - Taxa de acertos de valida\u00e7\u00e3o com 60 caracter\u00edsticas.......................48\nTabela 10 - Taxa\tde acertos\tde teste com\t10 caracter\u00edsticas.....................49\nTabela 11 - Taxa\tde acertos\tde teste com\t20 caracter\u00edsticas.....................49\nTabela 12 - Taxa\tde acertos\tde teste com\t30 caracter\u00edsticas.....................49\nTabela 13 - Taxa\tde acertos\tde teste com\t40 caracter\u00edsticas.....................49\nTabela 14 - Taxa\tde acertos\tde teste com\t50 caracter\u00edsticas.....................49\nTabela 15 - Taxa\tde acertos\tde teste com\t60 caracter\u00edsticas.....................49\nTabela 16 - Matriz de confus\u00e3o da rede...............................................50\nTabela 17 - Taxa de acertos de teste com 60 caracter\u00edsticas..........................51\nSUM\u00c1RIO\n1\tINTRODU\u00c7\u00c3O................................................7\n2\tFUNDAMENTA\u00c7\u00c3O TE\u00d3RICA....................................10\n2.1\tO MERCADO DE A\u00c7\u00d5ES......................................10\n2.1.1\tA Hip\u00f3tese do Mercado Eficiente (HME).................11\n2.1.2\tA An\u00e1lise T\u00e9cnica.....................................12\n2.2\tAS REDES NEURAIS ARTIFICIAIS..........................15\n2.3\t\u00c1RVORES DE DECIS\u00c3O E O GRADIENT BOOSTING................20\n2.4\tM\u00c9TRICAS DE DESEMPENHO..................................23\n2.5\tTRABALHOS RELACIONADOS..................................24\n3\tMETODOLOGIA..............................................28\n3.1\tBASE DE DADOS E SUA DIVIS\u00c3O.............................28\n3.2\tVARI\u00c1VEL DE PREVIS\u00c3O....................................28\n3.3\tCARACTER\u00cdSTICAS DE PREVIS\u00c3O.............................30\n3.3.1\tC\u00e1lculo das caracter\u00edsticas...........................31\n3.3.2\tRanqueamento das caracter\u00edsticas......................39\n3.4\tMODELO PROPOSTO.........................................41\n4\tRESULTADOS E DISCUSS\u00d5ES..................................46\n5\tCONCLUS\u00c3O................................................52\n6\tPROPOSTAS PARA TRABALHOS FUTUROS.........................54\nREFER\u00caNCIAS BIBLIOGR\u00c1FICAS..................................55\nANEXO - A\u00e7\u00f5es inclu\u00eddas nas caracter\u00edsticas.................59\n1 INTRODU\u00c7\u00c3O\nA previs\u00e3o do mercado financeiro tem sido um tema de grande interesse no campo das finan\u00e7as, da engenharia e da matem\u00e1tica devido ao seu potencial de ganho financeiro (YOO et al., 2005). No entanto, a previs\u00e3o do pre\u00e7o das a\u00e7\u00f5es \u00e9 altamente complexa, pois existem muitos fatores como eventos pol\u00edticos, condi\u00e7\u00f5es econ\u00f4micas, expectativas dos investidores e outros fatores ambientais que podem influenciar nos pre\u00e7os. Al\u00e9m disso, as s\u00e9ries hist\u00f3ricas de pre\u00e7os possuem altos n\u00edveis de ru\u00eddo, s\u00e3o din\u00e2micas, n\u00e3o-lineares, n\u00e3o-param\u00e9tricas e ca\u00f3ticas por natureza (ZHANG &amp; WU, 2009).\nDe acordo com Box et al. (2008), a previs\u00e3o baseada em s\u00e9ries temporais representa um meio de prover informa\u00e7\u00e3o e conhecimento para apoiar uma decis\u00e3o subsequente. Portanto, a an\u00e1lise de s\u00e9ries temporais tem por objetivo obter rela\u00e7\u00f5es de depend\u00eancia entre dados hist\u00f3ricos, ou seja, determinar estruturas e padr\u00f5es nesses dados e, desta an\u00e1lise, desenvolver um modelo que preveja seu comportamento.\nEm geral, as abordagens existentes para prever os pre\u00e7os do mercado financeiro podem ser amplamente classificadas em dois tipos, a An\u00e1lise Fundamental e a An\u00e1lise T\u00e9cnica (BLACK, 1982). A An\u00e1lise Fundamental baseia-se em dados macroecon\u00f4micos, como exporta\u00e7\u00f5es e importa\u00e7\u00f5es, oferta monet\u00e1ria, taxas de juros, taxas de infla\u00e7\u00e3o, taxas de c\u00e2mbio, taxa de desemprego, assim como no perfil financeiro espec\u00edfico da empresa, que inclui rendimentos, dividendos, valor de mercado, d\u00edvidas, entre outros (BASU, 1977; DECHOW et al, 2001).\nA An\u00e1lise T\u00e9cnica baseia-se na l\u00f3gica de que a hist\u00f3ria se repetir\u00e1 e que a correla\u00e7\u00e3o entre pre\u00e7o e volume revela o comportamento do mercado. A previs\u00e3o ocorre ao se explorar os hist\u00f3ricos anteriores, analisando padr\u00f5es e tend\u00eancias mostrados nos gr\u00e1ficos de pre\u00e7o e volume. A principal ferramenta da An\u00e1lise T\u00e9cnica s\u00e3o os indicadores t\u00e9cnicos, que s\u00e3o transforma\u00e7\u00f5es matem\u00e1ticas realizadas nos dados hist\u00f3ricos (PRING, 2016).\nAs an\u00e1lises Fundamental e T\u00e9cnica de previs\u00e3o de pre\u00e7os do mercado de a\u00e7\u00f5es tem uma import\u00e2ncia diferente quando examinada sob o ponto de vista do horizonte de previs\u00e3o. De acordo com Vanstone &amp; Finnie (2008), em sistemas de previs\u00e3o de longo termo, que possuem um horizonte temporal maior do que um ano,\na An\u00e1lise Fundamental \u00e9 preferida. Caso contr\u00e1rio, se o horizonte for inferior a um ano, a An\u00e1lise T\u00e9cnica \u00e9 preferida.\nDesde a introdu\u00e7\u00e3o do mercado financeiro, t\u00e9cnicas computacionais foram amplamente aplicadas para sua previs\u00e3o. Elas oferecem ferramentas \u00fateis na previs\u00e3o de ambientes ruidosos como o mercado de a\u00e7\u00f5es, capturando seu comportamento n\u00e3o-linear (ATSALAKIS &amp; VALAVANIS, 2008). Dentre as diversas t\u00e9cnicas destaca-se a utiliza\u00e7\u00e3o de regress\u00e3o linear e de sistemas inteligentes como as Redes Neurais, Sistemas Fuzzy, Algoritmos Gen\u00e9ticos, M\u00e1quinas de Vetores de Suporte, entre outros.\nAs Redes Neurais possuem uma \u00f3tima capacidade de prever as dire\u00e7\u00f5es do mercado, pois sua habilidade em descobrir rela\u00e7\u00f5es n\u00e3o-lineares entre as entradas e sa\u00eddas possibilita a modelagem de sistemas n\u00e3o-lineares din\u00e2micos como, por exemplo, o mercado de a\u00e7\u00f5es (QIU et al, 2016; LAWRENCE, 1997). Al\u00e9m disso, diferentemente dos m\u00e9todos estat\u00edsticos cl\u00e1ssicos, t\u00e9cnicas como as Redes Neurais possuem maior toler\u00e2ncia diante de dados incertos, incompletos e imprecisos, sendo, assim, uma ferramenta atrativa para previs\u00e3o de ambientes ruidosos como o mercado de a\u00e7\u00f5es (CHANG et al, 2008).\nNo entanto, embora haja muito estudo da aplica\u00e7\u00e3o de intelig\u00eancia computacional na previs\u00e3o do mercado financeiro, existe pouco estudo a respeito da performance de sistemas inteligentes na previs\u00e3o de suas tend\u00eancias semanais, por exemplo. Esses estudos, em sua maioria, ficam restritos \u00e0 previs\u00e3o do valor do dia seguinte dos ativos financeiros (NAEINI et al., 2010; ATSALAKIS &amp; VALAVANIS, 2009; KIM, 2003)\nO cen\u00e1rio escolhido para este trabalho foi a BM&amp;F Bovespa, pois \u00e9 um mercado pouco estudado quando comparado ao mercado internacional. Dos 100 artigos avaliados por Atsalakis &amp; Valavanis (2008), somente um se refere \u00e0 Bolsa de Valores de S\u00e3o Paulo (BOVESPA). Esse \u00e9 um n\u00famero muito pequeno, levando em conta que em 2008, ap\u00f3s a fus\u00e3o com a BM&amp;F, a nova BM&amp;F BOVESPA se tornou a terceira maior Bolsa de Valores do mundo de acordo com seu valor de mercado (CPC, 2018).\nEste trabalho tem por objetivo a aplica\u00e7\u00e3o de uma Rede Neural Feedforward na previs\u00e3o do \u00cdndice Bovespa. A vari\u00e1vel de previs\u00e3o \u00e9 um classificador que ir\u00e1 indicar se a cota\u00e7\u00e3o do \u00edndice ir\u00e1 subir ou descer em um horizonte de tempo de uma semana (5 dias \u00fateis). O sistema de previs\u00e3o desenvolvido possui como entradas:\n\u2022\tIndicadores T\u00e9cnicos: M\u00e9dia M\u00f3vel e Taxa de Varia\u00e7\u00e3o;\n\u2022\tCaracter\u00edsticas estat\u00edsticas: desvio padr\u00e3o;\n\u2022\tRela\u00e7\u00f5es entre os pre\u00e7os de abertura, fechamento, m\u00e1ximo e m\u00ednimo;\n\u2022\tS\u00e9ries ex\u00f3genas: pre\u00e7os das a\u00e7\u00f5es que comp\u00f5em o \u00cdndice Bovespa, pre\u00e7o do d\u00f3lar/real, pre\u00e7o do petr\u00f3leo e pre\u00e7o do ouro;\nO objetivo secund\u00e1rio deste trabalho \u00e9 fazer a sele\u00e7\u00e3o das caracter\u00edsticas mais significativas para a previs\u00e3o atrav\u00e9s do algoritmo Recursive Feature Elimination utilizando como modelo um Gradient Boosting de \u00e1rvores de decis\u00e3o.\n2 FUNDAMENTA\u00c7\u00c3O TE\u00d3RICA\n2.1\tO MERCADO DE A\u00c7\u00d5ES\nO papel fundamental da Economia \u00e9 a aloca\u00e7\u00e3o eficiente de capital. Para que isso seja obtido, o capital \u00e9 investido em setores onde h\u00e1 grandes expectativas de retorno, enquanto que setores com perspectivas ruins s\u00e3o evitados. Baseado nisso, os mercados financeiros s\u00e3o encarregados de assegurar uma distribui\u00e7\u00e3o adequada de investimentos (WURGLER, 2000). O termo Mercado Financeiro se refere a qualquer mercado onde ativos como a\u00e7\u00f5es, obriga\u00e7\u00f5es, moedas e derivativos s\u00e3o negociados. Os dois maiores mercados s\u00e3o o mercado de a\u00e7\u00f5es e o mercado monet\u00e1rio nos quais s\u00e3o negociados trilh\u00f5es de d\u00f3lares diariamente (LEVINSON, 2005).\nO mercado de a\u00e7\u00f5es \u00e9 um mercado p\u00fablico que re\u00fane investidores para a negocia\u00e7\u00e3o de a\u00e7\u00f5es e derivativos de empresas a um pre\u00e7o acordado. O mercado de a\u00e7\u00f5es estabelece pre\u00e7os de acordo com a oferta e a demanda. Assim, uma a\u00e7\u00e3o com alta demanda aumentar\u00e1 de pre\u00e7o, enquanto uma a\u00e7\u00e3o que est\u00e1 sendo fortemente vendida diminuir\u00e1 de pre\u00e7o. O mercado prim\u00e1rio lida com as novas emiss\u00f5es de t\u00edtulos diretamente da empresa. Um prospecto oficial \u00e9 publicado sob a lei da corpora\u00e7\u00e3o que cont\u00e9m todas as informa\u00e7\u00f5es sobre a empresa, e \u00e9 exigido pelos investidores para auxiliar na tomada de decis\u00f5es de investimento. Os t\u00edtulos existentes s\u00e3o comprados e vendidos no mercado secund\u00e1rio entre os comerciantes (CORPORATE FINANCE INSTITUTE, 2018).\nUma a\u00e7\u00e3o \u00e9 um documento emitido por uma empresa, que autoriza seu titular a ser um dos propriet\u00e1rios da empresa. Ao possuir uma a\u00e7\u00e3o, pode-se ganhar uma parte do lucro da empresa chamado de dividendo. Al\u00e9m disso, ao vender as a\u00e7\u00f5es, obt\u00e9m-se o ganho de capital. No entanto, existe o risco de uma perda de capital se o pre\u00e7o de venda da a\u00e7\u00e3o for inferior ao pre\u00e7o de compra (INVESTOPEDIA, 2018).\n2.1.1\tA Hip\u00f3tese do Mercado Eficiente (HME)\nUma grande parte dos estudos existentes associados \u00e0 previs\u00e3o do mercado financeiro suporta a Hip\u00f3tese do Mercado Eficiente (HME) segundo a qual o pre\u00e7o atual de uma a\u00e7\u00e3o reflete integralmente, a qualquer momento, as informa\u00e7\u00f5es dispon\u00edveis assimiladas pelos investidores. \u00c0 medida que novas informa\u00e7\u00f5es estiverem dispon\u00edveis, qualquer desequil\u00edbrio \u00e9 imediatamente detectado e contabilizado por uma mudan\u00e7a contr\u00e1ria em seu pre\u00e7o (FAMA, 1965). Sendo assim, de acordo com Hawawini &amp; Keim (1995) a previs\u00e3o dos pre\u00e7os do mercado de a\u00e7\u00f5es \u00e9 in\u00fatil e a correla\u00e7\u00e3o das s\u00e9ries cronol\u00f3gicas \u00e9 economicamente e estatisticamente insignificante porque os pre\u00e7os do mercado financeiro seguem uma tend\u00eancia aleat\u00f3ria.\nCom base no grau de efici\u00eancia do mercado financeiro, existem tr\u00eas vers\u00f5es da HME. A vers\u00e3o fraca da HME afirma que qualquer informa\u00e7\u00e3o resultante da an\u00e1lise do hist\u00f3rico passado da a\u00e7\u00e3o se reflete em seu pre\u00e7o. A vers\u00e3o semi-forte da HME afirma que toda nova informa\u00e7\u00e3o, uma vez que se torna p\u00fablica, \u00e9 rapidamente refletida nos pre\u00e7os das a\u00e7\u00f5es. No entanto, se tal informa\u00e7\u00e3o for, de alguma forma, conhecida previamente, ela pode ser usada para a obten\u00e7\u00e3o de lucros extras. A vers\u00e3o forte da HME afirma que toda informa\u00e7\u00e3o referente ao pre\u00e7o de uma a\u00e7\u00e3o, seja ela p\u00fablica ou privada, \u00e9 imediatamente contabilizada em seu pre\u00e7o (FAMA, 1991; HAUGEN, 1997).\nDe acordo com a forma fraca da HME, os pre\u00e7os das a\u00e7\u00f5es n\u00e3o podem ser previstos baseando-se apenas em seus valores passados devido ao seu comportamento aleat\u00f3rio. No entanto, apesar da popularidade da HME, h\u00e1 uma parcela significativa de investidores que n\u00e3o acreditam nela em qualquer uma de suas vers\u00f5es. Diversos estudos fornecem evid\u00eancias de que a An\u00e1lise T\u00e9cnica pode consistentemente produzir lucros e que o mercado de a\u00e7\u00f5es n\u00e3o \u00e9 completamente eficiente e nem os pre\u00e7os das a\u00e7\u00f5es seguem uma caminhada aleat\u00f3ria (BORODIN et al., 2004; LO &amp; MACKINLAY, 1988).\n2.1.2\tA An\u00e1lise T\u00e9cnica\nA An\u00e1lise T\u00e9cnica \u00e9 o estudo do comportamento do mercado, principalmente atrav\u00e9s do uso de gr\u00e1ficos, com o prop\u00f3sito de prever tend\u00eancias futuras dos pre\u00e7os (MURPHY, 1999). A An\u00e1lise T\u00e9cnica assume que o pre\u00e7o dos ativos financeiros se move de acordo com tend\u00eancias e padr\u00f5es que se mant\u00e9m em per\u00edodos at\u00e9 que alguma mudan\u00e7a nas condi\u00e7\u00f5es do mercado altere essa tend\u00eancia. Tipicamente s\u00e3o utilizadas informa\u00e7\u00f5es hist\u00f3ricas de pre\u00e7o e de volume para extrair indicadores t\u00e9cnicos, que tem o prop\u00f3sito de facilitar o entendimento das movimenta\u00e7\u00f5es do mercado. O principal objetivo da An\u00e1lise T\u00e9cnica \u00e9 prever o pre\u00e7o de um ativo em algum horizonte de tempo a fim de auxiliar os investidores do mercado a realizar opera\u00e7\u00f5es lucrativas (ROCKEFELLER, 2011).\nA An\u00e1lise T\u00e9cnica \u00e9 baseada em 3 premissas:\n\u2022\tOs movimentos do mercados j\u00e1 descontam tudo;\n\u2022\tOs pre\u00e7os se movem em tend\u00eancias;\n\u2022\tA hist\u00f3ria se repete.\nA primeira premissa \u00e9 considerada o fundamento da An\u00e1lise T\u00e9cnica. Ela afirma que os pre\u00e7os do mercado refletem n\u00e3o somente a informa\u00e7\u00e3o sobre fatores econ\u00f4micos, mas que tamb\u00e9m os fatores psicol\u00f3gicos, pol\u00edticos e geogr\u00e1ficos j\u00e1 est\u00e3o descontados e refletidos no pre\u00e7o atual do ativo. Dessa forma, o pre\u00e7o indiretamente fornece uma perspectiva dos aspectos fundamentais e, portanto, o estudo do pre\u00e7o \u00e9 suficiente para realizar previs\u00f5es (MURPHY, 1999).\nA segunda premissa sugere que os movimentos do ativo financeiro seguem tend\u00eancias. Isso significa que ap\u00f3s o estabelecimento de uma tend\u00eancia, \u00e9 mais prov\u00e1vel que o futuro movimento do pre\u00e7o seja na mesma dire\u00e7\u00e3o da tend\u00eancia do que contra ela, embora varia\u00e7\u00f5es de pre\u00e7o possam ocorrer. Portanto, a An\u00e1lise T\u00e9cnica busca por padr\u00f5es no pre\u00e7o que sinalizam uma continua\u00e7\u00e3o ou uma revers\u00e3o nas tend\u00eancias (MURPHY, 1999).\nA terceira premissa se baseia na suposi\u00e7\u00e3o de que a hist\u00f3ria tende a se repetir. Em outras palavras, padr\u00f5es de comportamento do mercado que ocorreram no passado v\u00e3o se repetir no futuro e, portanto, podem ser utilizados para prop\u00f3sitos de\nprevis\u00e3o. Na terminologia estat\u00edstica, as previs\u00f5es dependem da depend\u00eancia de sucessivas varia\u00e7\u00f5es do pre\u00e7o (LEVY, 1966).\nOs Indicadores T\u00e9nicos s\u00e3o uma ferramenta da An\u00e1lise T\u00e9cnica e s\u00e3o obtidos atrav\u00e9s de uma express\u00e3o matem\u00e1tica aplicada aos pre\u00e7os. Utilizados isoladamenteite eles n\u00e3o s\u00e3o capazes de prever o comportamento futuro de um ativo, no entanto, quando analisados em conjunto, podem fornecer informa\u00e7\u00f5es importantes sobre as tend\u00eancias do mercado (PRING, 2016).\nExistem centenas de Indicadores T\u00e9cnicos, sendo que muito investidores, inclusive, criam seus pr\u00f3prios indicadores. A seguir s\u00e3o listados os principais indicadores t\u00e9cnicos consolidados na literatura (PRING, 2016; WILDER, 1978):\n\u2022\tM\u00e9dia M\u00f3vel Simples (MMS): esse indicador \u00e9 calculado pela m\u00e9dia aritm\u00e9tica do pre\u00e7o dos \u00faltimos n dias. Como as s\u00e9ries temporais possuem muito ru\u00eddo, ele \u00e9 comumente usado para suavizar flutua\u00e7\u00f5es de curto prazo nos pre\u00e7os e ressaltar tend\u00eancias de mais longo prazo. De forma geral, se a MMS \u00e9 crescente, significa que a tend\u00eancia \u00e9 de alta, e se for decrescente que a tend\u00eancia \u00e9 de baixa. Uma das estrat\u00e9gias utilizadas \u00e9 de que quando o pre\u00e7o da a\u00e7\u00e3o cruza a M\u00e9dia M\u00f3vel por baixo, o pre\u00e7o tende a subir nos pr\u00f3ximos dias, j\u00e1 se o cruzamento for por cima, o pre\u00e7o tende a cair;\n\u2022\tTaxa de Varia\u00e7\u00e3o: esse indicador mede (ver Equa\u00e7\u00e3o (1)) a taxa com a qual o pre\u00e7o de uma a\u00e7\u00e3o variou em rela\u00e7\u00e3o a n per\u00edodos atr\u00e1s:\nPre\u00e7o \u2014 Pre\u00e7o n per\u00edodos atr\u00e1s\t(1)\nTaxa de Varia\u00e7\u00e3o =-------------------\u2014------------x 100\nPre\u00e7o n per\u00edodos atras\nQuando o indicador assume valores maiores que zero, o pre\u00e7o da a\u00e7\u00e3o que ele est\u00e1 medindo \u00e9 maior que seu pre\u00e7o n per\u00edodos atr\u00e1s. Al\u00e9m disso, se o indicador tamb\u00e9m estiver crescendo, a diferen\u00e7a entre o pre\u00e7o atual e seu valor n per\u00edodos atr\u00e1s tamb\u00e9m est\u00e1 crescendo. Se o indicador \u00e9 positivo mas decrescente, o pre\u00e7o continua acima do seu valor n per\u00edodos atr\u00e1s, por\u00e9m est\u00e1 decrescendo. A mesma l\u00f3gica \u00e9 usada quando o indicador assumir valores negativos.\n\u2022\tBandas de Bollinger: possibilitam avaliar a volatilidade e uma prov\u00e1vel evolu\u00e7\u00e3o dos pre\u00e7os. As bandas s\u00e3o constitu\u00eddas de 3 curvas, uma delas calculada pela m\u00e9dia m\u00f3vel dos dados em n per\u00edodos, e outras duas curvas situadas cada uma\na uma dist\u00e2ncia de duas vezes o desvio-padr\u00e3o, acima e abaixo, dos n per\u00edodos sobre os quais a m\u00e9dia-m\u00f3vel foi calculada. A largura da banda \u00e9 uma indica\u00e7\u00e3o direta da volatilidade do ativo considerado. Teoricamente, h\u00e1 mais de 95% de chance de que a evolu\u00e7\u00e3o do valor seja estabelecida dentro do quadro das bandas configuradas com uma dist\u00e2ncia de dois desvios-padr\u00e3o. Uma das interpreta\u00e7\u00f5es das Bandas de Bollinger \u00e9 de que quando as bandas se estreitam, existe uma grande chance de que ocorrer\u00e3o grandes mudan\u00e7as no pre\u00e7o da a\u00e7\u00e3o em um futuro pr\u00f3ximo. Uma das estrat\u00e9gias utilizadas \u00e9 de que quando o pre\u00e7o do ativo ultrapassa uma das bandas, a tend\u00eancia \u00e9 de que ir\u00e1 continuar naquela dire\u00e7\u00e3o. A Figura 1 ilustra o comportamento das bandas de Bollinger, onde o pre\u00e7o do ativo est\u00e1 em azul, a m\u00e9dia m\u00f3vel em verde e as bandas em vermelho.\nFigura 1 - Bandas de Bollinger\nFonte: autoria pr\u00f3pria\n\u2022 \u00cdndice de For\u00e7a Relativa (IFR): esse indicador de momento mede a for\u00e7a ou o enfraquecimento de uma tend\u00eancia baseado nos pre\u00e7os de fechamento de uma determinada a\u00e7\u00e3o. O seu valor varia entre 0 e 100 e \u00e9 calculado de acordo com a\nEqua\u00e7\u00e3o (2).\t100 (2) RSI = 100 -\t( ) 1 +RS\nonde RS \u00e9 a For\u00e7a Relativa (Relative Strenght), determinada pela Equa\u00e7\u00e3o (3).\nM\u00e9dia_ganhos (n)\t(3)\nM\u00e9dia_perdas (ri)\nonde ambas as m\u00e9dias s\u00e3o as obtidas nos \u00faltimos n per\u00edodos.\nO RSI compara os ganhos (tend\u00eancia de alta) e as perdas (tend\u00eancia de baixa) dos \u00faltimos n per\u00edodos. Wilder recomenda um n\u00famero de per\u00edodos, n, igual a 14. Uma interpreta\u00e7\u00e3o comum do RSI \u00e9 que ele sugere um estado de sobrevenda do ativo para valores menores que 30, e de sobrecompra para valores acima de 70 ou 80.\n2.2\tAS REDES NEURAIS ARTIFICIAIS\nUma rede neural artificial \u00e9 um modelo matem\u00e1tico inspirado no comportamento do c\u00e9rebro humano (MCCULLOCH; PITTS, 1943). A Rede Neural \u00e9 representada por um grafo orientado, onde cada n\u00f3 deste grafo representa um neur\u00f4nio e cada aresta representa uma sinapse, ou seja, uma conex\u00e3o entre dois neur\u00f4nios. A menor unidade de uma rede neural \u00e9 o pr\u00f3prio neur\u00f4nio, tamb\u00e9m conhecida por perceptron, apresentado na Figura 2.\nO neur\u00f4nio recebe sinais de entradas representados pelo vetor coluna x dado pela Equa\u00e7\u00e3o (4):\nX =\nrxn\n(4)\n^2\n^3\n-%n-\nA cada uma destas entradas, \u00e9 atribu\u00eddo um peso sin\u00e1ptico , onde j representa o sinal de entrada xj e i representa o neur\u00f4nio analisado. Desta forma, pode-se representar o vetor dos pesos sin\u00e1pticos pela Equa\u00e7\u00e3o (5):\n= [W\u00ed! Wi2 Wt3 ... W\u00edn]\n(5)\nEm seguida, a jun\u00e7\u00e3o aditiva \u00e9 aplicada aos sinais de entrada e seus respectivos pesos sin\u00e1pticos. Esta jun\u00e7\u00e3o aditiva \u00e9 uma combina\u00e7\u00e3o linear e pode ser dada pela Equa\u00e7\u00e3o (6):\n= \u2122\u00edi*i + W12X2 + - + winxn + bi= Wi^xi + bi\t(6)\nonde bi indica o termo bias aplicado ao neur\u00f4nio i.\nAs quantidades at s\u00e3o conhecidas como ativa\u00e7\u00f5es. Cada uma delas \u00e9 transformada utilizando uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o (p para gerar o sinal de sa\u00edda do neur\u00f4nio como mostrado pela Equa\u00e7\u00e3o (7):\nZi = v(a-i)\t(7)\nonde z, \u00e9 a sa\u00edda do neur\u00f4nio.\nAo processo desde a entrada dos sinais x at\u00e9 a gera\u00e7\u00e3o do sinal de sa\u00edda por meio da utiliza\u00e7\u00e3o da fun\u00e7\u00e3o de ativa\u00e7\u00e3o, \u00e9 dado o nome de feedforward propagation, ou propaga\u00e7\u00e3o em frente (HAYKIN, 2008).\nEm redes neurais artificiais, a fun\u00e7\u00e3o de ativa\u00e7\u00e3o y(.) de um neur\u00f4nio representa a taxa com a qual determinado neur\u00f4nio est\u00e1 sendo ativado ou utilizado (COPPIN, 2004). As fun\u00e7\u00f5es de ativa\u00e7\u00e3o t\u00eam um papel fundamental no treinamento de redes neurais e \u00e9 importante que elas possuam algumas caracter\u00edsticas a fim de melhorar o desempenho do treinamento das redes neurais. Segundo HAYKIN (2008), a fun\u00e7\u00e3o de ativa\u00e7\u00e3o deve ser diferenci\u00e1vel para que se possa utilizar um algoritmo que visa a minimizar o erro das tarefas realizadas pelas redes neurais. Al\u00e9m disto, se a fun\u00e7\u00e3o de ativa\u00e7\u00e3o for diferenci\u00e1vel mais de uma vez, \u00e9 poss\u00edvel desenvolver algoritmos que extraiam informa\u00e7\u00f5es de segunda ordem acerca do erro cometido\npelas redes neurais, o que possibilita um treinamento mais r\u00e1pido e eficiente. As fun\u00e7\u00f5es de ativa\u00e7\u00e3o mais comuns e suas derivadas est\u00e3o listadas na Tabela 1.\nTabela 1 - Fun\u00e7\u00f5es de ativa\u00e7\u00e3o e suas caracter\u00edsticas.\nFun\u00e7\u00e3o de ativa\u00e7\u00e3o\nEqua\u00e7\u00e3o\nDerivada\nIntervalo\nOrdem de\nde valores\ncontinuidade\nPasso bin\u00e1rio\nv(x)={?:\np(x) = 0, x 0\n[0,1]\nC\"1\nIdentidade\np(x) = x\n<p'(x') = 1\nC\u201d\nSigmoide\n1\n<P(x) =\t~\n1 + e x\n^'(x) = p(x) * (1 \u2014 p(x))\n[0,1]\nC\u201d\nSoftplus\np(x) = ln(1 + ex)\n<p'(x) = 1 \u2014&lt;p(x)2\n[0,+M\nC\u201d\nTangente hiperb\u00f3lica\np(x) = tanh(x)\n1\n^'(x)=\n[\u20141,1]\nC\u201d\nx &lt;0\nx > 0\n]-ot, +ot[\nFonte: elaborada pelo autor\nUm modelo de redes neurais de m\u00faltiplas camadas, ou multilayer perceptron (MLP), \u00e9 formado a partir da uni\u00e3o de v\u00e1rios neur\u00f4nios ligados entre si por meio de elos sin\u00e1pticos e bias. A Figura 3 mostra um exemplo de uma rede neural com uma camada de entrada, uma camada oculta e uma camada de sa\u00edda.\nFigura 3 - Representa\u00e7\u00e3o de uma rede neural MLP\nFonte: DOLHANSKY, 2018\nO fluxo de sinal percorre a rede neural da esquerda para a direita atrav\u00e9s do mecanismo de forward propagation. Deste modo, pode-se realizar a modelagem matem\u00e1tica da rede neural como uma cadeia de perceptrons conectados uns aos outros, onde o sinal de sa\u00edda de uma camada anterior representa o sinal de entrada da camada seguinte at\u00e9 que o sinal resultante saia da \u00faltima camada de neur\u00f4nios.\nSegundo Haykin (2001), os perceptrons de m\u00faltiplas camadas t\u00eam sido aplicados com sucesso para resolver problemas dif\u00edceis, atrav\u00e9s do seu treinamento de forma supervisionada com um algoritmo muito popular conhecido como algoritmo de retropropaga\u00e7\u00e3o de erro (error backpropagation).\nO desenvolvimento do algoritmo de retropropaga\u00e7\u00e3o representa um marco nas redes neurais, pois fornece um m\u00e9todo computacional eficiente para o treinamento de perceptrons de m\u00faltiplas camadas. Apesar de n\u00e3o podermos afirmar que o algoritmo de retropropaga\u00e7\u00e3o forne\u00e7a uma solu\u00e7\u00e3o \u00f3tima para todos os problemas resol\u00faveis, ele acabou com o pessimismo sobre a aprendizagem em m\u00e1quinas de m\u00faltiplas camadas (HAYKIN, 2001).\nO algoritmo de retropropaga\u00e7\u00e3o do erro visa a reajustar os pesos sin\u00e1pticos e bias das conex\u00f5es dentro da rede neural por meio de uma avalia\u00e7\u00e3o do erro obtido quando se apresenta um conjunto de sinais de entrada com sinais de sa\u00edda conhecidos. Desta forma, \u00e9 poss\u00edvel realizar um treinamento de uma rede neural num conjunto de dados dispon\u00edveis para que a mesma possa ser utilizada na previs\u00e3o de sinais de sa\u00edda desconhecidos.\nAssumindo um conjunto de N exemplos constitu\u00eddos de sinais de entrada x e seus respectivos sinais de sa\u00edda y, pode-se definir o erro de um sinal de sa\u00edda como na Equa\u00e7\u00e3o (8):\ne(n) = y(n) - y(n)\n(8)\nDefine-se a fun\u00e7\u00e3o custo quadr\u00e1tico m\u00e9dio para um neur\u00f4nio pela Equa\u00e7\u00e3o (9):\nN\n1\n(9)\nA fun\u00e7\u00e3o custo representa uma medida do desempenho do treinamento da rede neural. O objetivo do algoritmo de retropropaga\u00e7\u00e3o do erro \u00e9 encontrar os par\u00e2metros w e b que minimizam a fun\u00e7\u00e3o custo. Uma das condi\u00e7\u00f5es para que um par (w,b) indique um m\u00ednimo da fun\u00e7\u00e3o custo \u00e9 a de que o gradiente em torno deste ponto seja aproximadamente zero. O gradiente da fun\u00e7\u00e3o custo resulta na Equa\u00e7\u00e3o (10):\ndj(w, b)\nd(w,b)\n1 N\n1\nX p'(z) *%i\n(10)\nA corre\u00e7\u00e3o aplicada aos pesos sin\u00e1pticos e bias \u00e9 definida pela regra delta, dada pela Equa\u00e7\u00e3o (11):\nhwji\u00edn) = \u2014ax\ndj(w, b) d(w,b)\n(11)\nOu seja, a corre\u00e7\u00e3o \u00e9 feita no sentido de descr\u00e9scimo da fun\u00e7\u00e3o de custo a fim de se atingir o m\u00ednimo. O termo a \u00e9 o par\u00e2metro da taxa de aprendizagem do algoritmo de retropropaga\u00e7\u00e3o. Ele \u00e9 respons\u00e1vel por determinar a magnitude da mudan\u00e7a dos pesos sin\u00e1pticos no sentido de descida do gradiente. O uso da Equa\u00e7\u00e3o (10) em (11), resulta em:\nN\n&amp;\n1\n^wji(n) =\n\u2014y *\n* ty'(z) *X\u00ed\n(12)\nDefine-se o gradiente local por:\n5j(n) =\nN\ne(n) * y'(z)\n1\n(13)\nLogo:\nhWji(n) = y * 8j(n) * x.\n(14)\nDesta forma, o gradiente local aponta no sentido das modifica\u00e7\u00f5es necess\u00e1rias nos pesos sin\u00e1pticos.\nSegundo Faceli et al. (2011), um algoritmo de aprendizado de m\u00e1quina supervisionado \u00e9 uma fun\u00e7\u00e3o que, dado um conjunto de exemplos rotulados, constr\u00f3i um estimador. O r\u00f3tulo ou etiqueta toma valores num dom\u00ednio conhecido. Se esse dom\u00ednio for um conjunto de valores nominais, tem-se um problema de classifica\u00e7\u00e3o, tamb\u00e9m conhecido como aprendizado de conceitos, e o estimador gerado \u00e9 um classificador. Se o dom\u00ednio for um conjunto infinito e ordenado de valores, tem-se um problema de regress\u00e3o, que induz um regressor. A Figura 4 ilustra os dois tipos de problemas.\nFigura 4 - Tipos de tarefas\nClassifica\u00e7\u00e3o\tRegress\u00e3o\nFonte: MEDIUM, 2018\nEm outras palavras, \u00e9 poss\u00edvel realizar os dois tipos de tarefas por meio de redes neurais. Ao mostrar exemplos cujo resultado \u00e9 conhecido, a rede neural aprende a prever um valor ou uma classifica\u00e7\u00e3o quando encontra um novo conjunto de entradas.\n2.3\t\u00c1RVORES DE DECIS\u00c3O E O GRADIENT BOOSTING\n\u00c1rvores de Decis\u00e3o s\u00e3o modelos obtidos particionando-se recursivamente o espa\u00e7o de dados, tornando os novos subconjuntos de dados mais f\u00e1ceis de interpretar. Assim, dentro de cada parti\u00e7\u00e3o \u00e9 ajustado um modelo de previs\u00e3o simples\n(LOH, 2011). A Figura 5 ilustra as parti\u00e7\u00f5es (na esquerda) e a estrutura de uma \u00c1rvore de Decis\u00e3o (na direita) que possui tr\u00eas classes e duas vari\u00e1veis de entrada. A classe de previs\u00e3o \u00e9 dada em cada folha (n\u00f3 terminal) da \u00e1rvore.\nO Gradient Boosting \u00e9 uma t\u00e9cnica de Aprendizagem de M\u00e1quina utilizada para problemas de regress\u00e3o e classifica\u00e7\u00e3o desenvolvida por Friedman (2001). Os m\u00e9todos chamados de boosting se baseiam no princ\u00edpio da minimiza\u00e7\u00e3o de uma fun\u00e7\u00e3o custo atrav\u00e9s da agrega\u00e7\u00e3o de m\u00faltiplos modelos fracos (weak learners) para a constru\u00e7\u00e3o de um modelo final mais forte utilizando o m\u00e9todo do gradiente como procedimento.\nDe forma semelhante a outros m\u00e9todos de Aprendizagem de M\u00e1quina, dado um conjunto de treinamento {y,, de valores conhecidos (y,x), o objetivo \u00e9 encontrar uma fun\u00e7\u00e3o F*(x) que mapeie x em y, de forma que sobre a distribui\u00e7\u00e3o conjunta de todos os valores de (y,x), o valor esperado de uma fun\u00e7\u00e3o custo especificada \u00a5(y,F(x)) \u00e9 minimizada, conforme mostra a Equa\u00e7\u00e3o (15).\nF*(x) = arg minF(x)Ey,x [^(y,F(x))]\n(15)\nM\nO m\u00e9todo Boosting faz uma aproxima\u00e7\u00e3o da fun\u00e7\u00e3o F*(x) atrav\u00e9s de uma expans\u00e3o aditiva, conforme a Equa\u00e7\u00e3o (16).\n(16) ftmMx, &amp;m)\nm=0\nonde as fun\u00e7\u00f5es gen\u00e9ricas h(x; a), chamadas de \u201cmodelos fracos\u201d, normalmente s\u00e3o fun\u00e7\u00f5es simples de x com par\u00e2metros a = {a1, a2,...}, e M \u00e9 o de fun\u00e7\u00f5es utilizadas.\nOs coeficientes de expans\u00e3o {0m}o e os par\u00e2metros (a^}\u00f2: s\u00e3o determinados em etapas para os dados de treinamento. Inicia-se com uma estimativa inicial F0(x), e para m = 1,2, os par\u00e2metros s\u00e3o determinados de forma a minimizar a fun\u00e7\u00e3o custo da soma entre o modelo anterior e a nova fun\u00e7\u00e3o aditiva, conforme mostram as Equa\u00e7\u00f5es (17) e (18).\n(17) (Pm, ttm)\tttTQ min^Q\t^(y\u00bf, ^m-1(^i) + ph(x, &amp;))\ni-1\nFfn^X^\tFm-i(X) + pmh(x, ttm)\n(18)\nO Gradient Boosting utilizando \u00c1rvores de Decis\u00e3o especializa este m\u00e9todo onde a fun\u00e7\u00e3o gen\u00e9rica h(x;a) \u00e9 uma \u00e1rvore com L folhas (ver Equa\u00e7\u00e3o (19)). A \u00e1rvores particiona o espa\u00e7o de entradas em L regi\u00f5es disjuntas R1m, ..., RLm e prev\u00ea um valor constante em cada regi\u00e3o.\n(19) 1(X \u00a3 Rim)\n1-1\nonde ylm \u00e9 a m\u00e9dia de yim em cada regi\u00e3o Rlm. E yim \u00e9 chamada de pseudo-res\u00edduo, calculado pela Equa\u00e7\u00e3o (20).\ny.m = -\t(20)\nL\nh(x,{Rlm}1) = y\nOs par\u00e2metros dessas fun\u00e7\u00f5es gen\u00e9ricas s\u00e3o as vari\u00e1veis de divis\u00e3o dos n\u00f3s e os correspondentes pontos de divis\u00e3o que definem a \u00e1rvore, que por sua vez definem as correspondentes regi\u00f5es\tda parti\u00e7\u00e3o na m-\u00e9sima itera\u00e7\u00e3o.\nO Gradient Boosting \u00e9 tipicamente utilizado com \u00c1rvores de Decis\u00e3o, especialmente \u00e1rvores CART (Classification and Regression Trees). Um dos benef\u00edcios de se utilizar m\u00e9todos de ensemble de \u00c1rvores de Decis\u00e3o como o Gradient Boosting \u00e9 que eles automaticamente prov\u00eam uma estimativa da import\u00e2ncia das caracter\u00edsticas do modelo preditivo treinado. A import\u00e2ncia de uma caracter\u00edstica \u00e9 calculada pelo n\u00famero de vezes que sua utiliza\u00e7\u00e3o melhora a medida de performance da \u00e1vore. Assim, quanto mais uma caracter\u00edstica \u00e9 utilizada para tomar decis\u00f5es nas \u00e1rvores, maior ser\u00e1 sua relativa import\u00e2ncia. A import\u00e2ncia final de cada caracter\u00edstica \u00e9, ent\u00e3o, calculada pela m\u00e9dia de sua import\u00e2ncia em cada \u00e1rvore que comp\u00f5e o modelo. Essa import\u00e2ncia \u00e9 calculada explicitamente para cada caracter\u00edstica, permitindo que elas sejam classificadas e comparadas umas \u00e0s outras (CHEN &amp; GUESTRIN, 2016).\n2.4\tM\u00c9TRICAS DE DESEMPENHO\nPara quantificar o desempenho de uma rede neural na previs\u00e3o de s\u00e9ries temporais, costuma-se utilizar m\u00e9tricas que analisam as diferen\u00e7as entre a s\u00e9rie de valores previstos e a s\u00e9rie de valores reais. A seguir, s\u00e3o mostradas algumas das m\u00e9tricas mais utilizadas para estes c\u00e1lculos nos estudos pesquisados.\n\u2022 Erro Percentual Absoluto M\u00e9dio: o Erro M\u00e9dio Percentual Absoluto (ou MAPE - Mean Absolute Percentage Error) obt\u00e9m as diferen\u00e7as percentuais entre todos os valores reais e previstos obtidos e faz uma m\u00e9dia simples destes valores. Como todos os elementos da s\u00e9rie temporal tem igual peso no resultado final, resultados isolados muito diferentes dos demais n\u00e3o fazem tanta diferen\u00e7a. Essa m\u00e9trica \u00e9 \u00fatil para se ter uma vis\u00e3o geral do erro m\u00e9dio gerado pelo algoritmo de previs\u00e3o escolhido. O MAPE \u00e9 definido de acordo com a Equa\u00e7\u00e3o (21), onde N \u00e9 o n\u00famero de dias da s\u00e9rie temporal sendo analisada, Preai,i \u00e9 o valor real da s\u00e9rie no dia i e Pprevisto.\u00ed \u00e9 o valor previsto para a s\u00e9rie, tamb\u00e9m no dia i.\nMAPE =\nN\nl = 1\n(\\Preal,i\tPprevisto,i |\\\nPprevisto,i\t/\nP\n1 previsto,i\nx 100\n(21)\n\u2022 Raiz Quadrada do Erro Quadr\u00e1tico M\u00e9dio: essa m\u00e9trica, tamb\u00e9m chamada de RMS ou RMSE (Root Mean Squared Error), \u00e9 semelhante ao MAPE no sentido de que obt\u00eam o erro de todos os valores calculados. A diferen\u00e7a est\u00e1 no fato do erro calculado n\u00e3o ser um percentual, mas sim um valor num\u00e9rico que indica o tamanho do erro m\u00e9dio obtido. O quanto mais pr\u00f3ximo de zero for o erro, melhor s\u00e3o os resultados obtidos. O RMS \u00e9 calculado a partir da Equa\u00e7\u00e3o (22), onde N \u00e9 o n\u00famero de dias da s\u00e9rie temporal sendo analisada, Pprevisto,i \u00e9 o valor previsto para a s\u00e9rie no dia i e Preai,i \u00e9 o valor real da s\u00e9rie tamb\u00e9m no dia i.\nRMS =\nN\n1 V\n/ (Preal.i\n\u2014 P \u25a0 V\n1 previsto,ij\ni=1\n(22)\nN\n\u2022 Erro M\u00e9dio Quadr\u00e1tico: o erro m\u00e9dio quadr\u00e1tico, ou MSE (Mean Squared Error) \u00e9 a m\u00e9trica mais utilizada para calcular o desempenho de modelos de previs\u00e3o. \u00c9 calculado a partir da soma da vari\u00e2ncia e dos quadrados das diferen\u00e7as obtidas entre os valores reais e previstos, e \u00e9 dado pela Equa\u00e7\u00e3o (23), onde N \u00e9 o n\u00famero de dias da s\u00e9rie temporal sendo analisada, Pprevisto,i \u00e9 o valor previsto para a s\u00e9rie no dia i e Preai.\u00ed \u00e9 o valor real da s\u00e9rie tamb\u00e9m no dia i.\nMSE =\nN\nl = 1\n\u2014 P\t.)2\n1 previsto,ij\n(23)\n2.5\tTRABALHOS RELACIONADOS\nExiste uma vasta quantidade de trabalhos na literatura que estuda o problema da previs\u00e3o de tend\u00eancias do mercado financeiro, e um grande n\u00famero entre esses utiliza Redes Neurais Artificiais como modelo de previs\u00e3o. Entre os estudos sobre o assunto, Atsalakis &amp; Valavanis (2008) analisam 100 trabalhos relevantes que estudam\na utiliza\u00e7\u00e3o de t\u00e9cnicas computacionais para abordar o problema. Essas t\u00e9cnicas s\u00e3o classificadas de acordo com:\n\u2022\tO mercado do qual os dados s\u00e3o obtidos;\n\u2022\tAs vari\u00e1veis de entrada;\n\u2022\tA metodologia e os par\u00e2metros utilizados (pr\u00e9-processamento, tamanho do conjunto de dados, tipo da rede e m\u00e9todo de treinamento);\n\u2022\tOs modelos utilizados como benchmark;\n\u2022\tAs m\u00e9tricas de performance utilizadas para avaliar o m\u00e9todo proposto.\nAl\u00e9m disso, quanto \u00e0 vari\u00e1vel de previs\u00e3o, esses problemas podem ser classificados em dois grandes grupos: aqueles que tem por objetivo prever os n\u00edveis, ou seja, os valores que o \u00edndice atingir\u00e1 no futuro ou o retorno previsto em um determinado horizonte de tempo, os quais se enquadram em problemas de regress\u00e3o. O outro grupo tem por objetivo prever a dire\u00e7\u00e3o da varia\u00e7\u00e3o dos pre\u00e7os, ou seja, se os valores futuros ser\u00e3o maiores ou menores do que o valor atual, os quais se enquadram nas t\u00e9cnicas de classifica\u00e7\u00e3o.\nNaeini et al. (2010) propuseram dois modelos de previs\u00e3o do pre\u00e7os de a\u00e7\u00f5es cotadas na Bolsa de Valores de Teer\u00e3. O primeiro deles \u00e9 uma Rede Neural Feedforward e o segundo uma Rede Recorrente de Elman. O objetivo deste estudo foi utilizar essas redes para fazer previs\u00f5es baseadas nos dados hist\u00f3ricos das a\u00e7\u00f5es. Foram utilizadas como entradas das redes os pre\u00e7os m\u00e1ximo, m\u00ednimo e a m\u00e9dia entre o m\u00e1ximo e o m\u00ednimo dos \u00faltimos d dias, com d variando de 1 a 10. Foi avaliada a performance das redes na previs\u00e3o da dire\u00e7\u00e3o do pre\u00e7o do dia seguinte (problema de classifica\u00e7\u00e3o) e do valor do pre\u00e7o do dia seguinte (problema de regress\u00e3o). Os autores conclu\u00edram que para a previs\u00e3o da dire\u00e7\u00e3o do dia seguinte, uma simples regress\u00e3o linear obteve a melhor taxa de acertos. Para a previs\u00e3o do valor do dia seguinte, o m\u00e9todo que obteve a melhor performance (medida atrav\u00e9s do Erro Quadr\u00e1tico M\u00e9dio) foi a Rede Neural Feedforward.\nQiu et al. (2016) propuseram a utiliza\u00e7\u00e3o de uma Rede Neural treinada com o algoritmo Backpropagation na previs\u00e3o do \u00edndice da bolsa de valores japonesa, Nikkei 225. Foram pr\u00e9-selecionadas 71 vari\u00e1veis que incluem indicadores financeiros e dados macroecon\u00f4micos como, por exemplo, valor da taxa de juros, taxa de c\u00e2mbio,\n\u00edndice de pre\u00e7os ao consumidor, \u00edndice de produ\u00e7\u00e3o industrial e taxa de dep\u00f3sito. Atrav\u00e9s da implementa\u00e7\u00e3o de superf\u00edcies Fuzzy, foram selecionadas 18 vari\u00e1veis das 71 que demonstraram ter maior import\u00e2ncia, atrav\u00e9s da medida da correla\u00e7\u00e3o entre as vari\u00e1veis de entrada e a vari\u00e1vel de sa\u00edda. O conjunto de dados utilizados cobre o per\u00edodo de Novembro de 1993 at\u00e9 Julho de 2013, sendo que 70% dos dados foram utilizados para o treinamento e 30% para os testes. A arquitetura da rede possui 3 camadas, sendo que a camada de entrada possui 18 n\u00f3s e a camada de sa\u00edda possui um n\u00f3 com o valor da previs\u00e3o. Foi constatado que o menor Erro M\u00e9dio Quadr\u00e1tico foi m\u00ednimo quando a rede possu\u00eda entre 10 e 30 neur\u00f4nios na camada oculta. A fim de contornar o problema da converg\u00eancia local das Redes Neurais, t\u00e9cnicas de procura de converg\u00eancia global foram utilizadas com o aux\u00edlio de Algoritmos Gen\u00e9ticos e Arrefecimento Simulado. Foi demonstrado que o algoritmo h\u00edbrido proposto obteve uma melhor performace comparado ao Backpropagation comum. O erro quadr\u00e1tico m\u00e9dio do algoritmo h\u00edbrido foi de 0,0043 enquanto que do algoritmo Backpropagation comum foi de 0,1077.\nKim (2003) prop\u00f5e a utiliza\u00e7\u00e3o de M\u00e1quinas de Vetores de Suporte na previs\u00e3o da dire\u00e7\u00e3o do dia seguinte do \u00cdndice composto do KOSPI (\u00cdndice de bolsa de valores sul-coreano). O modelo possui como entradas 12 indicadores t\u00e9cnicos, e a SVM \u00e9 treinada com diferentes par\u00e2metros C e S2, onde C \u00e9 o termo de regulariza\u00e7\u00e3o e S2 \u00e9 o par\u00e2metro da fun\u00e7\u00e3o de Kernel utilizada. O modelo SVM desenvolvido obteve uma taxa de acertos de 57,83% em sua melhor performance, enquanto uma Rede Neural Feedforward com Backpropagation obteve uma taxa de acertos de 54,73% na mesma s\u00e9rie hist\u00f3rica.\nKara et al. (2010) prop\u00f5em a utiliza\u00e7\u00e3o de Redes Neurais Feedforward e de M\u00e1quinas de Vetores de Suporte para a previs\u00e3o dos movimentos di\u00e1rios do \u00cdndice da Bolsa de Valores de Istambul (Istanbul Stock Exchange (ISE) National 100 Index). Como entradas dos modelos foram utilizados 10 indicadores t\u00e9cnicos. O conjunto de dados \u00e9 composto das cota\u00e7\u00f5es do \u00edndice no per\u00edodo de 2 de janeiro de 1997 a 31 de dezembro de 2007. Do conjunto total de dados, 20% foram utilizados para a determina\u00e7\u00e3o de par\u00e2metros dos modelos. Em seguida, o conjunto total de dados foi dividido em dois conjuntos de mesmo tamanho para treinamento e para valida\u00e7\u00e3o. Essa divis\u00e3o foi realizada de forma que cada conjunto possu\u00edsse a mesma propor\u00e7\u00e3o de classes do conjunto original. Os modelos foram implementados utilizando-se\ndiferentes configura\u00e7\u00f5es de par\u00e2metros, como n\u00famero de neur\u00f4nios e taxa de aprendizagem, e a taxa de acertos m\u00e9dia de valida\u00e7\u00e3o para a Rede Neural foi de 75,74% e para o modelo SVM foi de 71,52%.\nPesquisas recentes tendem a utilizar t\u00e9cnicas h\u00edbridas de Aprendizagem de M\u00e1quina. A proposta de Hiemstra (1995) foi de combinar Redes Neurais com L\u00f3gica Fuzzy, pois assim seria poss\u00edvel captar as complexidades do mapeamento funcional, sem ser necess\u00e1ria a especifica\u00e7\u00e3o da fun\u00e7\u00e3o a ser aproximada. Kim e Shin (2007) propuseram um modelo h\u00edbrido utilizando Algoritmos Gen\u00e9ticos com Redes Neurais para a otimiza\u00e7\u00e3o do tempo de delay e fatores da arquitetura da rede, utilizando Algoritmos Gen\u00e9ticos para melhorar a efic\u00e1cia do modelo na Rede Neural.\nAtsalakis &amp; Psomatakis (2014) prop\u00f5em a utiliza\u00e7\u00e3o de um modelo h\u00edbrido utiliando Redes Neurais com Algoritmos Gen\u00e9ticos na previs\u00e3o das movimenta\u00e7\u00f5es di\u00e1rias das 5 principais a\u00e7\u00f5es cotadas na Bolsa de Valores de Atenas (Athens Stock Exchange). Foram utilizadas como entradas indicadores t\u00e9cnicos como o \u00cdndice de For\u00e7a Relativa, a Taxa de Varia\u00e7\u00e3o e a M\u00e9dia M\u00f3vel. Foi obtida com esse modelo uma taxa de acertos m\u00e9dia de 57,5% na previs\u00e3o da cota\u00e7\u00e3o das a\u00e7\u00f5es.\n3\tMETODOLOGIA\n3.1\tBASE DE DADOS E SUA DIVIS\u00c3O\nA base de dados utilizada para este estudo \u00e9 composta pelos pre\u00e7os hist\u00f3ricos di\u00e1rios do \u00cdndice BOVESPA, das a\u00e7\u00f5es que o comp\u00f5em, do pre\u00e7o do d\u00f3lar (em reais), assim como dos pre\u00e7os do petr\u00f3leo e do ouro obtidos da base de dados do YAHOO FINANCE (2018). Cada dia possui as informa\u00e7\u00f5es das cota\u00e7\u00f5es em seu fechamento e abertura, seus pontos m\u00e1ximo e m\u00ednimo e o volume de transa\u00e7\u00f5es realizadas. O per\u00edodo utilizado foi de 27 de setembro de 2011 a 15 de mar\u00e7o de 2018, resultando em um total de 1597 dias.\nOs dados foram divididos inicialmente em 2 conjuntos, sendo os primeiros 70%, de 27 de setembro de 2011 a 12 de fevereiro de 2016, utilizados para o treinamento e valida\u00e7\u00e3o da rede, e os \u00faltimos 30%, de 13 de fevereiro de 2016 a 15 de mar\u00e7o de 2018, para teste. Essa divis\u00e3o foi feita em ordem cronol\u00f3gica, pois \u00e9 uma das metodologias mais utilizadas pela literatura para a previs\u00e3o do mercado financeiro e que possui maior sentido pr\u00e1tico (TAY &amp; CAO, 2001; HUANG et al., 2004; PAI &amp; LIN, 2004).\n3.2\tVARI\u00c1VEL DE PREVIS\u00c3O\nA vari\u00e1vel de previs\u00e3o est\u00e1 relacionada com a taxa de varia\u00e7\u00e3o dos pr\u00f3ximos 5 dias do \u00cdndice Bovespa, que significa o quanto se obteria de retorno se o \u00edndice fosse comprado no dia em quest\u00e3o e vendido 5 dias depois. A Taxa de Retorno \u00e9 calculada de acordo com a Equa\u00e7\u00e3o (24).\nPre\u00e7Ori+c Pre\u00e7od\t(24)\nTaxa de Retorno ('%') =--------------x 100\nPre\u00e7od\nonde Pre\u00e7od \u00e9 o pre\u00e7o atual e Pre\u00e7od+5 \u00e9 o pre\u00e7o 5 dias adiante.\nO pre\u00e7o do \u00cdndice Bovespa e a Taxa de Retorno de 5 dias no per\u00edodo de 27 de setembro de 2011 a 15 de mar\u00e7o de 2018 s\u00e3o apresentados na Figura 6.\nA fim de se obter um melhor entendimento da distribui\u00e7\u00e3o da Taxa de Retorno, foi criado um histograma dessa vari\u00e1vel. Ele \u00e9 apresentado na Figura 7.\nFigura 7 - Histograma da taxa de retorno\nObserva-se a que a distribui\u00e7\u00e3o dos retornos \u00e9 aproximadamente normal, com uma m\u00e9dia de 0,16 e desvio-padr\u00e3o de 3,12.\nEste problema de previs\u00e3o foi tratado como um problema de classifica\u00e7\u00e3o bin\u00e1ria. Dessa forma, o classificador assumir\u00e1 valores 0 e 1, de acordo com as seguintes condi\u00e7\u00f5es:\n0 se r &lt;0\ny {1 se r > 0\nonde y \u00e9 o classificador e r \u00e9 a Taxa de Retorno.\nA distribui\u00e7\u00e3o de classes dentro de cada um dos conjuntos de dados \u00e9 apresentada na Tabela 2.\nTabela 2 - Divis\u00e3o de classes.\t\t\t\nClasse\tTreinamento / Valida\u00e7\u00e3o\tTeste\tTotal\n0\t653 (58%)\t229 (48%)\t882 (55%)\n1\t464 (42%)\t251 (52%)\t715 (45%)\n3.3\tCARACTER\u00cdSTICAS DE PREVIS\u00c3O\nAs caracter\u00edsticas de previs\u00e3o foram calculadas sobre a pr\u00f3pria s\u00e9rie a ser prevista, assim como sobre s\u00e9ries ex\u00f3genas que possuem um poss\u00edvel car\u00e1ter preditivo. As caracter\u00edsticas de previs\u00e3o consistem em:\n\u2022\tIndicadores T\u00e9cnicos: M\u00e9dia M\u00f3vel, Taxa de Varia\u00e7\u00e3o, rela\u00e7\u00e3o entre m\u00e9dias m\u00f3veis de volume;\n\u2022\tVolatilidade (desvio padr\u00e3o);\n\u2022\tRela\u00e7\u00f5es entre os pre\u00e7os de abertura, fechamento, m\u00e1ximo e m\u00ednimo;\n\u2022\tS\u00e9ries ex\u00f3genas: cota\u00e7\u00f5es das a\u00e7\u00f5es que comp\u00f5em o \u00cdndice Bovespa, o pre\u00e7o do d\u00f3lar/real, o pre\u00e7o do petr\u00f3leo e pre\u00e7o do ouro.\nO processo de c\u00e1lculo das caracter\u00edsticas pode ser observado na Figura 8. As caracter\u00edsticas s\u00e3o calculadas em uma sub-s\u00e9rie (em lil\u00e1s) que antecede o momento a ser realizada a previs\u00e3o (em verde). \u00c9 importante observar que a escolha do n\u00famero de per\u00edodos para o c\u00e1lculo desses indicadores influencia diretamente nas caracter\u00edsticas extra\u00eddas do mercado. Por exemplo, a M\u00e9dia M\u00f3vel de 50 dias vai capturar tend\u00eancias de mais longo termo que a M\u00e9dia M\u00f3vel de 10 dias. Por isso, cada\num dos indicadores foi calculado em 5 diferentes janelas de tempo, de 5, 10, 20, 50 e\n100 per\u00edodos.\nFigura 8 - C\u00e1lculo das caracter\u00edsticas\nFonte: TSFRESH, 2018\n3.3.1\tC\u00e1lculo das caracter\u00edsticas\nNo campo das finan\u00e7as, o fato da cota\u00e7\u00e3o de um ativo estar a R$20 ou ter um volume de 10000 negocia\u00e7\u00f5es, por exemplo, \u00e9 de pouca import\u00e2ncia quando se trata da previs\u00e3o dos movimentos futuros dos pre\u00e7os. Ao inv\u00e9s dos valores brutos, \u00e9 mais relevante que as entradas da Rede Neural forne\u00e7am valores relativos \u00e0 outras vari\u00e1veis. Por exemplo, em vez de informar o pre\u00e7o de uma cota\u00e7\u00e3o, ela deve indicar a taxa de varia\u00e7\u00e3o do pre\u00e7o em rela\u00e7\u00e3o a valores anteriores, e em vez de informar o volume de negocia\u00e7\u00f5es, a caracter\u00edstica deve indicar o quanto esse volume est\u00e1 abaixo ou acima da m\u00e9dia. Isso ir\u00e1 prevenir a Rede Neural de focar se um ativo financeiro possui um valor alto ou baixo e permitir\u00e1 uma maior generaliza\u00e7\u00e3o das caracter\u00edsticas e de suas rela\u00e7\u00f5es (VANSTONE &amp; FINNIE, 2008).\nCom exce\u00e7\u00e3o das caracter\u00edsticas que s\u00e3o calculadas a partir dos pre\u00e7os de abertura, m\u00e1ximo e m\u00ednimo, optou-se por utilizar o valor de fechamento como refer\u00eancia para os c\u00e1lculos. Tal decis\u00e3o se justifica pelo fato de que esse valor \u00e9 utilizado para estimar a varia\u00e7\u00e3o percentual em rela\u00e7\u00e3o ao dia anterior para os papeis\nnegociados em bolsa e, conforme apresentado por DOW C.H. (1902) seria a representa\u00e7\u00e3o do valor a ser pago aceito pelos investidores que possuem o melhor n\u00edvel informacional para formarem posi\u00e7\u00f5es para o dia seguinte. As caracter\u00edsticas foram calculadas como segue:\n\u2022 M\u00e9dia M\u00f3vel Simples: \u00e9 uma vers\u00e3o suavizada do pre\u00e7o do ativo financeiro. Para ser utilizada como entrada da Rede Neural, a M\u00e9dia M\u00f3vel foi calculada de acordo com a Equa\u00e7\u00e3o (25).\nM\u00e9dia M\u00f3vel (pr\u00e9 \u2014 processada)\nPre\u00e7o\nM\u00e9dia M\u00f3vel\n(25)\nDessa forma, a vari\u00e1vel assumir\u00e1 valores positivos se o pre\u00e7o for maior que sua M\u00e9dia M\u00f3vel, negativos se o pre\u00e7o for menor que a M\u00e9dia M\u00f3vel e iguais a zero no cruzamento entre as curvas. Assim \u00e9 poss\u00edvel resumir o comportamento da M\u00e9dia M\u00f3vel em rela\u00e7\u00e3o ao pre\u00e7o original em uma \u00fanica vari\u00e1vel de entrada.\nNa Figura 9 \u00e9 apresentado o aspecto da M\u00e9dia M\u00f3vel de 20 dias juntamente com as cota\u00e7\u00f5es do \u00cdndice Bovespa.\nFigura 9 - M\u00e9dia M\u00f3vel Simples (20 dias) do \u00cdndice Bovespa\n90000\nNa Figura 10 \u00e9 apresentado o aspecto da M\u00e9dia M\u00f3vel de 20 dias ap\u00f3s aplicado o pr\u00e9-processamento da Equa\u00e7\u00e3o (25).\nFigura 10 - M\u00e9dia M\u00f3vel Simples (20 dias) do \u00cdndice Bovespa\n\u2022 Taxa de Varia\u00e7\u00e3o: foi calculada de acordo com a Equa\u00e7\u00e3o (1). N\u00e3o foi necess\u00e1rio aplicar c\u00e1lculos suplementares \u00e0 Taxa de Varia\u00e7\u00e3o nesta etapa uma vez que ela j\u00e1 possui valores relativos a per\u00edodos anteriores. A cota\u00e7\u00e3o do \u00cdndice Bovespa e o aspecto da Taxa de Varia\u00e7\u00e3o calculada em um per\u00edodo de 10 dias s\u00e3o apresentados na Figura 11, respectivamente.\n\u2022 Volume de transa\u00e7\u00f5es: o volume de transa\u00e7\u00f5es realizadas \u00e9 um fator importante de s\u00e9ries temporais financeiras, pois assim como o pre\u00e7o, padr\u00f5es de volume tamb\u00e9m existem nessas s\u00e9ries e, portanto podem ser utilizados na previs\u00e3o\nde pre\u00e7os. No entanto, assim como os pre\u00e7os, os volumes brutos possuem pouco significado comparados aos volumes relativos, portanto um bom indicador dos n\u00edveis de volume \u00e9 a raz\u00e3o entre m\u00e9dias m\u00f3veis, como mostra a Equa\u00e7\u00e3o (26):\nVolume (pr\u00e9 \u2014 processado)\nM\u00e9dia M\u00f3vel Volume 1\nM\u00e9dia M\u00f3vel Volume 2\n(26)\nonde a M\u00e9dia M\u00f3vel 1 \u00e9 calculada em um per\u00edodo menor que a M\u00e9dia M\u00f3vel 2.\nNa Figura 12 s\u00e3o apresentados o volume de transa\u00e7\u00f5es do \u00cdndice Bovespa e a raz\u00e3o entre as m\u00e9dias m\u00f3veis de 10 e 50 per\u00edodos.\nFigura 12 - Volume e raz\u00e3o entre m\u00e9dias m\u00f3veis\n\u2022 Desvio padr\u00e3o m\u00f3vel: o desvio padr\u00e3o \u00e9 uma caracter\u00edstica importante pois ele estima a volatilidade do mercado. A fim de se desprezar os n\u00edveis de pre\u00e7o, seus valores foram divididos pela m\u00e9dia m\u00f3vel, resultando em um valor de desvio percentual em rela\u00e7\u00e3o \u00e0 m\u00e9dia. Na Figura 13 s\u00e3o apresentados o \u00cdndice Bovespa e o comportamento do desvio padr\u00e3o para uma janela de 20 dias, respectivamente.\n\u2022 Pre\u00e7os de abertura, fechamento, m\u00e1ximo e m\u00ednimo: o c\u00e1lculo dos indicadores at\u00e9 aqui foram realizados com os pre\u00e7os de fechamento, no entanto os pre\u00e7os de abertura, de m\u00e1ximo e de m\u00ednimo podem conter informa\u00e7\u00f5es importantes para a descoberta de padr\u00f5es. Uma das caracter\u00edsticas calculadas foi a volatilidade di\u00e1ria, calculada pela taxa percentual de varia\u00e7\u00e3o entre o m\u00e1ximo e o m\u00ednimo do per\u00edodo, de acordo com a Equa\u00e7\u00e3o (27).\nm\u00e1ximo\tPre\u00e7om\u00e1ximo(n) - Pre\u00e7omMmo(ri)\t(27)\nPre\u00e7o (\u2014 -----) =-----------------------\u2014-----------x 100\nmxrnmo\tPre\u00e7om\u00ednimo(ri)\nonde os pre\u00e7os m\u00e1ximo e m\u00ednimo s\u00e3o calculados no mesmo per\u00edodo n.\nPartindo-se da hip\u00f3tese de que um comportamento suavizado das caracter\u00edsticas, assim como foi feito para os outros indicadores calculados at\u00e9 aqui, \u00e9 mais significativo para previs\u00f5es de m\u00faltiplos per\u00edodos adiante, foi calculada a m\u00e9dia m\u00f3vel da volatilidade di\u00e1ria nas mesmas janelas de tempo utilizadas para os outros indicadores. O comportamento da m\u00e9dia m\u00f3vel de 10 dias da volatilidade di\u00e1ria \u00e9 apresentado na Figura 14.\nOutra caracter\u00edstica extra\u00edda foi a varia\u00e7\u00e3o nos pre\u00e7os entre a abertura e o fechamento do per\u00edodo. Ela \u00e9 calculada conforme a Equa\u00e7\u00e3o (28).\nfechamento\tPre\u00e7Ofechamento(.n)\tPre\u00e7OaberturaC^.')\t(28)\nPre\u00e7o(\u2014 -----------) =---------------------------\u2014-------------x 100\nabertura\tPre\u00e7oabertura(n)\nonde os pre\u00e7os de fechamento e de abertura s\u00e3o calculados no mesmo per\u00edodo n.\nDiferentemente da volatilidade di\u00e1ria, essa caracter\u00edstica pode apresentar valores positivos ou negativos. Dessa forma, o c\u00e1lculo da m\u00e9dia m\u00f3vel foi realizado para os valores reais e tamb\u00e9m para os valores absolutos. A m\u00e9dia m\u00f3vel dos valores reais ir\u00e1 indicar o comportamento do equ\u00edlibrio entre as altas e as quedas, enquanto que a m\u00e9dia m\u00f3vel dos valores absolutos ir\u00e1 indicar a magnitude desses movimentos. A m\u00e9dia m\u00f3vel de 10 dias da rela\u00e7\u00e3o entre os pre\u00e7os de fechamento e de abertura \u00e9 apresentado na Figura 15 para seus valores reais e absolutos, respectivamente.\nOutra caracter\u00edstica extra\u00edda \u00e9 a rela\u00e7\u00e3o entre o pre\u00e7o de abertura de um per\u00edodo e o pre\u00e7o de fechamento do per\u00edodo anterior. A disparidade entre esses valores reflete as expectativas e o interesse dos investidores causados por an\u00fancios das corpora\u00e7\u00f5es, desastres naturais, entre outras not\u00edcias (INVESTOPEDIA, 2018). Seu c\u00e1lculo \u00e9 feito conforme a Equa\u00e7\u00e3o (29).\nabertura(n)\tPre\u00e7oabertura(n) - Pre\u00e7of\nechamento\nPre\u00e7ot\t) =\tx 100\nfechamento(n - 1)\tPre\u00e7ofechamento(n -\nonde os pre\u00e7os com a nota\u00e7\u00e3o (n) s\u00e3o calculados no per\u00edodo atual e os pre\u00e7os com a nota\u00e7\u00e3o (n-1) s\u00e3o calculados no per\u00edodo anterior.\nO comportamento da m\u00e9dia m\u00f3vel de 10 dias da rela\u00e7\u00e3o entre os pre\u00e7os de\nabertura e de fechamento do per\u00edodo anterior \u00e9 apresentado na Figura 16 para seus\nvalores reais e absolutos, respectivamente.\nFigura 16 - Rela\u00e7\u00e3o entre os pre\u00e7os de abertura e de fechamento do per\u00edodo anterior (10 dias)\n\u2022 S\u00e9ries ex\u00f3genas: Al\u00e9m das caracter\u00edsticas extra\u00eddas da pr\u00f3pria s\u00e9rie a ser prevista foram utilizadas as cota\u00e7\u00f5es de 52 dos 67 pap\u00e9is que compunham o \u00cdndice Bovespa no \u00faltimo dia da base de dados (ANEXO). Algumas a\u00e7\u00f5es n\u00e3o foram utilizadas por falta de disponibilidade na internet ou por serem a\u00e7\u00f5es que existem h\u00e1 pouco tempo e, portanto, possuem somente dados hist\u00f3ricos recentes.\nTamb\u00e9m foram inclu\u00eddas as cota\u00e7\u00f5es do d\u00f3lar/real, do petr\u00f3leo e do ouro. Diversos estudos sugerem que essas vari\u00e1veis tem influ\u00eancia sobre o mercado internacional embora poucos estudos tenham sido feitos para o mercado brasileiro. (LEE &amp; ZENG, 2011; RAHMAN &amp; MUSTAFA, 2011; BAHMANI-OSKOOEE &amp; SOHRABIAN, 1992). Dessas s\u00e9ries foram utilizadas como caracter\u00edsticas as taxas de varia\u00e7\u00e3o dos pre\u00e7os, calculados pela Equa\u00e7\u00e3o (1). O comportamento da taxa de varia\u00e7\u00e3o de 10 dias do d\u00f3lar/real, do petr\u00f3leo e do ouro \u00e9 apresentado nas Figuras 17, 18 e 19, respectivamente.\nFigura 17 - Taxa de Varia\u00e7\u00e3o (10 dias) da cota\u00e7\u00e3o do D\u00f3lar/Real\nA fim de se dar a mesma importancia para cada uma das caracter\u00edsticas e acelerar o treinamento da rede, as vari\u00e1veis foram normalizadas pela m\u00e9dia e pelo desvio-padr\u00e3o, conforme a Equa\u00e7\u00e3o (30). Dessa forma, as vari\u00e1veis assumir\u00e3o valores na mesma ordem de grandeza, assumindo, na maior parte do tempo, valores entre -1 e 1.\nz = x~^\t(30)\na\nonde z \u00e9 a vari\u00e1vel normalizada, x o valor bruto da vari\u00e1vel, a m\u00e9dia da popula\u00e7\u00e3o e a o desvio-padr\u00e3o da popula\u00e7\u00e3o.\nO c\u00e1lculo da m\u00e9dia e do desvio-padr\u00e3o foram realizados sobre os dados de treinamento/valida\u00e7\u00e3o, e os dados de teste foram normalizados baseados nesses valores. Dessa forma, as previs\u00f5es no conjunto de teste n\u00e3o ser\u00e3o enviesadas pela contabiliza\u00e7\u00e3o de informa\u00e7\u00f5es que est\u00e3o no futuro, simulando, assim, uma situa\u00e7\u00e3o real, onde os dados de teste s\u00e3o totalmente desconhecidos tanto no treinamento quanto durante a tomada de decis\u00f5es.\n3.3.2\tRanqueamento das caracter\u00edsticas\nAp\u00f3s o c\u00e1lculo e a normaliza\u00e7\u00e3o das vari\u00e1veis, esta etapa tem por objetivo listar as caracter\u00edsticas por ordem de import\u00e2ncia. O ranqueamento das caracter\u00edsticas foi realizado utilizando-se como modelo o m\u00e9todo do Gradient Boosting em conjunto com o algoritmo de Elimina\u00e7\u00e3o Recursiva (Recursive Feature Selection).\nO m\u00e9todo Gradient Boosting foi implementado utilizando-se a biblioteca xgboost 0.72 do Python. O algoritmo XGBoost fornece uma pontua\u00e7\u00e3o que indica o qu\u00e3o \u00fatil\ncada vari\u00e1vel foi na constru\u00e7\u00e3o das \u00e1rvores de decis\u00e3o do modelo. A import\u00e2ncia de uma caracter\u00edstica \u00e9 calculada pelo n\u00famero de vezes que sua utiliza\u00e7\u00e3o melhora a medida de performance da \u00e1vore. Assim, quanto mais uma caracter\u00edstica \u00e9 utilizada para tomar decis\u00f5es nas \u00e1rvores, maior ser\u00e1 sua relativa import\u00e2ncia. A import\u00e2ncia final de cada caracter\u00edstica \u00e9, ent\u00e3o, calculada pela m\u00e9dia de sua import\u00e2ncia em cada \u00e1rvore que comp\u00f5e o modelo. Assim, essa import\u00e2ncia \u00e9 calculada explicitamente para cada caracter\u00edstica, permitindo que sejam ranqueadas e comparadas umas \u00e0s outras. O algoritmo utilizado para a realiza\u00e7\u00e3o do ranqueamento das caracter\u00edsticas \u00e9 apresentado na Figura 20.\nFigura 20 - Algoritmo de ranqueamento das caracter\u00edsticas\nInicializa com o conjunto total de caracter\u00edsticas\nv\nTreina o modelo do Gradfent Boost\u00edrttj\n\u00b1\nRealiza o ranqueamento das caracter\u00edsticas baseado na import\u00e2ncia para a constru\u00e7\u00e3o do modelo\n'\u00ed\nElimina a caracter\u00edstica com a menor pontua\u00e7\u00e3o\nDessa forma, pelo algoritmo de Elimina\u00e7\u00e3o Recursiva, a caracter\u00edstica que estiver com a menor pontua\u00e7\u00e3o \u00e9 eliminada e, ent\u00e3o, um novo subconjunto de caracter\u00edsticas \u00e9 novamente classificado pelo Gradient Boosting. Assim, a constru\u00e7\u00e3o do ranking \u00e9 feita at\u00e9 que todas as caracter\u00edsticas sejam eliminadas, sendo a que for eliminada por \u00faltimo \u00e9 a caracter\u00edstica mais importante do ranking.\n3.4\tMODELO PROPOSTO\nA Rede Neural proposta \u00e9 uma Feedforward implementada utilizando-se a biblioteca Keras 2.1.4 do Python. A rede foi treinada com o algoritmo de otimiza\u00e7\u00e3o Adam, o qual tem apresentado resultados superiores a outros algoritmos como o m\u00e9todo do gradiente (KINGMA &amp; BA, 2014). A fun\u00e7\u00e3o custo utilizada foi a de Entropia Cruzada, calculada pela Equa\u00e7\u00e3o (31), j\u00e1 que ela tende a minimizar o problema da desacelera\u00e7\u00e3o no aprendizado causado pelas derivadas parciais das fun\u00e7\u00f5es de ativa\u00e7\u00e3o.\n1\"\t(31)\nc = --/ \u00cdMi-lnCPn) + (1 -yJ-ln(1 - O\nn \u00bf\u2014i\nn=1\nonde N \u00e9 o n\u00famero de itens de dados de treinamento, yn \u00e9 a sa\u00edda desejada e yn \u00e9 a ativa\u00e7\u00e3o da unidade de sa\u00edda do n-\u00e9simo elemento dos dados de treinamento.\nForam realizados alguns testes preliminares nos quais foram utilizados diferentes n\u00fameros de camadas ocultas e diferentes fun\u00e7\u00f5es de ativa\u00e7\u00f5es para cada uma das camadas. Verificou-se que independente do n\u00famero de caracter\u00edsticas utilizadas, a rede obteve melhores taxas de acertos utilizando-se 2 camadas ocultas. Al\u00e9m disso, as fun\u00e7\u00f5es de ativa\u00e7\u00e3o que apresentaram melhores resultados foram a fun\u00e7\u00e3o tangente hiperb\u00f3lica para os neur\u00f4nios da primeira camada oculta, a fun\u00e7\u00e3o linear para os neur\u00f4nios da segunda camada oculta e a fun\u00e7\u00e3o sigmoide para a camada de sa\u00edda.\nO ranqueamento das caracter\u00edsticas n\u00e3o deixa expl\u00edcita a quantidade de caracter\u00edsticas que devem ser utilizadas. Portanto, como o seu n\u00famero ideal n\u00e3o \u00e9 conhecido, foram implementadas diferentes redes utilizando 10, 20, 30, 40, 50 e 60 das caracter\u00edsticas mais bem classificadas no ranking. Para o n\u00famero de neur\u00f4nios das camadas ocultas utilizou-se 3 valores diferentes, sendo eles a quantidade de caracter\u00edsticas, a metade da quantidade de caracter\u00edsticas e o dobro da quantidade\nde caracter\u00edsticas, totalizando 6 x 3 x 3 = 54 modelos. A Figura 21 ilustra o n\u00famero de neur\u00f4nios utilizados em cada camada oculta em fun\u00e7\u00e3o do n\u00famero de caracter\u00edsticas. A fim de se reduzir os efeitos da converg\u00eancia a um m\u00ednimo local das Redes Neurais, cada modelo foi treinado 3 vezes e aquele com a maior taxa de acertos no conjunto de valida\u00e7\u00e3o foi registrado.\nFigura 21 - N\u00famero de neur\u00f4nios dos modelos em cada camada\n10\t5, 10, 20\t5, 10, 20\n20\t10, 20,40\t10, 20,40\n30\t15, 30, 60\t15, 30, 60\n40\t20, 40, 80\t20, 40, 80\n50\t25, 50, 100\t25, 50, 100\n60\t30, 60, 120\t30, 60, 120\nFonte: Adaptado de DOLHANSKY, 2018\nA fim de se avaliar a capacidade de generaliza\u00e7\u00e3o da rede para dados fora do conjunto de treinamento foi utilizada a t\u00e9cnica stratified k folds de valida\u00e7\u00e3o cruzada. Na t\u00e9cnica k folds, a amostra original \u00e9 dividida de forma aleat\u00f3ria em k sub-amostras. Uma entre elas \u00e9 utilizada como conjunto de valida\u00e7\u00e3o e as k-1 restantes s\u00e3o\nutilizadas para o treinamento. O processo de valida\u00e7\u00e3o cruzada \u00e9 repetido k vezes, utilizando-se cada um dos k conjuntos uma vez como conjunto de valida\u00e7\u00e3o. A taxa de acertos do modelo \u00e9, ent\u00e3o, obtida pela m\u00e9dia dos k resultados.\nVisto que a taxa de acertos \u00e9 dependente da divis\u00e3o aleat\u00f3ria dos conjuntos, foi feita uma estratifica\u00e7\u00e3o proporcional dos dados, de forma que cada conjunto \u00e9 constru\u00eddo de forma a conter aproximadamente a mesma distribui\u00e7\u00e3o de classes do conjunto original. Neste trabalho foi utilizado o valor de k igual a 3, pois este valor apresentou resultados melhores em alguns testes preliminares. A Figura 22 ilustra como \u00e9 feita a divis\u00e3o e o treinamento utilizando-se o m\u00e9todo k folds.\nIteration 1\nIteration 2\nIteration 3\nFigura 22 - Valida\u00e7\u00e3o cruzada k folds\nTest\tTrain\tTrain\n\t\t\nTrain\tTest\tTrain\n\t\t\nTrain\tTrain\tTest\nFonte: Adaptado de MEDIUM, 2018\nUtilizando-se essa t\u00e9cnica de valida\u00e7\u00e3o cruzada s\u00e3o constru\u00eddos 3 modelos. Desses 3 modelos, \u00e9 criado um modelo final atrav\u00e9s de uma t\u00e9cnica de ensembling, que tem por objetivo obter um modelo mais forte a partir dos outros modelos. O m\u00e9todo utilizado \u00e9 o m\u00e9todo de vota\u00e7\u00e3o, no qual a previs\u00e3o final \u00e9 aquela mais votada pela 3 redes. Para a avalia\u00e7\u00e3o do modelo final \u00e9 utilizado um conjunto de dados de teste os quais n\u00e3o fazem parte dos conjuntos de treinamento e de valida\u00e7\u00e3o e s\u00e3o os dados mais recentes do conjunto total.\nA fim de prevenir um sobretreinamento do modelo utilizou-se um ponto de verifica\u00e7\u00e3o durante o treinamento que tem por objetivo salvar o modelo treinado a cada \u00e9poca somente se a taxa de acertos do conjunto de valida\u00e7\u00e3o apresentar uma melhora em rela\u00e7\u00e3o \u00e0 \u00e9poca anterior. Caso mais de uma \u00e9poca apresentar a melhor taxa de acertos durante o treinamento, o desempate \u00e9 feito pela fun\u00e7\u00e3o custo. Essa t\u00e9cnica tem por objetivo evitar um sobreajuste do modelo aos dados de treinamento,\nmelhorando, assim, sua generaliza\u00e7\u00e3o para dados desconhecidos. A Figuras 23 e 24 ilustram a taxa de acertos e o custo, respectivamente, do conjunto de treino (em vermelho) e de valida\u00e7\u00e3o (em azul) durante o treinamento da rede com 30 caracter\u00edsticas de entrada e possuindo 30 e 15 neur\u00f4nios nas camadas ocultas.\nFigura 23 - Taxa de acertos dos conjuntos de treinamento e de valida\u00e7\u00e3o\nFigura 24 - Custo dos conjuntos de treinamento e de valida\u00e7\u00e3o\nObserva-se que apesar de a taxa de acertos e o custo dos dados de treinamento (em vermelho) continuarem melhorando, a partir da \u00e9poca 30, a taxa de acertos do conjunto de valida\u00e7\u00e3o (em azul) volta a cair e o custo a aumentar, indicando que um sobreajuste est\u00e1 ocorrendo. Nesse caso o modelo \u00e9 salvo em torno da \u00e9poca 30, onde o modelo obteve o melhor resultado.\n4\tRESULTADOS E DISCUSS\u00d5ES\nA classifica\u00e7\u00e3o das caracter\u00edsticas utilizando-se o algoritmo Gradient Boosting com o m\u00e9todo de Elimina\u00e7\u00e3o Recursiva obteve os resultados mostrados na Tabela 3, na qual s\u00e3o apresentadas as 60 caracter\u00edsticas mais importantes identificadas pelo m\u00e9todo. Os valores entre parenteses indicam o n\u00famero de per\u00edodos para o c\u00e1lculo das caracter\u00edsticas.\nTabela 3 - Ranking de caracter\u00edsticas.\nRanking\tCaracter\u00edstica\n1\tDesvio-padr\u00e3o (50)\n2\tDesvio-padr\u00e3o (100)\n3\tAbertura (n) / Fechamento (n-1) [Absoluto] (50)\n4\tM\u00e9dia m\u00f3vel (100)\n5\tM\u00e9dia M\u00f3vel volume 10/50\n6\tM\u00e9dia M\u00f3vel volume 50/100\n7\tPetrobr\u00e1s (5)\n8\tTelef\u00f4nica Brasil (20)\n9\tEmbraer (10)\n10\tOuro (10)\n11\tBrasil Foods (5)\n12\tEquatorial Energia (10)\n13\tCompanhia Paranaense de Energia (20)\n14\tPetr\u00f3leo (10)\n15\tCielo (5)\n16\tWEG (5)\n17\tCompanhia Sider\u00fargica Nacional (10)\n18\tBraskem (20)\n19\tCompanhia Paranaense de Energia (10)\n20\tNatura (20)\n21\tCyrela (20)\n22\tTaxa de varia\u00e7\u00e3o (50)\n23\tDesvio-padr\u00e3o (20)\n24\tAbertura (n) / Fechamento (n-1) (1)\n25\tEletrobr\u00e1s (5)\n26\tBrasil Foods (20)\n27\tM\u00e1ximo / M\u00ednimo (50)\n28\tCompanhia Brasileira de Distribui\u00e7\u00e3o (20)\n29\tMetal\u00fargica Gerdau (10)\n30\tTelef\u00f4nica Brasil (10)\n31\tCompanhia de Concess\u00f5es Rodovi\u00e1rias (5)\n32\tEletrobr\u00e1s (20)\n33\tLocaliza (10)\n34\tMRV Engenharia (20)\n35\tPetrobr\u00e1s (5)\n36\tAmbev (10)\n37\tD\u00f3lar / Real (20)\n38\tBanco Bradesco (10)\n39\tAbertura (n) / Fechamento (n-1) (100)\n40\tAbertura (n) / Fechamento (n-1) [Absoluto] (20)\n41\tM\u00e9dia M\u00f3vel volume 5/50\n42\tMagazine Luiza (5)\n43\tGerdau S.A. (5)\n44\tUltrapar (5)\n45\tNatura (10)\n46\tEquatorial Energia (20)\n47\tAbertura (n) / Fechamento (n-1) (20)\n48\tMarfrig Alimentos (20)\n49\tM\u00e9dia M\u00f3vel volume 10/20\n50\tSabesp (20)\n51\tMultiplan (20)\n52\tBrasil Bolsa Balc\u00e3o (10)\n53\tEmbraer (5)\n54\tCosan (10)\n55\tM\u00e1ximo / M\u00ednimo (5)\n56\tUltrapar (10)\n57\tBR Malls (20)\n58\tAbertura (n) / Fechamento (n-1) (50)\n59\tEquatorial Energia (5)\n60\tPetr\u00f3leo (5)\nAs taxas de acerto das redes para os dados de valida\u00e7\u00e3o utilizando-se diferentes n\u00fameros de caracter\u00edsticas s\u00e3o apresentadas nas Tabelas 4, 5, 6, 7, 8, 9, onde N1 representa o n\u00famero de neur\u00f4nios da primeira cadama oculta e N2 o n\u00famero de neur\u00f4nios da segunda camada oculta.\nTabela 4 - Taxa de acertos de valida\u00e7\u00e3o com 10 caracter\u00edsticas.\n\tN2\t5\t10\t20\n5\t\t59,53%\t60,06%\t58,64%\n10\t\t60,34%\t60,61%\t58,91%\n20\t\t58,81%\t59,43%\t59,89%\nTabela 5 - Taxa de acertos de valida\u00e7\u00e3o com 20 caracter\u00edsticas.\nN1'-\t.\tN2\t10\t20\t40\n10\t\t56,22%\t57,47%\t56,58%\n20\t\t56,04%\t56,58%\t55,68%\n40\t\t57,56%\t57,57%\t56,31%\nTabela 6 - Taxa de acertos de valida\u00e7\u00e3o com 30 caracter\u00edsticas.\n\tN2\t15\t30\t60\n15\t\t57,83%\t56,58%\t56,95%\n30\t\t57,92%\t59,37%\t58,72%\n60\t\t57,39%\t60,34%\t59,00%\nN1'-\t.\tN2\t20\t40\t80\n20\t\t57,56%\t57,38%\t57,12%\n40\t\t58,63%\t57,83%\t58,55%\n80\t\t58,63%\t59,08%\t57,84%\nTabela 8 - Taxa de acertos de valida\u00e7\u00e3o com 50 caracter\u00edsticas.\n\tN2\t25\t50\t100\n25\t\t56,94%\t59,63%\t57,49%\n50\t\t59,71%\t56,04%\t60,97%\n100\t\t60,42%\t57,92%\t58,81%\nTabela 9 - Taxa de acertos de valida\u00e7\u00e3o com 60 caracter\u00edsticas.\n\tN2\t30\t60\t120\n30\t\t57,75%\t57,74%\t57,74%\n60\t\t57,66%\t57,38%\t59,53%\n120\t\t60,06%\t57,84%\t59,00%\n\u00c9 poss\u00edvel observar que as taxas de acertos para o conjunto de valida\u00e7\u00e3o ficou compreendida entre 56% e 61%, apresentando pouca varia\u00e7\u00e3o em fun\u00e7\u00e3o da quantidade de caracter\u00edsticas e de neur\u00f4nios utilizados. A taxa de acertos m\u00e9dia do conjunto de valida\u00e7\u00e3o em fun\u00e7\u00e3o do n\u00famero de caracter\u00edsticas de entrada \u00e9 apresentada na Figura 25.\nFigura 25 - Taxa de acertos do conjunto de valida\u00e7\u00e3o\nPara o conjunto de testes as taxas de acerto das redes s\u00e3o apresentadas nas Tabelas 10, 11, 12, 13, 14, 15.\nN1'-\t.\tN2\t5\t10\t20\n5\t\t49,58%\t51,66%\t49,17%\n10\t\t52,29%\t48,54%\t50,00%\n20\t\t52,50%\t47,50%\t47,29%\nTabela 11 - Taxa de acertos de teste com 20 caracter\u00edsticas.\n\tN2\t10\t20\t40\n10\t\t53,95%\t48,96%\t48,75%\n20\t\t52,91%\t51,87%\t52,71%\n40\t\t54,16%\t54,79%\t52,08%\nTabela 12 - Taxa de acertos de teste com 30 caracter\u00edsticas.\n\tN2\t15\t30\t60\n15\t\t54,58%\t56,04%\t55,41%\n30\t\t57,50%\t55,62%\t54,58%\n60\t\t55,83%\t54,17%\t53,33%\nTabela 13 - Taxa de acertos de teste com 40 caracter\u00edsticas.\n\tN2\t20\t40\t80\n20\t\t57,45%\t56,45%\t55,41%\n40\t\t58,13%\t57,75%\t55,62%\n80\t\t56,62%\t55,21%\t55,21%\nTabela 14 - Taxa de acertos de teste com 50 caracter\u00edsticas.\n\tN2\t25\t50\t100\n25\t\t54,37%\t54,79%\t56,00%\n50\t\t55,83%\t54,37%\t54,91%\n100\t\t55,83%\t56,87%\t54,37%\nTabela 15 - Taxa de acertos de teste com 60 caracter\u00edsticas.\n\tN2\t30\t60\t120\n30\t\t55,21%\t55,83%\t56,67%\n60\t\t52,71%\t52,91%\t53,54%\n120\t\t54,79%\t54,17%\t52,92%\nObserva-se que as taxas de acertos do conjunto de testes n\u00e3o tiveram uma varia\u00e7\u00e3o significativa em fun\u00e7\u00e3o da quantidade de neur\u00f4nios. As redes que obtiveram as maiores taxas de acertos foram aquelas que inclu\u00edram 30, 40 ou 50 caracter\u00edsticas de entrada. Mais especificamente, as redes que obtiveram o melhor resultado foram aquelas incluindo 40 caracter\u00edsticas de entrada, com uma taxa de acertos m\u00e9dia de\n56,43% e uma taxa de acertos m\u00e1xima de 58,13% para a rede com 40 neur\u00f4nios na primeira camada oculta e 20 neur\u00f4nios na segunda camada oculta. A taxa de acertos m\u00e9dia do conjunto de testes em fun\u00e7\u00e3o do n\u00famero de caracter\u00edsticas \u00e9 apresentada na Figura 26.\nFigura 26 - Taxa de acertos do conjunto de testes\nA Matriz de Confus\u00e3o do conjunto de teste da rede utilizando 40 caracter\u00edsticas de entrada, 40 neur\u00f4nios na primeira camada oculta e 20 neur\u00f4nios na segunda camada oculta \u00e9 apresentada na Tabela 16.\nTabela 16 - Matriz de confus\u00e3o da rede\n\tPrevisto\t\t\t\nReal\t\t0\t1\tTotal\n\t0\t171\t58\t229\n\t1\t143\t108\t251\n\tTotal\t314\t166\t480\nSem a utiliza\u00e7\u00e3o da sele\u00e7\u00e3o de caracter\u00edsticas as taxas de acerto das redes para o conjunto de teste, utilizando-se todas as 220 caracter\u00edsticas, s\u00e3o apresentadas na Tabela 17.\nN1\t\t110\t220\t440\n110\t\t50,14%\t49,24%\t50,28%\n220\t\t49,31%\t51,60%\t47,99%\n440\t\t51,39%\t49,93%\t48,54%\nObserva-se que o resultado foi bastante inferior comparado \u00e0s redes que utilizam a sele\u00e7\u00e3o de caracter\u00edsticas. Al\u00e9m disso, muitas das taxas de acerto s\u00e3o inferiores \u00e0 50%, o que, pode-se dizer, \u00e9 t\u00e3o ruim quanto uma classifica\u00e7\u00e3o aleat\u00f3ria.\nFoi avaliada tamb\u00e9m as taxas de acerto para os dados de teste utilizando-se o algoritmo Gradient Boosting como modelo. A taxa de acerto em fun\u00e7\u00e3o do n\u00famero de caracter\u00edsticas utilizadas como entrada \u00e9 apresentada na Figura 27.\nFigura 27 - Taxa de acertos para os dados de teste do algoritmo XGBoost\nObserva-se que a taxa de acertos m\u00e1xima foi de 62,71% com 49 caracter\u00edsticas, o que \u00e9 um resultado melhor do que o obtido com a Rede Neural. Al\u00e9m disso, o algoritmo foi executado com os par\u00e2metros padr\u00e3o, ent\u00e3o \u00e9 prov\u00e1vel que ele ainda possa ser melhorado. No entanto, embora esse resultado indique o Gradient Boosting de \u00c1rvores de Decis\u00e3o como um melhor modelo de previs\u00e3o, a sele\u00e7\u00e3o de caracter\u00edsticas foi implementada utilizando esse m\u00e9todo, ent\u00e3o \u00e9 natural que ele tenha uma taxa de acertos mais alta.\n5\tCONCLUS\u00c3O\nEste trabalho teve por objetivo a aplica\u00e7\u00e3o de uma Rede Neural Feedforward na previs\u00e3o das tend\u00eancias do \u00cdndice Bovespa em um horizonte de tempo de uma semana. Foram calculadas 220 diferentes caracter\u00edsticas consistindo em indicadores t\u00e9cnicos, volatilidade e nas cota\u00e7\u00f5es do d\u00f3lar, do petr\u00f3leo, do ouro, assim como das a\u00e7\u00f5es que comp\u00f5em o \u00edndice. Foi realizado um ranqueamento das caracter\u00edsticas utilizando-se como modelo o m\u00e9todo Gradient Boosting em um algoritmo Recursive Feature Elimination. Foram implementadas diferentes redes utilizando diferentes n\u00fameros de neur\u00f4nios e quantidades variadas das caracter\u00edsticas mais bem classificadas.\nObteve-se uma taxa de acertos de 58,63% para o conjunto de valida\u00e7\u00e3o e 58,13% para o conjunto de teste para a rede utilizando as 40 caracter\u00edsticas mais bem classificadas pelo ranking. Utilizando-se todas as entradas pr\u00e9-selecionadas a rede obteve uma taxa de acertos de 51,39%, mostrando a importancia da sele\u00e7\u00e3o de caracter\u00edsticas nesse problema. A taxa de acertos no conjunto de testes do algoritmo Gradient Boosting foi de 62,71% utilizando 49 caracter\u00edsticas, o que \u00e9 um resultado melhor que o obtido pela Rede Neural. Isso, no entanto, parece natural visto que a sele\u00e7\u00e3o de caracter\u00edsticas foi implementada utilizando-se esse m\u00e9todo.\nOs resultados obtidos s\u00e3o similares aos de outros estudos da \u00e1rea, como Kim (2003), por exemplo, que obteve uma taxa de acertos de 57,83% na previs\u00e3o do \u00cdndice Sul-Coreano, e Atsalakis &amp; Psomatakis (2014) que obtiveram uma taxa de acertos m\u00e9dia de 57,5% na previs\u00e3o da cota\u00e7\u00e3o de a\u00e7\u00f5es. Outros trabalhos, como o de Kara et al. (2010), obtiveram uma taxa de acertos de 75,74% na previs\u00e3o do \u00cdndice da Bolsa de Istambul para os dados de valida\u00e7\u00e3o. No entanto, de acordo com Racine (2000), para que a valida\u00e7\u00e3o cruzada funcione como uma ferramenta de sele\u00e7\u00e3o de modelos, \u00e9 necess\u00e1rio que os conjuntos de treinamento e valida\u00e7\u00e3o sejam independentes. O problema com s\u00e9ries temporais \u00e9 que pontos adjacentes s\u00e3o altamente dependentes de modo que t\u00e9cnicas padr\u00e3o de valida\u00e7\u00e3o cruzada ser\u00e3o enviesadas e n\u00e3o cumprir\u00e3o t\u00e3o bem sua fun\u00e7\u00e3o. Portanto, como os autores n\u00e3o utilizam um conjunto de testes, \u00e9 dif\u00edcil saber a real capacidade de generaliza\u00e7\u00e3o da rede para dados fora dos conjuntos de treinamento e valida\u00e7\u00e3o.\nPrever o mercado financeiro \u00e9 uma tarefa desafiadora, pois, por mais que existam padr\u00f5es nas s\u00e9ries financeiras, ainda existe um grande fator psicol\u00f3gico e outros fatores que s\u00e3o muito complicados de modelar com precis\u00e3o. No entanto, ainda que, na maior parte do tempo, o mercado se comporte de maneira imprevis\u00edvel, a descoberta de padr\u00f5es \u00e9 poss\u00edvel, rejeitando, em parte, a Hip\u00f3tese do Mercado Eficiente j\u00e1 que os pre\u00e7os das a\u00e7\u00f5es n\u00e3o se movimentam de forma completamente aleat\u00f3ria.\n6\tPROPOSTAS PARA TRABALHOS FUTUROS\nExistem diversos caminhos que podem dar sequ\u00eancia a esse trabalho. Dentre eles est\u00e1 a inclus\u00e3o de outras m\u00e9tricas ou s\u00e9ries que possam ter rela\u00e7\u00e3o com o \u00edndice, assim como a utiliza\u00e7\u00e3o de outras t\u00e9cnicas de sele\u00e7\u00e3o de caracter\u00edsticas. Podem ainda ser aplicados outros m\u00e9todos de pr\u00e9-processamento, como a discretiza\u00e7\u00e3o das vari\u00e1veis e a aplica\u00e7\u00e3o de filtros que podem ajudar a minimizar os efeitos da aleatoriedade das s\u00e9ries financeiras.\nOutra possibilidade \u00e9 a utiliza\u00e7\u00e3o de outros m\u00e9todos ou outras arquiteturas de redes como, por exemplo, as redes LSTM (Long Short-Term Memory). Esse tipo de rede \u00e9 capaz de fazer previs\u00f5es n\u00e3o s\u00f3 baseadas em um conjuntos de entradas, mas tamb\u00e9m nas informa\u00e7\u00f5es sequenciais armazenadas ao longo do tempo.\nEste trabalho utilizou somente os valores di\u00e1rios do \u00edndice. \u00c9 poss\u00edvel que possam existir informa\u00e7\u00f5es nos dados de outros timeframes que podem ser \u00fateis para as previs\u00f5es. Uma possibilidade seria a constru\u00e7\u00e3o de um ensemble de modelos que utilizem dados de diferentes bases de tempo, permitindo, assim, que o sistema de previs\u00e3o extraia outras informa\u00e7\u00f5es do comportamento do mercado ao longo do dia.\nREFER\u00caNCIAS BIBLIOGR\u00c1FICAS\nATSALAKIS, G. S. &amp; PSOMATAKIS, M. A. Stock Market Trend Forecasting by Technical Analysis and Hybrid Genetically Evolved Neural Networks. Journal of Computational Optimization in Economics and Finance, Vol. 6, N. 3. 1941-3971,2014.\nATSALAKIS, G. S.; VALAVANIS, K. P. Surveying stock market forecasting techniques - part II: Soft computing methods. Expert Systems with Applications, 36(3), 59325941,2008.\nATSALAKIS, G. S.; VALAVANIS, K. P. Forecasting stock market short-term trends using a neuro-fuzzy based methodology. Expert Systems with Applications, 36, 10696-10707, 2009.\nBAHMANI-OSKOOEE M. &amp; SOHRABIAN A. Stock prices and the effective exchange rate of the dollar, Apllied Economics Journal, Volume 24, 1992.\nBASU, S. The investment performance of common stocks in relation to their priceearnings ratios: A test of the efficient market hypothesis. Journal of Finance 32: 663682, 1977.\nBLACK, F. The trouble with econometrics models. Financial Analysis Journal 4(5): 7587, 1982.\nBORODIN, A.; EL-YANIV, R; GOGAN, V. Can We Learn to Beat the Best Stock. Journal of Artificial Intelligence Research 21: 579-594, 2004.\nBOX, G.E.P.; JENKINS, G.M.; REINSEL, G.C. Time Series Analysis, Forecasting and Control, 4th ed., Wiley Series in Probability and Statistics, 2008.\nCHANG R.P., RHEE S.G., STONE G.R., TANG N. How does the call market method affect price efficiency? Evidence from the Singapore Stock Market. Journal of Banking &amp; Finance, Volume 32, Issue 10, 2008.\nCHEN T. &amp; GUESTRIN C. Xgboost: A scalable tree boosting system. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 978-1-4503-4232-2, 2016.\nCHOUDHRY, R., and KUMUM, G. A hybrid machine learning system for stock market forecasting, World Academy of Science, Engineering and Technology 39.3: 315-318,\n2008.\nCORPORATE FINANCE INSTITUTE. Equity Capital Market. Dispon\u00edvel em:&lt;https://corporatefinanceinstitute.com/resources/knowledge/finance/equity-capital-market-ecm/>. Visitado em Mar\u00e7o de 2018.\nCPC (Comit\u00ea de Pronunciamentos Cont\u00e1beis). BM&amp;F Bovespa. Dispon\u00edvel em: &lt;http://cpc.org.br/bovespa.htm/>. Visitado em Mar\u00e7o de 2018.\nDECHOW, P. M. ; HUTTON, A. P.; MEULBROEK, L. ; SLOAN, R. G. Short-sellers, fundamental analysis, and stock returns Journal of Financial Economics 61: 77-106, 2001.\nDOLHANSKY, B. Artificial Neural Networks: Mathematics of Backpropagation. Dispon\u00edvel em:&lt;http://briandolhansky.com/blog/2013/9/27/artificial-neural-networks-backpropagation-part-4>. Visitado em Abril de 2018.\nDOW C.H. Swings Within Swings. The Wall Street Journal of January, 1902.\nFACELI K., LORENA A.C., GAMA J., CARVALHO A. Intelig\u00eancia artificial: uma abordagem de aprendizado de m\u00e1quina. 1a Edi\u00e7\u00e3o. Rio de Janeiro, LTC: 2011.\nFAMA E.F. Short-Term Interest Rates as Predictors of Inflation. The American Economic Review, Vol. 65, No. 3, pp. 269-282, 1975.\nFAMA E.F. Efficient Capital Markets: II. The Journal of Finance, Vol. 46, Issue 5, pp. 1575-1617, 1991.\nFRIEDMAN J.H. Greedy Function Approximation: A Gradient Boosting Machine, The Annals of Statistics, Vol. 29, No. 5, pp. 1189-1232, 2001.\nHAYKIN, Simon. Redes neurais: princ\u00edpios e pr\u00e1tica. 2a Edi\u00e7\u00e3o. Porto Alegre. Bookman: 2001.\nHIEMSTRA, Y. Modeling structured nonlinear knowledge to predict stock market returns, Chaos &amp; Nonlinear Dynamics in the Financial Markets: Theory, Evidence and Applications, Irwin, pp. 163-175, 1995.\nHUANGA W., NAKAMORIA Y., WANGB S.Y., Forecasting stock market movement direction with support vector machine, Computers &amp; Operations Research vol. 32, no. 10, 1820-6425, 2005.\nINVESTOPEDIA.\tFinancial\tMarket.\tDispon\u00edvel\tem:\n<https://www.investopedia.com/terms/f/financial-market.asp>. Visitado em Mar\u00e7o de 2018.\nKARA Y., BOYACIOGLU M. A., BAYKAN O. K. Predicting direction of stock price index movement using artificial neural networks and support vector machines: The sample of the Istanbul Stock Exchange. Expert Systems with Applications, Volume 38, 53115319, 2010.\nKIM K. J. Financial time series forecasting using support vector machines. Neurocomputing no. 55, 307-319, 2003.\nKIM, H.; SHIN, K., A hybrid approach based on neural networks and genetic algorithms for detecting temporal patterns in stock markets, Applied Soft Computing, Volume 7, Issue 2, Pages 569-576, 2007.\nKINGMA D.P. &amp; BA J. Adam: A Method for Stochastic Optimization. Proceedings of the 3rd International Conference on Learning Representations (ICLR) : 1412.6980, 2014.\nLAWRENCE R. Using Neural Networks to Forecast Stock Market Prices, University of Manitoba, 1997.\nLEE C.C &amp; ZENG J.H. The impact of oil price shocks on stock market activities: Asymmetric effect with quantile regression. Volume 81, 2011.\nLEVINSON M. Guide to Financial Markets. 4a ed. London: The Economist, 2005.\nLEVY, R. Conceptual Foundations of Technical Analysis. Financial Analysts Journal. Vol. 22, No. 4: 83-891966, 1966.\nLO A. W., MACKINLAY, A. C. Stock market prices do not follow random walks: evidence from a simple specification test, Rev. Financial Stud. 1: 41-66, 1988.\nLOH W.Y. Classification and regression trees. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, Volume 1, Issue 1,2011.\nMCCULLOCH,W. S.; PITTS,W. A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics, Springer, v. 5, n. 4, p. 115-133, 1943.\nMEDIUM. Regression vs Classification Problems in Machine Learning. Dispon\u00edvel em:&lt;https://medium.com/@heyozramos/regression-vs-classification86d73c281c5e>. Visitado em Abril de 2018.\nMURPHY, John J. Technical Analysis of the Financial Markets. 1a ed. New York: New York Institute of Finance, 1999.\nNAEINI M.P., TAREMIAN H., HASHEMI H.B. Stock market value prediction using neural networks. International Conference on Computer Information Systems and Industrial Management Applications (CISIM), 978-1-4244-7818-7, 2010.\nPRING, M. Technical Analysis Explained. 5a Edi\u00e7\u00e3o. McGraw-Hill, 2016.\nPAI P.F. &amp; LIN C.S. A hybrid ARIMA and support vector machines model in stock price forecasting, Omega 33, 497-505, 2005.\nQIU, M; SONG, Y; AKAGI, F. Application of artificial neural network for the prediction of stock market returns: The case of the Japanese stock market. Chaos, Solitons and Fractals 85: 1-7, 2016.\nRACINE J. Consistent cross-validatory model-selection for dependent data: hv-block cross-validation. Journal of Econometrics 99, 39-61, 2000.\nRAHMAN M. &amp; MUSTAFA M. Effects of Crude Oil and Gold Prices on US Stock Market: Evidence for USA from ARDL Bounds Testing. Mathematics and Computers in Simulation 81(9), 1910-1920, 2011.\nROCKEFELLER, Barbara. Technical Analysis for Dummies. 2a ed. Indianapolis: Wiley Publishing, Inc., 2011.\nROSENBLATT, F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review, American Psychological Association, v. 65, n. 6, p. 386, 1958.\nSAAD E. W., PROKHOROV D. V., WUNSCH D. C. Comparative study of stock trend prediction using time delay, recurrent and probabilistic neural networks. Neural Networks, IEEE Transactions on, IEEE, v. 9, n. 6, p. 1456-1470, 1998.\nTAY F.E.H &amp; CAO L. Application of support vector machines in financial time series forecasting, Omega, 29(4):309-317, 2001.\nTSFRESH. Time Series Forecasting. Dispon\u00edvel em:\t<\nhttp://tsfresh.readthedocs.io/en/latest/text/forecasting.html/>. Visitado em Maio de 2018.\nVANSTONE B. &amp; FINNIE G. An empirical methodology for developing stock market trading systems using artificial neural networks, Expert Systems with Applications 36: 6668-6680, 2008.\nWILDER, J. W. New concepts in technical trading systems. Hunter Publishing Company. Winston-Salem &amp; Greensboro, NC: Trend Research. Library of Congress Card Catalog No. 78-60759, 1978.\nWURGLER, Jeffrey. Financial markets and the allocation of capital. Journal of Financial Economics, n. 58, p. 187-214, 2000.\nYAHOO FINANCE. Dispon\u00edvel em:&lt;https://finance.yahoo.com/>.Visitado em Abril de 2018.\nYOO, P. D.; KIM, M. H.; JAN, T. Machine Learning Techniques and Use of Event Information for Stock, Market Prediction: A Survey and Evaluation, 2005.\nZHANG, Y., &amp; WU, L. Stock market prediction of S&amp;P 500 via combination of improved BCO approach and BP neural network. Expert Systems with Applications, 36(5), 88498854, 2009.\nANEXO - A\u00e7\u00f5es inclu\u00eddas nas caracter\u00edsticas\nC\u00d3DIGO\tA\u00c7\u00c3O\nABEV3\tAMBEV S/A\nBBAS3\tBRASIL\nBBDC3\tBRADESCO\nBBDC4\tBRADESCO\nBBSE3\tBBSEGURIDADE\nBRAP4\tBRADESPAR\nBRFS3\tBRF SA\nBRKM5\tBRASKEM\nBRML3\tBR MALLS PAR\nBTOW3\tB2W DIGITAL\nCCRO3\tCCR SA\nCIEL3\tCIELO\nCMIG4\tCEMIG\nCPFE3\tCPFL ENERGIA\nCPLE6\tCOPEL\nCSAN3\tCOSAN\nCSNA3\tSID NACIONAL\nCYRE3\tCYRELA REALT\nECOR3\tECORODOVIAS\nEGIE3\tENGIE BRASIL\nELET3\tELETROBRAS\nELET6\tELETROBRAS\nEMBR3\tEMBRAER\nENBR3\tENERGIAS BR\nEQTL3\tEQUATORIAL\nFIBR3\tFIBRIA\nFLRY3\tFLEURY\nGGBR4\tGERDAU\nGOAU4\tGERDAU MET\nGOLL4\tGOL\nHYPE3\tHYPERA\nIGTA3\tIGUATEMI\nITSA4\tITAUSA\nITUB4\tITAUUNIBANCO\nJBSS3\tJBS\nLREN3\tLOJAS RENNER\nMGLU3\tMAGAZ LUIZA\nMRFG3\tMARFRIG\nMRVE3\tMRV\nMULT3\tMULTIPLAN\nNATU3\tNATURA\nPCAR4\tP.ACUCAR-CBD\nPETR3\tPETROBRAS\nPETR4\tPETROBRAS\nQUAL3\tQUALICORP\nRADL3\tRAIADROGASIL\nRENT3\tLOCALIZA\nSBSP3\tSABESP\nTIMP3\tTIM PART S/A\nUGPA3\tULTRAPAR\nUSIM5\tUSIMINAS\nVALE3\tVALE\nVIVT4\tTELEF BRASIL"}]}}}