{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.17040"}, {"@name": "filename", "#text": "2375_222388.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNIVERSIDADE FEDERAL DE SANTA CATARINA \nPROGRAMA DE P\u00d3S-GRADUA\u00c7\u00c3O EM \n\nCI\u00caNCIAS DA COMPUTA\u00c7\u00c3O \n \n \n \n \n\nDennis Kerr Coelho \n \n \n \n \n \n\nSISTEMA NEURAL PARA PREVIS\u00c3O DE TEMPO \nDE PERFURA\u00c7\u00c3O DE PO\u00c7OS DE PETR\u00d3LEO \n\n \n \n \n \n\n \nDisserta\u00e7\u00e3o submetida \u00e0 Universidade Federal de Santa Catarina como parte dos \nrequisitos para a obten\u00e7\u00e3o do grau de Mestre em Ci\u00eancias da Computa\u00e7\u00e3o \n \n \n \n \n \n\nProf. Dr. Mauro Roisenberg \nOrientador \n\n \n \n \n \n \n \n \n\nFlorian\u00f3polis, Julho 2005 \n\n\n\n \n\n \n\n2\n\n \n\nSistema neural para previs\u00e3o de tempo de perfura\u00e7\u00e3o de \npo\u00e7os de petr\u00f3leo \n\n \n \n \n\nDennis Kerr Coelho \n \n \n \n\nEsta Disserta\u00e7\u00e3o foi julgada adequada para a obten\u00e7\u00e3o do t\u00edtulo de Mestre em Ci\u00eancia \nda Computa\u00e7\u00e3o \u00c1rea de Concentra\u00e7\u00e3o - Sistema de Conhecimento e aprovada em sua \nforma final pelo Programa de P\u00f3s-Gradua\u00e7\u00e3o em Ci\u00eancia da Computa\u00e7\u00e3o. \n\n \n \n \n\n            ________________________________ \n                                             Raul Sidnei Wazlawick, Dr \n                                                                                Coordenador do Curso \n\n \n           ________________________________ \n\n             Mauro Roisenberg, Dr.                            \n                                                           Orientador \n\n \nBanca Examinadora \n                          \n\n           ________________________________ \n      Dante Augusto Couto Barone,Dr.  \n \n \n\n                              ________________________________ \n      Paulo Jos\u00e9 de Freitas Filho,Dr.  \n\n   \n      \n\n                              ________________________________ \n      Silvia Modesto Nassar, Dr.\u00aa \n\n \n \n\n\n\n \n\n \n\n3\n\n \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\nAo meu pai e minha m\u00e3e Jony Coelho e Joan Kerr Coelho. \n\nQue me propiciaram uma boa educa\u00e7\u00e3o e tudo necess\u00e1rio \n\nPara que pudesse me dedicar totalmente aos estudos. \n\n \n\n\n\n \n\n \n\n4\n\n \n\nAGRADECIMENTOS \n \n \n\nInicialmente agrade\u00e7o a meus pais que sempre me incentivaram. Agrade\u00e7o a meus \n\nav\u00f3s e meus familiares. Agrade\u00e7o a minha namorada que sempre me deu for\u00e7as. E \n\nfinalmente agrade\u00e7o a meu orientador que me ajudou durante todo o mestrado e sem \n\nquem n\u00e3o teria realizado um trabalho t\u00e3o completo. \n\n \n\n\n\n \n\n \n\n5\n\n \n\nSUM\u00c1RIO \n \n\n \n\nCAP\u00cdTULO 1 ............................................................................................................... 11 \n\n1.1 Introdu\u00e7\u00e3o .............................................................................................................. 11 \n1.2 Objetivos ................................................................................................................ 13 \n1.2.1 Objetivo Geral .................................................................................................... 13 \n1.2.2 Objetivos Espec\u00edficos ......................................................................................... 13 \n1.3 Metodologia ........................................................................................................... 13 \n1.4 Estrutura do Texto ................................................................................................ 14 \n  \nCAP\u00cdTULO 2 \u2013 REDES NEURAIS, MINERA\u00c7\u00c3O DE DADOS E \n\nRECONHECIMENTO DE PADR\u00d5ES .................................................................... \n\n \n\n15 \n\n2.1 Descoberta de Conhecimento em Bases de Dados .............................................. 15 \n2.2 O Processo KDD .................................................................................................... 16 \n2.3 Minera\u00e7\u00e3o de Dados .............................................................................................. 16 \n2.4 Reconhecimento de Padr\u00f5es ................................................................................. 17 \n2.4.1 Abordagem Estat\u00edstica de Reconhecimento de Padr\u00f5es (AERP) .................. 17 \n2.4.1.1 An\u00e1lise de Cluster ........................................................................................... 18 \n2.4.1.2 Regress\u00e3o ......................................................................................................... 18 \n2.4.2 Abordagem Sint\u00e1tica de Reconhecimento de Padr\u00f5es (ASRP) ..................... 19 \n2.4.2.1 \u00c1rvore de Decis\u00e3o ........................................................................................... 19 \n2.4.3 Abordagem Neural para Reconhecimento de Padr\u00f5es (ANRP) .................... 20 \n2.4.3.1 Redes Neurais .................................................................................................. 21 \n2.4.4 Compara\u00e7\u00e3o entre as Abordagens de Reconhecimento de Padr\u00f5es .............. 21 \n2.5 Redes Neurais ........................................................................................................ 23 \n2.5.1 Redes Diretas ...................................................................................................... 23 \n2.5.2 Aprendizagem Supervisionada ......................................................................... 24 \n2.5.3 Retropropaga\u00e7\u00e3o de Erros ................................................................................ 25 \n2.5.4 Rede Competitiva Simples ................................................................................. 27 \n  \nCAP\u00cdTULO 3 - PERFURA\u00c7\u00c3O E EXPLORA\u00c7\u00c3O DE PETR\u00d3LEO ................ 30 \n\n3.1 Perfura\u00e7\u00e3o .............................................................................................................. 30 \n3.2 Completa\u00e7\u00e3o .......................................................................................................... 33 \n  \nCAP\u00cdTULO 4 - SISTEMA PROPOSTO .................................................................. 35 \n4.1. Propostas Preliminares ........................................................................................ 35 \n4.2. Proposta Adotada ................................................................................................. 39 \n4.2.1 Rede Competitiva ............................................................................................... 40 \n4.2.2 Rede Direta ......................................................................................................... 41 \n4.3. Treinamento das Redes ....................................................................................... 42 \n4.4 Implementa\u00e7\u00e3o ...................................................................................................... 44 \n4.4.1 Plataforma de Desenvolvimento ....................................................................... 44 \n4.4.2 Detalhes de Desenvolvimento ............................................................................ 44 \n\n\n\n \n\n \n\n6\n\n \n\n4.4.3 Interface .............................................................................................................. 45 \n4.4.3.1 Interface de treinamento ................................................................................ 45 \n4.4.3.2 Interface de Avalia\u00e7\u00e3o .................................................................................... 51 \n  \nCAP\u00cdTULO 5 - TESTES E VALIDA\u00c7\u00c3O ............................................................... 52 \n\n5.1. Dados para os Testes ........................................................................................... 52 \n5.2. Simula\u00e7\u00f5es ............................................................................................................ 53 \n5.3 An\u00e1lise Detalhada ................................................................................................. 55 \n5.4 An\u00e1lise de Erro ...................................................................................................... 60 \n5.5 Testes com Dados Reais ........................................................................................ 64 \n  \nCAP\u00cdTULO 6 - CONSIDERA\u00c7\u00d5ES FINAIS .......................................................... 66 \n\n6.1. Conclus\u00e3o .............................................................................................................. 66 \n\n6.2. Trabalhos Futuros ................................................................................................ 68 \n\n  \nREFER\u00caNCIAS .......................................................................................................... 70 \n\n \n \n\n\n\n \n\n \n\n7\n\n \n\nLISTA DE FIGURAS \n \n\nFigura 2.1 \u2013 \u00c1rvore de decis\u00e3o para o conceito compra ......................................... 20 \n\nFigura 2.2 \u2013  Exemplo de rede direta ....................................................................... 24 \n\nFigura 2.3 \u2013 Aprendizado supervisionado ............................................................... 24 \n\nFigura 2.4 \u2013 Arquitetura da rede competitiva .......................................................... 27 \n\nFigura 2.5 \u2013 Apresenta\u00e7\u00e3o de um padr\u00e3o a rede competitiva .................................. 28 \n\nFigura 2.6 \u2013 Representa\u00e7\u00e3o esquem\u00e1tica da aprendizagem numa rede competitiva  29 \n\nFigura 3.1 \u2013 Sonda ................................................................................................... 31 \n\nFigura 3.2 \u2013 Brocas .................................................................................................. 32 \n\nFigura 4.1 \u2013 Arquitetura de redes do sistema .......................................................... 39 \n\nFigura 4.2 \u2013 Arquitetura da rede competitiva .......................................................... 41 \n\nFigura 4.3 \u2013 Arquitetura da rede direta .................................................................... 42 \n\nFigura 4.4 \u2013 Tela da etapa 1, entrada de dados ........................................................ 46 \n\nFigura 4.5 \u2013 Tela da etapa 2, an\u00e1lise de dados ....................................................... 47 \n\nFigura 4.6 \u2013 Tela da etapa 3, par\u00e2metros de treinamento ........................................ 48 \n\nFigura 4.7 \u2013 Tela da etapa, 4 treinamento ............................................................... 49 \n\nFigura 4.8 \u2013 Tela da etapa 5, relat\u00f3rios ................................................................... 50 \n\nFigura 4.9 \u2013  Avalia\u00e7\u00e3o \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 51 \n\nFigura 5.1 \u2013 Histograma de distribui\u00e7\u00e3o dos dados no tempo, simula\u00e7\u00e3o 8 ........... 57 \n\nFigura 5.2 \u2013 Histograma de distribui\u00e7\u00e3o dos dados no tempo, simula\u00e7\u00e3o 9 ........... 57 \n\nFigura 5.3 \u2013 Histograma de distribui\u00e7\u00e3o dos dados no tempo, simula\u00e7\u00e3o 8 ........... 58 \n\nFigura 5.4 \u2013 Histograma de distribui\u00e7\u00e3o dos dados no tempo, simula\u00e7\u00e3o 9 ........... 58 \n\nFigura 5.5 \u2013 Gr\u00e1ficos de distribui\u00e7\u00e3o de resultados para o teste 8 .......................... 59 \n\nFigura 5.6 \u2013  Gr\u00e1ficos de distribui\u00e7\u00e3o de resultados para o teste 9 ......................... 60 \n\nFigura 5.7 \u2013 Histogramas de distribui\u00e7\u00e3o do erro nas simula\u00e7\u00f5es 8 e 9................... 61 \n\n\n\n \n\n \n\n8\n\n \n\nLISTA DE TABELAS \n\n \n\nTabela 2.1 \u2013 Compara\u00e7\u00e3o entre as abordagens de eeconhecimento de padr\u00f5es ...... 22 \n\nTabela 4.1 \u2013 Exemplo de dados reais ...................................................................... 38 \n\nTabela 4.2 \u2013 Compara\u00e7\u00e3o entre dado original e dado convertido ........................... 43 \n\nTabela 5.1 \u2013 N\u00famero de dados pertencentes aos arquiovos de dados ..................... 53 \n\nTabela 5.2 \u2013 Par\u00e2metros referentes ao treinamento nas simula\u00e7\u00f5es realizadas e \n\nerro m\u00e9dio para cada par\u00e2metro de sa\u00edda ................................................................ \n\n \n\n54 \n\nTabela 5.4 \u2013 Testes realizados com dados reais ...................................................... 64 \n\nTabela 5.5 \u2013 Intervalo de confian\u00e7a de 90% para cada teste ................................ 65 \n\n\n\n \n\n \n\n9\n\n \n\nRESUMO \n \n\n \n\nEsta disserta\u00e7\u00e3o tem como objetivo mostrar como a abordagem conexionista \npode ser utilizada na avalia\u00e7\u00e3o e previs\u00e3o do tempo total em opera\u00e7\u00f5es de \nperfura\u00e7\u00e3o e completa\u00e7\u00e3o de po\u00e7os de petr\u00f3leo em \u00e1guas profundas. Os valores \ndos par\u00e2metros utilizados para estimar o tempo total gasto da opera\u00e7\u00e3o \nrealizada no po\u00e7o foram retirados de um banco de dados hist\u00f3ricos de uma  \ncompanhia petrol\u00edfera. As correla\u00e7\u00f5es e as caracter\u00edsticas destes par\u00e2metros foram \ndetectadas utilizando-se de uma rede neural competitiva conectada a uma rede \nneural direta que foi treinada para estimar a m\u00e9dia, o desvio padr\u00e3o e o tempo \ntotal gasto na opera\u00e7\u00e3o realizada no po\u00e7o. S\u00e3o apresentados os \nexperimentos realizados para valida\u00e7\u00e3o do modelo e os resultados s\u00e3o  \nutilizados para avaliar o desempenho e validade da proposta. Uma das vantagens da \nmetodologia proposta, est\u00e1 no fato de ser uma ferramenta simples e pr\u00e1tica \npara obten\u00e7\u00e3o de uma estimativa do tempo total de uma opera\u00e7\u00e3o realizada \nsobre um po\u00e7o de petr\u00f3leo baseado em par\u00e2metros geom\u00e9tricos e \ntecnol\u00f3gicos, sem a necessidade de especificar todas as sub-opera\u00e7\u00f5es de \nperfura\u00e7\u00e3o e completa\u00e7\u00e3o como acontece nos m\u00e9todos tradicionais de analise \nde risco. \n\nPalavras-chave: Redes Neurais Artificiais, An\u00e1lise de Risco e Reconhecimento de \nPadr\u00f5es. \n\n\n\n \n\n \n\n10\n\n \n\nABSTRACT \n \n\n \n\nThis dissertation\u2019s objective is to demonstrate how the connectionist approach can \nbe used in the evaluation and prediction of the total time spent in drilling and \ncompletion operations of oil wells in deep waters. The parameter values utilized to \nestimate the total time spent in oil well operations were taken from an oil company\u2019s \nhistorical data bank. The correlation and characteristics of these parameters were \ndetected using a competitive neural network connected to a feedforward neural network \nthat was trained to estimate the average values, the standard deviation and the total time \nspent in the realization of the oil well operation. \n\nThe experiments created to validate the model are presented, and the results are \nutilized to evaluate the performance and validity of the proposition. One of the \nadvantages of the proposed methodology is the fact that it\u2019s a simple and practical tool. \nIt can be used to estimate the total time spent in an oil well operation, based on \ngeometric and technological parameters, without the need to specify all the drilling and \ncompletion sub-operations, unlike the traditional methods of risk analysys. \n\nKey Words: Neural Networks, Risk Analisis, Pattern Recognition. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\n\n\n \n\n \n\n11\n\n \n\nCap\u00edtulo 1 \n \n\n1.1 Introdu\u00e7\u00e3o \n \n\nApesar do petr\u00f3leo ser a maior fonte de energia utilizada atualmente pelo homem, \n\nesta \u00e9 uma fonte energ\u00e9tica n\u00e3o-renov\u00e1vel, cujas reservas estimadas podem se esgotar \n\nem aproximadamente 4 ou 5 d\u00e9cadas. Ainda assim, a explora\u00e7\u00e3o petrol\u00edfera \u00e9 uma \n\natividade econ\u00f4mica na qual s\u00e3o investidos bilh\u00f5es de d\u00f3lares todo ano e onde est\u00e3o \n\nenvolvidos complexos problemas de decis\u00e3o, de conhecimento, de risco, de incertezas e \n\nonde se busca atingir o objetivo de encontrar mais petr\u00f3leo (SILVA, 2000). Segundo \n\nestudos publicados na internet (ALEKLETT &amp; CAMPBELL, 2005) pela ASPO News \n\n(The Association for the Study of Peak Oil), as atividades de explora\u00e7\u00e3o ainda \n\nrequisitar\u00e3o significativas melhorias cient\u00edficas, tecnol\u00f3gicas e gerenciais pelo menos \n\ndurante o primeiro quarto do s\u00e9culo XXI. \n\nO Brasil est\u00e1 buscando a auto-sufici\u00eancia na produ\u00e7\u00e3o de petr\u00f3leo, entretanto, o \n\npico na produ\u00e7\u00e3o brasileira de petr\u00f3leo em terra foi atingido em 1997. Hoje em dia a \n\nmaior parte das novas reservas brasileiras de petr\u00f3leo est\u00e3o localizadas em \u00e1guas \n\nprofundas, o que leva o pa\u00eds a investir em novas tecnologias e modelos para explora\u00e7\u00e3o \n\ne produ\u00e7\u00e3o de petr\u00f3leo. (SILVA, 2000). \n\nA explora\u00e7\u00e3o de petr\u00f3leo em \u00e1guas profundas \u00e9 uma tarefa complexa e sujeita a \n\num grande n\u00famero de falhas, pois acontece num ambiente extremamente hostil onde \n\nqualquer pequeno erro pode causar um grande problema. No processo de perfura\u00e7\u00e3o de \n\npo\u00e7os de petr\u00f3leo nestas condi\u00e7\u00f5es s\u00e3o utilizadas as mais modernas tecnologias de \n\nperfura\u00e7\u00e3o de po\u00e7os. Toda essa tecnologia tem um custo elevado, que aumenta ainda \n\nmais com as falhas ocorridas durante o processo. S\u00f3 para se ter uma id\u00e9ia, segundo \n\nTHOMAS (1996), o aluguel de uma sonda de perfura\u00e7\u00e3o custa em torno de US$ \n\n180.000 / dia. Esse custo alto do aluguel da sonda faz com que as opera\u00e7\u00f5es envolvidas \n\nno processo de perfura\u00e7\u00e3o e explora\u00e7\u00e3o de petr\u00f3leo sejam extensamente planejadas e \n\nsimuladas antes de sua execu\u00e7\u00e3o. \n\nA previs\u00e3o do tempo gasto com opera\u00e7\u00f5es de perfura\u00e7\u00e3o e completa\u00e7\u00e3o \n\n(seq\u00fc\u00eancia de tarefas realizadas sobre um po\u00e7o visando prepar\u00e1-lo para a produ\u00e7\u00e3o) de \n\npo\u00e7os de petr\u00f3leo ou g\u00e1s est\u00e1 sujeita a uma s\u00e9rie de incertezas e fatores de risco. Este \n\nrisco est\u00e1 associado ao conhecimento limitado dispon\u00edvel sobre as caracter\u00edsticas \n\n\n\n \n\n \n\n12\n\n \n\ngeol\u00f3gicas da forma\u00e7\u00e3o, das dificuldades t\u00e9cnicas e dos comportamentos imprevistos de \n\noperadores humanos (JACINTO, 2002). O planejamento e a an\u00e1lise de risco destas \n\natividades s\u00e3o influenciados por eventos inesperados, tais como: \u201ckick\u201d (perda de \n\ncontrole do flu\u00eddo de perfura\u00e7\u00e3o) e perda de circula\u00e7\u00e3o ou colapso do po\u00e7o. Estes \n\neventos levam a perdas de tempo, aumento de custos, decl\u00ednio da produ\u00e7\u00e3o ou at\u00e9 \n\nmesmo a perda do po\u00e7o. \n\nT\u00e9cnicas de an\u00e1lise de risco e gerenciamento de opera\u00e7\u00f5es de explora\u00e7\u00e3o \n\npetrol\u00edfera est\u00e3o crescendo a n\u00edvel mundial e v\u00e1rias companhias internacionais t\u00eam \n\nmelhorado seu desempenho utilizando t\u00e9cnicas de an\u00e1lise de risco combinadas a novas \n\ntecnologias de an\u00e1lise de dados. Entre os estudiosos desta especificidade cita-se \n\nHARBAUGH et all (1995) e ROSE (2001). \n\nEm um po\u00e7o de petr\u00f3leo s\u00e3o realizados v\u00e1rios tipos de interven\u00e7\u00f5es: perfura\u00e7\u00e3o \n\nexplorat\u00f3ria, completa\u00e7\u00e3o, restaura\u00e7\u00e3o etc. Essas interven\u00e7\u00f5es s\u00e3o compostas por \n\nopera\u00e7\u00f5es do tipo: Canhoneio, Instala\u00e7\u00e3o de BOP, Abandono de po\u00e7o, Retirada de BOP \n\netc. Atualmente a maior parte das t\u00e9cnicas de an\u00e1lise e previs\u00e3o de custo (tempo) s\u00e3o \n\nbaseadas em simula\u00e7\u00f5es num\u00e9ricas das opera\u00e7\u00f5es envolvidas no processo de perfura\u00e7\u00e3o \n\ne completa\u00e7\u00e3o. Neste tipo de sistema, todas as opera\u00e7\u00f5es envolvidas no processo de \n\nperfura\u00e7\u00e3o e completa\u00e7\u00e3o s\u00e3o simuladas numericamente. O usu\u00e1rio do sistema necessita \n\nentrar com todas as opera\u00e7\u00f5es que ser\u00e3o realizadas, bem como as \u201cfun\u00e7\u00f5es de tempo\u201d \n\n(fun\u00e7\u00f5es de distribui\u00e7\u00e3o probabil\u00edstica do tempo gasto na opera\u00e7\u00e3o). As \u201cfun\u00e7\u00f5es de \n\ntempo\u201d s\u00e3o fun\u00e7\u00f5es de probabilidade que no momento da simula\u00e7\u00e3o, retornam o valor \n\nde tempo para a dada opera\u00e7\u00e3o estando baseadas numa distribui\u00e7\u00e3o de probabilidades. \n\nO m\u00e9todo tradicional possui algumas caracter\u00edsticas que muitas vezes o \n\nimpossibilita de ser utilizado numa an\u00e1lise r\u00e1pida. Entre estas, ressalta-se a necessidade \n\nde conhecer antecipadamente todas as opera\u00e7\u00f5es envolvidas na interven\u00e7\u00e3o a ser \n\nsimulada e, al\u00e9m disso, deve-se conhecer a distribui\u00e7\u00e3o de probabilidade do tempo de \n\ntodas as opera\u00e7\u00f5es.  \n\nO Sistema proposto nesta disserta\u00e7\u00e3o apresenta uma abordagem alternativa e \n\nsimplificada para a estimativa do tempo total de interven\u00e7\u00f5es de perfura\u00e7\u00e3o e \n\ncompleta\u00e7\u00e3o de po\u00e7os de petr\u00f3leo, baseada em dados hist\u00f3ricos. Esse Sistema tem como \n\nobjetivo calcular o tempo de uma interven\u00e7\u00e3o utilizando-se de uma extensa base de \n\ndados pertencente \u00e0 companhia petrol\u00edfera. Para isso, o Sistema utiliza uma arquitetura \n\n\n\n \n\n \n\n13\n\n \n\nneural, arquitetura essa utilizada no processo de generaliza\u00e7\u00e3o dos dados hist\u00f3ricos. A \n\narquitetura adotada no Sistema possibilita que um cen\u00e1rio (uma bacia, um campo de \n\npetr\u00f3leo ou mesmo todos os campos de uma empresa) seja apresentado ao Sistema e \n\nutilizados em seu treinamento. Tendo treinado o Sistema, a avalia\u00e7\u00e3o de uma \n\ninterven\u00e7\u00e3o pertencente ao cen\u00e1rio treinado ou a um cen\u00e1rio similar \u00e9 uma tarefa \n\nsimples e r\u00e1pida que n\u00e3o exige um planejamento das opera\u00e7\u00f5es. \n\n \n\n1.2 Objetivos \n\n \n1.2.1 Objetivo Geral \n\n \nPropor uma arquitetura neural para extra\u00e7\u00e3o de conhecimento hist\u00f3rico de bases \n\nde dados e sua utiliza\u00e7\u00e3o para poss\u00edveis previs\u00f5es. \n\n \n\n1.2.2 Objetivos Espec\u00edficos \n\n \na) Estudar t\u00e9cnicas de descoberta de conhecimento em bases de dados e de \n\nreconhecimento de padr\u00f5es; \n\nb) Estudar m\u00e9todos para utiliza\u00e7\u00e3o de redes neurais em aplica\u00e7\u00f5es de auxilio a \n\ntomada de decis\u00e3o; \n\nc) Estudar os processos envolvidos na perfura\u00e7\u00e3o e completa\u00e7\u00e3o de po\u00e7os de \n\npetr\u00f3leo; \n\nd) Desenvolver uma t\u00e9cnica que possibilite a previs\u00e3o dos tempos de interven\u00e7\u00f5es \n\nbaseados em dados hist\u00f3ricos e represente esta previs\u00e3o como uma distribui\u00e7\u00e3o de \n\nprobabilidades associadas \u00e0 incerteza da previs\u00e3o; \n\ne) Avaliar os resultados obtidos da utiliza\u00e7\u00e3o da t\u00e9cnica proposta. \n\n \n\n1.3 Metodologia \n\n \n Tendo definido o problema, parte-se para a defini\u00e7\u00e3o da metodologia a ser \n\nutilizada. Inicialmente foi feito um trabalho de pesquisa dentro do escopo do problema, \n\nesta pesquisa foi realizada buscando-se, na literatura, fontes que descrevessem as \n\n\n\n \n\n \n\n14\n\n \n\nt\u00e9cnicas de descoberta de conhecimento em bases de dados, Reconhecimento de \n\npadr\u00f5es, Perfura\u00e7\u00e3o de po\u00e7os de petr\u00f3leo, T\u00e9cnicas de an\u00e1lise de risco e Redes Neurais \n\nArtificiais.   \n\nAp\u00f3s esta pesquisa, iniciou-se a prototipa\u00e7\u00e3o de poss\u00edveis arquiteturas, sempre \n\nbuscando uma arquitetura que melhor se adaptasse aos requisitos do Sistema.  \n\nAo definir-se a arquitetura ideal, iniciou-se a fase de projeto onde foram tratados \n\nalguns detalhes que influenciavam a precis\u00e3o do Sistema. Com o projeto pronto foi \n\nrealizada a fase de implementa\u00e7\u00e3o. \n\nEm seguida o Sistema passou por uma fase de testes objetivando a valida\u00e7\u00e3o do \n\nmodelo. Para isto foi utilizada uma fra\u00e7\u00e3o da base de dados, fra\u00e7\u00e3o esta n\u00e3o utilizada \n\nnos treinamentos. Esse conjunto de testes foi apresentado ao Sistema e seus resultados \n\nforam comparados com os valores reais sendo retiradas assim as conclus\u00f5es sobre a \n\nprecis\u00e3o e confiabilidade do sistema. \n \n\n1.4 Estrutura do Texto \n\n \n No cap\u00edtulo 2 trata-se da base te\u00f3rica sobre extra\u00e7\u00e3o de conhecimentos de bases \n\nde dados, reconhecimento de padr\u00f5es e redes neurais.  \n\nNo cap\u00edtulo 3 \u00e9 dada uma breve explica\u00e7\u00e3o sobre os processos envolvidos na \n\nperfura\u00e7\u00e3o e completa\u00e7\u00e3o de po\u00e7os de petr\u00f3leo. \n\nNo cap\u00edtulo 4 s\u00e3o descritos detalhadamente todo o processo envolvido na \n\nelabora\u00e7\u00e3o da proposta adotada e no projeto e na implementa\u00e7\u00e3o do sistema. \n\nNo cap\u00edtulo 5 s\u00e3o descritos os testes de valida\u00e7\u00e3o realizados com o sistema, al\u00e9m \n\ndo modelo proposto e seu grau de confiabilidade. \n\nNo cap\u00edtulo 6 s\u00e3o apresentadas as conclus\u00f5es ontidas do sistema e do modelo, \n\nbem como as sugest\u00f5es para poss\u00edveis melhorias e trabalhos futuros. \n\n \n\n\n\n \n\n \n\n15\n\n \n\nCAP\u00cdTULO 2 \u2013  REDES NEURAIS, MINERA\u00c7\u00c3O DE DADOS E \nRECONHECIMENTO DE PADR\u00d5ES \n \n\n No processo de an\u00e1lise do problema, procurou-se um conjunto de metodologias \ne t\u00e9cnicas que, ao ser implementado em um sistema, fosse capaz de fazer uma previs\u00e3o \n\nv\u00e1lida para tempos de interven\u00e7\u00f5es envolvidas no processo de perfura\u00e7\u00e3o de po\u00e7os de \n\npetr\u00f3leo. Esta an\u00e1lise demonstrou estar-se diante de um problema de Descoberta de \n\nConhecimento em Base de Dados (KDD \u2013 Knowledge Discovery Database), pois esta \n\nprevis\u00e3o deveria levar em conta aspectos gerais da opera\u00e7\u00e3o, tais como fatores \n\ngeol\u00f3gicos, tecnol\u00f3gicos e humanos, e ser baseada em dados hist\u00f3ricos, ao inv\u00e9s do \n\nm\u00e9todo tradicional de estimativa que envolve a simula\u00e7\u00e3o da seq\u00fc\u00eancia das opera\u00e7\u00f5es \n\nde engenharia de po\u00e7o que devem ser realizadas no processo de perfura\u00e7\u00e3o e \n\ncompleta\u00e7\u00e3o do po\u00e7o. Estes atributos est\u00e3o geralmente presentes em bases de dados das \n\ngrandes companhias de petr\u00f3leo, entretanto, uma an\u00e1lise mais profunda mostrou que \n\nesta aplica\u00e7\u00e3o vai al\u00e9m das principais tarefas normalmente associadas \u00e0s aplica\u00e7\u00f5es de \n\nKDD, tais como, associa\u00e7\u00e3o, classifica\u00e7\u00e3o ou agrupamento de vari\u00e1veis do problema, \n\nenvolvendo tamb\u00e9m a Minera\u00e7\u00e3o de Dados e o Reconhecimento de Padr\u00f5es existentes \n\nna base hist\u00f3rica e um processo de previs\u00e3o ou estimativa de tempos de perfura\u00e7\u00e3o de \n\nnovos po\u00e7os. \n\n \n\n2.1 Descoberta de Conhecimento em Bases de Dados \n\n \nO avan\u00e7o de tecnologia tornou acess\u00edveis ferramentas que possibilitam o ac\u00famulo \n\nde grande quantidade de dados. A conseq\u00fc\u00eancia \u00e9 a amplia\u00e7\u00e3o do uso dos Data \n\nWarehouses, grandes reposit\u00f3rios de dados, agregados de forma organizada e eficiente, \n\ne em geral, de natureza hist\u00f3rica. Essa grande quantidade de dados armazenados est\u00e1 \n\ncada vez sendo mais valorizada. Muitas empresas utilizam-se de profissionais \n\nespecializados para vasculhar suas Data Warehouses em busca de padr\u00f5es e tend\u00eancias. \n\nEntretanto, a an\u00e1lise dos dados de uma Data Warehouses por um especialista \u00e9 um \n\nprocesso demorado, dispendioso e sujeito a erros. Assim sendo, torna-se necess\u00e1ria uma \n\nforma de an\u00e1lise, interpreta\u00e7\u00e3o e aquisi\u00e7\u00e3o de dados automatizada. Motivadas por essa \n\ntend\u00eancia, as t\u00e9cnicas de Descoberta de Conhecimento em Bases de Dados est\u00e3o \n\ntornando-se cada vez mais refinadas, complexas e indispens\u00e1veis (DATA \n\n\n\n \n\n \n\n16\n\n \n\nWAREHOUSE, 2000). Estas t\u00e9cnicas normalmente servem para auxiliar o especialista \n\nno cumprimento de suas tarefas.  \n\n \n\n2.2 O Processo KDD \n\n \nO KDD \u00e9 na verdade a aplica\u00e7\u00e3o de um conjunto de t\u00e9cnicas com o objetivo de \n\nextrair conhecimentos de uma base de dados. Enquanto um c\u00e9rebro humano, \n\ncomprovadamente, consegue fazer at\u00e9 oito compara\u00e7\u00f5es ao mesmo tempo (DATA \n\nWAREHOUSE, 2000), um sistema de KDD consegue fazer milhares de compara\u00e7\u00f5es e \n\nencontrar padr\u00f5es impercept\u00edveis a um ser humano. O KDD \u00e9 basicamente a aplica\u00e7\u00e3o \n\nde t\u00e9cnicas estat\u00edsticas, matem\u00e1ticas e de IA para a extra\u00e7\u00e3o de conhecimento de uma \n\nbase de dados. Segundo DATA WAREHOUSE (2000), usualmente um processo de \n\nKDD segue alguns passos:  \n\n \na) Limpeza dos dados: para remover ru\u00eddos e inconsist\u00eancia nos \ndados; \nb) Integra\u00e7\u00e3o de dados: onde m\u00faltiplas fontes de dados podem ser \ncombinadas; \nc) Transforma\u00e7\u00e3o nos dados: onde dados s\u00e3o transformados em \npadr\u00f5es mais simples de serem trabalhados; \nd) Minera\u00e7\u00e3o nos dados: m\u00e9todos (estat\u00edsticos, de IA,....) s\u00e3o \naplicados para extrair padr\u00f5es dos dados; \ne) Avalia\u00e7\u00e3o de padr\u00f5es: medidas que avaliam o qu\u00e3o interessante \u00e9 \ncada padr\u00e3o, ou seja, o qu\u00e3o relevante \u00e9 o padr\u00e3o em rela\u00e7\u00e3o aos \ndados avaliados e \nf) Apresenta\u00e7\u00e3o do conhecimento: t\u00e9cnicas de visualiza\u00e7\u00e3o e de \nrepresenta\u00e7\u00e3o do conhecimento. \n\n \n\n2.3 Minera\u00e7\u00e3o de Dados \n\n \nA Minera\u00e7\u00e3o de Dados (Data Mining) \u00e9 considerada por muitos autores como a \n\nfase mais importante do processo de KDD. \u00c9 nesta fase que geralmente \u00e9 feita a \n\ndescoberta de conhecimento ou de padr\u00f5es, para a solu\u00e7\u00e3o do problema. \n\nA minera\u00e7\u00e3o de dados nada mais \u00e9 do que um processo de reconhecimento de \n\npadr\u00f5es existentes em uma base de dados. No t\u00f3pico 2.4 tratara-se das t\u00e9cnicas \n\nutilizadas para reconhecimento de padr\u00f5es. \n\n \n\n\n\n \n\n \n\n17\n\n \n\n \n\n2.4 Reconhecimento de Padr\u00f5es \n\n \nSCHALKOFF (1992), apresenta que as  \n\n \nT\u00e9cnicas de Reconhecimento de Padr\u00f5es (RP) tem sido uma \nimportante componente de sistemas inteligentes e usada em muitos \nsistemas de pr\u00e9-processamento de dados e tomadas de decis\u00e3o. \nSimplificando, reconhecimento de padr\u00f5es (RP) \u00e9 uma ci\u00eancia que se \nconcentra na descri\u00e7\u00e3o ou classifica\u00e7\u00e3o (reconhecimento) de \nmedidas. \n\n \n\nAssim sendo, t\u00e9cnicas de reconhecimento de padr\u00f5es podem se utilizadas como \n\nt\u00e9cnicas de pr\u00e9-processamento de dados em sistemas de auxilio para tomada de decis\u00e3o. \n\nTamb\u00e9m podem ser utilizadas para o agrupamento e classifica\u00e7\u00e3o de grandes \n\nquantidades de dados. \n\nDe acordo com SCHALKOFF (1992), existem tr\u00eas abordagens correlatas para \n\nreconhecimento de padr\u00f5es: \n\na) Abordagem Estat\u00edstica de Reconhecimento de Padr\u00f5es. \n\nb) Abordagem Sint\u00e1tica de Reconhecimento de Padr\u00f5es. \n\nc) Abordagem Neural de Reconhecimento de Padr\u00f5es. \n\n \n\n2.4.1 Abordagem Estat\u00edstica de Reconhecimento de Padr\u00f5es (AERP) \n\n \n Uma abordagem estat\u00edstica para reconhecimento de padr\u00f5es assume uma base \n\nestat\u00edstica, ou seja, algoritmos matem\u00e1ticos normalmente baseados para classifica\u00e7\u00e3o. \n\nEsta base estat\u00edstica \u00e9 utilizada na obten\u00e7\u00e3o de um conjunto de caracter\u00edsticas \n\nmensur\u00e1veis, que s\u00e3o extra\u00eddas dos dados de entrada, e s\u00e3o utilizados na cria\u00e7\u00e3o de \n\nvetores de caracter\u00edsticas para uma de cada n classes (SCHALKOFF, 1992). \n\nDuas das t\u00e9cnicas que seguem uma abordagem estat\u00edstica para reconhecimento de \n\npadr\u00f5es s\u00e3o as t\u00e9cnicas de An\u00e1lise de Cluster e Regress\u00e3o. Essas t\u00e9cnicas s\u00e3o descritas \n\nnos t\u00f3picos 2.4.1.1 e 2.4.1.2. \n\n \n\n \n\n\n\n \n\n \n\n18\n\n \n\n \n\n2.4.1.1 An\u00e1lise de Cluster \n\n \nSegundo HAN, J. &amp; KAMBER (2000), o processo de agrupar um conjunto de \n\nobjetos f\u00edsicos ou abstratos em classes de objetos similares \u00e9 chamado de clusteriza\u00e7\u00e3o. \n\nUm cluster \u00e9 uma cole\u00e7\u00e3o de dados com similaridades a outros dados do mesmo cluster \n\ne diferen\u00e7as a objetos de outros clusters. Um cluster de dados pode ser tratado \n\ncoletivamente em v\u00e1rias aplica\u00e7\u00f5es. O termo cluster, aglomerado ser\u00e1 mantido em \n\ningl\u00eas nesta disserta\u00e7\u00e3o, pois se trata de um termo bem difundido dentro das Ci\u00eancias da \n\nComputa\u00e7\u00e3o. \n\nNum escopo estat\u00edstico, an\u00e1lise de cluster foi extensamente estudada por v\u00e1rios \n\nanos, focada principalmente na an\u00e1lise de cluster baseada na dist\u00e2ncia. Ferramentas de \n\nan\u00e1lise de cluster baseadas em k-media, e alguns outros m\u00e9todos s\u00e3o implementados na \n\nmaioria dos pacotes de programas para estat\u00edstica. \n\nEm aprendizado de m\u00e1quina, an\u00e1lise de cluster refere-se \u00e0 aprendizagem n\u00e3o \n\nsupervisionada. Diferente da classifica\u00e7\u00e3o, a clusteriza\u00e7\u00e3o n\u00e3o somente trabalha com \n\nclasses pr\u00e9 definidas, mas suas classes s\u00e3o criadas a partir do conjunto de treinamento. \n\nPor essa raz\u00e3o essa \u00e9 uma forma de aprendizagem por observa\u00e7\u00e3o, isto \u00e9, aprendendo \n\npor exemplos.  \n\n \n\n2.4.1.2 Regress\u00e3o \n\n \nSegundo HAN &amp; KAMBER (2000), numa regress\u00e3o linear os dados s\u00e3o \n\nmodelados utilizando-se uma linha reta. Regress\u00e3o linear \u00e9 a forma mais simples de \n\nregress\u00e3o. Regress\u00e3o linear bi-vari\u00e1vel modelam uma vari\u00e1vel rand\u00f4mica, Y (chamada \n\nde vari\u00e1vel resposta), sendo uma fun\u00e7\u00e3o linear de outra vari\u00e1vel rand\u00f4mica, X (chamada \n\nde vari\u00e1vel de predi\u00e7\u00e3o). \n\nY = ? + ?X. \n\nOnde a varia\u00e7\u00e3o de Y \u00e9 assumida como sendo constante, e ? e ? s\u00e3o coeficientes \n\nde regress\u00e3o especificando a intercess\u00e3o com Y e a inclina\u00e7\u00e3o da linha. Os coeficientes \n\npodem ser resolvidos utilizando-se o m\u00e9todo do m\u00ednimo quadrado, o qual minimiza o \n\nerro entre a linha atual que separa os dados e a linha estimada. \n\n\n\n \n\n \n\n19\n\n \n\n Regress\u00e3o m\u00faltipla \u00e9 uma extens\u00e3o da regress\u00e3o linear envolvendo mais de uma \n\nvari\u00e1vel de predi\u00e7\u00e3o. Isso habilita a vari\u00e1vel de resposta Y a ser modelada por uma \n\nfun\u00e7\u00e3o linear de um vetor multidimensional de atributos. \n\n \n\n2.4.2 Abordagem Sint\u00e1tica de Reconhecimento de Padr\u00f5es (ASRP) \n\n \n Muitas vezes a informa\u00e7\u00e3o significativa de um padr\u00e3o n\u00e3o est\u00e1 meramente na \n\npresen\u00e7a, aus\u00eancia, ou no valor num\u00e9rico de um conjunto de caracter\u00edsticas. As inter-\n\nrela\u00e7\u00f5es e interconex\u00f5es entre elas possuem importantes informa\u00e7\u00f5es estruturais, e sua \n\nidentifica\u00e7\u00e3o facilita a descri\u00e7\u00e3o estrutural ou classifica\u00e7\u00e3o. Esta abordagem \u00e9 a base da \n\nabordagem sint\u00e1tica de reconhecimento de padr\u00f5es, ou seja, usando ASRP, se estar\u00e1 \n\napto a quantificar e extrair informa\u00e7\u00f5es estruturais e acessar a similaridade estrutural \n\nentre os padr\u00f5es, utilizando-se para isso de gram\u00e1ticas ou aut\u00f4matos. (SCHALKOFF, \n\n1992). \n\nUma das t\u00e9cnicas de reconhecimento de padr\u00f5es que utiliza uma abordagem \n\nsint\u00e1tica \u00e9 a t\u00e9cnica de \u00c1rvore de Decis\u00e3o que est\u00e1 descrita no t\u00f3pico 2.4.2.1. \n\n \n\n2.4.2.1 \u00c1rvore de Decis\u00e3o \n\n  \nSegundo HAN &amp; KAMBER, uma \u00e1rvore da decis\u00e3o \u00e9 uma estrutura em forma de \n\n\u00e1rvore, onde cada nodo interno denota um teste em um atributo, cada aresta representa \n\num resultado do teste e os nodos folha representam classes ou distribui\u00e7\u00f5es da classe.  O \n\nn\u00f3 mais alto em uma \u00e1rvore \u00e9 o n\u00f3 da raiz.  Uma \u00e1rvore de decis\u00e3o t\u00edpica \u00e9 mostrada na \n\nFig. 2.1. Representa o conceito compra de computador, predizendo se um consumidor \n\nda AllEletronics tem tend\u00eancia a comprar um computador. Os nodos internos s\u00e3o \n\nrepresentados como ret\u00e2ngulos e os nodos folhas como ovais. A fim de classificar uma \n\namostra desconhecida os valores dos atributos de um exemplo s\u00e3o testados na \u00e1rvore de \n\ndecis\u00e3o.  Um caminho \u00e9 tra\u00e7ado da raiz at\u00e9 o nodo folha que contenha a classe de \n\npredi\u00e7\u00e3o para o dado exemplo. As \u00e1rvores da decis\u00e3o podem facilmente ser convertidas \n\npara regras de classifica\u00e7\u00e3o. \n\n \n\n\n\n \n\n \n\n20\n\n \n\n \nFIGURA 2.1 \u2013 Uma \u00e1rvore da decis\u00e3o para o conceito compra de computador, indicando se um cliente da \n\nAllElectronics \u00e9 um prov\u00e1vel comprador de computador. Cada nodo (n\u00e3o-folha) interno representa um \n\nteste em um atributo.  Cada nodo folha representa uma classe (comprador de computador = sim ou \n\ncomprador de computador = n\u00e3o) \n\n \n\n2.4.3 Abordagem Neural para Reconhecimento de Padr\u00f5es (ANRP) \n\n \n Modernos computadores digitais podem n\u00e3o emular o paradigma computacional \n\nde sistemas biol\u00f3gicos. A alternativa para computa\u00e7\u00e3o neural emerge das tentativas de \n\nconhecer como os sistemas neuronais biol\u00f3gicos armazenam e manipulam informa\u00e7\u00e3o, \n\nisso liga uma classe de sistemas neurais artificiais chamados redes neurais. \n\n(SCHALKOFF, 1992). \n\nA ANRP \u00e9 uma abordagem n\u00e3o algor\u00edtmica, estrat\u00e9gia do tipo caixa-preta, \n\ntrein\u00e1vel. O objetivo \u00e9 \u201ctreinar\u201d a caixa-preta neural para \u201caprender\u201d a correta resposta \n\nou sa\u00edda (neste caso classifica\u00e7\u00e3o) para cada exemplo do treinamento. Esta estrat\u00e9gia \u00e9 \n\natrativa para os projetistas de sistemas de reconhecimento de padr\u00f5es desde que \n\npossuam, antecipadamente, uma grande quantidade de conhecimento detalhado do \n\nfuncionamento interno do sistema sendo este requisito m\u00ednimo. Al\u00e9m disso, depois do \n\ntreinamento espera-se que a estrutura interna da rede neural se auto-organize para \n\n\n\n \n\n \n\n21\n\n \n\nhabilitar a extrapola\u00e7\u00e3o quando apresentada a um novo padr\u00e3o, seguindo as bases da \n\n\u201cexperi\u00eancia\u201d adquirida dos padr\u00f5es de treinamento. (SCHALKOFF, 1992). \n\nUma das t\u00e9cnicas de reconhecimento de padr\u00f5es que utiliza uma abordagem \n\nneural \u00e9 a t\u00e9cnica de Redes Neurais que est\u00e1 descrita no t\u00f3pico 2.4.3.1. \n\n \n\n2.4.3.1 Redes Neurais \n\n \nEm termos gerais uma rede neural \u00e9 um conjunto de entradas e sa\u00eddas conectadas \n\nonde cada conex\u00e3o tem um peso associado a ela.  Durante a fase da aprendizagem, a \n\nrede aprende ajustando os pesos para poder predizer corretamente a classe do exemplo \n\nde entrada.  A aprendizagem da rede neural tamb\u00e9m \u00e9 tratada como aprendizagem \n\nconexionista devido \u00e0s conex\u00f5es entre unidades. (HAN &amp; KAMBER, 2000) \n\nRedes neurais necessitam de longos tempos de treinamento e s\u00e3o, \n\nconseq\u00fcentemente, mais apropriadas para as aplica\u00e7\u00f5es onde este tempo \u00e9 aceit\u00e1vel.  A \n\nt\u00e9cnica requer um n\u00famero de par\u00e2metros que normalmente s\u00e3o determinados \n\nempiricamente, como a topologia ou \u201cestrutura\u201d da rede (Idem).  \n\nAs redes neurais foram criticadas por sua dificuldade de interpreta\u00e7\u00e3o, por conta \n\nda dificuldade dos humanos de interpretarem o significado escondido nos pesos da rede.  \n\nEstas caracter\u00edsticas tornaram inicialmente as redes neurais menos aconselh\u00e1veis para a \n\nminera\u00e7\u00e3o dos dados. (Idem). \n\nAs vantagens das redes neurais, entretanto, incluem sua toler\u00e2ncia elevada aos \n\ndados ruidosos e como sua habilidade em classificar padr\u00f5es em que n\u00e3o foram \n\ntreinadas.  Al\u00e9m disso, diversos algoritmos t\u00eam sido desenvolvidos recentemente para a \n\nextra\u00e7\u00e3o das regras ocultas nas redes neurais treinadas.  Estes fatores contribuem para a \n\nutilidade das redes neurais para a classifica\u00e7\u00e3o na minera\u00e7\u00e3o dos dados. (Idem). \n\n \n\n2.4.4 Compara\u00e7\u00e3o entre as Abordagens de Reconhecimento de Padr\u00f5es \n\n \n A tabela 2.1 exibe as caracter\u00edsticas de cada uma das abordagens utilizadas para \n\nreconhecimento dos padr\u00f5es. Como podemos ver a abordagem neural pode ser utilizada \n\npara previs\u00e3o do tempo de perfura\u00e7\u00e3o de po\u00e7os de petr\u00f3leo, pois nesse processo de \n\nprevis\u00e3o n\u00e3o estamos interessados no conte\u00fado sem\u00e2ntico dos dados, mas sim na \n\ncorrela\u00e7\u00e3o entre um novo po\u00e7o e os existentes na base de dados. \n\n\n\n \n\n \n\n22\n\n \n\n \n\nTabela 2.1 \u2013 Compara\u00e7\u00e3o entre as abordagens de reconhecimento de padr\u00f5es. \n \n\n Estatica (AERP) Sintatica \n(ASRP) \n\nNeural (ANRP)\n\n1 - Gera\u00e7\u00e3o de \nPadr\u00e3o B\u00e1sico \n\nModelos \nProbabil\u00edsticos \n\nGram\u00e1ticas Formais Estados Est\u00e1vel ou \nMatriz de Pesos \n\n2 \u2013 Classifica\u00e7\u00e3o \nde Padr\u00f5es \n(Reconhecimento/ \nDescri\u00e7\u00e3o) B\u00e1sico \n\nEstima\u00e7\u00e3o/ Teoria \nda Decis\u00e3o \n\nParser Baseado em \nPropriedades das \nRedes Neurais \n\n3 \u2013 Organiza\u00e7\u00e3o de \nCaracter\u00edsticas \n\nVetor de \nCaracter\u00edsticas \n\nPrimitivas e \nRela\u00e7\u00f5es \nObservadas \n\nEntradas dos \nNeur\u00f4nios ou \nEstados \nArmazenados \n\n4 \u2013 Abordagem \nT\u00edpica Para \nAprendizado \n(Treinamento) \n \nA - \nSupervisionado   \n \n \n \n \n \n \nB \u2013 N\u00e3o \nSupervisionado \n\n \n \n \n \n \nDensidade/ \nDistribui\u00e7\u00e3o \n(Usualmente \nParam\u00e9trico) \n \n \n \nClusterizando \n\n \n \n \n \n \nFormando \nGram\u00e1ticas ( \nHeur\u00edstica ou \nInfer\u00eancia \nGramatical) \n \n \nClusterizando \n\n \n \n \n \n \nDeterminando os \npar\u00e2metro da Rede \nNeural \n \n \n \n \nClusterizando \n\n5 - Limita\u00e7\u00f5es Dificuldade em \nexpressar \ninforma\u00e7\u00e3o \nestrutural \n\nDificuldade em \naprender regras \nestruturais \n\nFreq\u00fcentemente  a \nrede passa pouca \ninforma\u00e7\u00e3o \nsem\u00e2ntica \n\nFonte: SCHALKOFF, Robert. Pattern Recognition. New York: John Wiley &amp; Sons, Inc, 1992. \n \n \n\nSendo a proposta deste trabalho a utiliza\u00e7\u00e3o de uma abordagem neural para \n\nresolu\u00e7\u00e3o do problema, a sess\u00e3o 2.5 descreve o funcionamento das redes neurais. \n\nutilizadas neste trabalho. \n\n  \n\n \n\n\n\n \n\n \n\n23\n\n \n\n2.5 Redes Neurais \n\n \n O nosso c\u00e9rebro \u00e9 composto por aproximadamente 100 bilh\u00f5es de neur\u00f4nios, \n\nestas pequenas c\u00e9lulas componentes do nosso sistema nervoso, atuam sobre todas as \n\nfun\u00e7\u00f5es e movimentos do nosso organismo. O neur\u00f4nio tem um corpo celular chamado \n\nsoma e diversas ramifica\u00e7\u00f5es, as ramifica\u00e7\u00f5es conhecidas como dendritos, conduzem \n\nsinais das extremidades para o corpo celular. Existe tamb\u00e9m uma ramifica\u00e7\u00e3o \n\ngeralmente \u00fanica chamada ax\u00f4nio que transmite as informa\u00e7\u00f5es do corpo celular para as \n\nsuas extremidades, as extremidades dos ax\u00f4nios s\u00e3o conectadas com dendritos de outros \n\nneur\u00f4nios pelas sinapses. Em muitos casos um neur\u00f4nio \u00e9 conectado com outros \n\nax\u00f4nios ou com o corpo de outro neur\u00f4nio. O conjunto de todos os neur\u00f4nios \n\nconectados forma uma grande rede denominada Rede Neural. (BARRETO, 1999). \n\nAs sinapses transmitem est\u00edmulos atrav\u00e9s de diferentes concentra\u00e7\u00f5es de Na+ \n\n(S\u00f3dio) e K+ (Pot\u00e1ssio) e o resultado disto pode ser estendido por todo o corpo humano. \n\nEsta grande rede proporciona uma fabulosa capacidade de processamento e \n\narmazenamento de informa\u00e7\u00e3o. (HAYKIN, 2001).  \n\nTendo como inspira\u00e7\u00e3o este sistema biol\u00f3gico surgiram varias t\u00e9cnicas de Redes \n\nNeurais Artificiais (RNAs), sendo que todas essas t\u00e9cnicas baseiam-se em modelos de \n\nneur\u00f4nios artificiais implementados de forma a possuir algumas das caracter\u00edsticas de \n\nneur\u00f4nios biol\u00f3gicos, essas t\u00e9cnicas de RNAs est\u00e3o em sua maioria fundadas sobre o \n\nfato da intelig\u00eancia surgir atrav\u00e9s do peso das conex\u00f5es sinapticas. \n\nExistem v\u00e1rias topologias de redes neurais diferentes e tamb\u00e9m muitas formas de \n\ntrein\u00e1-las. As principais topologias s\u00e3o as redes diretas e as redes recorrentes e cada \n\ntopologia possui formas diferentes de treinamento. Nas se\u00e7\u00f5es seguintes ser\u00e3o \n\nabordadas as topologias de redes neurais utilizados no Sistema. \n\n \n\n2.5.1 Redes Diretas \n\n \n As redes diretas, ou \u201cfeedforward\u201d s\u00e3o redes neurais cujo grafo n\u00e3o possui ciclos \n\ne geralmente est\u00e3o representadas em camadas. Nestas redes, os neur\u00f4nios de uma \n\ncamada i transmitem seu sinal de sa\u00edda para os neur\u00f4nios de uma camada j, onde j > i.. \n\nPor exemplo, os neur\u00f4nios que recebem sinais de excita\u00e7\u00e3o do meio externo est\u00e3o na \n\ncamada de entrada, os neur\u00f4nios que est\u00e3o na sa\u00edda s\u00e3o chamados de camada de sa\u00edda, e \n\n\n\n \n\n \n\n24\n\n \n\nos que n\u00e3o pertencem nem a camada de entrada e nem a camada de sa\u00edda s\u00e3o os \n\nneur\u00f4nios internos, pertencentes \u00e0 camada intermedi\u00e1ria. \n\nEsta topologia \u00e9 uma das mais conhecidas e utilizadas, principalmente pelo fato de \n\nque a implementa\u00e7\u00e3o de m\u00e9todos de aprendizado para estas redes ser mais simples. O \n\nalgoritmo \u201c\u201dbackpropagation\u201d \u00e9 um dos mais utilizados nestas redes. (DAYHOFF, \n\n1990). \n\n \nFIGURA  2.2 \u2013 Exemplo de Rede Direta \n\n \n\n2.5.2 Aprendizagem Supervisionada \n\n \n Neste tipo de aprendizado, um \u201cprofessor\u201d indica se o comportamento da rede \u00e9 \n\nbom ou ruim. Este m\u00e9todo de aprendizado \u00e9 o mais comum no treinamento das RNAs e \n\n\u00e9  chamado Aprendizado Supervisionado porque a o resultado desejado na sa\u00edda da rede \n\n\u00e9 fornecido por um \u201cprofessor\u201d externo. O objetivo \u00e9 ajustar os par\u00e2metros da rede de \n\nforma a encontrar uma liga\u00e7\u00e3o entre os pares de entrada e sa\u00edda fornecidos.  \n\n \n\n \nFIGURA 2.3 \u2013 Aprendizado supervisionado. \n\n \n\n\n\n \n\n \n\n25\n\n \n\nNo aprendizado supervisionado, a cada exemplo colocado na entrada da rede, a \n\nsa\u00edda obtida nos neur\u00f4nios de sa\u00eddas \u00e9 comparada com os resultados desejados e o \n\nprofessor, atrav\u00e9s do erro obtido, supervisiona o ajuste dos pesos de forma com que a \n\nrede possa direcionar o seu aprendizado para a resposta correta, ou seja, os pesos s\u00e3o \n\najustados de forma a minimizar o erro.  \n\nO algoritmo de Retropropaga\u00e7\u00e3o de Erros (Error Backpropagation) \u00e9 o algoritmo \n\nmais conhecido de aprendizagem supervisionada para redes de camadas.  \n\n \n\n2.5.3 Retropropaga\u00e7\u00e3o de Erros \n\n \nNesta se\u00e7\u00e3o o algoritmo de Retropopaga\u00e7\u00e3o de Erros est\u00e1 descrito de forma \n\nsimplificada, este algoritmo foi retirado de  BARRETO (1992). \n\nO Algoritmo:  \n\n1. \u201cSeja A, o n\u00famero de neur\u00f4nios da camada de entrada, conforme \n\ndeterminado pelo comprimento dos vetores de entrada de treinamento,C, o \n\nn\u00famero de neur\u00f4nios da camada de sa\u00edda. Escolha B, o n\u00famero de \n\nneur\u00f4nios da camada intermedi\u00e1ria. Geralmente as camadas de entrada e \n\nintermedi\u00e1ria t\u00eam, cada uma, um neur\u00f4nios extra, usado como polariza\u00e7\u00e3o \n\n(\u201cbias\u201d), portanto, usa-se os intervalos (0, ... ,A) e (0, ... ,B) para estas \n\ncamadas, especificamente.\u201d \n\n2. \u201cInicialize os pesos da rede. Cada peso deve ajustado aleatoriamente.\u201d \n\n3. \u201cInicialize as ativa\u00e7\u00f5es dos neur\u00f4nios com bias, ou seja x0 = 1 e h0 = 1;\u201d \n\n4. \u201cEscolha um par entrada-sa\u00edda. Suponha que o vetor de entrada seja Xl, e \n\nque o vetor de sa\u00edda desejada seja Yl, Atribua n\u00edveis de ativa\u00e7\u00e3o, aos \n\nneur\u00f4nios da camada de entrada.\u201d \n\n5. \u201cPropague a ativa\u00e7\u00e3o dos neur\u00f4nios da camada de entrada para os da \n\ncamada de intermedi\u00e1ria, usando-se como sugest\u00e3o, a fun\u00e7\u00e3o sigm\u00f3ide \n\nunipolar.\u201d  \n\nBk\ne\n\nH ak ,,1,1\n1\n\n???=?\n+\n\n=  \n\n Onde: \n\n\n\n \n\n \n\n26\n\n \n\n?\n=\n\n=\nA\n\nl\nllk XWa\n\n0\n)1(  \n\n6.  \u201cPropague a ativa\u00e7\u00e3o dos neur\u00f4nios da camada intermedi\u00e1ria para os da \n\ncamada de sa\u00edda.\u201d \n\nCk\ne\n\nY ak ,,,1\n1\n\n????\n+\n\n=  \n\n Onde: \n\n?\n=\n\n=\nB\n\nl\nllk HWa\n\n0\n)2(  \n\n \n\n7. \u201cCompute os erros dos neur\u00f4nios da camada de sa\u00edda, denotado por ?2k.\u201d \n\nCkYTYY kkkkk ,,1),)(1(2 ???=???=?  \n\n8. \u201cCompute os erros dos neur\u00f4nios da camada intermedi\u00e1ria, denotada por \n\n?1k.\u201d \n\nBkWHH\nC\n\nl\nlklkkk ,,1,22)1(1\n\n1\n???=??= ?\n\n=\n\n??  \n\n9. \u201cAjuste os pesos, entre a camada intermedi\u00e1ria e a de sa\u00edda. O coeficiente \n\nde aprendizagem \u00e9 denotado por ?.\u201d \n\nCkBlHW lkllk ,,0;,,0,22 ???=????=?=? ??  \n\n10. \u201cAjuste os pesos entre a camada de entrada e a intermedi\u00e1ria.\u201d \n\nBkAlXW lklk ,,1;,,0,11 ???=????=?=? ??  \n\n11. \u201cV\u00e1 para a etapa 4 e repita. Quando todos pares entrada-sa\u00edda, tiverem \n\nsido apresentados \u00e0 rede, uma \u00e9poca ter\u00e1 sido completada. Repita as etapas \n\nde 4 a 10, para tantas \u00e9pocas quanto forem desejadas.\u201d \n\n \n\nMaiores detalhes sobre o algoritmo de aprendizagem por retropropaga\u00e7\u00e3o de erros  \n\npodem ser encontrados em BARRETO (1999). \n\n \n\n \n\n \n\n \n\n\n\n \n\n \n\n27\n\n \n\n2.5.4 Rede Competitiva Simples \n\n \nRedes Competitivas Simples (RCS) s\u00e3o redes neurais onde o aprendizado emerge \n\nda competi\u00e7\u00e3o entre seus neur\u00f4nios. O resultado dessa competi\u00e7\u00e3o pode ser utilizado \n\npara classificar padr\u00f5es. \n\n \nA rede b\u00e1sica do aprendizado competitivo consiste de duas camadas \n\u2013 uma camada de entrada e uma camada competitiva. Na camada \ncompetitiva, as unidades competem pela oportunidade  de responder \naos padr\u00f5es de entrada.  A vencedora representa a categoria de \nclassifica\u00e7\u00e3o para o padr\u00e3o que entrou.  A competi\u00e7\u00e3o pode ser \nrealizada por meio de um algoritmo que designa a unidade vencedora, \nou, alternativamente, atrav\u00e9s da inibi\u00e7\u00e3o entre as unidades da camada \ncompetitiva.  No caso de inibi\u00e7\u00e3o, a camada competitiva progride a \num estado em que somente a unidade vencedora fica ativa \n(BARRETO, 1999). \n\n \n\n O treinamento de uma RCS consiste na apresenta\u00e7\u00e3o de cada exemplo \u00e0 rede. O \n\nneur\u00f4nio vencedor tem seus pesos atualizados de acordo com um passo alfa. Os \n\nexemplos s\u00e3o apresentados sucessivamente at\u00e9 que o erro da RCS seja aceit\u00e1vel. \n\nA arquitetura de uma rede competitiva pode ser vista na Fig. 2.4. \n\n \n\n \n\n \nFIGURA  2.4 \u2013 Arquitetura da Rede Competitiva. \n\n \n\n \n\n\n\n \n\n \n\n28\n\n \n\nComo se pode ver na Fig. 2.4 os neur\u00f4nios da camada de entrada s\u00e3o conectados \n\naos neur\u00f4nios da camada de sa\u00edda atrav\u00e9s de pesos. Toda vez que um padr\u00e3o \u00e9 \n\napresentado, as dist\u00e2ncias entre o padr\u00e3o e os pesos de cada uma das sa\u00eddas s\u00e3o \n\ncalculadas. Assumindo os pesos e o novo padr\u00e3o como vetores podemos ver uma \n\nrepresenta\u00e7\u00e3o gr\u00e1fica na Fig. 2.5. \n\n \nFIGURA  2.5 \u2013 Apresenta\u00e7\u00e3o de um padr\u00e3o a rede competitiva. \n\n \n\nO neur\u00f4nio de sa\u00edda cuja dist\u00e2ncia \u00e9 a menor torna-se o neur\u00f4nio vencedor da \n\ncompeti\u00e7\u00e3o. A sa\u00edda do neur\u00f4nio vencedor \u00e9 1 e a dos outros neur\u00f4nios \u00e9 reduzida a 0.   \n\nDurante o treinamento s\u00e3o apresentados sucessivos padr\u00f5es a rede competitiva, \n\npara cada padr\u00e3o apresentado \u00e9 calculado um neur\u00f4nio vencedor. O neur\u00f4nio vencedor \n\n\u00e9 modificado seguindo uma taxa de aprendizagem ?, para que se aproxime ainda mais \n\ndo padr\u00e3o apresentado.  \n\n \n\n \n\n \n\n \n\n\n\n \n\n \n\n29\n\n \n\nNa Fig. 2.6 pode-se ver uma representa\u00e7\u00e3o esquem\u00e1tica da influ\u00eancia da taxa de \n\naprendizado sobre os pesos do neur\u00f4nio vencedor. \n\n \nFIGURA  2.6 \u2013 Representa\u00e7\u00e3o esquem\u00e1tica da aprendizagem numa rede competitiva. \n\n \n\n \n\n\n\n \n\n \n\n30\n\n \n\nCAP\u00cdTULO 3 \u2013 PERFURA\u00c7\u00c3O E EXPLORA\u00c7\u00c3O DE PETR\u00d3LEO \n \n\nOs processos de perfura\u00e7\u00e3o e completa\u00e7\u00e3o de po\u00e7os de petr\u00f3leo s\u00e3o processos \n\ncomplexos e caros, uma boa parte do custo est\u00e1 associada ao tempo das interven\u00e7\u00f5es. O \n\naluguel de uma sonda custa em torno de US$ 180.000 por dia, segundo THOMAS \n\n(1996). Neste cap\u00edtulo, ser\u00e1 apresentada uma descri\u00e7\u00e3o dos processos de perfura\u00e7\u00e3o e \n\ncompleta\u00e7\u00e3o, assim como as opera\u00e7\u00f5es envolvidas nesses processos. \n\n \n\n3.1 Perfura\u00e7\u00e3o \n\n \nA perfura\u00e7\u00e3o de um po\u00e7o de petr\u00f3leo \u00e9 realizada atrav\u00e9s de uma sonda como pode \n\nser visto na Fig. 3.1. No processo de perfura\u00e7\u00e3o rotativa, as rochas s\u00e3o perfuradas pela \n\na\u00e7\u00e3o da rota\u00e7\u00e3o e do peso aplicado a uma broca existente na extremidade de uma coluna \n\nde perfura\u00e7\u00e3o. A coluna de perfura\u00e7\u00e3o consiste basicamente de comandos (tubos de \n\nparedes espessas) e de tubos de perfura\u00e7\u00e3o (tubos de paredes finas). Os fragmentos de \n\nrocha s\u00e3o removidos continuamente atrav\u00e9s de um fluido de perfura\u00e7\u00e3o, lama, injetado \n\npor bombas para o interior da coluna de perfura\u00e7\u00e3o. O fluido de perfura\u00e7\u00e3o \u00e9 injetado na \n\ncoluna de perfura\u00e7\u00e3o atrav\u00e9s da cabe\u00e7a de inje\u00e7\u00e3o ou \u201cswivel\u201d e retorna \u00e0 superf\u00edcie \n\natrav\u00e9s do espa\u00e7o anular formado pelas paredes do po\u00e7o e da coluna. \n\n\n\n \n\n \n\n31\n\n \n\n \nFIGURA 3.1 \u2013 Sonda (Extra\u00eddo de DOMINGOS, Lu\u00eds. Perfura\u00e7\u00e3o no mar. Dispon\u00edvel em: \n\n<http://histpetroleo.no.sapo.pt/perf_mar.htm>. acesso em: 1 mar. 2004). \n \n\nAo atingir certa profundidade a coluna de perfura\u00e7\u00e3o \u00e9 retirada do po\u00e7o e uma \n\ncoluna de revestimento de a\u00e7o, com di\u00e2metro inferior ao da broca, \u00e9 descida no po\u00e7o. O \n\nespa\u00e7o anular entre o tubo de revestimento e as paredes do po\u00e7o \u00e9 cimentado com a \n\nfinalidade de isolar as rochas atravessadas, permitindo ent\u00e3o o avan\u00e7o da perfura\u00e7\u00e3o \n\ncom seguran\u00e7a. Ap\u00f3s a opera\u00e7\u00e3o de cimenta\u00e7\u00e3o, a coluna de perfura\u00e7\u00e3o \u00e9 novamente \n\ndescida no po\u00e7o, tendo em sua extremidade uma nova broca, como mostra a Fig. 3.2, de \n\ndi\u00e2metro menor do que a do revestimento, para prosseguimento da perfura\u00e7\u00e3o. Dessa \n\n\n\n \n\n \n\n32\n\n \n\nmaneira o po\u00e7o \u00e9 perfurado em diversas fases, caracterizadas pelos diferentes di\u00e2metros \n\ndas brocas. (THOMAS, 1996). \n\n \n\n \nFIGURA 3.2 \u2013 Brocas (Extra\u00eddo de \n\nDOMINGOS, Lu\u00eds. Perfura\u00e7\u00e3o no mar. Dispon\u00edvel em:&lt;http://histpetroleo.no.sapo.pt/perf_mar.htm>. \nacesso em: 1 mar. 2004). \n\n \n\nAs opera\u00e7\u00f5es t\u00edpicas de perfura\u00e7\u00e3o s\u00e3o: Alargamento e repassamento, Conex\u00e3o, \n\nManobra e circula\u00e7\u00e3o, Revestimento, Cimenta\u00e7\u00e3o, Perfilagem e Movimenta\u00e7\u00e3o da \n\nsonda. A opera\u00e7\u00e3o de alargamento e repassamento consiste em se perfurar o po\u00e7o com \n\numa broca de di\u00e2metro maior que a utilizada para perfura\u00e7\u00e3o. A opera\u00e7\u00e3o de conex\u00e3o, \n\nmanobra e circula\u00e7\u00e3o consiste na conex\u00e3o ou desconex\u00e3o dos tubos de perfura\u00e7\u00e3o \u00e0 \n\ncoluna e a circula\u00e7\u00e3o refere-se a circular o fluido de perfura\u00e7\u00e3o para retirar os cascalhos \n\ndo espa\u00e7o anular. A opera\u00e7\u00e3o de revestimento do po\u00e7o constitui-se na instala\u00e7\u00e3o das \n\ncolunas de revestimento: condutor, revestimento de superf\u00edcie, revestimento \n\nintermedi\u00e1rio, revestimento de produ\u00e7\u00e3o, liner, ti\u00e9 back. A cimenta\u00e7\u00e3o \u00e9 feita no espa\u00e7o \n\nanular entre a tubula\u00e7\u00e3o de revestimento e as paredes do po\u00e7o.A refilagem \u00e9 feita ap\u00f3s a \n\nperfura\u00e7\u00e3o e consiste em descer v\u00e1rias ferramentas com a finalidade de medir \n\npropriedades das forma\u00e7\u00f5es. Ao fim das etapas de perfura\u00e7\u00e3o inicia-se o processo de \n\ncompleta\u00e7\u00e3o. (JACINTO, 2002). \n\n \n\n\n\n \n\n \n\n33\n\n \n\n3.2 Completa\u00e7\u00e3o \n\n \n\nAo terminar a perfura\u00e7\u00e3o de um po\u00e7o \u00e9 necess\u00e1rio deix\u00e1-lo em condi\u00e7\u00f5es de \n\noperar de forma segura e econ\u00f4mica durante toda sua vida produtiva. Ao conjunto de \n\nopera\u00e7\u00f5es destinadas a equipar o po\u00e7o para produzir \u00f3leo ou g\u00e1s (ou ainda injetar fluido \n\nnos reservat\u00f3rios) denomina-se completa\u00e7\u00e3o. \n\nQuanto aos aspectos t\u00e9cnico e operacional deve-se buscar otimizar a vaz\u00e3o de \n\nprodu\u00e7\u00e3o (ou inje\u00e7\u00e3o) e tornar a completa\u00e7\u00e3o a mais permanente poss\u00edvel, ou seja, \n\naquela que minimize a necessidade de interven\u00e7\u00f5es futuras para manuten\u00e7\u00e3o do po\u00e7o \n\n(as chamadas opera\u00e7\u00f5es de \u201cworkover\u201d). \n\nConsiderando que a completa\u00e7\u00e3o tem reflexos em toda vida produtiva do po\u00e7o e \n\nenvolve altos custos faz-se necess\u00e1rio um planejamento criterioso das opera\u00e7\u00f5es e uma \n\nan\u00e1lise econ\u00f4mica cuidadosa. (THOMAS, 1996). \n\nA completa\u00e7\u00e3o pode ser dividida: \n\na) Quanto ao posicionamento da cabe\u00e7a do po\u00e7o: terrestres ou mar\u00edtimas (\u00e1guas \n\nrasas ou \u00e1guas profundas), impactando diretamente nos sistemas de cabe\u00e7a de po\u00e7o e no \n\ntipo de \u00e1rvore de natal (conjunto de v\u00e1lvulas acopladas a cabe\u00e7a do po\u00e7o e que \n\ncontrolam a passagem do fluido) utilizada. \n\nb) Quanto ao revestimento de produ\u00e7\u00e3o: o po\u00e7o aberto (zona produtora totalmente \n\naberta), com liner rasgado ou canhoneado (posicionamento dos tubos previamente \n\nrasgado em frente \u00e0 zona produtora ou ent\u00e3o cimentado e posteriormente canhoneado \n\nnas zonas de interesse); com revestimento canhoneado (mais utilizado, compreendendo \n\na descida do revestimento de produ\u00e7\u00e3o at\u00e9 o fundo do po\u00e7o); ap\u00f3s a cimenta\u00e7\u00e3o do \n\nespa\u00e7o anular, o revestimento \u00e9 canhoneado nos intervalos de interesse. \n\nc) Quanto aos n\u00fameros de zonas exploradas: Simples (produ\u00e7\u00e3o de modo \n\ncontrolado e independente de uma \u00fanica zona de produ\u00e7\u00e3o, atrav\u00e9s de uma \u00fanica \n\ntubula\u00e7\u00e3o); M\u00faltipla (permite produzir ao mesmo tempo duas ou mais zonas ou \n\nreservat\u00f3rios diferentes, atrav\u00e9s de uma ou mais colunas de produ\u00e7\u00e3o descidas no po\u00e7o). \n\nAs etapas t\u00edpicas de uma completa\u00e7\u00e3o de um po\u00e7o mar\u00edtimo comp\u00f5em-se da \n\ninstala\u00e7\u00e3o dos equipamentos de superf\u00edcie (cabe\u00e7a de produ\u00e7\u00e3o BOP), condicionamento \n\ndo po\u00e7o (condicionamento do revestimento de produ\u00e7\u00e3o e substitui\u00e7\u00e3o do fluido que se \n\nencontra no interior do po\u00e7o, pelo fluido de completa\u00e7\u00e3o); avalia\u00e7\u00e3o da qualidade da \n\n\n\n \n\n \n\n34\n\n \n\ncimenta\u00e7\u00e3o (avalia\u00e7\u00e3o atrav\u00e9s de perfis ac\u00fasticos que medem a ader\u00eancia do cimento ao \n\nrevestimento e do cimento \u00e0 forma\u00e7\u00e3o); canhoneio (perfura\u00e7\u00e3o do revestimento \n\nutilizando cargas explosivas, visando comunicar o interior do po\u00e7o com a forma\u00e7\u00e3o \n\nprodutora); instala\u00e7\u00e3o da coluna de produ\u00e7\u00e3o (descida da coluna de produ\u00e7\u00e3o pelo \n\ninterior do revestimento de produ\u00e7\u00e3o) e coloca\u00e7\u00e3o do po\u00e7o em produ\u00e7\u00e3o (induz-se a \n\nsurg\u00eancia no po\u00e7o ou inicia-se o m\u00e9todo de eleva\u00e7\u00e3o artificial e efetua-se o teste inicial \n\nde produ\u00e7\u00e3o para medir a vaz\u00e3o de produ\u00e7\u00e3o e avaliar o desempenho do po\u00e7o). \n\n(JACINTO, 2002). \n\nAs opera\u00e7\u00f5es citadas acima se desdobram em v\u00e1rias sub-opera\u00e7\u00f5es que n\u00e3o foram \n\ndescritas, pois o intuito deste cap\u00edtulo \u00e9 dar uma no\u00e7\u00e3o geral do processo de perfura\u00e7\u00e3o \n\ne completa\u00e7\u00e3o de po\u00e7os de petr\u00f3leo. \n\n \n\n\n\n \n\n \n\n35\n\n \n\nCAP\u00cdTULO 4 \u2013 SISTEMA PROPOSTO \n \n\nEstudos a respeito da acur\u00e1cia ou incerteza das respostas fornecidas por RNAs, \n\nassim como sobre uma poss\u00edvel distribui\u00e7\u00e3o estat\u00edstica para o erro da resposta, tanto \n\npara o conjunto de treinamento como para o conjunto de testes, s\u00e3o raros na literatura e \n\nenvolvem conhecimentos bastante complexos, sendo que alguns estudos para \n\narquiteturas espec\u00edficas podem ser vistas em (HAYKIN 2001). Entretanto parece \n\ncorreto afirmar que a precis\u00e3o da resposta fornecida por uma RNA depende do modelo \n\nou arquitetura da RNA utilizada, bem como da representatividade dos dados nos \n\nconjuntos utilizados para treinamento e teste da Rede. (Idem) \n\nDurante o desenvolvimento deste trabalho uma s\u00e9rie de modelos de RNAs foram \n\npropostas, sendo realizados testes com a base de casos dispon\u00edvel, com o objetivo de \n\navaliar de maneira mais pragm\u00e1tica a adequa\u00e7\u00e3o e precis\u00e3o de cada modelo para estimar \n\no tempo total de interven\u00e7\u00f5es e detectar aspectos relevantes da constitui\u00e7\u00e3o do conjunto \n\nde treinamento. Com os resultados destas propostas direcionou-se a implementa\u00e7\u00e3o da \n\nsolu\u00e7\u00e3o pela qual se optou. \n\nEstas propostas preliminares, a proposta da arquitetura neural adotada no sistema, \n\nbem como uma descri\u00e7\u00e3o detalhada dos m\u00f3dulos que comp\u00f5em o Sistema  e seu \n\nfuncionamento, s\u00e3o apresentadas neste cap\u00edtulo. \n\n \n\n4.1. Propostas Preliminares \n\n \nDurante a fase de projeto foram desenvolvidos v\u00e1rios prot\u00f3tipos utilizando \n\ndiversos modelos e arquiteturas diferentes de RNAs. Esses prot\u00f3tipos revelaram-se de \n\nextrema import\u00e2ncia no processo de entendimento do problema, al\u00e9m de \n\nproporcionarem uma evolu\u00e7\u00e3o da arquitetura que levou \u00e0 arquitetura adotada no \n\nSistema. \n\nA base utilizada nos testes e no desenvolvimento do Sistema foi cedida por uma \n\nempresa do setor petrol\u00edfero. No caso dos testes, a base utilizada nos teste possu\u00eda os \n\ncampos: Tipo de Interven\u00e7\u00e3o, Tipo de Flu\u00eddo, Tipo de Po\u00e7o, Afastamento Lateral, \n\nL\u00e2mina D'\u00c1gua, Campo, Sonda, Profundidade Final, Azimute, Tempo Total. Estes \n\ncampos foram obtidos atrav\u00e9s da filtragem dos campos de uma tabela de interven\u00e7\u00f5es \n\n\n\n \n\n \n\n36\n\n \n\nrealizadas pela empresa do setor petrol\u00edfero que cedeu a base de dados. Esta tabela \n\npossui 3050 interven\u00e7\u00f5es cadastradas, al\u00e9m dos campos de controle interno da empresa, \n\nque n\u00e3o tem relev\u00e2ncia para o estudo realizado. \n\nAlguns modelos e testes que foram propostos e efetuados,  bem como uma an\u00e1lise \n\nresumida dos resultados, podem ser vistos a seguir: \n\n1. Teste utilizando toda a base como conjunto de treinamento \nEste teste foi realizado utilizando o matlab e consistiu no treinamento de uma rede \n\nneural direta utilizando 70% da base de dados como conjunto de treinamento e 30% \n\ncomo conjunto de avalia\u00e7\u00e3o. A rede foi para prever somente o tempo total de \n\nperfura\u00e7\u00e3o, o objetivo do teste era avaliar a rede direta para esse tipo de previs\u00e3o. As \n\nprevis\u00f5es feitas pela rede treinada possu\u00edam um grande erro se comparadas com valores \n\nreais, sendo este valores: erro m\u00e9dio do tempo total de perfura\u00e7\u00e3o de 412,8436 horas e \n\ndesvio padr\u00e3o do erro de 390,2307 horas, sendo que o tempo m\u00e9dio de  interven\u00e7\u00f5es \u00e9 \n\nde 409,7630 e o desvio padr\u00e3o \u00e9 de 504,8013 horas. Este erro deve-se a grande \n\nambig\u00fcidade encontrada nos dados utilizados para o treinamento da rede.   \n\n2. Teste utilizando os dados separados por tipo de interven\u00e7\u00e3o. \nEste teste foi realizado com uma implementa\u00e7\u00e3o pr\u00f3pria de rede neural direta \n\nconsistindo no treinamento de v\u00e1rias redes diretas, uma para cada tipo de interven\u00e7\u00e3o. \n\nOs resultados obtidos neste teste foram pouco melhores do que o obtido no teste \n\nanterior, isso demonstrou que normalmente os exemplos de um tipo de interven\u00e7\u00e3o n\u00e3o \n\nprejudicavam o aprendizado de outra interven\u00e7\u00e3o, o real problema estava nas \n\nambig\u00fcidades existentes dentro de uma mesma interven\u00e7\u00e3o. Assim sendo, partiu-se para \n\numa outra abordagem utilizada no teste 3. \n\n3. Teste eliminando dados cuja contribui\u00e7\u00e3o no erro final foi muito grande. \nO sistema do teste anterior foi modificado para retornar a participa\u00e7\u00e3o de cada \n\nelemento do conjunto de treinamento no erro total de treinamento. Os elementos com \n\nmaior participa\u00e7\u00e3o no erro total eram eliminados e a rede direta treinada novamente. \n\nEste teste obteve melhores resultados, pois os elementos que causavam as \n\nambig\u00fcidades no conjunto de treinamento possu\u00edam uma grande participa\u00e7\u00e3o no erro \n\ntotal. Em m\u00e9dia somente 20 elementos de um conjunto total de mais de 3000 eram \n\nrespons\u00e1veis por aproximadamente 50% do erro de treinamento da rede.  \n\n\n\n \n\n \n\n37\n\n \n\nApesar dos resultados obtidos neste teste terem sido satisfat\u00f3rios essa abordagem \n\nn\u00e3o deve ser utilizada, pois, simplesmente, induziu resultados satisfat\u00f3rios eliminando \n\nelementos discrepantes, que ao serem eliminados, descaracterizam os dados uma vez \n\nque uma das maiores caracter\u00edsticas do problema \u00e9 sua grande variabilidade. \n\n4. Teste agrupando os dados em conjuntos e utilizando a m\u00e9dia e o desvio \npadr\u00e3o. \n\nNeste teste, houve uma mudan\u00e7a significativa no sistema, os dados de treinamento \n\nforam agrupados utilizando um algoritmo estat\u00edstico k-media, baseado na dist\u00e2ncia \n\neuclidiana entre os dados. Para cada agrupamento gerado foi calculado a m\u00e9dia e o \n\ndesvio padr\u00e3o. A m\u00e9dia e o desvio padr\u00e3o do grupo transformaram-se nos objetivos de \n\ntreinamento em conjunto com o tempo total. Os resultados alcan\u00e7ados para m\u00e9dia e \n\ndesvio padr\u00e3o foram aceit\u00e1veis e para tempo total, melhoraram em rela\u00e7\u00e3o ao teste \n\nanterior. Essa abordagem mostrou-se mais satisfat\u00f3ria que a anterior, pois al\u00e9m de \n\nalcan\u00e7ar resultados melhores possui uma m\u00e9dia e um desvio padr\u00e3o associado \u00e0 \n\nresposta, esse fato auxilia na interpreta\u00e7\u00e3o dos resultados e na visualiza\u00e7\u00e3o da sua \n\nacur\u00e1cia.  \n\n5. Teste agrupando os dados em conjuntos e utilizando o grupo a que \npertence como valor de entrada. \n\nCom rela\u00e7\u00e3o ao teste anterior, a \u00fanica altera\u00e7\u00e3o realizada foi a adi\u00e7\u00e3o do conjunto \n\na que cada dado pertence. Assim sendo, ao passarem pela rede direta, os dados do \n\nconjunto de treinamento adquirem mais um par\u00e2metro que \u00e9 o conjunto a que o dado foi \n\nagrupado no passo anterior. Os resultados desse teste foram melhores se comparados \n\ncom o anterior, todos os erros possu\u00edam valores aceit\u00e1veis. Esse teste foi utilizado como \n\nbase da arquitetura utilizada na vers\u00e3o final do sistema. \n\nAlem disso, tendo conclu\u00eddo a etapa de avalia\u00e7\u00e3o dos prot\u00f3tipos foram detectados \n\naspectos do sistema que influenciavam decisivamente nos resultados. Estes aspectos \n\nforam analisados e os resultados dessa an\u00e1lise foram utilizados, assim como os \n\nresultados do teste anterior, no desenvolvimento da arquitetura final do sistema e sua \n\nimplementa\u00e7\u00e3o. Estes aspectos s\u00e3o: \n\na) Inconsist\u00eancias nos dados: a base de dados utilizada no projeto possu\u00eda uma \n\ngrande quantidade de dados inconsistentes ou incompletos. Esses dados, quando \n\n\n\n \n\n \n\n38\n\n \n\nsubstitu\u00eddos por valores padr\u00e3o causam uma grande quantidade de erros, que, \n\nprejudicando as previs\u00f5es, deixam os resultados menos confi\u00e1veis.  \n\nb) Grande variabilidade dos dados: os dados utilizados possu\u00edam uma grande \n\nvariabilidade, sendo que, nas mesmas situa\u00e7\u00f5es o tempo de perfura\u00e7\u00e3o variou mais de \n\n1000%. Com o objetivo de exemplificar esse fato, observa-se a tabela 4.1 onde \u00e9 \n\napresentado um exemplo real retirado da base de dados. Nesse exemplo, vimos duas \n\nPerfura\u00e7\u00f5es Explorat\u00f3rias com mesmos par\u00e2metros que, no entanto, possuem uma \n\ndiferen\u00e7a de mais de 1600% entre seus tempos totais. \n\n \nTabela 4.1 \u2013 Exemplo de dados reais \n\n \n\nTipoIntervencao FluidoPoco\nTipo \nPoco AfastamentoAlvo\n\nLamina\nDagua \n\nCam \nPoco\n\nTipo \nSonda \n\nProfFinal \nSondador \n\nAzimute \nPoco Total \n\nPerfura\u00e7\u00e3o \nExplorat\u00f3ria \n\n  0,00 -182,00 CVS SS 5.425,00  178,50 \n\nPerfura\u00e7\u00e3o \nExplorat\u00f3ria \n\n  0,00 -182,00 CVS SS 5.425,00  2.917,50\n\n Fonte: Dados reais retirados da base \n\n \n\nc) Resposta desejada do sistema: o software deve retornar n\u00e3o s\u00f3 uma previs\u00e3o \n\ndo tempo de perfura\u00e7\u00e3o, mas tamb\u00e9m a m\u00e9dia e o desvio padr\u00e3o associado a esse \n\nresultado. Como o tempo para o processo de perfura\u00e7\u00e3o possui uma grande \n\nvariabilidade, assim, po\u00e7os iguais levam tempos bastante diferentes para serem \n\nperfurados ou completados, uma rede neural preveria um valor intermedi\u00e1rio entre os \n\ndois po\u00e7os semelhantes. Esse valor intermedi\u00e1rio entre os dois po\u00e7os de nada serve sem \n\numa id\u00e9ia da variabilidade envolvida nesse n\u00famero. Assim sendo, o agrupamento de \n\npo\u00e7os semelhantes e o c\u00e1lculo da m\u00e9dia e dos desvios padr\u00e3o para esse conjunto de \n\npo\u00e7os, para serem utilizados posteriormente no treinamento, torna-se de grande \n\nimport\u00e2ncia para se ter uma no\u00e7\u00e3o da acur\u00e1cia e variabilidade dos resultados fornecidos \n\npela RNA. Al\u00e9m disso, deve-se retornar um valor de m\u00e9dia e desvio padr\u00e3o para que se \n\npossa realizar estudos sobre o risco envolvido na perfura\u00e7\u00e3o de po\u00e7o, estes estudos \n\npodem ser feitos da mesma forma que s\u00e3o feitos atualmente com os resultados de \n\nprogramas de simula\u00e7\u00e3o num\u00e9rica como o E&amp;P Risk III. \n\n \n\n \n\n\n\n \n\n \n\n39\n\n \n\n4.2. Proposta Adotada \n\n \nTendo conclu\u00eddo a etapa de testes e an\u00e1lise de alguns modelos e arquiteturas de \n\nRNAs, bem como de tratamento dos conjuntos de treinamento e teste e identificando as \n\ncaracter\u00edsticas mais relevantes das arquiteturas e dados de treinamento, iniciou-se a \n\nimplementa\u00e7\u00e3o da proposta adotada no Sistema.  \n\nA implementa\u00e7\u00e3o do sistema foi realizada com base no \u00faltimo prot\u00f3tipo avaliado, \n\nsendo esse o que apresentou melhores resultados. A maior diferen\u00e7a entre a arquitetura \n\ndo \u00faltimo prot\u00f3tipo e a arquitetura final do Sistema foi a ado\u00e7\u00e3o de uma rede \n\ncompetitiva em substitui\u00e7\u00e3o ao algoritmo estat\u00edstico k-media que classificava as \n\nentradas em grupos. Assim sendo, o n\u00facleo do Sistema tornou-se uma arquitetura \n\ncomposta por dois modelos de redes, uma rede direta e uma rede competitiva. \n\nA arquitetura neural do Sistema est\u00e1 ilustrada na Fig. 4.1. O diagrama de blocos \n\nda Fig. 4.1 apresenta as liga\u00e7\u00f5es entre as redes representadas na figura como caixas. \n\nNos t\u00f3picos 4.3 e 4.4 ser\u00e1 descrito o funcionamento de cada uma das redes, assim como \n\nsuas sa\u00eddas e entradas. \n\n \n\n \n\n \nFIGURA 4.1 \u2013 Arquitetura de redes do Sistema \n\n \n\n \n\n \n\n \n\n\n\n \n\n \n\n40\n\n \n\n4.2.1 Rede Competitiva \n\n \nNeste experimento, utilizou-se uma rede competitiva simples que possui duas \n\ncamadas de neur\u00f4nio totalmente conectadas entre si. Quando um dado \u00e9 apresentado a \n\nessa rede sua sa\u00edda \u00e9 o \u00edndice do neur\u00f4nio vencedor, ou seja, o neur\u00f4nio com maior \n\nvalor de ativa\u00e7\u00e3o para a entrada apresentada. \n\nA rede foi treinada atrav\u00e9s de um algoritmo de aprendizagem supervisionada, \n\nnesse sistema de aprendizado os exemplos s\u00e3o apresentados sucessivamente por um \n\ndeterminado n\u00famero de vezes. A cada exemplo apresentado \u00e0 rede, o neur\u00f4nio vencedor \n\n\u00e9 calculado, e seus pesos s\u00e3o modificados para aproximarem-se aos valores dos dados \n\nde entrada. \n\nInicialmente, todos os neur\u00f4nios possuem uma esp\u00e9cie de b\u00f4nus chamado de bias. \n\nPara cada vez que um neur\u00f4nio vence a disputa com os outros seu bias \u00e9 subtra\u00eddo at\u00e9 \n\num m\u00ednimo de zero. A utiliza\u00e7\u00e3o de bias \u00e9 de grande import\u00e2ncia para evitar que um \n\nneur\u00f4nio sempre seja vencedor e seja criado um \u00fanico grupo contendo todos os \n\nexemplos. A Fig. 4.2 cont\u00e9m um diagrama que demonstra como s\u00e3o as conex\u00f5es entre \n\nos neur\u00f4nios em uma rede competitiva. (KOHONEN, 1987). \n\nNo Sistema, a rede competitiva tem a incumb\u00eancia de agrupar os dados em grupos \n\nde dados semelhantes. A informa\u00e7\u00e3o de que grupo um dado pertence \u00e9 importante pois \n\npara cada grupo ser\u00e1 calculado uma m\u00e9dia e um desvio padr\u00e3o, que ser\u00e3o utilizados \n\nposteriormente para o treinamento da rede direta. Numa rede competitiva cada neur\u00f4nio \n\nda camada de sa\u00edda representa um grupo ou conjunto (Cluster). \n\nUma das vantagens da utiliza\u00e7\u00e3o de uma rede competitiva sobre o algoritmo \n\nestat\u00edstico k-media, utilizado nos testes 4 e 5 \u00e9 que depois de treinada, a rede \n\ncompetitiva pode determinar o grupo a que pertence um novo dado de entrada mesmo \n\nque esse dado n\u00e3o tenha sido visto durante o treinamento. Al\u00e9m disso, a rede \n\ncompetitiva gera um agrupamento mais preciso, pois n\u00e3o necessariamente o elemento \n\nrepresentativo do grupo deve estar presente no conjunto de treinamento, ao contr\u00e1rio do \n\nalgoritmo matem\u00e1tico, onde o elemento que representava o grupo era um elemento do \n\nconjunto de treinamento. No caso da rede competitiva o elemento utilizado para \n\ncompara\u00e7\u00e3o de um candidato com o conjunto \u00e9 o centro de gravidade do pr\u00f3prio \n\nconjunto. \n\n \n\n\n\n \n\n \n\n41\n\n \n\n \n\n \nFIGURA 4.2 \u2013 Arquitetura da rede competitiva \n\n \n\n4.2.2 Rede Direta \n\n \n Neste experimento foi utilizada uma rede direta de tr\u00eas camadas. Esta rede foi \n\ntreinada utilizando-se o algoritmo de Retropopaga\u00e7\u00e3o de Erros (Backpropagation). A \n\nrede direta tem a incumb\u00eancia de abstrair as varia\u00e7\u00f5es entre diferentes entradas. Nessa \n\narquitetura a rede direta \u00e9 treinada para fornecer tr\u00eas tipos de sa\u00edda: tempo total, m\u00e9dia e \n\ndesvio padr\u00e3o. Como entrada ela recebe, al\u00e9m do dado, par\u00e2metros relacionados \u00e0 \n\ninterven\u00e7\u00e3o apresentada \u00e0 rede e ao grupo a que o dado pertence, informa\u00e7\u00e3o esta obtida \n\nda rede competitiva. \n\nAp\u00f3s ter sido treinada essa rede direta tem a capacidade de abstrair as varia\u00e7\u00f5es \n\nentre os dados e sua influ\u00eancia nas tr\u00eas vari\u00e1veis de sa\u00edda. \n\nNa Fig. 4.3 \u00e9 apresentado um diagrama que descreve a rede neural direta utilizada \n\nnesse projeto. \n\n \n\n\n\n \n\n \n\n42\n\n \n\n \nFIGURA 4.3 \u2013 Arquitetura da rede direta \n\n \n\n4.3. Treinamento das Redes \n\n \nNo item anterior, foi descrito o funcionamento de cada uma das redes \n\nseparadamente, por\u00e9m, existem depend\u00eancias entre as redes durante o processo de \n\ntreinamento. Assim sendo, o treinamento das redes do sistema segue os seguintes \n\npassos:  \n\n1- Tratamento dos Dados: os dados s\u00e3o tratados para se adequarem ao formato \n\nexigido pelas redes neurais. Em primeiro lugar os dados que possuem campos em \n\nbranco s\u00e3o exclu\u00eddos. Em seguida os dados num\u00e9ricos s\u00e3o normalizados entre 0,1 e 0,9. \n\nOs dados qualitativos s\u00e3o transformados em bin\u00e1rio, ou seja, se existem X tipos para \n\ndada vari\u00e1vel s\u00e3o alocados X neur\u00f4nios para tal vari\u00e1vel. O neur\u00f4nio correspondente ao \n\ntipo da entrada recebe o valor 0,9 e os demais neur\u00f4nios que representam essa vari\u00e1vel \n\nrecebem 0,1. \n\n Normalmente, normalizam-se as vari\u00e1veis de sa\u00edda entre 0,1 e 0,9 para que os \n\nvalores de sa\u00edda n\u00e3o trabalhem nos extremos da fun\u00e7\u00e3o. Buscando padronizar a fun\u00e7\u00e3o \n\nde normaliza\u00e7\u00e3o, optou-se por normalizar tamb\u00e9m as entradas entre 0,1 e 0,9. \n\nNa tabela 4.2, s\u00e3o apresentados dois dados, um no formato que o sistema l\u00ea do \n\narquivo de dados e o outro no formato convertido para treinamento das redes. \n\n2- Divis\u00e3o dos Conjuntos: nessa etapa os dados ser\u00e3o divididos em dois \n\nconjuntos, um conjunto de treinamento e um conjunto de testes e valida\u00e7\u00e3o. A divis\u00e3o \u00e9 \n\nfeita de forma aleat\u00f3ria respeitando a propor\u00e7\u00e3o de 70% dos dados para treinamento e \n\n\n\n \n\n \n\n43\n\n \n\n30% para testes. Para trabalhos futuros fica a sugest\u00e3o de utiliza\u00e7\u00e3o de m\u00e9tricas mais \n\nconfi\u00e1veis que levem em considera\u00e7\u00e3o a natureza dos dados, como por exemplo, uma \n\nm\u00e9trica que garanta que pelo menos um exemplar de cada grupo gerado pela rede \n\ncompetitiva esteja presente no conjunto de treinamento. \n\n3-  Treinamento da Rede Competitiva: tendo os dados preparados \u00e9 iniciado o \n\ntreinamento da rede competitiva por um n\u00famero de \u00e9pocas pr\u00e9-determinado. Tendo \n\nconclu\u00eddo o treinamento o grupo a que pertence cada dado \u00e9 armazenado para posterior \n\nutiliza\u00e7\u00e3o no treinamento da rede direta. Os pesos da rede competitiva s\u00e3o armazenados. \n\n4- C\u00e1lculo da M\u00e9dia e do Desvio Padr\u00e3o: para cada grupo gerado pela rede \n\ncompetitiva s\u00e3o calculados a Media e o Desvio Padr\u00e3o do tempo total dos dados \n\npertencente ao grupo. Esses valores s\u00e3o armazenados para utiliza\u00e7\u00e3o no treinamento da \n\nrede direta. \n\n5- Treinamento da Rede Direta: a rede direta \u00e9 treinada utilizando os dados \n\nmais o grupo a que ele pertence, sendo a sa\u00edda desejada a m\u00e9dia e o desvio padr\u00e3o para \n\no conjunto a que o dado pertence, e o tempo total referente ao dado. A rede direta \u00e9 \n\ntreinada por um n\u00famero de \u00e9pocas pr\u00e9-determinado durante a etapa de sele\u00e7\u00e3o dos \n\npar\u00e2metros de treinamento do Sistema, e ap\u00f3s o treinamento seus pesos s\u00e3o \n\narmazenados. \n\n \n\nTabela 4.2 \u2013 Compara\u00e7\u00e3o entre dado original e dado convertido \n \n\nVari\u00e1veis Tipo \nInterven\u00e7\u00e3o \n\nTipo \nFlu\u00eddo \n\nTipo \nPo\u00e7o \n\nAfast. \nLateral \n\nLamina \nD\u2019Agua \n\n \nCampo \n\nTipo Sonda Profund. \nFinal \n\n \nAzimute \n\nTempo \nTotal \n\nDado \nOriginal \n\nRestaura\u00e7\u00e3o OL P 2147,85 -117,00 BG SM 4213,00 47,09 96,00 \n\nDado \nConvertido e \nnormalizado \n\n0.9 0.1 0.1 \n0.1 0.1 0.1 \n\n0.1 0.1 \n\n0.9 0.1 \n0.1 \n\n0.9 \n0.1 \n\n0.42 0.86 0.9 0.1 \n0.1 0.1 \n0.1 0.1 \n0.1 0.1 \n0.1 0.1 \n0.1 0.1 \n0.1 0.1 \n0.1 0.1 \n0.1 0.1 \n0.1 0.1 \n0.1 0.1 \n\n0.1 \n\n0.9 0.1 0.1 \n0.1 0.1 0.1 \n\n0.1 0.1 \n\n0,90 0,20 0.11 \n\n \n \n\n \n\n \n\n\n\n \n\n \n\n44\n\n \n\n \n\n4.4 Implementa\u00e7\u00e3o \n\n \n\n4.4.1 Plataforma de Desenvolvimento \n\n \nPara o desenvolvimento do software foi utilizada a linguagens C++ e o \n\ncompilador utilizado foi o C++ Builder. \n\nA Linguagem C++ foi escolhida, pois possibilita o desenvolvimento de softwares \n\nde alto desempenho e o sistema necessita de tal desempenho, pois, realiza um grande \n\nn\u00famero de opera\u00e7\u00f5es que demandam muito tempo. \n\nO C++ Builder foi utilizado por ser o m\u00e9todo mais simples de se desenvolver \n\ninterfaces gr\u00e1ficas em C++. O uso do C++ Builder agilizou todo o desenvolvimento das \n\ninterfaces, o que possibilitou uma maior concentra\u00e7\u00e3o do tempo no desenvolvimento da \n\nt\u00e9cnica utilizada. \n\n \n\n4.4.2 Detalhes de Desenvolvimento \n\n \nFoi desenvolvida uma biblioteca de entrada e tratamento de dados. Essa biblioteca \n\nl\u00ea um arquivo, exportado de uma base de dados no formato texto. Cada campo dos \n\ndados \u00e9 classificado automaticamente com quantitativo ou qualitativo. A classifica\u00e7\u00e3o \u00e9 \n\nfeita atrav\u00e9s de um algoritmo que analisa todos os campos de todos os dados e verifica \n\npara cada campo se ele possui somente valores num\u00e9ricos ou possui tamb\u00e9m valores \n\nnominais. Se um campo possuir somente valores num\u00e9ricos ele \u00e9 classificado como \n\nquantitativo. Se possuir algum valor que n\u00e3o seja num\u00e9rico o campo \u00e9 classificado \n\ncomo qualitativo. O usu\u00e1rio pode no sistema alterar a classifica\u00e7\u00e3o, mas um dado \n\nqualificado como qualitativo n\u00e3o pode ser classificado como quantitativo, pois n\u00e3o ser\u00e1 \n\nposs\u00edvel converter palavras em n\u00fameros, mas uma classifica\u00e7\u00e3o num\u00e9rica pode ser \n\nconsiderada como um dado qualitativo. O m\u00e9todo citado acima \u00e9 um m\u00e9todo simples \n\npara tipifica\u00e7\u00e3o de dados. Uma an\u00e1lise mais completa a respeito de solu\u00e7\u00f5es mais \n\nelaboradas para tipifica\u00e7\u00e3o de dados pode sem encontrada em SANTOS (2001). \n\n \n\n \n\n\n\n \n\n \n\n45\n\n \n\n \n\n4.4.3 Interface \n\n \nA interface do sistema possui duas abas: uma aba \u00e9 utilizada para avalia\u00e7\u00e3o de \n\nnovas opera\u00e7\u00f5es e outra aba utilizada para treinamento das redes do sistema. \n\n \n\n4.4.3.1 Interface de Treinamento \n\n \nA interface de treinamento do sistema foi implementada na forma de um guia de \n\nopera\u00e7\u00e3o, \u201cwizard\u201d, para facilitar seu uso. O usu\u00e1rio do sistema tem somente que \n\npreencher os dados de cada tela e passa para a seguinte clicando no bot\u00e3o Pr\u00f3ximo, ou \n\nvoltar para tela anterior clicando no bot\u00e3o Anterior. A maior parte das telas j\u00e1 vem \n\ntotalmente preenchidas, o usu\u00e1rio pode modificar os par\u00e2metros na tentativa de \n\nmelhorar os resultados, mas um usu\u00e1rio inexperiente tem como op\u00e7\u00e3o prosseguir o \n\ntreinamento sem se preocupar com os par\u00e2metros que ele desconhece. As etapas do guia \n\nde opera\u00e7\u00e3o s\u00e3o: \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n\n\n \n\n \n\n46\n\n \n\n \n\n \n\nEtapa 1 \u2013 entrada de dados: nessa etapa deve-se importar um arquivo que \n\ncontenha os dados provenientes do banco de dados, ou abrir um arquivo gravado \n\nanteriormente na etapa 2. Os dados provenientes da base de dados devem estar num \n\npadr\u00e3o texto, onde os campos s\u00e3o separados por \u201c;\u201d. Depois de selecionado o arquivo de \n\ndados, deve-se preencher o nome de cada um dos par\u00e2metros e selecionar o tipo de cada \n\ncampo, qualitativo ou num\u00e9rico, o sistema reconhece automaticamente o tipo dos \n\ncampos, mas o usu\u00e1rio tem a liberdade de alter\u00e1-los. Ap\u00f3s, deve-se selecionar qual dos \n\ncampos \u00e9 o de sa\u00edda. No nosso caso o campo que contenha o tempo total da interven\u00e7\u00e3o. \n\n \n\n \nFIGURA 4.4 \u2013 Tela da etapa 1, Entrada de Dados \n\n \n\n \n\n \n\n \n\n\n\n \n\n \n\n47\n\n \n\n \n\nEtapa 2 \u2013 analise de dados: essa etapa \u00e9 respons\u00e1vel pela analise de dados. A \n\nan\u00e1lise dos dados \u00e9 feita automaticamente e visa excluir os dados incompletos e alertar \n\no usu\u00e1rio de tipos que aparecem em menos de 1% dos dados. Este valor de 1% \u00e9 \n\nmeramente informativo e visa alertar o usu\u00e1rio que certo tipo pode n\u00e3o ser \n\nrepresentativo.  \n\nNesta etapa o usu\u00e1rio pode salvar os dados para na pr\u00f3xima vez que decidir \n\ntreinar com essa mesma base, n\u00e3o precisar rotular os par\u00e2metros novamente. \n\n \n\n \nFIGURA 4.5 \u2013 Tela da etapa 2, An\u00e1lise de dados \n\n \n\n \n\n \n\n \n\n \n\n \n\n\n\n \n\n \n\n48\n\n \n\n \n\nEtapa 3 \u2013 par\u00e2metros de treinamento: nesse passo deve-se selecionar os \n\npar\u00e2metros de treinamento. Existem dois modos, um modo b\u00e1sico e um modo avan\u00e7ado. \n\nNo modo b\u00e1sico o usu\u00e1rio pode somente setar o n\u00famero de \u00e9pocas de treinamento da \n\nrede competitiva e o n\u00famero de \u00e9pocas de treinamento da rede direta. No modo \n\navan\u00e7ado pode-se, al\u00e9m do que \u00e9 poss\u00edvel no modo b\u00e1sico, setar o n\u00famero de neur\u00f4nios \n\nde sa\u00edda, alfa da rede competitiva e n\u00famero de neur\u00f4nios na camada intermedi\u00e1ria, alfa, \n\neta, gain da rede direta. Esses par\u00e2metros ser\u00e3o utilizados no pr\u00f3ximo passo. \n\nNormalmente esses campos v\u00eam selecionados com valores padr\u00e3o, o n\u00famero de \n\nneur\u00f4nios na rede competitiva \u00e9 calculado automaticamente como sendo 5% do n\u00famero \n\ntotal de dados. Os outros campos est\u00e3o preenchidos com valores utilizados na realiza\u00e7\u00e3o \n\ndos testes de valida\u00e7\u00e3o da ferramenta. \n\nOs outros campos est\u00e3o selecionados com valores que, quando utilizados na base \n\nde dados de valida\u00e7\u00e3o, obtiveram valores aceit\u00e1veis de ERRO, em torno de 20h para os \n\npar\u00e2metros m\u00e9dia e desvio padr\u00e3o, com um tempo de treinamento pequeno, em torno de \n\n10 minutos na m\u00e1quina utilizada para testes. \n\n \n\n \n\n\n\n \n\n \n\n49\n\n \n\nFIGURA 4.6 \u2013 Tela da etapa 3, Par\u00e2metros de treinamento \n\n \n\nEtapa 4 \u2013 treinamento: nesse passo, as redes neurais s\u00e3o treinadas levando em \n\nconsidera\u00e7\u00e3o os par\u00e2metros de treinamento selecionados no passo anterior. Sendo  \n\nposs\u00edvel a qualquer momento, parar o treinamento de uma das redes e iniciar o \n\ntreinamento da pr\u00f3xima ou finalizar o treinamento. \n\n \n\n \nFIGURA 4.7 \u2013 Tela da etapa, 4 Treinamento \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n\n\n \n\n \n\n50\n\n \n\n \n\nEtapa 5 \u2013 relat\u00f3rios: neste passo s\u00e3o apresentados os relat\u00f3rios de treinamento \n\nde cada uma das duas redes. Para a rede competitiva \u00e9 exibido o n\u00famero de exemplos \n\nclassificados em cada conjunto, al\u00e9m do bias para o conjunto e o raio do conjunto. Para \n\na rede direta s\u00e3o apresentados: erro m\u00e9dio quadr\u00e1tico, erro m\u00e9dio para o par\u00e2metro \n\nTempo Total, erro m\u00e9dio para o par\u00e2metro M\u00e9dia e erro m\u00e9dio para o par\u00e2metro Desvio \n\nPadr\u00e3o. Isso para o conjunto de testes e para o conjunto de treinamento. Al\u00e9m disso, s\u00e3o \n\nexibidos tr\u00eas gr\u00e1ficos um para cada um dos par\u00e2metros. Os gr\u00e1ficos desenham pontos, \n\nque possuem na sua coordenada x o valor real e na coordenada y o valor simulado para \n\ncada exemplo do conjunto de treinamento, em azul e do conjunto de testes, em \n\nvermelho. Al\u00e9m disso, nesse passo pode-se exportar um relat\u00f3rio em Excel e salvar as \n\nredes treinadas para sua utiliza\u00e7\u00e3o na previs\u00e3o de um novo po\u00e7o. \n\n \n\n \nFIGURA 4.8 \u2013 Tela da etapa 5, Relat\u00f3rios \n\n \n\n \n\n\n\n \n\n \n\n51\n\n \n\n \n\n4.4.3.2 Interface de Avalia\u00e7\u00e3o \n\n \nTendo treinado previamente as redes do sistema e gravado um arquivo na etapa 5 \n\ndo treinamento com os dados referentes \u00e0s redes, pode-se utilizar a interface para avaliar \n\na a\u00e7\u00e3o de uma nova opera\u00e7\u00e3o. Para avaliar esta nova opera\u00e7\u00e3o deve-se carregar um \n\narquivo previamente gravado com os dados das redes e em seguida deve-se preencher o \n\nvalor dos par\u00e2metros pedidos. Executando as redes atrav\u00e9s do bot\u00e3o Executar redes o \n\nsistema apresenta o tempo total, a m\u00e9dia e o desvio padr\u00e3o para a opera\u00e7\u00e3o cujos dados \n\nforam preenchidos. Pode-se tamb\u00e9m gerar um relat\u00f3rio que conter\u00e1 os dados da \n\nopera\u00e7\u00e3o como tamb\u00e9m os resultado das redes. \n\n \n\n \nFIGURA 4.9 \u2013  Avalia\u00e7\u00e3o \n\n \n \n \n \n \n\n\n\n \n\n \n\n52\n\n \n\n \n \nCAP\u00cdTULO 5 - TESTES E VALIDA\u00c7\u00c3O \n \n\nNesse cap\u00edtulo, ser\u00e1 apresentada uma descri\u00e7\u00e3o dos testes realizados durante a \n\nvalida\u00e7\u00e3o do sistema, bem como os resultados alcan\u00e7ados. Na realiza\u00e7\u00e3o destes testes \n\nfoi utilizada a \u00faltima vers\u00e3o do sistema implementado, bem como v\u00e1rias tabelas de \n\ndados retirados da base cedida por uma empresa do setor petrol\u00edfero. Este conjunto de \n\ntestes foi realizado visando validar a solu\u00e7\u00e3o adotada e observar eventuais pontos \n\ndeficientes para futuras melhorias.  \n\n \n\n5.1. Dados para os Testes \n\n \nOs arquivos contendo os dados utilizados nos testes foram gerados a partir da base \n\nde dados hsit\u00f3ricos fornecida pela empresa e j\u00e1 descrita no cap\u00edtulo anterior. Filtrando \n\nesta tabela foram obtidos os seguintes campos relevantes aos testes: \n\n \n\n1. TipoInterven\u00e7\u00e3o: possui o tipo da interven\u00e7\u00e3o. \n\n2. FluidoPoco: possui o Tipo de Fluido do po\u00e7o. \n\n3. TipoPoco: possui o tipo do po\u00e7o, normalmente P (perfura\u00e7\u00e3o) e I (Inje\u00e7\u00e3o) \n\n4. AfastamentoAlvo: possui o afastamento lateral entre a boca do po\u00e7o e o \n\nreservat\u00f3rio de petr\u00f3leo. \n\n5. LaminaDagua: possui a altura da l\u00e2mina d\u2019\u00e1gua no local de perfura\u00e7\u00e3o. \n\n6. CamPoco: possui a sigla do campo onde o po\u00e7o est\u00e1 inserido. \n\n7. TipoSonda: possui a sigla que indica o tipo da sonda utilizada. \n\n8. ProfFinalSondador: possui a profundidade final atingida pelo sondador. \n\n9. AzimutePoco: posui o azimute do po\u00e7o. \n\n10. Total: possui o tempo total gasto na interven\u00e7\u00e3o. \n\n \n\nA partir dessa tabela foram gerados arquivos no formato texto que possu\u00edam \n\nalguns desses campos e seus dados respectivamente. Os arquivos gerados foram, \n\nArquivo 1: possui os campos 1,2,3,4,5,6,7,8,9 e10. \n\nArquivo 2: possui os campos 1,4,5,6,7,8,9 e10. \n\n\n\n \n\n \n\n53\n\n \n\nArquivo 3: possui os campos 1,4,5,6,7,8 e10 \n\nInicialmente, foi criado o Arquivo 1, que possu\u00eda todos os campos considerados \n\nrelevantes, com este arquivo foram realizados testes que nos levaram a perceber que \n\nmuitos dados eram descartados pois seus campos n\u00e3o estavam preenchidos. Um dos \n\nmaiores problemas ocorriam com o tipo de interven\u00e7\u00e3o \u201cperfura\u00e7\u00e3o explorat\u00f3rio\u201d, pois \n\nos campos \u201cFluidoPoco\u201d e \u201cTipoPoco\u201d normalmente n\u00e3o eram preenchidos. O campo \n\n\u201cFluidoPoco\u201d n\u00e3o foi preenchido para esse tipo de interven\u00e7\u00e3o porque durante a \n\nrealiza\u00e7\u00e3o de uma perfura\u00e7\u00e3o explorat\u00f3ria n\u00e3o se sabe ao certo que tipo de fluido ser\u00e1 \n\nencontrado. O campo \u201cTipoPoco\u201d tamb\u00e9m n\u00e3o fora preenchido em nenhuma situa\u00e7\u00e3o \n\npara esse tipo de interven\u00e7\u00e3o. Assim sendo, decidiu-se gerar um novo arquivo, o \n\nArquivo 2, retirando-se os campos \u201cTipoPoco\u201d e \u201cFluidoPoco\u201d. \n\nEnquanto se realizava a etapa de testes utilizando o Arquivo 2, percebeu-se que \n\numa grande quantidade de dados era exclu\u00edda do treinamento devido o n\u00e3o \n\npreenchimento do campo azimute. Dessa maneira, foi criado um terceiro arquivo para \n\ntestes, o Arquivo 3, este possui o maior n\u00famero de dados v\u00e1lidos para o processo de \n\ntreinamento e valida\u00e7\u00e3o. \n\n \n\nTabela 5.1 \u2013 N\u00famero de dados pertencentes aos arquiovos de dados \n \n\nArquivo de Dados N\u00famero Inicial de \nDados \n\nN\u00famero Dados \nExclu\u00eddos \n\nN\u00famero Dados \nRestantes Para \nTreinamento \n\nArquivo 1 3050 1316 1734 \nArquivo 2 3050 849 2201 \nArquivo 3 3050 187 2863 \n\n \n\nNa Tabela 5.1 est\u00e1 listado o n\u00famero de dados exclu\u00eddos para cada um dos \n\narquivos de dados. Al\u00e9m disso, tem-se o n\u00famero inicial de dados em cada tabela e o \n\nn\u00famero final de dados para treinamento. \n\n \n\n5.2. Simula\u00e7\u00f5es \n\n \nCom base nos arquivos de dados gerados, foi realizada uma s\u00e9rie de simula\u00e7\u00f5es \n\nonde os par\u00e2metros de entrada do Sistema foram alterados buscando determinar o valor \n\n\n\n \n\n \n\n54\n\n \n\ndos par\u00e2metros que leva ao melhor resultado final. Assim sendo, ap\u00f3s a realiza\u00e7\u00e3o dos \n\ntestes \u00e9 feita uma an\u00e1lise de seus resultados. \n\n \n\nTabela 5.2 \u2013 Par\u00e2metros referentes ao treinamento nas simula\u00e7\u00f5es realizadas e erro \nm\u00e9dio para cada par\u00e2metro de sa\u00edda \n\n \n\n \nRede Competitiva \n\n \nRede Direta \n\n \nErro m\u00e9dio (em horas) \n\n \nN\u00famero \n\nda \nSimula\u00e7\u00e3o \n\n \nArquivo \nUtilizado  \n\nNeur\u00f4nios \n \n\n\u00c9pocas \n \n\nNeur\u00f4nios\n \n\n\u00c9pocas \nTempo \nTotal \n\n \nM\u00e9dia \n\nDesvio \nPadr\u00e3o \n\n1 1 87 1000 30 1000 287.29 30.34 46.14 \n2 1 87 1000 60 5000 285.04 25.41 34.42 \n3 1 30 1000 30 1000 282.38 13.08 18.27 \n4 2 111 1000 30 1000 275.34 30.71 45.49 \n5 2 111 1000 60 5000 288.69 25.21 36.24 \n6 2 30 1000 30 1000 299.02 9.96 15.70 \n7 3 144 1000 30 1000 342.85 45.94 59.48 \n8 3 144 1000 60 5000 344.32 33.55 45.17 \n9 3 30 1000 30 1000 306.21 12.25 10.25 \n\n \n\nA tabela 5.2 descreve as simula\u00e7\u00f5es realizadas, as informa\u00e7\u00f5es relevantes ao \n\ntreinamento das redes e os erros obtidos em cada um dos par\u00e2metros de sa\u00edda. \n\nTendo realizado as simula\u00e7\u00f5es descritas na Tabela 5.2, foram gerados arquivos \n\ncontendo os dados referentes a cada simula\u00e7\u00e3o realizada. Um dos arquivos gerados \n\npossui os dados referentes a todas interven\u00e7\u00f5es utilizadas para teste e valida\u00e7\u00e3o. Entre \n\nestes dados est\u00e3o tempo simulado, tempo real e erro para os tr\u00eas par\u00e2metros de sa\u00edda: \n\nTempo Total, Media e Desvio Padr\u00e3o. O erro \u00e9 calculado de acordo com a f\u00f3rmula \n\napresentada na Equa\u00e7\u00e3o 5.1. \n\n \n\nE = |TS-TR| onde \n\nE = Erro \n\nTS = Tempo Simulado \n\nTR = Tempo Real \n\nEqua\u00e7\u00e3o 5.1 \u2013 Equa\u00e7\u00e3o do Erro \n\n \n\n\n\n \n\n \n\n55\n\n \n\nComo pode ser visto na tabela 5.2, o maior erro est\u00e1 contido no par\u00e2metro tempo \n\ntotal. Este erro deve-se, principalmente, \u00e0 grande variabilidade dos valores de tempo \n\ntotal do conjunto de treinamento.  \n\nOutro aspecto interessante a ser analisado \u00e9 o que acontece quando se aumenta o \n\nn\u00famero de neur\u00f4nios na rede direta e a quantidade de \u00e9pocas de treinamento. Este \n\naumento faz com que o sistema diminua o erro para m\u00e9dia e para o desvio padr\u00e3o, como \n\npode ser visto comparando as simula\u00e7\u00f5es 1 e 2, 4 e 5, 7 e 8.  Porem isso s\u00f3 acontece \n\npara tempo total na compara\u00e7\u00e3o entre 1 e 2, nos demais casos, essa expectativa n\u00e3o se \n\nconsolida. O motivo deste aumento \u00e9 que o Tempo Total n\u00e3o obedece a uma fun\u00e7\u00e3o em \n\nrela\u00e7\u00e3o as vari\u00e1veis de entrada, ou seja, exemplos com par\u00e2metros de entrada \n\nexatamente iguais geram tempos de perfura\u00e7\u00e3o bastante diferentes. Assim sendo, um \n\nn\u00famero maior de \u00e9pocas de treinamento causa uma diminui\u00e7\u00e3o do erro para o conjunto \n\nde treinamento, mas piora o conjunto de testes e valida\u00e7\u00e3o. Isto ocorre, pois a rede \n\naprende valores espec\u00edficos, mas n\u00e3o aprende a fun\u00e7\u00e3o que rege os valores do Tempo \n\nTotal. \n\nAs simula\u00e7\u00f5es 3, 6 e 9 foram as que tiveram melhor desempenho para seus \n\nrespectivos arquivos de dados. Este desempenho foi atingido atrav\u00e9s da diminui\u00e7\u00e3o do \n\nn\u00famero de neur\u00f4nios competitivos (as simula\u00e7\u00f5es 3, 6 e 9 s\u00e3o realizadas com 30 \n\nneur\u00f4nios na rede competitiva) e vem acompanhado de uma perda de precis\u00e3o do \n\nresultado final. Uma an\u00e1lise mais detalhada destes efeitos pode ser vista no t\u00f3pico a \n\nseguir. \n\n \n\n5.3 An\u00e1lise Detalhada \n\n \nPara uma an\u00e1lise mais detalhada foram selecionadas as simula\u00e7\u00f5es 8 e 9 pelos \n\nseguintes motivos: \n\na) Nestas simula\u00e7\u00f5es foram utilizados os conjuntos de dados que possu\u00edam o \n\nmaior n\u00famero de dados para facilitar a visualiza\u00e7\u00e3o dos efeitos causados pelos \n\npar\u00e2metros de treinamento. \n\nb) Estes experimentos possuem caracter\u00edsticas que devem ser analisadas para um \n\nmelhor entendimento do funcionamento do sistema. \n\n\n\n \n\n \n\n56\n\n \n\nUm dos aspectos mais importantes a ser analisado encontra-se na compara\u00e7\u00e3o \n\nentre as simula\u00e7\u00f5es 8 e 9. A simula\u00e7\u00e3o 9 tem um erro m\u00e9dio para os par\u00e2metros M\u00e9dia e \n\nDesvio Padr\u00e3o muito menor do que os da simula\u00e7\u00e3o 8, mas isso n\u00e3o quer dizer que as \n\nredes treinadas na simula\u00e7\u00e3o 9 resolvam o problema de maneira melhor do que  as \n\ntreinadas pela simula\u00e7\u00e3o 8. O problema \u00e9 que a diminui\u00e7\u00e3o do erro na simula\u00e7\u00e3o 9 \u00e9 \n\nbaseada na diminui\u00e7\u00e3o do n\u00famero de neur\u00f4nios na camada competitiva. Essa a\u00e7\u00e3o gera \n\nagrupamentos de dados maiores o que faz com que esses agrupamentos possuam \n\ngrandes desvios padr\u00f5es e medias pr\u00f3ximas \u00e0s m\u00e9dias globais, ou seja, a m\u00e9dia de todos \n\nos dados apresentados ao Sistema. \n\nSeguindo a id\u00e9ia de redu\u00e7\u00e3o do n\u00famero de conjuntos para obter um maior \n\ndesempenho, chegar\u00edamos a uma situa\u00e7\u00e3o em que ter\u00edamos um \u00fanico conjunto, e sua \n\nm\u00e9dia e desvio padr\u00e3o seriam iguais \u00e0 m\u00e9dia global do sistema. Assim sendo, todos os \n\npo\u00e7os pesquisados retornariam o mesmo resultado e os par\u00e2metros m\u00e9dia e desvio \n\npadr\u00e3o possuiriam um erro pr\u00f3ximo a zero. \n\nEnt\u00e3o a melhor forma de configurar o sistema \u00e9 buscar um n\u00famero de neur\u00f4nios \n\nna rede competitiva que gere agrupamentos pequenos, mas em contra partida n\u00e3o gere \n\nagrupamentos de um \u00fanico individuo. Desta forma, o erro n\u00e3o ser\u00e1 t\u00e3o baixo mas o \n\nsistema possuir\u00e1 mais capacidade de diferencia\u00e7\u00e3o entre os po\u00e7os testados. A melhor \n\nmaneira de diminuir o erro nos dois par\u00e2metros analisados \u00e9 at\u00e9 certo ponto o aumento \n\ndo n\u00famero de neur\u00f4nios na rede direta. \n\nA sele\u00e7\u00e3o de um n\u00famero \u00f3timo de agrupamentos \u00e9 um problema complexo que \n\nvem sendo abordado em disserta\u00e7\u00f5es e teses de doutorado como de SCREMIN (2003),  \n\nJOHSON e WICHER (1998) e MORRISON (1990).  \n\nAs Fig. 5.1 e 5.2 apresentam os gr\u00e1ficos referentes ao par\u00e2metro m\u00e9dia das \n\nsimula\u00e7\u00f5es 8 e 9. Nota-se que na simula\u00e7\u00e3o 9 existem muito menos valores de m\u00e9dia. \n\n\n\n \n\n \n\n57\n\n \n\nHistograma para Media na Simula\u00e7\u00e3o 8\n\n0\n\n5\n\n10\n\n15\n\n20\n\n25\n\n30\n\n35\n\n40\n\n45\n\n1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 10\n6\n\n11\n3\n\n12\n0\n\n12\n7\n\n13\n4\n\n14\n1\n\n14\n8\n\nTempo/10\n\nFr\neq\n\n\u00fc\u00ea\nnc\n\nia\n\n \n\nFIGURA 5.1 \u2013 Histograma de distribui\u00e7\u00e3o dos dados no tempo. O no eixo x est\u00e3o valores de tempo/10, \nou seja cada unidade representa 10 horas, e em y a freq\u00fc\u00eancia com que aparecem nos dados utilizados \n\npara teste e valida\u00e7\u00e3o. \n\n \n\nHistograma para Media na Simula\u00e7\u00e3o 9\n\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 10\n6\n\n11\n3\n\n12\n0\n\n12\n7\n\n13\n4\n\n14\n1\n\n14\n8\n\nTempo/10\n\nFr\neq\n\nu\u00ea\nnc\n\nia\n\n \n\nFIGURA 5.2 \u2013 Histograma de distribui\u00e7\u00e3o dos dados no tempo. O no eixo x est\u00e3o valores de tempo/10, \nou seja cada unidade representa 10 horas, e em y a freq\u00fc\u00eancia com que aparecem nos dados utilizados \n\npara teste e valida\u00e7\u00e3o. \n\n\n\n \n\n \n\n58\n\n \n\nHistograma para Desvio Padr\u00e3o na Simula\u00e7\u00e3o 8\n\n0\n\n5\n\n10\n\n15\n\n20\n\n25\n\n30\n\n35\n\n1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 10\n6\n\n11\n3\n\n12\n0\n\n12\n7\n\n13\n4\n\n14\n1\n\n14\n8\n\nTempo/10\n\nFr\neq\n\nu\u00ea\nnc\n\nia\n\n \n\nFIGURA 5.3 \u2013 Histograma de distribui\u00e7\u00e3o dos dados no tempo. O no eixo x est\u00e3o valores de tempo/10, \nou seja cada unidade representa 10 horas, e em y a freq\u00fc\u00eancia com que aparecem nos dados utilizados \n\npara teste e valida\u00e7\u00e3o. \n\n \n \n\nHistograma para Desvio Padrao na Simula\u00e7\u00e3o 9\n\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n1 8 15 22 29 36 43 50 57 64 71 78 85 92 99 10\n6\n\n11\n3\n\n12\n0\n\n12\n7\n\n13\n4\n\n14\n1\n\n14\n8\n\nTempo/10\n\nFr\neq\n\nu\u00ea\nnc\n\nia\n\n \n\nFIGURA 5.4 \u2013 Histograma de distribui\u00e7\u00e3o dos dados no tempo. O no eixo x est\u00e3o valores de tempo/10, \nou seja cada unidade representa 10 horas, e em y a freq\u00fc\u00eancia com que aparecem nos dados utilizados \n\npara teste e valida\u00e7\u00e3o. \n\n\n\n \n\n \n\n59\n\n \n\nAs Fig. 5.3 e 5.4 apresentam os gr\u00e1ficos referente ao par\u00e2metro desvio padr\u00e3o das \n\nsimula\u00e7\u00f5es 8 e 9. Nota-se que na simula\u00e7\u00e3o 9 existem poucas faixas de valores que \n\nconcentram quase todos os resultados para vari\u00e1vel desvio padr\u00e3o. Al\u00e9m disso, quase \n\nn\u00e3o existem valores de desvio padr\u00e3o pequenos na simula\u00e7\u00e3o 9.  \n\n\u00c9 poss\u00edvel notar nas Fig. 5.1 e 5.2 que os resultados referentes \u00e0 simula\u00e7\u00e3o 9 est\u00e3o \n\nmais concentrados em faixas pequenas de valores. Isso tem como causa a pequena \n\nquantidade de conjuntos utilizada o que faz com que muitas interven\u00e7\u00f5es diferentes \n\nsejam reconhecidas como pertencentes ao mesmo conjunto, j\u00e1 que esses conjuntos na \n\nsimula\u00e7\u00e3o 9 s\u00e3o grandes. J\u00e1 nos gr\u00e1ficos referentes \u00e0 simula\u00e7\u00e3o 8, os resultados s\u00e3o \n\nmais variados pois os conjuntos s\u00e3o menores e assim s\u00f3 classificam dados realmente \n\nsimilares. \n\n \n\n         \n\nFIGURA 5.5 \u2013 Gr\u00e1ficos de distribui\u00e7\u00e3o de resultados para o teste 8. Os c\u00edrculos que possuem na \ncoordenada x, o tempo real, para a dada interven\u00e7\u00e3o, e em y, o tempo simulado; os c\u00edrculos azuis \n\nrepresentam as interven\u00e7\u00f5es pertencentes ao conjunto de treinamento, e em vermelho as pertencentes ao \nconjunto de teste. \n\n \n\nNa Fig. 5.5, s\u00e3o apresentados gr\u00e1ficos para a m\u00e9dia e o desvio padr\u00e3o na \n\nsimula\u00e7\u00e3o 8, neste tipo de gr\u00e1fico, agrupamentos horizontais representam conjuntos. \n\nComo o n\u00famero de conjuntos \u00e9 grande e eles est\u00e3o bem distribu\u00eddos, pois essa \u00e9 uma \n\ncaracter\u00edstica do problema, quase n\u00e3o \u00e9 poss\u00edvel notar-se agrupamentos. Neste tipo de \n\ngr\u00e1fico os grupos (Clusters) podem ser visualizados como agrupamentos verticais de \n\npontos, pois todos os elementos de um grupo possuem aproximadamente um mesmo \n\n\n\n \n\n \n\n60\n\n \n\nvalor de sa\u00edda, ocorrendo somente uma pequena varia\u00e7\u00e3o que depende de sua dist\u00e2ncia \n\nem rela\u00e7\u00e3o ao centr\u00f3ide. \n\nNesse tipo de gr\u00e1fico, os pontos com menor erro est\u00e3o dispostos sobre a diagonal, \n\nsendo que, quanto mais distante um ponto estiver da diagonal maior o seu erro. \n\n \n\n          \n\nFIGURA 5.6 \u2013  Gr\u00e1ficos de distribui\u00e7\u00e3o de resultados para o teste 9. Os c\u00edrculos que possuem na \ncoordenada x, o tempo real, para a dada interven\u00e7\u00e3o, e em y, o tempo simulado; os c\u00edrculos azuis \n\nrepresentam as interven\u00e7\u00f5es pertencentes ao conjunto de treinamento, e em vermelho as pertencentes ao \nconjunto de teste. \n\n \n\nJ\u00e1 na Fig. 5.6, que representa a simula\u00e7\u00e3o 9, pode-se notar distintamente os \n\nagrupamentos. Al\u00e9m disso, todos os dados est\u00e3o concentrados em poucos valores, o que \n\nn\u00e3o reflete a grande variabilidade caracter\u00edstica do problema. \n\n \n\n5.4 An\u00e1lise de Erro \n\n \nNa literatura de redes neurais existem poucos estudos que abordam o \n\ncomportamento aleat\u00f3rio do erro. Este assunto quando tratado na literatura \u00e9 abordado \n\nde forma superficial e em problemas espec\u00edficos. \n\nDentro do Sistema, descobrir como \u00e9 a distribui\u00e7\u00e3o do erro, \u00e9 de suma \n\nimport\u00e2ncia por tratar-se de um sistema de an\u00e1lise de risco. Como na literatura n\u00e3o foi \n\nposs\u00edvel encontrar uma f\u00f3rmula que determine a distribui\u00e7\u00e3o de erro nas duas redes \n\nneurais utilizadas, partimos para um m\u00e9todo de an\u00e1lise das simula\u00e7\u00f5es. Para realizar \n\n\n\n \n\n \n\n61\n\n \n\nesta analise, foi utilizada uma ferramenta que realiza um teste de ader\u00eancia a v\u00e1rios \n\ntipos de fun\u00e7\u00f5es estat\u00edsticas. \n\nPara uma melhor visualiza\u00e7\u00e3o das simula\u00e7\u00f5es todos os erros dos testes foram \n\nagrupados em faixas de 10 horas. Com o resultado desse agrupamento foram gerados os \n\ngr\u00e1ficos que est\u00e3o na Fig. 5.7, estes foram gerados para os tr\u00eas par\u00e2metros de sa\u00edda: \n\nTempo Total, M\u00e9dia e Desvio Padr\u00e3o.  \n\n \n\nHistograma de Distribui\u00e7\u00e3o do M\u00f3dulo do Erro para o \nP\u00e2rametro Tempo Total Simula\u00e7\u00e3o 8\n\n0\n\n5\n\n10\n\n15\n\n20\n\n25\n\n30\n\n35\n\n1 11 21 31 41 51 61 71 81 91 101 111 121 131 141 151 161 171 181 191\n\n \n \n\nHistograma de Distribui\u00e7\u00e3o M\u00f3dulo do Erro para o P\u00e2rametro \nTempo Total Simula\u00e7\u00e3o 9\n\n0\n\n5\n\n10\n\n15\n\n20\n\n25\n\n30\n\n35\n\n1 11 21 31 41 51 61 71 81 91 101 111 121 131 141 151 161 171 181 191\n\n \n\n\n\n \n\n \n\n62\n\n \n\n \n \n\nHistograma de Distribui\u00e7\u00e3o M\u00f3dulo do Erro para o P\u00e2rametro \nM\u00e9dia Simula\u00e7\u00e3o 8\n\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\n600\n\n700\n\n800\n\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n\n \n \n \n \n\n \n\nHistograma de Distribui\u00e7\u00e3o M\u00f3dulo do Erro para o P\u00e2rametro \nM\u00e9dia Simula\u00e7\u00e3o 9\n\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\n600\n\n700\n\n800\n\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n\n \n \n \n\n\n\n \n\n \n\n63\n\n \n\nHistograma de Distribui\u00e7\u00e3o M\u00f3dulo do Erro para o P\u00e2rametro \nDesvio Padr\u00e3o Simula\u00e7\u00e3o 8\n\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\n600\n\n700\n\n800\n\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n\n \n \n\nHistograma de Distribui\u00e7\u00e3o M\u00f3dulo do Erro para o P\u00e2rametro \nDesvio Padr\u00e3o Simula\u00e7\u00e3o 9\n\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\n600\n\n700\n\n800\n\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n\n \nFIGURA 5.7 \u2013  Histogramas de distribui\u00e7\u00e3o do erro nas simula\u00e7\u00f5es 8 e 9. O no eixo x est\u00e3o valores de \ntempo/10, ou seja cada unidade representa 10 horas, e em y a freq\u00fc\u00eancia com que tal erro ocorre nos \n\ndados utilizados para teste e valida\u00e7\u00e3o. \n\n \n \n\nPara todos os casos analisados, a ferramenta de ader\u00eancia retornou que a forma da \n\nfun\u00e7\u00e3o do erro era exponencial. Saber a forma da fun\u00e7\u00e3o do erro facilita para que num \n\n\n\n \n\n \n\n64\n\n \n\ntrabalho futuro sejam estudadas uma f\u00f3rmula do erro embutido no sistema e sua \n\ninflu\u00eancia em cada resultado. \n\nSendo a forma da distribui\u00e7\u00e3o do erro uma exponencial, o usu\u00e1rio do sistema pode \n\nter uma id\u00e9ia do erro embutido nos resultados do sistema. Mas em trabalhos futuros, a \n\nf\u00f3rmula do erro deve ser estudada mais detalhadamente, podendo-se criar uma maneira \n\nformal de se avaliar o erro embutido no sistema.   \n\n \n\n5.5 Testes com Dados Reais \n\n \nPara finalizar a an\u00e1lise dos resultados, foram realizados testes utilizando dados \n\nreais, dados estes n\u00e3o utilizados no treinamento. Tais simula\u00e7\u00f5es foram realizadas sobre \n\nas redes treinadas na Simula\u00e7\u00e3o 8.  \n\n \n\nTabela 5.4 \u2013 Testes realizados com dados reais \n \n\nN\u00b0 \n \n\nTipo da \nInterven\u00e7\u00e3o \n\nAfast. \nLateral \n(Metros) \n\nLamina \nD\u2019\u00c1gua \n(Metros) \n\nCampo Sonda Prof. \nFinal \n(Metros) \n\nTempo \nReal \n(Horas) \n\nTempo \nSimulado \n(Horas) \n\nM\u00e9dia \n(Horas) \n\nDesvio \nPadr\u00e3o  \n(Horas) \n\n1 Perfura\u00e7\u00e3o de \nDesenvolvimento \n\n319,84 -960,00 MRL SS 2905,00 629,50 818,79 706,11 335,03 \n\n2 Perfura\u00e7\u00e3o \nExplorat\u00f3ria \n\n0,00 -322,00 AB SS 2979,00 629,50 731,29 786,8 179,55 \n\n3 Completa\u00e7\u00e3o 2372,75 -142,00 CH SM 4188,00 455,50 464,28 438,58 294,01 \n4 Perfura\u00e7\u00e3o \n\nExplorat\u00f3ria \n0,00 -118,00 RJS SS 2780,00 703,50 940,93 962,44 655,31 \n\n \n \n\nNa tabela 5.4 est\u00e3o dispostos os dados de interven\u00e7\u00f5es reais que utilizadas bem \n\ncomo os resultados obtidos pelo sistema. Os campos Interven\u00e7\u00e3o, Afastamento Lateral, \n\nLamina D\u2019\u00c1gua, Campo, Sonda e Profundidade Final s\u00e3o os par\u00e2metros da entrada do \n\nsistema. O campo Tempo Real refere-se ao tempo de dura\u00e7\u00e3o real para a dada \n\ninterven\u00e7\u00e3o. Os campos Tempo Simulado, M\u00e9dia e Desvio Padr\u00e3o possuem os retornos \n\nobtidos pela simula\u00e7\u00e3o. \n\nAo analisar-se os testes contidos na tabela 5.4, observa-se que os valores de tempo \n\ntotal simulado est\u00e3o sempre pr\u00f3ximos a m\u00e9dia, sendo esta uma caracter\u00edstica do sistema \n\ndevido \u00e0 grande variabilidade do problema. \n\nPode-se ver na tabela 5.4 que para a simula\u00e7\u00e3o 1 o tempo previsto para a \n\ninterven\u00e7\u00e3o foi de 818,79 horas, com m\u00e9dia de 706,11 horas e desvio padr\u00e3o de 335,03 \n\n\n\n \n\n \n\n65\n\n \n\nhoras. Seu tempo real da interven\u00e7\u00e3o foi de 629,50 horas que \u00e9 satisfat\u00f3rio num tipo de \n\nproblema que se caracteriza pela grande variabilidade Se uma an\u00e1lise de confiabilidade \n\nfosse feita, sendo adotada uma margem de confiabilidade de 90% o valor real deveria \n\nestar entre 613,23 e 798,98 horas. Assim sendo, pode-se considerar satisfat\u00f3rio o \n\nresultado obtido pelo Sistema. Para o c\u00e1lculo deste intervalo de confian\u00e7a, foi utilizada \n\na Equa\u00e7\u00e3o 5.2. \n\n \n\nn\nMT\n\n)*64.1( ?\n\u00b1=  \n\n   Onde: \n\nT \u00e9 o intervalo de confian\u00e7a \n\n   M \u00e9 a m\u00e9dia  \n\n   DP \u00e9 o desvio padr\u00e3o \n\n   N \u00e9 o n\u00famero de elementos do cluster  \n\nEqua\u00e7\u00e3o 5.2 \u2013 Intervalo de Confian\u00e7a de 90%. \n\n \n\nNa tabela 5.5 est\u00e3o calculados os intervalos de confian\u00e7a para cada um dos testes. \n\nComparando-se a tabela 5.5 com a tabela 5.4 pode-se perceber que somente em um caso \n\no Tempo Real n\u00e3o caiu dentro do intervalo de Confian\u00e7a de 90%, mas esse fato n\u00e3o \n\ninvalida o bom resultado obtido.  \n\n \n\nTabela 5.5 \u2013 Intervalo de Confian\u00e7a de 90% Para Cada Teste \n \n\nIntervalo de Confian\u00e7a 90% N\u00ba do Teste N\u00ba de elementos no cluster \n\nInicio Fim \n\n1 35 613,2361 798,9839 \n2 2 578,5839 995,0161 \n3 4 197,4918 679,6682 \n4 44 800,4216 1124,458 \n\n \n\n\n\n \n\n \n\n66\n\n \n\nCAP\u00cdTULO 6 - CONSIDERA\u00c7\u00d5ES FINAIS \n \n\n6.1. Conclus\u00e3o \n\n \n\nDurante a fase inicial do projeto foi realizada uma extensa bateria de testes \n\nvisando \u00e0 identifica\u00e7\u00e3o de poss\u00edveis modelos a serem utilizados no Sistema. Esta fase \n\nteve uma contribui\u00e7\u00e3o muito grande para com as etapas posteriores, pois a an\u00e1lise de \n\nv\u00e1rios modelos, mesmo que estes n\u00e3o fossem utilizados no Sistema final, forneceu um \n\nbom conhecimento do problema. Esse conhecimento foi revelado pelo comportamento \n\ndos dados reais utilizados durante esta etapa de testes. \n\nO prot\u00f3tipo final da etapa de testes foi utilizado como base para a arquitetura final \n\ndo sistema essa arquitetura adotada foi composta por duas redes neurais, uma rede \n\ncompetitiva e uma rede direta sendo implementada com sucesso num Sistema de f\u00e1cil \n\nutiliza\u00e7\u00e3o por usu\u00e1rios com conhecimentos de redes neurais. Assim sendo foi poss\u00edvel a \n\nrealiza\u00e7\u00e3o de uma extensa bateria de testes visando a valida\u00e7\u00e3o do sistema. \n\nOs resultados obtidos com esses testes demonstraram que a arquitetura utilizada \n\nno sistema \u00e9 capaz de prever, com um alto grau de confiabilidade os tempos de \n\ninterven\u00e7\u00f5es realizadas sobre po\u00e7os de petr\u00f3leo, mas, esse grau de confiabilidade do \n\nresultado depende de v\u00e1rios fatores. Alguns fatores que influenciam na confiabilidade \n\ndos resultados est\u00e3o listados a seguir: \n\na) Volume de dados: para conseguir uma boa confiabilidade nos resultados deve-\n\nse possuir uma base de dados com o maior n\u00famero de casos reais poss\u00edveis.  \n\nb) Erro nos dados: a base de dados deve possuir o m\u00ednimo poss\u00edvel de dados com \n\nvalores incorretos, pois muitas vezes esses valores incorretos levam a contradi\u00e7\u00f5es \n\nque dificultam o aprendizado das redes neurais. \n\nc) Par\u00e2metros de treinamento: uma m\u00e1 escolha dos par\u00e2metros de treinamento \n\npode prejudicar completamente no resultado final. Como foi visto no cap\u00edtulo 5, \n\numa escolha equivocada da quantidade de neur\u00f4nios na rede competitiva tornou o \n\nresultado muito menos confi\u00e1vel \n\nQuando os fatores listados acima s\u00e3o contornados, o sistema mostrou-se de grande \n\nvalor na resolu\u00e7\u00e3o do problema proposto, tendo chegado a resultados aceit\u00e1veis e \n\ncoerentes com a realidade. Uma avalia\u00e7\u00e3o completa da veracidade dos resultados \n\n\n\n \n\n \n\n67\n\n \n\nobtidos com o sistema s\u00f3 poder\u00e1 ser feita com a utiliza\u00e7\u00e3o deste em po\u00e7os reais. Mas \n\neste fato n\u00e3o impede que o sistema cumpra seus objetivos, pois ele \u00e9 um sistema de \n\nauxilio e seus resultados ser\u00e3o comparados com o de outros sistemas baseados em \n\nan\u00e1lises estat\u00edsticas e por especialistas no assunto.  \n\nO sistema cumpre com sucesso seus objetivos, no que diz respeito a prever os \n\nresultados de um po\u00e7o de petr\u00f3leo baseado em dados hist\u00f3ricos, pois se utilizado \n\ncorretamente e com par\u00e2metros corretos realiza uma previs\u00e3o precisa no que diz \n\nrespeito \u00e0s caracter\u00edsticas dos dados utilizados no seu treinamento. \n\nMesmo cumprindo com sucesso seus objetivos, o sistema tem alguns problemas; \n\n\u2022 O sistema n\u00e3o tem nenhuma forma de corrigir dados incompletos, ou seja, \n\nem opera\u00e7\u00f5es em determinado campo n\u00e3o se aplica este n\u00e3o \u00e9 preenchido, \n\nsendo o dado todo exclu\u00eddo. \n\n\u2022 O sistema n\u00e3o guarda nenhuma informa\u00e7\u00e3o sobre o treinamento no \n\narquivo que cont\u00e9m os pesos da rede treinada. Assim sendo, os que \n\ntiverem acesso somente a este arquivo n\u00e3o tem como conhecer grau de \n\nconfiabilidade da rede utilizada. \n\n\u2022 Muitos dos par\u00e2metros necess\u00e1rios para treinamento das redes dependem \n\nmuito das caracter\u00edsticas do conjunto de treinamento. Assim sendo \n\ndependem muito do conhecimento em redes neurais do usu\u00e1rio e mesmo \n\nassim s\u00e3o necess\u00e1rios v\u00e1rios testes at\u00e9 encontrar-se um valor aceit\u00e1vel. \n\nIsso torna o Sistema restrito a pessoas com algum conhecimento em redes \n\nneurais. \n\n \n\nBoa parte dos problemas citada acima ser\u00e1 resolvida caso sejam implementadas \n\nas sugest\u00f5es para trabalhos futuros. \n\nMesmo com estes problemas o Sistema proposto nesta disserta\u00e7\u00e3o \u00e9 uma boa \n\nalternativa aos m\u00e9todos tradicionais. \n\n  \n\n  \n\n \n\n \n\n \n\n\n\n \n\n \n\n68\n\n \n\n6.2. Trabalhos Futuros \n\n \n\nDurante a etapa de testes e valida\u00e7\u00e3o, foram percebidas varias modifica\u00e7\u00f5es que \n\npodem vir a serem feitas no sistema para tornar mais simples sua utiliza\u00e7\u00e3o al\u00e9m de \n\ntorn\u00e1-lo mais robusto e mais confi\u00e1vel. As poss\u00edveis melhorias ao sistema est\u00e3o abaixo \n\ncitadas como sugest\u00e3o de trabalhos futuros. \n\na) Tratamento inicial dos dados \u2013 \u00e9 necess\u00e1rio que o sistema possua uma \n\nmaneira autom\u00e1tica, melhor que a utilizada atualmente, para excluir dados \n\nincompletos ou incorretos e se poss\u00edvel preencher campos de dados onde tal \n\ncampo n\u00e3o se aplica. \n\nb) M\u00e9todo autom\u00e1tico de c\u00e1lculo do n\u00famero de neur\u00f4nios na camada \n\ncompetitiva - \u00e9 necess\u00e1rio que o sistema possua um sistema autom\u00e1tico de \n\nsele\u00e7\u00e3o de n\u00famero de neur\u00f4nios na camada competitiva. Esse sistema autom\u00e1tico \n\npode ser criado utilizando-se de t\u00e9cnicas de algoritmos gen\u00e9ticos. \n\nc) Novas informa\u00e7\u00f5es nos arquivos de pesos das redes treinadas: \u00e9 \n\nnecess\u00e1ria a inclus\u00e3o de dados relativos ao treinamento das redes no arquivo que \n\ncontem os pesos da rede, pois esse arquivo pode ser utilizado por varias pessoas, \n\nn\u00e3o necessariamente quem treinou a rede, assim sendo o usu\u00e1rio deste arquivo \n\ndeve possuir uma maneira de checar o erro de treinamento embutido nos pesos \n\nutilizados. \n\nd) Garantir que conjuntos pr\u00f3ximos tenham semelhan\u00e7as \u2013 no m\u00e9todo \n\nutilizado atualmente os dados classificados em conjuntos pr\u00f3ximos, como 1 e 2 \n\npor exemplo, n\u00e3o necessariamente devem possuir alguma semelhan\u00e7a. Para \n\ngarantir essa semelhan\u00e7a geogr\u00e1fica pode-se ao inv\u00e9s de utilizar redes \n\ncompetitivas utilizar uma rede de korronen. \n\ne) Tempo de treinamento elevado - o tempo de treinamento das redes para \n\numa base de dados grande \u00e9 elevado. Uma das solu\u00e7\u00f5es para esse problema seria a \n\nutiliza\u00e7\u00e3o de um algoritmo paralelo de treinamento, o que possibilitaria a \n\nutiliza\u00e7\u00e3o de m\u00e1quinas multi-processadas ou mesmo um cluster para seu \n\ntreinamento.  \n\nAl\u00e9m de todos os aspectos citados acima ainda existe um outro aspecto que pode \n\nser abordado em trabalhos futuros, pois o sistema foi criado para resolu\u00e7\u00e3o de um \n\n\n\n \n\n \n\n69\n\n \n\nproblema de previs\u00e3o de tempo de perfura\u00e7\u00e3o de po\u00e7os de petr\u00f3leo, mas nada impede o \n\nsistema ser utilizado em outros problemas de previs\u00e3o. Por exemplo, o sistema pode ser \n\nutilizado no auxilio na tomada de decis\u00e3o de um empr\u00e9stimo banc\u00e1rio. Assim sendo, \n\noutras utiliza\u00e7\u00f5es do sistema como poss\u00edveis adapta\u00e7\u00f5es s\u00e3o sugest\u00f5es para trabalhos \n\nfuturos.  \n\n\n\n \n\n \n\n70\n\n \n\nREFER\u00caNCIAS BIBLIOGR\u00c1FICAS \n \n\nALEKLETT, K. and CAMPBELL, C.J. The Peak and Decline of World Oil and Gas \nProduction. Published by the Association for the Study of Peak Oil and Gas. \nDispon\u00edvel em &lt;www.asponews.org>. Acesso em: 25 maio 2005. \n \n\nBARRETO, J. M. Intelig\u00eancia Artificial no Liminar do S\u00e9culo XXI. 2 ed. \nFlorian\u00f3polis: Duplic, 2000. \n \n\nBISHOP, Christopher. Neural Networks for Pattern Recognition. Oxford: Clarendon \nPress,1995. \n \n\nDAYHOFF, Judith. Neural Network Architectures \u2013 An Introduction. New York: \nVan Nostrand Reinhold Co, 1990 \n \n\nDOMINGOS, Lu\u00eds. Perfura\u00e7\u00e3o no mar. Dispon\u00edvel em: \n<http://histpetroleo.no.sapo.pt/perf_mar.htm>. acesso em: 1 mar. 2004. \n \n\nHAYKIN, Simon. Redes Neurais Princ\u00edpios e Pr\u00e1tica. Trad. Paulo Martins Engel. 2 \ned. Porto Alegre: Bookman, 2001. \n \n\nHAN, J. &amp; KAMBER, M. Data Mining: Concepts and Techniques. Simon Fraser \nUniversity: Morgan Kaufmann Publishers, 2000. \n \n\nHARBAUGH, J. W., DAVIS, J. C. and WENDEBOURG . Computing Risk for Oil \nProspects: Principles and Programs. Pergamon. UK. 1995. \n \n\nJACINTO, Carlos Magno. Modelagem e Simula\u00e7\u00e3o do Risco na Perfura\u00e7\u00e3o e \nCompleta\u00e7\u00e3o de Po\u00e7os de Petr\u00f3leo e G\u00e1s em \u00c1guas Profundas. Disserta\u00e7\u00e3o \n(Mestrando em Ci\u00eancias) \u2013 Programa de P\u00f3s-Gradua\u00e7\u00e3o em Ci\u00eancia, Universidade \nFederal Fluminense, Rio de Janeiro: 2002. \n \n\nJOHSON, R.A.; WICHERN, D.W. Applied multivariate statistical analysis. \nPrentice-Hall: New Jersey, 1998. 3. ed. \n \n\nKIMBALL, Ralph. Data Warehouse Toolkit. New Jersey: John Wiley &amp; Sons, Inc, \n1997. \n \n\nKOHONEN, T. Self-Organization and Associative Memory. 2Nd Edition, Berlin: \nSpringer-Verlag, 1987. \n \n\n\n\n \n\n \n\n71\n\n \n\nMORRISON, D. F. Multivariate statistical methods. McGraw-Hill: USA, 1990. 3. ed. \n \n\nROSE, P. Risk Analysis and Management of Petroleum Exploration Ventures. AAPG \nMethods in Exploration Series, No. 12.  AAPG. USA. 2001. \n \n\nRUD, Ol\u00edvia Parr. Modeling Data for Marketing, Risk, and Customer Relationship \nManagement. New Jersey: John Wiley &amp; Sons, Inc, 2001.  \n \n\nSCHALKOFF, Robert. Pattern Recognition. New York: John Wiley &amp; Sons, Inc, \n1992. \n \n\nSILVA, Reneu Rodrigues da. Explorator: Prot\u00f3tipo de Sistema Hol\u00edstico em \nExplora\u00e7\u00e3o de Petr\u00f3leo. 2000. Tese (Doutorado em Geologia) \u2013 Programa de P\u00f3s-\nGradua\u00e7\u00e3o em Geologia, Universidade Federal do Rio de Janeiro, Rio de Janeiro: 2000. \n \n\nTHOMAS, J. E. (Org.). Fundamentos de Engenharia de Petr\u00f3leo. [S.l.: s. n.],1996. \n \n\nSANTOS, Jos\u00e9 Gon\u00e7alo dos. Sistema Especialista para Tipifica\u00e7\u00e3o de Dados. 2001. \nDisserta\u00e7\u00e3o (Mestrado em Sistema de Conhecimento) \u2013 Programa de P\u00f3s-Gradua\u00e7\u00e3o em \nCi\u00eancia da Comput\u00e7\u00e3o, Universidade Federal de Santa Catarina, Florian\u00f3polis: 2001. \n \n\nSCREMIN, Marcos Ant\u00f4nio Antonelio. M\u00e9todo para a sele\u00e7\u00e3o do n\u00famero de \ncomponentes principais com base na l\u00f3gica difusa. 2003. Tese (Doutorado em \nEngenharia da Produ\u00e7\u00e3o) \u2013 Programa de P\u00f3s-Gradua\u00e7\u00e3o em Engenharia de Produ\u00e7\u00e3o. \nUniversidade Federal de Santa Catarina, Florian\u00f3polis: 2003."}]}}}