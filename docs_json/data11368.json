{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.14910"}, {"@name": "filename", "#text": "21299_245142.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNIVERSIDADE FEDERAL DE SANTA CATARINA \nPROGRAMA DE P\u00d3S-GRADUA\u00c7\u00c3O EM CI\u00caNCIA DA  \n\nCOMPUTA\u00c7\u00c3O \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\nHumberto Fioravante Ferro \n \n \n \n \n \n \n \n \n \n\n \nOTIMIZA\u00c7\u00c3O DA PREVIS\u00c3O DE CARGA EL\u00c9TRICA DE \n\nCURTO PRAZO UTILIZANDO CRIT\u00c9RIOS DE SIMILARIDADE \nENTRE PERFIS DE CONSUMO \n\n \n \n \n \nDisserta\u00e7\u00e3o submetida \u00e0 Universidade Federal de Santa Catarina como parte dos \n\nrequisitos para a obten\u00e7\u00e3o do grau de Mestre em Ci\u00eancia da Computa\u00e7\u00e3o \n \n \n \n \n\nOrientador: Raul Sidnei Wazlawick, Dr. \n \n \n \n \n \n\nFlorian\u00f3polis, setembro de 2007\n\n\n\nOTIMIZA\u00c7\u00c3O DA PREVIS\u00c3O DE CARGA EL\u00c9TRICA DE \nCURTO PRAZO UTILIZANDO CRIT\u00c9RIOS DE SIMILARIDADE \n\nENTRE PERFIS DE CONSUMO \n \n\nHumberto Fioravante Ferro \n\n \n\nEsta Disserta\u00e7\u00e3o foi julgada adequada para a obten\u00e7\u00e3o do t\u00edtulo de Mestre em Ci-\n\n\u00eancia da Computa\u00e7\u00e3o \u00c1rea de Concentra\u00e7\u00e3o Sistema de Conhecimento e aprovada em \n\nsua forma final pelo Programa de P\u00f3s-Gradua\u00e7\u00e3o em Ci\u00eancia da Computa\u00e7\u00e3o. \n\n \n\n \n\n________________________________ \n\nRog\u00e9rio Cid Bastos, Dr. Eng. \n(Coordenador do Curso) \n\nBanca Examinadora \n \n \n\n________________________________ \n\nRaul Sidnei Wazlawick, Dr. Eng. (orientador) \n \n \n \n \n________________________________ \n\nDayna Maria Bortoluzzi, Dra. Eng. \n \n \n \n \n________________________________ \n\nPedro Alberto Barbetta, Dr. Eng. \n \n \n \n \n\n \n\n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\u201cLa scienza \u00e8 il capitano, e la pratica sono i soldati. \nStudia prima la scienza e poi seguita la pratica nata \nda essa scienza. Quelli che s'innamorano della \npratica senza scienza, sono come i nocchieri che \nentrano nella nave senza timone o bussola.\u201d \n \n\nLEONARDO DA VINCI, Codici \n \n\n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nAo prof. Fioravante Ferro, Dr., por muito ter me \n\nensinado sobre a virtude de se viver. \n \n\n\u00c0 profa. Lydia Semenow, Dra., por ter me feito \nentender que quando algo parece muito dif\u00edcil, \nprovavelmente est\u00e1 sendo feito do jeito errado. \n\n \nA D. Maria Elena, ao eng. Paulo Lopes e aos seus \n\nfilhos Ana, Karina e C\u00e1ssio, por terem me aco-\nlhido entre os seus nos momentos mais dif\u00edceis de \n\nminha vida. \n\n\n\n v \n\n \n\n\n\n \n \n\nAGRADECIMENTOS \n \n\nAo prof. Wazlawick, Dr., meu orientador, pela paci\u00eancia e por todos os seus \n\nconselhos, al\u00e9m da oportunidade dada junto ao programa de P\u00f3s Gradua\u00e7\u00e3o em Ci\u00eancia \n\nda Computa\u00e7\u00e3o da Universidade Federal de Santa Catarina. Gra\u00e7as a ele, consegui ini-\n\nciar e acabar um projeto de pesquisa com sucesso. Simplesmente obrigado, professor! \n\nAo prof. Rog\u00e9rio Cid Bastos, Dr., pelo apurado senso cient\u00edfico e pelas in\u00fameras \n\nsugest\u00f5es dadas ao longo desta disserta\u00e7\u00e3o. Ele \u00e9 quase um quiromante da estat\u00edstica, \n\nconseguindo distinguir padr\u00f5es onde outros s\u00f3 v\u00eaem ru\u00eddo branco. Grato, professor! \n\nAos integrantes do Projeto PCarga, em especial o Cl\u00e1udio M. de Oliveira, Dr., e \n\no Luiz \u00c2ngelo D. de Luca, pelo tempo dispendido no aux\u00edlio \u00e0 realiza\u00e7\u00e3o deste trabalho. \n\nN\u00e3o fosse por voc\u00eas, eu ainda estaria procurando por um tema de pesquisa... \n\nAo eng. C\u00e1ssio Guimar\u00e3es Lopes, PhD., pelo conhecimento enciclop\u00e9dico cedi-\n\ndo sem parcim\u00f4nia a qualquer momento do dia ou da noite. O C\u00e1ssio, \u00e0s vezes, \u00e9 um \n\npouco dram\u00e1tico, mas se ele n\u00e3o fosse assim, eu jamais teria aprendido que rir da pr\u00f3-\n\npria sina pode ser um santo rem\u00e9dio. Valeu por tudo, irm\u00e3ozinho! \n\nAo prof. Marco Aur\u00e9lio Benedetti, Dr., por ter me infundido o gosto pelo traba-\n\nlho cient\u00edfico e por ter sido sempre franco e justo. A felicidade pode ser ef\u00eamera, mas \n\ntamb\u00e9m n\u00e3o h\u00e1 mazela que dure para sempre. Um dia chove na horta, Benedetti! \n\n\u00c0s Centrais El\u00e9tricas de Santa Catarina S.A. - CELESC, pela cess\u00e3o de seu his-\n\nt\u00f3rico de medi\u00e7\u00f5es do sistema SCADA. \n\nAo Luiz Andr\u00e9, amigo de todas as horas, pela sua contribui\u00e7\u00e3o a este trabalho. \n\nPois quem h\u00e1 de questionar o valor de todas aquelas horas junto a um balc\u00e3o, tomando \n\ncerveja e discutindo assuntos em nada relacionados a modelos inteligentes h\u00edbridos?... \n\n\u00c0 Susi Helen que, mesmo nas madrugadas em que meus modelos inteligentes \n\nn\u00e3o pareciam muito inteligentes e deixavam de convergir, sempre me incentivou e apoi-\n\nou. Susi, h\u00e1 momentos em que estar pr\u00f3ximo representa muito \u2013 obrigado por tudo!   \n\n\n\nSUM\u00c1RIO \n \n \n \n\n\u00cdNDICE DE FIGURAS ............................................................................................................. IX \n\n\u00cdNDICE DE EQUA\u00c7\u00d5ES ......................................................................................................... X \n\n\u00cdNDICE DE TABELAS .......................................................................................................... XII \n\nRESUMO ................................................................................................................................XIII \n\nABSTRACT ............................................................................................................................ XIV \n\n1 INTRODU\u00c7\u00c3O.................................................................................................................... 1 \n1.1 OBJETIVOS .................................................................................................................................... 8 \n1.2 JUSTIFICATIVA .............................................................................................................................. 8 \n1.3 METODOLOGIA ............................................................................................................................ 11 \n1.4 LIMITA\u00c7\u00d5ES DO TRABALHO ........................................................................................................ 12 \n1.5 ORGANIZA\u00c7\u00c3O DO TRABALHO .................................................................................................... 13 \n\n2 O SISTEMA EL\u00c9TRICO ................................................................................................. 15 \n2.1 BREVE PERSPECTIVA HIST\u00d3RICA, DEFINI\u00c7\u00d5ES ESSENCIAIS E ALGUNS ELEMENTOS \nMATEM\u00c1TICOS ........................................................................................................................................ 15 \n2.2 ELEMENTOS DO SISTEMA EL\u00c9TRICO............................................................................................ 19 \n\n3 ESTIMA\u00c7\u00c3O E PREDI\u00c7\u00c3O ........................................................................................... 22 \n3.1 INTRODU\u00c7\u00c3O............................................................................................................................... 22 \n3.2 ESTIMA\u00c7\u00c3O ................................................................................................................................. 23 \n3.3 PREDI\u00c7\u00c3O.................................................................................................................................... 30 \n3.4 TEORIA DE APRENDIZADO ESTAT\u00cdSTICO E MINIMIZA\u00c7\u00c3O DE RISCO ........................................... 33 \n\n3.4.1 Considera\u00e7\u00f5es iniciais........................................................................................................ 34 \n3.4.2 Princ\u00edpios de indu\u00e7\u00e3o ......................................................................................................... 37 \n\n4 M\u00c1QUINAS DE VETORES DE SUPORTE (SUPPORT VECTOR MACHINES)...... 48 \n4.1 INTRODU\u00c7\u00c3O............................................................................................................................... 48 \n4.2 CONTEXTUALIZA\u00c7\u00c3O .................................................................................................................. 53 \n4.3 ALGORITMO DE CLASSIFICA\u00c7\u00c3O BIN\u00c1RIO .................................................................................. 55 \n4.4 HIPERPLANOS DE CLASSIFICA\u00c7\u00c3O E O HIPERPLANO \u00d3TIMO ......................................................... 58 \n4.5 C\u00c1LCULO DO HIPERPLANO \u00d3TIMO ............................................................................................... 61 \n4.6 M\u00c1QUINAS DE VETORES DE SUPORTE ......................................................................................... 65 \n4.7 HIPERPLANOS DE MARGENS SUAVES (SOFT MARGIN HYPERPLANES) ........................................... 69 \n4.8 REGRESS\u00c3O SVM (SVR \u2013 SUPPORT VECTOR REGRESSION) ........................................................ 71 \n\n5 ESTADO DA ARTE .......................................................................................................... 77 \n\n6 M\u00c9TODO DE OTIMIZA\u00c7\u00c3O DA PREDI\u00c7\u00c3O DE CARGA...................................... 85 \n6.1 EXTRA\u00c7\u00c3O DE CARACTER\u00cdSTICAS ............................................................................................... 88 \n6.2 ALGORITMO DE CLASSIFICA\u00c7\u00c3O................................................................................................ 105 \n6.3 RESULTADOS ........................................................................................................................ 106 \n\n7 DISCUSS\u00d5ES E CONCLUS\u00c3O .................................................................................... 109 \n\n8 REFER\u00caNCIAS ............................................................................................................... 112 \n\n\n\n viii \n\n9 ANEXOS ........................................................................................................................... 115 \n9.1 VARI\u00c1VEIS DISPON\u00cdVEIS PARA A PREDI\u00c7\u00c3O DE CARGA .............................................................. 115 \n9.2 VARI\u00c1VEIS RELEVANTES EM CADA PERFIL DE CONSUMO........................................................... 118 \n\n \n \n\n\n\n \n\n\u00cdNDICE DE FIGURAS \n\nFigura 1 \u2013 Diagrama Esquem\u00e1tico do Sistema El\u00e9trico e Escopo desta Disserta\u00e7\u00e3o ................................... 2 \nFigura 2 \u2013 Esquema da Constru\u00e7\u00e3o de um Preditor de Carga e Escopo deste Trabalho .............................. 4 \nFigura 3 \u2013 Altern\u00e2ncia de Perfis numa Regi\u00e3o de Consumo Hipot\u00e9tica ...................................................... 6 \nFigura 4 \u2013 Evolu\u00e7\u00e3o dos Perfis de Consumo em uma Regi\u00e3o ...................................................................... 7 \nFigura 5 \u2013 Sistema de Predi\u00e7\u00e3o de Carga Otimizado com o Uso de uma Base de Conhecimento ............. 12 \nFigura 6 \u2013 Elementos de um Sistema El\u00e9trico Moderno ............................................................................ 20 \nFigura 7 \u2013 Vari\u00e2ncia no Tempo: (a) Sistema Invariante e (b) Sistema Variante ........................................ 26 \nFigura 8 \u2013 M\u00e9dias de Dois Sistemas: (a) Sistema Estacion\u00e1rio e (b) Sistema N\u00e3o-Estacion\u00e1rio ............... 27 \nFigura 9 \u2013 Modelo de Aprendizado Supervisionado .................................................................................. 29 \nFigura 10 \u2013 Dados para um Modelo de Predi\u00e7\u00e3o ....................................................................................... 31 \nFigura 11 \u2013 Modelo Preditor Temporal (malha de atraso) ......................................................................... 33 \nFigura 12 \u2013 O Dilema do Superajuste ........................................................................................................ 39 \nFigura 13 \u2013 Valida\u00e7\u00e3o Cruzada e Generaliza\u00e7\u00e3o........................................................................................ 41 \nFigura 14 \u2013 Limites Probabil\u00edsticos entre os Riscos Emp\u00edrico e Esperado ................................................ 45 \nFigura 15 \u2013 Erros no Aprendizado ............................................................................................................. 46 \nFigura 16 \u2013 O Produto Interno Can\u00f4nico como M\u00e9trica de Similaridade .................................................. 50 \nFigura 17 \u2013 Mapeamento do espa\u00e7o 2??X  para o espa\u00e7o 3??Z ................................................... 52 \nFigura 18 \u2013 Classifica\u00e7\u00e3o Bin\u00e1ria............................................................................................................... 53 \nFigura 19 \u2013 An\u00e1lise de Discriminante para Amostras de Duas Categorias ................................................ 54 \nFigura 20 \u2013 Classifica\u00e7\u00e3o Bin\u00e1ria num Espa\u00e7o de Caracter\u00edsticas ............................................................. 56 \nFigura 21 \u2013 A Fun\u00e7\u00e3o Sinal (sgn)............................................................................................................... 58 \nFigura 22 \u2013 Hiperplano \u00d3timo e Vetores de Suporte para uma Classifica\u00e7\u00e3o Bin\u00e1ria ............................... 65 \nFigura 23 \u2013 Arquitetura de uma M\u00e1quina de Vetores de Suporte .............................................................. 68 \nFigura 24 \u2013 Fun\u00e7\u00e3o de Decis\u00e3o no Espa\u00e7o de Entrada............................................................................... 68 \nFigura 25 \u2013 Fun\u00e7\u00e3o de Perda ? -insensitiva de Vapnik ............................................................................. 72 \nFigura 26 \u2013 Regress\u00e3o SVM....................................................................................................................... 73 \nFigura 27 \u2013 Arquitetura da Regress\u00e3o SVM............................................................................................... 75 \nFigura 28 \u2013 Etapas na Constru\u00e7\u00e3o de um Modelo Preditor ........................................................................ 78 \nFigura 29 \u2013 Analogia entre os Modelos de Avalia\u00e7\u00e3o e Definitivo............................................................ 79 \nFigura 30 \u2013 Sistema Neural Difuso para a Predi\u00e7\u00e3o do Pre\u00e7o da Energia no Mercado Spot ..................... 82 \nFigura 31 \u2013 Modelo Preditor H\u00edbrido RNA-SVM...................................................................................... 82 \nFigura 32 \u2013 Extraindo o Conhecimento dos Preditores de Carga ............................................................... 85 \nFigura 33 \u2013 M\u00e9todo de Otimiza\u00e7\u00e3o ............................................................................................................ 86 \nFigura 34 \u2013 N\u00e3o Estacionariedade da Carga............................................................................................... 89 \nFigura 35 \u2013 Gr\u00e1fico de Probabilidade Normal da Carga El\u00e9trica ............................................................... 90 \nFigura 36 \u2013 Histograma da Distribui\u00e7\u00e3o da Carga ..................................................................................... 91 \nFigura 37 \u2013 Gr\u00e1fico de Desempenho de Diversos Perfis de Consumo ....................................................... 93 \nFigura 38 \u2013 Cria\u00e7\u00e3o do Extrator de Caracter\u00edsticas Utilizando SVM......................................................... 95 \nFigura 39 \u2013 Curvas de Desempenho de Dois Perfis de Consumo Semelhantes ......................................... 96 \nFigura 40 \u2013 Curvas de Desempenho de Dois Perfis de Consumo N\u00e3o-Semelhantes ................................. 97 \nFigura 41 \u2013 Diagrama Esquem\u00e1tico do Extrator de Caracter\u00edsticas ......................................................... 100 \nFigura 42 \u2013Vetores de Caracter\u00edsticas dos Perfis de Consumo ................................................................ 101 \nFigura 43 \u2013 Determina\u00e7\u00e3o da Relev\u00e2ncia Preditiva das Vari\u00e1veis Dispon\u00edveis em um Perfil ................. 103 \nFigura 44 \u2013 Semelhan\u00e7a entre as Preditoras dos Perfis de Consumo ....................................................... 105 \nFigura 45 \u2013 Preditores Neuronais Criados para Validar a Otimiza\u00e7\u00e3o ..................................................... 106 \n \n \n\n\n\n \n\n\u00cdNDICE DE EQUA\u00c7\u00d5ES \n\nEqua\u00e7\u00e3o 1 \u2013 Pot\u00eancia El\u00e9trica .................................................................................................................... 18 \nEqua\u00e7\u00e3o 2 \u2013 Lei de Ohm ............................................................................................................................ 18 \nEqua\u00e7\u00e3o 3 \u2013 Um Modelo de Regress\u00e3o Simples ........................................................................................ 25 \nEqua\u00e7\u00e3o 4 \u2013 O Operador f como um Modelo de Estima\u00e7\u00e3o....................................................................... 28 \nEqua\u00e7\u00e3o 5 \u2013 Conjunto de Treinamento ...................................................................................................... 30 \nEqua\u00e7\u00e3o 6 \u2013 Modelo Preditor Explanat\u00f3rio................................................................................................ 31 \nEqua\u00e7\u00e3o 7 \u2013 Conjunto de Treinamento para um Modelo Explanat\u00f3rio...................................................... 32 \nEqua\u00e7\u00e3o 8 \u2013 Modelo Preditor Temporal..................................................................................................... 32 \nEqua\u00e7\u00e3o 9 \u2013 Modelo de um Sistema Preditor Temporal ............................................................................ 32 \nEqua\u00e7\u00e3o 10 \u2013 Distribui\u00e7\u00e3o de Probabilidade Conjunta de X e Y ................................................................ 34 \nEqua\u00e7\u00e3o 11 \u2013 Classe de Fun\u00e7\u00f5es (estimadores) ......................................................................................... 35 \nEqua\u00e7\u00e3o 12 \u2013 Risco Funcional de if ......................................................................................................... 35 \nEqua\u00e7\u00e3o 13 \u2013 Fun\u00e7\u00e3o de Perda................................................................................................................... 35 \nEqua\u00e7\u00e3o 14 \u2013 Fun\u00e7\u00e3o de Perda do Erro Quadr\u00e1tico ................................................................................... 35 \nEqua\u00e7\u00e3o 15 \u2013 Esperan\u00e7a Matem\u00e1tica Definida como Risco Funcional Esperado ..................................... 36 \nEqua\u00e7\u00e3o 16 \u2013 Fun\u00e7\u00e3o de Risco Condicionada a X .................................................................................. 36 \nEqua\u00e7\u00e3o 17 \u2013 Minimiza\u00e7\u00e3o do Risco Ponto a Ponto .................................................................................. 36 \nEqua\u00e7\u00e3o 18 \u2013 Esperan\u00e7a Condicionada ...................................................................................................... 36 \nEqua\u00e7\u00e3o 19 \u2013 Risco Emp\u00edrico .................................................................................................................... 38 \nEqua\u00e7\u00e3o 20 \u2013 O Fator de Regulariza\u00e7\u00e3o ?  (limite probabil\u00edstico do risco emp\u00edrico) .............................. 43 \nEqua\u00e7\u00e3o 21 \u2013 O Risco Esperado Relacionado ao Risco Emp\u00edrico e ao Fator de Regulariza\u00e7\u00e3o ? .......... 43 \nEqua\u00e7\u00e3o 22 \u2013 A Complexidade de f(x) Medida Indiretamente por Meio de uma Fun\u00e7\u00e3o Indicadora ........ 44 \nEqua\u00e7\u00e3o 23 \u2013 Conjunto de Treinamento .................................................................................................... 48 \nEqua\u00e7\u00e3o 24 \u2013 M\u00e9trica de Similaridade em X .......................................................................................... 49 \nEqua\u00e7\u00e3o 25 \u2013 Produto Interno Can\u00f4nico .................................................................................................... 49 \nEqua\u00e7\u00e3o 26 \u2013 Mapeando o Espa\u00e7o de Entrada X para o Espa\u00e7o de Caracter\u00edsticas cH ......................... 50 \nEqua\u00e7\u00e3o 27 \u2013 Similaridade no Espa\u00e7o de Caracter\u00edsticas .......................................................................... 51 \nEqua\u00e7\u00e3o 28 \u2013 Centr\u00f3ides das Classes (classifica\u00e7\u00e3o bin\u00e1ria) ..................................................................... 55 \nEqua\u00e7\u00e3o 29 \u2013 Fun\u00e7\u00e3o de Decis\u00e3o Empregando o Degrau .......................................................................... 57 \nEqua\u00e7\u00e3o 30 \u2013 Defini\u00e7\u00e3o da Fun\u00e7\u00e3o Degrau ............................................................................................... 57 \nEqua\u00e7\u00e3o 31 \u2013 Valor de Bias ....................................................................................................................... 58 \nEqua\u00e7\u00e3o 32 \u2013 Hiperplano de Classifica\u00e7\u00e3o ................................................................................................ 59 \nEqua\u00e7\u00e3o 33 \u2013 Propriedade do Vetor de Par\u00e2metros w\n\n?\n.............................................................................. 59 \n\nEqua\u00e7\u00e3o 34 \u2013 Fun\u00e7\u00e3o de Decis\u00e3o ............................................................................................................... 59 \nEqua\u00e7\u00e3o 35 \u2013 Forma Can\u00f4nica do Hiperplano de Classifica\u00e7\u00e3o ................................................................ 60 \nEqua\u00e7\u00e3o 36 \u2013 Desigualdades de Decis\u00e3o.................................................................................................... 60 \nEqua\u00e7\u00e3o 37 \u2013 Condi\u00e7\u00f5es para a Obten\u00e7\u00e3o do Hiperplano \u00d3timo............................................................... 60 \nEqua\u00e7\u00e3o 38 \u2013 Par\u00e2metros para Determinar o Hiperplano \u00d3timo ............................................................... 61 \nEqua\u00e7\u00e3o 39 \u2013 Margem de Separa\u00e7\u00e3o entre as Classes................................................................................ 61 \nEqua\u00e7\u00e3o 40 \u2013 Ponto M\u00e9dio da Margem de Separa\u00e7\u00e3o ............................................................................... 62 \nEqua\u00e7\u00e3o 41 \u2013 Equa\u00e7\u00e3o do Hiperplano \u00d3timo............................................................................................. 62 \nEqua\u00e7\u00e3o 42 \u2013 Restri\u00e7\u00f5es de Desigualdade da Forma Can\u00f4nica ................................................................. 62 \nEqua\u00e7\u00e3o 43 \u2013 Fun\u00e7\u00e3o Objetivo para Determinar o Hiperplano \u00d3timo....................................................... 62 \n\nEqua\u00e7\u00e3o 44 \u2013 Rela\u00e7\u00e3o entre 0w\n?\n\ne ( ) 1,},min{| 22 ?+?= bxwywww ii\n?????\n\n......................... 63 \nEqua\u00e7\u00e3o 45 \u2013 Lagrangiano ......................................................................................................................... 63 \nEqua\u00e7\u00e3o 46 \u2013 Fun\u00e7\u00e3o de Decis\u00e3o Empregando os Multiplicadores de Lagrange ...................................... 64 \nEqua\u00e7\u00e3o 47 \u2013 Margem Obtida com o Hiperplano \u00d3timo ........................................................................... 64 \nEqua\u00e7\u00e3o 48 \u2013 Dist\u00e2ncia entre os Vetores de Suporte (largura da margem) ................................................ 65 \n\n\n\n xi \n\nEqua\u00e7\u00e3o 49 \u2013 Expans\u00e3o do Kernel k ........................................................................................................ 66 \nEqua\u00e7\u00e3o 50 \u2013 Condi\u00e7\u00e3o de Mercer............................................................................................................. 66 \nEqua\u00e7\u00e3o 51 \u2013 Decis\u00e3o Impl\u00edcita no Espa\u00e7o de Caracter\u00edsticas................................................................... 67 \nEqua\u00e7\u00e3o 52 \u2013 Kernel de Fun\u00e7\u00e3o de Base Radial ........................................................................................ 69 \nEqua\u00e7\u00e3o 53 \u2013 Relaxamento da Forma Can\u00f4nica ........................................................................................ 70 \nEqua\u00e7\u00e3o 54 \u2013 Fun\u00e7\u00e3o Objetivo para Determinar o Hiperplano Quase-\u00d3timo (condi\u00e7\u00f5es relaxadas) ........ 70 \nEqua\u00e7\u00e3o 55 \u2013 Restri\u00e7\u00f5es para o Lagrangiano............................................................................................. 71 \nEqua\u00e7\u00e3o 56 \u2013 Fun\u00e7\u00e3o de Perda ? -insensitiva de Vapnik .......................................................................... 72 \nEqua\u00e7\u00e3o 57 \u2013 Regress\u00e3o Linear.................................................................................................................. 73 \nEqua\u00e7\u00e3o 58 \u2013 Fator de Otimiza\u00e7\u00e3o Quadr\u00e1tica .......................................................................................... 73 \nEqua\u00e7\u00e3o 59 \u2013 Fun\u00e7\u00e3o Objetivo para a Regress\u00e3o Linear ........................................................................... 73 \nEqua\u00e7\u00e3o 60 \u2013 Restri\u00e7\u00f5es da Fun\u00e7\u00e3o Objetivo ............................................................................................ 74 \nEqua\u00e7\u00e3o 61 \u2013 Fun\u00e7\u00e3o de Regress\u00e3o ........................................................................................................... 74 \nEqua\u00e7\u00e3o 62 \u2013 Desempenho de um Estimador Expresso pelo seu RMSE ................................................... 94 \nEqua\u00e7\u00e3o 63 \u2013 Conjunto de Regi\u00f5es de Consumo ....................................................................................... 98 \nEqua\u00e7\u00e3o 64 \u2013 Conjunto de Estimadores Leigos ......................................................................................... 98 \nEqua\u00e7\u00e3o 65 \u2013 O desempenho do Estimador x?  Aplicado \u00e0 Regi\u00e3o de Consumo y? ............................... 98 \nEqua\u00e7\u00e3o 66 \u2013 Limiar de Similaridade entre w?  e z? .............................................................................. 98 \nEqua\u00e7\u00e3o 67 \u2013 O Vetor de Caracter\u00edsticas da Regi\u00e3o y ............................................................................... 99 \nEqua\u00e7\u00e3o 68 \u2013 Variabilidade Total de um Sistema .................................................................................... 102 \nEqua\u00e7\u00e3o 69 \u2013 Identidade Fundamental da An\u00e1lise de Vari\u00e2ncia.............................................................. 102 \nEqua\u00e7\u00e3o 70 \u2013 Complexidade de Kolmogorov de Acordo com o MDL.................................................... 103 \nEqua\u00e7\u00e3o 71 \u2013 Normaliza\u00e7\u00e3o do Tempo Otimizado de Converg\u00eancia ...................................................... 108 \n \n \n\n\n\n \n\n\u00cdNDICE DE TABELAS \n\nTabela 1 \u2013 Regras de Decis\u00e3o para a Classifica\u00e7\u00e3o Bin\u00e1ria ....................................................................... 57 \nTabela 2 \u2013 Correla\u00e7\u00f5es dos Vetores de Caracter\u00edsticas de Cada Regi\u00e3o de Consumo ............................... 97 \nTabela 3 \u2013 Desempenho de Todos os Estimadores Aplicados a Todas as Regi\u00f5es .................................. 100 \nTabela 4 \u2013 Tempos de Converg\u00eancia para Gerar Modelos Preditores com e sem Otimiza\u00e7\u00e3o ................ 107 \n \n\n\n\n \n\nRESUMO \n\nAs novas condi\u00e7\u00f5es do mercado de energia el\u00e9trica exigem que as concession\u00e1rias \n\nmantenham altos n\u00edveis de qualidade nos seus sistemas. Isso se traduz em aspectos co-\n\nmo n\u00edvel de carregamento, continuidade de fornecimento e, mais recentemente, atua\u00e7\u00e3o \n\ninteligente no mercado atacadista de energia. Neste contexto, as informa\u00e7\u00f5es atuais ou \n\nhist\u00f3ricas n\u00e3o s\u00e3o suficientes para subsidiar o processo decis\u00f3rio: \u00e9 desej\u00e1vel conhecer \n\nas condi\u00e7\u00f5es do sistema no futuro, em especial a carga el\u00e9trica. Dada a complexidade \n\nt\u00edpica dos sistemas el\u00e9tricos, diversos trabalhos apresentam solu\u00e7\u00f5es para a predi\u00e7\u00e3o de \n\ncarga que se baseiam em sistemas inteligentes h\u00edbridos. Entretanto, embora estes siste-\n\nmas sejam eficazes e assegurem uma precis\u00e3o maior do que a obtida com modelos b\u00e1si-\n\ncos, muitas vezes eles demandam um alto custo computacional. Esse custo torna-se es-\n\npecialmente cr\u00edtico na determina\u00e7\u00e3o da relev\u00e2ncia preditiva das vari\u00e1veis dispon\u00edveis. \n\nNeste trabalho, \u00e9 apresentado um m\u00e9todo de classifica\u00e7\u00e3o para os perfis de consumo \n\nque otimiza a sele\u00e7\u00e3o das vari\u00e1veis preditoras. Como os perfis de consumo s\u00e3o proces-\n\nsos estoc\u00e1sticos variantes no tempo, as t\u00e9cnicas convencionais de extra\u00e7\u00e3o de caracter\u00eds-\n\nticas n\u00e3o s\u00e3o eficazes na sua representa\u00e7\u00e3o, formando padr\u00f5es inconsistentes. Por esta \n\nraz\u00e3o, \u00e9 apresentada uma nova forma de representa\u00e7\u00e3o baseada no desempenho de re-\n\ngressores SVM (Support Vector Machine) que estimam a carga el\u00e9trica em fun\u00e7\u00e3o das \n\ndiversas vari\u00e1veis com potencial preditivo. Esta t\u00e9cnica \u00e9 validada mediante a inspe\u00e7\u00e3o \n\ndo espa\u00e7o de caracter\u00edsticas gerado, o qual forma agrupamentos que compartilham os \n\nmesmos conjuntos de preditoras. \n\nPalavras-chave: previs\u00e3o de carga, intelig\u00eancia artificial, extra\u00e7\u00e3o de caracter\u00edsti-\n\ncas, SVM, redes neuronais. \n\n\n\nABSTRACT \n\nIn order to achieve high quality standards in electrical power systems, utility com-\n\npanies rely upon load forecasting to accomplish critical activities such as optimal dy-\n\nnamic dispatch and smart performance in the power wholesale market. Several works \n\npropose hybrid intelligent forecasting models to deal with the dynamic and non-linear \n\ncharacteristics of the load at a relatively high computational cost. While such ap-\n\nproaches give emphasis to the forecasting itself, this work presents a procedure to detect \n\nsimilarities among distinct consumption profiles. Empirical results show that similar \n\nprofiles share similar sets of relevant predictors. As finding similarities among profiles \n\nis less costly than finding the set of relevant predictors from scratch, a new parameter \n\nselection method is proposed. Such method is employed to build some neural forecast-\n\ners with considerable improvement in the learning time. \n\nKey words: load forecasting, artificial intelligence, feature extraction, SVM, neu-\n\nral networks. \n\n \n\n\n\n1 INTRODU\u00c7\u00c3O \n\nA desregulamenta\u00e7\u00e3o da economia vem afetando a sociedade de muitas formas \n\ndesde o advento da globaliza\u00e7\u00e3o na d\u00e9cada de 90. Novas diretrizes econ\u00f4micas foram \n\ndefinidas e modificaram o mercado de energia, o que conduziu \u00e0 dissolu\u00e7\u00e3o de muitos \n\nmonop\u00f3lios energ\u00e9ticos hist\u00f3ricos ao redor do globo. Como decorr\u00eancia deste panora-\n\nma, o pre\u00e7o da energia el\u00e9trica aos consumidores finais tem apresentado uma tend\u00eancia \n\nde queda (Iyer et al., 2003).  \n\nEmbora a forma como os governos conduzem seus mercados de energia possa va-\n\nriar ligeiramente de um pa\u00eds para o outro, observa-se certa propens\u00e3o de dividir toda a \n\ncadeia de fornecimento de energia entre pequenas concession\u00e1rias de gera\u00e7\u00e3o e trans-\n\nmiss\u00e3o. Estas concession\u00e1rias utilizam leil\u00f5es de energia para comprar ou vender ener-\n\ngia no mercado atacadista (Iyer et al., 2003). Al\u00e9m disso, elas devem atender certos pa-\n\ndr\u00f5es de qualidade relacionados \u00e0 estabilidade de fornecimento, n\u00edveis de tens\u00e3o acura-\n\ndos e outros aspectos t\u00e9cnicos (Santoso et al., 2002; Guo et al., 2006). \n\nPara lograr \u00eaxito neste cen\u00e1rio competitivo, as concession\u00e1rias lan\u00e7am m\u00e3o de di-\n\nversos recursos t\u00e9cnicos, tal como a predi\u00e7\u00e3o de carga (Iyer et al., 2003; Tao et al., \n\n2004; Guo et al., 2004; Niu et al., 2005). Se a predi\u00e7\u00e3o n\u00e3o for apropriadamente con-\n\ntemplada, as concession\u00e1rias podem sofrer perdas financeiras severas (Guo et al., 2004; \n\nHong et al., 2005; Niu et al., 2005), al\u00e9m de sujeitarem os consumidores a problemas de \n\nfornecimento (Santoso et al., 2002). Antever a demanda de energia permite o aprimo-\n\nramento de muitas atividades cr\u00edticas para o setor, como a compra de energia, controle \n\nde gera\u00e7\u00e3o, chaveamento de carga, negocia\u00e7\u00e3o de contratos e planejamento de infra-\n\nestrutura (Iyer et al., 2003; Tao et al., 2004; Hong et al., 2005; Guo et al., 2006).  \n\nO mercado de energia \u00e9 segmentado em tr\u00eas atividades distintas, mas fortemente \n\nacopladas: gera\u00e7\u00e3o, transmiss\u00e3o e distribui\u00e7\u00e3o (Pansini, 2005), mostradas esquemati-\n\ncamente na Figura 1. A gera\u00e7\u00e3o utiliza usinas de for\u00e7a que, mediante processos eletro-\n\nmagn\u00e9ticos, produzem eletricidade a partir de outros tipos de energia (t\u00e9rmica ou poten-\n\ncial hidr\u00e1ulica). A transmiss\u00e3o \u00e9 respons\u00e1vel por estruturas que coletam a energia el\u00e9tri-\n\n\n\n 2 \n\nca das usinas, elevam seu n\u00edvel de tens\u00e3o e a transportam at\u00e9 os centros consumidores \n\npor meio de linhas de transmiss\u00e3o. Nos centros consumidores, a distribui\u00e7\u00e3o encarrega-\n\nse de conectar as linhas de transmiss\u00e3o a subesta\u00e7\u00f5es de distribui\u00e7\u00e3o, as quais energi-\n\nzam os transformadores de distribui\u00e7\u00e3o atrav\u00e9s de circuitos de m\u00e9dia voltagem deno-\n\nminados alimentadores. Finalmente, ainda na distribui\u00e7\u00e3o, os consumidores finais s\u00e3o \n\nconectados aos transformadores da distribui\u00e7\u00e3o. O escopo deste trabalho \u00e9 orientado \u00e0 \n\ndistribui\u00e7\u00e3o, principalmente \u00e0s regi\u00f5es de consumo, real\u00e7adas no diagrama da Figura 1. \n\nEscopo do Trabalho\n\nG\n\nS\n\nS\n\nS\n\nT\n\nT\n\nT\n\nT\n\nT\n\nT\n\nFor\u00e7a\n(gera\u00e7\u00e3o)\n\nCarga\n(consumo)\n\nLinha de Transmiss\u00e3o Alimentador\n\nG\n\nS\n\nT\n\nConsumidor Final\n\nTransformador de \ndistribui\u00e7\u00e3o\n\nSubesta\u00e7\u00e3o de \ndistribui\u00e7\u00e3o\n\nGerador de Energia\n\nRegi\u00e3o de consumo\n\n \nFigura 1 \u2013 Diagrama Esquem\u00e1tico do Sistema El\u00e9trico e Escopo desta Disserta\u00e7\u00e3o \n\nAs subesta\u00e7\u00f5es abastecem consumidores localizados dentro de regi\u00f5es que s\u00e3o to-\n\npologicamente bem definidas (as regi\u00f5es de consumo) e que apresentam um perfil de \n\nconsumo caracter\u00edstico. Estes perfis definem o comportamento da carga el\u00e9trica em fun-\n\n\u00e7\u00e3o das diversas vari\u00e1veis explanat\u00f3rias, fornecendo informa\u00e7\u00f5es valiosas para otimizar \n\na distribui\u00e7\u00e3o de energia. Regi\u00f5es de consumo s\u00e3o est\u00e1ticas e estabelecem limites geo-\n\ngr\u00e1ficos para os perfis; estes \u00faltimos, por sua vez, s\u00e3o processos variantes no tempo que \n\ndescrevem as rela\u00e7\u00f5es causais entre as vari\u00e1veis explanat\u00f3rias e a carga. Um novo perfil \n\nde consumo \u00e9 determinado toda vez que essas rela\u00e7\u00f5es causais se alteram substancial-\n\nmente. Assim, as regi\u00f5es s\u00e3o perenes, contrastando com os perfis, que s\u00e3o transit\u00f3rios. \n\n\n\n 3 \n\nA carga mede a pot\u00eancia el\u00e9trica que uma regi\u00e3o consome num determinado ins-\n\ntante. Dependendo do perfil de consumo associado, a carga el\u00e9trica pode ser descrita \n\npor associa\u00e7\u00f5es de certas vari\u00e1veis explanat\u00f3rias, como temperatura, hor\u00e1rio ou situa\u00e7\u00e3o \n\ngeogr\u00e1fica. A compreens\u00e3o destas associa\u00e7\u00f5es \u00e9 vital para caracterizar os perfis de con-\n\nsumo, compar\u00e1-los e construir modelos computacionais capazes de predizer a demanda \n\nde energia el\u00e9trica. \n\nEste trabalho lida com predi\u00e7\u00e3o de carga de curto prazo; ou seja, com predi\u00e7\u00e3o de \n\npoucos minutos ou horas \u00e0 frente (Oliveira, 2004). No entanto, diferentemente de traba-\n\nlhos correlatos mencionados ao longo desta pesquisa, a proposta desta pesquisa \u00e9 otimi-\n\nzar algoritmos j\u00e1 existentes. Uma premissa fundamental \u00e9 que a informa\u00e7\u00e3o necess\u00e1ria \n\npara se construir um modelo de previs\u00e3o est\u00e1 dispon\u00edvel, restando identific\u00e1-la e proces-\n\ns\u00e1-la de forma adequada. Isso n\u00e3o \u00e9 uma tarefa trivial, considerando que a previs\u00e3o de \n\ncarga el\u00e9trica envolve o entendimento de processos n\u00e3o-lineares e variantes no tempo. \n\nPortanto, ainda que as vari\u00e1veis preditoras sejam de f\u00e1cil obten\u00e7\u00e3o, sua influ\u00eancia na \n\ncarga pode ser desconhecida ou mal compreendida. Al\u00e9m disso, \u00e9 poss\u00edvel que o con-\n\njunto de vari\u00e1veis preditoras com efetiva influ\u00eancia na demanda se altere com o perfil \n\ns\u00f3cio-geogr\u00e1fico, conforme demonstrado por Oliveira (2004) e Hong et al. (2005).  \n\nEm geral, a constru\u00e7\u00e3o de um modelo preditor eficiente exige uma escolha criteri-\n\nosa das vari\u00e1veis de entrada (Oliveira, 2004; Tao et al., 2004; Hong et al., 2005), as \n\nquais tipicamente comp\u00f5em um subconjunto de todas as vari\u00e1veis dispon\u00edveis, como \n\nmostrado na Figura 2. Como destacado nessa figura, o escopo do presente trabalho n\u00e3o \n\nconsiste nos modelos de predi\u00e7\u00e3o propriamente ditos, mas na sele\u00e7\u00e3o de par\u00e2metros e \n\nidentifica\u00e7\u00e3o de preditoras (tamb\u00e9m chamadas de vari\u00e1veis explanat\u00f3rias, vari\u00e1veis \n\npreditoras ou simplesmente preditoras1). \n\n\u00c9 relevante observar que o termo sele\u00e7\u00e3o de par\u00e2metros \u00e9 empregado na biblio-\n\ngrafia de estat\u00edstica com uma conota\u00e7\u00e3o distinta. Neste trabalho, assim como em muitas \n\nrefer\u00eancias de intelig\u00eancia artificial e de Teoria do Aprendizado Estat\u00edstico, a sele\u00e7\u00e3o de \n\n                                                           \n1 As refer\u00eancias bibliogr\u00e1ficas utilizadas para a elabora\u00e7\u00e3o deste trabalho s\u00e3o predominantemente escritas \nem ingl\u00eas, onde as vari\u00e1veis preditoras s\u00e3o denominadas de predictors (adjetivo), e os modelos de predi-\n\u00e7\u00e3o, forecasters (substantivo). Ambos os termos s\u00e3o traduzidos para o portugu\u00eas como preditores. Assim, \npara evitar problemas sem\u00e2nticos, optou-se neste trabalho por traduzir o primeiro como preditoras (de \nvari\u00e1veis preditoras), e o segundo como preditores (de modelos preditores).  \n\n\n\n 4 \n\npar\u00e2metros consiste no processo de sele\u00e7\u00e3o do modelo mais apropriado para a predi\u00e7\u00e3o; \n\nou seja, a sele\u00e7\u00e3o de par\u00e2metros define o conjunto de par\u00e2metros de entrada que \u00e9 rele-\n\nvante para a predi\u00e7\u00e3o [Tao et al., 2004; Hong et al., 2005]. \n\nA sele\u00e7\u00e3o de par\u00e2metros \u00e9 necess\u00e1ria para manter a complexidade computacional \n\nsob controle e diminuir o tempo de converg\u00eancia, al\u00e9m de assegurar a precis\u00e3o das pre-\n\ndi\u00e7\u00f5es. As preditoras constituem os par\u00e2metros fixos do modelo e devem possuir rele-\n\nv\u00e2ncia preditiva; caso contr\u00e1rio, o desempenho da predi\u00e7\u00e3o pode se degradar devido a \n\nfatores como ru\u00eddo ou multicolinearidade (Haykin, 1998; Montgomery et al., 2001). \n\nPortanto, a an\u00e1lise preditiva passa a depender tamb\u00e9m de um mecanismo de sele\u00e7\u00e3o de \n\npar\u00e2metros. \n\nVari\u00e1veis de \nEntrada\n\nSele\u00e7\u00e3o de\nPar\u00e2metros\n\nPreditoras Modelo de\nPredi\u00e7\u00e3o\n\nm? n?\nmn ?\n\nTodas as \nvari\u00e1veis \n\ndispon\u00edveis\n\nVari\u00e1veis \nRelevantes\n\nEscopo do Trabalho\n\n \n\nFigura 2 \u2013 Esquema da Constru\u00e7\u00e3o de um Preditor de Carga e Escopo deste Trabalho \n\n\u00c9 preciso considerar tamb\u00e9m que o perfil de consumo de uma regi\u00e3o \u00e9, em geral, \n\ndin\u00e2mico, o que significa que as rela\u00e7\u00f5es causais entre os preditores e a carga n\u00e3o \u00e9 \n\nconstante. Em outras palavras, a relev\u00e2ncia preditiva das vari\u00e1veis explanat\u00f3rias pode se \n\nmodificar ao longo do tempo (Oliveira, 2004); por exemplo, uma dada vari\u00e1vel pode ser \n\nrelevante somente em alguns per\u00edodos do ano. Por essa raz\u00e3o, os modelos de predi\u00e7\u00e3o \n\ns\u00e3o transit\u00f3rios, devendo ser monitorados e, caso necess\u00e1rio, reconstru\u00eddos. Sem esta \n\ncautela, os erros de predi\u00e7\u00e3o tendem a aumentar progressivamente \u2013 um fen\u00f4meno co-\n\nnhecido como obsolesc\u00eancia (Oliveira, 2004).  \n\nDentro do cen\u00e1rio descrito, destacam-se tr\u00eas fatores que prejudicam o desempe-\n\nnho da predi\u00e7\u00e3o de carga:  \n\na) A constru\u00e7\u00e3o cont\u00ednua de modelos preditores atualizados, o que se traduz em \n\ntempo de processamento. \n\n\n\n 5 \n\nb) A determina\u00e7\u00e3o das vari\u00e1veis preditoras (par\u00e2metros fixos do modelo2). \n\nc) O descarte do conhecimento assimilado pelos modelos obsoletos.  \n\nCada vez que um preditor se torna obsoleto ou um perfil de consumo desconheci-\n\ndo \u00e9 processado, a sele\u00e7\u00e3o de par\u00e2metros deve ser realizada para que um novo preditor \n\npossa ser constru\u00eddo. Se iniciada a partir de nenhum conhecimento pr\u00e9vio, tal sele\u00e7\u00e3o \n\npode consumir horas de processamento em um grid computacional (Oliveira, 2004), \n\ndesperdi\u00e7ando o conhecimento incorporado nos modelos j\u00e1 consolidados. Uma forma \n\nde minimizar os fatores citados \u00e9 criar um crit\u00e9rio de similaridade entre os perfis de \n\nconsumo, permitindo que os modelos obsoletos subsidiem de alguma forma a constru-\n\n\u00e7\u00e3o dos novos modelos.  \n\nEste trabalho explora este ponto considerando a seguinte hip\u00f3tese: perfis de con-\n\nsumo similares possuem conjuntos similares de preditoras. Se for demonstrado que esta \n\nhip\u00f3tese \u00e9 consistente, ser\u00e1 poss\u00edvel tornar a sele\u00e7\u00e3o de par\u00e2metros mais simples e di-\n\nminuir o tempo necess\u00e1rio para construir um modelo preditor. Al\u00e9m disso, novos mode-\n\nlos podem ser constru\u00eddos com base nos j\u00e1 consolidados, dependendo do grau de simila-\n\nridade entre os perfis de consumo. Por exemplo, se duas regi\u00f5es de consumo distintas \n\npossuem perfis de consumo similares, seus preditores tendem a serem parecidos e em-\n\npregar\u00e3o conjuntos de preditoras semelhantes. Quanto maior a similaridade entre os \n\nperfis, mais parecidos ser\u00e3o os seus preditores. Teoricamente, no limite, o conjunto de \n\npreditoras ser\u00e1 o id\u00eantico e mesmo preditor servir\u00e1 para ambos. \n\nUm outro exemplo \u00e9 o caso de certas regi\u00f5es balne\u00e1rias onde o consumo de ener-\n\ngia \u00e9 alto no ver\u00e3o (alta temporada), mas decresce consideravelmente no restante do ano \n\n(baixa temporada). Em tese, na aus\u00eancia de crescimento vegetativo, a sazonalidade do \n\nconsumo estabeleceria dois perfis de consumo, um para a alta temporada e outro para a \n\nbaixa. A Figura 3 mostra este cen\u00e1rio modelado como uma m\u00e1quina de estados finitos \n\ncom dois estados, cada um deles correspondendo a uma temporada que, por sua vez, \n\ndetermina um perfil de consumo.  \n\n                                                           \n2 Vladmir Vapnik (Vapnik, 1998; Vapnik, 1999) conceitua as vari\u00e1veis explanat\u00f3rias como par\u00e2metros \nfixos do modelo em oposi\u00e7\u00e3o aos par\u00e2metros ajust\u00e1veis, que s\u00e3o as constantes ajust\u00e1veis (fatores de pon-\ndera\u00e7\u00e3o) utilizadas para combinar linearmente as entradas (vari\u00e1veis explanat\u00f3rias) do modelo. \n\n\n\n 6 \n\nSempre que uma temporada se encerra, ocorre uma transi\u00e7\u00e3o. Como existem dois \n\nperfis, somente dois modelos s\u00e3o necess\u00e1rios para predizer carga nesta regi\u00e3o de con-\n\nsumo. Ent\u00e3o, n\u00e3o h\u00e1 necessidade de se criar novos modelos para essa regi\u00e3o \u2013 tudo que \n\n\u00e9 necess\u00e1rio fazer \u00e9 alternar o modelo em uso quando ocorre uma transi\u00e7\u00e3o. Entretanto, \n\na aus\u00eancia de um crit\u00e9rio de similaridade pode fazer com que um novo modelo seja \n\nconstru\u00eddo toda vez que uma temporada se encerra, simplesmente porque o fen\u00f4meno \n\nda altern\u00e2ncia de perfis n\u00e3o \u00e9 percebido.  \n\n \n\nPerfil A\n(Preditor 1)\n\nPerfil B\n(Preditor 2)\n\nBaixa esta\u00e7\u00e3o\n\nVer\u00e3o\n\n \nFigura 3 \u2013 Altern\u00e2ncia de Perfis numa Regi\u00e3o de Consumo Hipot\u00e9tica \n\nA Figura 3 mostra um cen\u00e1rio bastante simplificado, onde as vantagens de se rea-\n\nproveitar o conhecimento existente em preditores consolidados s\u00e3o pequenas. Entretan-\n\nto, numa aplica\u00e7\u00e3o industrial de grande escala onde uma concession\u00e1ria de distribui\u00e7\u00e3o \n\nmanda instru\u00e7\u00f5es de despacho a cada 15 minutos para sua geradora, salvaguardar recur-\n\nsos computacionais pode ser importante.  \n\nN\u00e3o \u00e9 poss\u00edvel aproveitar o conhecimento acumulado pelos preditores de carga j\u00e1 \n\nconsolidados, exceto se uma m\u00e9trica de similaridade entre os perfis for estabelecida. Os \n\nesfor\u00e7os deste trabalho est\u00e3o concentrados na defini\u00e7\u00e3o de tal m\u00e9trica, idealizada a par-\n\ntir de dados reais de subesta\u00e7\u00f5es existentes. Estes dados foram obtidos pelo sistema \n\nSCADA das Centrais El\u00e9tricas de Santa Catarina (concession\u00e1ria de distribui\u00e7\u00e3o do \n\nestado de Santa Catarina).  \n\n\u00c9 preciso notar que a similaridade n\u00e3o se deriva naturalmente dos dados amostra-\n\ndos (brutos), mas requer um processamento elaborado de cada perfil. Como os perfis \n\ns\u00e3o na realidade grandes conjuntos amostrados de grandezas el\u00e9tricas e meteorol\u00f3gicas, \n\num novo m\u00e9todo foi criado durante esta pesquisa para extrair caracter\u00edsticas deles. Des-\n\n\n\n 7 \n\nta forma, torna-se poss\u00edvel buscar regularidades em um espa\u00e7o geom\u00e9trico conveniente \n\n(espa\u00e7o de caracter\u00edsticas), onde os perfis s\u00e3o visualizados como vetores. A mesma a-\n\nbordagem foi modificada para analisar a relev\u00e2ncia preditiva das diferentes vari\u00e1veis em \n\nrela\u00e7\u00e3o \u00e0 carga, gerando um outro espa\u00e7o geom\u00e9trico (espa\u00e7o causal). Ambos os espa-\n\n\u00e7os s\u00e3o descritos neste trabalho e indicam que perfis semelhantes compartilham conjun-\n\ntos semelhantes de preditoras. \n\nA utiliza\u00e7\u00e3o do m\u00e9todo desenvolvido permitiria armazenar os dados de todos os \n\nperfis processados at\u00e9 um determinado instante. Ap\u00f3s um lapso de tempo razo\u00e1vel, uma \n\nbase de conhecimento com estas informa\u00e7\u00f5es poderia minimizar a necessidade de pr\u00e9-\n\nprocessamento (sele\u00e7\u00e3o de par\u00e2metros). De fato, a m\u00e1quina de estados da Figura 3 mos-\n\ntra que a obsolesc\u00eancia de um preditor ocorre quando o perfil de uma regi\u00e3o muda. Se a \n\nbase de conhecimento for grande o suficiente, toda transi\u00e7\u00e3o da m\u00e1quina de estados \n\nconduzir\u00e1 a um perfil conhecido (j\u00e1 processado).  \n\nA Figura 4 mostra esse cen\u00e1rio, onde uma regi\u00e3o de consumo hipot\u00e9tica evolui a-\n\ntrav\u00e9s de perfis conhecidos pela base de conhecimento, como indicado pelas setas ver-\n\nmelhas. Os perfis em segundo plano n\u00e3o s\u00e3o atingidos pelas transi\u00e7\u00f5es dessa regi\u00e3o, \n\nmas poderiam pertencer a outras regi\u00f5es. Como os perfis s\u00e3o conhecidos, os preditores \n\nassociados, bem como os respectivos conjuntos de preditoras, tamb\u00e9m o s\u00e3o. Desta \n\nforma, n\u00e3o h\u00e1 necessidade de se criarem novos preditores e o custo de opera\u00e7\u00e3o deste \n\nsistema se resumiria \u00e0 recupera\u00e7\u00e3o de informa\u00e7\u00f5es da base de conhecimento.  \n\n \n\n \nFigura 4 \u2013 Evolu\u00e7\u00e3o dos Perfis de Consumo em uma Regi\u00e3o \n\n\n\n 8 \n\nAinda que perfis id\u00eanticos sejam uma idealidade inalcan\u00e7\u00e1vel, freq\u00fcentemente a \n\nsimilaridade observada \u00e9 muito grande. Sob estas condi\u00e7\u00f5es, n\u00e3o se evita a constru\u00e7\u00e3o \n\nde novos preditores, mas o tempo necess\u00e1rio para constru\u00ed-los \u00e9 substancialmente redu-\n\nzido, como ser\u00e1 mostrado no Cap\u00edtulo 6 e discutido no Cap\u00edtulo 7. \n\n1.1 Objetivos \n\nConforme salienta a Figura 2, este trabalho n\u00e3o lida diretamente com a predi\u00e7\u00e3o \n\nde carga, mas analisa e prop\u00f5e mecanismos para otimiz\u00e1-la computacionalmente. O \n\nobjetivo geral \u00e9 identificar padr\u00f5es \u00fateis na predi\u00e7\u00e3o de carga dos perfis de consumo. \n\nDesta forma, esta pesquisa \u00e9 orientada a algoritmos de predi\u00e7\u00e3o como o PCarga (Olivei-\n\nra, 2004), o SPDS (Guo et al., 2004) ou o GRNN (Iyer et al., 2003), sendo poss\u00edvel que \n\noutras abordagens diferenciadas tamb\u00e9m possam aplicar as t\u00e9cnicas aqui desenvolvidas. \n\nA predi\u00e7\u00e3o de carga \u00e9 uma tarefa computacionalmente complexa. De fato, somen-\n\nte a determina\u00e7\u00e3o da relev\u00e2ncia preditiva das vari\u00e1veis dispon\u00edveis pode consumir horas \n\nde processamento, ao passo que os modelos assim gerados podem se defasar rapidamen-\n\nte, n\u00e3o sendo mais capazes de produzir informa\u00e7\u00e3o \u00fatil (Oliveira, 2004). Esta pesquisa \n\nexplora este aspecto da predi\u00e7\u00e3o de carga, determinando uma m\u00e9trica de similaridade \n\npara os perfis de consumo tal que perfis semelhantes possuam conjunto de preditoras \n\nsemelhantes. Com isso, o tempo necess\u00e1rio para descobrir novos preditores de carga \u00e9 \n\nsignificativamente reduzido, como demonstrado neste trabalho. \n\n1.2 Justificativa \n\nA estrutura do mercado de energia el\u00e9trica sofreu transforma\u00e7\u00f5es radicais em mui-\n\ntos pa\u00edses a partir da d\u00e9cada de 90, inclusive no Brasil. A eletricidade passou a ser con-\n\nsiderada uma commodity, sendo inclusive utilizada por investidores como op\u00e7\u00e3o de \n\ninvestimento cotada em mercados de energia spot. Dentro deste novo conceito, os gran-\n\ndes monop\u00f3lios regionais ou nacionais s\u00e3o pulverizados em unidades menores de gera-\n\n\n\n 9 \n\n\u00e7\u00e3o e distribui\u00e7\u00e3o, as quais integram um grande mercado atacadista de energia (a C\u00e2ma-\n\nra de Comercializa\u00e7\u00e3o de Energia, no caso do Brasil).  \n\nPassando ao largo de considera\u00e7\u00f5es de cunho ideol\u00f3gico, \u00e9 poss\u00edvel afirmar que \n\ntal conceito \u00e9 essencialmente ben\u00e9fico, porque imp\u00f5e ao sistema el\u00e9trico as regras con-\n\nvencionais do mercado de bens e servi\u00e7o, baseadas nas consagradas rela\u00e7\u00f5es entre ofer-\n\nta e demanda. Assim, espera-se que o mercado seja capaz de se regular sozinho e que a \n\ncompeti\u00e7\u00e3o pela venda da commodity no mercado resulte numa queda de pre\u00e7o aos \n\nconsumidores finais. Do outro lado da rela\u00e7\u00e3o de consumo, as geradoras e as distribui-\n\ndoras empenham-se em diminuir os custos operacionais e melhorar a efici\u00eancia de suas \n\nestruturas f\u00edsicas, buscando alternativas tecnol\u00f3gicas que subsidiem sua opera\u00e7\u00e3o e as-\n\nsegurem sua competitividade.  \n\nEntre os recursos tecnol\u00f3gicos existentes para assegurar a atua\u00e7\u00e3o inteligente do \n\nmercado energ\u00e9tico, est\u00e3o as solu\u00e7\u00f5es de predi\u00e7\u00e3o de carga. Antecipar a demanda por \n\nenergia \u00e9 vital n\u00e3o somente para os participantes do mercado atacadista de energia, mas \n\ntamb\u00e9m para a sociedade como um todo. A regulamenta\u00e7\u00e3o prescrita \u00e0s empresas de \n\nenergia envolve a manuten\u00e7\u00e3o de certos n\u00edveis de qualidade que s\u00f3 podem ser mantidos \n\nmediante manobras t\u00e9cnicas corretas e investimentos apropriados na infra-estrutura. Por \n\noutro lado, os consumidores esperam usufruir o fornecimento independentemente das \n\ndecis\u00f5es t\u00e9cnicas ou administrativas necess\u00e1rias para manter os sistemas de energia em \n\nfuncionamento. Neste contexto, prever o consumo em horizontes de tempo que variam \n\nde poucos minutos a muitos anos a frente \u00e9 uma vantagem competitiva valiosa.  \n\nEmbora a predi\u00e7\u00e3o de energia seja uma \u00e1rea aparentemente consolidada, inclusive \n\ncom v\u00e1rias solu\u00e7\u00f5es comerciais dispon\u00edveis, existem alguns aspectos que parecem n\u00e3o \n\nestar totalmente sedimentados. Com efeito, grande parte dos trabalhos analisados pro-\n\np\u00f5e a aplica\u00e7\u00e3o de t\u00e9cnicas inteligentes h\u00edbridas baseadas em redes neuronais. Via de \n\nregra, estas abordagens consistem em arquiteturas inovadoras, visando sempre aprimo-\n\nrar a precis\u00e3o obtida, o tempo de converg\u00eancia ou a diminui\u00e7\u00e3o do custo computacional.  \n\nNo entanto, como a demanda de energia \u00e9 um processo estoc\u00e1stico din\u00e2mico, os \n\nmodelos de predi\u00e7\u00e3o devem ser adaptativos; ou seja, devem acompanhar as mudan\u00e7as \n\nque ocorrem nas regi\u00f5es de consumo ao longo do tempo (Figura 4). Ora, todos os traba-\n\n\n\n 10 \n\nlhos analisados s\u00e3o baseados em t\u00e9cnicas conexionistas est\u00e1ticas, onde a adapta\u00e7\u00e3o s\u00f3 \u00e9 \n\nposs\u00edvel durante a fase de aprendizado. Como conseq\u00fc\u00eancia, as predi\u00e7\u00f5es podem se \n\ntornar imprecisas, o que exige a constru\u00e7\u00e3o de novos preditores.  \n\nEsta pesquisa focaliza esse ponto, propondo um m\u00e9todo para reciclar o conheci-\n\nmento existente nos modelos j\u00e1 criados, de forma que eles subsidiem a constru\u00e7\u00e3o de \n\nnovos modelos. Com isso, pretende-se diminuir o custo computacional necess\u00e1rio para \n\nconstruir novos preditores, uma vez que isso envolve tempos de processamento relati-\n\nvamente longos. \u00c9 importante destacar que a redu\u00e7\u00e3o destes tempos n\u00e3o \u00e9 meramente \n\numa quest\u00e3o de efici\u00eancia computacional, principalmente na previs\u00e3o de curto prazo \n\n(tema desta pesquisa). Em condi\u00e7\u00f5es reais de opera\u00e7\u00e3o, o tempo da resposta \u00e9 t\u00e3o cr\u00edtico \n\nquanto a sua precis\u00e3o.   \n\nA estrat\u00e9gia delineada neste trabalho consiste em comparar perfis de consumo dis-\n\ntintos. O problema inicia na determina\u00e7\u00e3o de crit\u00e9rios de similaridade v\u00e1lidos para os \n\nperfis, de tal forma que perfis semelhantes utilizem modelos preditores semelhantes. A \n\nid\u00e9ia b\u00e1sica \u00e9 realizar uma atividade de baixo custo computacional (determinar a simila-\n\nridade entre os perfis) para poder otimizar uma atividade de alto custo computacional \n\n(construir modelos de predi\u00e7\u00e3o). A otimiza\u00e7\u00e3o \u00e9 baseada em duas propriedades essenci-\n\nais da predi\u00e7\u00e3o de energia, demonstradas ao longo desta pesquisa:  \n\na) Perfis de consumo semelhantes possuem conjuntos semelhantes de vari-\n\n\u00e1veis com relev\u00e2ncia preditiva. \n\nb) A cria\u00e7\u00e3o de um preditor para um perfil de consumo desconhecido pode \n\nser facilitada quando iniciada a partir de outro preditor, desde que am-\n\nbos os preditores estejam associados a perfis de consumo semelhantes.  \n\nA propriedade (a) parece expressar uma no\u00e7\u00e3o do senso comum, mas a aus\u00eancia \n\nde um crit\u00e9rio de similaridade v\u00e1lido impossibilita sua aplica\u00e7\u00e3o no contexto da predi-\n\n\u00e7\u00e3o de carga. A propriedade (b) \u00e9 uma decorr\u00eancia da propriedade (a), uma vez que a \n\nrelev\u00e2ncia dos preditores na carga el\u00e9trica constitui fator preponderante na similaridade \n\nentre os perfis. Assim, basicamente esta pesquisa consiste em descobrir um crit\u00e9rio de \n\n\n\n 11 \n\nsimilaridade que satisfa\u00e7a a propriedade (a) para que possa ser explorada a propriedade \n\n(b). \n\n1.3 Metodologia \n\nA literatura de reconhecimento de padr\u00f5es (por exemplo, Duda 2001 ou Haykin \n\n1994) n\u00e3o aborda a extra\u00e7\u00e3o de caracter\u00edsticas para sistemas variantes no tempo, dando \n\n\u00eanfase \u00e0s t\u00e9cnicas de reconhecimento propriamente ditas. Outros trabalhos, como o \n\ncl\u00e1ssico de Oppenheim (1989), apresentam diversas ferramentas matem\u00e1ticas para pro-\n\ncessamento de sinais, mas sem apresentar diretamente solu\u00e7\u00f5es para a representa\u00e7\u00e3o de \n\nsistemas como os perfis de consumo.  \n\n\u00c9 preciso considerar que, matematicamente, os perfis de consumo s\u00e3o grandes \n\nconjuntos amostrados de grandezas meteorol\u00f3gicas e el\u00e9tricas, normalmente armazena-\n\ndos em estruturas matriciais de alta dimensionalidade. Portanto, n\u00e3o existe uma maneira \n\ndireta de represent\u00e1-los convenientemente. Por essa raz\u00e3o, o primeiro passo dessa pes-\n\nquisa foi criar um espa\u00e7o de caracter\u00edsticas onde os perfis de consumo pudessem ser \n\nvisualizados como vetores e uma m\u00e9trica de similaridade pudesse ser estabelecida. Es-\n\ntabelecido o espa\u00e7o de caracter\u00edsticas, torna-se necess\u00e1rio classificar os perfis de con-\n\nsumo. Esta etapa foi implementada utilizando escalonamento multidimensional e k-\n\nmeans, de forma que perfis semelhantes sejam representados dentro dos mesmos agru-\n\npamentos. Ap\u00f3s a classifica\u00e7\u00e3o, o perfil \u00e9 comparado com outros, obtidos anteriormen-\n\nte. Se a compara\u00e7\u00e3o indicar similaridade com algum perfil armazenado, o modelo asso-\n\nciado a este \u00faltimo \u00e9 recuperado e utilizado para construir o novo modelo. Com isso, o \n\nprocesso de sele\u00e7\u00e3o de par\u00e2metros pode se tornar mais simples e mais r\u00e1pido.  \n\nA Figura 5 mostra o sistema descrito como um diagrama de blocos. Como mos-\n\ntrado, a extra\u00e7\u00e3o de caracter\u00edsticas deve ser capaz de representar um determinado perfil \n\nde consumo atrav\u00e9s do vetor de caracter\u00edsticas, constitu\u00eddo por um grupo manuse\u00e1vel de \n\nn\u00fameros. Tamb\u00e9m \u00e9 mostrado um banco de dados, denominado de Base de Conheci-\n\nmento. Esta base armazena dados relativos a perfis de consumo j\u00e1 processados, ou seja; \n\n\n\n 12 \n\nvetores de caracter\u00edsticas, conjuntos \u00f3timos de vari\u00e1veis preditoras e modelos preditores \n\nconsolidados.  \n\nBase de\nConhecimento\n\nPerfis de consumo Extra\u00e7\u00e3o de \nCaracter\u00edsticas\n\nCompara\u00e7\u00e3o e \nControle\n\nConstru\u00e7\u00e3o do \nModelo Preditor\n\nAlgoritmo de \nClassifica\u00e7\u00e3o\n\nCaracter\u00edsticas\n(vetor de caracter\u00edsticas)\n\nInforma\u00e7\u00e3o Relevante \npara a Predi\u00e7\u00e3o\n\nVetores de caracter\u00edsticas, \npreditoras e modelos de predi\u00e7\u00e3o\n\nDados \nArmazenados\n\nModelo de Predi\u00e7\u00e3o\n\n(Preditoras e modelos \nde predi\u00e7\u00e3o)\n\n(S\u00e9ries hist\u00f3ricas de vari\u00e1veis\nel\u00e9tricas e meteorol\u00f3gicas)\n\n \nFigura 5 \u2013 Sistema de Predi\u00e7\u00e3o de Carga Otimizado com o Uso de uma Base de Conhecimento \n\nO m\u00f3dulo de Compara\u00e7\u00e3o e Controle controla o fluxo de informa\u00e7\u00f5es em toda a \n\nestrutura. Este m\u00f3dulo fornece par\u00e2metros para a extra\u00e7\u00e3o de caracter\u00edsticas e determina \n\nqual dos perfis armazenados mais se assemelha com o perfil de entrada. Assim, a cons-\n\ntru\u00e7\u00e3o do novo modelo preditor pode iniciar a partir das informa\u00e7\u00f5es associadas ao mo-\n\ndelo similar. No caso de preditores adaptativos, como as RNAs, isso permite deslocar o \n\nponto de inicializa\u00e7\u00e3o para uma regi\u00e3o pr\u00f3xima do melhor m\u00ednimo local conhecido \n\n(possivelmente um m\u00ednimo global) na superf\u00edcie de erro, acelerando a converg\u00eancia.  \n\nDos m\u00f3dulos mencionados, somente a extra\u00e7\u00e3o de caracter\u00edsticas e a classifica\u00e7\u00e3o \n\nser\u00e3o descritas neste trabalho. Os demais s\u00e3o omitidos por tratarem de aspectos secun-\n\nd\u00e1rios da pesquisa, tais como o armazenamento de dados e o controle do fluxo de in-\n\nforma\u00e7\u00f5es. \n\n1.4 Limita\u00e7\u00f5es do Trabalho \n\nA solu\u00e7\u00e3o desenvolvida neste trabalho \u00e9 essencialmente constitu\u00edda de uma an\u00e1li-\n\nse explorat\u00f3ria dos perfis de consumo para determinar regularidades \u00fateis na otimiza\u00e7\u00e3o \n\nda predi\u00e7\u00e3o de carga el\u00e9trica. Esta \u00e9 uma abordagem heur\u00edstica cuja validade \u00e9 demons-\n\ntrada empiricamente para uma s\u00e9rie de casos reais, utilizados pelo projeto PCarga (Oli-\n\n\n\n 13 \n\nveira, 2004). Assim, a regra de similaridade criada \u00e9 baseada em tend\u00eancias observadas \n\nnos espa\u00e7os criados, e n\u00e3o necessariamente em demonstra\u00e7\u00f5es matem\u00e1ticas rigorosas.  \n\nEm tese, esse fato poderia suscitar d\u00favidas quanto \u00e0 generalidade das t\u00e9cnicas de-\n\nsenvolvidas. N\u00e3o obstante, \u00e9 oportuno observar que muitas aplica\u00e7\u00f5es consolidadas, \n\nespecialmente aquelas baseadas em modelos conexionistas, fazem uso de abordagens \n\nsemelhantes. Em todas estas abordagens, sistemas complexos s\u00e3o modelados por estru-\n\nturas de aprendizado capazes de reproduzir com precis\u00e3o rela\u00e7\u00f5es de causa e efeito que, \n\nmuitas vezes, n\u00e3o s\u00e3o explicadas analiticamente. O mecanismo que assegura esta fun-\n\ncionalidade \u00e9 a chamada abordagem emp\u00edrica (Vapnik, 1998; Vapnik, 1999), onde as \n\nregras causais de um sistema s\u00e3o depreendidas a partir de uma amostra de dados, sem \n\npreju\u00edzo da generalidade (infer\u00eancia indutiva). \n\n1.5 Organiza\u00e7\u00e3o do Trabalho \n\nEste trabalho est\u00e1 organizado em sete Cap\u00edtulos, descritos brevemente a seguir.  \n\nO Cap\u00edtulo 1 apresenta uma breve introdu\u00e7\u00e3o ao tema, os objetivos, as justificati-\n\nvas, a metodologia desenvolvida e as limita\u00e7\u00f5es do trabalho. \n\nNo Cap\u00edtulo 2 s\u00e3o apresentados os conceitos b\u00e1sicos dos sistemas de energia, in-\n\ncluindo algumas breves considera\u00e7\u00f5es t\u00e9cnicas, necess\u00e1rias para a compreens\u00e3o do ce-\n\nn\u00e1rio em que este trabalho foi desenvolvido.  \n\nO Cap\u00edtulo 3 apresenta uma revis\u00e3o bibliogr\u00e1fica sobre Estima\u00e7\u00e3o e Predi\u00e7\u00e3o, \n\nmencionando elementos fundamentais da Teoria do Aprendizado Estat\u00edstico como a \n\nminimiza\u00e7\u00e3o de risco. \n\nNo Cap\u00edtulo 4 \u00e9 apresentada uma revis\u00e3o bibliogr\u00e1fica sobre M\u00e1quinas de Vetores \n\nde Suporte, sobre as quais este trabalho se fundamenta. \n\nO Cap\u00edtulo 5 apresenta sucintamente algumas solu\u00e7\u00f5es de predi\u00e7\u00e3o de carga de-\n\nsenvolvidas recentemente no meio acad\u00eamico.  \n\n\n\n 14 \n\nO Cap\u00edtulo 6 descreve as hip\u00f3teses de trabalho e os procedimentos experimentais \n\nlevados a cabo para fundament\u00e1-las. Ainda neste Cap\u00edtulo, s\u00e3o realizadas algumas simu-\n\nla\u00e7\u00f5es que demonstram empiricamente a validade do m\u00e9todo desenvolvido.  \n\nPor fim, o Cap\u00edtulo 7 apresenta as conclus\u00f5es e uma discuss\u00e3o final referentes ao \n\ntrabalho, bem como sugest\u00f5es de trabalhos futuros. \n\n \n\n\n\n2 O SISTEMA EL\u00c9TRICO \n\n2.1 Breve Perspectiva Hist\u00f3rica, Defini\u00e7\u00f5es Essenciais e Alguns Ele-\n\nmentos Matem\u00e1ticos \n\nPara os f\u00edsicos, todo o Universo \u00e9 constitu\u00eddo por manifesta\u00e7\u00f5es de duas entidades \n\nfundamentais: massa e energia (Halliday et al., 2004). Massa \u00e9 a medida da in\u00e9rcia de \n\num corpo, enquanto que energia \u00e9 a capacidade de um sistema de realizar trabalho.  \n\nTodas as atividades humanas dependem de energia. Nos prim\u00f3rdios da humanida-\n\nde, o ser humano utilizava somente a energia oriunda de seu pr\u00f3prio corpo para ativida-\n\ndes como a ca\u00e7a e a manufatura. Com a evolu\u00e7\u00e3o do conhecimento, surgiram avan\u00e7os \n\ntecnol\u00f3gicos que exigiram novas fontes de energia. Assim, ainda na Antiguidade, surgi-\n\nram os sistemas mec\u00e2nicos que dependiam exclusivamente da for\u00e7a motriz de animais \n\nou da energia hidr\u00e1ulica, tais como as rodas d\u2019\u00e1gua e os engenhos.   \n\nOs sistemas mec\u00e2nicos que acompanharam a revolu\u00e7\u00e3o industrial do s\u00e9culo XVIII \n\nficaram maiores e mais complexos. Durante o s\u00e9culo XIX, a tecnologia evoluiu e foram \n\nconcebidos os sistemas a vapor, que propiciaram uma revolu\u00e7\u00e3o nos transportes com o \n\nadvento dos motores a vapor, empregados em locomotivas e navios. Muitas das ind\u00fas-\n\ntrias de ent\u00e3o foram se remodelando, ficando mais semelhantes \u00e0s plantas industriais \n\nmodernas, aumentando a produ\u00e7\u00e3o de bens e consumindo mais energia. A partir de en-\n\nt\u00e3o, a quest\u00e3o energ\u00e9tica ficou atrelada \u00e0 economia de um pa\u00eds, tornando-se t\u00e3o relevan-\n\nte quanto o poderio b\u00e9lico e, mais do que isso, tornou-se uma m\u00e9trica importante do \n\ngrau de desenvolvimento de uma na\u00e7\u00e3o. O extrativismo passou a contemplar as novas \n\nnecessidades energ\u00e9ticas, que demandavam quantidades cada vez maiores de carv\u00e3o e, \n\nmais recentemente, de petr\u00f3leo. No s\u00e9culo XX, o termo matriz energ\u00e9tica passou a ser \n\num item importante nos programas de governo das na\u00e7\u00f5es civilizadas.  \n\n\n\n 16 \n\nEm meados do s\u00e9culo XIX e durante o s\u00e9culo XX, as inova\u00e7\u00f5es se sucederam \n\ncom grande velocidade. Surgiram os motores de combust\u00e3o interna que em muitos ca-\n\nsos substitu\u00edram as m\u00e1quinas a vapor (ditas de combust\u00e3o externa), especialmente nos \n\nmeios de transporte. Mas os motores de combust\u00e3o, qualquer que fosse o tipo, apresen-\n\ntavam o mesmo inconveniente dos antigos sistemas hidr\u00e1ulicos: a energia tinha que ser \n\ngerada no local onde se precisava dela. Para contornar esta quest\u00e3o de mobilidade, os \n\ncientistas contempor\u00e2neos, em especial Thomas Alva Edison e Nikola Tesla, determina-\n\nram uma forma de transportar energia eficientemente: a eletricidade (Meyer, 1971).  \n\nA eletricidade \u00e9, antes de tudo, uma forma conveniente de transporte de energia. \n\nDe fato, as aplica\u00e7\u00f5es exclusivas para a eletricidade n\u00e3o s\u00e3o t\u00e3o corriqueiras quanto o \n\nsenso comum indica; em geral, os dispositivos el\u00e9tricos ou eletr\u00f4nicos convertem a ele-\n\ntricidade em outras formas de energia, como luminosa, t\u00e9rmica ou mec\u00e2nica. Natural-\n\nmente, outras formas de transmiss\u00e3o de energia s\u00e3o poss\u00edveis \u2013 o comit\u00ea que adminis-\n\ntrou a constru\u00e7\u00e3o da primeira grande hidroel\u00e9trica do mundo nas Cataratas do Ni\u00e1gara \n\nem 1896, considerou brevemente a utiliza\u00e7\u00e3o de um sistema pneum\u00e1tico antes de se \n\ndecidir por um sistema el\u00e9trico (Meyer, 1971). A id\u00e9ia era transportar a energia cin\u00e9tica \n\ndas cataratas at\u00e9 a cidade de Buffalo por meio de ar comprimido. Entretanto, nenhuma \n\noutra forma de energia apresenta rendimento t\u00e3o alto e \u00e9 t\u00e3o gerenci\u00e1vel quanto a eletri-\n\ncidade. Provavelmente, se tivesse sido levado a cabo, o grande sistema pneum\u00e1tico do \n\nNi\u00e1gara teria redundado em fracasso. \n\nA gera\u00e7\u00e3o de eletricidade e os sistemas de distribui\u00e7\u00e3o s\u00f3 foram poss\u00edveis a partir \n\nda descoberta do princ\u00edpio da indu\u00e7\u00e3o eletromagn\u00e9tica por Michael Faraday, em 1831 \n\n(Halliday et al., 2004). Tal princ\u00edpio permite o interc\u00e2mbio eficiente entre energia el\u00e9-\n\ntrica e energia mec\u00e2nica, sendo aplicado por todas as m\u00e1quinas el\u00e9tricas e pelos trans-\n\nformadores de for\u00e7a de qualquer natureza. Todavia, at\u00e9 a idealiza\u00e7\u00e3o dos sistemas de \n\ntransmiss\u00e3o e distribui\u00e7\u00e3o de energia, a descoberta de Faraday n\u00e3o seria de grande apli-\n\ncabilidade pr\u00e1tica. \n\nOs sistemas de transmiss\u00e3o e distribui\u00e7\u00e3o de energia foram patenteados por Edi-\n\nson em 1880, um ano depois que ele inventara a l\u00e2mpada el\u00e9trica (Meyer, 1971). Em \n\n1882, o primeiro sistema comercial de distribui\u00e7\u00e3o el\u00e9trica foi inaugurado em Manhat-\n\ntam pelo pr\u00f3prio Edison, dando in\u00edcio a um segmento econ\u00f4mico especialmente promis-\n\n\n\n 17 \n\nsor. A Edison General Electric, fundada por Edison em 1888, ainda existe e tornou-se \n\numa das maiores pot\u00eancias da era Industrial. \n\nEdison constru\u00edra um sistema de distribui\u00e7\u00e3o de tens\u00e3o cont\u00ednua (CC, corrente \n\ncont\u00ednua) trifilar concebido para as l\u00e2mpadas el\u00e9tricas de sua fabrica\u00e7\u00e3o (Meyer, 1971). \n\nComo se tratava de uma implementa\u00e7\u00e3o comercial, ele dedicou-se a apregoar as vanta-\n\ngens de seu sistema mesmo quando do surgimento de um sistema superior, idealizado \n\npor Nikola Tesla em 1887. Isso conduziu a uma grande dissens\u00e3o entre dois dos maiores \n\nnomes da ci\u00eancia contempor\u00e2nea, tendo sido registrado na Hist\u00f3ria como a Guerra das \n\nCorrentes. \n\nTesla, que havia sido colaborador de Edison por alguns anos, prop\u00f4s que a energia \n\nel\u00e9trica fosse transmitida e distribu\u00edda na forma alternada (CA, corrente alternada) (Me-\n\nyer, 1971). A tens\u00e3o alternada pode ser transmitida por grandes dist\u00e2ncias, o que, em \n\nprinc\u00edpio, n\u00e3o \u00e9 vi\u00e1vel com a tens\u00e3o cont\u00ednua. De fato, os primeiros geradores de Edison \n\nn\u00e3o podiam estar a mais de uma milha (aproximadamente 1,6 km) dos consumidores.   \n\nO sistema proposto por Tesla \u00e9 essencialmente o mesmo utilizado hoje em dia no \n\nmundo todo. Uma de suas maiores contribui\u00e7\u00f5es \u00e9 permitir que os geradores estejam \n\ndistantes dos centros consumidores, o que \u00e9 comum no caso das usinas hidroel\u00e9tricas.  \n\nA primeira grande hidroel\u00e9trica do mundo, inaugurada em 1896 nas quedas do \n\nNi\u00e1gara (New York, Estados Unidos), foi projetada pelo pr\u00f3prio Tesla (Meyer, 1971). A \n\nusina do Ni\u00e1gara entregava energia el\u00e9trica a 26 milhas (42 km) de dist\u00e2ncia, na cidade \n\nde Buffalo (Estados Unidos), um percurso muito maior do que os alcan\u00e7ados pelos sis-\n\ntemas de Edison. Dist\u00e2ncias como essa somente s\u00e3o poss\u00edveis porque as perdas de ener-\n\ngia no sistema CA s\u00e3o menores do que as observadas em sistemas CC. \n\nAs perdas de energia observadas nos sistemas CA s\u00e3o menores porque, depois de \n\ngerada, a tens\u00e3o pode ser elevada a n\u00edveis alt\u00edssimos, tipicamente centenas de milhares \n\nde volts (por exemplo, 138 Kv ou 500 Kv) (Pansini, 2005). Conforme mostra a Equa\u00e7\u00e3o \n\n1, a pot\u00eancia el\u00e9trica P \u00e9 uma grandeza constante cujo m\u00f3dulo \u00e9 dado pelo produto da \n\ntens\u00e3o (V) pela corrente (I). Isso significa que, para um mesmo valor de pot\u00eancia, se \n\nelevada a tens\u00e3o, a corrente ser\u00e1 rebaixada em raz\u00e3o proporcional.  \n\n\n\n 18 \n\nIVP \u00d7=  \nEqua\u00e7\u00e3o 1 \u2013 Pot\u00eancia El\u00e9trica \n\nCom a corrente el\u00e9trica sendo mantida em n\u00edveis mais baixos devido ao esquema \n\nde eleva\u00e7\u00e3o de tens\u00e3o, as chamadas perdas \u00f4hmicas s\u00e3o reduzidas. Essas perdas causam \n\nquedas de tens\u00e3o na transmiss\u00e3o de energia e superaquecimento dos condutores (efeito \n\nJoule) (Halliday et al., 2004). \n\nUma vez que a resist\u00eancia do sistema de transmiss\u00e3o \u00e9 calculada em fun\u00e7\u00e3o da \n\ndist\u00e2ncia, da se\u00e7\u00e3o transversal e do material utilizado nos condutores, ela pode ser con-\n\nsiderada constante. A resist\u00eancia deveria ser t\u00e3o baixa quanto poss\u00edvel; teoricamente, \n\num conjunto de condutores ideal (ou seja, com resist\u00eancia nula), permitiria a transmis-\n\ns\u00e3o de uma infinita quantidade de energia. Entretanto, al\u00e9m disso n\u00e3o ser observado em \n\nsitua\u00e7\u00f5es pr\u00e1ticas, existe uma limita\u00e7\u00e3o f\u00edsica na quantidade de energia que pode ser \n\ngerada eficientemente por um gerador el\u00e9trico, conforme enunciado pelo Teorema da \n\nM\u00e1xima Transfer\u00eancia de Pot\u00eancia. \n\nA equa\u00e7\u00e3o 2 mostra a chamada lei de Ohm, que mostra a rela\u00e7\u00e3o entre a queda de \n\ntens\u00e3o (?V) numa linha de transmiss\u00e3o, a corrente e resist\u00eancia el\u00e9tricas. \n\n \nIRV \u00d7=?  \n\nEqua\u00e7\u00e3o 2 \u2013 Lei de Ohm \n\nOra, se a resist\u00eancia el\u00e9trica R \u00e9 considerada constante, quanto maior a corrente I \n\nque circula pelo sistema de transmiss\u00e3o, maior a queda de tens\u00e3o observada. Logo, para \n\nminimizar esta perda sem reduzir a quantidade de pot\u00eancia el\u00e9trica transmitida, \u00e9 neces-\n\ns\u00e1rio diminuir a intensidade da corrente e, como visto, isto exige o emprego de n\u00edveis de \n\ntens\u00e3o maiores. Devido ao princ\u00edpio da indu\u00e7\u00e3o eletromagn\u00e9tica, isso s\u00f3 \u00e9 poss\u00edvel em \n\nsistemas AC como os sugeridos por Tesla. Na atualidade, sistemas CC de grande exten-\n\ns\u00e3o tornaram-se poss\u00edveis, mas somente durante a transmiss\u00e3o: a energia \u00e9 gerada em \n\nCA, convertida para CC utilizando dispositivos de estado s\u00f3lido inexistentes na \u00e9poca \n\nde Edison, transmitida em CC, e reconvertida para CA antes da utiliza\u00e7\u00e3o. Esses siste-\n\nmas, conhecidos como sistemas HVDC (High voltage direct current, corrente cont\u00ednua \n\nde alta tens\u00e3o), s\u00e3o utilizados em aplica\u00e7\u00f5es muito espec\u00edficas, como cabos de transmis-\n\ns\u00e3o submarinos. \n\n\n\n 19 \n\n2.2 Elementos do Sistema El\u00e9trico \n\nO princ\u00edpio de conserva\u00e7\u00e3o de energia, enunciado por Lavoisier, atesta a impossi-\n\nbilidade de a energia ser criada. Ela ocorre naturalmente no Universo, podendo ser cap-\n\nturada ou convertida, mas jamais gerada no sentido estrito do termo (Halliday et al., \n\n2004).  \n\nAssim, fontes de energia natural devem ser aproveitadas para produzir eletricidade \n\n(Pansini, 2005). Em pa\u00edses com muitos recursos h\u00eddricos tais como o Brasil, usinas hi-\n\ndroel\u00e9tricas utilizam a energia potencial da \u00e1gua armazenada em represas ou a energia \n\ncin\u00e9tica dos cursos de \u00e1gua para esse fim. Outros tipos de usinas, as termoel\u00e9tricas, em-\n\npregam a energia qu\u00edmica armazenada em cadeias carb\u00f4nicas, muito comuns em com-\n\npostos de origem org\u00e2nica como o carv\u00e3o ou o diesel, liberada atrav\u00e9s da oxida\u00e7\u00e3o. As \n\nusinas termonucleares utilizam a energia t\u00e9rmica obtida com a fus\u00e3o ou, mais recente-\n\nmente, com a fiss\u00e3o at\u00f4mica. Tamb\u00e9m existem formas alternativas de gerar eletricidade, \n\ncomo os geradores e\u00f3licos ou solares geralmente utilizados em sistemas de gera\u00e7\u00e3o dis-\n\ntribu\u00edda.  \n\nQualquer que seja a forma empregada para tanto, a primeira etapa de um sistema \n\nel\u00e9trico \u00e9 a produ\u00e7\u00e3o de energia el\u00e9trica. O termo \u201cgera\u00e7\u00e3o\u201d \u00e9 empregado para designar \n\nessa etapa ainda que, como ressaltado, se trate de um erro conceitual. Nesse est\u00e1gio, as \n\ntens\u00f5es s\u00e3o da ordem de 103 volts; 20 Kv \u00e9 um valor t\u00edpico (Pansini, 2005). \n\nFreq\u00fcentemente, os centros consumidores de energia se localizam bem afastados \n\ndas fontes de produ\u00e7\u00e3o de energia el\u00e9trica; dist\u00e2ncias de centenas ou mesmo milhares de \n\nquil\u00f4metros s\u00e3o comuns. Para minimizar as perdas \u00f4hmicas, a tens\u00e3o deve ser elevada \n\npor subesta\u00e7\u00f5es elevadoras a centenas de milhares de volts. Essa etapa \u00e9 denominada \n\ntransmiss\u00e3o de energia e emprega valores de tens\u00e3o como 130 Kv, 230 Kv, 500 Kv ou \n\n750 Kv para percorrer as linhas de for\u00e7a que conectam as usinas geradoras aos centros \n\nconsumidores (Pansini, 2005). \n\nNos centros consumidores, as linhas de transmiss\u00e3o s\u00e3o conectadas a subesta\u00e7\u00f5es \n\nrebaixadoras (muitas vezes chamadas simplesmente de subesta\u00e7\u00f5es), respons\u00e1veis por \n\ndiminuir o n\u00edvel da tens\u00e3o a patamares tecnicamente mais adequados para o consumo. \n\n\n\n 20 \n\nEmbora as dist\u00e2ncias envolvidas nos centros consumidores sejam menores, a quest\u00e3o da \n\nperda \u00f4hmica ainda \u00e9 um problema. Por essa raz\u00e3o, as subesta\u00e7\u00f5es entregam energia em \n\nn\u00edveis de tens\u00e3o muito mais altos do que os usu\u00e1rios do sistema em geral est\u00e3o prepara-\n\ndos para consumir. Ent\u00e3o, as concession\u00e1rias de energia empregam um esquema de dis-\n\ntribui\u00e7\u00e3o que se baseia em dois n\u00edveis de tens\u00e3o, denominadas tens\u00e3o prim\u00e1ria (ou MT, \n\nm\u00e9dia tens\u00e3o) e tens\u00e3o secund\u00e1ria (ou BT, baixa tens\u00e3o) (Pansini, 2005).  \n\nOs alimentadores s\u00e3o os circuitos que distribuem a tens\u00e3o prim\u00e1ria, utilizando \n\ntens\u00f5es de 5Kv a 23 Kv, sendo 13.8 Kv o valor mais comum no Brasil. Nos pontos geo-\n\ngr\u00e1ficos onde os ramais de consumo se concentram (chamados de centro de carga), os \n\nalimentadores energizam os transformadores de distribui\u00e7\u00e3o (TDs) os quais alimentam \n\nos ramais dos consumidores finais por meio dos circuitos secund\u00e1rios. Esse esquema \n\ndestina-se em grande medida aos consumidores residenciais e \u00e0queles cujos consumos \n\nestejam abaixo de certos valores padronizados. Grandes consumidores comerciais e \n\nindustriais s\u00e3o energizados diretamente em tens\u00e3o prim\u00e1ria, responsabilizando-se eles \n\npr\u00f3prios pelo rebaixamento da tens\u00e3o.  \n\nA Figura 6 mostra um diagrama de blocos com todas as etapas de um sistema el\u00e9-\n\ntrico moderno. As atividades mais relevantes sob uma perspectiva funcional s\u00e3o mos-\n\ntradas em vermelho, enquanto que as atividades de suporte s\u00e3o mostradas em azul.  \n\n \n\n \nFigura 6 \u2013 Elementos de um Sistema El\u00e9trico Moderno \n\nO presente trabalho \u00e9 voltado \u00e0 distribui\u00e7\u00e3o, cujas etapas est\u00e3o evidenciadas por \n\numa linha intermitente na Figura 6. No entanto, como os elementos do sistema el\u00e9trico \n\n\n\n 21 \n\ns\u00e3o fortemente acoplados entre si, pode-se aplicar os mesmos conceitos tamb\u00e9m \u00e0 gera-\n\n\u00e7\u00e3o ou \u00e0 transmiss\u00e3o. Isso \u00e9 poss\u00edvel porque o fluxo de pot\u00eancia, da gera\u00e7\u00e3o ao consu-\n\nmo, \u00e9 o mesmo; portanto, a predi\u00e7\u00e3o de energia numa etapa \u00e9 semelhante \u00e0 predi\u00e7\u00e3o em \n\noutra etapa.  \n\nEm princ\u00edpio, a diferen\u00e7a entre a transmiss\u00e3o e a distribui\u00e7\u00e3o, por exemplo, \u00e9 um \n\nfator de escala: enquanto as linhas de transmiss\u00e3o abastecem alguns poucos centros con-\n\nsumidores, as subesta\u00e7\u00f5es aplicam uma fra\u00e7\u00e3o desta energia a centenas de TDs. Eviden-\n\ntemente, \u00e9 razo\u00e1vel assumir que o perfil de consumo de um TD, por ser mais pulveriza-\n\ndo, possa ser mais bem compreendido do que o perfil de uma grande geradora como \n\nItaipu (a maior usina hidroel\u00e9trica do mundo), que abastece milh\u00f5es de consumidores \n\nem regi\u00f5es muito distintas entre si. Entretanto, tanto num caso como no outro, os mode-\n\nlos de predi\u00e7\u00e3o s\u00e3o n\u00e3o-lineares e din\u00e2micos, o que requer a ado\u00e7\u00e3o de estruturas predi-\n\ntivas igualmente complexas, pelo menos no que tange \u00e0 previs\u00e3o de curto prazo. \n\n \n\n \n\n\n\n3 ESTIMA\u00c7\u00c3O E PREDI\u00c7\u00c3O \n\n3.1 Introdu\u00e7\u00e3o \n\nO conceito de sistema \u00e9 empregado em muitas \u00e1reas da ci\u00eancia e tecnologia, pos-\n\nsuindo uma conota\u00e7\u00e3o comum em todas elas: um sistema \u00e9 uma entidade cujo compor-\n\ntamento varia em fun\u00e7\u00e3o dos est\u00edmulos recebidos (Oppenheim et al., 1999). Praticamen-\n\nte tudo que nos cerca pode ser considerado como um sistema, por exemplo: \n\na) Sistemas de distribui\u00e7\u00e3o de energia, cujo comportamento (carga el\u00e9trica) \n\nvaria em fun\u00e7\u00e3o dos est\u00edmulos (condi\u00e7\u00f5es atmosf\u00e9ricas, hor\u00e1rio, dia da \n\nsemana, etc). \n\nb) Um autom\u00f3vel, cujo comportamento (acelera\u00e7\u00e3o e velocidade) depende \n\ndos est\u00edmulos (press\u00e3o do acelerador). \n\nc) As commodities do mercado financeiro, cujo comportamento (cota\u00e7\u00e3o) \n\ndepende dos est\u00edmulos (pol\u00edticas fiscais do pa\u00eds, fatores de risco, taxa de \n\ninfla\u00e7\u00e3o, etc). \n\nMuitos sistemas, como os citados, podem ser modelados atrav\u00e9s das rela\u00e7\u00f5es cau-\n\nsais, tamb\u00e9m chamadas de depend\u00eancias funcionais. Nestes modelos, os valores de al-\n\ngumas vari\u00e1veis (est\u00edmulos) determinam o valor de outras (comportamento). O estudo e \n\na compreens\u00e3o dessas depend\u00eancias podem auxiliar diversas atividades humanas, como \n\no planejamento e o processo decis\u00f3rio nas organiza\u00e7\u00f5es (Makridakis et al., 1997).  \n\nCausalidade \u00e9 um conceito associado \u00e0 \u00e2nsia humana por padr\u00f5es. As pessoas de-\n\npendem de padr\u00f5es a um grau tal que os consideram pervasivos, o que explica certas \n\ncompuls\u00f5es como as teorias da conspira\u00e7\u00e3o ou os jogos de azar (Berry et al., 2004). \n\nExcetuando-se por essas aplica\u00e7\u00f5es esp\u00farias, denominadas de data dredging (Hand et \n\nal., 2001), a causalidade \u00e9 evidenciada pela correla\u00e7\u00e3o entre eventos (Montgomery et \n\n\n\n 23 \n\nal., 2001). Em algumas situa\u00e7\u00f5es, entretanto, os dados precisam ser transformados para \n\nque essa correla\u00e7\u00e3o seja visualizada apropriadamente, atrav\u00e9s de t\u00e9cnicas como a linea-\n\nriza\u00e7\u00e3o ou o logaritmo (Montgomery et al., 2001; Pindyck et al., 2004).  \n\n\u00c9 importante destacar que \u00e9 poss\u00edvel haver fortes correla\u00e7\u00f5es entre alguns eventos \n\nsem uma rela\u00e7\u00e3o causal subjacente (embora o inverso seja sempre verdadeiro) (Berry et \n\nal., 2004). Considere-se, por exemplo, o seguinte racioc\u00ednio: na cidade de Florian\u00f3polis, \n\nno ver\u00e3o, a venda de refrigerantes aumenta. Na mesma \u00e9poca, tamb\u00e9m s\u00e3o observados \n\nmais congestionamentos no tr\u00e2nsito e isso estabelece uma correla\u00e7\u00e3o entre os dois even-\n\ntos. Entretanto, \u00e9 arriscado creditar os engarrafamentos ao consumo de refrigerantes ou \n\no contr\u00e1rio; portanto, n\u00e3o h\u00e1 rela\u00e7\u00e3o causal plaus\u00edvel entre ambos. \u00c9 mais prov\u00e1vel que \n\na chegada do ver\u00e3o cause um aumento tanto na venda de refrigerantes como no fluxo de \n\nmotoristas que procuram as praias de Florian\u00f3polis, sem que os eventos estejam direta-\n\nmente relacionados entre si. \n\n3.2 Estima\u00e7\u00e3o \n\nEstima\u00e7\u00e3o possui conota\u00e7\u00f5es distintas na estat\u00edstica param\u00e9trica e na minera\u00e7\u00e3o \n\nde dados. Em estat\u00edstica, o termo estima\u00e7\u00e3o \u00e9 frequentemente utilizado para descrever \n\nos procedimentos matem\u00e1ticos que aproximam (ou seja, estimam) os valores dos par\u00e2-\n\nmetros fixos de um modelo estat\u00edstico (por exemplo, os coeficientes angulares de um \n\nmodelo de regress\u00e3o linear) (Montgomery et al., 2001; Pindyck et al., 2004). Em con-\n\ntrapartida, em minera\u00e7\u00e3o de dados o termo est\u00e1 associado aos modelos de regress\u00e3o \n\npropriamente ditos (Berry et al., 2004), enquanto que o procedimento para aproximar os \n\npar\u00e2metros de tais modelos \u00e9 chamado de aprendizado (Haykin, 1998; Vapnik, 1998; \n\nVapnik, 1999; Duda et al., 2000). Neste trabalho, foi adotada a conota\u00e7\u00e3o empregada na \n\nliteratura de minera\u00e7\u00e3o de dados. Assim, nesta disserta\u00e7\u00e3o, estima\u00e7\u00e3o \u00e9 a resposta obti-\n\nda por um modelo de regress\u00e3o a partir dos valores das vari\u00e1veis de entrada, enquanto \n\nque estimador \u00e9 o pr\u00f3prio modelo de regress\u00e3o (independentemente de como ele \u00e9 cons-\n\ntru\u00eddo). \n\n\n\n 24 \n\nOs estimadores descrevem as depend\u00eancias funcionais de um sistema trav\u00e9s de \n\nmodelos matem\u00e1ticos convenientes. Estes modelos mostram como os est\u00edmulos X (tam-\n\nb\u00e9m chamados de entradas, vari\u00e1veis regressoras/explanat\u00f3rias, fatores de influ\u00eancia \n\nou preditoras) influenciam o comportamento Y do sistema (respostas) (Montgomery et \n\nal., 2001; Hastie et al., 2003; Niu et al., 2005; Guo et al., 2006). Em outras palavras, \u00e9 \n\nposs\u00edvel simular o sistema e prever a sua resposta quando as regressoras assumem de-\n\nterminados valores. Este tipo de simula\u00e7\u00e3o \u00e9 muito conveniente para in\u00fameros ramos do \n\nconhecimento, tais como engenharia, medicina e economia.  \n\nO problema de estima\u00e7\u00e3o \u00e9 considerado um problema de infer\u00eancia estat\u00edstica, cu-\n\njo objetivo \u00e9 formalmente descrito como inferir as depend\u00eancias funcionais de um sis-\n\ntema atrav\u00e9s de uma amostra emp\u00edrica de dados. Os primeiros trabalhos de infer\u00eancia \n\ntinham como base os modelos probabil\u00edsticos (fun\u00e7\u00f5es de distribui\u00e7\u00f5es de probabilida-\n\nde) empregados na descri\u00e7\u00e3o de muitos sistemas reais (Vapnik, 1998).  \n\nOs principais modelos de infer\u00eancia estat\u00edstica foram unificados por Fisher \n\ndentro da estat\u00edstica param\u00e9trica. Com isso, a quest\u00e3o de estimar fun\u00e7\u00f5es a partir de \n\num conjunto de dados (an\u00e1lise de discriminantes, an\u00e1lise de regress\u00e3o e estima\u00e7\u00e3o de \n\ndensidade) seria descrita como um problema de estimar os par\u00e2metros de modelos pro-\n\nbabil\u00edsticos (param\u00e9tricos) espec\u00edficos (Vapnik, 1998). Fisher sugeriu ainda um m\u00e9todo \n\npara estimar os par\u00e2metros desconhecidos em todos esses modelos \u2013 o m\u00e9todo da m\u00e1-\n\nxima verossimilhan\u00e7a (maximum likelihood method) (Vapnik, 1998).  \n\nAs abordagens da Teoria de Aprendizado Estat\u00edstico (TAE), em contrapartida, \n\nempregam fun\u00e7\u00f5es determin\u00edsticas tais como fun\u00e7\u00f5es preditivas ou an\u00e1lise de agrupa-\n\nmentos (Herbrich, 2001). Por esta raz\u00e3o, muitos pesquisadores t\u00eam observado que as \n\nid\u00e9ias gerais da TAE se assemelham \u00e0 estima\u00e7\u00e3o n\u00e3o-param\u00e9trica que, ao contr\u00e1rio da \n\nestat\u00edstica param\u00e9trica, n\u00e3o considera um modelo probabil\u00edstico (distribui\u00e7\u00e3o de proba-\n\nbilidade) para o sistema sob estudo (Herbrich, 2001).  \n\nO aprendizado estat\u00edstico se limita a descrever dados novos que n\u00e3o foram utiliza-\n\ndos durante a constru\u00e7\u00e3o do modelo. A estat\u00edstica param\u00e9trica vai al\u00e9m disso, ao deter-\n\nminar qual distribui\u00e7\u00e3o de probabilidade descreve o sistema. Essa pode ser uma meta \n\nambiciosa, porque tanto a quantidade de dados como a de conhecimento a priori nem \n\n\n\n 25 \n\nsempre \u00e9 suficiente para tanto (Vapnik, 1998; Herbrich, 2001). Ademais, \u00e9 poss\u00edvel de-\n\nmonstrar que nem sempre problemas reais podem ser descritos por modelos probabil\u00eds-\n\nticos cl\u00e1ssicos (Vapnik, 1998). Isso favorece a aplica\u00e7\u00e3o da TAE em muitos problemas \n\nreais, porque n\u00e3o requer grandes amostras de dados e dispensa qualquer conhecimento a \n\npriori do sistema em quest\u00e3o (Haykin, 1998; Vapnik, 1998).  \n\nAo desprezar o modelo estat\u00edstico subjacente a um sistema, a TAE incorre numa \n\nlimita\u00e7\u00e3o sem\u00e2ntica: a descri\u00e7\u00e3o dos dados gerada pelo modelo n\u00e3o possui interpreta\u00e7\u00e3o \n\nt\u00e3o clara como a fornecida pelos modelos estat\u00edsticos. Um modelo de regress\u00e3o linear, \n\npor exemplo, \u00e9 definido em fun\u00e7\u00e3o de dois par\u00e2metros, mostrados na Equa\u00e7\u00e3o 3.  \n\nbxaxyy +?== )(  \n\nEqua\u00e7\u00e3o 3 \u2013 Um Modelo de Regress\u00e3o Simples \n\nO par\u00e2metro a (coeficiente angular) define como a resposta y do sistema varia em \n\nfun\u00e7\u00e3o do regressor x, enquanto que o par\u00e2metro b (coeficiente linear) mostra a resposta \n\ny do sistema quando x \u00e9 nulo (Montgomery et al., 2001). \n\nPor outro lado, o aprendizado estat\u00edstico considera conjuntos aninhados de fun-\n\n\u00e7\u00f5es implementadas por uma m\u00e1quina de aprendizado, respons\u00e1vel tamb\u00e9m por definir \n\numa medida da capacidade (grau de complexidade) para cada um destes conjuntos \n\n(Vapnik, 1998). N\u00e3o existe nenhum modelo anal\u00edtico em particular associado ao esti-\n\nmador gerado: as fun\u00e7\u00f5es v\u00e3o sendo testadas iterativamente at\u00e9 que uma delas consiga \n\ndescrever os dados com precis\u00e3o suficiente. Conseq\u00fcentemente, os par\u00e2metros do esti-\n\nmador gerado ser\u00e3o necessariamente obscuros; ou seja, n\u00e3o ter\u00e3o uma interpreta\u00e7\u00e3o \n\nclara. \n\nNeste trabalho, as poss\u00edveis interpreta\u00e7\u00f5es sem\u00e2nticas que possam ser extra\u00eddas \n\ndos modelos de estima\u00e7\u00e3o n\u00e3o auxiliam na solu\u00e7\u00e3o do problema proposto. Por si s\u00f3, tal \n\nfato n\u00e3o impede a aplica\u00e7\u00e3o dos m\u00e9todos param\u00e9tricos; por\u00e9m, n\u00e3o existe informa\u00e7\u00e3o a \n\npriori suficiente sobre os modelos probabil\u00edsticos que descrevem um sistema de distri-\n\nbui\u00e7\u00e3o de energia. Ao contr\u00e1rio, os trabalhos de pesquisa nesta \u00e1rea comprovam o car\u00e1-\n\nter din\u00e2mico da carga el\u00e9trica (Tao et al., 2004; Guo et al., 2004; Oliveira, 2004; Hong \n\net al., 2005). Isso viola a chamada premissa da continuidade (Makridakis et al., 1997) e \n\n\n\n 26 \n\ntorna os par\u00e2metros de um poss\u00edvel modelo probabil\u00edstico fun\u00e7\u00f5es do tempo, inviabili-\n\nzando a abordagem. Assim, a op\u00e7\u00e3o natural para implementar as solu\u00e7\u00f5es sugeridas \n\nneste trabalho passa a ser a abordagem n\u00e3o-param\u00e9trica. \n\nA defini\u00e7\u00e3o de sistema din\u00e2mico \u00e9 intuitiva \u2013 um sistema \u00e9 din\u00e2mico quando suas \n\npropriedades variam com o tempo, raz\u00e3o pela qual esse tipo de sistema tamb\u00e9m \u00e9 de-\n\nnominado de sistema variante no tempo. Matematicamente, isso corresponde \u00e0 fam\u00edlia \n\nde equa\u00e7\u00f5es que s\u00e3o fun\u00e7\u00f5es expl\u00edcitas do tempo (Oppenheim et al., 1999). A Figura 7 \n\nilustra graficamente este conceito. \n\nO sinal da Figura 7a \u00e9 um sinal sinusoidal na forma ( )tseny = , enquanto que o si-\nnal da Figura 7b \u00e9 uma sinus\u00f3ide degenerada na forma ( )tsenty ?=  (notar que, no \u00falti-\nmo caso, o termo t aparece fora do argumento da fun\u00e7\u00e3o, caracterizando uma depend\u00ean-\n\ncia expl\u00edcita do tempo). Se, por hip\u00f3tese, ambos os sinais forem modelados como pro-\n\ncessos gaussianos (abordagem param\u00e9trica), eles teriam que ser completamente caracte-\n\nrizados por dois par\u00e2metros: m\u00e9dia e vari\u00e2ncia (Montgomery et al., 2001; Johnson et al., \n\n2002; Pindyck et al., 2004). Isso parece ser adequado para o sinal da Figura 7a, que a-\n\npresenta ambos os par\u00e2metros constantes, mas n\u00e3o \u00e9 o caso do sinal da Figura 7b, como \n\ndiscutido a seguir. \n\n \n\nFigura 7 \u2013 Vari\u00e2ncia no Tempo: (a) Sistema Invariante e (b) Sistema Variante \n\nSejam os gr\u00e1ficos da Figura 8a e da Figura 8b, que mostram a m\u00e9dia no tempo pa-\n\nra, respectivamente, os sinais mostrados na Figura 7a e Figura 7b. Essas m\u00e9dias s\u00e3o \n\ncalculadas de forma incremental; ou seja, consideram conjunto de valores progressiva-\n\nmente maiores. Isso significa que, para uma janela arbitr\u00e1ria de n amostras, cada curva \n\n\n\n 27 \n\nda Figura 8 \u00e9 calculada da seguinte maneira: o primeiro ponto \u00e9 a m\u00e9dia de n amostras, \n\no segundo de n\u00d72  amostras, e assim por diante. Com isso, \u00e9 poss\u00edvel visualizar como a \n\nm\u00e9dia se comporta ao longo do tempo e realizar algumas infer\u00eancias \u00fateis.  \n\n \n\nFigura 8 \u2013 M\u00e9dias de Dois Sistemas: (a) Sistema Estacion\u00e1rio e (b) Sistema N\u00e3o-Estacion\u00e1rio \n\nComo se pode notar, a m\u00e9dia do sistema invariante (Figura 8a) tende a um valor \n\ndefinido, enquanto que a do sistema variante (Figura 8b) fica oscilando, sem uma ten-\n\nd\u00eancia de converg\u00eancia. A vari\u00e2ncia apresenta um comportamento geometricamente \n\nid\u00eantico para os dois sinais. Naturalmente, o exemplo citado \u00e9 simplista e, possivelmen-\n\nte, poderia ser contornado para permitir o uso da estima\u00e7\u00e3o param\u00e9trica. Entretanto, a \n\ncarga el\u00e9trica e as vari\u00e1veis preditoras (tais como grandezas atmosf\u00e9ricas) s\u00e3o intrinse-\n\ncamente mais complexas, conforme discutido no Cap\u00edtulo 6. Claramente, neste trabalho, \n\n\u00e9 mais interessante criar uma fun\u00e7\u00e3o que reproduza a rela\u00e7\u00e3o causal entre preditoras e a \n\ncarga el\u00e9trica sem tentar determinar o modelo estat\u00edstico subjacente do que criar este \n\nmodelo e determinar os par\u00e2metros que os caracterizam. \n\nExistem ainda outros fatores que influenciaram a escolha das abordagens n\u00e3o-\n\nparam\u00e9tricas neste trabalho em detrimento das param\u00e9tricas. Vladimir Vapnik (Vapnik, \n\n1998) menciona que a abordagem n\u00e3o-param\u00e9trica, desde o seu advento com as redes \n\nneuronais na d\u00e9cada de 60, capturava algo nos problemas reais de alta dimensionalidade \n\nque as t\u00e9cnicas descritivas cl\u00e1ssicas n\u00e3o conseguiam, sen\u00e3o em situa\u00e7\u00f5es de baixa di-\n\nmensionalidade. Este fen\u00f4meno tornou-se conhecido a maldi\u00e7\u00e3o da dimensionalidade \n\n(Vapnik, 1998; Vapnik, 1999; Herbrich, 2001; Hastie et al., 2003). Por essa raz\u00e3o, a \n\nliteratura enquadra os m\u00e9todos n\u00e3o-param\u00e9tricos como uma generaliza\u00e7\u00e3o dos m\u00e9todos \n\nparam\u00e9tricos (Vapnik, 1998). Isso \u00e9 intuitivo se for considerado que, apesar dos mode-\n\n\n\n 28 \n\nlos param\u00e9tricos apresentarem um desempenho restrito em dom\u00ednios de alta dimensio-\n\nnalidade, os n\u00e3o-param\u00e9tricos tratam tanto os dom\u00ednios de alta como os de baixa dimen-\n\nsionalidade com acentuada desenvoltura.  \n\nUm estimador \u00e9 concebido como o modelo matem\u00e1tico de um sistema; ou seja, \n\nele \u00e9 uma abstra\u00e7\u00e3o matem\u00e1tica, capaz de descrever a resposta deste sistema a um de-\n\nterminado conjunto de est\u00edmulos (valores de entrada). Esse modelo assume a forma de \n\numa fun\u00e7\u00e3o ou, mais genericamente, de um operador n\u00e3o-linear, ressaltando-se que a \n\nlinearidade \u00e9 uma forma espec\u00edfica de n\u00e3o-linearidade (Steinbruch, 1987 et al.). A \n\nEqua\u00e7\u00e3o 4 \u00e9 uma generaliza\u00e7\u00e3o da Equa\u00e7\u00e3o 3, que mostra um operador n\u00e3o-linear f ma-\n\npeando o dom\u00ednio X (regressoras) na imagem Y (resposta) de um dado sistema. Em situ-\n\na\u00e7\u00f5es pr\u00e1ticas, admitem-se muitas formas diferentes para f, sendo que todas elas admi-\n\ntem um erro residual; ou seja, a modelagem nunca \u00e9 perfeita (Haykin, 1998; Montgo-\n\nmery et al., 2001).  \n\nEqua\u00e7\u00e3o 4 \u2013 O Operador f como um Modelo de Estima\u00e7\u00e3o \n\nEm sentido matem\u00e1tico mais amplo, tanto X como Y s\u00e3o espa\u00e7os vetoriais; portan-\n\nto, todo Xx ?  e Yy ?  s\u00e3o vetores (Steinbruch, 1987 et al.). Tipicamente, define-se \n\npX ??  (onde ??> 0p ) e ??Y  (Herbrich, 2001; Hastie et al., 2003).  \n\nA Teoria de Aprendizado Estat\u00edstico denomina o processo de cria\u00e7\u00e3o dos modelos \n\nde regress\u00e3o como aprendizado supervisionado (Vapnik, 1999; Hastie et al., 2003). O \n\ntermo supervisionado \u00e9 empregado porque o operador f \u00e9 determinado a partir de um \n\nmodelo de aprendizado iterativo. Em cada itera\u00e7\u00e3o, a sa\u00edda y?  estimada por f \u00e9 compa-\n\nrada com y, a sa\u00edda original do sistema. Esse modelo de aprendizado \u00e9 composto de tr\u00eas \n\ncomponentes, conforme mostra a Figura 9 (Vapnik, 1998; Vapnik, 1999): \n\na) Um gerador G, que produz vetores aleat\u00f3rios pXx ??? , os quais se distribu-\n\nem de acordo com uma fun\u00e7\u00e3o de distribui\u00e7\u00e3o de probabilidade F(x) desconhe-\n\ncida. \n\nYXf ?:\n\n\n\n 29 \n\nb) Um sistema S, que retorna uma sa\u00edda ??? Yy  para cada x apresentado em \n\nsua entrada de acordo com uma fun\u00e7\u00e3o de distribui\u00e7\u00e3o condicional F(y|x) des-\n\nconhecida. \n\nc) Uma m\u00e1quina de aprendizado LM (Learning Machine), capaz de implementar \n\num conjunto de fun\u00e7\u00f5es na forma ),(\u02c6 ?xfy = , onde y?  \u00e9 uma estimativa de y  \n\nproduzida por f  e ?  \u00e9 um conjunto de par\u00e2metros ajust\u00e1veis, \u00fanico para cada \n\nfun\u00e7\u00e3o.  \n\nG\n\nS\n\nLM\n\nx\n\ny\n\ny?\n\nEntrada Sa\u00edda\n\nSa\u00edda estimada\n\n \n\nFigura 9 \u2013 Modelo de Aprendizado Supervisionado \n\n \n\nO conjunto ?  \u00e9 que ret\u00e9m o conhecimento de cada modelo gerado; ou seja, \u00e9 a \n\npartir dele que as depend\u00eancias funcionais s\u00e3o explicadas (Pindyck et al., 2004). No \n\ncaso do modelo linear simples, mostrado na Equa\u00e7\u00e3o 3, ?  \u00e9 constitu\u00eddo pelos par\u00e2me-\n\ntros a e b; em se tratando de um modelo conexionista, \u00e9 o conjunto de pesos sin\u00e1pticos \n\n(Haykin, 1998; Duda et al., 2000). Depois do processo de aprendizado, o conjunto de \n\npar\u00e2metros do estimador \u00e9 mantido constante, raz\u00e3o pela qual \u00e9 comum substituir-se a \n\nnota\u00e7\u00e3o ),( ?xf  (dita nota\u00e7\u00e3o param\u00e9trica3) por f(x) simplesmente. \n\nO aprendizado pode ser descrito como o ato de determinar qual fun\u00e7\u00e3o ),( ?xf  \n\nproduz a melhor estimativa para a resposta y  do sistema (Vapnik, 1999). Em princ\u00edpio, \n\nquanto menor a diferen\u00e7a entre a sa\u00edda estimada y?  e a resposta y, melhor \u00e9 o modelo. \n\n                                                           \n3 O termo nota\u00e7\u00e3o param\u00e9trica \u00e9 refer\u00eancia aos par\u00e2metros ajust\u00e1veis de uma fam\u00edlia de estimadores, n\u00e3o \nse relacionando a estima\u00e7\u00e3o param\u00e9trica da estat\u00edstica descritiva. De fato, tanto os m\u00e9todos param\u00e9tricos \ncomo os n\u00e3o-param\u00e9tricos empregam estimadores com par\u00e2metros ajust\u00e1veis. \n\n\n\n 30 \n\nA Figura 9 mostra ainda um gerador G que produz as entradas x . Esse gerador \u00e9 \n\numa abstra\u00e7\u00e3o do processo de amostragem (ou coleta), que seleciona os dados que com-\n\np\u00f5em o conjunto de treinamento. A Equa\u00e7\u00e3o 5 mostra este conjunto como sendo com-\n\nposto por L pares ordenados (x, y), de forma que cada par associa uma entrada x  \u00e0 sa\u00edda \n\ncorrespondente y. Ap\u00f3s o aprendizado, espera-se que o modelo produza respostas acu-\n\nradas para qualquer elemento de X, incluindo as que foram omitidas no conjunto de \n\ntreinamento. Estatisticamente, isso \u00e9 poss\u00edvel porque a amostragem representa a popula-\n\n\u00e7\u00e3o subjacente que representa a verdadeira rela\u00e7\u00e3o sob estudo (Pindyck et al., 2004). \n\n{ }L\nlll YXyxS 1),( =\u00d7?=  \n\nEqua\u00e7\u00e3o 5 \u2013 Conjunto de Treinamento \n\nUma parte dos problemas de modelagem acontece quando o conjunto de treina-\n\nmento \u00e9 inadequado, fazendo com que o modelo seja tendencioso (Montgomery et al., \n\n2001; Pindyck et al., 2004). Para evitar isso, o conjunto deve ser balanceado (Berry et \n\nal., 2004). O balanceamento pode ser entendido informalmente como um m\u00e9todo ho-\n\nmog\u00eaneo de amostragem, de tal sorte que o conjunto de treinamento, embora limitado, \n\nseja representativo. Isso pode ser assegurado se os dados do conjunto forem obtidos de \n\nforma id\u00eantica e independentemente distribu\u00edda (as chamadas condi\u00e7\u00f5es i.i.d., indepen-\n\ndent and identically distributed) (Vapnik, 1999).  \n\nSe o conjunto n\u00e3o puder ser amostrado corretamente, ainda \u00e9 poss\u00edvel balancear o \n\nconjunto de treinamento mediante o uso de fatores de pondera\u00e7\u00e3o (Berry et al., 2004). \n\nEste procedimento permite ajustar a contribui\u00e7\u00e3o de um grupo de amostras no resultado \n\nda an\u00e1lise, ponderando seus valores.  \n\n3.3 Predi\u00e7\u00e3o \n\nA predi\u00e7\u00e3o (ou previs\u00e3o) \u00e9 essencialmente uma esp\u00e9cie de estima\u00e7\u00e3o, tal como \n\ndefinida no in\u00edcio da se\u00e7\u00e3o 3.2 (Haykin, 1998; Berry et al., 2004). A diferen\u00e7a \u00e9 que \n\nestimador f  (Equa\u00e7\u00e3o 4) mapeia as resposta y num instante posterior \u00e0 amostragem de \n\nx . Isso significa que, dado uma entrada x obtida num instante t , f  retorna uma estima-\n\ntiva para y  (ou seja, y? ) em ?+t , onde ?  \u00e9 o intervalo de tempo desejado.  \n\n\n\n 31 \n\nUma das diferen\u00e7as construtivas mais significativas entre os modelos de estima-\n\n\u00e7\u00e3o e de predi\u00e7\u00e3o est\u00e1 na forma de compor os conjuntos de dados para o aprendizado do \n\nmodelo. A Figura 10 mostra de forma esquem\u00e1tica a estrat\u00e9gia normalmente adotada \n\npara criar o conjunto de treinamento para um sistema de predi\u00e7\u00e3o. A id\u00e9ia \u00e9 que o mo-\n\ndelo possa aprender como os dados do passado remoto afetaram a resposta do sistema \n\nno passado recente. Assim, baseando-se na premissa de que o futuro imita o passado, \n\ntorna-se poss\u00edvel prever o futuro alimentando-se o estimador com dados do passado \n\n(Makridakis et al., 1997; Berry et al., 2004). \n\nPassado \nmais distante\n\nPassado \ndistante\n\nPassado \nrecente\n\nPresente Futuro\n\nConstru\u00e7\u00e3o do modelo\n(aprendizado)\n\nAplica\u00e7\u00e3o do modelo\n(predi\u00e7\u00e3o)\n\n \n\nFigura 10 \u2013 Dados para um Modelo de Predi\u00e7\u00e3o \n\nExistem dois tipos b\u00e1sicos de modelos preditores: explanat\u00f3rios e temporais (Ma-\n\nkridakis et al., 1997).  \n\nOs modelos explanat\u00f3rios s\u00e3o estruturalmente id\u00eanticos aos estimadores \u2013 a dife-\n\nren\u00e7a reside no intervalo de tempo entre a amostragem das regressoras e a observa\u00e7\u00e3o \n\nda sa\u00edda. Durante o aprendizado, f  deve prever y  no instante 'kt =  a partir de x  a-\n\nmostrado em kt ?= , onde k?  \u00e9 um instante de tempo anterior \u00e0 'k  (ou seja, 'kk&lt;? ). \n\nA Equa\u00e7\u00e3o 6 mostra uma representa\u00e7\u00e3o matem\u00e1tica para o modelo descrito, enquanto \n\nque a Equa\u00e7\u00e3o 7 mostra como \u00e9 representado o conjunto utilizado para o aprendizado \n\ndesse modelo.  \n\n)(' kk xfy ?=  \n\nEqua\u00e7\u00e3o 6 \u2013 Modelo Preditor Explanat\u00f3rio  \n\n \n \n\n\n\n 32 \n\nliYXS yx\nii\n\nk\n\ni\n\nk\n\ni\n,...,2,1),(\n\n'\n=\u00d7?= ?  \n\nEqua\u00e7\u00e3o 7 \u2013 Conjunto de Treinamento para um Modelo Explanat\u00f3rio \n\nAssim como no caso dos estimadores, os modelos explanat\u00f3rios assumem que e-\n\nxiste uma depend\u00eancia funcional entre X e Y, mas nos moldes da Equa\u00e7\u00e3o 6. Para que o \n\nmodelo seja est\u00e1vel, assume-se que a depend\u00eancia funcional n\u00e3o se altera com o tempo, \n\no que \u00e9 chamado de presun\u00e7\u00e3o da continuidade (Makridakis et al., 1997).  \n\nOs modelos de s\u00e9ries temporais diferem dos explanat\u00f3rios por n\u00e3o considerar a \n\ndepend\u00eancia funcional mostrada na Equa\u00e7\u00e3o 4. Ao inv\u00e9s disso, o sistema \u00e9 considerado \n\numa caixa preta, e a predi\u00e7\u00e3o \u00e9 baseada somente nos valores passados (s\u00e9ries hist\u00f3ricas) \n\nda resposta4 (Makridakis et al., 1997; Berry et al., 2004). A denomina\u00e7\u00e3o temporal se \n\ndeve justamente ao emprego de s\u00e9ries hist\u00f3ricas, tamb\u00e9m denominadas de s\u00e9ries tempo-\n\nrais.  \n\nA Equa\u00e7\u00e3o 8 modela analiticamente um preditor temporal f, representando-o co-\n\nmo um mapeamento de Y para Y. Nesta equa\u00e7\u00e3o, k  \u00e9 o n\u00famero de amostras hist\u00f3ricas \n\nnecess\u00e1rias para prever a resposta. A Equa\u00e7\u00e3o 9 mostra o mesmo conceito.  \n\n121 ,...,,: +??? ? YyYYf k  \n\nEqua\u00e7\u00e3o 8 \u2013 Modelo Preditor Temporal \n\n),...,,( 211 kyyyfy ???+ =  \n\nEqua\u00e7\u00e3o 9 \u2013 Modelo de um Sistema Preditor Temporal \n\nExistem duas raz\u00f5es b\u00e1sicas para tratar alguns sistemas como uma caixa preta \n\n(Makridakis et al., 1997). Primeiro, o sistema pode ser pouco conhecido ou as depen-\n\nd\u00eancias funcionais podem ser dif\u00edceis de serem estabelecidas. Segundo, \u00e9 poss\u00edvel que \n\numa determinada an\u00e1lise esteja focada t\u00e3o somente na predi\u00e7\u00e3o, n\u00e3o havendo interesse \n\nnas possibilidades de um modelo explanat\u00f3rio, tais como a cria\u00e7\u00e3o de cen\u00e1rios e simu-\n\nla\u00e7\u00f5es.  \n\n                                                           \n4 \u00c9 oportuno destacar a exist\u00eancia de modelos que n\u00e3o s\u00e3o puramente explanat\u00f3rios ou temporais, mas \nincorporam caracter\u00edsiticas de ambos. Estes modelos s\u00e3o alimentados por s\u00e9ries hist\u00f3ricas de diferentes \nvari\u00e1veis explanat\u00f3rias (eventualmente, uma dessas entradas poderia ser uma s\u00e9rie hist\u00f3rica da pr\u00f3pria \nvari\u00e1vel-resposta). Poderiam, por esta raz\u00e3o, ser classificados como modelos h\u00edbridos, mas a bibliografia \nconsultada ao longo desta pesquisa reconhecia apenas os tipos puros (explanat\u00f3rios ou temporais).  \n\n\n\n 33 \n\nA Figura 11 mostra um esquema te\u00f3rico, mostrando um preditor temporal baseado \n\nna m\u00e1quina de aprendizado de Vapnik (Figura 9). Como a predi\u00e7\u00e3o est\u00e1 num instante de \n\ntempo posterior ao presente, a exatid\u00e3o da resposta n\u00e3o pode ser avaliada sen\u00e3o a poste-\n\nriori ou durante o aprendizado, conforme sugerem a Figura 10 e a Equa\u00e7\u00e3o 7. \n\n \n\nFigura 11 \u2013 Modelo Preditor Temporal (malha de atraso) \n\nEm rela\u00e7\u00e3o \u00e0 Figura 9, a Figura 11 apresenta uma diferen\u00e7a significativa: a inclu-\n\ns\u00e3o de uma base de dados hist\u00f3ricos H, que armazena os dados necess\u00e1rios para a defi-\n\nni\u00e7\u00e3o dos conjuntos de treinamento S. \n\n3.4 Teoria de Aprendizado Estat\u00edstico e Minimiza\u00e7\u00e3o de Risco \n\nOs algoritmos de aprendizado emp\u00edrico dependem de uma figura de m\u00e9rito para \n\navaliar a qualidade da modelagem5. Na abordagem n\u00e3o-param\u00e9trica, empregada pelos \n\nmodelos conexionistas, o aprendizado \u00e9 iterativo e o ajuste do modelo deve ser verifica-\n\ndo a cada itera\u00e7\u00e3o. Em geral, o aprendizado \u00e9 considerado completo (ou bem sucedido) \n\nquando a figura de m\u00e9rito atinge um determinado valor.  \n\n                                                           \n5 A figura de m\u00e9rito \u00e9 referida na literatura de estat\u00edstica param\u00e9trica como medida de adequa\u00e7\u00e3o do \nmodelo.  \n\n\n\n 34 \n\nUma figura de m\u00e9rito popular \u00e9 o erro m\u00e9dio quadr\u00e1tico (RMSE, Root Mean \n\nSquared Error), que transforma o aprendizado em um problema de minimiza\u00e7\u00e3o conve-\n\nxa (caso do backpropagation, utilizado pelas redes neuronais perceptron). Ent\u00e3o, em \n\nprinc\u00edpio, o aprendizado consiste na busca de um conjunto de par\u00e2metros tal que o \n\nRMSE seja m\u00ednimo. Todavia, freq\u00fcentemente a minimiza\u00e7\u00e3o conduz a uma anomalia \n\nconhecida como perda de generaliza\u00e7\u00e3o (Haykin, 1998).  \n\nEm seus trabalhos, Vladimir Vapnik (Vapnik, 1998; Vapnik 1999) contempla essa \n\nquest\u00e3o, propondo que o aprendizado emp\u00edrico n\u00e3o fosse determinado somente pelo \n\ndesempenho (RMSE), mas sim por um compromisso entre o desempenho e a complexi-\n\ndade dos modelos gerados. Desta forma, a quest\u00e3o da perda de generaliza\u00e7\u00e3o pode ser \n\ncontornada sem preju\u00edzo do desempenho obtido. \n\n3.4.1 Considera\u00e7\u00f5es iniciais \n\nConsiderando a Equa\u00e7\u00e3o 4 e a Equa\u00e7\u00e3o 5, que definem a depend\u00eancia funcional \n\nYX ? e o conjunto de treinamento YXS \u00d7= , assume-se que a depend\u00eancia funcional \n\nassinalada pela equa\u00e7\u00e3o 2 n\u00e3o \u00e9 determin\u00edstica, no sentido de que cada valor de x n\u00e3o \n\ndetermina um valor de y mas, sim, uma distribui\u00e7\u00e3o de probabilidade P(X,Y), mostrada \n\nna Equa\u00e7\u00e3o 10.  \n\n)|()(),( XYPXPYXP ?=  \n\nEqua\u00e7\u00e3o 10 \u2013 Distribui\u00e7\u00e3o de Probabilidade Conjunta de X e Y \n\nA Equa\u00e7\u00e3o 10 mostra P(X,Y) como uma distribui\u00e7\u00e3o de probabilidade desconhe-\n\ncida que gera o conjunto S independente e id\u00eanticamente (as chamadas condi\u00e7\u00f5es i.i.d., \n\nindenpendent and identically distributed) (Cristiani, 2001). Portanto, YX ?  \u00e9 uma \n\ndepend\u00eancia probabil\u00edstica descrita por P=P(X,Y).  \n\nO aprendizado estat\u00edstico consiste em definir um estimador f (definido na \n\nEqua\u00e7\u00e3o 4) que seja capaz de predizer o valor de y para qualquer Xx ?  a partir de S. \n\nEsta estrat\u00e9gia \u00e9 chamada de modelagem emp\u00edrica, raz\u00e3o pela qual f \u00e9 tamb\u00e9m chamado \n\nde modelo emp\u00edrico do sistema (Vapnik, 1999).  \n\nA Equa\u00e7\u00e3o 11 define f como membro de uma grande classe ou fam\u00edlia de fun\u00e7\u00f5es \n\nF, tamb\u00e9m denominado de espa\u00e7o de hip\u00f3teses. Portanto, a Equa\u00e7\u00e3o 4 admite muitas \n\n\n\n 35 \n\nsolu\u00e7\u00f5es distintas, restando definir uma figura de m\u00e9rito para selecionar qual delas \u00e9 \n\nmais adequada. \n\n \n\n{ }C\niifF 1==  \n\nEqua\u00e7\u00e3o 11 \u2013 Classe de Fun\u00e7\u00f5es (estimadores) \n\nA Teoria do Aprendizado Estat\u00edstico define essa figura de m\u00e9rito em termos do \n\nrisco funcional, mostrado na Equa\u00e7\u00e3o 12 (Vapnik, 1998). O risco funcional mede a \n\nquantidade m\u00e9dia de erro (risco) associado a um estimador f, criando assim uma figura \n\nde m\u00e9rito para selecionar o melhor estimador de F, denominado de f0 (fun\u00e7\u00e3o alvo), \n\ncomo sendo aquele que apresenta o menor risco.  \n\n)( ifRR =  \n\nEqua\u00e7\u00e3o 12 \u2013 Risco Funcional de if  \n\nO risco funcional \u00e9 definido em fun\u00e7\u00e3o dos erros de estima\u00e7\u00e3o de fi. A Figura 9 e \n\na Figura 11 destacam este fato, ao utilizar nota\u00e7\u00f5es diferentes para as sa\u00eddas real (y, a \n\nsa\u00edda do sistema) e estimada ( y? ). Nesta se\u00e7\u00e3o, ambas as sa\u00eddas ser\u00e3o denotadas respec-\n\ntivamente como y e f(x). A fun\u00e7\u00e3o de perda (loss function) (Vapnik, 1998; Cristiani, \n\n2001; Hastie et al., 2003) mostrada na Equa\u00e7\u00e3o 13 define uma penaliza\u00e7\u00e3o para os erros \n\nde estima\u00e7\u00e3o. A literatura prop\u00f5e uma s\u00e9rie de implementa\u00e7\u00f5es para esta fun\u00e7\u00e3o, sendo \n\na mais popular mostrada na Equa\u00e7\u00e3o 14, chamada de perda do erro quadr\u00e1tico (squa-\n\nred-error loss function) (Hastie et al., 2003).  \n\n( )( )xfyLL ,=  \n\nEqua\u00e7\u00e3o 13 \u2013 Fun\u00e7\u00e3o de Perda \n\n( )( ) ( )[ ]2, xfyxfyLL ?==  \n\nEqua\u00e7\u00e3o 14 \u2013 Fun\u00e7\u00e3o de Perda do Erro Quadr\u00e1tico \n\nA partir da no\u00e7\u00e3o de perda, \u00e9 poss\u00edvel definir o risco funcional como o erro de es-\n\ntima\u00e7\u00e3o esperado (EPE, expected prediction error) na forma da esperan\u00e7a matem\u00e1tica \n\n\n\n 36 \n\nmostrada na Equa\u00e7\u00e3o 15 (Vapnik, 1998; Hastie et al., 2003). Como assinalado, o c\u00e1lculo \n\ndo c\u00e1lculo da esperan\u00e7a (E) exige que a fun\u00e7\u00e3o de perda deva ser integr\u00e1vel para qual-\n\nquer Ffi ? .  \n\n( ) ( )( )[ ] ( )( ) ( )? ?=?\nYX\n\niii dxdyyxPxfyLXfYLEfR\n,\n\n,,,  \n\nEqua\u00e7\u00e3o 15 \u2013 Esperan\u00e7a Matem\u00e1tica Definida como Risco Funcional Esperado \n\nA Equa\u00e7\u00e3o 16 mostra a esperan\u00e7a da Equa\u00e7\u00e3o 15 condicionada a X. O condicio-\n\nnamento \u00e9 obtido fatorando a distribui\u00e7\u00e3o conjunta ( ) ( ) ( )XPXYPYXP ?= |, , onde \n( ) ( ) ( )XPXYPXYP ,| = , e dividindo a integral bivariada de acordo (Hastie et al., \n\n2003). \n\n( ) ( )( )[ ]XxfyLEEfR iXYXi |,|?  \n\nEqua\u00e7\u00e3o 16 \u2013 Fun\u00e7\u00e3o de Risco Condicionada a X  \n\nCom base na defini\u00e7\u00e3o da Equa\u00e7\u00e3o 15, o aprendizado estat\u00edstico pode ser formal-\n\nmente definido como a busca por uma fun\u00e7\u00e3o Ffi ?  tal que ( )ifR  seja m\u00ednimo. A lite-\nratura destaca que os problemas de estat\u00edstica b\u00e1sica relacionados \u00e0 estima\u00e7\u00e3o de fun-\n\n\u00e7\u00f5es (tais como m\u00ednimos quadrados ou vizinho-mais-pr\u00f3ximo) podem descritos como \n\nformas de minimizar o risco funcional a partir de uma cole\u00e7\u00e3o emp\u00edrica de dados (Vap-\n\nnik, 1998; Hastie et al., 2003). A Equa\u00e7\u00e3o 17 mostra a fun\u00e7\u00e3o de risco condicionada da \n\nEqua\u00e7\u00e3o 16 minimizada ponto a ponto, cuja solu\u00e7\u00e3o \u00e9 mostrada na Equa\u00e7\u00e3o 18 (Hastie \n\net al., 2003). \n\n \n\n( ) ( )( )xXcYExf XYc =?= |minarg 2|  \nEqua\u00e7\u00e3o 17 \u2013 Minimiza\u00e7\u00e3o do Risco Ponto a Ponto \n\n \n( ) ( )xXYExf == |0  \n\nEqua\u00e7\u00e3o 18 \u2013 Esperan\u00e7a Condicionada \n\nNo jarg\u00e3o da estat\u00edstica, a Equa\u00e7\u00e3o 18 \u00e9 a fun\u00e7\u00e3o de regress\u00e3o que modela a de-\n\npend\u00eancia YX ?  (Hastie et al., 2003). Embora se admita a exist\u00eancia de um estimador \n\nf0 tal que R(f0) \u00e9 m\u00ednimo, ele n\u00e3o pode ser determinado porque P(X,Y) (que define o \n\n\n\n 37 \n\nrisco na Equa\u00e7\u00e3o 15) n\u00e3o \u00e9 conhecido. Tudo que se conhece sobre o sistema \u00e9 uma a-\n\nmostra de dados \u2013 o conjunto S. Para superar esta limita\u00e7\u00e3o, \u00e9 utilizado um princ\u00edpio de \n\nindu\u00e7\u00e3o para aproximar R a partir desta amostra. Na modelagem emp\u00edrica, o processo \n\nde indu\u00e7\u00e3o deve ser tal que produza um estimador capaz de estimar respostas para dados \n\nque foram omitidos em S (poder de generaliza\u00e7\u00e3o).   \n\n \n\n3.4.2 Princ\u00edpios de indu\u00e7\u00e3o \n\nA Teoria do Aprendizado Estat\u00edstico, tal como concebida por Vapnik (1999), de-\n\nfine dois princ\u00edpios de indu\u00e7\u00e3o: Princ\u00edpio da Indu\u00e7\u00e3o da Minimiza\u00e7\u00e3o do Risco Emp\u00edri-\n\nco (ERM, Empirical Risk Minimization) e o Princ\u00edpio da Indu\u00e7\u00e3o da Minimiza\u00e7\u00e3o do \n\nRisco Estrutural (SRM, Structural Risk Minimization). O ERM \u00e9 a forma cl\u00e1ssica de \n\nminimiza\u00e7\u00e3o de risco empregado pelos primeiros algoritmos de aprendizado (modelos \n\nconexionistas), sendo de larga aceita\u00e7\u00e3o no meio cient\u00edfico. O SRM \u00e9 uma contribui\u00e7\u00e3o \n\noriginal dos trabalhos de Vapnik sobre o SVM (Support Vector Machine), desenvolvido \n\na partir da d\u00e9cada de 90 (Vapnik, 1998; Vapnik, 1999; Cristiani, 2001; Schlkopf et al., \n\n2001). \n\nNa modelagem emp\u00edrica, a quantidade e a qualidade das amostras de S determi-\n\nnam o desempenho do estimador obtido. Dado a sua natureza observacional, os dados \n\ns\u00e3o finitos e amostrados; por isso, problemas de amostragem s\u00e3o comuns, gerando da-\n\ndos n\u00e3o balanceados (Pindyck et al., 2004; Berry et al., 2004). Devido \u00e0 alta dimensiona-\n\nlidade do problema, S normalmente \u00e9 uma regi\u00e3o esparsa do espa\u00e7o das entradas. Con-\n\nseq\u00fcentemente, a estima\u00e7\u00e3o ser\u00e1 quase sempre um problema mal posto (ill posed), no \n\nsentido que diversas solu\u00e7\u00f5es s\u00e3o admitidas (Herbrich, 2001).  \n\nAs abordagens conexionistas est\u00e3o sujeitas a problemas de generaliza\u00e7\u00e3o, fre-\n\nq\u00fcentemente produzindo estimadores superajustados que apresentam um desempenho \n\nruim ap\u00f3s o aprendizado (Haykin, 1998). Isto \u00e9 uma conseq\u00fc\u00eancia direta dos algoritmos \n\nde otimiza\u00e7\u00e3o empregados para sele\u00e7\u00e3o de par\u00e2metros6, al\u00e9m das m\u00e9tricas estat\u00edsticas \n\n                                                           \n6 Sele\u00e7\u00e3o de par\u00e2metros \u00e9 um termo consagrado na literatura de redes neuronais, n\u00e3o possuindo rela\u00e7\u00e3o \ncom o conceito de estima\u00e7\u00e3o de par\u00e2metros empregada pela estat\u00edstica param\u00e9trica. Refere-se ao proces-\nso de determinar quais vari\u00e1veis de entradas (ou par\u00e2metros de entrada) s\u00e3o relevantes para modelar o \nsistema em quest\u00e3o \n\n\n\n 38 \n\nusadas para selecionar a melhor solu\u00e7\u00e3o. A qualidade de uma solu\u00e7\u00e3o \u00e9 dada pela mi-\n\nnimiza\u00e7\u00e3o do risco funcional que, no caso das abordagens conexionistas, \u00e9 obtido pela \n\naplica\u00e7\u00e3o do ERM.  \n\nO ERM minimiza o erro das estima\u00e7\u00f5es obtidas durante o treinamento. Ao final \n\ndo aprendizado, assume-se que o desempenho obtido com amostras novas ser\u00e1 similar \n\n\u00e0quele obtido com o conjunto de treinamento, o que nem sempre \u00e9 verdadeiro. A \n\nEqua\u00e7\u00e3o 15 mostra a defini\u00e7\u00e3o do risco esperado em termos da perda (fun\u00e7\u00e3o de perda) \n\ne da distribui\u00e7\u00e3o P(X,Y). Como a distribui\u00e7\u00e3o n\u00e3o \u00e9 conhecida, o risco s\u00f3 pode ser cal-\n\nculado por meio de uma aproxima\u00e7\u00e3o baseada na informa\u00e7\u00e3o dispon\u00edvel: o conjunto S e \n\nas propriedades de F; ou seja, o conjunto que cont\u00e9m a fam\u00edlia de estimadores f. \n\nA Equa\u00e7\u00e3o 19 mostra uma aproxima\u00e7\u00e3o para o risco esperado: o risco emp\u00edrico. \n\nTal risco \u00e9 a m\u00e9dia aritm\u00e9tica simples da fun\u00e7\u00e3o de perda para cada amostra do conjun-\n\nto S. O Teorema Chave da Teoria do Aprendizado (Vapnik, 1998; Vapnik, 1999) de-\n\nmonstra que o risco emp\u00edrico converge assintoticamente para o risco emp\u00edrico quando o \n\ntamanho da amostra \u00e9 muito grande; ou seja, quando ??L . Portanto, uma alta cardi-\n\nnalidade de S garante uma solu\u00e7\u00e3o emp\u00edrica satisfat\u00f3ria com ( ) ( )iiemp fRfR ? . \n\n( ) ( )( )?\n=\n\n?=\nL\n\nl\niliiemp yxfLLfR\n\n1\n\n,1  \n\nEqua\u00e7\u00e3o 19 \u2013 Risco Emp\u00edrico \n\nPor outro lado, quando a amostra n\u00e3o \u00e9 suficientemente representativa, a diferen\u00e7a \n\nentre Remp e R(fi) pode diferir por uma larga margem, acarretando problemas de supera-\n\njuste. Em termos pr\u00e1ticos, isso significa que a minimiza\u00e7\u00e3o do risco emp\u00edrico da \n\nEqua\u00e7\u00e3o 19 n\u00e3o assegura sempre um erro de generaliza\u00e7\u00e3o pequeno.  \n\nA Figura 12 mostra como a minimiza\u00e7\u00e3o emp\u00edrica (ERM) pode conduzir a ano-\n\nmalias, especialmente quando S \u00e9 pequeno ou a sua amostragem \u00e9 desbalanceada. Nesta \n\nfigura, \u00e9 mostrado como a minimiza\u00e7\u00e3o do erro durante o aprendizado n\u00e3o conduz ne-\n\ncessariamente a uma diminui\u00e7\u00e3o do erro de generaliza\u00e7\u00e3o. \n\n\n\n 39 \n\n \nFigura 12 \u2013 O Dilema do Superajuste \n\nNa Figura 12, existem duas classes de amostras identificadas por c\u00edrculos de cores \n\ndiferentes num espa\u00e7o de caracter\u00edsticas 2? . O problema consiste em determinar uma \n\nfun\u00e7\u00e3o discriminante tal que seja poss\u00edvel determinar a classe de uma amostra a partir \n\ndas suas caracter\u00edsticas. Portanto, o estimador pretendido \u00e9 um classificador capaz de \n\nidentificar as amostras com uma resposta bin\u00e1ria, digamos { }1,1 ?+?y . Em (a), um con-\njunto muito pequeno de dados \u00e9 utilizado para o treinamento. Com base neste conjunto, \n\ns\u00e3o definidas duas hip\u00f3teses de classifica\u00e7\u00e3o: uma discriminante complexa (a curva \n\ncont\u00ednua) e uma simples (a reta tracejada). Claramente, o desempenho da discriminante \n\ncont\u00ednua \u00e9 superior \u00e0 da tracejada em (a), pois a primeira hip\u00f3tese classifica as amostras \n\ncorretamente enquanto a segunda comete dois erros de classifica\u00e7\u00e3o.  \n\nA Figura 12(a) pode ser explicada em termos do erro de treinamento: a hip\u00f3tese \n\ncont\u00ednua \u00e9 complexa, mas apresenta um erro de treinamento inferior \u00e0 da hip\u00f3tese trace-\n\njada. Entretanto, este resultado aparentemente bom pode estar associado a um erro de \n\ngeneraliza\u00e7\u00e3o grande, o que seria percebido com amostras maiores. \n\nA Figura 12(b) e a Figura 12(c) analisam o desempenho das mesmas hip\u00f3teses na \n\npresen\u00e7a de mais dados, omitidos no treinamento. Se a hip\u00f3tese cont\u00ednua for correta, \n\ncorroborando o desempenho do treinamento, a hip\u00f3tese tracejada seria subajustada, \n\nclassificando mal as amostras na situa\u00e7\u00e3o (b). Se a hip\u00f3tese tracejada estiver correta, a \n\nhip\u00f3tese cont\u00ednua seria superajustada, tamb\u00e9m classificando mal as amostras em (c) a \n\ndespeito do bom desempenho no treinamento mostrado em (a). Nesta \u00faltima hip\u00f3tese, o \n\npequeno erro cometido pela hip\u00f3tese tracejada no treinamento (a) acaba conduzindo a \n\num melhor desempenho numa amostra maior de dados.  \n\n\n\n 40 \n\nO superajuste reside neste dilema: um pequeno erro de treinamento pode acabar \n\ndegradando o desempenho do estimador, diminuindo seu poder de generaliza\u00e7\u00e3o. Por-\n\ntanto, pode ser melhor admitir um erro de treinamento maior para assegurar um grau de \n\ngeneraliza\u00e7\u00e3o maior. A quest\u00e3o que surge \u00e9: at\u00e9 que ponto o erro de treinamento \u00e9 v\u00e1li-\n\ndo como crit\u00e9rio para sele\u00e7\u00e3o dos estimadores gerados? \n\nNa pr\u00e1tica, essa quest\u00e3o pode ser respondida atrav\u00e9s de um artif\u00edcio denominado \n\nvalida\u00e7\u00e3o cruzada (Haykin, 1998; Duda et al., 2000). A valida\u00e7\u00e3o cruzada prop\u00f5e que \n\num conjunto especial de dados, denominado conjunto de valida\u00e7\u00e3o, seja utilizado para \n\navaliar o estimador durante o processo de aprendizado.  \n\nO conjunto de treinamento \u00e9 utilizado para gerar iterativamente novos estimadores \n\nque minimizam cada vez mais o erro de treinamento. O conjunto de valida\u00e7\u00e3o, por sua \n\nvez, \u00e9 utilizado para verificar o erro de generaliza\u00e7\u00e3o a cada itera\u00e7\u00e3o, sem interferir di-\n\nretamente no aprendizado. Como estes conjuntos s\u00e3o disjuntos (n\u00e3o possuem elementos \n\nem comum), a utiliza\u00e7\u00e3o desta abordagem pode auxiliar a evitar estimadores superajus-\n\ntados. \n\nA Figura 13 mostra como a valida\u00e7\u00e3o cruzada pode ser empregada para minimizar \n\no erro de generaliza\u00e7\u00e3o em uma situa\u00e7\u00e3o de aprendizado t\u00edpica. No gr\u00e1fico, a ordenada \n\nmostra o desempenho dos estimadores gerados como o erro emp\u00edrico, percebido como \n\nRMSE (Root Mean Squared Error)7. A abscissa representa as itera\u00e7\u00f5es utilizadas para \n\ngerar cada estimador (\u00e9pocas), sendo uma medida discreta do tempo. Assim, para a \u00e9po-\n\nca 1 se tem um par estimador/erro, para a \u00e9poca 2 outro e assim sucessivamente.  \n\n                                                           \n7 O RMSE \u00e9 a forma mais popular de se medir o desempenho de um estimador (Haykin, 1998; Duda et \nal., 2000). Tecnicamente, o RMSE \u00e9 uma implementa\u00e7\u00e3o do erro emp\u00edrico (Equa\u00e7\u00e3o 19) com a perda \n\nquadr\u00e1tica (Equa\u00e7\u00e3o 14), sendo portanto definido como ( ) ( )( )?\n=\n\n?=\nI\n\ni\niiii yxfLIfRMSE\n\n1\n\n,1  ( )( )?\n=\n\n??=\nI\n\ni\niii yxfI\n\n1\n\n21  \n\n \n\n\n\n 41 \n\n Valida\u00e7\u00e3o\n Treinamento\n\n\u00c9pocas\n0,0\n\n0,2\n\n0,4\n\n0,6\n\n0,8\n\n1,0\n\n1,2\n\nR\nM\n\nS\nE\n\nGeneraliza\u00e7\u00e3o M\u00e1xima\n\n \nFigura 13 \u2013 Valida\u00e7\u00e3o Cruzada e Generaliza\u00e7\u00e3o \n\nA curva vermelha da Figura 13 mede o RMSE do treinamento de um estimador \n\nnuma aplica\u00e7\u00e3o de regress\u00e3o de fun\u00e7\u00e3o. Como pode ser observado, esse erro tende a \n\ndiminuir \u00e0 medida que o aprendizado progride e gera estimadores melhor adaptados ao \n\nconjunto de treinamento. Tipicamente, o estimador associado a cada \u00e9poca8 possui um \n\ndesempenho superior (RMSE menor) do que o estimador da \u00e9poca anterior, raz\u00e3o pela \n\nqual a curva \u00e9 decrescente. Para aplica\u00e7\u00f5es de regress\u00e3o de fun\u00e7\u00f5es, a curva ser\u00e1 sempre \n\nassint\u00f3tica, possivelmente tangenciando o n\u00edvel de erro zero quando o tempo (\u00e9poca) for \n\nrelativamente grande. \n\nA curva verde mostra o erro de valida\u00e7\u00e3o, que \u00e9 o desempenho obtido pelo esti-\n\nmador (RMSE) no processamento do conjunto de valida\u00e7\u00e3o. A gera\u00e7\u00e3o dos estimadores \n\nn\u00e3o \u00e9 influenciada pelo conjunto de valida\u00e7\u00e3o, o qual tem por \u00fanica finalidade verificar \n\no poder de generaliza\u00e7\u00e3o dos estimadores depois que eles s\u00e3o criados.   \n\n                                                           \n8 \u00c9poca \u00e9 empregada na literatura de redes neuronais e de Aprendizado Estat\u00edstico como sendo um passo \n(ou itera\u00e7\u00e3o) do processo iterativo de ajuste dos par\u00e2metros ajust\u00e1veis de um estimador. \n\n\n\n 42 \n\nO erro de generaliza\u00e7\u00e3o \u00e9 sempre maior do que o obtido com o conjunto de trei-\n\nnamento, embora as duas curvas tendam a decrescer juntas at\u00e9 um ponto denominado \n\ngeneraliza\u00e7\u00e3o m\u00e1xima (assinalado na Figura 13). A partir deste ponto, o modelo come-\n\n\u00e7a a perder o poder de generaliza\u00e7\u00e3o e, apesar do erro de treinamento continuar a cair, o \n\nerro de generaliza\u00e7\u00e3o come\u00e7a a aumentar. Neste caso, o comportamento do risco espe-\n\nrado aproxima-se do erro de generaliza\u00e7\u00e3o, que pode ser grande mesmo quando o erro \n\nde treinamento se aproxima de zero. Por essa raz\u00e3o, a literatura recomenda que o apren-\n\ndizado seja interrompido exatamente no ponto de generaliza\u00e7\u00e3o m\u00e1xima (Haykin, 1998; \n\nDuda et al., 2000; Hastie et al., 2003).  \n\nA valida\u00e7\u00e3o cruzada contorna a quest\u00e3o da generaliza\u00e7\u00e3o do ERM, permitindo \n\numa concilia\u00e7\u00e3o entre desempenho e generaliza\u00e7\u00e3o. Entretanto, \u00e9 necess\u00e1rio haver a-\n\nmostras suficientes para compor independentemente os conjuntos de treinamento e de \n\nvalida\u00e7\u00e3o. Al\u00e9m disso, a sele\u00e7\u00e3o do melhor estimador continua sendo um problema mal \n\nposto: pode haver muitas, possivelmente infinitas, fun\u00e7\u00f5es fi que minimizam o erro em-\n\np\u00edrico.  \n\nPor outro lado, a Figura 12 mostra que um erro de treinamento pequeno (erro em-\n\np\u00edrico) pode estar associado a uma hip\u00f3tese complexa que apresenta um alto erro de \n\ngeneraliza\u00e7\u00e3o. \u00c9 precisamente este ponto que o SRM explora para minimizar o risco \n\nesperado: restringir a complexidade dos estimadores gerados no aprendizado. De certa \n\nforma, o SRM \u00e9 uma aplica\u00e7\u00e3o da navalha de Occam9, ao considerar que um estimador \n\nsimples que explique a maioria dos dados de S com um erro pequeno \u00e9 melhor do que \n\num estimador complexo com desempenho igual ou mesmo superior (Figura 12). A id\u00e9ia \n\n\u00e9 definir um estimador pertencente a uma classe de fun\u00e7\u00e3o (Equa\u00e7\u00e3o 11), cuja comple-\n\nxidade seja a menor poss\u00edvel. \n\nExiste um paradoxo potencial no risco estrutural: a minimiza\u00e7\u00e3o de complexidade \n\npode aumentar o risco emp\u00edrico, o que conduziria a um erro esperado maior. Ent\u00e3o, a \n\nbusca de solu\u00e7\u00f5es no aprendizado n\u00e3o pode se limitar a poucas classes de fun\u00e7\u00f5es restri-\n\n                                                           \n9 A navalha (ou crivo) de Occam \u00e9 oriunda dos trabalhos de Guilherme de Occam, frade franciscano do \ns\u00e9c. XIV que \u00e9 considerado um dos precursores do pensamento cr\u00edtico cient\u00edfico. O original em latim, \npluralitas non est ponenda sine neccesitate, \u00e9 traduzido livremente como dada duas teorias que explicam \nigualmente os mesmos fatos, a mais simples deve ser a correta. No contexto da TAE, se uma fun\u00e7\u00e3o \n\n\n\n 43 \n\ntas, de pequena complexidade, mas sim considerar muitas classes diferentes de fun\u00e7\u00f5es. \n\nA melhor solu\u00e7\u00e3o poss\u00edvel \u00e9 um compromisso entre o erro emp\u00edrico e a complexidade \n\nda solu\u00e7\u00e3o utilizada para minimizar este erro (Vapnik, 1998). Este compromisso \u00e9 a \n\nbase qualitativa do SRM.  \n\nA Equa\u00e7\u00e3o 20 mostra a complexidade de um estimador, conhecido como fator de \n\nregulariza\u00e7\u00e3o, termo de confian\u00e7a ou termo de capacidade (Schlkopf et al., 2001), de-\n\nnotado por ? . ?  \u00e9 uma fun\u00e7\u00e3o da capacidade h, que mede a complexidade da classe F, \n\ndo n\u00famero L de amostras presentes no conjunto de treinamento e de uma probabilidade \n\nm\u00ednima ? . Intuitivamente, para uma mesma probabilidade ? , se a capacidade h \u00e9 gran-\n\nde e o n\u00famero de amostras L \u00e9 pequeno, ent\u00e3o a dist\u00e2ncia entre os erros emp\u00edrico e es-\n\nperado tende a ser grande tamb\u00e9m, o que conduz a erros de generaliza\u00e7\u00e3o grandes. \n\n \n\n?\n?\n?\n\n?\n?\n?\n?\n\n?\n?=? ?,\n\nL\nh\n\n \n\nEqua\u00e7\u00e3o 20 \u2013 O Fator de Regulariza\u00e7\u00e3o ?  (limite probabil\u00edstico do risco emp\u00edrico) \n \n\nO fator de regulariza\u00e7\u00e3o \u00e9 utilizado durante o aprendizado para controlar a com-\n\nplexidade do estimador usado para explicar S (Schlkopf et al., 2001), raz\u00e3o pela qual \n\ntamb\u00e9m \u00e9 chamado de termo de complexidade. A regulariza\u00e7\u00e3o fornece limites probabi-\n\nl\u00edsticos para a dist\u00e2ncia entre os riscos esperado e emp\u00edrico de qualquer fun\u00e7\u00e3o, incluin-\n\ndo o minimizador do risco emp\u00edrico em um espa\u00e7o de fun\u00e7\u00f5es que pode ser usado para \n\ncontrolar o superajuste (Vapnik, 1999). \n\nA rela\u00e7\u00e3o entre o risco esperado, o risco emp\u00edrico e o termo de regulariza\u00e7\u00e3o \u00e9 \n\nmostrada por meio da desigualdade da Equa\u00e7\u00e3o 21.  \n\n \n\n( ) ( ) ??\n?\n\n?\n?\n?\n?\n\n?\n?+? ?,\n\nL\nh\n\nfRfR iempi  \n\nEqua\u00e7\u00e3o 21 \u2013 O Risco Esperado Relacionado ao Risco Emp\u00edrico e ao Fator de Regulariza\u00e7\u00e3o ?  \n\n                                                                                                                                                                          \nsimples explica uma amostra emp\u00edrica de dados, n\u00e3o h\u00e1 necessidade de buscar outra mais complexa. Por \nesta raz\u00e3o, o crivo tamb\u00e9m \u00e9 conhecido como Princ\u00edpio da Economia. \n\n\n\n 44 \n\nA TAE define muitas formas de medir a capacidade h de uma classe de fun\u00e7\u00f5es F, \n\nsendo que a mais comum \u00e9 a chamada dimens\u00e3o VC (dimens\u00e3o de Vapnik e Chervo-\n\nnenkis) (Vapnik, 1998; Herbrich, 2001). O termo \u201cdimens\u00e3o\u201d neste contexto tem uma \n\nconota\u00e7\u00e3o diferente da usual, ao designar uma medida da capacidade de um algoritmo \n\nde classifica\u00e7\u00e3o bin\u00e1ria. Essa medida \u00e9 dada pelo maior conjunto de pontos p que tal \n\nalgoritmo pode distinguir dicotomicamente em todas as 2p maneiras poss\u00edveis (Vapnik, \n\n1998; Hastie et al., 2003).  \n\nEm geral, os discriminantes lineares possuem a capacidade h igual ao n\u00famero de \n\npar\u00e2metros livres mais um; ou seja, quanto maior o grau de liberdade, maior a capacida-\n\nde do discriminante e, conseq\u00fcentemente, maior a complexidade envolvida (Herbrich, \n\n2001; Hastie et al., 2003). Outros tipos de discriminante, como a sinus\u00f3ide, podem ter \n\ncapacidade infinita (Vapnik, 1999; Hastie et al., 2003). Para aplica\u00e7\u00f5es de regress\u00e3o, \n\nonde ( ) ??xf , a capacidade de f(x) \u00e9 medida indiretamente por meio de uma fun\u00e7\u00e3o \nindicadora, nos termos da Equa\u00e7\u00e3o 22 (Hastie et al., 2003). Esta fun\u00e7\u00e3o indicadora pos-\n\nsui como par\u00e2metros f(x) e ?, uma constante que assumes valores na mesma faixa que \n\nf(x), retornando dois valores poss\u00edveis (classifica\u00e7\u00e3o bin\u00e1ria). Neste caso, a capacidade \n\nh  de f(x) ser\u00e1 adequadamente aproximada por I (Hastie et al., 2003). \n\n( )( )??= xfII  \nEqua\u00e7\u00e3o 22 \u2013 A Complexidade de f(x) Medida Indiretamente por Meio de uma Fun\u00e7\u00e3o Indicadora \n\nA Equa\u00e7\u00e3o 21 determina um risco esperado m\u00ednimo R(fi) atrav\u00e9s de um erro de \n\ntreinamento Remp(fi) pequeno e de um estimador t\u00e3o simples quanto poss\u00edvel (fator de \n\nregulariza\u00e7\u00e3o ?  pequeno). Essa abordagem admite duas situa\u00e7\u00f5es extremas:  \n\na) Uma classe de fun\u00e7\u00e3o Fk produz um fator de regulariza\u00e7\u00e3o baixo, mas um alto \n\nerro no treinamento \u00e9 observado. \n\nb) Uma classe de fun\u00e7\u00e3o Fk\u2019 produz um erro de treinamento baixo, mas o fator de \n\nregulariza\u00e7\u00e3o obtido \u00e9 grande. \n\nA melhor classe de fun\u00e7\u00e3o est\u00e1 entre os dois extremos mostrados, conforme mos-\n\ntra a Figura 14, dado que o interesse \u00e9 obter uma fun\u00e7\u00e3o (estimador) que explique os \n\n\n\n 45 \n\ndados do treinamento suficientemente bem e que mantenha o risco esperado (erro de \n\ngeneraliza\u00e7\u00e3o) baixo.   \n\n \n\n Confian\u00e7a\n Risco Emp\u00edrico\n Risco Esperado\n\nComplexidade do Conjunto de Fun\u00e7\u00f5es\n-0,2\n\n0,0\n\n0,2\n\n0,4\n\n0,6\n\n0,8\n\n1,0\n\n1,2\n\n1,4\n\n1,6\n\nBaixa complexidade Alta complexidade\n\n \nFigura 14 \u2013 Limites Probabil\u00edsticos entre os Riscos Emp\u00edrico e Esperado \n\nA Figura 14 mostra graficamente a desigualdade da Equa\u00e7\u00e3o 21, onde s\u00e3o tra\u00e7a-\n\ndos o erro emp\u00edrico (erro de treinamento, em vermelho), o limite superior do termo de \n\ncomplexidade (em azul) e o risco esperado correspondente (em verde). A an\u00e1lise da \n\nfigura mostra que uma complexidade alta assegura um erro emp\u00edrico baixo, mas o limite \n\nsuperior da confian\u00e7a se torna pior. O ponto m\u00ednimo do erro esperado (assinalado na \n\nfigura) \u00e9 atingido para a capacidade h de uma determinada classe F. Portanto, o apren-\n\ndizado consiste num ponto de equil\u00edbrio entre o erro emp\u00edrico e a complexidade ? . \n\nA inspe\u00e7\u00e3o da Figura 13 e da Figura 14 mostra que o risco esperado e o erro de \n\ngeneraliza\u00e7\u00e3o est\u00e3o fortemente correlacionados. Na primeira figura, o n\u00famero de \u00e9pocas \n\n(abscissa do gr\u00e1fico) torna os modelos cada vez mais especializados, e a partir do ponto \n\nde m\u00e1xima generaliza\u00e7\u00e3o ocorre perda de generaliza\u00e7\u00e3o. Na segunda, os riscos esperado \n\ne emp\u00edrico caem \u00e0 medida que a capacidade h cresce; quando o limite probabil\u00edstico \n\ncome\u00e7a a se tornar muito alto, o risco esperado come\u00e7a a subir enquanto o erro emp\u00edrico \n\n\n\n 46 \n\ncontinua caindo. Ambas as figuras sugerem que \u00e9 necess\u00e1rio balancear a capacidade h e \n\no erro emp\u00edrico, sem o qu\u00ea o risco esperado (ou o erro de generaliza\u00e7\u00e3o) pode compro-\n\nmeter o desempenho do estimador gerado. Portanto, h\u00e1 ind\u00edcios que, durante o processo \n\niterativo de aprendizado, os estimadores gerados v\u00e3o se tornando cada vez mais com-\n\nplexos. Como conseq\u00fc\u00eancia, fica estabelecido que uma das formas de controlar a com-\n\nplexidade dos estimadores gerados \u00e9 restringir o n\u00famero de itera\u00e7\u00f5es do processo de \n\naprendizado. \n\nA Figura 15 mostra o processo de aprendizado por meio de uma analogia gr\u00e1fica. \n\nNesta analogia, os membros de uma classe de fun\u00e7\u00f5es s\u00e3o representados num espa\u00e7o de \n\nhip\u00f3teses, que \u00e9 um subconjunto de todos os estimadores poss\u00edveis (espa\u00e7o alvo).  \n\n \nFigura 15 \u2013 Erros no Aprendizado \n\nNa Figura 15, erro de generaliza\u00e7\u00e3o \u00e9 representado como a soma vetorial do erro \n\nde estima\u00e7\u00e3o e do erro de aproxima\u00e7\u00e3o. O erro de estima\u00e7\u00e3o \u00e9 conseq\u00fc\u00eancia do proce-\n\ndimento de aprendizado, que em fun\u00e7\u00e3o de uma s\u00e9rie de limita\u00e7\u00f5es (como a escolha de \n\npar\u00e2metros ou um n\u00famero de amostras insuficiente) acaba produzindo um modelo sub-\n\n\u00f3timo ( Lnf ,\n\u02c6 ) dentre aqueles dispon\u00edveis em F \u2013 na figura, o melhor modelo dispon\u00edvel \u00e9 \n\nnf . O erro de aproxima\u00e7\u00e3o \u00e9 uma conseq\u00fc\u00eancia do espa\u00e7o de hip\u00f3teses ser menor do \n\nque o espa\u00e7o alvo \u2013 assim, se a fun\u00e7\u00e3o alvo 0f  estiver fora do espa\u00e7o de hip\u00f3tese, o \n\nmelhor modelo que pode ser constru\u00eddo ser\u00e1 necessariamente sub-\u00f3timo.  \n\n\n\n 47 \n\nA classe de fun\u00e7\u00f5es F pode ser demasiadamente grande, raz\u00e3o pela qual o apren-\n\ndizado normalmente considera espa\u00e7os de hip\u00f3teses menores H. O SRM prop\u00f5e que \n\nseja empregada uma seq\u00fc\u00eancia aninhada de espa\u00e7os de hip\u00f3teses \n\nMHHHH ???? ...321 , onde cada espa\u00e7o tenha uma capacidade finita mh  maior do \n\nque todos os conjuntos nele contido; ou seja, Mhhhh&lt;<<&lt;...321 . Por exemplo, mH  \n\npoderia ser o conjunto de polin\u00f4mios de grau m . \n\n \n \n\n \n\n \n\n\n\n4 M\u00e1quinas de Vetores de Suporte (Support Vector Machines) \n\n4.1 Introdu\u00e7\u00e3o \n\nO SVM (Support Vector Machine, M\u00e1quina de Vetores de Suporte) \u00e9 um conjunto \n\nde algoritmos supervisionados usados para classifica\u00e7\u00e3o e regress\u00e3o, constituindo uma \n\nop\u00e7\u00e3o atraente para modelagem emp\u00edrica de dados. O m\u00e9todo explora a id\u00e9ia de regula-\n\nriza\u00e7\u00e3o, mencionada no Cap\u00edtulo 3. Com isso, limita-se a complexidade da fun\u00e7\u00e3o gera-\n\nda no aprendizado enquanto que o erro de generaliza\u00e7\u00e3o \u00e9 mantido sobre controle. Outra \n\nno\u00e7\u00e3o importante empregada pelo SVM \u00e9 o chamado princ\u00edpio da margem que n\u00e3o so-\n\nmente permite evitar o superajuste como contorna a maldi\u00e7\u00e3o da dimensionalidade (se-\n\n\u00e7\u00e3o 3.2). Com efeito, o SVM n\u00e3o depende explicitamente da dimensionalidade do espa-\n\n\u00e7o de entrada, mas somente do produto interno de vetores, que \u00e9 um valor real. Isso \n\npermite a constru\u00e7\u00e3o de hiperplanos de classifica\u00e7\u00e3o em espa\u00e7os de alta dimensionali-\n\ndade, at\u00e9 mesmo em espa\u00e7os de Hilbert com dimensionalidade infinita (Vapnik, 1998).  \n\nUma das aplica\u00e7\u00f5es mais comuns da teoria do aprendizado \u00e9 a classifica\u00e7\u00e3o que, \n\nassim como a estima\u00e7\u00e3o, \u00e9 uma forma de aprendizado emp\u00edrico (indu\u00e7\u00e3o estat\u00edstica). A \n\nid\u00e9ia \u00e9 construir um estimador que, a partir de um conjunto de treinamento, seja capaz \n\nde classificar amostras desconhecidas com um erro m\u00ednimo (capacidade de generaliza-\n\n\u00e7\u00e3o). A Equa\u00e7\u00e3o 23 mostra um conjunto de treinamento para um problema de classifi-\n\nca\u00e7\u00e3o bin\u00e1ria, onde L  \u00e9 o total de amostras e cada classe \u00e9 identificada por um r\u00f3tulo \n\nnum\u00e9rico matematicamente conveniente (+1 ou -1). \n\n( ) ( ) ( ){ } { }1,,,...,,,, 2211 \u00b1=??\u00d7?= YXYXyxyxyxS NLL  \n\nEqua\u00e7\u00e3o 23 \u2013 Conjunto de Treinamento \n\nN\u00e3o existe nenhuma premissa a respeito de X, exceto que se trata de um conjunto \n\nde dados onde certos vetores multidimensionais x s\u00e3o associados \u00e0 y. A forma como \n\n\n\n 49 \n\nesses vetores de X s\u00e3o determinados a partir de uma situa\u00e7\u00e3o no mundo real (extra\u00e7\u00e3o \n\nde caracter\u00edsticas) \u00e9 completamente abstra\u00edda.  \n\nPara que a classifica\u00e7\u00e3o seja poss\u00edvel, algum tipo de similaridade deve ser defini-\n\ndo tanto em X como em Y, de tal sorte que similaridades na entrada impliquem em simi-\n\nlaridades na sa\u00edda. Para aplica\u00e7\u00f5es de classifica\u00e7\u00e3o, a similaridade na sa\u00edda \u00e9 obtida \n\ndiretamente porque os valores envolvidos s\u00e3o discretos e facilmente compar\u00e1veis: as \n\nsa\u00eddas podem ser iguais ou diferentes. Em contra partida, a forma de similaridade na \n\nentrada \u00e9 conceitualmente mais complexa de definir, constituindo um dos principais \n\nobjetivos do aprendizado (Schlkopf et al., 2001).  \n\nA Equa\u00e7\u00e3o 24 mostra uma fun\u00e7\u00e3o de similaridade k, que associa um n\u00famero real \u2013 \n\no grau de similaridade \u2013 a dois vetores de X. Na literatura de aprendizado estat\u00edstico, \n\nesta fun\u00e7\u00e3o \u00e9 chamada de kernel (n\u00facleo) (Schlkopf et al., 2001). \n\n( ) ( )',',|: xxkxxXXk ???\u00d7  \n\nEqua\u00e7\u00e3o 24 \u2013 M\u00e9trica de Similaridade em X  \n\nUma forma bem conhecida de similaridade \u00e9 o produto interno, que pode ser de-\n\nfinido de diversas formas (Steinbruch, 1987 et al.; Schlkopf et al., 2001). O produto \n\ninterno can\u00f4nico \u00e9 uma dessas formas, mostrada na Equa\u00e7\u00e3o 25. Esta m\u00e9trica, que s\u00f3 \u00e9 \n\nprecisa quando os vetores comparados s\u00e3o normalizados, \u00e9 numericamente igual ao co-\n\nseno do \u00e2ngulo observado entre esses vetores. Considerando que os vetores s\u00e3o norma-\n\nlizados, a Figura 16 mostra que o produto interno can\u00f4nico (dado pelo co-seno de ? ) \u00e9 \n\numa medida indireta da dist\u00e2ncia euclidiana entre eles, dada por 21 xx ?  (destacada na \n\nFigura 16 como retas tracejadas).  \n\n?\n=\n\n?=\nN\n\ni\nii xxxx\n\n1\n2121 ,  \n\nEqua\u00e7\u00e3o 25 \u2013 Produto Interno Can\u00f4nico \n\nDe fato, se x1 e x2 s\u00e3o similares em um determinado espa\u00e7o de caracter\u00edsticas, es-\n\npera-se que eles estejam topologicamente pr\u00f3ximos. Isso diminui o \u00e2ngulo ?  e torna o \n\n\n\n 50 \n\nco-seno deste \u00e2ngulo mais pr\u00f3ximo de 1 (similaridade m\u00e1xima). Caso contr\u00e1rio, maior \u00e9 \n\na dist\u00e2ncia entre os vetores, o \u00e2ngulo observado \u00e9 maior e o co-seno deste \u00e2ngulo apro-\n\nxima-se de 0 (similaridade m\u00ednima). Tamb\u00e9m \u00e9 poss\u00edvel que a dist\u00e2ncia observada seja \n\ntal que o \u00e2ngulo formado \u00e9 obtuso, hip\u00f3tese na qual o co-seno se aproximaria de -1 (dis-\n\nsimilaridade m\u00e1xima).  \n\n \n\nFigura 16 \u2013 O Produto Interno Can\u00f4nico como M\u00e9trica de Similaridade \n\n\u00c9 importante notar que esta aplica\u00e7\u00e3o do produto interno \u00e9 an\u00e1loga \u00e0 correla\u00e7\u00e3o \n\nestat\u00edstica, que tamb\u00e9m mede a semelhan\u00e7a entre vetores (Steinbruch, 1987 et al.; Oppe-\n\nnheim et al., 1999; Montgomery et al., 2001). \n\nO produto interno, em sua conota\u00e7\u00e3o mais ampla, n\u00e3o \u00e9 definido para todo espa\u00e7o \n\ngeom\u00e9trico (Schlkopf et al., 2001). Portanto, sua utiliza\u00e7\u00e3o \u00e9 limitada a determinadas \n\nclasses de espa\u00e7os, denominados espa\u00e7os euclidianos (Steinbruch, 1987 et al.) ou espa-\n\n\u00e7os de Hilbert (Vapnik, 1999; Schlkopf et al., 2001). Dado que a natureza do espa\u00e7o de \n\nentrada pode ser muito diversificada, talvez seja necess\u00e1rio convert\u00ea-lo mediante um \n\nmapeamento apropriado (extra\u00e7\u00e3o de caracter\u00edsticas), tal como mostrado na Equa\u00e7\u00e3o \n\n26.  \n\n( )xxx\nHX c\n?=\n\n??\n?\n\n?\n\n:\n \n\nEqua\u00e7\u00e3o 26 \u2013 Mapeando o Espa\u00e7o de Entrada X para o Espa\u00e7o de Caracter\u00edsticas cH  \n\n\n\n 51 \n\nAlgumas t\u00e9cnicas de classifica\u00e7\u00e3o ou regress\u00e3o comumente utilizadas, como redes \n\nRBF (Radial Basis Function Network) ou MLP (Multilayer Perceptron), utilizam o ma-\n\npeamento implicitamente, ao modificar o espa\u00e7o de entrada original atrav\u00e9s de fun\u00e7\u00f5es \n\nde base radial ou de camadas ocultas. A id\u00e9ia do mapeamento ?  \u00e9 representar os pa-\n\ndr\u00f5es de entradas como vetores num espa\u00e7o de caracter\u00edsticas cH . Com isso, uma m\u00e9-\n\ntrica de similaridade tal como o produto interno can\u00f4nico pode ser aplicado, o que n\u00e3o \u00e9 \n\nnecessariamente poss\u00edvel no espa\u00e7o original. Na Equa\u00e7\u00e3o 26, essa id\u00e9ia \u00e9 refor\u00e7ada pela \n\nnota\u00e7\u00e3o empregada: enquanto os padr\u00f5es de entrada s\u00e3o representados como x, os veto-\n\nres de caracter\u00edsticas correspondentes em H s\u00e3o denotados por x\n?\n\n.  \n\nA Equa\u00e7\u00e3o 27 salienta que o uso do mapeamento permite calcular a similaridade \n\nde dois padr\u00f5es de entrada (x1 e x2) mesmo num espa\u00e7o onde o produto interno n\u00e3o est\u00e1 \n\ndefinido.  \n\n( ) ( ) ( )212121 ,,, xxxxxxk ??==\n??\n\n \n\nEqua\u00e7\u00e3o 27 \u2013 Similaridade no Espa\u00e7o de Caracter\u00edsticas \n\nEm muitas situa\u00e7\u00f5es, o mapeamento \u00e9 imprescind\u00edvel ao SVM, como nos casos \n\nem que os padr\u00f5es n\u00e3o s\u00e3o linearmente separ\u00e1veis. Tipicamente, o mapeamento \u00e9 um \n\noperador n\u00e3o-linear que representa o espa\u00e7o original em uma dimens\u00e3o muito mais alta. \n\nQuando a dimensionalidade for suficientemente alta, as amostras transformadas poder\u00e3o \n\nser discriminadas por um hiperplano (Duda et al., 2000); ou seja, por um discriminante \n\nlinear. Por esta raz\u00e3o, Hc \u00e9 algumas vezes denominado de espa\u00e7o de lineariza\u00e7\u00e3o (Schl-\n\nkopf et al., 2001). \n\nA Figura 17 mostra uma situa\u00e7\u00e3o hipot\u00e9tica, onde um aumento de dimensionali-\n\ndade torna a fun\u00e7\u00e3o de decis\u00e3o mais simples. No gr\u00e1fico da Figura 17a, os padr\u00f5es n\u00e3o \n\npodem ser discriminados por uma fun\u00e7\u00e3o linear, ao contr\u00e1rio do que acontece com o \n\nespa\u00e7o transformado de maior dimensionalidade mostrado no gr\u00e1fico da Figura 17b. \n\n\n\n 52 \n\n \n\nFigura 17 \u2013 Mapeamento do espa\u00e7o 2??X  para o espa\u00e7o 3??Z  \n\nNeste ponto, um paradoxo parece se estabelecer: por um lado, o mapeamento para \n\num espa\u00e7o de dimensionalidade maior possibilita a discrimina\u00e7\u00e3o linear entre os pa-\n\ndr\u00f5es. Mas, em contrapartida, o princ\u00edpio da maldi\u00e7\u00e3o da dimensionalidade parece res-\n\ntringir a aplicabilidade deste tipo de mapeamento. De acordo com a maldi\u00e7\u00e3o da dimen-\n\nsionalidade, a quantidade de padr\u00f5es necess\u00e1ria para amostrar adequadamente o espa\u00e7o \n\nde entrada \u00e9, em tese, uma fun\u00e7\u00e3o exponencial da dimensionalidade (Haykin, 1998; \n\nDuda et al., 2000). Em contrapartida, o mapeamento pode tornar o aprendizado muito \n\nmais simples, restringindo a capacidade (complexidade) do discriminante. Isso pode ser \n\npercebido pela Figura 17, onde a fun\u00e7\u00e3o de decis\u00e3o a  \u00e9 consideravelmente mais com-\n\nplexa que em b , muito embora o primeiro espa\u00e7o esteja no 2?  e o segundo, no 3? . \u00c9 \n\nneste ponto que o SVM se distingue fundamentalmente de outras t\u00e9cnicas de classifica-\n\n\u00e7\u00e3o, como os discriminantes de Fischer: o aprendizado est\u00e1 muito mais fortemente liga-\n\ndo ao pr\u00e9-processamento (o mapeamento) do que propriamente ao algoritmo de classifi-\n\nca\u00e7\u00e3o (Duda et al., 2000). \n\nIndependentemente de o mapeamento ser necess\u00e1rio, ele pode ser \u00fatil para repre-\n\nsentar convenientemente os padr\u00f5es de entrada. Como os padr\u00f5es de entrada s\u00e3o repre-\n\nsentados como vetores no espa\u00e7o de caracter\u00edsticas, muitos conceitos \u00fateis de \u00e1lgebra \n\nlinear e geometria anal\u00edtica podem ser aplicados \u00e0 teoria do aprendizado. Mesmo nos \n\n\n\n 53 \n\ncasos onde existe um produto interno definido no espa\u00e7o de entrada, o mapeamento \n\npode ser \u00fatil se permitir o emprego de outras formas de similaridade mais adequadas ou \n\nmesmo o uso de outros algoritmos de aprendizado (Schlkopf et al., 2001).  \n\n4.2 Contextualiza\u00e7\u00e3o \n\nSem preju\u00edzo da generaliza\u00e7\u00e3o, considere-se um problema de classifica\u00e7\u00e3o bin\u00e1-\n\nria, onde o objetivo \u00e9 construir um discriminante que distinga duas classes de amostras \n\n(identificadas pelos r\u00f3tulos num\u00e9ricos 1+  e 1? ) num determinado espa\u00e7o de caracter\u00eds-\n\nticas. A Figura 18 mostra o cen\u00e1rio descrito, representando as duas classes como objetos \n\ndiferentes num espa\u00e7o de caracter\u00edsticas 2? . A fun\u00e7\u00e3o de decis\u00e3o (ou discriminante) \n\npode ter diversas formas, como as linhas mostradas nesta figura.  \n\n \n\nFigura 18 \u2013 Classifica\u00e7\u00e3o Bin\u00e1ria \n\nO desempenho dos discriminantes da Figura 18 \u00e9 satisfat\u00f3rio para todos os casos \n\nmostrados. N\u00e3o obstante, n\u00e3o \u00e9 poss\u00edvel determinar a priori qual desses discriminantes \n\ndeve funcionar melhor com amostras desconhecidas, a menos que uma m\u00e9trica espec\u00edfi-\n\n\n\n 54 \n\nca seja concebida para isso. O conceito de vetor de suporte se aplica em situa\u00e7\u00f5es como \n\nessa, determinando crit\u00e9rios para a escolha de um discriminante \u00f3timo cujo desempenho \n\nseja probabilisticamente assegurado tamb\u00e9m com amostras desconhecidas. O SVM es-\n\ntabelece uma no\u00e7\u00e3o intuitiva: o melhor discriminante \u00e9 aquele que maximiza a dist\u00e2ncia \n\nentre ele e os pontos mais pr\u00f3ximos de cada classe. Esse classificador \u00e9 \u00fanico, sendo \n\ndenominado de hiperplano separador \u00f3timo (Vapnik, 1998; Schlkopf et al., 2001). \n\nExistem abordagens param\u00e9tricas que apresentam solu\u00e7\u00f5es correlatas, tais como a \n\nan\u00e1lise de discriminantes (Duda et al., 2000; Rencher, 2002; Hastie et al., 2003). Entre-\n\ntanto, a abordagem param\u00e9trica \u00e9 limitada em algumas aplica\u00e7\u00f5es do mundo real devido \n\na tr\u00eas fatores: maldi\u00e7\u00e3o da dimensionalidade, incompatibilidade da fun\u00e7\u00e3o de distribui-\n\n\u00e7\u00e3o real com as fun\u00e7\u00f5es de distribui\u00e7\u00e3o estat\u00edsticas cl\u00e1ssicas e restri\u00e7\u00f5es \u00e0 aplica\u00e7\u00e3o do \n\nm\u00e9todo da m\u00e1xima verossimilhan\u00e7a para estima\u00e7\u00e3o de densidade (Vapnik, 1998). Essas \n\nlimita\u00e7\u00f5es s\u00f3 podem ser contornadas quando a cardinalidade (n\u00famero de elementos) do \n\nconjunto de amostras \u00e9 muito grande em compara\u00e7\u00e3o com a sua dimensionalidade. Isso \n\npode ser percebido mediante a inspe\u00e7\u00e3o da Figura 19, que mostra duas classes bivaria-\n\ndas normais delimitadas por elipses. Se estas duas classes forem multivariadas normais \n\ne possu\u00edrem matrizes de covari\u00e2ncias semelhantes, \u00e9 poss\u00edvel demonstrar que a separa-\n\n\u00e7\u00e3o proporcionada por qualquer discriminante pode ser expressa em uma nova dimen-\n\ns\u00e3o (Rencher, 2002), tal como mostrado nessa figura.  \n\n \n\nFigura 19 \u2013 An\u00e1lise de Discriminante para Amostras de Duas Categorias \n\nNotar que o espa\u00e7o de caracter\u00edsticas da Figura 19 \u00e9 bidimensional, sendo consti-\n\ntu\u00eddo por y1 e y2. A dimens\u00e3o z \u00e9 uma representa\u00e7\u00e3o geom\u00e9trica alternativa \u00e0 fun\u00e7\u00e3o \n\n\n\n 55 \n\ndiscriminante. A linha que une os pontos de intersec\u00e7\u00e3o das duas elipses pode ser proje-\n\ntada sobre a reta z, identificando assim o ponto de m\u00e1xima separa\u00e7\u00e3o entre as classes e o \n\nmelhor discriminante (ponto de sobreposi\u00e7\u00e3o m\u00ednima) (Rencher, 2002). Com efeito, as \n\nduas gaussianas tra\u00e7adas sobre z est\u00e3o bem espa\u00e7adas, mais do que seria poss\u00edvel com \n\nqualquer outro discriminante.  \n\nN\u00e3o obstante a eleg\u00e2ncia e a simplicidade da solu\u00e7\u00e3o param\u00e9trica mostrada na \n\nFigura 19, \u00e9 preciso destacar a forte influ\u00eancia que a amostragem exerce nesta aborda-\n\ngem.  Em termos pr\u00e1ticos, a forma como a amostragem \u00e9 feita pode deslocar os centr\u00f3i-\n\ndes de cada elipse ou modificar o contorno de cada uma delas, o que fatalmente condu-\n\nziria a conclus\u00f5es deturpadas, prejudicando o c\u00e1lculo do melhor discriminante. Al\u00e9m \n\ndisso, existe uma premissa n\u00e3o declarada quando da utiliza\u00e7\u00e3o desses m\u00e9todos: a invari-\n\n\u00e2ncia no tempo, que determina a const\u00e2ncia dos par\u00e2metros do modelo (m\u00e9dia e vari\u00e2n-\n\ncia, no caso da distribui\u00e7\u00e3o normal). Neste trabalho, ambos os quesitos (amostragem e \n\ninvari\u00e2ncia) n\u00e3o s\u00e3o completamente atendidos, o que justifica a escolha da minimiza\u00e7\u00e3o \n\nde risco estrutural com SVM em detrimento dos m\u00e9todos param\u00e9tricos ou mesmo dos \n\nmodelos conexionistas (minimiza\u00e7\u00e3o de risco emp\u00edrico). \n\n4.3 Algoritmo de Classifica\u00e7\u00e3o Bin\u00e1rio \n\nA Equa\u00e7\u00e3o 28 mostra os centr\u00f3ides das duas classes (rotuladas como 1+  e 1? ) \n\nenvolvidas num problema de classifica\u00e7\u00e3o bin\u00e1ria. O centr\u00f3ide de cada classe \u00e9 um ve-\n\ntor m\u00e9dio ( +c\n?\n\n e ?c\n?\n\n), computado como a m\u00e9dia aritm\u00e9tica dos vetores de cada classe. \n\nNessa equa\u00e7\u00e3o, +m  \u00e9 a quantidade de amostras com r\u00f3tulo 1+ , enquanto que ?m  \u00e9 a \n\nquantidade de amostras com r\u00f3tulo 1? . \n\n{ } { }\n??\n\n?=?\n?\n\n+=+\n+ ==\n\n1|1|\n\n11\n\nii yi\ni\n\nyi\ni xm\n\ncx\nm\n\nc\n????\n\n \n\nEqua\u00e7\u00e3o 28 \u2013 Centr\u00f3ides das Classes (classifica\u00e7\u00e3o bin\u00e1ria) \n\nA partir dos centr\u00f3ides, \u00e9 poss\u00edvel aplicar a regra do vizinho mais pr\u00f3ximo (nea-\n\nrest neighbor) (Duda et al., 2000) para identificar amostras desconhecidas (omitidas ou \n\n\n\n 56 \n\nn\u00e3o dispon\u00edveis durante o aprendizado). A Figura 20 mostra os centr\u00f3ides de alguns \n\npadr\u00f5es representados num espa\u00e7o de caracter\u00edsticas plano ( 2? ). \n\n \n\nFigura 20 \u2013 Classifica\u00e7\u00e3o Bin\u00e1ria num Espa\u00e7o de Caracter\u00edsticas \n\nAplicando no\u00e7\u00f5es de \u00e1lgebra e geometria anal\u00edtica aos conceitos desenvolvidos, \u00e9 \n\nposs\u00edvel definir um algoritmo de classifica\u00e7\u00e3o ao mesmo tempo simples e eficiente. \n\nConsidere-se o cen\u00e1rio descrito pela Figura 20, onde o objetivo \u00e9 classificar uma amos-\n\ntra desconhecida x\n?\n\n (mostrada como um asterisco vermelho) a partir das demais amos-\n\ntras. Seja c\n?\n\n o vetor m\u00e9dia dos centr\u00f3ides, w\n?\n\n o vetor diferen\u00e7a dos centr\u00f3ides e \n\ncxd\n???\n\n?=  o vetor que une c\n?\n\n \u00e0 x\n?\n\n. A classifica\u00e7\u00e3o de x\n?\n\n \u00e9 dada pela sua afinidade com \n\num dos centr\u00f3ides, que pode ser medida pelo \u00e2ngulo ?  entre w\n?\n\n e d\n?\n\n. A regra de decis\u00e3o \n\ncorrespondente \u00e0 Figura 20 \u00e9 mostrada na Tabela 1 (Schlkopf et al., 2001). \n\n\n\n 57 \n\nTabela 1 \u2013 Regras de Decis\u00e3o para a Classifica\u00e7\u00e3o Bin\u00e1ria \n\n????????????\t\n??? \n??\n\n??\n\n2\n?? &lt; ???\n\n2\n?? >  ???\n\n2\n?? =  ?????\t?\t???\n\nA Equa\u00e7\u00e3o 29 mostra essa regra de decis\u00e3o expressada com o uso da fun\u00e7\u00e3o de-\n\ngrau (sgn), cujo comportamento \u00e9 definido na Equa\u00e7\u00e3o 30 e mostrado graficamente na \n\nFigura 21. Como pode ser constatado, existe um ponto de descontinuidade no gr\u00e1fico \n\nonde a fun\u00e7\u00e3o n\u00e3o \u00e9 definida. Este ponto de descontinuidade \u00e9 chamado de limiar que, \n\nno argumento da Equa\u00e7\u00e3o 30, ser\u00e1 nulo. \n\n( )( )\n( ) ( )( )\n\n( )bcxcx\nccccx\n\nwcxy\n\n+?=\n\n???=\n\n?=\n\n?+\n\n?+?+\n????\n\n?????\n\n???\n\n,,sgn\n\n,2sgn\n\n,sgn\n\n \n\nEqua\u00e7\u00e3o 29 \u2013 Fun\u00e7\u00e3o de Decis\u00e3o Empregando o Degrau \n\n( )\n\t\n\n\n?\n\n<?\n>+\n\n=\n0,1\n0,1\n\nsgn\na\n\na\na  \n\nEqua\u00e7\u00e3o 30 \u2013 Defini\u00e7\u00e3o da Fun\u00e7\u00e3o Degrau \n\nA fun\u00e7\u00e3o degrau (tamb\u00e9m fun\u00e7\u00e3o sinal, limiar ou treshold) mapeia qualquer n\u00fa-\n\nmero real para { }1,1 ?+ , n\u00e3o definindo nenhum outro valor para o seu contradom\u00ednio. \nMediante a manipula\u00e7\u00e3o alg\u00e9brica mostrada na Equa\u00e7\u00e3o 29, essa propriedade permite \n\nimplementar a regra de decis\u00e3o da Figura 20, raz\u00e3o pela qual no aprendizado estat\u00edstico \n\no degrau \u00e9 chamado de fun\u00e7\u00e3o de decis\u00e3o. \n\n\n\n 58 \n\n \n\nFigura 21 \u2013 A Fun\u00e7\u00e3o Sinal (sgn) \n\nA Equa\u00e7\u00e3o 29 define um desvio (offset ou bias) aplicado ao argumento da fun\u00e7\u00e3o \n\ndegrau. Geometricamente, o desvio equivale a deslocar o limiar do degrau de 0  (Figura \n\n21a) para b (Figura 21b). Sua aplica\u00e7\u00e3o \u00e9 necess\u00e1ria quando os centr\u00f3ides das classes \n\nn\u00e3o s\u00e3o sim\u00e9tricos em rela\u00e7\u00e3o \u00e0 origem, exigindo uma compensa\u00e7\u00e3o na fun\u00e7\u00e3o de deci-\n\ns\u00e3o. A Equa\u00e7\u00e3o 31 mostra que b  \u00e9 calculado a partir dos centr\u00f3ides, tendendo a diminu-\n\nir quando seus m\u00f3dulos forem parecidos. Se este par\u00e2metro fosse simplesmente omiti-\n\ndo, o hiperplano \u00e9 for\u00e7ado a cruzar a origem dos eixos, restringindo a solu\u00e7\u00e3o (Schlkopf \n\net al., 2001). \n\n( )2221 +? ??= ccb\n??\n\n \n\nEqua\u00e7\u00e3o 31 \u2013 Valor de Bias \n\n4.4 Hiperplanos de classifica\u00e7\u00e3o e o Hiperplano \u00f3timo \n\n\u00c9 poss\u00edvel e conveniente fazer uso da fun\u00e7\u00e3o de decis\u00e3o justamente no limiar \n\nmostrado na Equa\u00e7\u00e3o 29 e na Equa\u00e7\u00e3o 30. O limiar representa o limite de decis\u00e3o entre \n\nas classes \u2013 de fato, a resposta do degrau no limiar \u00e9 indefinida \u2013 determinando um hi-\n\nperplano perpendicular ao vetor w\n?\n\n. Este hiperplano \u00e9 formado pelos pontos cujas res-\n\npostas ao degrau somadas ao efeito de b  s\u00e3o nulas. Em particular na Figura 20, o espa-\n\n\u00e7o de caracter\u00edsticas est\u00e1 no 2? , de tal sorte que o hiperplano formado \u00e9 uma reta (tra-\n\n\u00e7ada em verde).  \n\n\n\n 59 \n\n A Equa\u00e7\u00e3o 32 pode ser obtida a partir da Equa\u00e7\u00e3o 29 e mostra como o hiperplano \n\nde classifica\u00e7\u00e3o pode ser descrito pelo limiar de decis\u00e3o (Vapnik, 1999; Schlkopf et al., \n\n2001).  Dependendo de w\n?\n\n, essa equa\u00e7\u00e3o pode definir uma ampla fam\u00edlia de hiperplanos \n\naptos a discriminar corretamente os padr\u00f5es de entrada. Essa fam\u00edlia \u00e9 linear em seus \n\npar\u00e2metros, o que torna poss\u00edvel determinar a sua complexidade (capacidade).  \n\n0, =+ bxw\n??\n\n \n\nEqua\u00e7\u00e3o 32 \u2013 Hiperplano de Classifica\u00e7\u00e3o \n\nComo w\n?\n\n ajusta a fam\u00edlia de hiperplanos definida na Equa\u00e7\u00e3o 32, ele \u00e9 chamado \n\nde vetor de pondera\u00e7\u00e3o, de pesos ou de par\u00e2metros (Haykin, 1998; Duda et al., 2000). \n\nA propriedade mostrada na Equa\u00e7\u00e3o 33 ressalta que o limite de decis\u00e3o representado \n\npelo hiperplano de classifica\u00e7\u00e3o n\u00e3o cont\u00e9m nenhuma amostra conhecida. Como conse-\n\nq\u00fc\u00eancia, toda amostra existente \u00e9 obrigatoriamente classificada, n\u00e3o existindo ambig\u00fci-\n\ndades (Schlkopf et al., 2001).  \n\n( ) mibxwy ii ,...,2,10, =?>+?\n??\n\n \n\nEqua\u00e7\u00e3o 33 \u2013 Propriedade do Vetor de Par\u00e2metros w\n?\n\n \n\nUma ambig\u00fcidade de classifica\u00e7\u00e3o seria notada como um ponto contido no hiper-\n\nplano ou ent\u00e3o muito pr\u00f3ximo dele, fazendo com que a resposta de uma fun\u00e7\u00e3o de deci-\n\ns\u00e3o seja indefinida. No caso da fun\u00e7\u00e3o degrau (Equa\u00e7\u00e3o 30), isso equivale \u00e0 resposta do \n\ndegrau justamente no limiar ou muito pr\u00f3ximo dele. \n\nA Equa\u00e7\u00e3o 34 mostra a fun\u00e7\u00e3o de decis\u00e3o correspondente \u00e0 fam\u00edlia de hiperplanos \n\ndefinida na Equa\u00e7\u00e3o 32. \n\n( )bxwy += ??,sgn  \n\nEqua\u00e7\u00e3o 34 \u2013 Fun\u00e7\u00e3o de Decis\u00e3o \n\nA solu\u00e7\u00e3o da Equa\u00e7\u00e3o 32 \u00e9 indeterminada; ou seja, admite v\u00e1rias solu\u00e7\u00f5es. Sem \n\npreju\u00edzo da generalidade, \u00e9 imprescind\u00edvel restringi-la de alguma forma. Ent\u00e3o, por \n\nconven\u00e7\u00e3o, exige-se que o hiperplano de classifica\u00e7\u00e3o seja cartesiano. Isso significa re-\n\n\n\n 60 \n\nescalonar o vetor w\n?\n\n e a constante b de tal forma que a Equa\u00e7\u00e3o 33 se restringe \u00e0 forma \n\nda Equa\u00e7\u00e3o 35.  \n\n( ) mibxwy ii ,...,2,11, =??+?\n??\n\n \n\nEqua\u00e7\u00e3o 35 \u2013 Forma Can\u00f4nica do Hiperplano de Classifica\u00e7\u00e3o \n\nIndependentemente da forma can\u00f4nica, a constante b  deve satisfazer as duas de-\n\nsigualdades mostradas na Equa\u00e7\u00e3o 36 (Vapnik, 1998) para que a fun\u00e7\u00e3o de decis\u00e3o da \n\nEqua\u00e7\u00e3o 34 efetue a classifica\u00e7\u00e3o de forma consistente. Como pode ser notado, a res-\n\nposta n\u00e3o \u00e9 definida no limiar b . \n\n1,)(\n\n1,)(\n\n?=??<\n\n+=??>\n\nybxwb\n\nybxwa\n??\n\n??\n\n \n\nEqua\u00e7\u00e3o 36 \u2013 Desigualdades de Decis\u00e3o \n\nA literatura (Vapnik, 1999; Duda et al., 2000; Schlkopf et al., 2001) prop\u00f5e diver-\n\nsos algoritmos para problemas de classifica\u00e7\u00e3o onde os padr\u00f5es de entrada podem ser \n\nseparados por hiperplanos; ou seja, situa\u00e7\u00f5es onde os padr\u00f5es de entrada s\u00e3o linearmen-\n\nte separ\u00e1veis (Haykin, 1998; Duda et al., 2000). Entre esses algoritmos, existe um de-\n\nnominado panorama generalizado (generalized portrait), baseado em duas no\u00e7\u00f5es fun-\n\ndamentais (Schlkopf et al., 2001). \n\nA primeira no\u00e7\u00e3o \u00e9 a de hiperplano \u00f3timo, caracterizado pela m\u00e1xima margem de \n\nsepara\u00e7\u00e3o poss\u00edvel entre as diferentes classes. A Equa\u00e7\u00e3o 37 mostra como o hiperplano \n\n\u00f3timo pode ser interpretado analiticamente: a menor dist\u00e2ncia ( ( )ixx\n??\n\n?min ) entre uma \n\namostra de cada classe ( ix ) e o hiperplano ( 0,| =+ bxwx\n???\n\n) deve ser a maior poss\u00edvel \n\n( ( ){ }ixx\n??\n\n?minmax ). Se a forma can\u00f4nica expressa pela Equa\u00e7\u00e3o 35 n\u00e3o for observada, \n\na Equa\u00e7\u00e3o 37 torna-se indeterminada; ou seja, n\u00e3o admite solu\u00e7\u00e3o \u00fanica (Vapnik, 1998). \n\n( ){ } mibxwHxxx ci ,...,2,1,0,,minmax ==+??\n?????\n\n \n\nEqua\u00e7\u00e3o 37 \u2013 Condi\u00e7\u00f5es para a Obten\u00e7\u00e3o do Hiperplano \u00d3timo \n\n\n\n 61 \n\nA segunda no\u00e7\u00e3o \u00e9 que a capacidade de separa\u00e7\u00e3o dos hiperplanos diminui \u00e0 me-\n\ndida que a largura da margem cresce, o que explica a boa generaliza\u00e7\u00e3o do hiperplano \n\n\u00f3timo (Schlkopf et al., 2001). A largura da margem \u00e9 um conceito an\u00e1logo ao intervalo \n\nde confian\u00e7a da estat\u00edstica descritiva, mensurando qualitativamente a precis\u00e3o do classi-\n\nficador gerado: em geral, quanto maior a margem, maior a esperan\u00e7a que a resposta \n\nfornecida pelo classificador est\u00e1 correta (princ\u00edpio da margem) (Herbrich, 2001).  \n\n4.5 C\u00e1lculo do hiperplano \u00f3timo \n\nA resolu\u00e7\u00e3o da Equa\u00e7\u00e3o 37 requer algumas considera\u00e7\u00f5es sobre a forma como a \n\nregra de decis\u00e3o \u00e9 implementada. A regra mostrada Equa\u00e7\u00e3o 29 \u00e9 similar \u00e0 da Equa\u00e7\u00e3o \n\n34, mas a forma como os hiperplanos s\u00e3o obtidos \u00e9 diferente. No primeiro caso, a \n\nFigura 20 mostra que o vetor normal ao hiperplano ( w\n?\n\n) \u00e9 calculado mediante um pro-\n\ncedimento simples: a diferen\u00e7a entre os centr\u00f3ides ( ?+ ?= ccw\n???\n\n).  \n\nNo segundo caso, a estrat\u00e9gia empregada \u00e9 mais elaborada e w\n?\n\n \u00e9 obtido resolven-\n\ndo a Equa\u00e7\u00e3o 38 para o m\u00e1ximo valor da margem ?  (ou seja, ( )?max ), mostrada na \nEqua\u00e7\u00e3o 39 (Vapnik, 1998). \u00c9 poss\u00edvel demonstrar que a margem ( )w??  \u00e9 m\u00e1xima den-\ntro da regi\u00e3o 1?w\n\n?\n, sendo atingida no limite 1=w\n\n?\n. Este ponto m\u00e1ximo \u00e9 uma decor-\n\nr\u00eancia da continuidade de ?  na \u00e1rea delimitada por 1?w\n?\n\n (Vapnik, 1998). \n\n( )\n( ) 1,max\n\n1,min\n\n1\n\n1\n\n+==\n\n?==\n\n+\n\n?\n\nii\n\nii\n\nyxwwc\n\nyxwwc\n???\n\n???\n\n \n\nEqua\u00e7\u00e3o 38 \u2013 Par\u00e2metros para Determinar o Hiperplano \u00d3timo \n\n( ) ( ) ( ) 1\n2\n\n11 =\n?\n\n= ++ w\nwcwc\n\nw\n?\n\n??\n?\n\n?  \n\nEqua\u00e7\u00e3o 39 \u2013 Margem de Separa\u00e7\u00e3o entre as Classes \n\n\n\n 62 \n\nConsidere-se um vetor 0w\n?\n\n tal que ( )0w\n?\n\n?  \u00e9 o maior valor poss\u00edvel para ?  que sa-\n\ntisfaz as desigualdades da Equa\u00e7\u00e3o 36 e o ponto m\u00e9dio 0c , definido na Equa\u00e7\u00e3o 40. \n\nEnt\u00e3o, 0w\n?\n\n e 0c  determinam um hiperplano de classifica\u00e7\u00e3o que assegura a m\u00e1xima se-\n\npara\u00e7\u00e3o entre as classes: o hiperplano \u00f3timo, mostrado na Equa\u00e7\u00e3o 41 (Vapnik, 1998). \n\n( ) ( )\n2\n\n0101\n0\n\nwcwc\nc\n\n??\n+? +=  \n\nEqua\u00e7\u00e3o 40 \u2013 Ponto M\u00e9dio da Margem de Separa\u00e7\u00e3o \n\n0, 00 =+ cxw\n??\n\n \n\nEqua\u00e7\u00e3o 41 \u2013 Equa\u00e7\u00e3o do Hiperplano \u00d3timo \n\nA forma \u00f3tima do hiperplano mostrada na Equa\u00e7\u00e3o 41 \u00e9 can\u00f4nica, possuindo por-\n\ntanto as propriedades da Equa\u00e7\u00e3o 42, que s\u00e3o uma decorr\u00eancia da defini\u00e7\u00e3o mostrada na \n\nEqua\u00e7\u00e3o 35 (Schlkopf et al., 2001).  \n\n11,\n\n11,\n\n00\n\n00\n\n?=??+\n\n+=+?+\n\nii\n\nii\n\nycxw\n\nycxw\n??\n\n??\n\n \n\nEqua\u00e7\u00e3o 42 \u2013 Restri\u00e7\u00f5es de Desigualdade da Forma Can\u00f4nica \n\nConsidere-se a fun\u00e7\u00e3o mostrada na Equa\u00e7\u00e3o 43, denominada de fun\u00e7\u00e3o objetivo. \n\nDentro das restri\u00e7\u00f5es impostas pela forma can\u00f4nica definida na Equa\u00e7\u00e3o 35, \u00e9 poss\u00edvel \n\ndemonstrar o valor de w\n?\n\n que satisfaz a Equa\u00e7\u00e3o 43 est\u00e1 relacionado \u00e0 0w\n?\n\n pela rela\u00e7\u00e3o \n\nmostrada na Equa\u00e7\u00e3o 44 (Vapnik, 1998).  \n\n( ) wwww ???? ,\n2\n1\n\n2\n1\n\nmin\n2\n\n?=?=?  \n\nEqua\u00e7\u00e3o 43 \u2013 Fun\u00e7\u00e3o Objetivo para Determinar o Hiperplano \u00d3timo \n\n \n\n\n\n 63 \n\nw\nw\n\nw ?\n?\n\n?\n=0  \n\nEqua\u00e7\u00e3o 44 \u2013 Rela\u00e7\u00e3o entre 0w\n?\n\ne ( ) 1,},min{| 22 ?+?= bxwywww ii\n?????\n\n \n\nJuntas, as restri\u00e7\u00f5es da Equa\u00e7\u00e3o 42 e a fun\u00e7\u00e3o objetivo da Equa\u00e7\u00e3o 43 formam o \n\nchamado problema de otimiza\u00e7\u00e3o restrita (constrained optimization problem) (Schlkopf \n\net al., 2001). Determinar o hiperplano \u00f3timo consiste em solucionar este problema; ou \n\nseja, atingir a fun\u00e7\u00e3o objetivo observando as restri\u00e7\u00f5es de desigualdade. Matematica-\n\nmente, devido \u00e0 forma quadr\u00e1tica da Equa\u00e7\u00e3o 43, o problema da otimiza\u00e7\u00e3o restrita \u00e9 \n\nconsiderado uma quest\u00e3o de otimiza\u00e7\u00e3o quadr\u00e1tica (Vapnik, 1998). Uma das formas de \n\ntratar a otimiza\u00e7\u00e3o quadr\u00e1tica \u00e9 mapeando w\n?\n\n e b  para um espa\u00e7o dual \u2013 mais especifi-\n\ncamente, o espa\u00e7o dos multiplicadores de Lagrange (Vapnik, 1998; Vapnik, 1999; Schl-\n\nkopf et al., 2001; Hastie et al., 2003).  \n\nO Lagrangiano \u00e9 uma solu\u00e7\u00e3o matem\u00e1tica padr\u00e3o para problemas de otimiza\u00e7\u00e3o \n\ntal como o descrito. A Equa\u00e7\u00e3o 45 mostra o Lagrangiano que deve ser minimizado com \n\nrespeito \u00e0s vari\u00e1veis fundamentais w\n?\n\n e b  ao mesmo tempo em que deve ser maximiza-\n\ndo para as vari\u00e1veis duais n\u00e3o negativas i? , o que equivale a procurar por um ponto de \n\ncela na superf\u00edcie definida por esta fun\u00e7\u00e3o (Vapnik, 1998; Schlkopf et al., 2001). A \n\nforma como o Lagrangiano pode ser resolvido requer a aplica\u00e7\u00e3o de princ\u00edpios de c\u00e1lcu-\n\nlo para analisar os pontos extremos de sua superf\u00edcie, o que foge ao escopo deste traba-\n\nlho. Contudo, informa\u00e7\u00f5es detalhadas sobre a resolu\u00e7\u00e3o do Lagrangiano podem ser ob-\n\ntidas em (Vapnik, 1998; Vapnik, 1999; Cristiani, 2001; Schlkopf et al., 2001, Hastie et \n\nal., 2003). \n\n( ) ( )( )?\n=\n\n?+??=\nm\n\ni\niii bwxywbwL\n\n1\n\n2\n1,\n\n2\n1\n\n,,\n????\n\n??  \n\nEqua\u00e7\u00e3o 45 \u2013 Lagrangiano \n\nO Lagrangiano da Equa\u00e7\u00e3o 45 pode ser aplicado \u00e0 fun\u00e7\u00e3o de decis\u00e3o mostrada na \n\nEqua\u00e7\u00e3o 34, produzindo a fun\u00e7\u00e3o de decis\u00e3o visualizada na Equa\u00e7\u00e3o 46, onde x\n?\n\n \u00e9 a \n\namostra a ser classificada e ix\n?\n\n \u00e9 a i-\u00e9sima amostra do conjunto de treinamento.  \n\n\n\n 64 \n\n \n\n?\n?\n\n?\n?\n?\n\n?\n+?= ?\n\n=\n\nm\n\ni\niii bxxyy\n\n1\n\n,sgn\n??\n\n?  \n\nEqua\u00e7\u00e3o 46 \u2013 Fun\u00e7\u00e3o de Decis\u00e3o Empregando os Multiplicadores de Lagrange \n\nA Equa\u00e7\u00e3o 44 mostra que o vetor 0w\n?\n\n \u00e9 normalizado; isto \u00e9, possui norma unit\u00e1ria. \n\nA normaliza\u00e7\u00e3o \u00e9 imprescind\u00edvel porque a norma dos vetores obtidos durante o proces-\n\nso de aprendizado pode variar, o que tornaria inconsistente a compara\u00e7\u00e3o entre as diver-\n\nsas solu\u00e7\u00f5es poss\u00edveis (Herbrich, 2001).  \n\nA Equa\u00e7\u00e3o 47 mostra a largura da margem obtida com o hiperplano \u00f3timo (Vap-\n\nnik, 1998).  \n\n( )\nw\nw\n\nw\nw\n\nwxwxw i\ny\n\ni\nyw ii\n\n?\n\n?\n?\n\n?\n?????\n\n?\n\n==??\n?\n\n?\n?\n?\n?\n\n?\n??=\n\n?=+=\n00\n\n1\n0\n\n1\n0\n\n1\n,,2\n\n1 maxminsup\n0\n\n?  \n\nEqua\u00e7\u00e3o 47 \u2013 Margem Obtida com o Hiperplano \u00d3timo \n\nA Figura 22 mostra o conceito de hiperplano \u00f3timo graficamente. As amostras \n\nmais pr\u00f3ximas do hiperplano (circuladas em vermelho) determinam a largura da mar-\n\ngem, sendo chamadas de vetores de suporte (Vapnik, 1998; Duda et al., 2000; Schlkopf \n\net al., 2001). \u00c9 de grande interesse notar que o hiperplano de separa\u00e7\u00e3o, \u00f3timo ou n\u00e3o, \n\npode ser determinado t\u00e3o somente pelos vetores de suporte, sendo independente das \n\ndemais amostras (Schlkopf et al., 2001).  \n\nSe o problema \u00e9 linearmente separ\u00e1vel, existe um vetor de pesos w\n?\n\n e um limiar b  \n\ntal que ( ) 0, >+? bxwy ii\n??\n\n, onde ix  \u00e9 a i-\u00e9sima amostra do conjunto de treinamento. \n\nRedimensionando w\n?\n\n e b  de tal forma que 1, =+ bxw\n??\n\n \u00e9 satisfeita para os pontos de \n\ncada classe que est\u00e3o mais pr\u00f3ximos do hiperplano ( 1x  e 2x , real\u00e7ados com c\u00edrculos \n\ntracejados), diz-se que o hiperplano est\u00e1 na forma can\u00f4nica (Equa\u00e7\u00e3o 35). Neste caso, a \n\ndist\u00e2ncia entre os vetores de suporte, mostrada na Equa\u00e7\u00e3o 48, \u00e9 igual \u00e0 \nw\n?2  (Schl-\n\n\n\n 65 \n\nkopf et al., 2001). Como o hiperplano \u00e9 linear, essa largura \u00e9 mantida ao longo de todo o \n\nespa\u00e7o de caracter\u00edsticas.  \n\nw\nxx\n\nw\nw\n\nxxw\nbxw\n\nbxw\n?\n\n??\n?\n\n?\n???\n\n??\n\n??\n2\n\n,2,\n1,\n\n1,\n1212\n\n2\n\n1\n=??=?\n\n\n?\n\n\n?\n?\n\n+=+\n\n?=+\n \n\nEqua\u00e7\u00e3o 48 \u2013 Dist\u00e2ncia entre os Vetores de Suporte (largura da margem) \n\nx2\n\nx 1\n\nw\n?\n\n1?=iy\n\n1+=iy\n\n{ }1,| ?=+bxwx ???\n\n{ }0,| =+ bxwx ???\n\n{ }1,| +=+bxwx ???\n\n1x 2x\n\n \n\nFigura 22 \u2013 Hiperplano \u00d3timo e Vetores de Suporte para uma Classifica\u00e7\u00e3o Bin\u00e1ria \n\n4.6 M\u00e1quinas de Vetores de Suporte \n\nOs conceitos de mapeamento e de similaridade no espa\u00e7o de caracter\u00edsticas defi-\n\nnem um algoritmo de aprendizado especialmente poderoso: as m\u00e1quinas de vetores de \n\nsuporte. A id\u00e9ia essencial deste algoritmo \u00e9 bem ilustrada pelos gr\u00e1ficos da Figura 17, \n\nonde uma fun\u00e7\u00e3o de decis\u00e3o complexa num espa\u00e7o de baixa dimensionalidade (Figura \n\n17a) \u00e9 substitu\u00edda por uma fun\u00e7\u00e3o de decis\u00e3o linear num espa\u00e7o de dimensionalidade \n\nmaior (Figura 17b). Desta forma, conforme salientado na se\u00e7\u00e3o 1, se, por um lado, a \n\ncomplexidade aumenta devido ao aumento de dimensionalidade, por outro as regras de \n\ndecis\u00e3o tendem a se tornar mais simples. \n\n\n\n 66 \n\nN\u00e3o obstante, a despeito do poder de generaliza\u00e7\u00e3o do hiperplano \u00f3timo ser com-\n\nprovado, determin\u00e1-lo \u00e9 apenas uma possibilidade te\u00f3rica (Vapnik, 1998; Vapnik, \n\n1999). Com efeito, a dimensionalidade do espa\u00e7o de caracter\u00edsticas tende a ser muito \n\nmais alta do que a do espa\u00e7o original (Duda et al., 2000) e, conseq\u00fcentemente, o pro-\n\nblema pode se tornar invi\u00e1vel computacionalmente. Por exemplo, um discriminante \n\npolinomial de grau 4 ou 5 num espa\u00e7o original 200?  exige um espa\u00e7o de caracter\u00edsticas \n\nde bilh\u00f5es de dimens\u00f5es para formar hiperplanos separadores (Vapnik, 1999). A exis-\n\nt\u00eancia de fun\u00e7\u00f5es de decis\u00e3o simples (hiperplanos) em espa\u00e7os de caracter\u00edsticas de alta \n\ndimensionalidade \u00e9 uma certeza te\u00f3rica; entretanto, determin\u00e1-los pode ser uma tarefa \n\ncomputacional intrat\u00e1vel. \n\nEntretanto, Vapnik e outros pesquisadores (Vapnik, 1998; Vapnik, 1999) determi-\n\nnaram que o mapeamento, embora realmente necess\u00e1rio para assegurar a exist\u00eancia de \n\nfun\u00e7\u00f5es de decis\u00e3o simples, n\u00e3o precisava ser considerado na forma expl\u00edcita. De fato, a \n\nEqua\u00e7\u00e3o 27 mostra que a similaridade no espa\u00e7o de caracter\u00edsticas pode ser determinada \n\nsem efetuar o mapeamento, atrav\u00e9s do kernel k . Assim, o kernel torna poss\u00edvel deter-\n\nminar o hiperplano sem que seja necess\u00e1rio efetuar o mapeamento explicitamente. Ma-\n\ntematicamente, isso \u00e9 assegurado pelo Teorema de Mercer ou condi\u00e7\u00f5es de Mercer \n\n(Vapnik, 1998; Vapnik, 1999; Cristiani, 2001; 80).  \n\nA exist\u00eancia da expans\u00e3o do kernel k  mostrada na Equa\u00e7\u00e3o 49, assegura a exis-\n\nt\u00eancia de um espa\u00e7o de caracter\u00edsticas cH  tal que k  \u00e9 o seu produto interno. Para que \n\nesta expans\u00e3o seja poss\u00edvel, o teorema de Mercer associa toda fun\u00e7\u00e3o 2Lg ?  ao kernel \n\nk  por meio de uma integral dupla, mostrada na Equa\u00e7\u00e3o 50. Se a integra\u00e7\u00e3o for positi-\n\nva, a expans\u00e3o \u00e9 poss\u00edvel e k  descreve um produto interno.  \n\n( ) ( ) ( ) 0,\n1\n\n2121 >??= ?\n?\n\n=\nk\n\ni\ni xxxxk ??  \n\nEqua\u00e7\u00e3o 49 \u2013 Expans\u00e3o do Kernel k  \n\n( ) ( ) ( ) ( )??? ?<axx dagddxgxgxxk 212121,  \n\nEqua\u00e7\u00e3o 50 \u2013 Condi\u00e7\u00e3o de Mercer \n\n\n\n 67 \n\n\u00c9 justamente a convolu\u00e7\u00e3o do produto interno que permite construir fun\u00e7\u00f5es de \n\ndecis\u00e3o n\u00e3o-lineares (alta complexidade) no espa\u00e7o de entrada, as quais equivalem a \n\nfun\u00e7\u00f5es de decis\u00e3o lineares nos espa\u00e7os de caracter\u00edsticas de alta dimensionalidade cri-\n\nados por ?  ( k  \u00e9 uma convolu\u00e7\u00e3o do produto interno para este espa\u00e7o de caracter\u00edsti-\n\ncas) (Schlkopf et al., 2001). \n\nSubstituir ( ) ( ) 2121 ,, xxxx\n??\n\n=??  por ( )21, xxk , tal como a Equa\u00e7\u00e3o 24 sugere ser \nposs\u00edvel, \u00e9 um artif\u00edcio simples conhecido como truque do kernel (kernel trick) (Schl-\n\nkopf et al., 2001; Herbrich, 2001). Tal artif\u00edcio \u00e9 suficientemente poderoso para estender \n\na funcionalidade dos hiperplanos formados pelo panorama generalizado (discutido na \n\nse\u00e7\u00e3o 4.4) ao expressar a similaridade entre os vetores de cH  diretamente a partir de \n\nX . A forma da fun\u00e7\u00e3o de decis\u00e3o \u00e9 mostrada no termo \u00e0 direita da Equa\u00e7\u00e3o 51 (Schl-\n\nkopf et al., 2001). Como se observa, esta express\u00e3o faz uso dos multiplicadores lagran-\n\ngianos 0?i? , mas omite o mapeamento ? .  \n\n( ) ( ) ( ) ( ) ?\n?\n\n?\n?\n?\n\n?\n+=?\n\n?\n\n?\n?\n?\n\n?\n+??= ??\n\n==\n\nm\n\ni\niii\n\nm\n\ni\niii bxxkybxxyxf\n\n11\n\n,sgn,sgn ??  \n\nEqua\u00e7\u00e3o 51 \u2013 Decis\u00e3o Impl\u00edcita no Espa\u00e7o de Caracter\u00edsticas \n\nOs algoritmos que definem fun\u00e7\u00f5es de decis\u00e3o com a forma do termo \u00e0 direita da \n\nEqua\u00e7\u00e3o 51 s\u00e3o chamadas de m\u00e1quinas de vetores de suporte. Com efeito, o argumento \n\nda fun\u00e7\u00e3o de decis\u00e3o ( ( )? + bxxky iii ,? ) somente precisa considerar os vetores de su-\nporte, omitindo as demais amostras (Vapnik, 1999).  \n\nO termo m\u00e1quina de vetores de suporte enfatiza a id\u00e9ia b\u00e1sica de expans\u00e3o dos \n\nvetores de suporte na forma do termo \u00e0 direita da Equa\u00e7\u00e3o 51. \u00c9 por essa raz\u00e3o que no \n\nSVM a complexidade do aprendizado est\u00e1 relacionada ao n\u00famero de vetores de suporte, \n\ne n\u00e3o \u00e0 dimensionalidade do espa\u00e7o de caracter\u00edsticas (Vapnik, 1999). A Figura 23 mos-\n\ntra o diagrama esquem\u00e1tico de uma m\u00e1quina de vetores de suporte, cuja arquitetura \u00e9 \n\nsemelhante a um MLP de duas camadas. \n\n \n\n\n\n 68 \n\n \n\nFigura 23 \u2013 Arquitetura de uma M\u00e1quina de Vetores de Suporte \n\nA Figura 24 mostra um classificador obtido por meio de um kernel de base radial \n\nmostrada na Equa\u00e7\u00e3o 52 (a chamada base radial gaussiana) (Schlkopf et al., 2001). O \n\ndiscriminante \u00e9 mostrado como uma linha s\u00f3lida verde, enquanto que as linhas traceja-\n\ndas delimitam a margem, atendendo a restri\u00e7\u00e3o da forma can\u00f4nica expressa na Equa\u00e7\u00e3o \n\n35. Isso significa que os vetores de suporte (amostras circuladas em vermelho) se en-\n\ncontram justamente sobre aquelas linhas, de maneira que, se i  \u00e9 o \u00edndice de qualquer \n\numa desses vetores, ( ) 1, ?+? bxwy ii\n??\n\n.  \n\n \n\nFigura 24 \u2013 Fun\u00e7\u00e3o de Decis\u00e3o no Espa\u00e7o de Entrada \n\n\n\n 69 \n\n( )\n?\n?\n\n?\n\n?\n\n?\n?\n\n?\n\n? ?\n?=\n\n2\n\n2\n21\n\n21 2\nexp,\n\n?\nxx\n\nxxk  \n\nEqua\u00e7\u00e3o 52 \u2013 Kernel de Fun\u00e7\u00e3o de Base Radial \n\nNa Figura 24, quanto mais afastada as amostras se encontram do limite de deci-\n\ns\u00e3o, maior \u00e9 o valor de ( )?\n=\n\n+\nm\n\ni\niii bxxky\n\n1\n\n,?  (m\u00f3dulo do argumento da fun\u00e7\u00e3o de deci-\n\ns\u00e3o) (Schlkopf et al., 2001). \n\n4.7 Hiperplanos de Margens Suaves (Soft Margin hyperplanes) \n\nPor raz\u00f5es pr\u00e1ticas, pode ser necess\u00e1rio relaxar o crit\u00e9rio da forma can\u00f4nica mos-\n\ntrado na Equa\u00e7\u00e3o 35, permitindo assim alguns erros de classifica\u00e7\u00e3o durante o aprendi-\n\nzado. At\u00e9 ent\u00e3o, o objetivo era maximizar a largura da margem, assegurando assim um \n\nerro de generaliza\u00e7\u00e3o (esperado) muito baixo. Mediante a aplica\u00e7\u00e3o do truque do kernel, \n\n\u00e9 sempre poss\u00edvel restringir a complexidade do classificador, tornando-o linear em al-\n\ngum espa\u00e7o de caracter\u00edsticas.  \n\nA no\u00e7\u00e3o de maximiza\u00e7\u00e3o da margem de classifica\u00e7\u00e3o \u00e9 um ponto de partida con-\n\nceitual para a constru\u00e7\u00e3o de algoritmos mais robustos adequados a situa\u00e7\u00f5es reais (Cris-\n\ntiani, 2001). Por exemplo, sob condi\u00e7\u00f5es n\u00e3o-ideais, \u00e9 prov\u00e1vel que a amostragem do \n\nconjunto de treinamento esteja contaminada por algum tipo de ru\u00eddo, o que pode causar \n\numa sobreposi\u00e7\u00e3o entre as classes (Schlkopf et al., 2001). Em geral, isso impede a sepa-\n\nra\u00e7\u00e3o linear entre as classes a menos que sejam empregadas fun\u00e7\u00f5es de kernel t\u00e3o pode-\n\nrosas como a fun\u00e7\u00e3o radial definida na Equa\u00e7\u00e3o 52. Nestas condi\u00e7\u00f5es, o classificador \n\npode se tornar super ajustado, produzindo uma larga discrep\u00e2ncia entre o risco emp\u00edrico \n\ne o risco real (Cristiani, 2001; Herbrich, 2001). Outra n\u00e3o idealidade que pode afetar a \n\nsepara\u00e7\u00e3o linear \u00e9 a ocorr\u00eancia de pontos discrepantes, que pode tornar a converg\u00eancia \n\nextremamente lenta (Herbrich, 2001). \n\n\n\n 70 \n\nEssas defici\u00eancias do algoritmo podem ser superadas com o emprego de uma heu-\n\nr\u00edstica denominada SVM de margem suave (soft margin SVM). Uma margem suave \n\npermite o relaxamento na forma can\u00f4nica do discriminante (Equa\u00e7\u00e3o 35), atrav\u00e9s da \n\nintrodu\u00e7\u00e3o de par\u00e2metros livres, como mostrado na Equa\u00e7\u00e3o 53 (Vapnik, 1998; Vapnik, \n\n1999, Schlkopf et al., 2001).  \n\n( ) { }mibxwy iiii ,...,2,101, ?????+? ??\n??\n\n \n\nEqua\u00e7\u00e3o 53 \u2013 Relaxamento da Forma Can\u00f4nica \n\nDe certa forma, ao admitir erros de classifica\u00e7\u00e3o, o relaxamento da Equa\u00e7\u00e3o 53 \n\ntorna o classificador quase-\u00f3timo. Entretanto, em muitas situa\u00e7\u00f5es reais esta \u00e9 a \u00fanica \n\nmaneira de manter o erro de generaliza\u00e7\u00e3o sob controle, o que torna esta solu\u00e7\u00e3o efeti-\n\nvamente superior.  \n\nPara determinar o classificador, \u00e9 necess\u00e1rio modificar a fun\u00e7\u00e3o objetivo original \n\n(Equa\u00e7\u00e3o 43) para admitir uma taxa de erro, limitando-a de forma conveniente, tal como \n\nmostrado na Equa\u00e7\u00e3o 54 (Schlkopf et al., 2001).  \n\n( ) 0\n2\n1\n\n,min\n1\n\n2\n>?+?= ?\n\n=\nCCww\n\nm\n\ni\ni???\n????\n\n \n\nEqua\u00e7\u00e3o 54 \u2013 Fun\u00e7\u00e3o Objetivo para Determinar o Hiperplano Quase-\u00d3timo (condi\u00e7\u00f5es \n\nrelaxadas) \n\nCom esta nova fun\u00e7\u00e3o objetivo, a determina\u00e7\u00e3o do classificador passou a depen-\n\nder do controle da complexidade (via w\n?\n\n) e do somat\u00f3rio ?\n=\n\nm\n\ni\ni\n\n1\n\n?\n?\n\n, onde C  \u00e9 uma cons-\n\ntante que permite encontrar um ponto de equil\u00edbrio entre a maximiza\u00e7\u00e3o da margem e a \n\nminimiza\u00e7\u00e3o do erro de treinamento. Como no caso do hiperplano \u00f3timo, a fun\u00e7\u00e3o obje-\n\ntivo \u00e9 atingida com a utiliza\u00e7\u00e3o de um kernel e de multiplicadores de Lagrange, os quais \n\nest\u00e3o sujeitos \u00e0 restri\u00e7\u00e3o da Equa\u00e7\u00e3o 55. \n\n \n\n\n\n 71 \n\n{ }miyC\nm\n\ni\niii ,...,2,100\n\n1\n\n??=?? ?\n=\n\n??  \n\nEqua\u00e7\u00e3o 55 \u2013 Restri\u00e7\u00f5es para o Lagrangiano \n\nO Lagrangiano e outros aspectos matem\u00e1ticos relacionados s\u00e3o omitidos por ex-\n\ntrapolarem o escopo deste estudo; no entanto, sua resolu\u00e7\u00e3o \u00e9 uma extens\u00e3o natural do \n\nLagrangiano utilizado para determinar o hiperplano \u00f3timo. Considera\u00e7\u00f5es mais apro-\n\nfundadas s\u00e3o mostradas em (Vapnik, 1998; Vapnik, 1999, Schlkopf et al., 2001). \n\n4.8 Regress\u00e3o SVM (SVR \u2013 Support Vector Regression) \n\nA an\u00e1lise de regress\u00e3o distingue-se fundamentalmente da classifica\u00e7\u00e3o por consi-\n\nderar muitos (possivelmente infinitos) valores num\u00e9ricos cont\u00ednuos como resposta (ou \n\nseja, ??iy ), ao inv\u00e9s de um pequeno n\u00famero de possibilidades categ\u00f3ricas (discretas). \n\nPor esta raz\u00e3o, a regress\u00e3o pode ser considerada uma forma de generaliza\u00e7\u00e3o da classi-\n\nfica\u00e7\u00e3o, onde a resposta esperada varia continuamente dentro de uma faixa determinada. \n\nA regress\u00e3o SVM \u00e9 semelhante \u00e0 determina\u00e7\u00e3o dos hiperplanos de margem suave, \n\npor\u00e9m com a ado\u00e7\u00e3o de uma fun\u00e7\u00e3o de perda. Uma fun\u00e7\u00e3o de perda comum \u00e9 a fun\u00e7\u00e3o \n\n? -insensitiva de Vapnik, mostrada na Figura 25 (Vapnik, 1998; Vapnik, 1999; Schl-\n\nkopf et al., 2001; Herbrich, 2001). Entretanto, outras fun\u00e7\u00f5es de perda tamb\u00e9m s\u00e3o po-\n\npulares, tais como o erro quadr\u00e1tico e suas varia\u00e7\u00f5es, a fun\u00e7\u00e3o de Huber, o Laplaciano \n\nou as polinomiais (Vapnik, 1998; Vapnik, 1999, Schlkopf et al., 2001). \n\n\n\n 72 \n\n \n\nL\n?\n\n( )xfy ?\n0,0\n\n0,0\n\n \n\nFigura 25 \u2013 Fun\u00e7\u00e3o de Perda ? -insensitiva de Vapnik \n\nO gr\u00e1fico da Figura 25 mostra a penaliza\u00e7\u00e3o ou perda ( L ) em fun\u00e7\u00e3o do erro ob-\n\nservado ( ( )xfy ? ). Quanto maior o erro, maior a penaliza\u00e7\u00e3o e se n\u00e3o houver erro, n\u00e3o \nh\u00e1 penaliza\u00e7\u00e3o ( 0=L ). Deve-se notar que s\u00f3 h\u00e1 penaliza\u00e7\u00e3o na fun\u00e7\u00e3o ? -insensitiva \n\nquando o m\u00f3dulo do erro extrapola um valor arbitr\u00e1rio ? . Isso forma uma regi\u00e3o de \n\ntoler\u00e2ncia determinada por ( )?? +? ,  (regi\u00e3o insensitiva), visualizada como um plat\u00f4 na \nparte inferior da curva mostrada na Figura 25. Fora da faixa de toler\u00e2ncia, todo erro \u00e9 \n\npenalizado em propor\u00e7\u00e3o linear ao seu m\u00f3dulo. \n\nA Equa\u00e7\u00e3o 56 expressa algebricamente a fun\u00e7\u00e3o de perda da Figura 25. \n\n( )( ) ( ) ( ){ }?\n?\n\n??=?= xfyxfyxfyxc ,0max,,  \n\nEqua\u00e7\u00e3o 56 \u2013 Fun\u00e7\u00e3o de Perda ? -insensitiva de Vapnik \n\nA regi\u00e3o de toler\u00e2ncia pode ser visualizada na regress\u00e3o mostrada na Figura 26, \n\nonde a curva ajustada (em vermelho) \u00e9 calculada levando em conta somente os erros \n\ncujos m\u00f3dulos extrapolam ? . Isso determina um tubo de raio ?  ao redor da curva ajus-\n\ntada. Ent\u00e3o, o melhor modelo \u00e9 aquele cuja capacidade \u00e9 relativamente baixa e o n\u00fame-\n\nro de pontos fora do tubo \u00e9 relativamente pequeno.  \n\n\n\n 73 \n\nx\n\ny\n\nx\n?\n\n \n\nFigura 26 \u2013 Regress\u00e3o SVM \n\nComo no caso da classifica\u00e7\u00e3o, a estima\u00e7\u00e3o de uma fun\u00e7\u00e3o linear na forma da \n\nEqua\u00e7\u00e3o 57 envolve um fator de otimiza\u00e7\u00e3o quadr\u00e1tica, mostrada na Equa\u00e7\u00e3o 58. Este \n\nfator \u00e9 utilizado pela fun\u00e7\u00e3o objetivo mostrada na Equa\u00e7\u00e3o 59. \n\n( ) bxwxf += ??? ,  \n\nEqua\u00e7\u00e3o 57 \u2013 Regress\u00e3o Linear \n\n( )?\n=\n\n??+?\nm\n\ni\nii xfyCw\n\n1\n\n2\n\n2\n1\n\n?\n\n?\n \n\nEqua\u00e7\u00e3o 58 \u2013 Fator de Otimiza\u00e7\u00e3o Quadr\u00e1tica \n\n( )( )( ) ( )?\n?\n\n?\n?\n?\n\n?\n+?+?= ?\n\n=\n\nm\n\ni\niiCww\n\n1\n\n*2*\n\n2\n1min,min ????\n\n???\n \n\nEqua\u00e7\u00e3o 59 \u2013 Fun\u00e7\u00e3o Objetivo para a Regress\u00e3o Linear \n\nA fun\u00e7\u00e3o objetivo da Equa\u00e7\u00e3o 59 cont\u00e9m duas vari\u00e1veis livres: ?  e *? , denotadas \n\ncoletivamente como ( )*?\n?\n\n. Elas s\u00e3o introduzidas para limitar o erro lateralmente; ou seja, \n\npara considerar tanto a situa\u00e7\u00e3o em que ( ) ?>? ii yxf  como ( ) ?>? ii xfy  (Schlkopf et \n\n\n\n 74 \n\nal., 2001). A Equa\u00e7\u00e3o 60 mostra as restri\u00e7\u00f5es que devem ser observadas para alcan\u00e7ar a \n\nfun\u00e7\u00e3o objetivo (Vapnik, 1999), destacando-se que ?  e *?  podem ser nulos no caso do \n\nm\u00f3dulo do erro ser inferior a ? . \n\n( )\n( )\n0,)(\n\n)(\n\n)(\n\n*\n\n*\n\n?\n\n+??\n\n+??\n\nii\n\niii\n\niii\n\nc\n\nxfyb\n\nyxfa\n\n??\n??\n??\n\n?\n\n?\n\n \n\nEqua\u00e7\u00e3o 60 \u2013 Restri\u00e7\u00f5es da Fun\u00e7\u00e3o Objetivo \n\nComo os problemas do mundo real nem sempre podem ser representados direta-\n\nmente por um modelo linear como o da Equa\u00e7\u00e3o 57, \u00e9 poss\u00edvel utilizar o mesmo artif\u00ed-\n\ncio empregado na classifica\u00e7\u00e3o SVM: mapear o espa\u00e7o de entrada original para um es-\n\npa\u00e7o de caracter\u00edsticas diferente, com dimensionalidade mais alta, onde o modelo se \n\ntorne linear. Entretanto, assim como na classifica\u00e7\u00e3o, o mapeamento n\u00e3o precisa ser \n\nefetuado explicitamente, se um kernel k  for utilizado (Schlkopf et al., 2001). Assim, \n\naplicando o kernel, a fun\u00e7\u00e3o objetivo \u00e9 alcan\u00e7ada a utiliza\u00e7\u00e3o de um dos multiplicadores \n\nde Lagrange, definindo assim a fun\u00e7\u00e3o linear mostrada na Equa\u00e7\u00e3o 61. \n\n( ) ( ) ( )?\n=\n\n+??=\nm\n\ni\niii bxxkxf\n\n1\n\n* ,??  \n\nEqua\u00e7\u00e3o 61 \u2013 Fun\u00e7\u00e3o de Regress\u00e3o \n\nA demonstra\u00e7\u00e3o de como a Equa\u00e7\u00e3o 61 \u00e9 obtida a partir da fun\u00e7\u00e3o objetivo \u00e9 omi-\n\ntida neste trabalho. Para considera\u00e7\u00f5es mais aprofundadas sobre este tema, \u00e9 oportuno \n\nconsiderar que se trata de uma generaliza\u00e7\u00e3o do SVM de margem suave, como detalha-\n\ndo em (Vapnik, 1999; Schlkopf et al., 2001).  \n\nComo visto, a classifica\u00e7\u00e3o SVM depende somente de um subconjunto de dados \n\n(os vetores de suporte), ignorando as amostras que se encontram fora da margem de \n\nclassifica\u00e7\u00e3o. Analogamente, a regress\u00e3o SVM depende de um subconjunto dos dados, \n\nporque a fun\u00e7\u00e3o de perda ignora quaisquer padr\u00f5es que estejam suficientemente pr\u00f3xi-\n\nmos (dentro de uma dist\u00e2ncia ? ) \u00e0 fun\u00e7\u00e3o estimada (Figura 26). \n\n\n\n 75 \n\nA Figura 27 mostra um diagrama esquem\u00e1tico do SVR, considerando o kernel \n\n( )xxk i ,  como o produto interno de ix  e x . O mapeamento denotado por ( )x? , \u00e9 mos-\ntrado por raz\u00f5es conceituais, uma vez que de acordo com a Equa\u00e7\u00e3o 27, \n\n( ) ( ) ( )xxxxxxk iii ??== ,,,\n??\n\n e, portanto, o mapeamento pode ser omitido.  \n\n \n\nFigura 27 \u2013 Arquitetura da Regress\u00e3o SVM \n\nComo mostrado na Figura 27, a resposta para uma entrada desconhecida x  \u00e9 obti-\n\nda em tr\u00eas etapas. Primeiro, s\u00e3o calculados os produtos internos de cada vetor de supor-\n\nte com esta entrada. Na seq\u00fc\u00eancia, estes produtos s\u00e3o combinados linearmente com os \n\nfatores ( )iiiv ?? ?= *  e, finalmente, este resultado \u00e9 somado ao termo constante b , tal \ncomo mostrado na Equa\u00e7\u00e3o 61. Este processo \u00e9 basicamente o mesmo que acontece em \n\numa rede neuronal, excetuando-se pelo fato que no SVM os pesos sin\u00e1pticos das unida-\n\ndes de entrada s\u00e3o constitu\u00eddos por um subconjunto dos dados de treinamento (os veto-\n\nres de suporte). Na Figura 27, isso denotado utilizando-se o \u00edndice n  para o total de \n\npadr\u00f5es existentes, ao inv\u00e9s de m , o total de amostras. Na Equa\u00e7\u00e3o 61, isso \u00e9 denotado \n\nimplicitamente, ao admitir que ii ?? ?\n*  possa ser nulo para alguns valores de i .  \n\n\u00c9 importante destacar que o SVM escolhe a fun\u00e7\u00e3o mais linear poss\u00edvel entre a-\n\nquelas que predizem os dados originais com uma dada precis\u00e3o. Conceitualmente, a \n\nlinearidade \u00e9 obtida somente no espa\u00e7o de caracter\u00edsticas; entretanto, \u00e9 importante notar \n\n\n\n 76 \n\nque a fun\u00e7\u00e3o de regress\u00e3o equivalente no espa\u00e7o de entrada original tende a ser suave. \n\nIsso se deve ao fato de que os kernels podem impor essa suavidade atrav\u00e9s de operado-\n\nres de regulariza\u00e7\u00e3o (Schlkopf et al., 2001). \n\n\n\n 77 \n\n5 ESTADO DA ARTE \n\nEmbora a predi\u00e7\u00e3o de carga el\u00e9trica venha sendo explorada h\u00e1 muitos anos, o foco \n\ndeste trabalho \u00e9 uma nova \u00e1rea de pesquisa. Esta pesquisa, ao mesmo tempo em que \n\nconsidera o j\u00e1 consolidado campo de predi\u00e7\u00e3o como cen\u00e1rio de fundo, prop\u00f5e uma a-\n\nbordagem nova baseada na detec\u00e7\u00e3o de similaridades entre perfis de consumo para a-\n\nprimorar o desempenho de algoritmos de predi\u00e7\u00e3o conhecidos, tal como o PCarga (Oli-\n\nveira, 2004).  \n\nDe acordo com o per\u00edodo de previs\u00e3o, abordagens diferentes s\u00e3o empregadas para \n\nprever a carga el\u00e9trica. Para a predi\u00e7\u00e3o de curto prazo, os algoritmos neurais h\u00edbridos \n\ns\u00e3o escolhas quase universais, porque asseguram alta precis\u00e3o e s\u00e3o capazes de manipu-\n\nlar grandes quantidades de informa\u00e7\u00e3o (Guo et al., 2004; Hong et al., 2005). Nos \u00falti-\n\nmos anos, alguns trabalhos bem sucedidos t\u00eam proposto modelos h\u00edbridos empregando \n\nm\u00e1quinas de vetores de suporte (SVM). Os resultados obtidos com tais modelos s\u00e3o \n\nequivalentes ou superiores a aqueles obtidos com o uso de redes neurais artificiais \n\n(RNAs) (Tao et al., 2004; Hong et al., 2005; Niu et al., 2005; Guo et al., 2006).  \n\nAssim como no caso dos modelos b\u00e1sicos, o desempenho dos modelos h\u00edbridos \u00e9 \n\nfortemente influenciado pela natureza dos dados de entrada. Uma vez que, em geral, \n\ndados brutos n\u00e3o s\u00e3o muito expressivos, uma parcela significativa de recursos computa-\n\ncionais \u00e9 gasta para transform\u00e1-los adequadamente. No caso dos algoritmos h\u00edbridos, \n\nm\u00f3dulos espec\u00edficos processam os dados de entrada antes que uma RNA ou SVM possa \n\nrealizar infer\u00eancias. Omitir esse passo, conhecido como pr\u00e9-processamento, implica em \n\ndegradar o desempenho do modelo de predi\u00e7\u00e3o (Tao et al., 2004; Guo et al., 2004; Oli-\n\nveira, 2004; Hong et al., 2005). Na realidade, o desempenho geral do modelo depende \n\nmais do pr\u00e9-processamento do que da arquitetura da RNA (ou SVM).  \n\nA Figura 28 mostra um diagrama que mostra as etapas normalmente existentes \n\nnos sistemas para gerar preditores de carga, sendo que as etapas relacionadas ao pr\u00e9-\n\nprocessamento est\u00e3o destacadas por uma linha tracejada. Os trabalhos da \u00e1rea prop\u00f5em \n\nabordagens ligeiramente diferentes entre si mas, em geral, implementam o esquema \n\n\n\n 78 \n\nmostrado nesta figura. Como pode ser percebido, o m\u00f3dulo de pr\u00e9-processamento \u00e9 im-\n\nplementado por quatro etapas distintas: (a) a sele\u00e7\u00e3o de par\u00e2metros, (b) um algoritmo de \n\navalia\u00e7\u00e3o, (c) um modelo de avalia\u00e7\u00e3o e (d) um crit\u00e9rio de parada.  \n\n \n\nFigura 28 \u2013 Etapas na Constru\u00e7\u00e3o de um Modelo Preditor \n\nNo contexto da Figura 28, a sele\u00e7\u00e3o de par\u00e2metros \u00e9 respons\u00e1vel por gerar iterati-\n\nvamente conjuntos diferentes com as vari\u00e1veis de entrada, os quais possuem sua rele-\n\nv\u00e2ncia preditiva testada depois de gerados. Se for constatado que um determinado con-\n\njunto \u00e9 relevante, ent\u00e3o ele \u00e9 considerado um conjunto de preditores (ou par\u00e2metros) \n\nv\u00e1lido.  \n\nA cardinalidade do conjunto preditor \u00e9 uma das inc\u00f3gnitas a serem descobertas na \n\nsele\u00e7\u00e3o de par\u00e2metros. Como na maior parte das situa\u00e7\u00f5es pr\u00e1ticas as vari\u00e1veis de en-\n\ntrada s\u00e3o consideravelmente redundantes (Tao et al., 2004), \u00e9 mesmo poss\u00edvel determi-\n\nnar dois conjuntos preditores de cardinalidade distinta. No entanto, alguns trabalhos \n\nignoram esta peculiaridade da predi\u00e7\u00e3o de carga e utilizam um conjunto fixo de vari\u00e1-\n\nveis (Iyer et al., 2003; Niu et al., 2005), o que pode reduzir a acur\u00e1cia em algumas apli-\n\nca\u00e7\u00f5es de predi\u00e7\u00e3o de carga (Tao et al., 2004; Oliveira, 2004; Hong et al., 2005). \n\nO algoritmo de avalia\u00e7\u00e3o define como os modelos de avalia\u00e7\u00e3o s\u00e3o gerados. Co-\n\nmo em geral h\u00e1 muitas vari\u00e1veis de entrada dispon\u00edveis, a sele\u00e7\u00e3o de par\u00e2metros \u00e9 in-\n\ntrinsecamente lenta. Portanto, \u00e9 importante que o algoritmo de avalia\u00e7\u00e3o assegure uma \n\nr\u00e1pida converg\u00eancia, para diminuir o overhead geral na gera\u00e7\u00e3o do preditor.  \n\n\n\n 79 \n\nO modelo de avalia\u00e7\u00e3o \u00e9 criado pelo algoritmo de avalia\u00e7\u00e3o utilizando o conjunto \n\nde par\u00e2metros gerados no in\u00edcio do fluxo mostrado na Figura 28. O objetivo do modelo \n\nde avalia\u00e7\u00e3o \u00e9 testar os conjuntos de par\u00e2metros em condi\u00e7\u00f5es de opera\u00e7\u00e3o real\u00edsticas, \n\nde tal forma que o desempenho obtido com ele seja o desempenho esperado do modelo \n\ndefinitivo. A id\u00e9ia, mostrada na Figura 29, \u00e9 utilizar um determinado conjunto de predi-\n\ntores para alimentar o modelo de avalia\u00e7\u00e3o. Se este conjunto permitir que o modelo de \n\navalia\u00e7\u00e3o prediga o passado recente a partir do passado remoto com razo\u00e1vel desempe-\n\nnho, ent\u00e3o o modelo definitivo ser\u00e1 capaz de prever o futuro com base no presente com \n\ndesempenho semelhante. \n\n \n\nFigura 29 \u2013 Analogia entre os Modelos de Avalia\u00e7\u00e3o e Definitivo \n\nConforme mostrado na Figura 28, diversos modelos de avalia\u00e7\u00e3o podem ser gera-\n\ndos iterativamente at\u00e9 que um conjunto de preditores v\u00e1lidos seja encontrado (Tao et al., \n\n2004; Oliveira, 2004; Hong et al., 2005). Como o n\u00famero de itera\u00e7\u00f5es pode ser muito \n\ngrande, \u00e9 poss\u00edvel a utiliza\u00e7\u00e3o de modelos de avalia\u00e7\u00e3o mais simples que os modelos \n\ndefinitivos (Tao et al., 2004). Com isso, as itera\u00e7\u00f5es se tornam mais breves e os conjun-\n\ntos de par\u00e2metros gerados podem ser testados mais rapidamente. \n\nO crit\u00e9rio de parada normalmente \u00e9 uma fun\u00e7\u00e3o de desempenho: se o conjunto de \n\npar\u00e2metros testado permite o modelo de avalia\u00e7\u00e3o alcan\u00e7ar um patamar de desempenho \n\npreviamente definido como satisfat\u00f3rio, ent\u00e3o o pr\u00e9-processamento est\u00e1 conclu\u00eddo; caso \n\ncontr\u00e1rio, um novo conjunto de par\u00e2metros deve ser gerado e testado. No caso dos mo-\n\ndelos neurais, que empregam o princ\u00edpio da minimiza\u00e7\u00e3o do risco emp\u00edrico, \u00e9 preciso \n\ntomar algumas precau\u00e7\u00f5es contra o super ajuste, tal como a valida\u00e7\u00e3o cruzada. A n\u00e3o \n\nobserv\u00e2ncia dessas precau\u00e7\u00f5es pode conduzir \u00e0 perda de generaliza\u00e7\u00e3o dos modelos \n\n(Haykin, 1998; Duda et al., 2000). No caso das m\u00e1quinas SV, a possibilidade de supera-\n\n\n\n 80 \n\njuste \u00e9 minimizada atrav\u00e9s do controle da complexidade do modelo (minimiza\u00e7\u00e3o de \n\nrisco estrutural) (Vapnik, 1998; Vapnik, 1999, Schlkopf et al., 2001). \n\nMuitos trabalhos empregam solu\u00e7\u00f5es diferentes para o pr\u00e9-processamento em \n\nmodelos h\u00edbridos. Oliveira (2004) prop\u00f4s a utiliza\u00e7\u00e3o de um algoritmo gen\u00e9tico (AG) \n\npara realizar a sele\u00e7\u00e3o de par\u00e2metros. O AG tenta formar um conjunto de preditores \n\natrav\u00e9s de uma busca heur\u00edstica inspirada na biologia evolucion\u00e1ria, utilizando t\u00e9cnicas \n\ncomo heran\u00e7a, muta\u00e7\u00e3o, sele\u00e7\u00e3o e recombina\u00e7\u00e3o (crossover). O crit\u00e9rio de parada \u00e9 for-\n\nnecido pela fun\u00e7\u00e3o de fitness do AG, associada ao desempenho do modelo de avalia\u00e7\u00e3o. \n\nComo somente as vari\u00e1veis com relev\u00e2ncia preditiva s\u00e3o fornecidas para o modelo defi-\n\nnitivo, este esquema assegura uma precis\u00e3o maior e um tempo de converg\u00eancia menor. \n\nPor outro lado, o AG exige um cluster com v\u00e1rios computadores para rodar o pr\u00e9-\n\nprocessamento eficientemente. \n\nOutras abordagens an\u00e1logas s\u00e3o propostas por Hong et al. (2005) e Tao et al. \n\n(2004). Em Hong et al. (2005), a sele\u00e7\u00e3o de par\u00e2metros \u00e9 feita com um algoritmo de \n\nt\u00eampora simulada (Simulated Annealing Algorithm), que \u00e9 uma generaliza\u00e7\u00e3o do m\u00e9to-\n\ndo de Monte Carlo para minimizar fun\u00e7\u00f5es multivariadas. J\u00e1 em Tao et al. (2004), a \n\nsele\u00e7\u00e3o de par\u00e2metros \u00e9 efetuada mediante uma estrat\u00e9gia de busca em \u00e1rvore denomi-\n\nnada m\u00e9todo de busca flutuante (Floating Search Method). Nestas duas abordagens, os \n\nmodelos definitivos s\u00e3o constru\u00eddos com m\u00e1quinas SV. \n\nGuo et al. (2004) foge do esquema geral mostrado na Figura 28 ao sugerir um m\u00e9-\n\ntodo de sele\u00e7\u00e3o de par\u00e2metros baseado no uso de PCA (Principal Components Analysis, \n\nAn\u00e1lise de Componentes Principais). A PCA explora as correla\u00e7\u00f5es estat\u00edsticas existen-\n\ntes nos dados de entrada, produzindo um conjunto de vari\u00e1veis transformadas (os com-\n\nponentes principais) que s\u00e3o combina\u00e7\u00f5es lineares das vari\u00e1veis originais (Johnson et \n\nal., 2002; Rencher, 2002).  \n\nOs fatores principais s\u00e3o ordenados por ordem de import\u00e2ncia, a qual \u00e9 percebida \n\ncomo o impacto na variabilidade total dos dados de entrada. Se nestes dados forem per-\n\ncebidas correla\u00e7\u00f5es muito fortes, \u00e9 poss\u00edvel utilizar um pequeno n\u00famero de fatores para \n\nreproduzir a variabilidade original. Assim, um conjunto com n  vari\u00e1veis de entrada \n\npoderia ser substitu\u00eddo por m  componentes principais, onde nm ? . Por exemplo, nos \n\n\n\n 81 \n\nestudos conduzidos durante esta pesquisa, verificou-se que na subesta\u00e7\u00e3o ILHA-\n\nCENTRO durante o inverno (perfil de consumo ICO_INV), percebeu-se cinco compo-\n\nnentes principais conseguiam reproduzir cerca de 85% da variabilidade total observada \n\nnum conjunto de 104 vari\u00e1veis. Por\u00e9m, como as grandezas meteorol\u00f3gicas e el\u00e9tricas \n\ns\u00e3o din\u00e2micas, as correla\u00e7\u00f5es entre elas tamb\u00e9m s\u00e3o din\u00e2micas; portanto, a PCA pode \n\nconduzir a inconsist\u00eancias se o per\u00edodo de predi\u00e7\u00e3o for muito longo. No entanto, os re-\n\nsultados mostrados em (Guo et al., 2004) indicam que o m\u00e9todo \u00e9 especialmente pode-\n\nroso quando aplicado a predi\u00e7\u00f5es de at\u00e9 24 horas adiante.  \n\nIyer et al. (2003) desenvolveu um sistema neural difuso para uma aplica\u00e7\u00e3o que \n\ndepende da predi\u00e7\u00e3o de carga: a predi\u00e7\u00e3o do pre\u00e7o da energia no mercado spot. O mer-\n\ncado spot trata a energia como uma commodity, negociada em transa\u00e7\u00f5es \u00e0 vista e en-\n\ntregue imediatamente. Em geral, as concession\u00e1rias distribuidoras compram energia das \n\ngeradoras e transmissoras em leil\u00f5es nos mercados atacadistas de energia (as chamadas \n\nc\u00e2maras de comercializa\u00e7\u00e3o) com grande anteced\u00eancia. Essa energia \u00e9 entregue aos \n\nconsumidores finais ao longo de um grande per\u00edodo de tempo. Se as previs\u00f5es de de-\n\nmanda de consumo no longo prazo estiverem incorretas, as distribuidoras podem ficar \n\ncom energia sobrando ou faltando no curto prazo, o que as obriga a negociar esta dife-\n\nren\u00e7a no mercado spot quase em tempo real. Esta caracter\u00edstica din\u00e2mica \u00e9 acentuada \n\npela atua\u00e7\u00e3o de especuladores, que atuam no mercado spot da mesma forma como numa \n\nbolsa de valores. Como resultado, os pre\u00e7os de compra e venda de energia oscilam mui-\n\nto, dependendo do consumo de energia no curto prazo. \n\nPara predizer o valor da energia no mercado spot, o sistema proposto por Iyer et \n\nal. (2003) emprega uma RNA alimentada por dados oriundos de duas fontes distintas, \n\ncomo mostrado na Figura 30: uma s\u00e9rie hist\u00f3rica de pre\u00e7os e um m\u00f3dulo preditor difuso \n\nque prev\u00ea a demanda de carga no curto prazo. O preditor difuso, por sua vez, \u00e9 alimen-\n\ntado por um conjunto fixo de vari\u00e1veis (dia, hora, esta\u00e7\u00e3o e temperatura) e prediz a \n\ncarga el\u00e9trica como um valor discreto de consumo; ou seja, um tipo de carga, que pode \n\nser alto, m\u00e9dio ou baixo. Os resultados mostrados neste trabalho s\u00e3o promissores, mas \n\ncomo as regras de infer\u00eancia do m\u00f3dulo difuso s\u00e3o implementadas manualmente, uma \n\naplica\u00e7\u00e3o em escala industrial poderia ser tecnicamente invi\u00e1vel. \n\n \n\n\n\n 82 \n\n \n\nFigura 30 \u2013 Sistema Neural Difuso para a Predi\u00e7\u00e3o do Pre\u00e7o da Energia no Mercado \n\nSpot \n\nNiu et al. (2005) adotou um sistema que guarda algumas semelhan\u00e7as com a pro-\n\nposta de Iyer et al. (2003), mas no contexto de predi\u00e7\u00e3o de carga de curto prazo. Nesta \n\nsolu\u00e7\u00e3o, mostrada esquematicamente na Figura 31, o consumo de energia \u00e9 classificado \n\nem tr\u00eas n\u00edveis (tipos) discretos: alto, m\u00e9dio e baixo. Uma RNA analisa as preditoras \n\n(valores hist\u00f3ricos da carga, temperatura, umidade, dia da semana e feriado) e prediz o \n\nn\u00edvel de consumo. Para cada tipo de consumo, existe uma m\u00e1quina SV espec\u00edfica, trei-\n\nnada para predizer carga desse tipo.  \n\nClassifica\u00e7\u00e3o\nbaseada em RNA\n\nH\nist\u00f3ricos \nde carga\n\nT\nem\n\nperatura\n\nU\nm\n\nidade\n\nD\nia da \n\nsem\nana\n\nF\neriado\n\nTipo da\nCarga\n\nPreditor\nSVM\n\ncarga m\u00e9dia\n\nPreditor\nSVM\n\ncarga alta\n\nPreditor\nSVM\n\ncarga baixa\n\nAlta\n\nM\u00e9dia\n\nBaixa\n\nP\nredi\u00e7\u00e3o de carga\n\n \n\nFigura 31 \u2013 Modelo Preditor H\u00edbrido RNA-SVM \n\nNa descri\u00e7\u00e3o dos resultados, Niu et al. (2005) assevera que a utiliza\u00e7\u00e3o da classi-\n\nfica\u00e7\u00e3o neuronal permite a composi\u00e7\u00e3o mais racional dos conjuntos de treinamento; isto \n\n\u00e9, possibilita a cria\u00e7\u00e3o de conjuntos balanceados. O fato \u00e9 que a utiliza\u00e7\u00e3o de tr\u00eas mo-\n\ndelos preditores limita a variabilidade da carga que cada um deles deve predizer e, con-\n\nseq\u00fcentemente, os resultados tendem a ser melhores do que seria poss\u00edvel obter com \n\n\n\n 83 \n\nmodelos neuronais ou SV b\u00e1sicos. Esta solu\u00e7\u00e3o \u00e9 assaz criativa, mas \u00e9 importante des-\n\ntacar que, da forma como foi concebida, a classifica\u00e7\u00e3o da carga \u00e9 feita com um conjun-\n\nto pr\u00e9-definido de vari\u00e1veis, as quais tamb\u00e9m s\u00e3o utilizadas para alimentar os predito-\n\nres. Assim, \u00e9 poss\u00edvel que algumas vari\u00e1veis relevantes sejam omitidas, o que poderia \n\nrestringir o desempenho da predi\u00e7\u00e3o. \n\nEmbora a arquitetura de predi\u00e7\u00e3o de carga mostrada no presente trabalho seja ori-\n\nginal, ela utiliza uma forma generalizada da classifica\u00e7\u00e3o de carga. No entanto, diferen-\n\ntemente da proposta de Niu et al. (2005), onde a carga dos perfis \u00e9 categorizada em n\u00ed-\n\nveis discretos, no presente trabalho os pr\u00f3prios perfis s\u00e3o categorizados antes que seu \n\npreditor seja constru\u00eddo. Portanto, trata-se de abordagens muito distintas. \n\nComo esta se\u00e7\u00e3o mostra, o pr\u00e9-processamento \u00e9 uma caracter\u00edstica comum nas so-\n\nlu\u00e7\u00f5es de predi\u00e7\u00e3o, exceto quando s\u00e3o utilizados modelos de s\u00e9ries temporais tal como \n\no proposto por Guo et al. (2006). O pr\u00e9-processamento assegura um desempenho supe-\n\nrior \u00e0 predi\u00e7\u00e3o tanto em termos de precis\u00e3o como converg\u00eancia. N\u00e3o obstante, o concei-\n\nto de similaridade entre perfis pode ser aprimorar ainda mais a predi\u00e7\u00e3o atrav\u00e9s da reci-\n\nclagem do conhecimento existente nos preditores j\u00e1 consolidados. Na pr\u00e1tica, um crit\u00e9-\n\nrio de similaridade poderia facilitar a inicializa\u00e7\u00e3o dos par\u00e2metros livres das RNAs e \n\nsubsidiar a escolha dos preditores \u00f3timos de um novo perfil de consumo. \n\nA inicializa\u00e7\u00e3o dos par\u00e2metros em uma RNA \u00e9 um gigantesco campo de estudo \n\npor si s\u00f3, mas poderia ser facilitado dentro do contexto deste trabalho pela aplica\u00e7\u00e3o de \n\numa heur\u00edstica muito simples: preditores de perfis similares tendem a serem parecidos. \n\nComo destacado no Cap\u00edtulo 1, um \u00fanico preditor seria adequado para dois perfis que \n\nsejam id\u00eanticos. Ainda que perfis id\u00eanticos sejam conceitos ideais, perfis similares s\u00e3o \n\ncomuns e compartilham algumas caracter\u00edsticas. No caso das RNAs, a similaridade en-\n\ntre perfis leva a superf\u00edcies de erros e pontos cr\u00edticos semelhantes. Assim, \u00e9 mais f\u00e1cil \n\ntreinar uma RNA analisando as j\u00e1 consolidadas do que faz\u00ea-lo sem nenhum conheci-\n\nmento a priori.   \n\nOs benef\u00edcios da aplica\u00e7\u00e3o do crit\u00e9rio de similaridade s\u00e3o demonstrados atrav\u00e9s \n\ndos resultados emp\u00edricos mostrados no Cap\u00edtulo 6. Al\u00e9m disso, s\u00e3o desenvolvidas duas \n\nferramentas gr\u00e1ficas explorat\u00f3rias \u2013 o espa\u00e7o de caracter\u00edsticas e o espa\u00e7o causal, tam-\n\n\n\n 84 \n\nb\u00e9m mostradas no Cap\u00edtulo 6 \u2013 foram desenvolvidas para suportar tal crit\u00e9rio, al\u00e9m de \n\npermitir infer\u00eancias mais profundas sobre perfis de consumo e o seu comportamento. \n\n\n\n 85 \n\n6 M\u00e9todo de Otimiza\u00e7\u00e3o da Predi\u00e7\u00e3o de Carga \n\nO m\u00e9todo de otimiza\u00e7\u00e3o proposto na se\u00e7\u00e3o 1.3 baseia-se na compara\u00e7\u00e3o entre per-\n\nfis de consumo, os quais determinam o comportamento da carga el\u00e9trica numa regi\u00e3o de \n\nconsumo face \u00e0 a\u00e7\u00e3o de alguns fatores de influ\u00eancia (as preditoras). \u00c9 importante desta-\n\ncar que uma regi\u00e3o de consumo \u00e9 um crit\u00e9rio de delimita\u00e7\u00e3o geogr\u00e1fica, enquanto que \n\num perfil \u00e9 um processo estoc\u00e1stico que descreve a carga el\u00e9trica numa regi\u00e3o em um \n\ndeterminado instante.  \n\nO ganho obtido com o m\u00e9todo consiste no reaproveitamento do conhecimento in-\n\ncorporado nos preditores de carga constru\u00eddos e homologados. Os cap\u00edtulos 1, 3 e 5 \n\nmostram que tal conhecimento consiste na modelagem das rela\u00e7\u00f5es causais entre a car-\n\nga el\u00e9trica e as preditoras. Especificamente, o Cap\u00edtulo 5 descreve a sele\u00e7\u00e3o de par\u00e2me-\n\ntros como um processo iterativo que exige um alto custo computacional (Oliveira, \n\n2004), dado que a adequa\u00e7\u00e3o do modelo deve ser conferida a cada itera\u00e7\u00e3o (Haykin, \n\n1998; Vapnik, 1999; Duda et al., 2000). \n\nPara que o conhecimento dos preditores consolidados seja reciclado, ele deve ser \n\narmazenado antes que novos modelos sejam constru\u00eddos. A Figura 32 mostra a primeira \n\netapa do m\u00e9todo, que \u00e9 a constru\u00e7\u00e3o de uma base de conhecimento com os dados perti-\n\nnentes a cada preditor (e, conseq\u00fcentemente, a cada perfil).  \n\n \n\nSele\u00e7\u00e3o de\nPar\u00e2metros\n\nAlgoritmo de\nAvalia\u00e7\u00e3o\n\nModelo de\nAvalia\u00e7\u00e3o\n\nCrit\u00e9rio de\nparada?\n\nN\n\nS\n\nPr\u00e9-processamento\n\nIn\u00edcio\n\nConstru\u00e7\u00e3o \ndo modelo\n\nCaptura da\nconfigura\u00e7\u00e3o\n\nArmazenamento \nda configura\u00e7\u00e3o\n\nFim\n\nBase de\nConhecimento\n\n \nFigura 32 \u2013 Extraindo o Conhecimento dos Preditores de Carga \n\n\n\n 86 \n\nInicialmente, os modelos s\u00e3o constru\u00eddos a partir de uma estrat\u00e9gia de pr\u00e9-\n\nprocessamento existente, como as discutidas no Cap\u00edtulo 5. Ap\u00f3s a constru\u00e7\u00e3o do mode-\n\nlo preditor, sua configura\u00e7\u00e3o \u00e9 capturada e armazenada na Base de Conhecimento. \n\nA Base de Conhecimento armazena as preditoras, os modelos preditores e os veto-\n\nres de caracter\u00edsticas dos perfis. A utiliza\u00e7\u00e3o deste conhecimento exige um crit\u00e9rio de \n\nsimilaridade para determinar qual configura\u00e7\u00e3o armazenada pode acelerar a cria\u00e7\u00e3o do \n\npreditor de um perfil novo.  \n\nA Figura 33 mostra um diagrama onde a estrat\u00e9gia de otimiza\u00e7\u00e3o \u00e9 mostrada, uti-\n\nlizando a arquitetura mostrada no Cap\u00edtulo 1 (se\u00e7\u00e3o Metodologia). Como pode ser nota-\n\ndo, a otimiza\u00e7\u00e3o proposta n\u00e3o substitui o pr\u00e9-processamento (Figura 28), mas o com-\n\nplementa, fornecendo informa\u00e7\u00f5es a priori que podem acelerar a sele\u00e7\u00e3o de par\u00e2metros \n\ne a converg\u00eancia do modelo. Al\u00e9m disso, a Base de Conhecimento continua armazenan-\n\ndo as configura\u00e7\u00f5es dos modelos novos, sendo enriquecida toda vez que um novo predi-\n\ntor \u00e9 criado.  \n\n \n\nIn\u00edcio Extra\u00e7\u00e3o de\ncaracter\u00edsticas\n\nCompara\u00e7\u00e3o\n\nBase de \nConhecimento\n\nVetor de \ncaracter\u00edsticas\n\nConfigura\u00e7\u00f5es\narmazenadas\n\nConfigura\u00e7\u00e3o do \nperfil semelhante\n\nPr\u00e9\nprocessamento\n\nConstru\u00e7\u00e3o \ndo modelo\n\nCaptura da\nconfigura\u00e7\u00e3o\n\nArmazenamento\nda configura\u00e7\u00e3o\n\nConjuntos de\npar\u00e2metros\n\nFim\n\nPreditoras, vetores de\ncaracter\u00edsticas e modelos\n\nPerfil de \nconsumo\n\n \nFigura 33 \u2013 M\u00e9todo de Otimiza\u00e7\u00e3o \n\nConsidere-se, por exemplo, o pr\u00e9-processamento do PCarga (Oliveira, 2004), que \n\nutiliza um algoritmo gen\u00e9tico (AG) para determinar o conjunto \u00f3timo de preditores. A \n\narquitetura geral do PCarga enquadra-se na Figura 32, e prev\u00ea um processo iterativo (o \n\nAG) onde diversos conjuntos de par\u00e2metros s\u00e3o testados quanto \u00e0 sua relev\u00e2ncia predi-\n\ntiva. Um conjunto de par\u00e2metros inicial, denominado popula\u00e7\u00e3o inicial, vai sendo mo-\n\ndificado iterativamente atrav\u00e9s de opera\u00e7\u00f5es evolutivas (heran\u00e7a, muta\u00e7\u00e3o, sele\u00e7\u00e3o e \n\nrecombina\u00e7\u00e3o) at\u00e9 que o desempenho do modelo de avalia\u00e7\u00e3o seja considerado adequa-\n\ndo. Com o m\u00e9todo descrito neste trabalho, a popula\u00e7\u00e3o inicial seria dada pelos par\u00e2me-\n\n\n\n 87 \n\ntros do preditor do perfil mais semelhante. Assim, dependendo do grau de similaridade \n\nexistente, poderiam ser necess\u00e1rias menos itera\u00e7\u00f5es para determinar os par\u00e2metros de \n\num preditor novo. \n\nComo a Figura 33 mostra, a primeira etapa da otimiza\u00e7\u00e3o \u00e9 a extra\u00e7\u00e3o de caracte-\n\nr\u00edsticas dos perfis de consumo novos. A extra\u00e7\u00e3o gera um vetor de caracter\u00edsticas que \u00e9 \n\numa forma de representa\u00e7\u00e3o mais conveniente do que os conjuntos amostrados que \n\ncomp\u00f5em os perfis de consumo. De posse deste vetor, \u00e9 poss\u00edvel fazer uma busca efici-\n\nente na Base de Conhecimento, localizando o perfil armazenado que mais se assemelha \n\nao perfil novo, bem como o modelo associado a este \u00faltimo. A partir da\u00ed, \u00e9 poss\u00edvel \n\nconstruir um preditor novo a partir de um outro j\u00e1 consolidado e de um conjunto inicial \n\nde preditores. Com esta estrat\u00e9gia, espera-se que a constru\u00e7\u00e3o de preditores novos se \n\ntorne, em m\u00e9dia, uma tarefa computacional menos onerosa.  \n\nUma outra vantagem dos vetores de caracter\u00edsticas \u00e9 a facilidade de representa\u00e7\u00e3o \n\ngeom\u00e9trica num espa\u00e7o de caracter\u00edsticas. As s\u00e9ries hist\u00f3ricas de vari\u00e1veis meteorol\u00f3gi-\n\ncas e el\u00e9tricas que descrevem os perfis de consumo s\u00e3o usualmente representadas como \n\nhistogramas ou gr\u00e1ficos de dispers\u00e3o (Montgomery et al., 2001; Berry et al., 2004). \n\nEmbora esta representa\u00e7\u00e3o seja \u00fatil para determinados tipos de an\u00e1lise, ela n\u00e3o favorece \n\na compara\u00e7\u00e3o entre os perfis de consumo. Com a defini\u00e7\u00e3o de um espa\u00e7o de caracter\u00eds-\n\nticas, muitas ferramentas \u00fateis podem ser empregadas com esta finalidade, tal como a \n\nan\u00e1lise de agrupamentos. Dentro deste cen\u00e1rio, um espa\u00e7o de caracter\u00edsticas deve pos-\n\nsuir as seguintes propriedades: \n\na) Perfis de consumo similares devem estar topologicamente mais pr\u00f3ximos entre \n\nsi do que de perfis dissimilares, formando agrupamentos. \n\nb) A forma\u00e7\u00e3o dos agrupamentos possui uma interpreta\u00e7\u00e3o sem\u00e2ntica consistente. \n\nA propriedade (a) \u00e9 pr\u00e9-requisito para a an\u00e1lise de agrupamentos, a qual depende \n\nsobremaneira do arranjo topol\u00f3gico das amostras no espa\u00e7o de caracter\u00edsticas. A forma \n\ncomo a dist\u00e2ncia \u00e9 calculada (dist\u00e2ncia euclidiana, euclidiana quadr\u00e1tica, Manhattam, \n\nChebychev, entre outras), bem como as regras de amalgama\u00e7\u00e3o (liga\u00e7\u00e3o simples, com-\n\npleta, m\u00e9dia par-grupo ponderada/n\u00e3o-ponderada, entre outras), podem variar de acordo \n\n\n\n 88 \n\ncom o ambiente e os objetivos pretendidos (Duda et al., 2000). Todavia, qualquer que \n\nseja a configura\u00e7\u00e3o, a similaridade entre as amostras deve ser sempre uma fun\u00e7\u00e3o inver-\n\nsa da dist\u00e2ncia medida entre elas. Como conseq\u00fc\u00eancia direta deste corol\u00e1rio, espera-se \n\nque as dist\u00e2ncias observadas entre as amostras de um mesmo agrupamento sejam signi-\n\nficativamente menores do que as observadas entre amostras de agrupamentos diferentes \n\n(Hand et al., 2001).  \n\nA propriedade (b) \u00e9 essencial \u00e0 an\u00e1lise explorat\u00f3ria, tanto para testar hip\u00f3teses e-\n\nlaboradas a priori como para gerar hip\u00f3teses orientadas a dados (data-driven hypothesis \n\ngeneration) (Hand et al., 2001). Uma interpreta\u00e7\u00e3o sem\u00e2ntica consistente dos agrupa-\n\nmentos formados no espa\u00e7o de caracter\u00edsticas s\u00f3 \u00e9 poss\u00edvel quando a extra\u00e7\u00e3o de carac-\n\nter\u00edsticas captura aspectos relevantes dos perfis de consumo. Caso os crit\u00e9rios utilizados \n\npara a extra\u00e7\u00e3o de caracter\u00edsticas sejam prec\u00e1rios, os agrupamentos n\u00e3o ser\u00e3o significa-\n\ntivos, o que tornaria a compara\u00e7\u00e3o entre os perfis inconsistente.  \n\n6.1 Extra\u00e7\u00e3o de Caracter\u00edsticas  \n\nEm geral, os modelos de predi\u00e7\u00e3o de carga podem ser divididos em duas categori-\n\nas (Makridakis et al., 1997): s\u00e9ries temporais, baseada somente nos valores atuais e his-\n\nt\u00f3ricos da carga, e explanat\u00f3rios, que utiliza extensivamente vari\u00e1veis extr\u00ednsecas ao \n\nsistema el\u00e9trico, tais como radia\u00e7\u00e3o solar, temperatura e outros elementos clim\u00e1ticos \n\n(Guo et al., 2004; Oliveira, 2004). Em ambos os casos, a cardinalidade do conjunto de \n\nvari\u00e1veis \u00e9 relativamente grande, facilmente excedendo uma centena. Desta forma, uma \n\nop\u00e7\u00e3o natural para a representa\u00e7\u00e3o das subesta\u00e7\u00f5es seria a aplica\u00e7\u00e3o de t\u00e9cnicas multi-\n\nvariadas como a an\u00e1lise de componentes principais (PCA), visando \u00e0 redu\u00e7\u00e3o da dimen-\n\nsionalidade. Com efeito, o emprego da PCA pode ser vantajoso na predi\u00e7\u00e3o de curto \n\nprazo (onde o per\u00edodo de predi\u00e7\u00e3o varia de poucos minutos a algumas horas adiante), tal \n\ncomo demonstrado por (Guo et al., 2004). Entretanto, dentro do escopo desse trabalho, \n\nalgumas premissas necess\u00e1rias para a obten\u00e7\u00e3o de resultados consistentes nem sempre \n\ns\u00e3o observadas nas regi\u00f5es de consumo.  \n\n\n\n 89 \n\nA carga el\u00e9trica de uma subesta\u00e7\u00e3o t\u00edpica n\u00e3o adere aos conceitos de estacionarie-\n\ndade e normalidade, que s\u00e3o pr\u00e9-requisitos \u00e0 PCA e muitas outras t\u00e9cnicas multivaria-\n\ndas. A Figura 34 mostra como a vari\u00e2ncia da carga se comporta durante o inverno em \n\num perfil de consumo urbano (centro de Florian\u00f3polis, subesta\u00e7\u00e3o Ilha-Centro).  \n\nTempo\n\n0,0065\n\n0,0067\n\n0,0070\n\n0,0073\n\n0,0075\n\n0,0077\n\n0,0080\n\n0,0083\n\nV\nar\n\ni\u00e2\nnc\n\nia\n o\n\n lo\nng\n\no \ndo\n\n t\nem\n\npo\n\n \n\nFigura 34 \u2013 N\u00e3o Estacionariedade da Carga \n\nCada ponto da curva mostrada na Figura 34 \u00e9 calculado incrementalmente; ou se-\n\nja, o primeiro valor \u00e9 a vari\u00e2ncia das primeiras m amostras, o segundo \u00e9 a vari\u00e2ncia das \n\nprimeiras m\u00d72  amostras e assim por diante. Para um sistema estacion\u00e1rio, a curva se \n\nestabilizaria, tendendo a um valor constante. Entretanto, o comportamento mostrado na \n\nfigura \u00e9 outro \u2013 a vari\u00e2ncia oscila consideravelmente ao longo do tempo sem convergir \n\npara um valor definido, o que \u00e9 t\u00edpico de sistemas n\u00e3o-estacion\u00e1rios.  \n\nPor outro lado, a normalidade do mesmo sinal \u00e9 analisada com o uso do gr\u00e1fico de \n\nprobabilidade normal mostrado na Figura 35. Uma vez que a premissa de normalidade \n\nconduz a uma s\u00e9rie infer\u00eancias que podem ser esp\u00farias caso a distribui\u00e7\u00e3o subjacente \n\nn\u00e3o se distribua normalmente (Montgomery et al., 2001), a an\u00e1lise da Figura 35 \u00e9 alta-\n\nmente significativa. Pequenos desvios da premissa de normalidade n\u00e3o afetam a aplica-\n\n\u00e7\u00e3o das t\u00e9cnicas multivariadas; entretanto, se esses desvios forem consider\u00e1veis, os re-\n\nsultados ser\u00e3o inconsistentes.  \n\n\n\n 90 \n\n0,04 0,06 0,08 0,10 0,12 0,14 0,16 0,18 0,20 0,22 0,24 0,26 0,28 0,30 0,32 0,34\n\nValor Observado\n\n-2,5\n\n-2,0\n\n-1,5\n\n-1,0\n\n-0,5\n\n0,0\n\n0,5\n\n1,0\n\n1,5\n\n2,0\n\nV\nal\n\nor\n N\n\nor\nm\n\nal\n E\n\nsp\ner\n\nad\no\n\n \n\nFigura 35 \u2013 Gr\u00e1fico de Probabilidade Normal da Carga El\u00e9trica \n\nUm gr\u00e1fico de probabilidade normal \u00e9 um diagrama de dispers\u00e3o aonde os res\u00ed-\n\nduos do sinal testado (dispers\u00e3o de cada amostra em rela\u00e7\u00e3o \u00e0 m\u00e9dia) s\u00e3o plotados con-\n\ntra os res\u00edduos esperados caso a distribui\u00e7\u00e3o fosse realmente normal. Portanto, se a \n\npremissa de normalidade for verdadeira, a curva formada se aproximar\u00e1 da identidade. \n\nNo gr\u00e1fico da Figura 35, os res\u00edduos observados da carga el\u00e9trica ativa (em azul) s\u00e3o \n\nordenados e tra\u00e7ados contra os valores esperados dos res\u00edduos considerando uma distri-\n\nbui\u00e7\u00e3o normal. Para efeitos de compara\u00e7\u00e3o, o mesmo gr\u00e1fico mostra um gabarito para o \n\npadr\u00e3o de normalidade, indicado pela reta tra\u00e7ada em vermelho. Para salientar o desvio \n\nda normalidade, a tend\u00eancia linear deste gr\u00e1fico \u00e9 removida, formando o que a literatura \n\nde nomina de probabilidade normal sem tend\u00eancias (detrended normal probability). \n\nConforme pode ser constatado pela an\u00e1lise da Figura 35, os res\u00edduos formam uma \n\ncurva acentuada, diferindo consideravelmente do padr\u00e3o esperado para a normalidade. \n\nDessa forma, n\u00e3o \u00e9 poss\u00edvel assumir que a distribui\u00e7\u00e3o dessa grandeza \u00e9 gaussiana \n\n(Montgomery et al., 2001). Essa conclus\u00e3o \u00e9 corroborada pela an\u00e1lise da Figura 36, que \n\nmostra um histograma discretizado da carga el\u00e9trica. Claramente, h\u00e1 um desvio do pa-\n\ndr\u00e3o esperado para a normalidade. \n\n \n\n\n\n 91 \n\n0,00 0,05 0,10 0,15 0,20 0,25 0,30 0,35\n\nCarga\n\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\n600\n\nN\n\u00fam\n\ner\no \n\nde\n o\n\nbs\ner\n\nva\n\u00e7\u00f5\n\nes\n\n \nFigura 36 \u2013 Histograma da Distribui\u00e7\u00e3o da Carga \n\n\u00c9 importante destacar que as n\u00e3o-idealidades mostradas nos gr\u00e1ficos das figuras \n\nFigura 34, Figura 35 e Figura 36 tamb\u00e9m se aplicam \u00e0s vari\u00e1veis preditoras. Ora, a car-\n\nga el\u00e9trica \u00e9 o resultado da contribui\u00e7\u00e3o de muitas vari\u00e1veis id\u00eantica e independente-\n\nmente distribu\u00eddas, tal como demonstrado empiricamente em Tao et al. (2004), Guo et \n\nal. (2004), Oliveira (2004) e Hong et al. (2005). Por esta raz\u00e3o, em princ\u00edpio seria espe-\n\nrada uma distribui\u00e7\u00e3o normal para a carga, tal como assegurado pelo Teorema do Limite \n\nCentral (Johnson et al., 2002). De fato, existem muitos sistemas gaussianos din\u00e2micos \n\nque apresentam um comportamento variante no tempo. Ent\u00e3o, a despeito do comporta-\n\nmento din\u00e2mico mostrado na Figura 34, a carga el\u00e9trica deveria ser distribu\u00edda normal-\n\nmente. Todavia, face o teste de normalidade da Figura 35, esta hip\u00f3tese n\u00e3o pode ser \n\naceita. \n\n\u00c9 poss\u00edvel que massas de dados maiores pudessem reproduzir um comportamento \n\nnormal. No entanto, a coleta de dados num perfil \u00e9 rigidamente limitada no tempo e no \n\nespa\u00e7o: um perfil de consumo \u00e9 transit\u00f3rio e est\u00e1 restrito a uma \u00e1rea geogr\u00e1fica bem \n\ndefinida. De todo modo, ainda que fosse poss\u00edvel empregar amostras maiores, o com-\n\nportamento din\u00e2mico destacado na Figura 34 s\u00f3 pode ser contornado mediante a utiliza-\n\n\u00e7\u00e3o de amostras menores, onde a oscila\u00e7\u00e3o da vari\u00e2ncia n\u00e3o seja expressiva (Oppe-\n\n\n\n 92 \n\nnheim et al., 1999). Isto estabelece um paradoxo que restringe a aplica\u00e7\u00e3o das t\u00e9cnicas \n\nmultivariadas normalmente empregadas em problemas correlatos. \n\nPara suplantar estas limita\u00e7\u00f5es, esta pesquisa explorou uma propriedade dos mo-\n\ndelos de regress\u00e3o (estimadores), relacionada \u00e0 sua capacidade de modelar um sistema \n\ncujas caracter\u00edsticas s\u00e3o desconhecidas a priori (Haykin, 1998). Algoritmos como o \n\nSVM (Support Vector Machine) e o backpropagation extraem conhecimento de um sis-\n\ntema atrav\u00e9s de processos iterativos que minimizam uma fun\u00e7\u00e3o de erro (Duda et al., \n\n2000; Schlkopf et al., 2001). Essas fun\u00e7\u00f5es de erro envolvem a rela\u00e7\u00e3o entre as vari\u00e1-\n\nveis de entrada e a sa\u00edda desejada, que \u00e9 espec\u00edfica para cada sistema; portanto, os esti-\n\nmadores tornam-se ad hoc, tal como uma esp\u00e9cie de assinatura do sistema.  \n\nNo presente trabalho, as entradas s\u00e3o as preditoras, a sa\u00edda \u00e9 a carga el\u00e9trica ativa \n\ne o sistema \u00e9 o perfil de consumo. Do ponto de vista conceitual, como discutido no Ca-\n\np\u00edtulo 3, estimadores e preditores s\u00e3o semelhantes. Entretanto, no contexto deste traba-\n\nlho, os preditores s\u00e3o mais custosos em termos de processamento do que os estimado-\n\nres, principalmente devido \u00e0 sele\u00e7\u00e3o de vari\u00e1veis com relev\u00e2ncia preditiva (Tao et al., \n\n2004; Oliveira, 2004; Hong et al., 2005).  \n\nSeja um determinado estimador ?x especificamente constru\u00eddo para um perfil de \n\nconsumo desconhecido ?x. Como as propriedades de ?x n\u00e3o s\u00e3o conhecidas, ?x emprega \n\ntodas as vari\u00e1veis dispon\u00edveis como entradas, raz\u00e3o pela qual \u00e9 denominado de estima-\n\ndor leigo. Como discutido no Cap\u00edtulo 1, esta abordagem acrescenta um erro \u00e0 resposta \n\ndo estimador porque somente um subconjunto de todas as vari\u00e1veis dispon\u00edveis possui \n\nrelev\u00e2ncia preditiva. Entretanto, o poder de ?x para estimar carga n\u00e3o \u00e9 o foco: o seu real \n\nobjetivo \u00e9 detectar similaridades entre os perfis de consumo, de forma que o pr\u00e9-\n\nprocessamento possa ser acelerado (Figura 33), otimizando a predi\u00e7\u00e3o de carga. Por \n\noutro lado, como \u00e9 justamente a sele\u00e7\u00e3o de par\u00e2metros que torna onerosa a constru\u00e7\u00e3o \n\nde um preditor de carga (Tao et al., 2004; Oliveira, 2004; Hong et al., 2005), os estima-\n\ndores leigos s\u00e3o computacionalmente f\u00e1ceis de serem constru\u00eddos. Desta forma, a sua \n\nexist\u00eancia torna-se amplamente justificada porque eles podem acelerar a constru\u00e7\u00e3o de \n\npreditores de carga. \n\n\n\n 93 \n\nSe ?x \u00e9 empregado para estimar a carga de outro perfil ?y e o desempenho obser-\n\nvado \u00e9 satisfat\u00f3rio, assume-se que ?x e ?y s\u00e3o similares; caso contr\u00e1rio, eles s\u00e3o dissimi-\n\nlares. Este racioc\u00ednio \u00e9 baseado no fato que um estimador, assim como um preditor, \u00e9 \n\num modelo ad hoc de um sistema \u2013 se outro sistema \u00e9 modelado pelo mesmo estimador \n\ncom um desempenho compar\u00e1vel, ent\u00e3o \u00e9 plaus\u00edvel assumir que ambos os sistemas t\u00eam \n\nalgo em comum (ou seja, s\u00e3o similares de alguma forma).  \n\nPara que este crit\u00e9rio de similaridade seja considerado v\u00e1lido dentro dos objetivos \n\ndeste trabalho, \u00e9 necess\u00e1rio comprovar que regi\u00f5es de consumo similares possuem con-\n\njuntos similares de preditoras. Isto pode ser expresso atrav\u00e9s das seguintes hip\u00f3teses:  \n\nHA \u2013 O desempenho de um conjunto de estimadores de carga el\u00e9trica, quando a-\n\nplicado a um perfil de consumo, determina um vetor de caracter\u00edsticas que o \n\nrepresenta; \n\nHB \u2013 Dois perfis de consumo cujos vetores de caracter\u00edsticas s\u00e3o similares com-\n\npartilham conjuntos semelhantes de vari\u00e1veis preditoras. \n\nA Figura 37 mostra o desempenho de um conjunto de estimadores leigos ao pro-\n\ncessar um conjunto de perfis de consumo, produzindo curvas denominadas curvas de \n\ndesempenho. Cada ponto dessas curvas \u00e9 o desempenho de um estimador ao processar \n\num perfil ou, mais precisamente, as vari\u00e1veis de entrada de um perfil. \n\n \n\n ICO_INV\n ICO_OUT\n ICO_VER\n INE_INV\n INE_OU\n INE_V ER\n ISS_INV\n ISS_OUT\n ISS_VER\n SIA_INV\n SIA_OUT\n SIA_VER\n SRA_INV\n SRA_OUT\n SRA_VER\n TDE_INV\n TDE_OUT\n TDE_VER\n\nS\nV\n\nM\n_I\n\nC\nO\n\n_I\nN\n\nV\n\nS\nV\n\nM\n_I\n\nC\nO\n\n_O\nU\n\nT\n\nS\nV\n\nM\n_I\n\nC\nO\n\n_V\nE\n\nR\n\nS\nV\n\nM\n_I\n\nN\nE\n\n_I\nN\n\nV\n\nS\nV\n\nM\n_I\n\nN\nE\n\n_O\nU\n\nT\n\nS\nV\n\nM\n_I\n\nN\nE\n\n_V\nE\n\nR\n\nS\nV\n\nM\n_I\n\nS\nS\n\n_I\nN\n\nV\n\nS\nV\n\nM\n_I\n\nS\nS\n\n_O\nU\n\nT\n\nS\nV\n\nM\n_I\n\nS\nS\n\n_V\nE\n\nR\n\nS\nV\n\nM\n_S\n\nIA\n_I\n\nN\nV\n\nS\nV\n\nM\n_S\n\nIA\n_O\n\nU\nT\n\nS\nV\n\nM\n_S\n\nIA\n_V\n\nE\nR\n\nS\nV\n\nM\n_S\n\nR\nA\n\n_I\nN\n\nV\n\nS\nV\n\nM\n_S\n\nR\nA\n\n_O\nU\n\nT\n\nS\nV\n\nM\n_S\n\nR\nA\n\n_V\nE\n\nR\n\nS\nV\n\nM\n_T\n\nD\nE\n\n_W\nIN\n\nS\nV\n\nM\n_T\n\nD\nE\n\n_A\nU\n\nT\n\nS\nV\n\nM\n_T\n\nD\nE\n\n_S\nU\n\nM\n\nEstimadores SVM\n\n-0,1\n\n0,0\n\n0,1\n\n0,2\n\n0,3\n\n0,4\n\n0,5\n\n0,6\n\n0,7\n\nD\ne\n\nse\nm\n\npe\nn\n\nho\n \n\n?  \n\n \n\nFigura 37 \u2013 Gr\u00e1fico de Desempenho de Diversos Perfis de Consumo \n\n\n\n 94 \n\nPor se basear no desempenho dos estimadores leigos, este gr\u00e1fico foi denominado \n\nde gr\u00e1fico de desempenho. No eixo das abscissas, s\u00e3o mostrados os estimadores leigos, \n\nimplementados com SVM, enquanto que o eixo das ordenadas mostra o erro m\u00e9dio \n\nquadr\u00e1tico (desempenho do estimador). Neste trabalho, o desempenho de um estimador \n\n\u00e9 definido como o erro m\u00e9dio quadr\u00e1tico (Root Mean Squared Error, RMSE) entre os \n\nvalores observados e estimados da carga. A Equa\u00e7\u00e3o 62 mostra esta defini\u00e7\u00e3o, onde ? \u00e9 \n\no RMSE, m \u00e9 o n\u00famero de observa\u00e7\u00f5es, yi \u00e9 o valor observado da carga e ?i \u00e9 o seu va-\n\nlor estimado. \n\n( )?\n=\n\n??=\nm\n\ni\nii yym\n\n1\n\n2\u02c61?  \n\nEqua\u00e7\u00e3o 62 \u2013 Desempenho de um Estimador Expresso pelo seu RMSE \n\nCada um dos estimadores leigos indicados na Figura 37 foi constru\u00eddo especifi-\n\ncamente para um dos perfis de consumo processados. Assim, espera-se que o melhor \n\ndesempenho esperado de cada estimador (ponto de m\u00ednimo da curva de desempenho) \n\nseja obtido quando ele processa o perfil para o qual foi constru\u00eddo. \n\nAs curvas de desempenho da Figura 37 se referem a 6 regi\u00f5es de consumo do es-\n\ntado de Santa Catarina, a saber: \n\na) Regi\u00e3o Trindade (TDE) \u2013 regi\u00e3o litor\u00e2nea de Florian\u00f3polis cuja carga \u00e9 mis-\n\nta (residencial e comercial). Abastece tamb\u00e9m a Universidade Federal de San-\n\nta Catarina, que \u00e9 o maior consumidor individual da ilha de Santa Catarina. \n\nb) Regi\u00e3o Ilha-Norte (INE) \u2013 regi\u00e3o norte de Florian\u00f3polis, predominantemen-\n\nte constitu\u00edda por resid\u00eancias e com\u00e9rcio de veraneio. \n\nc) Regi\u00e3o Ilha-Centro (ICO) \u2013 regi\u00e3o central de Florian\u00f3polis, constitu\u00edda por \n\ncarga predominante comercial e um pequeno percentual residencial.  \n\nd) Regi\u00e3o Itaja\u00ed-Salseiros (ISS) \u2013 regi\u00e3o litor\u00e2nea do Vale do Itaja\u00ed (cidade de \n\nItaja\u00ed), com carga residencial predominantemente unifamiliar, comercial, in-\n\ndustrial e portu\u00e1ria (porto de Itaja\u00ed). \n\n\n\n 95 \n\ne) Regi\u00e3o Sadia (SIA) \u2013 regi\u00e3o de consumo constitu\u00edda pelo transformador da \n\nsubesta\u00e7\u00e3o Conc\u00f3rdia (cidade de Conc\u00f3rdia, no oeste do estado de Santa Ca-\n\ntarina) que abastece a ind\u00fastria de alimentos Sadia S/A. \n\nf) Regi\u00e3o Seara (SRA) \u2013 regi\u00e3o de consumo do oeste de Santa Catarina (cidade \n\nde Seara), com carga residencial predominantemente unifamiliar, comercial e \n\nindustrial. \n\nEstas 6 regi\u00f5es de consumo s\u00e3o analisadas durante tr\u00eas esta\u00e7\u00f5es do ano de 2003: \n\ninverno (INV), outono (OUT) e ver\u00e3o (VER). Como geralmente cada esta\u00e7\u00e3o do ano \n\nimp\u00f5e um perfil de consumo diferente \u00e0s regi\u00f5es, elas foram divididas em 18 perfis de \n\nconsumo, representadas pelas curvas de desempenho mostradas na Figura 37: \n\nICO_INV, ICO_OUT, ICO_VER, INE_INV, INE_OUT, INE_VER, ISS_INV, \n\nISS_OUT, ISS_VER, SIA_INV, SIA_OUT, SIA_VER, SRA_INV, SRA_OUT, \n\nSRA_VER, TDE_INV, TDE_OUT e TDE_VER.  \n\nA Figura 38 mostra um diagrama esquem\u00e1tico que relaciona alguns perfis aos \n\nseus estimadores. Como cada estimador modela um perfil de consumo, \u00e9 poss\u00edvel com-\n\nparar os perfis atrav\u00e9s dos respectivos estimadores. Assim, \u00e9 o conjunto de estimadores \n\nque extrai as caracter\u00edsticas de cada perfil, permitindo o uso de um recurso geom\u00e9trico \n\npara represent\u00e1-los convenientemente: o espa\u00e7o de caracter\u00edsticas dos perfis de consu-\n\nmo. \n\n \n\nDados Amostrados\ndo Perfil 1\n\nSVM Estimador 1\n\nDados Amostrados\ndo Perfil 2\n\nSVM Estimador 2\n\nDados Amostrados\ndo Perfil 3\n\nSVM Estimador 3\n\nDados Amostrados\ndo Perfil n\n\nSVM Estimador n\n\n.\n\n.\n\n.\n\n.\n\n.\n\nExtrator de caracter\u00edsticas\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n \n\nFigura 38 \u2013 Cria\u00e7\u00e3o do Extrator de Caracter\u00edsticas Utilizando SVM \n\n\n\n 96 \n\nCada curva de desempenho da Figura 37 pode ser entendida como uma abstra\u00e7\u00e3o \n\nde um perfil de consumo, \u00fatil na determina\u00e7\u00e3o de regularidades que podem otimizar a \n\npredi\u00e7\u00e3o de carga. Como mostrado, o desempenho da estima\u00e7\u00e3o em cada perfil pode \n\nvariar bastante, de acordo com o estimador utilizado. Dentro das hip\u00f3teses enunciadas, a \n\nsimilaridade entre as regi\u00f5es de consumo \u00e9 determinada pela semelhan\u00e7a entre as envol-\n\nt\u00f3rias de suas respectivas curvas de desempenho. Considere-se, por exemplo, o caso de \n\ndois perfis que mant\u00eam grande similaridade entre si (SRA_OUT e SRA_VER) compa-\n\nrados com o caso de dois perfis dissimilares (ISS_OUT e SRA_INV).  \n\nNo primeiro caso, mostrado na Figura 39, a similaridade \u00e9 denotada por uma cor-\n\nrela\u00e7\u00e3o forte entre as curvas de desempenho. Se tra\u00e7ados num espa\u00e7o de caracter\u00edsticas, \n\nespera-se que os perfis estejam muito pr\u00f3ximos entre si. No segundo caso, mostrado na \n\nFigura 40, ocorre o inverso, sendo a dissimilaridade evidenciada pela anti-correla\u00e7\u00e3o \n\ndas curvas. Portanto, num espa\u00e7o de caracter\u00edsticas, esses perfis deveriam estar afasta-\n\ndos um do outro. \n\n \n\n-0,1\n\n0,0\n\n0,1\n\n0,2\n\n0,3\n\n0,4\n\n0,5\n\n0,6\n\nD\ne\n\nse\nm\n\npe\nn\n\nh\no \n\n? \n \n\nSRA_OUT\n\nSRA_VER\n\n \nFigura 39 \u2013 Curvas de Desempenho de Dois Perfis de Consumo Semelhantes \n\n \n\nAs curvas mostradas nos gr\u00e1ficos de desempenho s\u00e3o bastante sugestivas. Embora \n\na teoria que fundamenta a interpreta\u00e7\u00e3o desses gr\u00e1ficos seja heur\u00edstica e, portanto, de \n\ncomprova\u00e7\u00e3o emp\u00edrica, ela \u00e9 corroborada por conceitos derivados da Teoria de Apren-\n\ndizado Estat\u00edstico (Cap\u00edtulo 3) e da estat\u00edstica param\u00e9trica, como discutido a seguir. \n\n\n\n 97 \n\n-0,1\n\n0,0\n\n0,1\n\n0,2\n\n0,3\n\n0,4\n\n0,5\n\n0,6\n\nD\ne\n\nse\nm\n\npe\nn\n\nh\no \n\n? \n \n\nISS_OUT\n\nSRA_INV\n\n \nFigura 40 \u2013 Curvas de Desempenho de Dois Perfis de Consumo N\u00e3o-Semelhantes \n\nAnalisando HA \n\nPor inspe\u00e7\u00e3o, parece haver tr\u00eas ou quatro padr\u00f5es delineados na Figura 37, o que \u00e9 \n\ncorroborado pela an\u00e1lise da matriz de correla\u00e7\u00f5es dos vetores de caracter\u00edsticas de cada \n\nregi\u00e3o, mostrada na Tabela 2.  \n\nTabela 2 \u2013 Correla\u00e7\u00f5es dos Vetores de Caracter\u00edsticas de Cada Regi\u00e3o de Consumo \n\n \nICO \nINV \n\nICO\nOUT \n\nICO \nVER \n\nINE \nINV \n\nINE \nOUT \n\nINE \nVER \n\nISS \nINV \n\nISS \nOUT \n\nISS \nVER \n\nSIA \nINV \n\nSIA \nOUT \n\nSAI \nVER \n\nSRA \nINV \n\nSRA\nOUT \n\nSRA \nVER \n\nTDE \nINV \n\nTDE\nOUT \n\nTDE\nVER \n\nICO \nINV 1.00 0.98 0.88 0.95 0.92 \n\n-\n0.62 \n\n-\n0.82 \n\n-\n0.85 \n\n-\n0.89 0.95 0.95 0.95 0.94 0.94 0.95 \n\n-\n0.16 \n\n-\n0.33 \n\n-\n0.62 \n\nICO \nOUT 0.98 1.00 0.93 0.94 0.95 \n\n-\n0.54 \n\n-\n0.80 \n\n-\n0.81 \n\n-\n0.85 0.94 0.94 0.94 0.93 0.93 0.94 \n\n-\n0.14 \n\n-\n0.26 \n\n-\n0.54 \n\nICO \nVER 0.88 0.93 1.00 0.84 0.90 \n\n-\n0.35 \n\n-\n0.74 \n\n-\n0.73 \n\n-\n0.70 0.87 0.88 0.89 0.86 0.86 0.87 \n\n-\n0.12 \n\n-\n0.18 \n\n-\n0.35 \n\nINE \nINV 0.95 0.94 0.84 1.00 0.96 \n\n-\n0.42 \n\n-\n0.63 \n\n-\n0.68 \n\n-\n0.74 0.84 0.85 0.87 0.82 0.82 0.85 0.11 \n\n-\n0.09 \n\n-\n0.42 \n\nINE \nOUT 0.92 0.95 0.90 0.96 1.00 \n\n-\n0.32 \n\n-\n0.62 \n\n-\n0.64 \n\n-\n0.69 0.83 0.84 0.87 0.81 0.81 0.84 0.11 0.00 \n\n-\n0.33 \n\nINE \nVER \n\n-\n0.62 \n\n-\n0.54 \n\n-\n0.35 \n\n-\n0.42 \n\n-\n0.32 1.00 0.86 0.88 0.90 \n\n-\n0.74 \n\n-\n0.72 \n\n-\n0.67 \n\n-\n0.76 \n\n-\n0.77 \n\n-\n0.73 0.74 0.88 1.00 \n\nISS \nINV \n\n-\n0.82 \n\n-\n0.80 \n\n-\n0.74 \n\n-\n0.63 \n\n-\n0.62 0.86 1.00 0.99 0.96 \n\n-\n0.94 \n\n-\n0.93 \n\n-\n0.90 \n\n-\n0.95 \n\n-\n0.96 \n\n-\n0.94 0.68 0.76 0.86 \n\nISS \nOUT \n\n-\n0.85 \n\n-\n0.81 \n\n-\n0.73 \n\n-\n0.68 \n\n-\n0.64 0.88 0.99 1.00 0.98 \n\n-\n0.95 \n\n-\n0.94 \n\n-\n0.91 \n\n-\n0.96 \n\n-\n0.96 \n\n-\n0.95 0.64 0.76 0.88 \n\nISS \nVER \n\n-\n0.89 \n\n-\n0.85 \n\n-\n0.70 \n\n-\n0.74 \n\n-\n0.69 0.90 0.96 0.98 1.00 \n\n-\n0.95 \n\n-\n0.94 \n\n-\n0.91 \n\n-\n0.96 \n\n-\n0.97 \n\n-\n0.95 0.56 0.71 0.90 \n\nSIA \nINV 0.95 0.94 0.87 0.84 0.83 \n\n-\n0.74 \n\n-\n0.94 \n\n-\n0.95 \n\n-\n0.95 1.00 1.00 0.99 1.00 1.00 1.00 \n\n-\n0.42 \n\n-\n0.55 \n\n-\n0.74 \n\nSIA \nOUT 0.95 0.94 0.88 0.85 0.84 \n\n-\n0.72 \n\n-\n0.93 \n\n-\n0.94 \n\n-\n0.94 1.00 1.00 0.99 0.99 0.99 1.00 \n\n-\n0.40 \n\n-\n0.53 \n\n-\n0.72 \n\nSIA \nVER 0.95 0.94 0.89 0.87 0.87 \n\n-\n0.67 \n\n-\n0.90 \n\n-\n0.91 \n\n-\n0.91 0.99 0.99 1.00 0.98 0.98 0.99 \n\n-\n0.34 \n\n-\n0.47 \n\n-\n0.67 \n\nSRA \nINV 0.94 0.93 0.86 0.82 0.81 \n\n-\n0.76 \n\n-\n0.95 \n\n-\n0.96 \n\n-\n0.96 1.00 0.99 0.98 1.00 1.00 1.00 \n\n-\n0.45 \n\n-\n0.58 \n\n-\n0.77 \n\nSRA \nOUT 0.94 0.93 0.86 0.82 0.81 \n\n-\n0.77 \n\n-\n0.96 \n\n-\n0.96 \n\n-\n0.97 1.00 0.99 0.98 1.00 1.00 0.99 \n\n-\n0.46 \n\n-\n0.58 \n\n-\n0.77 \n\nSRA \nVER 0.95 0.94 0.87 0.85 0.84 \n\n-\n0.73 \n\n-\n0.94 \n\n-\n0.95 \n\n-\n0.95 1.00 1.00 0.99 1.00 0.99 1.00 \n\n-\n0.42 \n\n-\n0.54 \n\n-\n0.74 \n\nTDE \nINV \n\n-\n0.16 \n\n-\n0.14 \n\n-\n0.12 0.11 0.11 0.74 0.68 0.64 0.56 \n\n-\n0.42 \n\n-\n0.40 \n\n-\n0.34 \n\n-\n0.45 \n\n-\n0.46 \n\n-\n0.42 1.00 0.93 0.74 \n\nTDE \nOUT \n\n-\n0.33 \n\n-\n0.26 \n\n-\n0.18 \n\n-\n0.09 0.00 0.88 0.76 0.76 0.71 \n\n-\n0.55 \n\n-\n0.53 \n\n-\n0.47 \n\n-\n0.58 \n\n-\n0.58 \n\n-\n0.54 0.93 1.00 0.88 \n\nTDE \nVER \n\n-\n0.62 \n\n-\n0.54 \n\n-\n0.35 \n\n-\n0.42 \n\n-\n0.33 1.00 0.86 0.88 0.90 \n\n-\n0.74 \n\n-\n0.72 \n\n-\n0.67 \n\n-\n0.77 \n\n-\n0.77 \n\n-\n0.74 0.74 0.88 1.00 \n\n\n\n 98 \n\nNa Tabela 2, as correla\u00e7\u00f5es das curvas mostradas na Figura 39 s\u00e3o destacadas em \n\nlaranja, enquanto que as das curvas Figura 40, em verde. Basicamente, as correla\u00e7\u00f5es \n\napresentam a mesma informa\u00e7\u00e3o dos gr\u00e1ficos de desempenho na forma num\u00e9rica. \n\nConsidere-se um conjunto de regi\u00f5es de consumo ?  para o qual \u00e9 constru\u00eddo um \n\nconjunto de estimadores leigos ? , de acordo com a Equa\u00e7\u00e3o 63 e a Equa\u00e7\u00e3o 64. Em \n\nambas as equa\u00e7\u00f5es, n \u00e9 o n\u00famero total de estimadores e de regi\u00f5es, sendo que x?  \u00e9 o \n\nestimador de x?  para todo x=1, 2, ..., n.  \n \n\n[ ]n???? ,...,, 21=  \nEqua\u00e7\u00e3o 63 \u2013 Conjunto de Regi\u00f5es de Consumo \n\n \n[ ]n???? ,...,, 21=  \n\nEqua\u00e7\u00e3o 64 \u2013 Conjunto de Estimadores Leigos \n\nA Equa\u00e7\u00e3o 65 mostra yx,?  como sendo o desempenho do estimador x?  quando a-\n\nplicado \u00e0 regi\u00e3o y? . Como cada estimador \u00e9 constru\u00eddo especificamente para um perfil \n\nde consumo, espera-se que yx,?  seja m\u00ednimo quando x=y, como observado na Figura 37.  \n\n \n( )yxyx ??? =,  \n\nEqua\u00e7\u00e3o 65 \u2013 O desempenho do Estimador x?  Aplicado \u00e0 Regi\u00e3o de Consumo y?  \n\nDado o problema de obter um modelo de predi\u00e7\u00e3o w?  para w?  a partir do conjun-\n\nto de estimadores ? (definido na Equa\u00e7\u00e3o 64), seja z?  (z=1, 2, ..., n) o modelo de predi-\n\n\u00e7\u00e3o de z? , z?  o estimador de z? , zzZ ,max ?? =  o desempenho m\u00e1ximo de z?  e wz ,?  o \n\ndesempenho de z?  aplicado a w? . Seja tamb\u00e9m ???  uma constante arbitrariamente \n\npequena, utilizada na Equa\u00e7\u00e3o 66 e definida como limiar de similaridade. \n\n \n\n??? ?? max, Zwz  \n\nEqua\u00e7\u00e3o 66 \u2013 Limiar de Similaridade entre w?  e z?  \n\n\n\n 99 \n\nSe a condi\u00e7\u00e3o estabelecida na Equa\u00e7\u00e3o 66 for atendida para um determinado z, en-\n\nt\u00e3o w?  e z?  s\u00e3o consideradas similares e a constru\u00e7\u00e3o de w?  pode ser acelerada com as \n\ninforma\u00e7\u00f5es de z? . Caso contr\u00e1rio, w?  e z?  s\u00e3o dissimilares e o crit\u00e9rio \u00e9 de pouca \n\nutilidade pr\u00e1tica para este trabalho porque, embora se possa afirmar com seguran\u00e7a que \n\nw?  n\u00e3o se assemelha a z? , n\u00e3o se pode dizer com o qu\u00ea w?  se assemelha. Como con-\n\nseq\u00fc\u00eancia, n\u00e3o se disp\u00f5e de nenhuma informa\u00e7\u00e3o extra para construir w? .  \n\nDo exposto, fica estabelecida a necessidade de se utilizar mais figuras de m\u00e9rito \n\npara a an\u00e1lise, como o vetor \nn\n\ny ???  da Equa\u00e7\u00e3o 67, constitu\u00eddo pelos desempenhos do \n\nconjunto de estimadores ?  aplicado a y? . Dentro das premissas estabelecidas por HA, \n\ny? \u00e9 o vetor de caracter\u00edsticas de y?  e define sua curva de desempenho.  \n\n( )ynyyy ,,2,1 ,...,, ???=?  \nEqua\u00e7\u00e3o 67 \u2013 O Vetor de Caracter\u00edsticas da Regi\u00e3o y \n\n Tanto as curvas de desempenho como os vetores de caracter\u00edsticas representam \n\nos perfis de consumo. De fato, a similaridade entre perfis pode ser mensurado tanto pela \n\ndist\u00e2ncia entre seus vetores de caracter\u00edsticas como pela similaridade entre suas curvas \n\nde desempenho, tal como mostrado nas Figuras Figura 39 e Figura 40. Cada ponto de \n\numa curva de desempenho determina uma dimens\u00e3o do vetor de caracter\u00edsticas sendo \n\nque, no caso deste trabalho em particular, as caracter\u00edsticas s\u00e3o definidas num espa\u00e7o \n18? . A disponibilidade de mais estimadores permitiria incrementar a dimensionalidade \n\ndeste espa\u00e7o, ao mesmo tempo em que o torna menos esparso. \n\nA Figura 41 mostra como as caracter\u00edsticas de um perfil de consumo desconheci-\n\ndo s\u00e3o extra\u00eddos com o uso dos estimadores mostrados na Figura 38. Como pode ser \n\nvisto, cada caracter\u00edstica de um perfil \u00e9 extra\u00edda por um estimador, formando o vetor \n\ndescrito na Equa\u00e7\u00e3o 67. Originalmente, um perfil \u00e9 constitu\u00eddo por s\u00e9ries hist\u00f3ricas (a-\n\nmostras da carga el\u00e9trica e das vari\u00e1veis explanat\u00f3rias) representadas numa matriz de \n\nalta cardinalidade e alta dimensionalidade; ou seja, grande n\u00famero de linhas (amostras) \n\ne colunas (preditoras). A conveni\u00eancia da abordagem desenvolvida neste trabalho con-\n\nsiste justamente em representar esta estrutura complexa atrav\u00e9s de um vetor de baixa \n\n\n\n 100 \n\ndimensionalidade n .  Com o uso desta representa\u00e7\u00e3o, a compara\u00e7\u00e3o entre perfis torna-\n\nse computacionalmente trat\u00e1vel, possibilitando a realiza\u00e7\u00e3o de infer\u00eancias \u00fateis. \n\n \n\nEstimador 1 Estimador 2 Estimador 3 Estimador n................\n\nDados Amostrados\ndo Perfil \n\nDesconhecido\n\nCaracter\u00edstica \n1\n\nCarcater\u00edstica\n2\n\nCaracter\u00edstica\n3\n\nCaracter\u00edstica\nn\n\n................\n\nExtrator de caracter\u00edsticas\n\nVetor de caracter\u00edsticas\n \n\nFigura 41 \u2013 Diagrama Esquem\u00e1tico do Extrator de Caracter\u00edsticas \n\nA Tabela 3 mostra o desempenho de todos os estimadores aplicados a todas as re-\n\ngi\u00f5es de consumo, constituindo uma forma de representa\u00e7\u00e3o alternativa a gr\u00e1ficos como \n\nos da Figura 37. A diagonal principal desta tabela armazena os menores valores de cada \n\ncoluna, uma vez que nesta regi\u00e3o os \u00edndices de linha e coluna s\u00e3o iguais e, como desta-\n\ncado anteriormente, espera-se que yx,?  seja m\u00ednimo quando x = y.  \n\nTabela 3 \u2013 Desempenho de Todos os Estimadores Aplicados a Todos os Perfis de Consumo \n\n1?  2?  \n... \n\nn?  \n1,1?  2,1?  ... n,1?  \n\n1,2?  2,2?  ... n,2?  \n... ... ...  \n\n1,n?  2,n?  ... nn,?  \n\nO gr\u00e1fico da Figura 42 mostra as curvas de desempenho da Figura 37 representa-\n\ndas como vetores no espa\u00e7o de caracter\u00edsticas. Nesse espa\u00e7o, reduzido ao plano cartesi-\n\nano com o uso de escalonamento multidimensional, nota-se forma\u00e7\u00e3o de agrupamentos \n\nbem definidos e consistentes com a defini\u00e7\u00e3o intuitiva de similaridade entre perfis. Por \n\n\n\n 101 \n\nexemplo, nas \u00e1reas onde h\u00e1 sazonalidade de consumo relacionada \u00e0 temperatura, os per-\n\nfis de consumo correspondentes \u00e0s esta\u00e7\u00f5es frias (outono e inverno) est\u00e3o situados em \n\nagrupamentos diferentes da esta\u00e7\u00e3o quente (ver\u00e3o).  \n\nDiante da an\u00e1lise efetuada e da evid\u00eancia gr\u00e1fica da Figura 42, verifica-se que a \n\nhip\u00f3tese HA \u00e9 consistente, sendo aceita. Uma vez que o crit\u00e9rio de similaridade proposto \n\nparece ser adequado para representar as regi\u00f5es de consumo, resta demonstrar se os con-\n\njuntos de preditoras s\u00e3o semelhantes para regi\u00f5es da mesma classe, como asseverado \n\npor HB. \n \n\nICO_INV\n\nICO_OUT\n\nICO_VER\n\nINE_INV\n\nINE_OUT\n\nINE_VER\n\nISS_INV\n\nISS_OUT\n\nISS_VER\n\nSIA_INV\nSIA_OUT\nSIA_VER\n\nSRA_INVSRA_OUT\nSRA_VER\n\nTDE_INV\n\nTDE_OUT\n\nTDE_VER\n\n-1,0 -0,8 -0,6 -0,4 -0,2 0,0 0,2 0,4 0,6 0,8 1,0 1,2 1,4 1,6\n\nDimens\u00e3o 1\n\n-0,20\n\n-0,15\n\n-0,10\n\n-0,05\n\n0,00\n\n0,05\n\n0,10\n\n0,15\n\nD\nim\n\nen\ns\u00e3\n\no\n 2\n\n3\n\n5\n\n4\n\n2\n\n1\n\n \nFigura 42 \u2013Vetores de Caracter\u00edsticas dos Perfis de Consumo \n\n \nAnalisando HB \n\nO m\u00e9todo de extra\u00e7\u00e3o de caracter\u00edsticas descrito \u00e9 validado mediante a explora\u00e7\u00e3o \n\nde um conceito derivado da an\u00e1lise de vari\u00e2ncia (ANOVA): a variabilidade total do \n\nsistema. Como discutido no Cap\u00edtulo 1, existem muitas vari\u00e1veis dispon\u00edveis que podem \n\nestar associadas \u00e0 carga el\u00e9trica, mas em geral nem todas possuem relev\u00e2ncia preditiva. \n\nA Equa\u00e7\u00e3o 68 \u00e9 uma identidade fundamental da an\u00e1lise de vari\u00e2ncia, que mostra como \n\n\n\n 102 \n\num modelo de estima\u00e7\u00e3o explica a variabilidade de um sistema (Montgomery et al., \n\n2004). Nessa equa\u00e7\u00e3o, iy \u00e9 a sa\u00edda real do sistema (observada), iy? \u00e9 a resposta do mode-\n\nlo (estimada) e y  \u00e9 m\u00e9dia das sa\u00eddas reais.  \n\n( ) ( )iiii yyyyyy \u02c6\u02c6 ?+?=?  \nEqua\u00e7\u00e3o 68 \u2013 Variabilidade Total de um Sistema \n\nA Equa\u00e7\u00e3o 69, obtida a partir da Equa\u00e7\u00e3o 68, mostra como a variabilidade total do \n\nsistema ( ) ?\n?\n\n?\n?\n?\n\n?\n??\n\n=\n\nn\n\ni\ni yy\n\n1\n\n2\n\n depende da variabilidade explicada pelo estimador \n\n( ) ?\n?\n\n?\n?\n?\n\n?\n??\n\n=\n\nn\n\ni\ni yy\n\n1\n\n2\u02c6  e de um erro associado ( ) ?\n?\n\n?\n?\n?\n\n?\n??\n\n=\n\nn\n\ni\nii yy\n\n1\n\n2\u02c6 . Para que um estimador seja con-\n\nsiderado satisfat\u00f3rio, a variabilidade explicada por ele deve ser pr\u00f3xima \u00e0 variabilidade \n\ntotal do sistema, sem o qu\u00ea o erro torna-se inaceit\u00e1vel. \n\n( ) ( ) ( )???\n===\n\n?+?=?\nn\n\ni\nii\n\nn\n\ni\ni\n\nn\n\ni\ni yyyyyy\n\n1\n\n2\n\n1\n\n2\n\n1\n\n2 \u02c6\u02c6  \n\nEqua\u00e7\u00e3o 69 \u2013 Identidade Fundamental da An\u00e1lise de Vari\u00e2ncia \n\nUm estimador neuronal ou SVM implementa uma transforma\u00e7\u00e3o n\u00e3o-linear que \n\nassocia as vari\u00e1veis de entrada \u00e0 sa\u00edda. Se, num primeiro momento, todas as vari\u00e1veis \n\nde entrada dispon\u00edveis s\u00e3o utilizadas (ou seja, o estimador \u00e9 leigo), o mapeamento tende \n\na refor\u00e7ar a influ\u00eancia das vari\u00e1veis relevantes em detrimento das demais.  \n\nComo salientado no Cap\u00edtulo 1, a utiliza\u00e7\u00e3o de todas as vari\u00e1veis pode degradar o \n\ndesempenho do modelo, o que \u00e9 normalmente percebido como um ru\u00eddo na resposta. \n\nEntretanto, a amplitude desse ru\u00eddo diminui durante a converg\u00eancia do modelo e a con-\n\ntribui\u00e7\u00e3o das vari\u00e1veis irrelevantes torna-se menor do que a das vari\u00e1veis relevantes. \n\nIsso \u00e9 uma decorr\u00eancia do princ\u00edpio de aprendizado Hebbiano, segundo o qual ativida-\n\ndes correlacionadas refor\u00e7am sinapses ao passo que atividades n\u00e3o-correlacionadas as \n\nenfraquecem (Haykin, 1994). Dito de outra forma, o estimador leigo captura o grau de \n\nrelev\u00e2ncia das vari\u00e1veis de entrada.  \n\nDo exposto, decorre que a relev\u00e2ncia das vari\u00e1veis de entrada pode ser percebida \n\ncomo o impacto que elas t\u00eam na variabilidade total da carga el\u00e9trica. Isso significa que, \n\nquanto maior a relev\u00e2ncia de uma vari\u00e1vel, mais ela afeta a variabilidade da carga, ana-\n\n\n\n 103 \n\nlogamente ao que ocorre na An\u00e1lise de Componentes Principais, onde a propor\u00e7\u00e3o da \n\nvariabilidade devido a um fator principal determina a relev\u00e2ncia deste fator (Johnson e \n\nWichern, 2005).  \n\nEstabelecida essa rela\u00e7\u00e3o entre a variabilidade das entradas e a da carga el\u00e9trica, \n\ntorna-se poss\u00edvel extrair o grau de relev\u00e2ncia de cada vari\u00e1vel atrav\u00e9s de um teste de \n\nrelev\u00e2ncia simples, mostrado na Figura 43.  \n \n\nIN\u00cdCIO\n\nNULIFICA\u00c7\u00c3O DA\nPR\u00d3XIMA VARI\u00c1VEL\n\nFIM\n\n \n\nDEGRADA\u00c7\u00c3O DO\nDESEMPENHO?\n\nVARI\u00c1VEL\nRELEVANTE\n\nSIM\nVARI\u00c1VEL\n\nIRRELEVANTE\n\nN\u00c3O\n\n \nTODAS VARI\u00c1VEIS\n\nTESTADAS?\n\nMENSURA\u00c7\u00c3O \nDO DESEMPENHO\n\nSIM\n\nN\u00c3O\n\nCONSTRU\u00c7\u00c3O DO \nESTIMADOR LEIGO\n\n \nFigura 43 \u2013 Determina\u00e7\u00e3o da Relev\u00e2ncia Preditiva das Vari\u00e1veis Dispon\u00edveis em um Perfil \n\nO teste de relev\u00e2ncia proposto na Figura 43 se assemelha ao Descritor de Com-\n\nprimento M\u00ednimo (MDL, Minimum Descritor Length), utilizado justamente para mensu-\n\nrar a relev\u00e2ncia preditiva (Taft et al, 2005). O MDL constr\u00f3i um modelo de predi\u00e7\u00e3o \n\nsimples a partir de cada vari\u00e1vel dispon\u00edvel. Uma vez criados, esses modelos s\u00e3o com-\n\nparados e ordenados de acordo com a sua simplicidade algor\u00edtmica e com o grau de \n\ncompress\u00e3o obtido. Esta estrat\u00e9gia, que premia a simplicidade em detrimento da com-\n\nplexidade, \u00e9 adotada para evitar o super ajuste (over-fitting) (Grunwald, 2005).  \n\nA Equa\u00e7\u00e3o 70 mostra a complexidade algor\u00edtmica (complexidade de Kolmogorov) \n\nde um modelo MDL, denotada por ( )Dh,? , onde h \u00e9 o modelo, D \u00e9 a carga el\u00e9trica e \nDh \u00e9 a carga el\u00e9trica como descrita por h. O objetivo \u00e9 validar os modelos onde cujas \n\ncomplexidades sejam baixas em rela\u00e7\u00e3o aos demais, permitindo identificar quais vari\u00e1-\n\nveis possuem alto potencial preditivo (Duda, 2001).   \n\n( ) ( ) ( )hDhDh ?+?=? ,  \nEqua\u00e7\u00e3o 70 \u2013 Complexidade de Kolmogorov de Acordo com o MDL \n\n\n\n 104 \n\nNesta pesquisa, o MDL produziu uma classifica\u00e7\u00e3o consistente das vari\u00e1veis, i-\n\ndentificando quais eram relevantes e quais eram irrelevantes. Entretanto, para validar \n\nHB, n\u00e3o \u00e9 suficiente saber se a vari\u00e1vel testada \u00e9 relevante ou n\u00e3o, mas sim o qu\u00e3o rele-\n\nvante uma vari\u00e1vel \u00e9. Embora o MDL atribua graus de relev\u00e2ncia para cada vari\u00e1vel \n\n(Taft et al, 2005), a an\u00e1lise de agrupamentos conduzida com estes valores n\u00e3o gerou os \n\nagrupamentos esperados. A conclus\u00e3o que se chegou \u00e9 que o MDL n\u00e3o fornece a preci-\n\ns\u00e3o requerida para este tipo de an\u00e1lise.  \n\nPara contornar este fato e validar HB, a concep\u00e7\u00e3o do MDL foi alterada, utilizando \n\no procedimento mostrado na Figura 43. Ao inv\u00e9s de criar um preditor para cada vari\u00e1vel \n\ndispon\u00edvel, a id\u00e9ia \u00e9 construir um \u00fanico estimador leigo e verificar seu desempenho \n\nquando a vari\u00e2ncia de cada uma de suas entradas \u00e9 anulada, uma por vez. Anular a vari-\n\n\u00e2ncia significa cancelar a dispers\u00e3o em torno da m\u00e9dia, atribuindo um valor constante a \n\ncada vari\u00e1vel. Se, nessas condi\u00e7\u00f5es, o desempenho do modelo se degradar significati-\n\nvamente, a vari\u00e1vel testada \u00e9 relevante; caso contr\u00e1rio, \u00e9 irrelevante. De toda forma, o \n\ngrau de relev\u00e2ncia dessa vari\u00e1vel fica associado a um n\u00famero real \u2013 o desempenho as-\n\nsim obtido. \n\nOra, as vari\u00e1veis de entrada s\u00e3o comuns a todas as regi\u00f5es de consumo. Uma vez \n\nque o teste descrito atribui um fator de relev\u00e2ncia preditiva a cada vari\u00e1vel, \u00e9 poss\u00edvel \n\nformar um espa\u00e7o geom\u00e9trico, denominado espa\u00e7o causal, onde os eixos coordenados \n\nrepresentam a relev\u00e2ncia de cada vari\u00e1vel. Quando representadas neste espa\u00e7o, os perfis \n\nde consumo cujos conjuntos de relev\u00e2ncia preditiva sejam semelhantes tendem a se a-\n\ngrupar. Em outras palavras, regi\u00f5es cujas vari\u00e1veis apresentam graus de relev\u00e2ncia se-\n\nmelhantes formam agrupamentos.  \n\nA Figura 44 \u00e9 uma representa\u00e7\u00e3o de baixa resolu\u00e7\u00e3o (obtida por escalonamento \n\nmultidimensional) do espa\u00e7o causal, onde s\u00e3o tra\u00e7ados os vetores de cada perfil de con-\n\nsumo visualizado na Figura 37. Verifica-se a forma\u00e7\u00e3o de agrupamentos n\u00edtidos e bem \n\ndistribu\u00eddos, al\u00e9m de um fen\u00f4meno muito interessante: os agrupamentos formados, des-\n\ntacados com elipses, s\u00e3o os mesmos da Figura 42. Isso comprova que perfis similares de \n\nacordo com o crit\u00e9rio estabelecido por HA compartilham as mesmas vari\u00e1veis predito-\n\nras. Diante desta evid\u00eancia, se aceita HB.  \n \n\n\n\n 105 \n\nICO_INV\n\nICO_OUT\n\nICO_VER\n\nINE_INV\n\nINE_OUT\n\nINE_VER\n\nISS_INV\nISS_OUT\n\nISS_VER\n\nSIA_INV\n\nSIA_OUT\n\nSIA_VER\n\nSRA_INV\n\nSRA_OUT\n\nSRA_VER\nTDE_INV\n\nTDE_OUT\n\nTDE_VER\n\n-1,5 -1,0 -0,5 0,0 0,5 1,0 1,5 2,0\n\nDimens\u00e3o 1\n\n-1,4\n\n-1,2\n\n-1,0\n\n-0,8\n\n-0,6\n\n-0,4\n\n-0,2\n\n0,0\n\n0,2\n\n0,4\n\n0,6\n\n0,8\n\n1,0\n\nD\nim\n\nen\ns\u00e3\n\no\n 2 1\n\n3\n\n5\n\n2\n\n4\n\n \nFigura 44 \u2013 Semelhan\u00e7a entre as Preditoras dos Perfis de Consumo \n\n6.2 Algoritmo de classifica\u00e7\u00e3o \n\nA Figura 42 mostra de forma inequ\u00edvoca a forma\u00e7\u00e3o de agrupamentos, represen-\n\ntados no plano cartesiano. Embora essa seja uma comodidade geom\u00e9trica, relacionada \n\n\u00e0s limita\u00e7\u00f5es gr\u00e1ficas de representa\u00e7\u00e3o, ela mostra como a classifica\u00e7\u00e3o pode ser feita \n\ndiretamente mediante a aplica\u00e7\u00e3o de crit\u00e9rios topol\u00f3gicos relacionados \u00e0 dist\u00e2ncia eu-\n\nclidiana: membros de uma classe est\u00e3o mais pr\u00f3ximos do centr\u00f3ide de sua classe do que \n\nde outros centr\u00f3ides.  \n\nComo o espa\u00e7o \u00e9 bastante esparso, trata-se de uma aplica\u00e7\u00e3o t\u00edpica para t\u00e9cnicas \n\nde agrupamento convencionais. Neste trabalho, foi utilizado o k-means, que identificou \n\nos mesmos agrupamentos visualizados nos espa\u00e7os de baixa resolu\u00e7\u00e3o da Figura 42.  \n\n \n\n\n\n 106 \n\n6.3 RESULTADOS \n\nPara validar as t\u00e9cnicas propostas, diversos preditores neuronais puros foram cria-\n\ndos para os perfis visualizados nas Figuras Figura 37 e Figura 42. Como o objetivo das \n\nexperi\u00eancias n\u00e3o \u00e9 propor novos modelos de predi\u00e7\u00e3o, mas sim otimiz\u00e1-los, os predito-\n\nres criados s\u00e3o b\u00e1sicos; isto \u00e9, n\u00e3o cont\u00e9m a sofistica\u00e7\u00e3o de modelos como o PCarga \n\n(Oliveira, 2004)  ou o SPDS (Guo et al., 2004). Especificamente, foram criadas RNAs \n\najustadas atrav\u00e9s de gradiente descendente com taxa de momento e passo vari\u00e1vel de \n\naprendizado. A estrat\u00e9gia de predi\u00e7\u00e3o para estes modelos foi a malha de atraso, como \n\nrecomendado em Berry et al.  (2004), Duda et al. (2001) e Haykin (1994). A Figura 45 \n\nmostra o diagrama dos preditores criados, enfatizando o emprego da malha de atraso. \n\n \n\nFigura 45 \u2013 Preditores Neuronais Criados para Validar a Otimiza\u00e7\u00e3o \n\nA simplicidade dos preditores criados nestas experi\u00eancias n\u00e3o afeta a generalidade \n\nda concep\u00e7\u00e3o \u2013 a meta \u00e9 determinar uma regra de similaridade entre perfis de consumo \n\ndiferentes. A partir da\u00ed, decorre que o conhecimento utilizado para criar o preditor de \n\num deles pode ser utilizado para acelerar a constru\u00e7\u00e3o de um preditor para o outro. As-\n\nsim, em princ\u00edpio, n\u00e3o \u00e9 relevante considerar as estruturas preditoras utilizadas.  \n\nAs simula\u00e7\u00f5es consideraram um hist\u00f3rico de 5 horas para predizer a carga meia \n\nhora adiante. Se, neste cen\u00e1rio, for poss\u00edvel demonstrar que \u00e9 poss\u00edvel reciclar o conhe-\n\ncimento incorporado em preditores consolidados, espera-se obter resultados semelhan-\n\ntes em outras situa\u00e7\u00f5es. Para que a otimiza\u00e7\u00e3o pudesse ser realizada, o extrator de carac-\n\nter\u00edsticas mostrado na Figura 41 foi implementado utilizando os mesmos estimadores \n\nleigos empregados para gerar o gr\u00e1fico de desempenho da Figura 37.  \n\n\n\n 107 \n\nComo os modelos de predi\u00e7\u00e3o neuronais possuem um forte componente estoc\u00e1sti-\n\nco (a inicializa\u00e7\u00e3o dos par\u00e2metros livres), o tempo de converg\u00eancia pode se alterar subs-\n\ntancialmente de uma simula\u00e7\u00e3o para outra. Por esta raz\u00e3o, foram constru\u00eddos 20 predito-\n\nres para cada perfil, sendo considerados os tempos de converg\u00eancia m\u00ednimo (MINTC), \n\nm\u00e1ximo (MAXTC) e m\u00e9dio (AVGTC), mostrados na Tabela 4. Inicialmente, os 20 pre-\n\nditores foram constru\u00eddos para cada perfil sem utilizar nenhum conhecimento a priori. \n\nDado a aus\u00eancia de conhecimento pr\u00e9vio, a constru\u00e7\u00e3o destes preditores demandou um \n\ncusto computacional relativamente alto. Todos os vetores de caracter\u00edsticas e os predito-\n\nres gerados foram armazenados na Base de Conhecimento para subsidiar a constru\u00e7\u00e3o \n\nde novos preditores.  \n\nSubseq\u00fcentemente, os perfis foram comparados uns com os outros atrav\u00e9s de seus \n\nvetores de caracter\u00edsticas (Figura 42). Para um dado perfil ?a (coluna Perfil na Tabela 4), \n\nfoi determinado o perfil ?b (Perfil-S) que mais lhe assemelhava atrav\u00e9s da dist\u00e2ncia Eu-\n\nclidiana no espa\u00e7o de caracter\u00edsticas. Ap\u00f3s a compara\u00e7\u00e3o, a RNA que convergiu mais \n\nr\u00e1pido para ?b foi recuperada da Base de Conhecimento e retreinada com os dados de ?a, \n\nproduzindo uma nova RNA denominada RNA otimizada. Como pode ser observado na \n\nTabela 4, a RNA otimizada convergiu mais r\u00e1pido do que o tempo m\u00e9dio original \n\n(AVGTC) de ?a, como indicado pela coluna OTC (tempo de converg\u00eancia otimizado).  \n\nTabela 4 \u2013 Tempos de Converg\u00eancia para Gerar Modelos Preditores com e sem Otimiza\u00e7\u00e3o \n\n Perfil MINTC MAXTC AVGTC Perfil-S OTC Ganho OTC% \n1 ICO_INV 615.6 1272.8 1022.9 ICO_OUT 621.5 401.4 39.2% \n2 ICO_OUT 1056.5 1661.7 1350.5 ICO_INV 951.1 399.4 29.6% \n3 ICO_VER 1336.4 1696.5 1530.9 ICO_OUT 1509.0 21.9 1.4% \n4 INE_INV 91.6 194.5 123.9 INE_OUT 88.3 35.6 28.7% \n5 INE_OUT 120.9 212.1 175.0 INE_INV 57.4 117.7 67.2% \n6 INE_VER 87.7 173.8 128.2 TDE_VER 61.2 67.0 52.2% \n7 ISS_INV 60.8 155.6 106.2 ISS_OUT 29.9 76.3 71.9% \n8 ISS_OUT 113.4 220.0 165.1 ISS_INV 27.5 137.6 83.3% \n9 ISS_VER 62.1 89.0 72.7 ISS_OUT 31.8 40.9 56.2% \n10 SIA_INV 141.3 199.5 162.2 SIA_OUT 50.0 112.2 69.2% \n11 SIA_OUT 129.0 185.9 156.0 SIA_INV 56.5 99.5 63.8% \n12 SIA_VER 93.4 211.8 142.8 SIA_OUT 58.4 84.5 59.1% \n13 SRA_INV 141.8 258.3 190.7 SRA_OUT 86.7 104.0 54.5% \n14 SRA_OUT 102.4 186.5 163.6 SRA_INV 56.9 106.6 65.2% \n15 SRA_VER 97.9 178.6 132.0 SIA_INV 61.5 70.4 53.4% \n16 TDE_INV 84.3 139.4 106.7 TDE_OUT 59.3 47.4 44.4% \n17 TDE_OUT 93.8 128.8 113.4 TDE_INV 30.7 82.7 72.9% \n18 TDE_VER 91.5 341.2 153.4 INE_VER 47.7 105.7 68.9% \n\nM\u00e9dias 251.1 417.0 333.1  215.9 117.3 54.51% \n\n\n\n 108 \n\nPara efeitos de compara\u00e7\u00e3o, a Tabela 4 mostra tamb\u00e9m a rela\u00e7\u00e3o entre o tempo \n\nm\u00e9dio de converg\u00eancia e o TMCO (OTC%), definido na Equa\u00e7\u00e3o 71. Como mostrado, \n\no tempo otimizado \u00e9 sempre uma fra\u00e7\u00e3o do tempo m\u00e9dio de converg\u00eancia, validando a \n\nsolu\u00e7\u00e3o desenvolvida e comprovando experimentalmente as hip\u00f3teses HA e HB. \n\nAVGTC\nOTCAVGTC\n\nOTC\n?\n\n=%  \n\nEqua\u00e7\u00e3o 71 \u2013 Normaliza\u00e7\u00e3o do Tempo Otimizado de Converg\u00eancia \n\n \nA m\u00e9dia dos resultados obtidos foi inclu\u00edda na Tabela 4. Esta agrega\u00e7\u00e3o mostra \n\nque, em m\u00e9dia, os tempos de converg\u00eancia s\u00e3o sensivelmente reduzidos com o uso da \notimiza\u00e7\u00e3o, comprovando a viabilidade da abordagem. \n\n\n\n 109 \n\n7 DISCUSS\u00d5ES E CONCLUS\u00c3O \n\nO Cap\u00edtulo 6 mostra que a t\u00e9cnica de otimiza\u00e7\u00e3o desenvolvida reduz substancial-\n\nmente o tempo de aprendizado dos modelos preditores gerados. O tempo exigido para \n\ncriar os estimadores leigos que geram o espa\u00e7o de caracter\u00edsticas n\u00e3o foi considerado \n\nporque, uma vez criados, eles s\u00e3o armazenados na Base de Conhecimento e utilizados \n\nsempre que necess\u00e1rio. Al\u00e9m disso, o esfor\u00e7o necess\u00e1rio tanto para cri\u00e1-los como para \n\nutiliz\u00e1-los \u00e9 desprez\u00edvel. Desta forma, o m\u00e9todo criado torna-se uma abordagem real\u00eds-\n\ntica para otimizar a predi\u00e7\u00e3o de carga de curto prazo . \n\nO m\u00e9todo de otimiza\u00e7\u00e3o discutido no Cap\u00edtulo 6 n\u00e3o substitui os m\u00f3dulos de pr\u00e9-\n\nprocessamento utilizados em trabalhos de predi\u00e7\u00e3o de carga como os propostos por Guo \n\n(2004), Tao (2004), Oliveira (2004) ou Hong (2005). Este m\u00e9todo otimiza uma estrat\u00e9-\n\ngia de pr\u00e9-processamento fornecendo dados refinados, extra\u00eddos de modelos preditores \n\nconsolidados. Com isso, \u00e9 poss\u00edvel fornecer um conjunto inicial de preditoras para o \n\nm\u00f3dulo de pr\u00e9-processamento, ou fazer com que os novos modelos sejam constru\u00eddos a \n\npartir de modelos j\u00e1 existentes. Em ambos os casos, o pr\u00e9-processamento \u00e9 iniciado a \n\npartir de um conhecimento a priori, restringindo o espa\u00e7o de busca de uma solu\u00e7\u00e3o \u00f3ti-\n\nma.  \n\n\u00c9 preciso considerar que os preditores de carga utilizados na Tabela 4 (Cap\u00edtulo 6) \n\nn\u00e3o s\u00e3o preditores reais, mas operam sob condi\u00e7\u00f5es relaxadas, adotadas para viabilizar \n\nos experimentos. Isso significa que a precis\u00e3o das predi\u00e7\u00f5es \u00e9 mais baixa do que a ne-\n\ncess\u00e1ria para opera\u00e7\u00e3o em campo. Embora as regularidades mostradas na Figura 42 re-\n\npresentem t\u00e3o somente os perfis de consumo, sem fazer considera\u00e7\u00f5es sobre a arquitetu-\n\nra do preditor que possa ser neles empregado, o fato \u00e9 que n\u00e3o foram conduzidos testes \n\ncom preditores reais, onde \u00e9 necess\u00e1rio determinar a relev\u00e2ncia preditiva das vari\u00e1veis \n\nde entrada. Desta forma, a aplica\u00e7\u00e3o das t\u00e9cnicas de otimiza\u00e7\u00e3o em condi\u00e7\u00f5es reais \n\npermanece como um aspecto em aberto, a ser explorado em trabalhos futuros. \n\nAlgumas experi\u00eancias conduzidas com a Base de Conhecimento revelaram um fe-\n\nn\u00f4meno interessante: o grau de similaridade entre os perfis de consumo s\u00f3 \u00e9 consistente \n\n\n\n 110 \n\nquando a dist\u00e2ncia entre eles no espa\u00e7o de caracter\u00edsticas \u00e9 relativamente pequena. Caso \n\ncontr\u00e1rio, a similaridade n\u00e3o ser\u00e1 semanticamente significativa e conduzir\u00e1 a conclus\u00f5es \n\nesp\u00farias. Como conseq\u00fc\u00eancia, a constru\u00e7\u00e3o de um modelo preditor s\u00f3 pode ser otimiza-\n\nda quando o perfil em quest\u00e3o pertencer a alguma classe (agrupamento) existente. De \n\nfato, o \u00fanico agrupamento com uma \u00fanica amostra (agrupamento 1, composto pelo per-\n\nfil ICO_VER) apresenta um ganho muito modesto com a otimiza\u00e7\u00e3o \u2013 apenas 1.4%, \n\ncomo mostrado na Tabela 4. Por outro lado, os maiores ganhos foram observados nos \n\nagrupamentos onde os perfis estavam mais pr\u00f3ximos entre si; por exemplo, o preditor \n\nde ISS_OUT, quando iniciado a partir do modelo criado para ISS_INV, apresentou um \n\nganho de 83,3%.  \n\nO fen\u00f4meno descrito est\u00e1 consistente com a informa\u00e7\u00e3o fornecida pela Figura 42, \n\ncujas categorias (destacadas por elipses) s\u00e3o correspondentes \u00e0s categorias visualizadas \n\nna Figura 44. Entretanto, a disposi\u00e7\u00e3o entre os agrupamentos \u00e9 diferente em ambas as \n\nfiguras. A t\u00edtulo de exemplo, considere-se o caso do agrupamento 3 que na Figura 42 \n\nest\u00e1 mais pr\u00f3ximo do agrupamento 5 do que na Figura 44. Nesta \u00faltima figura, \u00e9 o a-\n\ngrupamento 4 que est\u00e1 mais pr\u00f3ximo do 3.  \n\nA falta de uma rela\u00e7\u00e3o rigorosa entre o grau de similaridade e o tempo de conver-\n\ng\u00eancia otimizado para todos os perfis evidencia uma limita\u00e7\u00e3o do m\u00e9todo proposto: o \n\nespa\u00e7o de caracter\u00edsticas revela tend\u00eancias e n\u00e3o determinismos, ao contr\u00e1rio do que \n\numa m\u00e9trica rigorosa de similaridade (a dist\u00e2ncia euclidiana) poderia talvez sugerir. \n\nEntretanto, conforme demonstrado no Cap\u00edtulo 6, essas tend\u00eancias s\u00e3o tanto mais preci-\n\nsas quanto menores forem as dist\u00e2ncias observadas entre os perfis. Ora, se a Base de \n\nConhecimento for povoada com uma grande quantidade de dados, o espa\u00e7o de caracte-\n\nr\u00edsticas se torna menos esparso. Desta forma, a dist\u00e2ncia de um perfil desconhecido ao \n\nagrupamento mais pr\u00f3ximo ser\u00e1 sempre relativamente pequena e o m\u00e9todo conduzir\u00e1 a \n\nalgum ganho no pr\u00e9-processamento. \n\nOs resultados emp\u00edricos obtidos indicam que a perda de precis\u00e3o do crit\u00e9rio de \n\nsimilaridade fora dos agrupamentos poderia ser atenuada aumentando a dimensionali-\n\ndade do espa\u00e7o de caracter\u00edsticas. Entretanto, como a massa de dados dispon\u00edvel para \n\nesta pesquisa era restrita, n\u00e3o foi poss\u00edvel testar essa hip\u00f3tese. \n\n\n\n 111 \n\nExistem outras quest\u00f5es relativas \u00e0 extra\u00e7\u00e3o de caracter\u00edsticas. Primeiro, a extra-\n\n\u00e7\u00e3o \u00e9 realizada atrav\u00e9s de estimadores (leigos) para otimizar a constru\u00e7\u00e3o de estimado-\n\nres. Ora, em princ\u00edpio seria poss\u00edvel empregar diretamente os preditores armazenados \n\nna Base de Conhecimento para gerar as curvas de desempenho e os vetores de caracte-\n\nr\u00edsticas. Entretanto, os preditores utilizam somente as vari\u00e1veis relevantes (Tao et al., \n\n2004; Oliveira, 2004; Hong et al., 2005). Dado que as preditoras de regi\u00f5es similares \n\npodem ser ligeiramente diferentes, o uso de preditores para extrair caracter\u00edsticas pode-\n\nria tornar a compara\u00e7\u00e3o tendenciosa. De fato, a raz\u00e3o de ser dos estimadores leigos \n\n(descritos no Cap\u00edtulo 5) \u00e9 extrair as caracter\u00edsticas dos perfis considerando todas as \n\nvari\u00e1veis dispon\u00edveis. Como o Cap\u00edtulo 6 destaca, esta estrat\u00e9gia produziu uma classifi-\n\nca\u00e7\u00e3o coerente dos perfis de consumo.  \n\nSegundo, os gr\u00e1ficos obtidos nas figuras Figura 42 e Figura 44 s\u00e3o obtidos com \n\nestimadores leigos SVM. Gr\u00e1ficos an\u00e1logos obtidos com estimadores neuronais n\u00e3o \n\nformaram padr\u00f5es t\u00e3o claros. Isto \u00e9 intr\u00ednseco \u00e0s RNAs, que possuem um forte fator \n\nestoc\u00e1stico associado (a inicializa\u00e7\u00e3o dos par\u00e2metros livres), a despeito de uma regra de \n\naprendizado definida rigorosamente (o gradiente descendente e suas varia\u00e7\u00f5es) (Haykin, \n\n1998). Por outro lado, o SVM calcula o risco m\u00e1ximo (erro) esperado no conjunto de \n\ntreinamento e limita-o tanto quanto poss\u00edvel (Schlkopf et al., 2001). Isto resulta em um \n\npoder de generaliza\u00e7\u00e3o maior e define padr\u00f5es semanticamente consistentes como os \n\nmostrados nas figuras Figura 42 e Figura 44. \n\n \n\n\n\n 112 \n\n8 REFER\u00caNCIAS \n\n[1]  Meyer, 1971 - Meyer, H. W. A HISTORY OF ELECTRICITY AND \nMAGNETISM. ISBN: 026213070X. The MIT Press, 1971 \n\n[2]  Steinbruch, 1987 et al.  - Steinbruch, A., Winterle, P. \u00c1LGEBRA LINEAR. ISBN: \n0074504126. Makron; 2a. edi\u00e7\u00e3o, 1987 \n\n[3]  Makridakis et al., 1997 - Makridakis, S. G., Wheelwright, S. C., Hyndman, R. J. \nFORECASTING: METHODS AND APPLICATIONS. ISBN: 0471532339. Wiley; \n3 edition, 1997 \n\n[4]  Haykin, 1998  - Haykin, S. NEURAL NETWORKS. ISBN: 0132733501 Pren-\ntice Hall; 2nd edition, 1998 \n\n[5]  Vapnik, 1998 - Vapnik, V. N.  STATISTICAL LEARNING THEORY ISBN: \n0471030031. Wiley-Interscience; 1998 \n\n[6]  Oppenheim et al., 1999 - Oppenheim, A. V., Schafer, R. W., Buck, J. R. \nDISCRETE-TIME SIGNAL PROCESSING. ISBN: 0137549202. Prentice Hall; \n2nd edition, 1999 \n\n[7]  Vapnik, 1999 - Vapnik, V. N. THE NATURE OF STATISTICAL LEARNING \nTHEORY. ISBN: 0387987800. Springer; 2nd edition, 1999 \n\n[8]  Duda et al., 2000 - Duda, R. O., Hart, P. E., Stork, D. G. PATTERN \nCLASSIFICATION. ISBN: 0471056693. Wiley-Interscience; 2nd edition, 2000 \n\n[9]  Cristiani, 2001 - Cristianini, N., Shawe-Taylor, J. AN INTRODUCTION TO \nSUPPORT VECTOR MACHINES AND OTHER KERNEL-BASED LEARNING \nMETHODS. ISBN: 0521780195. Cambridge University Press; 2000 \n\n[10]  Schlkopf et al., 2001 - Schlkopf, B., Smola, A. LEARNING WITH KERNELS - \nSUPPORT VECTOR MACHINES, REGULARIZATION, OPTIMIZATION, AND \nBEYOND. ISBN: 0262194759. MIT Press; 2001 \n\n[11]  Montgomery et al., 2001 - Montgomery, D. C., Peck, E. A., Vining, G. \nINTRODUCTION TO LINEAR REGRESSION ANALYSIS. ISBN: 0471315656. \nWiley-Interscience; 3rd edition, 2001 \n\n[12]  Herbrich, 2001 - Herbrich, R. LEARNING KERNEL CLASSIFIERS: THEORY \nAND ALGORITHMS. ISBN: 026208306X. MIT Press, 2001 \n\n[13]  Hand et al., 2001 - Hand, D. J., Mannila, H., Smyth, P. PRINCIPLES OF \nDATA MINING. ISBN: 026208290X. MIT Press, 2001 \n\n[14]  Johnson et al., 2002 - Johnson, R. A., Wichern, D. W. APPLIED \nMULTIVARIATE STATISTICAL ANALYSIS. ISBN: 0130925535. Prentice Hall; \n\n\n\n 113 \n\n5th edition, 2002 \n\n[15]  Acha et al., 2002  - Acha, E., Agelidis, V., Anaya, O., Miller, T. J. E. POWER \nELECTRONIC CONTROL IN ELECTRICAL SYSTEMS. ISBN: 0750651261. \nNewnes; 2002 \n\n[16]  Rencher, 2002 - Rencher, A. C. METHODS OF MULTIVARIATE ANALYSIS. \nISBN: 0471418897. John Wiley &amp; Sons, 2002 \n\n[17]  Santoso et al., 2002  Santoso, S., Beaty, H. W., Dugan, R. C., McGranaghan, \nM. M. ELECTRICAL POWER SYSTEMS QUALITY. ISBN: 007138622X. \nMcGraw-Hill Professional; 2 edition, 2002 \n\n[18]  Hastie et al., 2003 - Hastie, T., Tibshirani, R., Friedman, J. H. THE \nELEMENTS OF STATISTICAL LEARNING. ISBN: 0387952845. Springer; \n2003 \n\n[19]  Iyer et al., 2003 - Iyer, V., Fung, C.C., Gedeon, T. A FUZZY NEURAL \nAPPROACH TO ELECTRICITY LOAD AND SPOT-PRICE FORECASTING IN \nA DEREGULATED ELECTRICITY MARKET. TENCON 2003. Conference on \nConvergent Technologies for Asia-Pacific Region, Volume: 4, On page(s): 1479- \n1482 Vol.4 ISBN: 0-7803-8162-9; Oct. 2003 \n\n[20]  Halliday et al., 2004 - Halliday, D., Resnick, R., Walker, J. FUNDAMENTALS \nOF PHYSICS. ISBN: 0471216437. Wiley; 7th edition, 2004 \n\n[21]  Tao et al., 2004 - Tao, X., Renmu, H., Peng, W., Dongjie, X. INPUT \nDIMENSION REDUCTION FOR LOAD FORECASTING BASED ON SUPPORT \nVECTOR MACHINES. Electric Utility Deregulation, Restructuring and Power \nTechnologies, 2004. (DRPT 2004). Proceedings of the 2004 IEEE International \nConference on Electric Utility Deregulation, Restructuring and Power Technolo-\ngies, Volume 2, On Page(s): 510 - 514 Vol.2; April 2004 \n\n[22]  Guo et al., 2004 - Guo, X., Chen, Z., Ge, H., Liang, Y. SHORT-TERM LOAD \nFORECASTING USING NEURAL NETWORK WITH PRINCIPAL \nCOMPONENTS ANALYSIS. Proceedings of the Third International Conference \non Machine Learning and Cybernetics, Volume 6, On Page(s): 3365 - 3369 vol.6; \nAug. 2004 \n\n[23]  Oliveira, 2004 - Oliveira, C. M. MODELO ADAPTATIVO PARA PREVIS\u00c3O \nDE CARGA ATIVA DE CURTO PRAZO. Tese de Doutorado, Depto. de Engenha-\nria de Produ\u00e7\u00e3o \u2013 Universidade Federal de Santa Catarina, 2004 \n\n[24]  Pindyck et al., 2004 - Pindyck, R. S., Rubinfield, D. L. ECONOMETRIA: \nMODELOS &amp; PREVIS\u00d5ES.  ISBN: 8535213430. Campus; 4\u00aa  Edi\u00e7\u00e3o, 2004 \n\n[25]  Berry et al., 2004 - Berry, M. J. A, Linoff G. S. DATA MINING \nTECHNIQUES: FOR MARKETING, SALES, AND CUSTOMER RELATIONSHIP \nMANAGEMENT. ISBN: 0471470643. Wiley Publishing; 2nd edition, 2004 \n\n\n\n 114 \n\n[26]  Pansini, 2005 - Pansini, A. J. GUIDE TO ELECTRICAL POWER \nDISTRIBUTION SYSTEMS. ISBN: 084933666X. CRC; 6th edition, 2005 \n\n[27]  Grunwald, 2005 - Grunwald, P. D. (ed.), Myung, I. J.(ed.), Pitt, M. A. (ed.):  \nADVANCES IN MINIMUM DESCRIPTION LENGTH: THEORY AND \nAPPLICATIONS. ISBN: 0262072629. MIT; 2005 \n\n[28]  Taft et al., 2005 - Taft, M., Krishnan R., Hornick, M., Muhkin, D., Tang, G., \nThomas, S., Stengard, P. ORACLE DATA MINING CONCEPTS . Part no: \nB14339-01. Oracle Press; 2005 \n\n[29]  Hong et al., 2005 - Hong, W., Pai, P., Chen, C., Lin, C. ELECTRICITY \nLOAD FORECASTING BY USING SUPPORT VECTOR MACHINES WITH \nSIMULATED ANNEALING ALGORITHM. Proceedings on the 17th IMACS \nWorld Congress Scientific Computation, Applied Mathematics and Simulation, \nParis, France; July 2005 \n\n[30]  Niu et al., 2005 - Niu, D., Wang, Q., Li, J. SHORT TERM LOAD \nFORECASTING MODEL USING SUPPORT VECTOR MACHINE BASED ON \nARTIFICIAL NEURAL NETWORK. Proceedings of the Fourth International Con-\nference on Machine Learning and Cybernetics, Volume 7, On Page(s): 4260 - \n4265 Vol. 7; Aug. 2005 \n\n[31]  Guo et al., 2006  Guo, Y., Niu, D., Chen,Y. SUPPORT VECTOR MACHINE \nMODEL IN ELECTRICITY LOAD FORECASTING. Proceedings of the Fifth In-\nternational Conference on Machine Learning and Cybernetics, Dalian, 13-16 Au-\ngust; Aug. 2006 \n\n\n\n 115 \n\n9 ANEXOS \n\n9.1 Vari\u00e1veis dispon\u00edveis para a predi\u00e7\u00e3o de carga \n\nOs tempos dados em minutos se referem ao hor\u00e1rio em que a medi\u00e7\u00e3o for efetuada, por exemplo: \n\u2022 Derivada 2\u00aa. da Vel. Vento (30 minutos): derivada segunda da velocidade do vento h\u00e1 30 \n\nminutos atr\u00e1s; \n\u2022 Derivada Temp. (60 minutos, Ano Anterior): derivada da temperatura h\u00e1 60 minutos atr\u00e1s \n\nno ano anterior; \n\u2022 Derivada 2\u00aa. Temp. (Atual, Semana Anterior): derivada de segunda ordem da temperatura \n\nno mesmo hor\u00e1rio da semana anterior. \n \n\u00cdndice Vari\u00e1vel Descri\u00e7\u00e3o \n\n1 AGORA_DER2_PRS_0MINUTOS Derivada 2\u00aa. da Vel. Vento (Atual) \n\n2 AGORA_DER2_PRS_30MINUTOS Derivada 2\u00aa. da Vel. Vento (30 minutos) \n\n3 AGORA_DER2_TCW_30MINUTOS Derivada 2\u00aa. da Carga (30 minutos) \n\n4 AGORA_DER2_TMP_0MINUTOS Derivada 2\u00aa. da Temperatura (Atual) \n\n5 AGORA_DER2_TMP_30MINUTOS Derivada 2\u00aa. da Temperatura (30minutos) \n\n6 AGORA_DER_PRS_0MINUTOS Derivada da Vel. Vento (Atual) \n\n7 AGORA_DER_PRS_30MINUTOS Derivada da Vel. Vento (30 minutos) \n\n8 AGORA_DER_PRS_60MINUTOS Derivada da Vel. Vento (60 minutos) \n\n9 AGORA_DER_TCW_30MINUTOS Derivada da Carga (30 minutos) \n\n10 AGORA_DER_TCW_60MINUTOS Derivada da Carga (60 minutos) \n\n11 AGORA_DER_TMP_0MINUTOS Derivada da Temperatura (Atual) \n\n12 AGORA_DER_TMP_30MINUTOS Derivada da Temperatura (30 minutos) \n\n13 AGORA_DER_TMP_60MINUTOS Derivada da Temperatura (60 minutos) \n\n14 AGORA_PRS_0MINUTOS Velocidade do Vento (Atual) \n\n15 AGORA_PRS_30MINUTOS Velocidade do Vento (30 minutos) \n\n16 AGORA_PRS_60MINUTOS Velocidade do Vento (60 minutos) \n\n17 AGORA_PRS_90MINUTOS Velocidade do Vento (90 minutos) \n\n18 AGORA_PRS_MAX Velocidade do Vento (M\u00e1xima) \n\n19 AGORA_PRS_MED Velocidade do Vento (M\u00e9dia) \n\n20 AGORA_PRS_MIN Velocidade do Vento (M\u00ednima) \n\n21 AGORA_TCW_30MINUTOS Carga (30 minutos) \n\n22 AGORA_TCW_60MINUTOS Carga (60 minutos) \n\n23 AGORA_TCW_90MINUTOS Carga (90 minutos) \n\n24 AGORA_TMP_0MINUTOS Temperatura (Atual) \n\n25 AGORA_TMP_30MINUTOS Temperatura (30 minutos) \n\n26 AGORA_TMP_60MINUTOS Temperatura (60 minutos) \n\n27 AGORA_TMP_90MINUTOS Temperatura (90 minutos) \n\n28 AGORA_TMP_MAX Temperatura (M\u00e1xima) \n\n29 AGORA_TMP_MED Temperatura (M\u00e9dia) \n\n30 AGORA_TMP_MIN Temperatura (M\u00ednima) \n\n31 ANO_DER2_PRS_0MINUTOS Derivada 2\u00aa. Vel. Vento (Atual, Ano Anterior) \n\n32 ANO_DER2_PRS_30MINUTOS Derivada 2\u00aa. Vel. Vento (30 minutos, Ano Anterior) \n\n\n\n 116 \n\n33 ANO_DER2_TCW_0MINUTOS Derivada 2\u00aa. Carga (Atual, Ano Anterior) \n\n34 ANO_DER2_TCW_30MINUTOS Derivada 2\u00aa. Carga (30 minutos, Ano Anterior) \n\n35 ANO_DER2_TMP_0MINUTOS Derivada 2\u00aa. Temp. (Atual, Ano Anterior) \n\n36 ANO_DER2_TMP_30MINUTOS Derivada 2\u00aa. Temp. (30 minutos, Ano Anterior) \n\n37 ANO_DER_PRS_0MINUTOS Derivada 2\u00aa. Vel. Vento (Atual, Ano Anterior) \n\n38 ANO_DER_PRS_30MINUTOS Derivada 2\u00aa. Vel. Vento (30 minutos, Ano Anterior) \n\n39 ANO_DER_PRS_60MINUTOS Derivada 2\u00aa. Vel. Vento (60 minutos, Ano Anterior) \n\n40 ANO_DER_TCW_0MINUTOS Derivada Carga (Atual, Ano Anterior) \n\n41 ANO_DER_TCW_30MINUTOS Derivada Carga (30 minutos, Ano Anterior) \n\n42 ANO_DER_TCW_60MINUTOS Derivada Carga (60 minutos, Ano Anterior) \n\n43 ANO_DER_TMP_0MINUTOS Derivada Temp. (Atual, Ano Anterior) \n\n44 ANO_DER_TMP_30MINUTOS Derivada Temp. (30 minutos, Ano Anterior) \n\n45 ANO_DER_TMP_60MINUTOS Derivada Temp. (60 minutos, Ano Anterior) \n\n46 ANO_PRS_0MINUTOS Velocidade do Vento (Atual, Ano Anterior) \n\n47 ANO_PRS_30MINUTOS Velocidade do Vento (30 minutos, Ano Anterior) \n\n48 ANO_PRS_60MINUTOS Velocidade do Vento (60 minutos, Ano Anterior) \n\n49 ANO_PRS_90MINUTOS Velocidade do Vento (90 minutos, Ano Anterior) \n\n50 ANO_PRS_MAX Velocidade do Vento (M\u00e1xima, Ano Anterior) \n\n51 ANO_PRS_MED Velocidade do Vento (M\u00e9dia, Ano Anterior) \n\n52 ANO_PRS_MIN Velocidade do Vento (M\u00ednima, Ano Anterior) \n\n53 ANO_TCW_0MINUTOS Carga (Atual, Ano Anterior) \n\n54 ANO_TCW_30MINUTOS Carga (30 minutos, Ano Anterior) \n\n55 ANO_TCW_60MINUTOS Carga (60 minutos, Ano Anterior) \n\n56 ANO_TCW_90MINUTOS Carga (90 minutos, Ano Anterior) \n\n57 ANO_TCW_MAX Carga (M\u00e1xima, Ano Anterior) \n\n58 ANO_TCW_MED Carga (M\u00e9dia, Ano Anterior) \n\n59 ANO_TCW_MIN Carga (M\u00ednima, Ano Anterior) \n\n60 ANO_TMP_0MINUTOS Temperatura (Atual, Ano Anterior) \n\n61 ANO_TMP_30MINUTOS Temperatura (30 minutos, Ano Anterior) \n\n62 ANO_TMP_60MINUTOS Temperatura (60 minutos, Ano Anterior) \n\n63 ANO_TMP_90MINUTOS Temperatura (90 minutos, Ano Anterior) \n\n64 ANO_TMP_MAX Temperatura (M\u00e1xima, Ano Anterior) \n\n65 ANO_TMP_MED Temperatura (M\u00e9dia, Ano Anterior) \n\n66 ANO_TMP_MIN Temperatura (M\u00ednima, Ano Anterior) \n\n67 DIA_MES Dia do m\u00eas \n\n68 DIA_SEMANA Dia da Semana \n\n69 DIA_SEMANA_COS  \n\n70 DIA_SEMANA_SEN  \n\n71 HORA_MINUTO Hora do dia \n\n72 MEIA_HORA_DIA_COS  \n\n73 MEIA_HORA_DIA_SEN  \n\n74 MES M\u00eas \n\n75 SEMANA_ANO_COS  \n\n76 SEMANA_ANO_SEN  \n\n77 SEMANA_DER2_PRS_0MINUTOS Derivada 2\u00aa. Vel. Vento (Atual, Semana Anterior) \n\n78 SEMANA_DER2_PRS_30MINUTOS Derivada 2\u00aa. Vel. Vento (30 minutos, Semana Anteri-\nor) \n\n79 SEMANA_DER2_TCW_0MINUTOS Derivada 2\u00aa. Carga (Atual, Semana Anterior) \n\n80 SEMANA_DER2_TCW_30MINUTOS Derivada 2\u00aa. Carga (30 minutos, Semana Anterior) \n\n81 SEMANA_DER2_TMP_0MINUTOS Derivada 2\u00aa. Temp. (Atual, Semana Anterior) \n\n\n\n 117 \n\n82 SEMANA_DER2_TMP_30MINUTOS Derivada 2\u00aa. Temp. (30 minutos, Semana Anterior) \n\n83 SEMANA_DER_PRS_0MINUTOS Derivada Vel. Vento (Atual, Semana Anterior) \n\n84 SEMANA_DER_PRS_30MINUTOS Derivada Vel. Vento (30 minutos, Semana Anterior) \n\n85 SEMANA_DER_PRS_60MINUTOS Derivada Vel. Vento (60 minutos, Semana Anterior) \n\n86 SEMANA_DER_TCW_0MINUTOS Derivada Carga (Atual, Semana Anterior) \n\n87 SEMANA_DER_TCW_30MINUTOS Derivada Carga (30 minutos, Semana Anterior) \n\n88 SEMANA_DER_TCW_60MINUTOS Derivada Carga (60 minutos, Semana Anterior) \n\n89 SEMANA_DER_TMP_0MINUTOS Derivada Temp. (Atual, Semana Anterior) \n\n90 SEMANA_DER_TMP_30MINUTOS Derivada Temp. (30 minutos, Semana Anterior) \n\n91 SEMANA_DER_TMP_60MINUTOS Derivada Temp. (60 minutos, Semana Anterior) \n\n92 SEMANA_PRS_0MINUTOS Velocidade do Vento (Atual, Semana Anterior) \n\n93 SEMANA_PRS_30MINUTOS Velocidade do Vento (30 minutos, Semana Anterior) \n\n94 SEMANA_PRS_60MINUTOS Velocidade do Vento (60 minutos, Semana Anterior) \n\n95 SEMANA_PRS_90MINUTOS Velocidade do Vento (90 minutos, Semana Anterior) \n\n96 SEMANA_PRS_MAX Velocidade do Vento (M\u00e1xima, Semana Anterior) \n\n97 SEMANA_PRS_MED Velocidade do Vento (M\u00e9dia, Semana Anterior) \n\n98 SEMANA_PRS_MIN Velocidade do Vento (M\u00ednima, Semana Anterior) \n\n99 SEMANA_TCW_0MINUTOS Carga (Atual, Semana Anterior) \n\n100 SEMANA_TCW_30MINUTOS Carga (30 minutos, Semana Anterior) \n\n101 SEMANA_TCW_60MINUTOS Carga (60 minutos, Semana Anterior) \n\n102 SEMANA_TCW_90MINUTOS Carga (90 minutos, Semana Anterior) \n\n103 SEMANA_TCW_MAX Carga (M\u00e1xima, Semana Anterior) \n\n104 SEMANA_TCW_MED Carga (M\u00e9dia, Semana Anterior) \n\n105 SEMANA_TCW_MIN Carga (M\u00ednima, Semana Anterior) \n\n106 SEMANA_TMP_0MINUTOS Temperatura (Atual, Semana Anterior) \n\n107 SEMANA_TMP_30MINUTOS Temperatura (30 minutos, Semana Anterior) \n\n108 SEMANA_TMP_60MINUTOS Temperatura (60 minutos, Semana Anterior) \n\n109 SEMANA_TMP_90MINUTOS Temperatura (90 minutos, Semana Anterior) \n\n110 SEMANA_TMP_MAX Temperatura (M\u00e1xima, Semana Anterior) \n\n111 SEMANA_TMP_MED Temperatura (M\u00e9dia, Semana Anterior) \n\n112 SEMANA_TMP_MIN Temperatura (M\u00ednima, Semana Anterior) \n\n \n\n\n\n 118 \n\n9.2 Vari\u00e1veis relevantes em cada perfil de consumo \n\nO mesmo m\u00e9todo utilizado para gerar o espa\u00e7o causal (Cap\u00edtulo 6) pode ser usado para testar a relev\u00e2ncia \ndas vari\u00e1veis em cada perfil de consumo. A tabela a seguir mostra quais s\u00e3o as vari\u00e1veis consideradas \nmais relevantes em cada perfil, de acordo com o m\u00e9todo descrito no Cap\u00edtulo 6. \n \nPerfil de consumo Vari\u00e1veis relevantes \n\nICO_INVER 009, 010, 018, 019, 020, 021, 040, 041, 046, 047, 048, 049, 050, \n051, 052, 074, 086, 087, 088, 096, 097, 098, 099, 100 \n\nICO_OUTON 009, 010, 014, 015, 016, 017, 018, 019, 020, 021, 022, 023, 040, \n041, 046, 047, 048, 049, 050, 051, 052, 076, 086, 087, 088, 092, \n093, 094, 095, 096, 097, 098, 099 \n\nICO_VERAO 009, 010, 014, 015, 016, 017, 018, 019, 020, 021, 022, 023, 024, \n025, 026, 027, 028, 029, 030, 040, 041, 046, 047, 048, 049, 050, \n051, 052, 053, 062, 063, 064, 065, 066, 068, 075, 076, 086, 092, \n093, 094, 095, 096, 097, 098, 106, 107, 108, 109, 110, 111, 112 \n\nINE_INVER 009, 010, 017, 018, 019, 020, 021, 022, 023, 040, 050, 051, 052, \n053, 074, 086, 087, 096, 097, 098, 099, 100, 101, 102 \n\nINE_OUTON 009, 010, 018, 019, 021, 022, 023, 040, 041, 050, 051, 052, 053, \n054, 055, 056, 076, 086, 087, 098, 099 \n\nINE_VERAO 009, 021, 022, 023 \nISS_INVER 021, 022, 023 \nISS_OUTON 021, 022, 023 \nISS_VERAO 021, 022, 023 \nSIA_INVER \n\n009, 010, 021, 022, 023, 086 \nSIA_OUTON 009, 010, 021, 022, 023, 040, 053, 068, 076, 086 \nSIA_VERAO 009, 010, 021, 022, 023, 068, 075, 076, 086, 087, 110, 112 \nSRA_INVER 003, 009, 010, 021, 022, 040, 086, 087 \nSRA_OUTON 009, 010, 021, 022, 023, 040, 068, 086, 087 \nSRA_VERAO \n\n009, 010, 021, 022, 023, 028, 068, 075, 086, 099, 110, 111 \nTDE_INVER 009, 010, 021, 022, 023, 028, 068, 075, 086, 099, 110, 111 \nTDE_OUTON 009, 010, 021, 022, 023, 053, 054, 086, 099, 100 \nTDE_VERAO 009, 010, 021, 022, 023, 040, 053, 054, 055, 086, 099"}]}}}