{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.08159"}, {"@name": "filename", "#text": "12952_000823856.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNIVERSIDADE FEDERAL DO RIO GRANDE DO SUL\n\nDEPARTAMENTO DE ENGENHARIA QU\u00cdMICA\n\nENG07053 \n\n \n\n \n\n \n\n \n\n \n\n \n\nA v a l i a \u00e7 \u00e3 o  d e  r e g i \u00f5 e s  \n\no p e r a c i o n a i s\n\nd e  s e p a r a \u00e7 \u00e3 o  d e  p r o p e n o\n\nu t i l i z a n d o  \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nUNIVERSIDADE FEDERAL DO RIO GRANDE DO SUL \n\nESCOLA DE ENGENHARIA \n\nDEPARTAMENTO DE ENGENHARIA QU\u00cdMICA \n\nENG07053 - TRABALHO DE DIPLOMA\u00c7\u00c3O EM ENGENHARIA \nQU\u00cdMICA \n\nA v a l i a \u00e7 \u00e3 o  d e  r e g i \u00f5 e s  \n\no p e r a c i o n a i s  d e  u m a  c o l u n a  \n\nd e  s e p a r a \u00e7 \u00e3 o  d e  p r o p e n o\n\nu t i l i z a n d o  s e l f - o r g a n i z i n g  \n\nm a p s  \n\nAutor: Jos\u00e9 Ricardo Furlanetto de Azambuja\n\nOrientador: Marcelo Farenzena\n\nCo-Orientadora: Andrea Cabral Farias\n\nPorto Alegre, dezembro de 11 \n\n \n\nA v a l i a \u00e7 \u00e3 o  d e  r e g i \u00f5 e s  \n\nd e  u m a  c o l u n a  \n\nd e  s e p a r a \u00e7 \u00e3 o  d e  p r o p e n o  \n\na n i z i n g  \n\nJos\u00e9 Ricardo Furlanetto de Azambuja \n\nMarcelo Farenzena \n\nOrientadora: Andrea Cabral Farias \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\nii \n\nSu m \u00e1 rio  \n\nSum\u00e1rio ii \n\nAgradecimentos iii \n\nResumo iv \n\nLista de Figuras v \n\nLista de Tabelas vi \n\nLista de S\u00edmbolos vii \n\nLista de Abreviaturas e Siglas viii \n\n1 Introdu\u00e7\u00e3o 1 \n\n2 Revis\u00e3o Bibliogr\u00e1fica 3 \n\n2.1 Redes Neurais Artificiais 3 \n\n2.2 Mapas auto-organiz\u00e1veis 5 \n\n2.2.1 Inicializa\u00e7\u00e3o dos pesos sin\u00e1pticos 8 \n2.2.2 Processo de competi\u00e7\u00e3o 9 \n2.2.3 Processo de coopera\u00e7\u00e3o 9 \n2.2.4 Processo adaptativo 10 \n\n3 Materiais e M\u00e9todos 12 \n\n3.1 Aspen Plus 12 \n\n3.2 MATLAB 13 \n\n3.2.1 Algoritmo para pr\u00e9-processamento de dados 13 \n3.2.2 SOM Toolbox 13 \n\n4 Estudo de Caso 15 \n\n4.1 Unidade de Processamento de G\u00e1s Liquefeito de Petr\u00f3leo 15 \n\n4.1.1 Coluna despropanizadora 15 \n4.1.2 Coluna desetanizadora 15 \n4.1.3 Coluna de separa\u00e7\u00e3o propano e propeno 17 \n\n4.2 Constru\u00e7\u00e3o da simula\u00e7\u00e3o em Aspen Plus 18 \n\n5 Resultados 20 \n\n5.1 Simula\u00e7\u00e3o em Aspen Plus 20 \n\n5.2 Matrizes-U 21 \n\n5.2.1 Matrizes-U para todos os dados 21 \n5.2.2 Matrizes-U ap\u00f3s pr\u00e9-processamento dos dados 23 \n\n5.3 Trajet\u00f3rias aplicadas ao mapa escolhido 25 \n\n5.4 Predi\u00e7\u00e3o da concentra\u00e7\u00e3o de propeno no topo 27 \n\n6 Conclus\u00f5es e trabalhos futuros 31 \n\n6.1 Trabalhos futuros 32 \n\n7 Refer\u00eancias 33 \n\n  \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja iii\n\nA g rad e c im e n to s  \n\nGostaria de agradecer primeiramente e principalmente aos meus pais, Jos\u00e9 Luiz e \nTa\u00eds, e ao meu irm\u00e3o, Jos\u00e9 Rodrigo, pelo apoio incondicional e por me propiciarem as \ncondi\u00e7\u00f5es necess\u00e1rias para que o estudo sempre fosse a minha principal preocupa\u00e7\u00e3o. \nCertamente seus ensinamentos sempre fizeram parte da minha forma\u00e7\u00e3o. \n\nGostaria de agradecer tamb\u00e9m ao meu orientador professor Dr. Marcelo Farenzena \npela oportunidade de participar do seu grupo de pesquisa e pelas numerosas horas de \nconselhos, ajudas e sugest\u00f5es sem as quais este trabalho n\u00e3o teria sido poss\u00edvel. Gostaria \nde agradecer \u00e0 minha co-orientadora Andrea Cabral Farias pelas valiosas contribui\u00e7\u00f5es e \nsugest\u00f5es que foram imprescind\u00edveis para o desenvolvimento desta disserta\u00e7\u00e3o. \n\nFinalmente, gostaria de agradecer aos meus amigos, tanto os que me acompanharam \nem salas de aula quanto os que preservaram a amizade fora delas. Aos que me \nacompanharam nas salas de aula da UFRGS agrade\u00e7o principalmente \u00e0 RA\u00c7A.  \n\n \n\n  \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\niv \n\nRe s u m o  \n\nA constante melhora e aumento do n\u00famero de instrumentos de medi\u00e7\u00e3o e bancos de \ndados de vari\u00e1veis de planta t\u00eam-se mostrado como uma dificuldade no que se refere \u00e0 \ninterpreta\u00e7\u00e3o dos mesmos. Dentro desse contexto, \u00e9 apresentado um estudo sobre a \nt\u00e9cnica de self-organizing maps, ou mapas auto-organiz\u00e1veis, aplicada em uma unidade \nde processamento de g\u00e1s liquefeito de petr\u00f3leo. A simula\u00e7\u00e3o das colunas desetanizadora \ne de separa\u00e7\u00e3o propano e propeno foram constru\u00eddas no software Aspen Plus a partir de \ndados de projeto fornecidos por uma refinaria nacional. A coluna de separa\u00e7\u00e3o propano e \npropeno foi o foco do trabalho de identifica\u00e7\u00e3o e avalia\u00e7\u00e3o das regi\u00f5es operacionais e foi \nrealizada a predi\u00e7\u00e3o da concentra\u00e7\u00e3o de propeno na corrente de topo atrav\u00e9s de uma \netapa supervisionada, posterior ao treinamento do mapa. Tanto a identifica\u00e7\u00e3o das \nregi\u00f5es operacionais quanto a predi\u00e7\u00e3o de vari\u00e1veis apresentaram resultados muito \nsatisfat\u00f3rios. A identifica\u00e7\u00e3o das regi\u00f5es operacionais se fez atrav\u00e9s da marca\u00e7\u00e3o das \ntrajet\u00f3rias crescentes de vari\u00e1veis operacionais da planta frente \u00e0 concentra\u00e7\u00e3o de \npropeno na corrente de topo. O coeficiente de correla\u00e7\u00e3o (R\u00b2) para a predi\u00e7\u00e3o realizada \ncom o mapa treinado com tamanho grande foi de 0,9999. \n\n \n\n \n\n \n\n  \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja v\n\nL i sta d e  Fi gu ras  \n\nFigura 2.1: Representa\u00e7\u00e3o b\u00e1sica de um neur\u00f4nio. Extra\u00eddo de Haykin (1999). ................. 3 \n\nFigura 2.2: Rede neural artificial com uma \u00fanica camada. Extra\u00eddo de Haykin (1999). ...... 4 \n\nFigura 2.3: Rede neural artificial de m\u00faltiplas camadas. Extra\u00eddo de Haykin (1999). .......... 4 \n\nFigura 2.4: Estrutura de uma rede neural artificial com aprendizagem n\u00e3o supervisionada.\n ......................................................................................................................................... 4 \n\nFigura 2.5: Estrutura de uma rede neural artificial com aprendizagem supervisionada. .... 5 \n\nFigura 2.6: Exemplo de matriz-U. Fonte: Ng &amp; Srinivasan (2008a). .................................... 6 \n\nFigura 2.7: Exemplo de matriz-U combinada com BMU\u2019s. Fonte: Ng &amp; Srinivasan (2008a). 7 \n\nFigura 2.8: Mapas topol\u00f3gicos hexagonal e retangular. .................................................... 8 \n\nFigura 2.9: Fun\u00e7\u00e3o de vizinhan\u00e7a gaussiana. .................................................................... 10 \n\nFigura 4.1: Fluxograma da Unidade de Processamento de G\u00e1s Liquefeito de Petr\u00f3leo. .... 16 \n\nFigura 4.2: Fluxograma da simula\u00e7\u00e3o realizada em Aspen Plus. ....................................... 18 \n\nFigura 5.1: Matrizes-U para diferentes tamanhos de mapa. (a) pequeno, (b) normal e (c) \ngrande. ............................................................................................................................ 21 \n\nFigura 5.2: Matriz-U do mapa de tamanho 20x5. ............................................................. 22 \n\nFigura 5.3: Visualiza\u00e7\u00e3o da Matriz-U em 3 dimens\u00f5es para o mapa de tamanho 20x5. .... 22 \n\nFigura 5.4:  Matrizes-U para ? = ?, ??. ........................................................................... 23 \nFigura 5.5: Matrizes-U para ? = ?, ??. ............................................................................ 24 \nFigura 5.6: Matrizes-U para ? = ?, ?. .............................................................................. 24 \nFigura 5.7: Visualiza\u00e7\u00e3o da Matriz-U em 3 dimens\u00f5es com aplica\u00e7\u00e3o do algoritmo, T igual \na 0,02 e mapa de tamanho grande. .................................................................................. 25 \n\nFigura 5.8: (a) trajet\u00f3ria crescente de composi\u00e7\u00e3o de propeno no topo e (b) trajet\u00f3ria \ncrescente da fra\u00e7\u00e3o da corrente direcionada para produto de topo. ................................ 26 \n\nFigura 5.9: (a) trajet\u00f3ria crescente da composi\u00e7\u00e3o de propeno no topo e (b) trajet\u00f3ria \ncrescente da vaz\u00e3o de hot bypass. ................................................................................... 26 \n\nFigura 5.10: trajet\u00f3ria crescentes (a) e (c) da composi\u00e7\u00e3o de propeno no topo, (b) da \npress\u00e3o de descarga do compressor e (d) da carga de alimenta\u00e7\u00e3o. ................................ 27 \n\nFigura 5.11: Resultado da predi\u00e7\u00e3o para o mapa treinado com tamanho pequeno. ......... 28 \n\nFigura 5.12: Resultado da predi\u00e7\u00e3o para o mapa treinado com tamanho normal............. 28 \n\nFigura 5.13: Resultado da predi\u00e7\u00e3o para o mapa treinado com tamanho grande. ............ 29 \n\nFigura 5.14: Boxplot para os tr\u00eas diferentes tamanhos de mapas. ................................... 30 \n\n \n\n \n\n  \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\nvi \n\nL i sta d e  Tab e l as  \n\nTabela 5.1: Compara\u00e7\u00e3o dos dados de carga total, concentra\u00e7\u00e3o molar de propeno e \ntemperatura da simula\u00e7\u00e3o realizada em Aspen com os dados de projeto. ....................... 20 \n\n \n\n \n\n \n\n  \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja vii\n\nL i sta d e  S\u00ed mb o l os  \n\n\t\n,?  \u2013 peso sin\u00e1ptico do neur\u00f4nio j para o dado de entrada k \n??,\n \u2013 dist\u00e2ncia entre o neur\u00f4nio j e o neur\u00f4nio i \n? \u2013 largura efetiva da vizinhan\u00e7a topol\u00f3gica \n??,\n  \u2013 fun\u00e7\u00e3o de vizinhan\u00e7a topol\u00f3gica centrada no neur\u00f4nio i para o neur\u00f4nio j \n? \u2013 tempo discreto \n? \u2013 constante de tempo \n? \u2013 par\u00e2metro taxa de aprendizagem \nT  - valor arbitr\u00e1rio para compara\u00e7\u00e3o entre dados  \n\n  \n\n  \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\nviii \n\nL i sta d e  A b re vi atu ras  e  S i gl as  \n\nSOM \u2013 Self-Organizing Maps \n \nVLSI \u2013 Very-Large-Scale Implementation \n \nBMU \u2013 Best Matching Unit \n \nPCA \u2013 Principal Component Analysis \n \nFCC \u2013 Fluid Catalytic Cracking \n \nGLP \u2013 G\u00e1s Liquefeito de Petr\u00f3leo \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 1\n\n1 Intro d u \u00e7\u00e3o  \n\nAtualmente, devido ao avan\u00e7o em sensores e tecnologias de banco de dados, na \nopera\u00e7\u00e3o de uma planta muitas vari\u00e1veis s\u00e3o medidas e registradas, e interpret\u00e1-las \nacaba sendo uma tarefa de alta complexidade. Com o prop\u00f3sito de facilitar a visualiza\u00e7\u00e3o \ndestas vari\u00e1veis surgem as t\u00e9cnicas de redu\u00e7\u00e3o da dimensionalidade, que t\u00eam como \nobjetivo represent\u00e1-las de uma forma mais simples de ser interpretada. Outro problema \nrecorrente na ind\u00fastria s\u00e3o as opera\u00e7\u00f5es multiestado, ou seja, a opera\u00e7\u00e3o da planta pode \ntransitar em diferentes regi\u00f5es operacionais. Geralmente, regi\u00f5es de transi\u00e7\u00e3o entre \nestados representam opera\u00e7\u00f5es em que a planta n\u00e3o est\u00e1 operando em sua capacidade \n\u00f3tima. Sendo assim, a redu\u00e7\u00e3o da dimensionalidade e a identifica\u00e7\u00e3o das diferentes \nregi\u00f5es da planta se tornam muito importantes para operabilidade e lucratividade \nindustrial.  \n\nNo presente trabalho, ser\u00e1 aplicada uma t\u00e9cnica que se prop\u00f5e a anular esses dois \ngrandes problemas. A t\u00e9cnica em quest\u00e3o \u00e9 a de mapas auto-organiz\u00e1veis, ou self-\norganizing maps, que \u00e9 um tipo de rede neural de treinamento n\u00e3o supervisionado. \nOutro problema enfrentado nesse trabalho ser\u00e1 que, \u00e0s vezes, vari\u00e1veis de planta tomam \ntempo para serem medidas, como de concentra\u00e7\u00f5es de correntes, por exemplo. Ser\u00e1 \nproposto, dessa maneira, uma etapa posterior a de mapeamento de regi\u00f5es operacionais \na fim de predizer vari\u00e1veis de planta, atrav\u00e9s de um treinamento supervisionado. \n\nOs mapas auto-organiz\u00e1veis, n\u00e3o importando com quantas vari\u00e1veis s\u00e3o alimentados, \napresentar\u00e3o sempre uma sa\u00edda em duas ou tr\u00eas dimens\u00f5es, facilitando assim a \nvisualiza\u00e7\u00e3o de padr\u00f5es operacionais. Tais mapas se diferem das outras redes neurais \nartificiais pelas suas etapas de competi\u00e7\u00e3o e de coopera\u00e7\u00e3o. A etapa de competi\u00e7\u00e3o se \nbaseia na determina\u00e7\u00e3o do neur\u00f4nio que mais se assemelha a um dado conjunto de \nvari\u00e1veis alimentado, chamado de neur\u00f4nio vencedor. Por sua vez, a etapa de \ncoopera\u00e7\u00e3o atualiza com pesos diferentes neur\u00f4nios mais pr\u00f3ximos ao neur\u00f4nio \nvencedor. \n\n A visualiza\u00e7\u00e3o do mapa treinado \u00e9 atrav\u00e9s da chamada matriz-U, que relaciona a \ndist\u00e2ncia entre neur\u00f4nios vizinhos por uma escala de cores. Outra alternativa de \nvisualiza\u00e7\u00e3o \u00e9 marcar na matriz-U do mapa treinado os neur\u00f4nios vencedores de um \nconjunto de amostras ordenado de forma crescente ou decrescente em rela\u00e7\u00e3o a uma \nvari\u00e1vel. Assim sendo, \u00e9 poss\u00edvel ver a trajet\u00f3ria que determinada vari\u00e1vel percorre na \nmatriz-U. \n\nPara uma boa aplica\u00e7\u00e3o da t\u00e9cnica de mapas auto-organiz\u00e1veis se torna fundamental \num vasto banco de dados de diferentes regi\u00f5es de opera\u00e7\u00e3o da planta. De modo a se \nobterem os dados necess\u00e1rios foi constru\u00edda e validada com dados de projeto a simula\u00e7\u00e3o \nem Aspen Plus de uma unidade petroqu\u00edmica em funcionamento. A unidade em quest\u00e3o \npertence a uma refinaria nacional. De posse da simula\u00e7\u00e3o foram variadas diversas \ncaracter\u00edsticas operacionais, gerado o banco de dados e treinados os mapas para \nposterior identifica\u00e7\u00e3o de regi\u00f5es operacionais. A etapa seguinte foi o treinamento \nsupervisionado do mapa auto-organiz\u00e1vel, que \u00e9 na sua concep\u00e7\u00e3o n\u00e3o-supervisionado, \npara a predi\u00e7\u00e3o da concentra\u00e7\u00e3o de propeno na corrente de topo da \u00faltima torre de \ndestila\u00e7\u00e3o da unidade que \u00e9 respons\u00e1vel pela separa\u00e7\u00e3o entre propano e propeno. \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n2 \n\nO presente trabalho est\u00e1 dividido em cinco se\u00e7\u00f5es. Na primeira parte \u00e9 apresentada \numa revis\u00e3o bibliogr\u00e1fica sobre redes neurais artificiais e sobre mapas auto-organiz\u00e1veis. \nNa segunda se\u00e7\u00e3o \u00e9 apresentada a metodologia do trabalho e como os programas \nMATLAB e Aspen Plus foram utilizados para a obten\u00e7\u00e3o dos objetivos do trabalho. Na \nse\u00e7\u00e3o seguinte foi descrito o caso de estudo do presente trabalho para uma melhor \ncompreens\u00e3o do problema a ser enfrentado. Na quarta parte s\u00e3o apresentados os \nresultados da simula\u00e7\u00e3o e dos mapas treinados na forma de visualiza\u00e7\u00e3o de diversas \nmatrizes-U variando o tamanho do mapa e a utiliza\u00e7\u00e3o ou n\u00e3o do algoritmo de elimina\u00e7\u00e3o \nde amostras com dados similares, assim como as trajet\u00f3rias crescentes de vari\u00e1veis de \nopera\u00e7\u00e3o da planta e a predi\u00e7\u00e3o da composi\u00e7\u00e3o de propeno na corrente de topo da \ncoluna de separa\u00e7\u00e3o propano e propeno. Na \u00faltima se\u00e7\u00e3o est\u00e3o apresentadas as \nconclus\u00f5es obtidas ao longo do trabalho. \n\n  \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 3\n\n2 Rev is \u00e3o  B i b l io g r\u00e1f i ca  \n\n2.1 Redes Neurais Artificiais \n\nO conceito de redes neurais artificiais surgiu na tentativa de recriar as conex\u00f5es de \num c\u00e9rebro biol\u00f3gico utilizando ferramentas de um computador digital convencional. A \npartir disso, come\u00e7ou-se a imitar as intera\u00e7\u00f5es entre os neur\u00f4nios de um c\u00e9rebro a fim \nde recriar esse mesmo padr\u00e3o e organiza\u00e7\u00e3o em termos de processamento de dados. A \ngrande vantagem de um sistema biol\u00f3gico \u00e9 a experi\u00eancia adquirida e a adaptabilidade \nao meio ambiente em que ele est\u00e1 inserido, e ao estender-se aos computadores digitais \nesse conceito foi chamado de etapa de aprendizagem.  \n\nSegundo Haykin (1999), os maiores benef\u00edcios de uma rede neural artificial s\u00e3o: n\u00e3o-\nlinearidade, mapeamento de entrada-sa\u00edda, adaptabilidade, resposta a evid\u00eancias, \ninforma\u00e7\u00e3o contextual, toler\u00e2ncia a falhas, implementa\u00e7\u00e3o em VLSI (Very-Large-Scale \nImplementation), uniformidade de an\u00e1lise e projeto e analogia neurobiol\u00f3gica. VLSI \nconsiste em criar circuitos integrados combinando milhares de transistores em um \u00fanico \nchip, aumentando o poder computacional enormemente. \n\nA unidade b\u00e1sica de uma rede neural artificial assim como a de uma rede neural \nbiol\u00f3gica \u00e9 o neur\u00f4nio. No caso da artificial o neur\u00f4nio \u00e9 alimentado pelos dados de \ntodos neur\u00f4nios da camada anterior multiplicado por um valor chamado de peso \nsin\u00e1ptico. O peso sin\u00e1ptico, denominado por w, \u00e9 atualizado conforme a alimenta\u00e7\u00e3o de \nnovos dados de entrada e varia de 0 a 1. Os valores, depois de serem multiplicados pelo \npeso sin\u00e1ptico, s\u00e3o somados e alimentados no neur\u00f4nio, que por sua vez tem uma \nfun\u00e7\u00e3o de ativa\u00e7\u00e3o escolhida pelo usu\u00e1rio, normalmente uma fun\u00e7\u00e3o tangencial \nhiperb\u00f3lica. Outros exemplos de fun\u00e7\u00e3o de ativa\u00e7\u00e3o s\u00e3o fun\u00e7\u00e3o linear, degrau e rampa. A \nrepresenta\u00e7\u00e3o de um neur\u00f4nio t\u00edpico \u00e9 mostrada na Figura 2.1. \n\n \n\nFigura 2.1: Representa\u00e7\u00e3o b\u00e1sica de um neur\u00f4nio. Extra\u00eddo de Haykin (1999). \n\nOs neur\u00f4nios s\u00e3o dispostos em uma rede neural artificial em camadas de entrada, de \nsa\u00edda e ocultas. Quando uma rede artificial s\u00f3 apresenta uma camada \u00e9 chamada de rede \nde camada \u00fanica, assim os dados de entrada s\u00e3o alimentados direto na camada de sa\u00edda, \ncomo pode ser visto na Figura 2.2. No caso de haver camadas ocultas de neur\u00f4nios, ela \u00e9 \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n4 \n\nchamada de rede com m\u00faltiplas camadas, e torna-se importante quando \u00e9 desejado que \na rede extraia rela\u00e7\u00f5es altamente n\u00e3o-lineares entre os dados e consiga fazer uma \nconex\u00e3o adequada entre a camada de entrada de dados e a camada de sa\u00edda. Uma rede \ncom m\u00faltiplas camadas t\u00edpica pode ser vista na Figura 2.3. \n\n \n\nFigura 2.2: Rede neural artificial com uma \u00fanica camada. Extra\u00eddo de Haykin (1999). \n\n \n\nFigura 2.3: Rede neural artificial de m\u00faltiplas camadas. Extra\u00eddo de Haykin (1999). \n\n A etapa de aprendizagem pode ser feita de forma supervisionada ou n\u00e3o \nsupervisionada. Na aprendizagem n\u00e3o supervisionada n\u00e3o h\u00e1 a resposta desejada para os \ndados de entrada alimentados ao sistema. Sendo assim, os pesos sin\u00e1pticos dos \nneur\u00f4nios s\u00e3o atualizados conforme a rede consegue detectar padr\u00f5es do ambiente, \nlevando em conta a similaridade dos dados na camada de entrada. A estrutura dessa rede \npode ser vista na Figura 2.4. Nota-se que a sa\u00edda do neur\u00f4nio no sistema de \naprendizagem \u00e9 realimentado diretamente, sem passar por um valor base desejado. \n\n \n\nFigura 2.4: Estrutura de uma rede neural artificial com aprendizagem n\u00e3o supervisionada.\n  \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 5\n\nCaso o m\u00e9todo escolhido seja supervisionado \u00e9 preciso ter uma resposta do sistema \ndesejada para cada conjunto de dados de entrada. Esse conhecimento sobre o sistema \u00e9 \nchamado de professor, e a diferen\u00e7a entre o valor de sa\u00edda calculado pela rede neural e o \nvalor desejado \u00e9 realimentado na rede a fim de que os pesos sin\u00e1pticos dos neur\u00f4nios \nsejam atualizados e atinjam o valor mais pr\u00f3ximo poss\u00edvel do que se quer. Ao longo do \ntempo, quando os pesos sin\u00e1pticos j\u00e1 tiverem sido iterados e os neur\u00f4nios tenham \naprendido as caracter\u00edsticas da camada de entrada, \u00e9 poss\u00edvel prescindir o professor. Um \nexemplo de uma estrutura b\u00e1sica de uma rede supervisionada pode ser visto na Figura \n2.5. \n\n \n\nFigura 2.5: Estrutura de uma rede neural artificial com aprendizagem supervisionada. \n\n2.2 Mapas auto-organiz\u00e1veis \n\nOs mapas auto-organiz\u00e1veis, ou self-organizing maps (SOM), foram desenvolvidos no \nfinal da d\u00e9cada de 1980 por Teuvo Kohonen e s\u00e3o um tipo de rede neural artificial n\u00e3o \nsupervisionada, ou seja, n\u00e3o \u00e9 preciso o conhecimento do ambiente em que foram \ngerados os dados a serem alimentados na rede. Como resultado, \u00e9 gerado um mapa \nbidimensional que relaciona as dist\u00e2ncias entre os neur\u00f4nios do mapa j\u00e1 treinado, \npermitindo assim uma redu\u00e7\u00e3o da dimensionalidade dos dados de entrada. Rela\u00e7\u00f5es \nentre esses dados s\u00e3o facilmente vistas no mapa, enquanto que nos dados originais \nseriam mais dif\u00edceis quanto maior fosse o n\u00famero de vari\u00e1veis. \n\nOutras caracter\u00edsticas importantes dos mapas auto-organiz\u00e1veis, al\u00e9m da redu\u00e7\u00e3o da \ndimensionalidade, s\u00e3o a sua n\u00e3o-linearidade, a t\u00e9cnica de aprendizagem competitiva e a \nidentifica\u00e7\u00e3o de agrupamentos ou clusteriza\u00e7\u00e3o. Em rela\u00e7\u00e3o a sua n\u00e3o-linearidade, \u00e9 visto \ncomo uma generaliza\u00e7\u00e3o da an\u00e1lise dos componentes principais ou PCA. A t\u00e9cnica de \naprendizagem competitiva se baseia principalmente em n\u00e3o atualizar todos os neur\u00f4nios \nda rede, para isso \u00e9 definido um \u201cneur\u00f4nio vencedor\u201d, que \u00e9 o que mais se assemelha a \ndeterminado conjunto de dados de entrada e s\u00f3 ele e seus vizinhos s\u00e3o atualizados. A \nidentifica\u00e7\u00e3o de agrupamentos vem da interpreta\u00e7\u00e3o do mapa gerado, e s\u00e3o facilmente \nvistos quando h\u00e1 uma regi\u00e3o de neur\u00f4nios com pequena dist\u00e2ncia entre eles. \n\nUma desvantagem inerente ao uso de mapas auto-organiz\u00e1veis \u00e9 que o mapa gerado \npela t\u00e9cnica, sem que se conhe\u00e7a muito bem a origem dos dados de entrada, n\u00e3o \u00e9 muito \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n6 \n\ninformativo, ou seja, \u00e9 preciso que algu\u00e9m com conhecimento pr\u00e9vio reconhe\u00e7a os \npadr\u00f5es apresentados no gr\u00e1fico. Al\u00e9m disso, para a predi\u00e7\u00e3o de dados de sa\u00edda, \u00e9 \nnecess\u00e1rio uma etapa supervisionada posterior ao treinamento dos neur\u00f4nios pelo \nalgoritmo de SOM, com a vincula\u00e7\u00e3o dos dados de entrada com um valor esperado de \nsa\u00edda. \n\nO mapa treinado pelo algoritmo de SOM pode ser visto de duas maneiras diferentes \nque s\u00e3o a matriz-U e a visualiza\u00e7\u00e3o do \u201cbest matching unit\u201d (BMU) de determinado \nconjunto de dados de entrada. A matriz-U relaciona a dist\u00e2ncia entre os neur\u00f4nios da \ngrade e a sua vizinhan\u00e7a, sendo f\u00e1cil desse jeito visualizar agrupamento de padr\u00f5es de \nentrada, representados por regi\u00f5es com pequena dist\u00e2ncia entre os neur\u00f4nios adjacentes \ne regi\u00f5es de transi\u00e7\u00e3o, representadas por grandes dist\u00e2ncias. Na Figura 2.6 pode ser visto \numa matriz-U retirada de Ng &amp; Srinivasan (2008a) onde tr\u00eas clusters, apontados por C1, \nC2 e C3 s\u00e3o facilmente identificados. \n\n \n\nFigura 2.6: Exemplo de matriz-U. Fonte: Ng &amp; Srinivasan (2008a). \n\nUma desvantagem de utilizar a matriz-U \u00e9 que nenhuma no\u00e7\u00e3o temporal pode ser \nretirada dela, somente adicionando simultaneamente as informa\u00e7\u00f5es dos neur\u00f4nios \nvencedores. Para tanto, toma-se uma sequ\u00eancia temporal de dados e determina-se onde \nest\u00e3o os neur\u00f4nios vencedores para cada conjunto de dados. Assim sendo, pode-se ver \ncom facilidade a trajet\u00f3ria que os dados percorreram no mapa topol\u00f3gico treinado por \nSOM durante o tempo de amostra. Na Figura 2.7 se v\u00ea a trajet\u00f3ria em azul percorrida por \num conjunto de dados de entrada simulado pelos autores organizados temporalmente no \nmesmo mapa da Figura 2.6. \n\n \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 7\n\n \n\n \nFigura 2.7: Exemplo de matriz-U combinada com BMU\u2019s. Fonte: Ng &amp; Srinivasan (2008a). \n\nA t\u00e9cnica de mapas auto-organiz\u00e1veis vem sendo bastante estudada e utilizada, e o \ncampo de aplica\u00e7\u00e3o para ela \u00e9 muito amplo. Algumas aplica\u00e7\u00f5es s\u00e3o listadas a seguir: \n\n? Em Ng &amp; Srinivasan (2008a) foi sugerida uma nova implementa\u00e7\u00e3o para \nmelhor visualiza\u00e7\u00e3o de opera\u00e7\u00f5es multiestado de uma unidade de \ncraqueamento de petr\u00f3leo. Essa implementa\u00e7\u00e3o se baseia em excluir \npontos do estado estacion\u00e1rio que sejam muito parecidos, podendo \nvisualizar, assim, os estados de transi\u00e7\u00e3o mais claramente. A t\u00e9cnica foi \ntestada em uma destila\u00e7\u00e3o de etanol-\u00e1gua em escala de laborat\u00f3rio e \ntamb\u00e9m na opera\u00e7\u00e3o de um reator de craqueamento de uma refinaria \npara detec\u00e7\u00e3o de falhas operacionais; \n\n? Em Ng &amp; Srinivasan (2008b) a mesma implementa\u00e7\u00e3o de exclus\u00e3o de \npontos semelhantes utilizada em Ng &amp; Srinivasan (2008a) foi aplicada para \num acompanhamento online na detec\u00e7\u00e3o de falhas. A t\u00e9cnica foi aplicada \nna partida de uma planta de destila\u00e7\u00e3o em escala de laborat\u00f3rio e em um \ncaso conhecido como \u201cTennessee Eastman (TE) industrial challenge \nproblem\u201d; \n\n? Em Ouzounoglou et al. (2010) foi implementada a t\u00e9cnica de self \norganizing maps para detectar a exist\u00eancia ou n\u00e3o de um correspondente a \numa impress\u00e3o digital fornecida no banco de dados; \n\n? Em Aguado et al. (2008) a t\u00e9cnica de SOM e de PCA foram aplicadas para a \nan\u00e1lise de dados multidimensionais na remo\u00e7\u00e3o de f\u00f3sforo biol\u00f3gico de \n\u00e1guas residuais. As duas t\u00e9cnicas apresentaram resultados muito bons em \nrela\u00e7\u00e3o \u00e0 interpreta\u00e7\u00e3o dos dados, por\u00e9m foi apontado que o SOM teria \nvantagem sobre o PCA por ter uma estrat\u00e9gia apta a lidar com problemas \nn\u00e3o-lineares e tamb\u00e9m por lidar diretamente com as vari\u00e1veis originais; \n\n? Em Fuertes et al. (2010) foi utilizada a t\u00e9cnica de SOM para visualizar \nopera\u00e7\u00f5es de multiestado. Prop\u00f4s-se um m\u00e9todo que identifica os clusters \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n8 \n\npresentes na opera\u00e7\u00e3o e a probabilidade de transi\u00e7\u00e3o entre eles usando a \ntrajet\u00f3ria seguida pelos dados alimentados ao sistema no mapa 2D. Um \nnovo m\u00e9todo de detec\u00e7\u00e3o e identifica\u00e7\u00e3o de falhas tamb\u00e9m foi proposto. \nOs m\u00e9todos foram aplicados na supervis\u00e3o de uma planta real com 26 \nvari\u00e1veis; \n\n? Em Dom\u00ednguez et al. (2007) foi proposto um acompanhamento em tempo \nreal de visualiza\u00e7\u00f5es estacion\u00e1rias como plano de componentes e mapas \nde dist\u00e2ncias entre neur\u00f4nios e din\u00e2micas como a trajet\u00f3ria temporal no \nmapa dos dados de uma planta piloto. O objetivo do trabalho era detectar \nposs\u00edveis condi\u00e7\u00f5es anormais de opera\u00e7\u00e3o. \n\nO mapa topol\u00f3gico do SOM para o caso bidimensional possui duas op\u00e7\u00f5es de \ninicializa\u00e7\u00e3o: hexagonal ou retangular. Na Figura 2.8 est\u00e3o representadas as duas \nalternativas e \u00e9 f\u00e1cil ver que no caso retangular cada neur\u00f4nio tem quatro vizinhos \ndiretos, enquanto que no caso hexagonal cada neur\u00f4nio tem seis vizinhos diretos. A \ninicializa\u00e7\u00e3o mais comum \u00e9 a hexagonal. \n\n \n\nFigura 2.8: Mapas topol\u00f3gicos hexagonal e retangular. \n\nO algoritmo de treinamento do mapa auto organiz\u00e1vel come\u00e7a pela inicializa\u00e7\u00e3o dos \npesos sin\u00e1pticos dos neur\u00f4nios, que pode ser estimada pela an\u00e1lise da representa\u00e7\u00e3o de \ndados ou de forma aleat\u00f3ria, a mais utilizada. Segundo Haykin (1999) uma vez que a \ngrade tenha sido apropriadamente inicializada, h\u00e1 tr\u00eas processos essenciais envolvidos na \nforma\u00e7\u00e3o do mapa auto-organiz\u00e1vel: competi\u00e7\u00e3o, coopera\u00e7\u00e3o e adapta\u00e7\u00e3o sin\u00e1ptica. A \nseguir \u00e9 resumido como cada processo \u00e9 feito. \n\n2.2.1 Inicializa\u00e7\u00e3o dos pesos sin\u00e1pticos \n\nA inicializa\u00e7\u00e3o mais utilizada, a aleat\u00f3ria, \u00e9 tamb\u00e9m a mais simples. Nela nenhum \nestado de organiza\u00e7\u00e3o \u00e9 considerado e os pesos sin\u00e1pticos dos neur\u00f4nios s\u00e3o gerados por \num gerador de n\u00fameros aleat\u00f3rios que satisfa\u00e7a a condi\u00e7\u00e3o \n\n \n? \t\n?\n\n\n\n\n?\n= 1\t????\t????\t? (2.1) \n\nSendo j o sub-\u00edndice do neur\u00f4nio na grade e k o sub-\u00edndice que o relaciona ao seu \ndado de entrada, lembrando que existe um peso sin\u00e1ptico para cada dado que \u00e9 \nalimentado ao neur\u00f4nio. \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 9\n\n2.2.2 Processo de competi\u00e7\u00e3o \n\nUma caracter\u00edstica que diferencia o SOM de redes neurais artificiais comuns \u00e9 a t\u00e1tica \nde competi\u00e7\u00e3o entre os neur\u00f4nios. Dado um conjunto de dados de entrada, o neur\u00f4nio \nque tiver a maior ativa\u00e7\u00e3o \u00e0quele conjunto \u00e9 declarado o neur\u00f4nio vencedor, e s\u00f3 ele \nsofre a adapta\u00e7\u00e3o sin\u00e1ptica por completa. Para declarar qual neur\u00f4nio \u00e9 o vencedor \nprecisa-se de um algoritmo, que \u00e9 detalhado a seguir. \n\nSendo m a dimens\u00e3o dos dados de entrada, seleciona-se um conjunto de dados \nrepresentado por x, sendo \n\n ?\t =\t? ?,  !, \u2026 ,  #$%\t (2.2) \nA dimens\u00e3o do vetor de pesos sin\u00e1pticos do neur\u00f4nio \u00e9 a mesma dos dados de \n\nentrada e considerando que existam k neur\u00f4nios na grade, o vetor peso sin\u00e1ptico do \nneur\u00f4nio j \u00e9 representado por \n\n &amp;\t =\t'\t??, \t?!,\u2026 , \t?#(%\t, ? = 1,2, . . . +\t (2.3) \nPara declarar-se ent\u00e3o o neur\u00f4nio vencedor pode-se tomar como par\u00e2metro o \n\nproduto interno &lt;'\t?(%, ? > para todo j de 1 a k, sendo o neur\u00f4nio com maior ativa\u00e7\u00e3o \na certo conjunto de dados de entrada o que tenha o maior produto interno. Por\u00e9m, \nsegundo Haykin (1999) o crit\u00e9rio do melhor casamento, baseado na maximiza\u00e7\u00e3o do \n\nproduto interno &lt;'\t? (\n% , ? > \u00e9 matematicamente equivalente a minimizar a dist\u00e2ncia \n\neuclidiana entre os vetores ? e &amp;. Sendo essa uma representa\u00e7\u00e3o computacionalmente \nmais f\u00e1cil \u00e9 s\u00f3 determinar para todos os neur\u00f4nios o neur\u00f4nio i(x) que satisfa\u00e7a a \ncondi\u00e7\u00e3o representada por \n\n ./ 0 = \t??12.? 34 ? ?\t\t?43 , ?\t = \t1,2, . . . , +\t (2.4) \n\n2.2.3 Processo de coopera\u00e7\u00e3o \n\nO processo de coopera\u00e7\u00e3o \u00e9 de fundamental import\u00e2ncia na t\u00e9cnica de SOM e \nfunciona para atualizar o peso sin\u00e1ptico n\u00e3o s\u00f3 do neur\u00f4nio vencedor, e sim de uma \nvizinhan\u00e7a ao redor do mesmo. Quando o neur\u00f4nio vencedor \u00e9 determinado ele fica \ndefinido como o centro de uma vizinhan\u00e7a e vai ser atualizado por completo. \u00c0 medida \nque se afasta dele o fator de atualiza\u00e7\u00e3o \u00e9 decrescido at\u00e9 chegar a zero para neur\u00f4nios \nmuito distantes.  \n\nA fun\u00e7\u00e3o que descreve a vizinhan\u00e7a pode ser estabelecida conforme se quiser desde \nque satisfa\u00e7am as condi\u00e7\u00f5es de decrescer conforme a dist\u00e2ncia at\u00e9 o neur\u00f4nio vencedor \naumente e seja sim\u00e9trica em rela\u00e7\u00e3o ao centro da vizinhan\u00e7a. Uma escolha t\u00edpica para a \nfun\u00e7\u00e3o de vizinhan\u00e7a \u00e9 a fun\u00e7\u00e3o gaussiana que \u00e9 representada por \n\n ??,\n = \t6 ? 7? ??,\n!\n\n2?!8 (2.5) \nOnde ??,\n \u00e9 a dist\u00e2ncia entre o neur\u00f4nio j e o neur\u00f4nio vencedor i e ? \u00e9 a largura \n\nefetiva da vizinhan\u00e7a topol\u00f3gica como ilustrada na Figura 2.9. \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n10 \n\n \n\nFigura 2.9: Fun\u00e7\u00e3o de vizinhan\u00e7a gaussiana. \n\nUma caracter\u00edstica necess\u00e1ria para a fun\u00e7\u00e3o de vizinhan\u00e7a \u00e9 que ela  restrinja cada vez \nmais quantos neur\u00f4nios ser\u00e3o atualizados conforme o n\u00famero de itera\u00e7\u00f5es. Na pr\u00e1tica, \npara a fun\u00e7\u00e3o gaussiana o valor de ? deve ser reduzido, ou seja, a fun\u00e7\u00e3o deve ficar mais \nestreita. Um m\u00e9todo para se fazer isso \u00e9 descrito por Ritter &amp; Kohonen (1989), alterando \no valor da largura efetiva da vizinhan\u00e7a topol\u00f3gica em fun\u00e7\u00e3o do tempo, definido como  \n\n ?/?0 = \t?9 exp =? ???> ? = 0,1,2, \u2026, (2.6) \nSendo ?9 o valor de ? na inicializa\u00e7\u00e3o do algoritmo, ? o tempo discreto e ?? uma \n\nconstante de tempo. \n\nDesse jeito a fun\u00e7\u00e3o vizinhan\u00e7a que atende todos esses requisitos torna-se \n\n ??,\n(?) = \t6 ? 7? ??,\n!\n\n2?!(?)8 (2.7) \n\n2.2.4 Processo adaptativo \n\nNo \u00faltimo processo de atualiza\u00e7\u00e3o dos pesos sin\u00e1pticos dos neur\u00f4nios tem-se a sua \nefetiva modifica\u00e7\u00e3o. O valor \t?  no tempo (n+1) \u00e9 dado, como Kohonen (1982) \n\n \t? /? + 10 = \t\t?(?) + \t?(?)??,\n(?)? ? \t?(?)$ (2.8) \nOnde ?(?) \u00e9 chamado de taxa de aprendizagem e decresce exponencialmente com o \n\ntempo discreto n conforme  \n\n ?(?) = ?9exp =? n?!> , n = 0,1,2, \u2026, (2.9) \nSendo ?9 o valor inicial para o par\u00e2metro taxa de aprendizagem e ?! uma constante \n\nde tempo. \n\nPode-se dividir o processo adaptativo em duas distintas fases: fase de auto-\norganiza\u00e7\u00e3o ou de ordena\u00e7\u00e3o e fase de converg\u00eancia. A fase de ordena\u00e7\u00e3o ocorre nas \nprimeiras itera\u00e7\u00f5es e come\u00e7a com os pesos sin\u00e1pticos inicializados, ent\u00e3o \u00e9 necess\u00e1rio \nque eles sejam ordenados e se comece a identifica\u00e7\u00e3o dos padr\u00f5es dos dados de entrada. \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 11\n\nSegundo Kohonen (1997a) essa fase pode exigir 1000 itera\u00e7\u00f5es ou mais e algumas \nescolhas para os par\u00e2metros que se mostraram adequadas \u00e9 fazer com que a taxa de \naprendizagem decres\u00e7a gradualmente com o tempo, mas permane\u00e7a em um valor acima \nde 0,01 e a fun\u00e7\u00e3o de vizinhan\u00e7a inclua inicialmente quase todos os neur\u00f4nios da grade e \ndiminua para no final incluir apenas alguns neur\u00f4nios vizinhos em torno do neur\u00f4nio \n\nvencedor. Esses objetivos s\u00e3o alcan\u00e7ados escolhendo-se ?9=0,1, ?!=1000 e ?? = \t ?999CDEFG. \nNa fase de converg\u00eancia ocorre a sintonia fina dos neur\u00f4nios da grade e a \n\nrepresenta\u00e7\u00e3o efetiva dos dados de entrada. Ainda segundo Kohonen (1997a) o n\u00famero \nde itera\u00e7\u00f5es deve ser no m\u00ednimo de 500 vezes o n\u00famero de neur\u00f4nios na grade. O \npar\u00e2metro da taxa de aprendizagem deve se manter em um valor na ordem de 0,01 e n\u00e3o \ndeve-se permitir que chegue a zero, pois o mapa pode alcan\u00e7ar um estado que n\u00e3o se \natualize mais nem represente os dados de entrada. A fun\u00e7\u00e3o de vizinhan\u00e7a deve conter \napenas os vizinhos mais pr\u00f3ximos do neur\u00f4nio vencedor, ou \u00e0s vezes somente ele \npr\u00f3prio. \n\nO algoritmo do SOM se resume, ent\u00e3o, de acordo com Haykin (1999), em 5 etapas: \n \n\n1. Inicializa\u00e7\u00e3o: escolha dos pesos sin\u00e1pticos de todos os neur\u00f4nios para o tempo \n\ndiscreto ?=0. Usualmente a inicializa\u00e7\u00e3o \u00e9 feita de modo aleat\u00f3rio; \n2. Amostragem: retirada de um conjunto de dados do espa\u00e7o de entrada e \n\nalimenta\u00e7\u00e3o do mesmo no processo de competi\u00e7\u00e3o; \n\n3. Determina\u00e7\u00e3o do neur\u00f4nio vencedor: determinar qual neur\u00f4nio tem a maior \n\nativa\u00e7\u00e3o para o conjunto de dados alimentados pela menor dist\u00e2ncia euclidiana, \n\nessa etapa corresponde ao processo de competi\u00e7\u00e3o; \n\n4. Atualiza\u00e7\u00e3o: os pesos sin\u00e1pticos do neur\u00f4nio vencedor e de seus vizinhos s\u00e3o \n\natualizados conforme a equa\u00e7\u00e3o 2.8. Corresponde ao processo adaptativo; \n\n5. Continua\u00e7\u00e3o: volta ao passo da amostragem at\u00e9 que n\u00e3o sejam observadas \n\nmudan\u00e7as significativas no mapa. \n\n  \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n12 \n\n3 Mate ri ai s  e  M\u00e9 to do s  \n\nComo n\u00e3o se dispunha de dados operacionais contemplando uma ampla regi\u00e3o de \nopera\u00e7\u00e3o, optou-se pela constru\u00e7\u00e3o de uma simula\u00e7\u00e3o est\u00e1tica utilizando o software \nAspen Plus e obter os dados necess\u00e1rios para implementar a t\u00e9cnica de redes neurais e \nde self-organizing maps. O algoritmo referente aos mapas auto-organiz\u00e1veis j\u00e1 est\u00e1 \ndispon\u00edvel em MATLAB, ent\u00e3o foi escolhido este programa para processar as vari\u00e1veis de \nentrada. A seguir ser\u00e1 descrito como foi usado cada programa. \n\n3.1 Aspen Plus \n\nO software Aspen Plus oferece um amplo banco de dados no que se refere a \ncomponentes puros e equil\u00edbrio de fases entre eles, al\u00e9m de poder incluir no fluxograma \ncolunas de destila\u00e7\u00e3o, compressores e trocadores de calor. Sendo assim mostrou-se uma \nboa ferramenta para simular qualquer planta que fosse necess\u00e1ria. Adicionalmente, \u00e9 um \nprograma que gera os dados referentes \u00e0 simula\u00e7\u00e3o facilmente, caracter\u00edstica \nfundamental para uma boa utiliza\u00e7\u00e3o de mapas auto-organiz\u00e1veis, j\u00e1 que os mesmos \nrequerem um vasto conjunto de dados de entrada. \n\nPara a realiza\u00e7\u00e3o da simula\u00e7\u00e3o \u00e9 preciso escolher o pacote termodin\u00e2mico que o \nAspen Plus ir\u00e1 utilizar para o c\u00e1lculo das intera\u00e7\u00f5es entre os diversos componentes de \nalimenta\u00e7\u00e3o da planta. O pacote termodin\u00e2mico escolhido para a simula\u00e7\u00e3o foi o Peng-\nRobinson, que apresenta bons resultados quando os componentes presentes s\u00e3o de \norigem petroqu\u00edmica. Esse pacote n\u00e3o \u00e9 aconselhado quando se tem a presen\u00e7a de \u00e1gua, \no que acontecia nos dados fornecidos de simula\u00e7\u00e3o. A fim de contornar esse problema, \nfoi retirada a alimenta\u00e7\u00e3o de \u00e1gua da primeira coluna de destila\u00e7\u00e3o, respons\u00e1vel por \nseparar os compostos C2 dos C3, j\u00e1 que a totalidade da \u00e1gua \u00e9 retirada nessa coluna e o \nobjetivo de estudo do trabalho era a coluna de separa\u00e7\u00e3o de propeno e propano, sendo \nassim, a \u00e1gua n\u00e3o atrapalhou os resultados da simula\u00e7\u00e3o. \n\nPara a simula\u00e7\u00e3o das colunas de destila\u00e7\u00e3o foi utilizado o bloco \u201cRadFrac\u201d, que pode \nsimular todo tipo de fracionamento l\u00edquido-vapor em m\u00faltiplos est\u00e1gios. Para o \nrefervedor da coluna de separa\u00e7\u00e3o propano e propeno utilizou-se o bloco \u201cHeatX\u201d, que \u00e9 \nusado para a troca de calor entre duas correntes de alimenta\u00e7\u00e3o. Nesse bloco \u00e9 poss\u00edvel \nespecificar somente a \u00e1rea de troca t\u00e9rmica e as temperaturas de sa\u00edda s\u00e3o calculadas \ntomando valores para o coeficiente de troca t\u00e9rmica global. Para o compressor utilizou-se \no bloco \u201cCompr\u201d, escolhendo um modelo isentr\u00f3pico e especificando a press\u00e3o de \ndescarga. O vaso de topo foi simulado utilizando o bloco de nome \u201cFlash2\u201d, usado quando \nse tem duas correntes de sa\u00edda, para o mesmo foram especificadas a press\u00e3o e a \ntemperatura. \n\nAp\u00f3s concluir-se a simula\u00e7\u00e3o foram feitas diversas an\u00e1lises de sensibilidade da planta \nvariando tanto caracter\u00edsticas dentro do processo, como a quantidade de corrente \ndesviada para o hot bypass, press\u00e3o de sa\u00edda do compressor assim como a carga de \nalimenta\u00e7\u00e3o. A varia\u00e7\u00e3o dessas caracter\u00edsticas foi analisada coletando informa\u00e7\u00f5es \nimportantes e assim gerando um banco de dados de opera\u00e7\u00e3o da planta important\u00edssimo \npara o desenvolvimento do trabalho. \n\nDe posse desses dados foi poss\u00edvel seguir para a pr\u00f3xima etapa, realizada em \nMATLAB. \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 13\n\n3.2 MATLAB \n\nPara a aplica\u00e7\u00e3o da t\u00e9cnica das redes neurais e de mapas auto-organiz\u00e1veis escolheu-\nse trabalhar com o programa MATLAB, que se mostra uma ferramenta muito \u00fatil quando \nquer se trabalhar com matrizes, que \u00e9 o caso em quest\u00e3o. No MATLAB foram feitos dois \nprocessos distintos: pr\u00e9-processamento dos dados por eliminar amostras que seriam \nmuito semelhantes \u00e0s outras e a aplica\u00e7\u00e3o da t\u00e9cnica de self-organizing maps em si, para \nposterior escolha do que mais se adequava ao objetivo proposto. Esta se\u00e7\u00e3o est\u00e1 dividida \nnas duas partes j\u00e1 mencionadas. \n\n3.2.1 Algoritmo para pr\u00e9-processamento de dados \n\nO treinamento de um mapa por self-organizing maps \u00e9 influenciado somente pelos \ndados que s\u00e3o alimentados ao mesmo, assim sendo, a escolha dos dados a serem \nalimentados \u00e9 de fundamental import\u00e2ncia. A remo\u00e7\u00e3o de dados muito semelhantes \ntorna-se importante quando o banco de dados fornecido para o treinamento possui \nmuitas amostras da mesma regi\u00e3o. Desse jeito a regi\u00e3o que possui mais dados acaba \nsendo muito representada e a exist\u00eancia de outra regi\u00e3o com menos dados, por\u00e9m n\u00e3o \nnecessariamente menos importante, \u00e9 mascarada. \n\nEm MATLAB foi criado um algoritmo que conseguisse filtrar os dados de entrada em \ndados que fossem realmente diferentes entre si, a fim de acabar com o problema de um \nexagero de dados da mesma regi\u00e3o. Para tanto, cada conjunto de dados era comparado \ncom os dados da nova matriz filtrada atrav\u00e9s da equa\u00e7\u00e3o a seguir \n\n 4 \n,? ? H\n,?4 > I\t????\t. = 1,2,\u2026 , ?\t,+ = 1,2, \u2026 ,2\t6\t? = 1,2, \u2026 , J (3.1) \nOnde I \u00e9 um valor arbitr\u00e1rio,  \n,? \u00e9 o dado alimentado, H\n,? \u00e9 o dado da nova matriz j\u00e1 \n\nfiltrada, J \u00e9 o n\u00famero de vari\u00e1veis e ? e 2 s\u00e3o o numero de amostras do conjunto de \ndados alimentados e da matriz filtrada, respectivamente. \n\nNo algoritmo criado o primeiro dado alimentado era automaticamente transferido \npara a matriz filtrada e ent\u00e3o come\u00e7ava a rotina de analisar se a pr\u00f3xima amostra \nsatisfazia a equa\u00e7\u00e3o de n\u00famero 3.1. Se a equa\u00e7\u00e3o 3.1 fosse satisfeita para pelo menos um \nvalor de ? em todas as 2 amostras da nova matriz a amostra de dados alimentada era \nconsiderada apta a fazer parte da matriz filtrada. Desse jeito, foi poss\u00edvel pr\u00e9-processar os \ndados de forma eficiente e avaliar qual valor de I produzia um mapa de melhor \nqualidade facilmente.\t \n\n\u00c9 importante frisar que esse algoritmo s\u00f3 tem finalidade se for utilizado em dados \nnormalizados, j\u00e1 que o valor de I n\u00e3o muda para as vari\u00e1veis. Logo, se fosse aplicado em \ndados n\u00e3o normalizados, haveria distor\u00e7\u00f5es devido \u00e0s diferentes ordens de grandeza das \nvari\u00e1veis. A normaliza\u00e7\u00e3o, que no caso foi pela vari\u00e2ncia, foi feita dentro do mesmo \ntoolbox em que se aplicou a t\u00e9cnica de self-organizing maps.  \n\n3.2.2 SOM Toolbox \n\nO toolbox utilizado, chamado de \u201cSOM Toolbox\u201d, foi desenvolvido pela mesma equipe \nde pesquisadores que trabalha com quem formulou toda a base matem\u00e1tica para a \nevolu\u00e7\u00e3o da t\u00e9cnica de mapas auto-organiz\u00e1veis. O \u201cSOM Toolbox\u201d \u00e9 uma ferramenta \nmuito vers\u00e1til e de f\u00e1cil utiliza\u00e7\u00e3o, sendo poss\u00edvel tanto pr\u00e9-processar como processar os \ndados e visualizar os resultados de forma muito r\u00e1pida. \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n14 \n\nA biblioteca implementada pelo toolbox tem fun\u00e7\u00f5es para normalizar os dados de \nentrada, o que \u00e9 muito importante, j\u00e1 que as grandezas entre as vari\u00e1veis podem diferir \nconsideravelmente. Outras caracter\u00edsticas podem ser alteradas, como o n\u00famero de \nneur\u00f4nios treinados pelo mapa, treinamento sequencial ou em batelada, inicializa\u00e7\u00e3o do \nmapa topol\u00f3gico hexagonal ou retangular, fun\u00e7\u00e3o da vizinhan\u00e7a utilizada, inicializa\u00e7\u00e3o \ndos pesos sin\u00e1pticos rand\u00f4mica ou linear, entre outras. Tamb\u00e9m \u00e9 poss\u00edvel treinar o \nmapa em duas etapas: primeiro a etapa de converg\u00eancia com todos os dados e depois \nescolher um conjunto para a etapa de sintonia fina, assim representando-o de forma mais \nprecisa. \n\nAp\u00f3s o treinamento do mapa de neur\u00f4nios por self-organizing maps usou-se uma \netapa supervisionada de treinamento, ou seja, com um professor. Para cada conjunto de \ndados foi fornecida uma resposta desejada do sistema, ou seja, cada conjunto de \nvari\u00e1veis tinha um \u201cr\u00f3tulo\u201d referente a uma vari\u00e1vel de sa\u00edda. No caso, foi estabelecido \ncomo vari\u00e1vel de sa\u00edda a concentra\u00e7\u00e3o molar de propeno no produto de topo da segunda \ncoluna de destila\u00e7\u00e3o. \n\n   \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 15\n\n4 E stud o  d e  C as o  \n\nA metodologia estabelecida no Cap\u00edtulo 3 ser\u00e1 aplicada a uma unidade de \nprocessamento de g\u00e1s liquefeito de petr\u00f3leo em funcionamento pertencente \u00e0 \nPETROBRAS. O presente cap\u00edtulo est\u00e1 dividido em duas partes: a primeira parte \ndescrevendo a unidade que foi estudada e as suas caracter\u00edsticas e a segunda parte sobre \na constru\u00e7\u00e3o da simula\u00e7\u00e3o da unidade em quest\u00e3o no software Aspen Plus. Parte do \nescopo do trabalho ser\u00e1 a constru\u00e7\u00e3o da simula\u00e7\u00e3o est\u00e1tica da coluna desetanizadora e \nda coluna de separa\u00e7\u00e3o de propano e propeno e a predi\u00e7\u00e3o de vari\u00e1veis de sa\u00edda da \n\u00faltima coluna, que tem como objetivo separar uma alimenta\u00e7\u00e3o composta de propano e \npropeno e outros contaminantes. Os dados, tanto de caracter\u00edsticas do sistema como \ncomposi\u00e7\u00f5es das correntes, foram fornecidos e utilizados para a constru\u00e7\u00e3o da simula\u00e7\u00e3o \nem Aspen Plus. \n\n4.1 Unidade de Processamento de G\u00e1s Liquefeito de Petr\u00f3leo \n\nA alimenta\u00e7\u00e3o da unidade consiste de hidrocarbonetos de dois a seis carbonos e \nbasicamente de tr\u00eas colunas de destila\u00e7\u00e3o que ser\u00e3o melhores descritas a seguir. O \nfluxograma geral da unidade est\u00e1 representado na Figura 4.1. \n\n4.1.1 Coluna despropanizadora \n\nA primeira coluna da unidade recebe a alimenta\u00e7\u00e3o com hidrocarbonetos de C2 a C6 e \n\u00e1gua e tem a finalidade de separar os compostos com mais de quatro carbonos do \nrestante. Esta coluna consegue atingir uma remo\u00e7\u00e3o de praticamente 99,9% de \nindesejados, deixando passar apenas resqu\u00edcios de isobutano, isobuteno e 1-buteno junto \ncom o etano, o propano, o propeno e \u00e1gua. Essa coluna n\u00e3o foi simulada em Aspen, \nsomente foram utilizadas as propriedades e a composi\u00e7\u00e3o do produto de topo para a \nsegunda coluna. A coluna despropanizadora est\u00e1 representada por D-1 na Figura 4.1 e a \nalimenta\u00e7\u00e3o, refluxo, produto de topo e produto de fundo s\u00e3o as correntes 1, 3, 5 e 6 \nrespectivamente. A corrente 5 \u00e9 a alimenta\u00e7\u00e3o da segunda coluna, a desetanizadora, a \nqual ser\u00e1 objeto de estudo desse trabalho, juntamente com a coluna de separa\u00e7\u00e3o \npropano e propeno. \n\nA corrente de topo ainda \u00e9 passada por um tratamento de lavagem c\u00e1ustica, um vaso \nde lavagem com \u00e1gua e um vaso de decanta\u00e7\u00e3o para remo\u00e7\u00e3o de impurezas presentes \ncomo sulfeto de hidrog\u00eanio, representados por V-1, V-2 e V-3. \n\n4.1.2 Coluna desetanizadora \n\nA segunda coluna de destila\u00e7\u00e3o da unidade recebe o produto de topo da coluna \ndespropanizadora e tem a finalidade de remover o etano e a \u00e1gua para a pr\u00f3xima etapa. \nA remo\u00e7\u00e3o de etano \u00e9 de cerca de 99,8% da alimenta\u00e7\u00e3o e a \u00e1gua \u00e9 totalmente removida. \nO produto de topo da coluna \u00e9 mandado para a unidade de FCC (Fluid Catalytic Cracking) \ncontendo etano e tamb\u00e9m propano e propeno em baixas quantidades. O produto de \nfundo, contendo principalmente propano e propeno \u00e9 enviado para a coluna de \nsepara\u00e7\u00e3o dos dois. A coluna deetanizadora foi simulada em Aspen Plus com os dados de \nsimula\u00e7\u00e3o fornecidos pelo respectivo projeto. \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-organizing maps 16 \n\n \n\nFigura 4.1: Fluxograma da Unidade de Processamento de G\u00e1s Liquefeito de Petr\u00f3leo.\n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 17\n\nNa Figura 4.1 a coluna est\u00e1 representada pelo nome de D-2 e as correntes de \nalimenta\u00e7\u00e3o, refluxo, produto de topo e produto de fundo representadas pelas correntes \nde n\u00famero 5, 9, 8 e 10 respectivamente. A corrente 10 \u00e9 a alimenta\u00e7\u00e3o da terceira \ncoluna. \n\n4.1.3 Coluna de separa\u00e7\u00e3o propano e propeno \n\nA terceira coluna da unidade \u00e9 a mais complexa de todas, com mais de 150 pratos de \ndestila\u00e7\u00e3o e peculiaridades operacionais que a distinguem das outras colunas \npertencentes \u00e0 unidade. A alimenta\u00e7\u00e3o \u00e9 proveniente do produto de fundo da coluna \ndesetanizadora e \u00e9 composta de propano e propeno em grandes quantidades, totalizando \nquase 99,9% do total, e etano, isobutano, isobuteno e 1-buteno em baix\u00edssimas \nquantidades. A recupera\u00e7\u00e3o de propeno no produto de topo \u00e9 de 98,8% enquanto que a \nde propano no produto de fundo \u00e9 de 98,4%. \n\nO tamanho da coluna a princ\u00edpio parece exagerado, por\u00e9m quando comparam-se as \npropriedades f\u00edsicas e qu\u00edmicas de propano e propeno se torna evidente que \u00e9 necess\u00e1rio \numa coluna de tamanha propor\u00e7\u00e3o para que se tenha uma separa\u00e7\u00e3o efetiva, j\u00e1 que a \ndestila\u00e7\u00e3o simples utilizada baseia-se na diferen\u00e7a entre as temperaturas de ebuli\u00e7\u00e3o dos \ncomponentes. A viabilidade econ\u00f4mica da coluna tamb\u00e9m pode ser questionada, por\u00e9m \na diferen\u00e7a consider\u00e1vel de pre\u00e7o entre o propano, que retorna a GLP, e o propeno, que \u00e9 \nmat\u00e9ria-prima fundamental da ind\u00fastria de pol\u00edmeros, torna esse balan\u00e7o favor\u00e1vel \u00e0 \nsepara\u00e7\u00e3o entre os dois, mesmo que para isso seja necess\u00e1ria uma coluna de propor\u00e7\u00f5es \nt\u00e3o grandes.  \n\nA coluna est\u00e1 representada na Figura 4.1 pela legenda D-3, e sua alimenta\u00e7\u00e3o \u00e9 a \ncorrente 10. A sa\u00edda de topo, representada pela corrente 12, se junta com a corrente de \nvapor da sa\u00edda do vaso de topo, representada pela corrente 21, e entra em um vaso para \nretirada de l\u00edquido. A sa\u00edda de vapor desse vaso segue para um compressor, que ir\u00e1 \naumentar tanto a press\u00e3o como a temperatura dessa corrente. O uso de um vaso para a \nretirada de l\u00edquido tem import\u00e2ncia visto que a alimenta\u00e7\u00e3o do compressor tem que ser \ncomposta somente por vapor. \n\nO vapor comprimido da sa\u00edda do compressor \u00e9 dividido em duas correntes: a corrente \n16, que vai para o condensador refrigerado com \u00e1gua, e a corrente 14, que segue para o \nrefervedor da coluna. No refervedor da coluna h\u00e1 um trocador de calor, representado \npelo nome de E-1, entre a corrente 14 e a corrente 18, que \u00e9 recirculada para dentro da \ncoluna ap\u00f3s ser evaporada. Essa estrat\u00e9gia de opera\u00e7\u00e3o, chamada de bomba de calor, \ndispensa o uso de utilidades no refervedor da coluna, diminuindo os custos de opera\u00e7\u00e3o. \n\nA corrente 14, ap\u00f3s a passagem pelo trocador de calor, \u00e9 dividida mais uma vez em \nduas correntes: a corrente 15 \u00e9 resfriada e retirada como produto de topo rico em \npropeno e o resto junta-se com a corrente 16 que vem do condensador e vai para o vaso \nde topo. Do vaso de topo sai a corrente j\u00e1 mencionada 21 que se junta com a sa\u00edda de \ntopo da coluna e tamb\u00e9m a corrente 17 que retorna \u00e0 coluna como refluxo. \n\nOutra caracter\u00edstica dessa coluna de destila\u00e7\u00e3o \u00e9 a possibilidade de uma divis\u00e3o da \ncorrente de sa\u00edda do compressor direto para o vaso de topo, numerada pela corrente 19. \nEssa estrat\u00e9gia, chamada de hot bypass, \u00e9 uma forma de controlar a press\u00e3o dentro do \nvaso de topo de forma mais eficiente. \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n18 \n\nDo fundo da coluna saem duas correntes: a 18 que volta como recircula\u00e7\u00e3o \nproveniente do refervedor e a 11, que \u00e9 o produto de fundo rico em propano, \u00e9 \nbombeada como GLP. \n\nAs vari\u00e1veis controladas da coluna s\u00e3o a press\u00e3o de topo e os n\u00edveis da coluna, do \ncondensador e do refervedor. As principais vari\u00e1veis manipuladas s\u00e3o as vaz\u00f5es de \nrefluxo, de produto de topo e fundo.   \n\n4.2 Constru\u00e7\u00e3o da simula\u00e7\u00e3o em Aspen Plus \n\nPara a aplica\u00e7\u00e3o da t\u00e9cnica de self-organizing maps \u00e9 necess\u00e1rio que se tenha um \namplo banco de dados contendo ampla regi\u00e3o operacional da unidade estudada. Para \nisso, foi constru\u00edda a simula\u00e7\u00e3o da planta em Aspen plus. Desse jeito, seria f\u00e1cil manipular \nvari\u00e1veis da planta e gerar um conjunto de amostras significativo. Na Figura 4.2 se v\u00ea o \nfluxograma da simula\u00e7\u00e3o realizada. O pacote termodin\u00e2mico escolhido, como j\u00e1 foi \nmencionado, \u00e9 o Peng-Robinson (PR) visto que o simulador possui os par\u00e2metros \nnecess\u00e1rios para a mistura estudada, rica em hidrocarbonetos. \n\nNa simula\u00e7\u00e3o construiram-se apenas as colunas deetanizadora e de separa\u00e7\u00e3o \npropano e propeno, j\u00e1 que o foco do trabalho \u00e9 estudar a segunda. A coluna \ndesetanizadora foi a de mais f\u00e1cil implementa\u00e7\u00e3o, j\u00e1 que seus refluxos foram feitos \ninternamente no seu bloco. A coluna de separa\u00e7\u00e3o propano e propeno apresentou \nmaiores dificuldades na constru\u00e7\u00e3o e na converg\u00eancia pela necessidade de estabelecer os \nreciclos externamente ao bloco j\u00e1 implementado em Aspen Plus.  \n\n \n\nFigura 4.2: Fluxograma da simula\u00e7\u00e3o realizada em Aspen Plus. \n\nDe posse da simula\u00e7\u00e3o foi poss\u00edvel, atrav\u00e9s da ferramenta de an\u00e1lise de sensibilidade, \nvariar caracter\u00edsticas de simula\u00e7\u00e3o da planta e obter os dados necess\u00e1rios para aplica\u00e7\u00e3o \nda t\u00e9cnica. Para as vari\u00e1veis manipuladas variou-se a press\u00e3o de sa\u00edda do compressor, \nrepresentado na Figura 4.2 pelo bloco B11, a sa\u00edda de produto de topo variando o valor \ndo bloco B15, a vaz\u00e3o de hot bypass, alterando o valor de split do bloco que recebe a \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 19\n\ndescarga do compressor e tamb\u00e9m a carga de alimenta\u00e7\u00e3o da coluna deetanizadora \nrepresentada pela corrente 1. \n\nPara as vari\u00e1veis de sa\u00edda utilizou-se a carga total da planta, o split do bloco B15, as \ncomposi\u00e7\u00f5es de propano e propeno no produto de topo e de fundo, as vaz\u00f5es molares de \nproduto de topo e de fundo, a vaz\u00e3o da corrente que vai para o condensador, a vaz\u00e3o de \nhot bypass e de refluxo, a press\u00e3o de sa\u00edda do compressor, o calor trocado no refervedor \nda coluna e as temperaturas dos pratos 20, 40, 80, 100, 120 e 140 da coluna de separa\u00e7\u00e3o \npropano e propeno, resultando em 19 vari\u00e1veis. \n\nCom todas essas varia\u00e7\u00f5es criou-se um banco de dados com 1243 amostras das 19 \nvari\u00e1veis, alterando as vari\u00e1veis manipuladas at\u00e9 os seus limites de converg\u00eancia na \nsimula\u00e7\u00e3o. A press\u00e3o de sa\u00edda do compressor, representado pelo bloco B11, foi variada de \n33% a menos at\u00e9 20% a mais que a folha de dados de projeto. No bloco B15, em que foi \nvariada a fra\u00e7\u00e3o de corrente direcionada a produto de topo, foi alterado o valor de 0,05 \nat\u00e9 0,15, sendo que o dado de projeto \u00e9 de 0,08. A vaz\u00e3o de hot bypass, igualada a zero \nno projeto, foi variada de 0 a 5% de corrente direcionada do bloco que recebe a descarga \ndo compressor e a carga de alimenta\u00e7\u00e3o foi variada, em rela\u00e7\u00e3o aos dados de projeto, de \n40% menos at\u00e9 30% mais no que se refere \u00e0 vaz\u00e3o total.   \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n20 \n\n5 Re s u l tad os  \n\nOs resultados deste trabalho ser\u00e3o divididos em tr\u00eas partes. Na primeira parte ser\u00e3o \napresentados os resultados da simula\u00e7\u00e3o feita em Aspen Plus e os erros quando \ncomparados os dados de simula\u00e7\u00e3o aos dados de projeto. Na segunda ser\u00e3o mostradas as \nmatrizes-U para os mapas treinados pelos dados de simula\u00e7\u00e3o tanto com como sem a \naplica\u00e7\u00e3o do algoritmo de remo\u00e7\u00e3o de dados semelhantes assim como as trajet\u00f3rias \ncrescentes de composi\u00e7\u00e3o e de vari\u00e1veis de opera\u00e7\u00e3o da planta. Na terceira parte ser\u00e3o \nmostrados os resultados da etapa supervisionada para a predi\u00e7\u00e3o de composi\u00e7\u00e3o de \npropeno no produto de topo. \n\n5.1 Simula\u00e7\u00e3o em Aspen Plus \n\nA simula\u00e7\u00e3o em Aspen Plus foi realizada com os dados de projeto fornecidos para as \ncolunas desetanizadora e de separa\u00e7\u00e3o propano e propeno. Na Tabela 5.1 encontram-se \nos erros relativos entre a simula\u00e7\u00e3o realizada e os dados de projeto para a carga total e \nconcentra\u00e7\u00e3o molar de propeno nas principais correntes fornecidos pela refinaria. \n\nTabela 5.1: Compara\u00e7\u00e3o dos dados de carga total, concentra\u00e7\u00e3o molar de propeno e \ntemperatura da simula\u00e7\u00e3o realizada em Aspen com os dados de projeto. \n\nCorrentes \n\nErro relativo (%) \n\nentre a carga total \n\nde projeto e \n\nsimula\u00e7\u00e3o \n\nErro relativo (%) entre \n\na concentra\u00e7\u00e3o molar \n\nde propeno de \n\nprojeto e simula\u00e7\u00e3o \n\nErro relativo (%) \n\nentre a \n\ntemperatura de \n\nprojeto e de \n\nsimula\u00e7\u00e3o \n\n8 0,211 0,013 0,041 \n\n10 0,024 0,001 0,187 \n\n11 0,506 6,945 0,289 \n\n12 1,474 1,381 0,303 \n\n14 1,693 1,600 0,672 \n\n15 0,007 0,098 0,639 \n\n16 0,000 0,091 0,076 \n\n17 1,574 1,481 0,311 \n\n21 1,574 1,507 3,337 \n\n  \n\nComo visto na Tabela 5.1 a simula\u00e7\u00e3o gerou dados com erros muito baixos em rela\u00e7\u00e3o \naos dados de projeto. O maior erro, na corrente de n\u00famero 11 da concentra\u00e7\u00e3o de \npropeno, se explica porque essa corrente \u00e9 a de propano concentrado, portanto, a \nconcentra\u00e7\u00e3o de propeno \u00e9 muito baixa. \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 21\n\n5.2 Matrizes-U \n\nPara visualiza\u00e7\u00e3o do mapa treinado por SOM o mais comum \u00e9 utilizar-se a matriz-U. A \nmatriz-U \u00e9 calculada pela equa\u00e7\u00e3o 5.1 e \u00e9 preenchida com uma escala de cor para as \ndistancias calculadas. O centro de cada hex\u00e1gono \u00e9 um neur\u00f4nio e regi\u00f5es de cor \nreferentes a baixas dist\u00e2ncias podem ser interpretadas como clusters. \n\n K = ? ?/\t/?0 ? \t/200\n#\tL\tMM(N)\n\n (5.1) \n\nOnde D \u00e9 o valor mostrado na matriz-U, ?O\t(?) ? \t(2)P \u00e9 a dist\u00e2ncia entre o vetor \npeso sin\u00e1ptico do neur\u00f4nio ? e do neur\u00f4nio 2 e QQ(?) o conjunto de neur\u00f4nios vizinhos \na ?. \n\nA seguir ser\u00e3o mostradas diversas matrizes para diferentes tamanhos de mapas e \ntamb\u00e9m para diferentes valores para o algoritmo de pr\u00e9-processamento de dados e \ntamb\u00e9m trajet\u00f3rias crescentes de composi\u00e7\u00e3o para o mapa escolhido. \n\n5.2.1 Matrizes-U para todos os dados \n\nCom os dados obtidos a partir da simula\u00e7\u00e3o, foi treinado o mapa com o SOM Toolbox \npara diferentes tamanhos. O tamanho do mapa \u00e9 automaticamente calculado pelo \ntoolbox pelos auto valores associados \u00e0 matriz do conjunto de dados de entrada, e ent\u00e3o \nesse valor foi alterado para ver o que produzia a melhor matriz-U. Na Figura 5.1 s\u00e3o \nobservadas as matrizes de tamanho pequeno, normal e grande do mapa. O mapa de \ntamanho pequeno tem aproximadamente um quarto do n\u00famero de neur\u00f4nios do mapa \nde tamanho normal, enquanto que o mapa de tamanho grande tem quatro vezes o \nn\u00famero de neur\u00f4nios. \n\nO n\u00famero de neur\u00f4nios calculados para o mapa de tamanho normal pelos auto \nvalores associados \u00e0 matriz do conjunto de dados de entrada foi de 20x9. Sendo assim, os \nmapas de tamanho pequeno e grande t\u00eam tamanhos de 9x5 e 40x18. \n\n \n\nFigura 5.1: Matrizes-U para diferentes tamanhos de mapa. (a) pequeno, (b) normal e (c) \ngrande. \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n22 \n\nPela Figura 5.1 \u00e9 visto claramente como o tamanho do mapa tem import\u00e2ncia \nfundamental para a posterior caracteriza\u00e7\u00e3o do mesmo. O mapa pequeno n\u00e3o consegue \nseparar adequadamente as regi\u00f5es e acaba juntando diferentes regi\u00f5es de opera\u00e7\u00e3o no \nmesmo lugar, impossibilitando a an\u00e1lise. O mapa normal j\u00e1 come\u00e7a a delimitar melhor as \nregi\u00f5es de opera\u00e7\u00e3o e o mapa grande acaba tendo uma separa\u00e7\u00e3o exagerada das regi\u00f5es, \ncriando clusters muito grandes, representados pelas regi\u00f5es azuis. A seguir foi feito um \nmapa com tamanho 20x5, representado na Figura 5.2, para melhorar a resolu\u00e7\u00e3o do \nmapa de tamanho normal.  \n\n \n\nFigura 5.2: Matriz-U do mapa de tamanho 20x5. \n\nA seguir, na Figura 5.3 pode ser vista a visualiza\u00e7\u00e3o em 3D para a matriz-U, dessa vez \ncom uma componente vertical representando as dist\u00e2ncias entre o neur\u00f4nio e os seus \nneur\u00f4nios vizinhos. \n\n \n\nFigura 5.3: Visualiza\u00e7\u00e3o da Matriz-U em 3 dimens\u00f5es para o mapa de tamanho 20x5. \n\n\u00c9 poss\u00edvel ver quatro regi\u00f5es bem distintas na matriz em 3D representada na Figura \n5.3. As regi\u00f5es 1 e 4 est\u00e3o bem separadas das restantes, enquanto que as regi\u00f5es de 2 e 3 \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 23\n\nt\u00eam uma separa\u00e7\u00e3o mais suave entre elas. Para a posterior classifica\u00e7\u00e3o de cada uma das \nregi\u00f5es \u00e9 necess\u00e1rio tra\u00e7ar as trajet\u00f3rias dos neur\u00f4nios vencedores em ordem crescente \nou decrescente de uma das vari\u00e1veis. Dentre todos os mapas, o de tamanho 20x5 foi o \nque conseguiu separar melhor as regi\u00f5es e foi escolhido para a visualiza\u00e7\u00e3o das \ntrajet\u00f3rias. \n\n5.2.2 Matrizes-U ap\u00f3s pr\u00e9-processamento dos dados \n\nNa cria\u00e7\u00e3o do algoritmo para remo\u00e7\u00e3o de dados similares deixou-se o valor arbitr\u00e1rio \npodendo ser escolhido pelo usu\u00e1rio, e claramente a escolha dele tem implic\u00e2ncias diretas \nna qualidade do mapa treinado. A seguir s\u00e3o mostradas diversas matrizes-U resultantes \ndos mapas treinados utilizando diferentes valores de I. As matrizes s\u00e3o mostradas nos \ntamanhos normal e grande. \n\nQuanto maior o valor de T mais restrita \u00e9 a nova matriz de dados filtrada. De um \nbanco de dados inicial de 1243 amostras, a matriz filtrada para os valores de T 0,02, 0,04 \ne 0,1 tem, respectivamente, em torno de 740, 540 e 260 amostras. As Figuras 5.4, 5.5 e \n5.6 mostram as matrizes-U de tamanho normal e grande para valores de T iguais a 0,02, \n0,04 e 0,1, respectivamente. \n\n \n\nFigura 5.4:  Matrizes-U para ? = ?, ??. \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n24 \n\n \n\nFigura 5.5: Matrizes-U para ? = ?, ??. \n \n\n \n\nFigura 5.6: Matrizes-U para ? = ?, ?. \n\u00c9 visto, claramente, que quanto maior o valor de I cada vez menos regi\u00f5es \n\noperacionais s\u00e3o representadas no mapa devido ao cada vez menor n\u00famero de dados \nalimentados para o treinamento. O mapa treinado com o valor de I igual a 0,02 foi o que \napresentou a melhor separa\u00e7\u00e3o entre as regi\u00f5es e a visualiza\u00e7\u00e3o da matriz-U em 3D \u00e9 \nrepresentada na Figura 5.7. As seis principais regi\u00f5es operacionais que o mapa \napresentou est\u00e3o numeradas no gr\u00e1fico. \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 25\n\n \n\nFigura 5.7: Visualiza\u00e7\u00e3o da Matriz-U em 3 dimens\u00f5es com aplica\u00e7\u00e3o do algoritmo, T igual \na 0,02 e mapa de tamanho grande. \n\n5.3 Trajet\u00f3rias aplicadas ao mapa escolhido \n\nComo os mapas auto-organiz\u00e1veis n\u00e3o permitem, a princ\u00edpio, visualizar a evolu\u00e7\u00e3o de \nalguma vari\u00e1vel no mapa, \u00e9 preciso ordenar a vari\u00e1vel que se quer estudar, de forma \ncrescente ou decrescente e, para cada amostra calcular o neur\u00f4nio vencedor associado. \nPosteriormente, marcam-se na matriz-U os neur\u00f4nios vencedores e tra\u00e7a-se a trajet\u00f3ria \nentre os pontos. Na simula\u00e7\u00e3o, para a obten\u00e7\u00e3o dos dados, variaram-se 4 caracter\u00edsticas \nda planta: vaz\u00e3o do produto de topo, press\u00e3o de descarga do compressor, vaz\u00e3o de hot \nbypass e carga total de alimenta\u00e7\u00e3o. Obtiveram-se 499 dados para a varia\u00e7\u00e3o da fra\u00e7\u00e3o da \ncorrente direcionada para o produto, 99 para a vaz\u00e3o de hot bypass, 145 para a press\u00e3o \nde descarga do compressor e 500 para a carga de alimenta\u00e7\u00e3o. Para cada um desses \nbancos de dados foram feitas as trajet\u00f3rias crescentes da varia\u00e7\u00e3o respectiva e da \nconcentra\u00e7\u00e3o de propeno no produto de topo, portanto, cada par de matriz-U \napresentada no decorrer do trabalho foi alimentada com dados diferentes. \n\nNa Figura 5.8 tem-se a matriz-U com a trajet\u00f3ria crescente de composi\u00e7\u00e3o de propeno \nno topo e tamb\u00e9m a trajet\u00f3ria crescente da fra\u00e7\u00e3o direcionada ao produto de topo no \nbloco B15 da Figura 4.2. O menor valor est\u00e1 marcado com a cor azul, assim v\u00ea-se \nclaramente que a composi\u00e7\u00e3o e o valor da fra\u00e7\u00e3o seguem caminhos com sentidos \nopostos, por\u00e9m com a mesma tend\u00eancia.  \n\nDesse jeito conclui-se que a fra\u00e7\u00e3o da corrente de alimenta\u00e7\u00e3o do bloco que segue \ncomo produto tem rela\u00e7\u00e3o inversamente proporcional com a composi\u00e7\u00e3o de propeno, ou \nseja, quanto menor a vaz\u00e3o redirecionada para o produto de topo maior a concentra\u00e7\u00e3o \nde propeno dessa corrente. Tamb\u00e9m conclui-se que na matriz-U os valores de \ncomposi\u00e7\u00e3o baixa est\u00e3o em uma regi\u00e3o do mapa, enquanto que os de composi\u00e7\u00e3o alta \nest\u00e3o em outra regi\u00e3o oposta. Como os mapas s\u00e3o alimentados pelos mesmos dados, a \nescala de dist\u00e2ncia \u00e9 a mesma para os dois. A colora\u00e7\u00e3o do mapa na escala de cinza foi \nescolhida para melhor visualiza\u00e7\u00e3o da trajet\u00f3ria. \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n26 \n\n \n\nFigura 5.8: (a) trajet\u00f3ria crescente de composi\u00e7\u00e3o de propeno no topo e (b) trajet\u00f3ria \ncrescente da fra\u00e7\u00e3o da corrente direcionada para produto de topo. \n\n Um comportamento semelhante ao apresentado na Figura 5.8 \u00e9 mostrado na Figura \n5.9, que tem as trajet\u00f3rias crescentes da vaz\u00e3o de hot bypass e da concentra\u00e7\u00e3o de \npropeno no topo. V\u00ea-se claramente que ambas as trajet\u00f3rias possuem mesma tend\u00eancia, \npor\u00e9m agora as duas s\u00e3o diretamente proporcionais, o que pode ser visto pelos dois \nneur\u00f4nios marcados de azul referentes aos menores valores de vaz\u00e3o de hot bypass ou \nconcentra\u00e7\u00e3o. Assim conclui-se que, para os dados analisados, quanto maior o hot \nbypass, maior a concentra\u00e7\u00e3o de propeno no topo.  \n\n \n\nFigura 5.9: (a) trajet\u00f3ria crescente da composi\u00e7\u00e3o de propeno no topo e (b) trajet\u00f3ria \ncrescente da vaz\u00e3o de hot bypass. \n\n Nas Figuras 5.10 s\u00e3o apresentadas as trajet\u00f3rias crescentes de composi\u00e7\u00e3o de \npropeno no topo frente \u00e0 press\u00e3o de descarga do compressor e carga de alimenta\u00e7\u00e3o. V\u00ea-\nse que para os dados analisados a press\u00e3o de descarga do compressor segue a mesma \ntend\u00eancia at\u00e9 certo ponto e \u00e9 inversamente proporcional \u00e0 composi\u00e7\u00e3o de propeno no \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 27\n\ntopo, ou seja, quanto menor a press\u00e3o de descarga do compressor, maiores as \nconcentra\u00e7\u00f5es de propeno no topo para as amostras analisadas. \n\n \n\nFigura 5.10: trajet\u00f3ria crescentes (a) e (c) da composi\u00e7\u00e3o de propeno no topo, (b) da \npress\u00e3o de descarga do compressor e (d) da carga de alimenta\u00e7\u00e3o. \n\nA carga de alimenta\u00e7\u00e3o segue uma trajet\u00f3ria crescente completamente diferente da \ntrajet\u00f3ria crescente de composi\u00e7\u00e3o de propeno no topo para os mesmos dados \nanalisados, como pode ser visto na Figuras 5.10(c) e 5.10(d). Esse comportamento leva a \ncrer que a varia\u00e7\u00e3o da carga total de alimenta\u00e7\u00e3o da coluna n\u00e3o tem influ\u00eancia direta com \na composi\u00e7\u00e3o de propeno no produto.   \n\n5.4 Predi\u00e7\u00e3o da concentra\u00e7\u00e3o de propeno no topo \n\nPara a predi\u00e7\u00e3o da concentra\u00e7\u00e3o de propeno no topo \u00e9 preciso fazer uma etapa \nsupervisionada no mapa auto organiz\u00e1vel, que \u00e9 n\u00e3o supervisionado. A t\u00e9cnica do \nsupervisionado consiste em fornecer na etapa de treinamento um valor desejado para \ncada amostra. Posteriormente ao treinamento, \u00e9 alimentado um novo valor de amostras \nsem o valor que quer se predizer e calculado o BMU (Best Matching Unit). Cada neur\u00f4nio \ntem um valor associado a ele, e quando calcula-se o BMU de uma amostra tem-se o \nneur\u00f4nio que mais se assemelha \u00e0 amostra. Assim, o valor associado ao neur\u00f4nio \nvencedor \u00e9 tido como a resposta. \n\nA etapa de treinamento dos mapas foi realizada com os mesmos dados de simula\u00e7\u00e3o \nest\u00e1tica para os tr\u00eas diferentes tamanhos de mapa. Para a escolha dos dados que seriam \nusados somente para treinamento ordenou-se a matriz do banco de dados \naleatoriamente e tomaram-se as 1000 primeiras amostras. As 243 amostras restantes \nforam alimentadas na etapa supervisionada sem a concentra\u00e7\u00e3o de propeno no topo e \nrealizou-se a predi\u00e7\u00e3o da vari\u00e1vel. Com o valor predito pela t\u00e9cnica, o mesmo foi \ncomparado com o dado obtido na simula\u00e7\u00e3o est\u00e1tica da planta. \n\n A seguir, ser\u00e3o mostrados os resultados quando se prediz as composi\u00e7\u00f5es de propeno \nna corrente de topo utilizando mapas de tamanho pequeno, normal e grande. Por ter \nmais neur\u00f4nios, o mapa de tamanho grande \u00e9 previsto para ter os melhores resultados. \nComo a obten\u00e7\u00e3o do valor predito \u00e9 posterior \u00e0 determina\u00e7\u00e3o do neur\u00f4nio vencedor, se \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n28 \n\nhouver mais neur\u00f4nios no mapa, mais valores de resposta podem ser obtidos. O n\u00famero \nde neur\u00f4nios treinados pelos mapas de tamanho pequeno, normal e grande s\u00e3o 45, 180 e \n720, respectivamente.  \n\n Nas Figuras 5.11, 5.12 e 5.13 est\u00e3o apresentadas no gr\u00e1fico as concentra\u00e7\u00f5es \nprevistas pelo tamanho de mapa respectivo em um eixo e as concentra\u00e7\u00f5es da mesma \namostra tirada da simula\u00e7\u00e3o no outro eixo. Foi feita a predi\u00e7\u00e3o das mesmas 243 amostras \npara os tr\u00eas diferentes tamanhos de mapas e a reta de equa\u00e7\u00e3o H =  , que representa \nonde o erro \u00e9 nulo, tamb\u00e9m est\u00e1 representada no gr\u00e1fico.   \n\n \n\n  Figura 5.11: Resultado da predi\u00e7\u00e3o para o mapa treinado com tamanho pequeno. \n\n \n\n  Figura 5.12: Resultado da predi\u00e7\u00e3o para o mapa treinado com tamanho normal. \n\n8.80E-01\n\n9.00E-01\n\n9.20E-01\n\n9.40E-01\n\n9.60E-01\n\n9.80E-01\n\n1.00E+00\n\n1.02E+00\n\n0.88 0.9 0.92 0.94 0.96 0.98 1 1.02\n\nC\no\n\nn\nc\ne\n\nn\ntr\n\na\n\u00e7\n\u00e3\n\no\n p\n\nre\nv\n\nis\nta\n\nConcentra\u00e7\u00e3o de simula\u00e7\u00e3o\n\n8.80E-01\n\n9.00E-01\n\n9.20E-01\n\n9.40E-01\n\n9.60E-01\n\n9.80E-01\n\n1.00E+00\n\n1.02E+00\n\n0.88 0.9 0.92 0.94 0.96 0.98 1 1.02\n\nC\no\n\nn\nc\ne\n\nn\ntr\n\na\n\u00e7\n\u00e3\n\no\n p\n\nre\nv\n\nis\nta\n\nConcentra\u00e7\u00e3o de simula\u00e7\u00e3o\n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 29\n\n \n\n  Figura 5.13: Resultado da predi\u00e7\u00e3o para o mapa treinado com tamanho grande. \n\nO mapa de tamanho pequeno para diversas faixas de concentra\u00e7\u00f5es de sa\u00edda de \npropeno prev\u00ea o mesmo valor de sa\u00edda, isso se deve ao reduzido n\u00famero de neur\u00f4nios \ntreinados pelo mapa. Como visto anteriormente, cada neur\u00f4nio tem um valor desejado \nassociado, sendo assim o mapa de tamanho pequeno tem menos possibilidades de \nconcentra\u00e7\u00f5es de sa\u00edda resultando em maiores erros. Mesmo assim, o maior erro relativo \ncalculado para esse mapa foi de 2%. O mapa de tamanho normal apresenta a mesma \ntend\u00eancia de agrupamento de dados de sa\u00edda do mapa pequeno, por\u00e9m j\u00e1 come\u00e7a a \nrepresentar melhor algumas regi\u00f5es de concentra\u00e7\u00f5es. Para o mapa de tamanho normal \no maior erro relativo apresentado foi de 0,8%. \n\nComo previsto, o mapa de tamanho grande apresentou os menores erros para a \npredi\u00e7\u00e3o das amostras quando comparados com os outros tamanhos de mapas. O maior \nerro relativo apresentado por esse mapa foi de 0,5%, por\u00e9m mais de 93% dos dados \nanalisados apresentaram erros relativos menores que 0,1%. Pela an\u00e1lise dos desvios \npadr\u00f5es dos tr\u00eas diferentes mapas \u00e9 poss\u00edvel ver que o mapa de tamanho grande tem \ntamb\u00e9m a menor dispers\u00e3o em torno da m\u00e9dia, o que pode ser muito vantajoso. Os \ndesvios padr\u00f5es calculados s\u00e3o 0,57, 0,18 e 0,06 para os mapas de tamanho pequeno, \nnormal e grande, respectivamente. \n\nFoi tamb\u00e9m calculado o coeficiente de correla\u00e7\u00e3o entre os dados previstos e os de \npredi\u00e7\u00e3o para os tr\u00eas diferentes tamanhos de mapa. Para o mapa de tamanho pequeno \ntem-se um valor de R\u00b2 igual a 0,9924, para o mapa de tamanho normal tem-se R\u00b2 igual a \n0,9991 e para o mapa de tamanho grande o R\u00b2 \u00e9 igual a 0,9999. Esses valores para o \ncoeficiente de correla\u00e7\u00e3o demonstram que tanto o mapa de tamanho normal quanto o de \ntamanho grande apresentam resultados excelentes para a predi\u00e7\u00e3o da vari\u00e1vel estudada. \n\nO problema do agrupamento de concentra\u00e7\u00f5es, mais acentuado nos mapas de \ntamanho pequeno e normal, pode ser atenuado com uma melhora das amostras do \nbanco de dados alimentado \u00e0 rede neural para treinamento. Com a identifica\u00e7\u00e3o das \nregi\u00f5es em que o problema acontece \u00e9 poss\u00edvel gerar mais dados nessa regi\u00e3o e assim a \nmesma ser representada de forma mais satisfat\u00f3ria. A realiza\u00e7\u00e3o desse passo se faz \nconforme as necessidades do usu\u00e1rio, ou seja, \u00e9 aconselh\u00e1vel treinar o mapa com mais \ndados da regi\u00e3o que a planta opera normalmente e na qual ser\u00e1 feita a etapa de predi\u00e7\u00e3o \nde vari\u00e1veis.  \n\n8.80E-01\n\n9.00E-01\n\n9.20E-01\n\n9.40E-01\n\n9.60E-01\n\n9.80E-01\n\n1.00E+00\n\n1.02E+00\n\n0.88 0.9 0.92 0.94 0.96 0.98 1 1.02\n\nC\no\n\nn\nc\ne\n\nn\ntr\n\na\n\u00e7\n\u00e3\n\no\n p\n\nre\nv\n\nis\nta\n\nConcentra\u00e7\u00e3o de simula\u00e7\u00e3o\n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n30 \n\nO boxplot \u00e9 uma ferramenta estat\u00edstica muito \u00fatil para a visualiza\u00e7\u00e3o gr\u00e1fica de \nmedidas de tend\u00eancias centrais e de dispers\u00e3o. No gr\u00e1fico s\u00e3o mostradas as medianas, \nprimeiro e terceiro quartis e os limites superiores e inferiores, calculados multiplicando a \ndist\u00e2ncia interquart\u00edlica por 1,5. O boxplot com os valores da concentra\u00e7\u00e3o prevista pela \nt\u00e9cnica divididos pelos valores de simula\u00e7\u00e3o para os tr\u00eas tamanhos de mapas est\u00e1 \nrepresentado na Figura 5.14. \n\n \n\nFigura 5.14: Boxplot para os tr\u00eas diferentes tamanhos de mapas. \n\nComo visto anteriormente, o mapa de tamanho grande \u00e9 o que mais se aproxima do \nvalor ideal, representado pela linha vermelha e igual a unidade, uma vez que os dados \nalimentados para a constru\u00e7\u00e3o do boxplot foram as concentra\u00e7\u00f5es previstas divididas \npela concentra\u00e7\u00e3o de simula\u00e7\u00e3o. Pela an\u00e1lise do boxplot \u00e9 f\u00e1cil ver tamb\u00e9m que o mapa \nde tamanho grande apresenta a menor dispers\u00e3o dos dados em torno da m\u00e9dia, seguido \npelo mapa de tamanho normal e o mapa de tamanho pequeno.  \n\nA constru\u00e7\u00e3o do boxplot tamb\u00e9m facilita a visualiza\u00e7\u00e3o dos pontos que est\u00e3o mais \nafastados do valor ideal. Com a identifica\u00e7\u00e3o desses pontos \u00e9 poss\u00edvel alimentar mais \ndados dessa regi\u00e3o na fase de treinamento do mapa para que a mesma fique mais \nrepresentada. Como o mapa s\u00f3 depende dos dados alimentados, quanto melhor e mais \naperfei\u00e7oado for o banco de dados, menores os erros e maior a confiabilidade na \ndefini\u00e7\u00e3o das regi\u00f5es operacionais da planta v\u00e3o ser conquistados. \n\n  \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 31\n\n6 C on c lu s \u00f5 e s e  t rab al h os  fu tu ro s  \n\nA numerosa quantidade de vari\u00e1veis medidas em planta e a quantidade de dados \narmazenados no banco de dados se apresentam como as grandes dificuldades em \ninterpretar o funcionamento de uma opera\u00e7\u00e3o. No que se refere a esses dois problemas, \na t\u00e9cnica de mapas auto-organiz\u00e1veis se mostrou uma ferramenta com resultados muito \nsatisfat\u00f3rios. Em uma etapa posterior de treinamento supervisionado do mapa foi predita \na concentra\u00e7\u00e3o de propeno no produto de topo da coluna de separa\u00e7\u00e3o de propano e \npropeno. \n\nNo presente trabalho foi constru\u00edda a simula\u00e7\u00e3o em Aspen Plus de duas colunas \npertencentes a uma refinaria nacional. A partir dos dados obtidos de simula\u00e7\u00e3o \nestacion\u00e1ria variando caracter\u00edsticas operacionais da unidade, constru\u00edram-se as \nmatrizes-U tanto usando todos os dados como ap\u00f3s um pr\u00e9-processamento dos mesmos \nutilizando um algoritmo desenvolvido para remo\u00e7\u00e3o de dados similares. Posteriormente \ntreinou-se o mapa de forma supervisionada e realizou-se a predi\u00e7\u00e3o da concentra\u00e7\u00e3o de \npropeno na corrente de topo comparando-a com os dados da simula\u00e7\u00e3o. \n\nNo que tange \u00e0 constru\u00e7\u00e3o da simula\u00e7\u00e3o, os erros obtidos, quando comparados com \ndados de projeto, foram muito baixos tanto para vaz\u00f5es totais como concentra\u00e7\u00e3o de \npropeno e temperatura. Atrav\u00e9s da ferramenta de an\u00e1lise de sensibilidade variaram-se \ncaracter\u00edsticas operacionais da planta e coletaram-se dados de diversas medi\u00e7\u00f5es. De \nposse do banco de dados constru\u00eddo foi poss\u00edvel passar para a pr\u00f3xima parte do trabalho: \na aplica\u00e7\u00e3o dos mapas auto-organizaveis. \n\nA etapa n\u00e3o-supervisionada de treinamento, apresentada na forma de matrizes-U e \nde trajet\u00f3rias crescentes de vari\u00e1veis, reduziu a dimensionalidade dos dados de entrada a \nmapas em duas ou tr\u00eas dimens\u00f5es. A partir da an\u00e1lise dos mesmos foi poss\u00edvel delimitar \nregi\u00f5es de opera\u00e7\u00e3o da coluna de separa\u00e7\u00e3o propano e propeno. O mapa de tamanho \n20x5 foi o escolhido dentre todos para a visualiza\u00e7\u00e3o de trajet\u00f3rias e rela\u00e7\u00f5es entre \ncaracter\u00edsticas operacionais e a concentra\u00e7\u00e3o de propeno no produto de topo.  \n\nA visualiza\u00e7\u00e3o das trajet\u00f3rias foi feita de acordo com as quatro caracter\u00edsticas de \nopera\u00e7\u00e3o da coluna de separa\u00e7\u00e3o propano e propeno variadas na simula\u00e7\u00e3o em Aspen \nPlus: press\u00e3o de sa\u00edda do compressor, fra\u00e7\u00e3o de corrente desviada para o produto de \ntopo, vaz\u00e3o de hot bypass e vaz\u00e3o total de alimenta\u00e7\u00e3o da coluna. Para cada conjunto de \ndados tra\u00e7aram-se as trajet\u00f3rias crescentes tanto da concentra\u00e7\u00e3o de propeno no topo \ncomo da varia\u00e7\u00e3o operacional correspondente. A partir dos pares de matrizes-U com as \ntrajet\u00f3rias tra\u00e7adas foi poss\u00edvel visualizar a evolu\u00e7\u00e3o de cada uma no mapa e estabelecer \nrela\u00e7\u00f5es entre elas. \n\nA predi\u00e7\u00e3o de vari\u00e1veis, realizada ap\u00f3s um treinamento supervisionado dos dados de \nentrada, obteve resultados excelentes para a concentra\u00e7\u00e3o de propeno no produto de \ntopo da coluna de separa\u00e7\u00e3o propano e propeno, com coeficientes de correla\u00e7\u00e3o entre os \ndados simulados e preditos muito pr\u00f3ximos da unidade. \n\nA t\u00e9cnica de self-organizing maps mostrou-se, desse jeito, uma t\u00e9cnica robusta para a \nprospec\u00e7\u00e3o de conhecimento atrav\u00e9s do processamento de bancos de dados. A \ninterpreta\u00e7\u00e3o dos mapas treinados e a filtragem dos dados alimentados s\u00e3o fun\u00e7\u00f5es que \ncabem ao especialista, assim, o conhecimento da planta e a altera\u00e7\u00e3o dos par\u00e2metros de \ntreinamento do mapa t\u00eam fundamental import\u00e2ncia no resultado final. \n\n\n\nAvalia\u00e7\u00e3o de regi\u00f5es operacionais de uma coluna de separa\u00e7\u00e3o de propeno utilizando self-\norganizing maps \n\n32 \n\n6.1 Trabalhos futuros \n\nComo continuidade desse trabalho pode-se utilizar, ao inv\u00e9s de dados de simula\u00e7\u00e3o \nestacion\u00e1ria, dados reais da planta em opera\u00e7\u00e3o. Tamb\u00e9m \u00e9 poss\u00edvel estender a \nidentifica\u00e7\u00e3o de regi\u00f5es operacionais e a predi\u00e7\u00e3o de vari\u00e1veis de interesse para as outras \ncolunas da unidade. A melhora no banco de dados e a consequente melhor \nrepresenta\u00e7\u00e3o das regi\u00f5es se apresentam como tarefas que devem estar sendo sempre \naprimoradas e n\u00e3o podem ser cessadas. \n\n \n\n  \n\n\n\nDEQUI / UFRGS \u2013 Jos\u00e9 Ricardo Furlanetto de Azambuja 33\n\n7 Refe r\u00ea n ci as  \n\nAguado, D., Montoya, T., Borras, L., Seco, A. &amp; Ferrer, J. (2008). Using SOM and PCA for \nanalysing and interpreting data from a P-removal SBR. Engineering Applications of \nArtificial Intelligence, 21(6), 919-930. \n\nDom\u00ednguez, M., Fuertes, J. J., Reguera, P., D\u00edaz, I. &amp; Cuadrado, A. A. (2007). Internet-\nbased remote supervision of industrial processes using self-organizing maps. \nEngineering Applications of Artificial Intelligence, 20(6), 757-765. \n\nFuertes, J. J., Dom\u00ednguez, M., Reguera, P., Prada, M. A., D\u00edaz, I. &amp; Cuadrado, A. A. (2010). \nVisual dynamic model based on self-organizing maps for supervision and fault \ndetection in industrial processes. Engineering Applications of Artificial Intelligence, \n23(1), 8-17. \n\nHaykin, S. S. (1999). Neural networks : a comprehensive foundation. 2nd ed. Prentice Hall, \nUpper Saddle River, N.J. \n\nKohonen, T. (1982). Self-organized formation of topologically correct feature maps. \nBiological Cybernetics, 43, 43:59-69. \n\nNg, Y. S. &amp; Srinivasan, R. (2008a). Multivariate temporal data analysis using self-organizing \nMaps. 1. Training methodology for effective visualization of multistate operations. \nIndustrial and Engineering Chemistry Research, 47(20), 7744-7757. \n\nNg, Y. S. &amp; Srinivasan, R. (2008b). Multivariate temporal data analysis using self-organizing \nMaps. 2. Monitoring and diagnosis of multistate operations. Industrial and \nEngineering Chemistry Research, 47(20), 7758-7771. \n\nOuzounoglou, A. N., Economopoulos, T. L., Asvestas, P. A. &amp; Matsopoulos, G. K. (2010). \nFingerprint matching with self organizing maps. IFMBE Proceedings. 307-310. \n\nRitter, H. &amp; Kohonen, T. (1989). Self-organizing semantic maps. Biological Cybernetics, \n61(4), 241-254."}]}}}