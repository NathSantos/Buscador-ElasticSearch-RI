{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.07050"}, {"@name": "filename", "#text": "11686_RuedaSerrano_Dany_M.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNICAMP\nDANY RUEDA SERRANO\nRANDOM NOISE REDUCTION BY SMOOTHING OF CRS ATTRIBUTES\nREDU\u00c7\u00c3O DO RU\u00cdDO ALEATORIO MEDIANTE A SUAVIZA\u00c7\u00c3O DOS ATRIBUTOS CRS\nCAMPINAS\n2013\nii\nUNICAMP\nUNIVERSIDADE ESTADUAL DE CAMPINAS FACULDADE DE ENGENHARIA MEC\u00e2NICA E INSTITUTO DE GEOCiEnCIAS\nDANY RUEDA SERRANO\nRANDOM NOISE REDUCTION BY SMOOTHING OF CRS ATTRIBUTES\nSupervisor/Orientador: Prof. Dr. Martin Tygel\nREDU\u00c7\u00c3O DO RU\u00cdDO ALEAT\u00d3RIO MEDIANTE A SUAVIZA\u00c7\u00c3O DOS ATRIBUTOS CRS\nDisserta\u00e7\u00e3o de mestrado apresentada ao Programa de P\u00f3s Gradua\u00e7\u00e3o em Ci\u00e2ncias e Engenharia de Petr\u00f3leo da Faculdade de Engenharia Mecanica e Instituto de Geoci\u00e2ncias da Universidade Estadual de Campinas para obtencao do t\u00edtulo de Mestre em Ci\u00e2ncias e Engenharia de Petr\u00f3oleo na \u00f3area de Reservat\u00f3orios e Gesta\u00e3o.\nMSc Dissertation presented to the Graduate Program of the Science and Petroleum Engineering at Mechanical Engineering Faculty and Geosciences Institute of the University of Campinas to obtain the Master degree in Science and Petroleum Engineering in the area of Reservoir Engineering and Management.\nEste exemplar corresponde \u00e0 vers\u00e3o final da disserta\u00e7\u00e3o defendida pelo aluno Dany Rueda Serrano, e orientada pelo Prof. Dr. Martin Tygel.\n\tA\nSuper\tvisor ^Orientador\nCAMPINAS\n2013\nFicha catalogr\u00e1fica Universidade Estadual de Campinas Biblioteca da \u00c1rea de Engenharia e Arquitetura Rose Meire da Silva - CRB 8/5974\nRueda Serrano, Dany, 1982-\nR836r\tRandom noise reduction by smoothing of CRS attributes / Dany Rueda\nSerrano. - Campinas, SP : [s.n.], 2013.\nOrientador: Martin Tygel.\nDisserta\u00e7\u00e3o (mestrado) - Universidade Estadual de Campinas, Faculdade de Engenharia Mec\u00e2nica e Instituto de Geoci\u00eancias.\n1.\tGeof\u00edsica. 2. M\u00e9todo s\u00edsmico de reflex\u00e3o. 3. Ru\u00eddo. I. Tygel, Martin,1946-.\nII. Universidade Estadual de Campinas. Faculdade de Engenharia Mec\u00e2nica. III. T\u00edtulo.\nInforma\u00e7\u00f5es para Biblioteca Digital\nT\u00edtulo em outro idioma: Redu\u00e7\u00e3o do ru\u00eddo aleat\u00f3rio mediante a suaviza\u00e7\u00e3o dos atributos CRS\nPalavras-chave em ingl\u00eas:\nGeophysics\nSeismic reflection method\nNoise\n\u00c1rea de concentra\u00e7\u00e3o: Reservat\u00f3rios e Gest\u00e3o\nTitula\u00e7\u00e3o: Mestre em Ci\u00eancias e Engenharia de Petr\u00f3leo\nBanca examinadora:\nMartin Tygel [Orientador]\nLeonardo Tomazeli Duarte\nLeiv-Jacob Gelius\nData de defesa: 20-06-2013\nPrograma de P\u00f3s-Gradua\u00e7\u00e3o: Ci\u00eancias e Engenharia de Petr\u00f3leo\nUNICAMP\nUNIVERSIDADE ESTADUAL DE CAMPINAS\nFACULDADE DE ENGENHARIA MEC\u00c2NICA E INSTITUTO DE GEOCI\u00caNCIAS\nDISSERTA\u00c7\u00c3O DE MESTRADO ACAD\u00caMICO\nRANDOM NOISE REDUCTION BY SMOOTHING OF CRS ATTRIBUTES\nAutor: Dany Rueda Serrano\nOrientador: Prof. Dr. Martin Tygel\nA banca examinadora composta pelos membros abaixo aprovou esta disserta\u00e7\u00e3o:\nProf Dr.\nIMECC/\nrtin Tygel, Presidente\nProf Dr. Leonardo Tomazeli Duarte\nFCA/UNICAMP\nur. Leiv-jacoD oenus UNIVERSITY OF OSLO\nCampinas, 20 de junho de 2013\nTo my Wife.\nIf I have seen further than the others, it is because I stood on the shoulders of giants.\nSir Isaac Newton\nAcknowledgements\nAt this place I would also like to thank a number of people for their support to this research:\n\u2022\tI thank my advisor Martin for the opportunity to carry out this challenging Master\u2019s degree at Unicamp. I am especially thankful for his support, friendship, encouragement and his incredible intellectual capability to answer different kind of questions during these great years.\n\u2022\tI thank Prof. Dr. Leiv-Jacob Gelius for valuable advice at all stages of this work.\n\u2022\tI also want to thank my LGC colleagues: Jorge Facciperi Jr, Joao Renato Domingos do Sacramento and Alber Tabone for their support, encouragement, interest, friendship and shared feelings for Science in general and Geophysics in particular.\n\u2022\tI acknowledge support from the National Council of Scientific and Technological Development (Brazil), the National Petroleum Agency (Brazil) and the Wave Inversion Technology (WIT) Consortium.\n\u2022\tI also want to thank PETROBRAS, Laborat\u00f3rio de Geof\u00edsica Computacional (LGC), Centro de Estudos de Petr\u00f3leo (CEPETRO) and Departamento de Engenharia de Petr\u00edoleo (DEP) for support .\nAbstract\nSignal-to-noise (S/N) ratio in seismic data is affected by random noise, influencing the continuity and identification of reflectors. In this work, I present a method to overcome this problem based on smoothing Common-Reflection-Surface (CRS) parameters through application of local statistics in small windows aligned with reflection events. First, the CRS parameters are obtained by a standard application of the CRS stack method. Subsequently, the CRS parameters are smoothed so as to eliminate fluctuations and outliers. Finally, a CRS stack is performed with the new, smoothed parameters. The process may be iterative, to achieve optimal results. The proposed scheme has been applied on a 2D synthetic data set and marine field data. The synthetic data application showed effective random noise attenuation plus highlighting of the reflection events. Application to the real marine data resulted in an increase of S/N ratio with consequent highlight and greater continuity of the reflections. The seismic interpretation of stratigraphic elements has been more precise in the PostSTM section related with the CRS stack method. It is performed using smoothed attributes and a velocity model as a guide.\nKey-words: Geophysics, Seismic Reflection Method, Noise.\nxii\nResumo\nA raz\u00e3o sinal-ru\u00eddo, geralmente abreviada por raz\u00e3o S/N (do Ingl\u00eas signal-to-noise ratio) \u00e9 bastante afetada por ru\u00eddos aleat\u00f3rios, os quais degradam a continuidade e identifica\u00e7\u00e3o de refletores, com preju\u00f3zos para interpreta\u00e7\u00e3o geol\u00f3gica. Com vistas a superac\u00e3o dessas dificuldades, apresentamos neste trabalho uma t\u00e9ecnica baseado na suavizac\u00e7\u00e3ao de para\u00eamet-ros obtidos pela aplica\u00e7c\u00e3ao do m\u00e9etodo de empilhamento Common-Reflection-Surface (CRS). A suaviza\u00e7c\u00e3ao \u00e9e realizada atrav\u00e9es da utilizac\u00e7\u00e3ao de estat\u00e9sticas locais em pequenas janelas alinhadas com os eventos de reflex\u00e3o. Primeiramente, os par\u00e2metros CRS sao estimados atrav\u00e9es de uma aplica\u00e7c\u00e3ao convencional do m\u00e9etodo CRS. Em seguida, os par\u00eaametros CRS s\u00e3ao suavizados de modo a eliminar flutua\u00e7co\u00e3es e valores espu\u00e9rios. Finalmente, os dados originais s\u00e3ao submetidos a um novo empilhamento CRS, com utilizac\u00e7\u00e3ao dos para\u00eametros suavizados rec\u00e9em obtidos. O processo pode ser aplicado de maneira iterativa para otimizac\u00e7\u00e3ao de resultados. O esquema proposto foi aplicado em um dois conjuntos de dados mar\u00edtimos 2D, um sint\u00e9etico e um de campo. No dado sint\u00e9etico, obtivemos uma efetiva atenua\u00e7c\u00e3ao do ru\u00e9do aleat\u00e9orio com significativa \u00eaenfase dos eventos de reflexa\u00e3o. A aplicac\u00e7\u00e3ao nos dados de campo resultou num significativo increment da raz\u00e3ao S/N com consequente \u00eaenfase e aumento de continuidade dos refletores. A interpretac\u00e7\u00e3ao s\u00e9smica dos elementos estratigr\u00e9aficos tornou-se mais precisa na sec\u00e7a\u00e3o p\u00e9os-migrada em tempo (PostSTM ) correspondente ao m\u00e9etodo CRS. A sec\u00e7a\u00e3o migrada foi obtida com a utilizac\u00e7\u00e3ao dos par\u00eaametros suavizados em conjunto com um guia de velocidade.\nPalavras chaves: Geof\u00e9sica, M\u00e9etodo S\u00e9smico de Reflex\u00e3ao, Ru\u00e9do.\nxiv\nContents\n1\tINTRODUCTION\t1\n2\tGEOLOGY OF THE JEQUITINHONHA\tBASIN\t3\n2.1\tLocation........................................................... 3\n2.2\tRegional geology .................................................. 3\n2.3\tStratigraphy Chart................................................. 7\n2.4\tPetroleum System................................................... 7\n2.4.1\tSource Rock................................................. 9\n2.4.2\tSeal, Trap and Reservoir Rock............................... 9\n2.4.3\tGeneration and Migration.................................... 9\n3\tCONVENTIONAL PROCESSING\t11\n3.1\tAcquisition Parameters and Processing Layout...................... 11\n3.2\tSEG-Y Format...................................................... 11\n3.3\tField Geometry.................................................... 13\n3.3.1\tSetup Table................................................ 14\n3.3.2\tAuto-2D Table.............................................. 15\n3.3.3\tSource Table .............................................. 16\n3.3.4\tPattern Table.............................................. 16\n3.3.5\tBin Window................................................. 17\n3.3.6\tCDP Fold................................................... 18\n3.4\tTrace Editing......................................................20\n3.5\tAmplitude Correction...............................................24\n3.6\tDeconvolution and Filtering........................................27\n3.6.1\tSpiking Deconvolution.......................................27\n3.6.2\tTime-Variant Spectral Whitening TVSW........................31\n3.6.3\tOrmsby Bandpass Filter......................................33\n3.7\tCMP Sorting and Velocity Analysis..................................35\n3.7.1\tCommon Mid-Point (CMP) Sorting..............................35\n3.7.2\tVelocity Analysis and the Stacking Velocity Model ...............35\n3.8\tStacked Section........................................................42\n3.8.1\tCMP stacked section..............................................42\n4\tCONVENTIONAL CRS PROCESSING\t47\n4.1\tReview of the Common Reflection Surface (CRS) Stacking Method..........47\n4.1.1\tEstimation of CRS parameters.....................................50\n4.2\tCRS Stack with Automatic Search .......................................52\n4.2.1\tStacking Velocity Model and CRS Stacked Section..................52\n4.3\tCRS Stack with Guided Search...........................................52\n4.3.1\tStacking Velocity Model and CRS Stacked Section..................52\n5\tSMOOTHING OF CRS PARAMETERS\t57\n5.1\tFormulation............................................................57\n5.1.1\tSmoothing Window.................................................57\n5.1.2\tCentral ZO sample for different cases............................62\n5.2\tSynthetic Data Test of Smoothed Parameters\t..........................64\n5.3\tCRS Stack of Marine Data with Automatic Search and Smoothed\tParameters\t65\n5.3.1\tStacking Velocity Model and CRS Stacked Section..................65\n5.4\tCRS Stack of Marine Data with Guided Search\tand\tSmoothed Parameters\t. . 66\n5.4.1\tStacking Velocity Model\tand CRS Stacked Section..................66\n6\tMIGRATION\t75\n6.1\tReview of Kirchhoff Migration..........................................75\n6.2\tGeometrical Distortion ............................................... 76\n6.2.1\tDipping Reflector .............................................. 77\n6.2.2\tSyncline ....................................................... 77\n6.2.3\tPoint Difractor ................................................ 77\n6.3\tKirchhoff Time Migration Results ..................................... 78\n7\tSEISMIC INTERPRETATION\t85\n7.1\tGeological Model ..................................................... 85\n7.2\tStructural Framework and Seismic Stratigraphy ........................ 86\n8\tCONCLUSIONS\t93\nBibliography\t94\nList of Figures\n2.1\tLocalization of Jequitinhonha basin. (Source: ANP (2013))..................... 4\n2.2\tGeological section of Jequitinhonha Basin. (Source: ANP (2013)) .............. 5\n2.3\tSeismic (top) and cross-section (bottom) of the Jequitinhonha Basin. The\nbeds are folded as a result of gravitational spreading of the post-salt section, (Davison; 2007)............................................................... 6\n2.4\tStyle of salt tectonics on the Jequitinhonha basin (Davison; 2007). Correspond to a narrow basin with a relatively steep oceanward-dipping base salt horizon. As a characteristic, the salt pinch-out causes compression to propagate back\nup the slope and later turbidites may be trapped behind the folds............. 6\n2.5\tStratigraphic chart of Jequitinhonha Basin. (Source: ANP (2013)).............. 8\n3.1\tProcessing flowchart. In gray is shown the processing sequence carried out to\nobtain the CMP stacked section............................................... 12\n3.2\tScreenshot\tof\tmenu bar to build the 2D marine geometry....................... 14\n3.3\tScreenshot\tof\tthe\tsetup table used to build the 2D marine geometry........... 14\n3.4\tScreenshot\tof\tthe\tAuto Marine 2D Geometry spreadsheet editor..................15\n3.5\tScreenshot\tof\tthe\tSource Table used to build the 2D marine geometry.......... 16\n3.6\tScreenshot\tof\tthe\tPattern Table to build the 2D marine geometry...............16\n3.7\tScreenshot\tof\tthe\tbin window used to build the 2D marine geometry.............17\n3.8\tPlot of the CDP fold of line 214-2660 ....................................... 19\n3.9\tCommon shot gather before trace editing.......................................21\n3.10\tThe mono-frequency traces have been killed....................................22\n3.11\tDirect wave and guide or refraction wave have been removed....................23\n3.12\tSpectral analysis of the raw data.............................................24\n3.13\tGeometrical spreading correction..............................................26\n3.14\tInteractive Spectral analysis of FFID 787.................................... 29\n3.15\tInteractive Spectral analysis of FFID 787.................................... 30\n3.16\tInteractive Spectral analysis of FFID 787.................................... 30\n3.17\tSpectral analysis.............................................................32\n3.18\tLine 214-2660 without spiking deconvolution...................................32\n3.19\tLine 214-2660 with amplitude recovering and spiking deconvolution.............33\n3.20\tBandpass filter scheme........................................................34\n3.21\tSpectral analysis.............................................................34\n3.22\tReflection travel paths for seismogram traces.................................36\n3.23\tVelocity analysis of\tCMP\t600 ............................................... 39\n3.24\tVelocity analysis of\tCMP\t600 after NMO correction............................40\n3.25\tVelocity model constructed from standard velocity analysis....................41\n3.26\tCMP stacked\tsection\tbelonging to the\tseismic\tline\t214-2660................. 43\n3.27\tF-K Analysis\tDisplay\tWindow..................................................44\n3.28\tCMP stacked\tsection\tafter F-K filter........................................45\n4.1\tProcessing flowchart.\tIn gray is shown\tthe\tprocessing sequence carried out to\nobtain the CRS stacked section................................................48\n4.2\t(a) NIP wave and the associated radius of curvature. (b) The N wave and the\nassociated radius of curvature............................................... 50\n4.3\tVelocity model obtained from the conversion of C parameter....................53\n4.4\tStacking velocity model obtained from conversion of guided C parameter. ... 54\n4.5\tCRS stacked section without smoothed and KNIP attributes. These at-\ntributes were obtained with automatic search. ............................... 55\n4.6\tCRS stacked section obtained using the stacking velocity model................56\n5.1\tFigure showing the results of a signal ordered by a median filter of size five.\nTop: Five samples are enclosed in the red ellipse. The sample with nonphysical value (outlier) is represented in green. Bottom: The outlier is sorted on one side of the window. The middle point (fuchsia) of the ascending-value sequence is chosen. ......................................................... 59\n5.2\tCentered on the considered ZO sample, define a smoothing window with a\ntemporal width of nt samples and a spatial width of nx traces.................60\n5.3\tUsing the slope information (linear CRS parameters) at the central ZO sample,\norient the window along the event, in order to frame the reflection event. . . . 60\n5.4\tSelect all samples in window with respect to the central ZO sample............61\n5.5\tReject samples of coherence and dip difference 0 beyond a user-defined thresh-\nold, in the constructed window. ............................................. 61\n5.6\tIf there are no remaining parameters, use the original values of the central ZO\nsample. Repeat the procedure for each sample in the ZO section. ............. 62\n5.7\t2.5D model used to generate the synthetic data................................65\n5.8\tVelocity profile of the synthetic model.......................................66\n5.9\tSynthetic marine data set.....................................................68\n5.10\tProcessing flowchart. In gray is shown the processing sequence carried out to\nobtain the CRS stacked section based on smoothed attributes....................69\n5.11\tVelocity model obtained from conversion of smoothed C parameter............70\n5.12\tVelocity model obtained from conversion of smoothed and guided C parameter\t71\n5.13\tCRS stacked section created with smoothed and KNIP attributes..............72\n5.14\tCRS section generated using the smoothed attributes and velocity model\t...\t73\n6.1\tScattering traveltime curve from a fixed depth point.......................76\n6.2\tGeological model of a planar-dipping reflector surface.....................77\n6.3\tA synclinal feature and a \u2019bow-tie\u2019 shape..................................78\n6.4\tPoint difractor and difraction curve.......................................78\n6.5\tThe CMP stacked seismic section after post-stack Kirchhoff migration.......80\n6.6\tThe seismic section in Figure 5.14 after post-stack Kirchhoff migration\t....\t81\n6.7\tZooms of PostSTM sections corresponding to the left area...................82\n6.8\tZooms of PostSTM sections corresponding to the right area..................83\n7.1\tInterpretation on the PostSTM obtained from the CMP stack......................88\n7.2\tInterpretation on the PostSTM obtained from the CRS stack......................89\n7.3\tZooms of interpreted sections corresponding to the left area ..................90\n7.4\tZooms of interpreted sections corresponding to the right area..................91\nList of Tables\n3.1\tMarine data: acquisition geometry of line 214-2660 ................................... 13\n5.1\tIt\twill\tleave the\toriginal value\tbecause\tonly the central sample\tis\tselected.\t...\t62\n5.2\tIt\twill\tleave the\toriginal value\tbecause\tno sample is selected...................63\n5.3\tIt\twill\tleave the\toriginal value\tbecause\tno sample is selected.\t................... 63\n5.4\tIt\twill\tleave the\toriginal value\tbecause\tonly the central sample\tis\tselected.\t.\t.\t.\t63\n5.5\tIt\twill\tleave the\toriginal value\tbecause\tno sample is selected.\t................... 63\n5.6\tIt\twill\tleave the\toriginal value\tbecause\tonly the central sample\tis\tselected.\t.\t.\t.\t63\n5.7\tIt will work with the value of samples adjacent to the central sample, because\nthe central sample has low coherence value.............................................63\n5.8\tAll samples will be considered except the central ZO sample of the attribute\nKNip. As mentioned initially, it is assumed that the values of KNiP are not real for the central ZO sample, and for this reason, they are removed by the Median Filter..........................................................................64\n1.\tINTRODUCTION\nRandom noise diminishes the quality of seismic images, introducing difficulties in the identification of horizons and other image features that are useful for interpretation of seismic reflection data. Uncontrolled sources, such as wind, rain, road traffic, poorly planted geophones, or electrical noise, usually generate random noise in prestack seismic data. While stacking can, at least partly, attenuate random noise in prestack data, residual random noise after stacking will still survive and affect the accuracy of final data interpretation.\nMethods for random-noise attenuation of seismic data is an ever present topic of interest in the literature (e. g., Yilmaz; 2001). Different methods of eliminating random noise have been developed. Bednar (1983); Duncan and Beresford (1995); Mi and Margrave (2000) incorporated median-filter noise reduction into standard Kirchhoff time migration, Gulunay (2000) used the noncausal prediction filter for random-noise attenuation, Ristau and Moon (2001) compared several adaptive filters for the same purposes. Karsli et al. (2006) applied complex-trace analysis to seismic data for random-noise suppression, recommending it for lowfold seismic data. Transform methods were also used to eliminate seismic random noise, such as discrete cosine transform Lu and Liu (2007), curvelet transform Neelamani et al. (2008), seislet transform and seislet frame Fomel and Liu (2010).\nAll methods above attempt to attenuate random noise within the shot gather domain. As such, they often leave residuals which remain in the stacked seismic section decreasing the S/N ratio and consequently, declining the continuity of reflectors and their subsequent interpretation in poststack time or depth migrations. The idea in this work is to reduce random noise directly within that stacked section. For that, I make use of parameters obtained by the Common-Reflection-Surface (CRS) stack method (see, e. g., Duveneck; 2004). Such parameters are subjected to suitable smoothing process to eliminate fluctuations and outliers. After smoothing, a new CRS stack is performed. This is an iterative process which continues up to a user-selected level of optimal random-noise attenuation. The procedure has been applied to a real marine 2D data set, with encouraging results. The geological interpretation carried out on PostSTM sections, aims to distinguish stratigraphic and structural elements\n2\nChapter 1.\nINTRODUCTION\npresent in the area like onlap, unconformity and faults.\n2.\tGEOLOGY OF THE JEQUITINHONHA BASIN\n2.1\tLocation\nJequitinhonha basin is located in the northeast portion of the East Brazilian margin, on the southern of Bahia coast and behind to the mouth of the Jequitinhonha River (see Figure 2.1). It is limited in the northern boundary with the Camamu-Almada Basin and in the southern boundary with the Cumuraxitiba Basin. It occupies an area of 10,100 km2, of which 9,500 km2 is offshore (7,000 km2 to a water depth of 1,000m and 2,500 km2 between 1,000 and 2,000m).\n2.2\tRegional geology\nThree main stratigraphic mega-sequences characterize the evolution of the basin (Santos et al.; 1994):\nThe first one is associated with a syn-rift phase that started in the Lower Aptian, this megasequence is thicker at the onshore and in sea portion at south shows a thickness of 2000 m aproximately. This sequence is characterized by siliciclastics and shales of Mucuri Member belonging to Mariricu Formation, deposited in a fluvio-lacustrine environment. These sediments of Aptian age, show an increase of thickness in the onshore part and in the southern marine portion of the basin, belonging to Native Group. (see, Figure 2.2). The increased thickness is due to a heat input that began during the Barremian, whose volcanic rocks were only expelled in the southern part of the basin during the Paleocene and Eocene.\nThe second transitional mega-sequence is characterized by Neoaptian evaporites of Itaunas Member belonging to Mariricu Formation, this fact mark the beginning of a marine ingression,\ni.e., evaporite stage represents the first marine incursions during the transition of continental environment of rift phase for the open marine environment of post-rift phase.\nThe third mega-sequence, post-rift or marine, was formed during the continental drift and is characterized by the accumulation of marine transgressive sediments deposited during a\n\u25a0Almada T\nle Cumur\u00edixatiba T\nBada de Jequiti nhpi\nFigure 2.1: Localization of Jequitinhonha basin. (Source: ANP (2013))\nBada de SEAL_M\nBada de Jacuipe\nBada de C\nBada de Camamu-Almada M\nBada de Jequiti nhonha_M\nBada de Cumuruxatiba M\n104 Kilometers ZU\nBada de Mucuri_M\n0\nIZZ\nec\u00f4n^avo J4\nL?j-, fBada do Rec\u00f4ncavo T\n0\n(m)\n-1000\n-2000\n-3000\n-4000\n-5000\n-6000\nJequitinhonha Basin\nSchematic Geological Section\nFigure 2.2: Geological section of Jequitinhonha Basin. (Source: ANP (2013))\nphase of thermal subsidence of the basin, followed by a regressive marine phase. At the beginning of the marine transgressive sedimentation siliciclastic deposits occur in fan-delta belonging to S\u00e3o Mateus Formation and neritic carbonates of Reg\u00eancia Formation both of Barra Nova Group. The neritic carbonates were produced in the marine bathymetric zone, where waves and tides dominate, deposited from Albian to Coniacian age, being thicker in the south of basin. In the Upper Cretaceous and Paleocene occur transgressive deposits in slope and deep basin, pelites (sedimentary rock composed of fine fragments, as of clay or mud) and fine sandstones of Urucutuca Formation. From the Eocene a marine regressive phase is originated in the basin, with a system of alluvial fans (Rio Doce Formation) and neritic carbonates of high and low energy (Caravelas Formation) that harrow for bathyal shales (Urucutuca Formation). All the above mentioned formations are represented by the stratigraphic chart.\nAccording to Davison (2007), the Jequitinhonha basin in the central portion has a 3.1\u00b0 dip from the landward edge to the seaward edge of the salt, representing a total relief of 3400 m. (see, Figure 2.3). The mega-rollover anticline is generated by a large extensional listric fault formed at the landward edge of the salt basin. Early turbidite sandstone reservoirs may be trapped in the hanging wall of this fold (see, Figure 2.4). On the other hand, the pronounced contractional folding is due to a large gravitational component developed as a result of the steep topography on these margins.\n10 km\t.\nArrows indicate level at which folding commences\nJEQUITINHONHA\nFigure 2.3: Seismic (top) and cross-section (bottom) of the Jequitinhonha Basin. The beds are folded as a result of gravitational spreading of the post-salt section, (Davison; 2007).\n.Earlylurbdiles\"\n-\u2022-Early contraction-*\n_\t-------------Late contraction-------------------\u25ba\n\u25a0Early extension----------------\u25ba\nmajor lislrk: fault\nsea water\nAsymmetric fold and thrust\nsteeply-dipping base sail\nocean crust\nmega roll-over\ncontractional rejuvenation of early diapir\nFigure 2.4: Style of salt tectonics on the Jequitinhonha basin (Davison; 2007). Correspond to a narrow basin with a relatively steep oceanward-dipping base salt horizon. As a characteristic, the salt pinch-out causes compression to propagate back up the slope and later turbidites may be trapped behind the folds.\n2.3\tStratigraphy Chart\nThe stratigraphic column represented in Figure 2.5 is analogous to columns in other basins of eastern Brazilian coast, depicting lacustrine sediments of the rift phase started in Aptian age. These sediments are covered by evaporitic rocks of Neo-Aptian age and, subsequently by rocks of passive margin belonging to the open ocean associated with thermal subsidence. The stratigraphic architecture of the rift Aptian / Albian the newest and broad is similar to a basin being just stretched. This pattern may reflect an unusual contribution of heat, which began during the Barremian, caused by formation of domes, whose volcanic rocks were only expelled in the vicinity south of the basin during the Paleocene and Eocene. The Royal Complex Charlotte is the evidence of the volcanic event. After the thermal uplift during the Aptian and Albian ages, the appearance of extensional faults that, with the subsequent cooling, formed a system of rifts.\nDuring the Middle and Upper Aptian (equivalent to Middle and Upper Alagoas in the stratigraphic chart), salt domes with southeast-northwest direction were approached to the edge of the basin in its northern part. This is the opposite to other basins, where the sediment progradation associated with dip, encourage salt migration to more distal parts.\nThe marine environment is formed from the deposition of Eoalbian fan-delta on the edge of the basin, which quickly changed to high-energy carbonates. The sedimentation during the Albian was heavily influenced by salt movement corresponding to the lower sequence, generating the formation of a large and thick structural-high with North-South direction in the proximal part of the basin.\n2.4\tPetroleum System\nThe definition of a petroleum system in a sedimentary basin comprises all the essential elements and necessary processes for the existence of an accumulation of hydrocarbon. These essential elements are the source rock, reservoir rock and seal rock. On the other hand, the processes include trap formation and generation, migration path ways and accumulation of petroleum. The processes required to form a petroleum accumulation occur when all the essential elements are placed in time and space in a synchronized manner (Magoon and Dow; 1994).\nSeismic image is a tool used by the Geologist and Geophysicist to assess the quantity of oil and gas available for production from a field or to assess the potential of an undeveloped resource. The interpretations and conclusions from seismic data are integrated with the analysis of well logs, pressure tests, cores, geologic depositional knowledge and other information from exploratory and appraisal wells to determine if a known accumulation is commercial or to formulate an initial field development plan. If the seismic image is poor in quality, is possible\nin (/>\n&lt;<\nLd O => GO o o Ld CL G0 LlJ\n0 Stratigraphic Chart of Jequitinhonha Basin\nLITOESTRATIGR AFIA\nLITOLOGIA\nTERRA\t\u00c1GUAS PROF.\nMARINHO\nRESTRITO\nPR\u00ca-CAMBRIANO\nLlJ I\u2014 Z\nLd\n\\\tce\nO\tI-\nt \u2666 o\nm\n<\nFigure 2.5: Stratigraphic chart of Jequitinhonha Basin. (Source: ANP (2013))\nto create false structures that hinder petroleum system characterization.\nThe nomenclature of a petroleum system includes the designation of source rock, followed by the main reservoir rock and, finally, the symbol expressing the level of certainty. If the level of certainty is high, the petroleum system is called known and is indicated by the symbol (!). In a hypothetical petroleum system (.) geochemical information identifies a source rock, but no geochemical match exits between the source rock and the petroleum accumulation. When the presence of the source rock or petroleum is only based on the geological and geophysical evidence, this system is called speculative and receives the symbol (?).\nIn the basin under study, the petroleum system Reg\u00eancia - Mariricu (!) is responsible, for all occurrences of hydrocarbons (DPC and Assoc.; 2000). The only significant occurrence, related to this petroleum system, was discovered by well 1-BAS-37. Moreover, few evidences of oil were located in wells at the southern portion of the basin.\n2.4.1\tSource Rock\nThe source rocks are contained in Reg\u00eancia Formation (Albian-Cenomanian) and include shales rich in organic matter, deposited in anoxic marine carbonate. These rocks contain traces of Total Organic Carbon (TOC) varying from 2% to 5%, and a satisfactory potential of hydrocarbon generation with an average of 7 mgHC/g rock (Gaglione et al.; 1987). In the source rock, the dominant kerogen is of type II, shown by the hydrogen index (HI) ranging from 500 to 600 mgHC/GCOT. This hydrogen index is obtained from the ratio between the hydrogen and TOC. Marine source rocks are also found in Mariricu (Aptian) and Urucutuca (Cenomanian-Turonian) Formations, but it was recognized that both are poor in organic matter (DPC and Assoc.; 2000).\n2.4.2\tSeal, Trap and Reservoir Rock\nThe rocks that represent the reservoirs for oil are formed by Reg\u00eaencia Formation, this Formation is from Aptian age and it is composed by fluvial deposits of the siliciclastic member Mucuri (Mariricu Formation). The seal is composed by the evaporitic rocks of the Itaunas Member from Aptian age. The traps are essentially structural and the reservoirs are sealed by evaporites (DPC and Assoc.; 2000).\n2.4.3\tGeneration and Migration\nThe study of the reflectance of vitrinite made by Gaglione et al. (1987) in several wells of Jequitinhonha Basin indicated, that the top of the oil window ranges from 1000 to 1500 meters on the onshore part (proximal) and lies above 3000 meters in the ocean part or (distal). From this analysis, the shales of Reg\u00eaencia Formation are immature in virtually every platform area,\ngetting mature only in talud and deep oceanic regions. Possible migration path ways would be through the main normal faults and direct contacts with the carrier rocks of Mariricu Formation (DPC and Assoc.; 2000).\n3.\tCONVENTIONAL PROCESSING\n3.1\tAcquisition Parameters and Processing Layout\nThe seismic reflection line 214-2660 is part of a 2D marine seismic acquisition. It was acquired by Petrobras in 1985 along a NE direction over the Jequitinhonha basin. Table 3.1 gives a summary of the main acquisition parameters. In the line 214-2660 the length of streamer and the time sample rate is 2.975 km and 4 ms respectively. As can be seen, these parameters correspond to an old line. Generally, in modern marine data acquisition the time sample rate is 1 or 2 ms and the length of a streamer is about 6 to 12 km. Typically, in modern acquisition the receiver group spacing is 6.25 m with 1024 receivers or 12.5 m with 512 receivers.\nFive zero-offset (ZO) stacked sections were generated and studied in this thesis. One represents conventional CMP stacking and the other four, were generated applying the multi-step common-Reflection-surface (CRS) stacking method. The same pre-processed data were used as input to the CMP and CRS methods. The seismic pre-processing steps were: segy-input, geometry, trace editing, spherical divergence corrections, minimum phase spiking deconvolution, time-variant spectral whitening and zero-phase ormsby bandpass filter, as depicted on the processing flowchart (Figure 3.1).\n3.2\tSEG-Y Format\nThe data format that we generally use to store seismic recordings is SEG Y, which is a format defined by the Society of Exploration Geophysicists (SEG), according to Norris and Faichney (2002). This format is structured in different headers and its main headers are as follows:\n\u2022\tTextual File Header: The SEG Y data format contains an ASCII description of the seismic data of 40 lines, located at the first 3200-byte. This description contains information about, as example, the year of acquisition, the name of the line and other technical issues as measurement system, source, pattern, among others.\n\u2022\t400-byte Binary File Header: Contains crucial values or information for the processing of seismic data particularly the sampling interval and trace length. Its binary values affect the whole SEG Y file.\nSpherical Divergence Corrections\nMinimum Phase Spiking Deconvolution TV Spectral Whitening\nClassical Processing\nNMO\nVelocity Model\nGuided Velocity Search from NMO\nAutomatic Velocity Search\nCRS with Smoothed Atributes\nr-Automatic Velocity Search\nGuided Velocity Search from NMO\nCMP\nStacked Section\n~T\u201c\nCRS Stacked Section\nFigure 3.1: Processing flowchart. In gray is shown the processing sequence carried out to obtain the CMP stacked section.\nTable 3.1: Marine data: acquisition geometry of line 214-2660\nAcquisition Parameters Values\t\nSeismic line\t214-2660\nAcquisition type\tend-on\nMinimum offset\t150 m\nMaximum offset\t3125 m\nNumber of shots\t1577\nSource spacing\t25 m\nReceivers per shot\t120\nReceiver group spacing\t25 m\nRecording time\t7 s\nTime sample rate\t4 ms\nCMP spacing\t12.5 m\nMaximum CMP fold\t60\n\u2022\tTrace Header: Information of trace attributes needed to process or identify the trace, as example, the number of samples and the field geometry, are contained in the SEG Y trace header.\n\u2022\tTrace Data: In the SEG Y structure each Trace Header is followed by Trace Data. Moreover, the seismic data is organized into ensembles of traces or series of stacked traces.\nThe 2D seismic reflection data of Jequitinhonha basin were recorded in SEG Y format by Petrobr\u00e1s. These data were imported to the seismic processing package ProMAX, which is used to make the conventional processing of line 214-2660. Inside ProMAX, data are converted from SEG Y to an internal processing format.\n3.3\tField Geometry\nTo incorporate field geometry in the seismic data is an important step that requires close attention. Based on survey information, the coordinates of receivers and sources are assigned to all traces and used in the next steps of processing. One objective of introducing the field geometry into the trace header is to make it possible to efficiently sort the traces in CMP families or other types of configurations as common offset. If we do not do the geometry update correctly, many problems may appear in the seismic processing to follow.\nUsing the ProMAX software and its geometry assignment option, see Figure 3.2, the survey information was uploaded for line 214-2660. This was done by completing the following tables: Setup, Auto-2D, Sources, Patterns and Bin.\nFigure 3.2: Screenshot of menu bar to build the 2D marine geometry.\n3.3.1\tSetup Table\nIn this table (see, Figure 3.3), we fill in the information from the observer\u2019s log, as example, receiver station interval, source station interval, survey azimuth, the number of the first and last live station, the source type, among other parameters.\nFigure 3.3: Screenshot of the setup table used to build the 2D marine geometry.\n3.3.2\tAuto-2D Table\nThe Auto Marine 2D Geometry spreadsheet editor (see Figure 3.4), automatically generates the Source and Pattern tables or spreadsheet.\nFigure 3.4: Screenshot of the Auto Marine 2D Geometry spreadsheet editor used to build the 2D marine geometry.\n3.3.3\tSource Table\nWe must fill this table (see Figure 3.5), with the X, Y and Z coordinates, the station number, and the FFID number for each shot taking into account the observers report.\nFigure 3.5: Screenshot of the Source Table used to build the 2D marine geometry.\n3.3.4\tPattern Table\nThis spreadsheet called PAT Ordered Parameter File (OPF) (Figure 3.6), is used for entering, importing, or editing the definition of receiver patterns for all shots.\nFile Setup\t\tEdit\t\t\t\tHelp\t\t\t\t\n\tlark Block\tMin Chan\tMax/Gap Chan\tChan Inc\tSrc Pattern\tGrp Int\tX Offset\tY Offset\t\tA\n\t1\t120\t1\t-1\t\t25.0\t150.0\t0.0\t\t\n\t2\t\t\t\t1\t\t0.0\t0.0\t\t\n\t3\t\t\t\t\t\t0.0\t0.0\t\t\n\t4\t\t\t\t\t\t0.0\t0.0\t\t\n3.3.5\tBin Window\nThis window (Figure 3.7) allows one, to calculate Receiver X and Y coordinates, to enter binning parameters for midpoints and offsets, to bin the midpoints and offsets, to generate QC displays of the binned data, and to finalize the database.\n\n2D Marine Binning\nBinning Sequence\nAssign midpoints byi Matching pattern number in the SIN and PAT spreadsheets\nBinning\nFinalize database\nJ\nip\tS\n\n\n\n\n\n\n\n\n\n\n\n\nA:\n\u25a0r \u00bf\u00bfS:\n\t\t\t\t\t\t\n\tOk\t\tCancel\t\tHelp\t\n\t\t\t\t\t\t\nFigure 3.7: Screenshot of the bin window used to build the 2D marine geometry.\n3.3.6\tCDP Fold\nThe graph of CDP number vs fold is very important because it shows the number of traces in each CDP of the section, see Figure 3.8. In case of line 214-2660 we have 60 traces by CDP. As each shot gather of this seismic line was acquired with the same number of receivers, we have a constant full fold of 60 in the portion with maximum coverage. Plotting the CDP fold is another manner to review the geometry. The following formula can be used to calculate the 2D fold in marine seismic\n2D fold =\nN x Ag\n2 x As\n120 x 25 m\n2 x 25 m\n(3.1)\nwhere, N is the number of channels, Ag is the group interval and As is the source interval.\nFigure 3.8: Plot of the CDP fold of line 214-2660\n3.3. Field Geometry\t19\n3.4\tTrace Editing\nThe trace editing must be done before or after the geometry assignment and the geophysicist must pay close attention to not remove traces containing information. If we do not make trace editing, the quality of the results in the following steps can be affected. During this step we make a quality control of the seismic data, in order to, avoid propagation of mistakes. Therefore, noisy traces and sources are automatically and/or visually detected in the shot domain and removed. This is done without deteriorating the seismic data with the purpose to obtain better stacked or migrated sections.\nSeismic traces that contain different kind of noise may degrade the result of deconvolution or migration. Random noise, for example, can reduce the effectiveness of the deconvolution, because the noise can cause a bias in the autocorrelation function of the trace. Also, clustered random noise can be spread in the seismic section by the migration operator.\nIn this work, the 979 shots used in the processing were reviewed one by one in order to identify noisy traces. After loading the geometry into the seismic data, the trace editing was done in common shot domain. The main traces edited in a seismogram are: traces with low signal to noise ratio, traces without signal or zero amplitude due to problems in hydrophone. Figure 3.9 shows different wave types and it is used to illustrate the procedure of trace editing. It represents a common shot gather (FFID 637) of line 214-2660. From all common shot gathers the mono-frequency traces located in channels 12, 56, 59 and 82 were removed. These bad traces contained a frequency of approximately 60 Hz. This frequency is due to the electrical current present in the acquisition system. The direct wave and the refracted wave signal were also removed for the complete marine line.\nAfter trace-editing (see Figure 3.10), the mono-frequency traces have now been removed. Also, spikes present in some common shot gathers have been removed by interpolation of adjacent samples and in the same way, bursts of noise have been replaced with interpolated trace segments from adjacent traces. Linear coherent noise represented by the direct wave, was removed after application of a top mute function as illustrated in Figure 3.11, (in the same way, the guided or refracted wave was removed mainly present, in gathers close to the onshore).\nUsing the Fourier Transform a time domain signal is transformed to the frequency domain where it is equivalent to an Amplitude Spectrum and a Phase Spectrum. The Figure 3.12 was created with the ProMAX routine called Interactive Spectral Analysis. It uses Fourier Transforms to compute the average power spectrum (top right), the F-X power spectrum (bottom left), and the average phase spectrum (bottom right) of an interactively selected subset of the data (top left) that corresponds to the shot 787. It is a tool that help us to decide, as example, what are the best parameters to apply in deconvolution as will be explained later.\nFFID\nCHAM\n1\nI\n037\n106\nI\n500----\n1000----\nTrace Editin\nDirect arrival\nWater bottom reflection\nShallow reflector\n\u25a0 -\nRefraction arrival\n1500 \u2014\n2000 \u2014\n2500 \u2014\n3000 \u2014\n3500\n\n4000 \u2014\n4500 \u2014\n&amp;\n5000 \u2014\n\t\n5500\n6000 \u2014\n6500 \u2014\nFigure 3.9: Common shot gather before trace editing. We can see the mono-frequency traces located in the channels 12, 56, 59 and 82.\nFFID\nCHAM\n1\nI\n637\n106\nI\nrace Editiri;\n\n500 \u2014\n1000 \u2014\n1500 \u2014\n2000 \u2014\n2500 \u2014\n3000 \u2014\n3500 \u2014\n4000 \u2014\n\u2014\n4500 \u2014\n\n\n5000\n\u2014\n\n5500 \u2014\n\n6000 \u2014\n\n6500 \u2014\nFigure 3.10: Common shot gather after trace editing. The mono-frequency traces have been killed.\nFigure 3.11: Common shot gather after trace editing. Direct wave and guided wave have been removed after the application of top mute.\nFigure 3.12: Spectral analysis of the raw data\n3.5\tAmplitude Correction\nIn seismic pre-processing we try to correct the amplitudes of the field record registered by each hydrophone for various effects. A field record generated by a single shot represents a series of reflections. As the earth filters a propagating wavefield, the field record will contain decaying amplitudes with increasing propagation times as well as frequency absorption. Amplitude attenuation and frequency absorption are thus two undesirable effects causing loss of energy during propagation in the earth. The main causes of these two effects are geometrical spreading (spherical divergence), intrinsic attenuation or absorption and transmission losses. In this thesis work only geometrical spreading was corrected for, since this correction seemed to be enough to give good quality data. Theory related to intrinsic attenuation and transmission losses can be found in (e. g., Yilmaz; 2001). A brief description of geometrical spreading is presented below:\n1.\tGeometrical spreading (spherical divergence): The energy of the illuminating wavefield is distributed over larger areas during propagation. If the medium is homogeneous, energy density decays as\n1\nP x \u2019\n(3.2)\nwhere, p is the energy density per unity of surface, k means proportional to and r is the radius of wavefront. This is equivalent to that the same quantity of energy must be distributed over a larger spherical surface with radius r and area 4nr2. As the wave amplitude H is proportional to the square root of energy density; it decays as 1/r\nH&lt;x.\n(3.3)\nwhere, r is the radius of wavefront.\nIn a stratified medium the losses are larger, compared to a homogeneous medium. The amplitude attenuation can be described approximately by 1/ [v2(t) \u2022 t] (Newman; 1973), where, t is the two way traveltime and v (t) is the rms velocity of the primary reflections averaged over a survey area. Therefore, the gain function for geometric spreading compensation is defined by\ng(t) = i>2(i) \u2022 t,\n(3.4)\nTrue Amplitude Recovery is a tool of ProMAX used to compensate for loss of amplitude due to wavefront spreading and attenuation. In recovering the amplitude, different combinations between spherical divergence and inelastic attenuation were tested. The best result was obtained taking only into account the spherical divergence correction.\nIncluding compensation for inelastic attenuation, made, the amplitude level only balanced at middle and late traveltimes. In Figure 3.13, we can see the effect of amplitude balancing on traces belonging to common shot gather 637. The amplitude level has now been restored at all traveltimes.\nFigure 3.13: Geometrical spreading correction.\n3.6\tDeconvolution and Filtering\n3.6.1\tSpiking Deconvolution\nDeconvolution, or inverse filtering, is a step in seismic data processing used to recover high frequencies, attenuate reverberations and short-period multiples and thus improving the temporal resolution of seismic records. It is achieved by removing the negative filtering effects encountered by seismic waves during their travel through the earth. As we know, an impulse is expanded by the earth filter into a wavelet and due to reflection and refraction, several wavelets will be generated. Deconvolution or inverse filtering has been developed, in order to, partially reversing the effect of the earth filter, in others words, deconvolution tries to recover the reflectivity series or earth\u2019s impulse response e(t) from the recorded seismogram x(t) (e. g., Yilmaz; 2001).\nThe main objective of deconvolution is to compress each recorded wavelet into a shorter impulse that is optimal for further processing and interpretation.\nThe complete convolutional trace model is given by\nx(t) = w(t) * e(t) + n(t),\t(3.5)\nwhere x(t) is the filtered output or recorded seismogram, w(t) is the input signal or seismic wavelet, e(t) is the reflectivity series or earth\u2019s impulse response, n(t) is the random ambient noise and * denotes convolution. This convolutional model is based on the following assumptions:\n\u2022\tHorizontally layered earth model of constant velocity.\n\u2022\tNormal incident plane waves that impinge on layer boundaries without shear contribution.\n\u2022\tThe source waveform does not change as it travels in the subsurface, in other words the source waveform is stationary.\nFor the purpose to solve for the unknown e(t) in equation (3.5), we will consider the convolutional trace model given by\nx(t) = w(t) * e(t),\t(3.6)\nbased on the following assumptions:\n\u2022\tThe ambient noise component is zero.\n\u2022\tThe source waveform is known and minimum phase.\nThe earth\u2019s impulse response e(t) can be estimated if a defined filter operator f (t) is convolved with the known seismogram x(t) in this manner\ne(t) = f (t) * x(t)-\t(3.7)\nBy substituting equation (3.7) into equation (3.6), we get\nx(t) = w(t) * f (t) * x(t).\t(3.8)\nEliminating x(t) from both sides of the equation, we have:\n5(t) = w(t) * f (t),\t(3.9)\nFrom equation (3.9), we see that f (t) is the convolution inverse of w(t), namely\nf (t) = w_1(t).\t(3.10)\nAs can be seen, to recover the reflectivity series e(t) from the recorded seismogram, the filter operator f (t) must be the mathematical inverse of the seismic wavelet w(t). It can be accomplished mathematically by using the z-transform,\nF(z) = W(z).\t(3.11)\nIt is noteworthy that the inverse filter converts the recorded seismogram to a series of spikes that defines the earth\u2019s impulse response. In practice a more accurate way to do pulse compression is to employ least-squares filtering. This method designs a finite-length filter under the assumption of minimum error-energy in a least-squares sence. (see, GeoCLASS (2013)).\nUntil now, we have assumed that the seismic pulse is known. However, for most cases we do not know the seismic pulse. Therefore it is necessary to introduce approximations. Typically they are: the reflectivity series has the properties of white random noise and the source waveform is causal and minimum phase.\nThe autocorrelation of the reflectivity series, when it is assumed to have the properties of white random noise is given as\nUrr(Z) = u0, only contribution at zero lag\t(3.12)\nMoreover, from the trace convolutional model it follows:\nUXX(Z) = u0Uss(Z).\t(3.13)\nHence, the autocorrelation of the seismic trace is a scaled version of the autocorrelation of the seismic signal.\nAccording to the application there are different types of deconvolution:\n\u2022\tSpiking Deconvolution: desired output wavelet is a spike. It is also known as whitening deconvolution because a spike has the amplitude spectrum of white noise (i.e. all frequency components have the same amplitude).\n\u2022\tPredictive Deconvolution: attempts to remove the effect of multiples and reverberations.\nSeveral tests of deconvolution were analyzed using operator lengths of 80,160 and 320 ms. These results are displayed in Figures 3.14, 3.15 and 3.16 respectively. If we analyze each of the figures, it can be seen that the spiking deconvolution has been more efficient in the recovery of frequencies, when we used an operator length of 320 ms.\nAfter deconvolution, the traces contain significantly more energy at high frequency. Given that both the high frequency noise and signal are increased by deconvolution, the data needs to be subject to bandpass filter. Additionally, frequency spectral whitening of the traces can be used after deconvolution.\nFigure 3.14: Interactive Spectral analysis of shot gather FFID 787 after spiking deconvolution. The operator length used was 80 ms.\nFigure 3.15: Interactive Spectral analysis of shot gather FFID 787 after spiking deconvolution.\nThe operator length used was 160 ms.\nFFID 787 CHAN\t\t1 \t\t\t2\t3 \t\t4\t5 \t\tFrequ 6 \t\ti 9\t:\t8 \t\t9 \t\t\t\too\tno\t120 1\t1\tL,\t\t\n500 \u2014 1000-\t10\t20\t30\t40\t50\t60\t70\t80\t90\t100\t110\t-2\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n1500\t\t-\t\t\t\t\t\t\t\t\t\t\t\t\t\n2000 \u2014 2500 \u2014 \u201e 3000 \u2014 \u201c 3500 \u2014 4000 \u2014 4500 \u2014 5000 \u2014 5500 \u2014 6000 \u2014 6500 \u2014 120 \u2014 110- 100- 90 \u2014 80 \u2014 =\t70S\t60 \u2014 \u00b1\t50- 40 \u2014 30 \u2014 20- 10-\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t-12\t u -14\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t-\tv .\t-\t- -\t-\t.\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\tWyW\t\u00b0 -16\t -18 \u2014 -20 \u2014 -22 \u2014\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t-26 \u2014 -28 \u2014 -30 \u2014\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\u25a0\u25a0\u25a0\u25a0i\t80 \u2014 60 \u2014 40 \u2014 20 \u2014 -20\u2014 \u25a0 J -40\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\tu m\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t1\t\t\t\t\t\t\t\t\t\t\t\t\n\t- -\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t-60\t -80\t -100\t -120\t -140\t -160-\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t2 v : \u2019 -\tr\t\u2019 \u2019\t4\t\u2019 _ \u25a0\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t: --- =: x? - Av:&lt;_\u2019x :\t_ ? i E:_\tx x = z -xx-\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t=-\t=x<\tJ-\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t= ~x\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nFigure 3.16: Interactive Spectral analysis of shot gather FFID 787 after spiking deconvolution. The operator length used was 320 ms.\n3.6.2\tTime-Variant Spectral Whitening TVSW\nThe spectral whitening sometimes called balancing is used to recover high frequency signal components. It tries to reverse the absorption effect of high frequencies caused by wave propagation in subsurface. In practice, the idea is to flatten the amplitude spectrum as depicted in the top right panel of Figure 3.17. Special care must be taken during this operation. This operation not only tends to sharpen reflectors, it will also sharpen the noise and make everything more \u201dspike-like.\u201d, according to Stockwell (2009). The spectral whitening algorithm operates in the frequency domain. A bandpass filter is part of the process.\nAs mentioned above, if we observe the amplitude spectrum in Figure 3.16, which was obtained only after spiking deconvolution, we can see that the spectrum is almost flat and contains large amounts of energy at high frequencies. In marine data, to difference of land data is generally observed a good energy recovery at high frequencies after spiking deconvolution. For this seismic line is not necessary to apply the TVSW. Because not worsen the final result, the TVSW was applied in order to show its effect on the data.\nTime variant spectral whitening works by applying different gains to individual frequency bands. The spectral whitening selected will be applied to each input trace. The amount of whitening can vary as a function of time.\nEach trace will be transformed to frequency domain and multiplied by the filter slice spectrum, an inverse transform returns the trace to time, and a gain, AGC scalar, is applied to each narrow bandpass-filtered trace. Both the filtered trace and the filtered trace with the gain are summed to produce the whitened output trace and an average AGC scalar trace. The final output trace is divided by the average AGC scalar trace to restore true amplitude.\nFigure 3.19 shows a portion of a CMP stacked section of seismic line 214-2660 after application of time-variant spectral whitening and spiking deconvolution with an operator length of 320 ms. Making the comparison between Figure 3.18 with no spiking deconvolution and Figure 3.19, it is possible to see that Figure 3.19 contains thinner beds and higher frequencies,\ni.e., vertical resolution has been improved.\nFigure 3.17: Spectral analysis after the aplication of TVSW.\nFigure 3.18: Selected area of line 214-2660 without spiking deconvolution. Only amplitude recovery was applied.\nFigure 3.19: Selected area of line 214-2660 with amplitude recovery, spiking deconvolution and TVSW.\n3.6.3\tOrmsby Bandpass Filter\nOrmsby bandpass filtering is commonly used, its principle consists in removing frequencies outside a certain band. The interval is limited to a bandwidth of approximately 10 to 70 Hz because the usable seismic reflection energy falls in this range. Outside this range, seismic data contain high-frequency ambient noise, and ground roll characterized by low-frequency noise (if land data). In others words, the objective of a bandpass filter is to remove both low frequency, as well as high-frequency ambient noise.\nBandpass filtering can be performed before deconvolution to prevent that different kind of noise associated with low and high frequencies may contaminate the signal autocorrelation. It also can be performed before the standard velocity analysis to improve the velocity picking. The passband of a bandpass filter is defined by four frequency values as shown in Figure 3.20. The filter will take the first frequency as the initial value and will gradually allow frequencies to pass in the interval between the first and the second frequency; reaching the second frequency, the filter will pass all components between the second and the third frequency. Finally, from the third frequency, the amount of frequencies allowed to pass will gradually begin to decrease up to the fourth (see, Figure 3.20) .\nIn this work, I used a bandpass filter with the values (8-15-70-80) Hz. Just after the spiking deconvolution and the Time-Variant Spectral Whitening, this Ormsby Bandpass Filter was applied to the data (Figure 3.21). The objective of this bandpass filter was to remove both low frequency, as well as high-frequency ambient noise.\nFigure 3.21: Spectral analysis after spiking deconvolution, TVSW and ormsby bandpass filter have been applied.\n3.7\tCMP Sorting and Velocity Analysis\n3.7.1\tCommon Mid-Point (CMP) Sorting\nBefore the seismic data can be further analyzed, they are resorted in Common-Midpoint (CMP) gathers. The process of selecting a set of traces is called sorting. The set of traces sorted for a particular CMP stack is called the CMP gather. The seismic industry and the literature use the older term common depth point (CDP) interchangeably for CMP.\nSeismic data acquisition with multifold coverage is done in shot-receiver (S, G)-domain. The data is then resorted on a midpoint-offset form, i.e., described by the midpoint-offset (y, fandomain. (Note: y = (G + S)/2, h = (G \u2014 S)/2).\nThe example in Figure 3.22(a) illustrates reflection paths for traces on a single seismogram and reflections points for traces from several seismograms. Observe that for a source at Si, the interval between the reflections points R1, R2,..., R8 is one-half the receiver spacing.\nFigure 3.22(b) depicts the geometry of a CMP gather in case of a single horizontal reflector. In this case the gather can also be denoted a CDP gather because reflectors are horizontal and velocities do not vary horizontally. In this configuration, for isotropic horizontal layers and to small and intermediate offset values, the NMO velocity is equal to RMS velocity. However, when dipping reflectors in the subsurface (Figure 3.22(c)), only the term CMP gather should be used. In practice, when a velocity analysis is carried out, the velocity to be used is the stacking velocity because of the larger offsets.\n3.7.2\tVelocity Analysis and the Stacking Velocity Model\nIn preceding sections I discussed methods to improve the signal of each individual trace. In the velocity analysis our objective is to determine velocities that can flatten each of the hyperbolic reflections, so that we can, add the traces and obtain stacked sections with a good signal to noise ratio (S/N).\nAs explained in the next section, conventional CMP stacking involves summing the primary reflections along the calculated moveout curves which best approximate the actual reflection traveltime curves. For a CMP gather, and small offsets the traveltime curves are approximated by a hyperbolic formula (Hubral and Krey, 1980):\n4h2\nt2(h, -nmo) = t2 + -2--.\t(3.14)\nVNMO\nwhere t is the time of wave propagation from source to receiver, h is half-offset, to is zerooffset traveltime, and VNMO is the moveout (or NMO) velocity. For a single dipping layer the NMO velocity is given by\n\tS4\t\t\tG1\tG2\tG3\tG4\tG5\tG6\tG7\n\t\tS3\tG1\tG2\tG3\tG4\tG5\tG6\tG7\tG8\n\tS2\tG1\tG2\tG3\tG4\tG5\tG6\tG7\tG8\t\nS1\tG1\tG2\tG3\tG4\tG5\tG6\tG7\tG8\t\t\nprofile direction\ndepth\n(a)\tRecording procedure with an eight-channel system to obtain fourfield data. Rows of points indicate the horizontal positions of reflection points for each spread.\nprofile\n(c) The common depth point is not achieved in the case of a dipping reflector.\nFigure 3.22: Reflection travel paths for seismogram traces to be included in a succession of CMP gathers.\nVNMO = ------J \u2022\t(3.15)\ncos 0\nwhere V is the medium velocity and is the dip angle of the reflector. For several layers with arbitrary dips the definition of the NMO velocity becomes more complex. It depends on model parameters such as reflector positions and interval velocities.\nOn each trace in a CMP gather, the arrival time of the reflection from the same reflector will be different, due to the different source-receiver offsets of the traces. Because of these arrival time differences that is called normal move-out (NMO), dynamic time correction or normal move-out (NMO) correction is applied to shift reflections on all traces to a common arrival time before the traces can be added. In case of a stratigraphic earth, these arrival time differences depend on the root-mean-square (RMS) velocity, as well as, on the half-offset distance as we can see from the traveltime equation\nt2(h, vrms) =\t\u2022\t(3.16)\nVrms\nwhere t is the time of wave propagation from source position to depth point and back to receiver position, to is zero-offset traveltime, i.e., the traveltime measured for coincident source and receiver (h = 0), h is half-offset, and vrms is the root-mean-square (RMS) velocity. The root-mean-square (RMS) velocity is given by\nNN\nVLs =\tV2\tAt''\t(3.17)\ni=1\ti=1\nin which, Vi is the interval velocity of the ith layer and t is the two-way traveltime of the reflected ray through the ith layer. The vrms is the effective velocity of a stratigraphic Earth model.\nIn order to apply normal move-out corrections we first need to determine the velocities. This is typically done using an interactive computer program.\nSince the earth is not stratigraphic in general, and also since offsets are not small, equations (3.14) and (3.16) are in practice replaced by equation (3.18). The procedure of search used for velocity analysis is based on trial-and-error and its objective is to identify reflections contained in the CMP gathers. A range of velocity values are used to calculate NMO corrections and after that, the NMO corrected traces are stacked. The velocities which produce the maximum amplitudes of the reflected events in the stack of traces are called stacking velocities vst. Thus the NMO correction is done by a two parametric equation on the form\n2\t2\t4h2\nt (h) = tst + ~2~\u2019\nVst\n(3.18)\nOften stacking velocities are assumed to be close to rms velocities and interval velocities can then be derived using the Dix formula. During the velocity analysis, a velocity spectrum (Figure 3.23) is produced where NMO corrections are computed for narrow time windows along the entire trace, and for a range of velocities. Semblance, by means of the power of the stacked reflected wavelet, is used to assess the suitability of each velocity value. The velocity function defining the increase of velocity with time for a given CMP is derived by picking the peaks in the velocity spectrum. The spectrum is represented by contours corresponding to semblance values, such that contour peaks occur at times corresponding to reflected wavelets, and at velocities which produce an optimum stacked wavelet.\nThe velocity analysis was carried out in ProMAX, in which, the search of stacking velocities was made using semblance or the average absolute value of the data within time-windows for different test velocities. The highest value plotted on a histogram of time versus velocity is chosen as an optimal velocity function. This can be observed in Figure 3.23.\nFigure 3.23 shows the velocity analysis CMP 600. The semblance not only tends to be high if an event with good coherency, but also, is sensitive to if traces contribute equally or not. Consequently, strong events will exhibit high semblance values, weak events will show moderate semblance values, while, incoherent data have low semblance. Figure 3.24 shows the semblance analysis after NMO correction of CMP 600.\nThe velocity analysis was performed for each 100 CMP. Figure 3.25 shows the stacking velocity model obtained for line 214-2660, constructed by interpolation of the picked velocity functions.\nVelocity&lt;n/s> 2500 3000 3500 i I i i \u25a0 \u25a0 I i \u25a0 i i I \u25a0\nFunction#\n10 12\nFigure 3.23: Velocity analysis of CMP 600. From left to right panel we have: Velocity spectrum (semblance histogram), plot of CMP analyzed, mini-stacks based on picked velocity-function (yellow curve) and mini-stacks based on constantvelocity functions\n3.7. CMP Sorting and Velocity Analysis\t39\nJL\tVCiUUby CbllCblJ' old VI V1V1JL VVV CbJLWl 1N1V1V VVLLVVblVll. 11U111 1U10 bV JLJL^llb pcillVl VW lldW. VClVUbJ' OpUVbllllll\n(semblance histogram), plot of CMP analyzed, mini-stacks based on picked velocity-function (yellow curve) and mini-\nstacks based on constant-velocity functions\n40\tChapter 3. CONVENTIONAL PROCESSING\n3.7. CMP Sorting and Velocity Analysis\t41\nFigure 3.25: Stacking velocity model constructed from standard velocity analysis using ProMAX. Each velocity analysis\nis represented by blue lines spaced every 100 CMP.\nis represented by blue lines spaced every 100 CMP.\n3.8\tStacked Section\n3.8.1\tCMP stacked section\nThe procedure for stacking the equivalent zero-offset traces of a CMP gather, is described by the equation\nM\ni=1\nwhere, St is the summation of traces in a CMP family, M is the number of traces in the\nCMP-gather, is the amplitude value for trace i at two-way time t(i).\nAfter applying normal move-out corrections we shift the reflected wavelets to the same arrival times on the equivalent zero-offset traces. Strong reflected signals on the stacked trace are produced from the combination of these aligned wavelets.\nCoherent noise of refracted wavelets and surface waves show straight alignments on seismograms before the normal move-out corrections. When normal move-out correction is applied, they are shifted into random positions or along hyperbolic arcs because of straight alignments. In this case, stacking should attenuate coherent noise as well as other random noise. The conventional CMP-ZO stacked section of seismic line 214-2660 showed in Figure 3.26 has been obtained using the seismic processing package ProMAX. A F-K filter poststack (Figure 3.27) was applied to improved the signal to noise ratio. The polygon specifies a filter as a polygonal region of the F-K plane. This can be achieved thanks to that coherent linear noise in the T-X domain can be separated in the F-K domain by their dips. Coherent linear noise types include guided waves, which often are abundantly present in shallow marine data, ground roll and noise associated with shallow waterbottom side scatterers (e. g., Yilmaz; 2001). In Figure 3.28 is depicted the CMP-ZO stacked section after applying F-K filter. We can see that the events are stronger, clearer and have more continuity. The stacking velocity model used to construct the CMP stacked section was determined, by means of, standard velocity analysis. We will see later that the same velocity field will be used as a guide for CRS parameter estimation.\nFigure 3.26: CMP stacked section belonging to the seismic line 214-2660.\n3.8. Stacked Section\t43\n\nRelative Offset (ni)\n10000\t12000\t14000\n. I\n22000\t24000\n. I\nWavenumber (1/m)\n-0.035\t-0.03\t-0.025\t-0.02\t-0.015\t-0.01\t-0.005\t0\t0.005\t0.01\t0.015\t0.02\t0.025\t0.03\t0.035\n...\t. I .\t. . I .\t. I . .\t.............. I..................I\t.I\n\n\n\ni i\ti\n.......:......:\n[' \u00ae\ni.........................i............................................\nFigure 3.27: F-K Analysis Display Window. The T-X display is in the upper left, T-K display in the upper right, F-X display in the lower left, and F-K display in the lower right.\n44\tChapter 3. CONVENTIONAL PROCESSING\n4000\n0000\nCMP stacked section\n\u25a04000\n6000\nFigure 3.28: CMP stacked section belonging to the seismic line 214-2660. A F-K filter poststack was applied to improved the signal to noise ratio.\n3.8. Stacked Section\t45\n46\nChapter 3. CONVENTIONAL PROCESSING\n4.\tCONVENTIONAL CRS PROCESSING\n4.1\tReview of the Common Reflection Surface (CRS) Stacking Method\nFigure 4.1, shows the seismic processing flow performed to obtain the different CRS stacked sections analyzed in this chapter. The same pre-processed data was used as in the previous chapter.\nThe CRS stack method improves the S/N ratio, making use of the redundancy in seismic multicoverage data to obtain a stacked simulated zero-offset (ZO) section (2D case) or volume (3D case), (Duveneck; 2004). For a given reference trace and time sample, (x0,t0), on the ZO (stacked) volume to be constructed, the CRS method considers the so-called generalized hyperbolic normal moveout\nt2(Ax, h) = (t0 + AxTa)2 + AxTBAx + hTCh,\t(4.1)\ndesigned to approximates the traveltimes of reflection rays in the neighborhood (paraxial) of a reference ZO ray. That ray emerges at the surface point, Xo, specified on the measurement surface (supposed by simplicity as a planar surface) by the 2D-vector x0. The reference and paraxial rays are assumed to be primary and non-converted (PP) rays. In the above equation, Ax and h denote, respectively, the midpoint displacement with respect to x0, and half-offset coordinates of the source and receiver pair, xs and xg in the neighborhood of x0. In symbols, we have\nAx = xm - x0, xm = (xfl + xs)/2 and h = (xg - xs)/2.\t(4.2)\nThe 2D-vector parameter, a, and 2 x 2 parameters B and C are the coefficients of the second-order Taylor expansion of the square of traveltime, t2(x, h), in the vicinity of (x0, t0). Namely,\nwe have\ndt a = dx ,\n( d2t A \\dxmdxLj\nand C = i0( ahdh^) \u2022\n(4.3)\nall derivatives being evaluated at xm = h = 0.\nSpherical Divergence Corrections\nMinimum Phase Spiking Deconvolution TV Spectral Whitening\nClassical Processing\nNMO\nVelocity Model\nGuided Velocity Search from NMO\nAutomatic Velocity Search\nCRS with Smoothed Atributes\nr-Automatic Velocity Search\nGuided Velocity Search from NMO\nCMP\nStacked Section\n~T\u201c\nCRS Stacked Section\nFigure 4.1: Processing flowchart. In gray is shown the processing sequence carried out to obtain the CRS stacked section.\n2 sin P I a=\u2014I\nV0\nThe linear coefficient, a, represents the two-component vector slope at (x0,t0) of the ZO (stacked) traveltime surface to be constructed. It is related to the azimuth, a0, and emergence angle, ^0, of the reference, ZO ray at its arrival point, X0, at the surface. More specifically, we have\ncos a0 sin a0\nwhere v0 is the medium (near-surface) phase velocity at X0. Moreover, the second-order coefficients, B and C are 2 x 2 Hessian matrices, related to the curvature at (x0,t0) of the ZO (stacked) traveltime to be constructed. As described in Duveneck (2004), the parameters B and C can be interpreted in terms of wavefront curvature matrices, KN and KNip , of the so-called Normal (N) and Normal-Incident- Point (NIP) waves (Figure 4.2). The normalincidence-point, NIP, represents the point where the reference ZO ray hits the reflector. As explained in Iversen (2006), it is useful to interpret the N- and NIP-waves as related to the reference normal ray, which is the reflection leg of the reference ZO ray. In other words, the reference normal way is the one that starts at the NIP, with slowness vector normal to the reflector and progresses to the surface where it emerges at the point X0. The N-wave is then the one that starts at the NIP with identical curvature as the reflector and progresses along the reference normal way to the surface, arriving at X0 with curvature matrix KN. On the other hand, the NIP-wave is the one that starts at the NIP as a point source, progresses along the reference normal ray, arriving at X0 with curvature matrix, KNip . More specifically, we have the relations\nB = \u2014 Ht Kn H and&lt;\nV0\nin which H represents the transformation matrix\ncos a0 cos fi0 sin a0 cos fi0\nIn the case of single line seismic data acquisition and 2D propagation, the vectors h and xm reduce to scalars h and xm. Moreover, the traveltime formula (4.1) the simplifies to\nt2 (Ax, h) = (t0 + aAx)2 + B (Ax)2 + Ch2,\t(4.7)\n=\tHt KNip H,\nV0\n(4.5)\n\u2014 sin a0 \\ cos a0 )\n(4.6)\nwith\n2 sin x\t2t0 cos2 a =\t, B =\t V0\tv\t- k Kn\t2t0 cos2 &amp; _ and C \u2014\tKnip . V0\t(4.8)\nin which v0 and ^0 are as previously.\t\t\t\nIt is also convenient to write the B and C parameters as\t\t\t\n|B| --24-\tand\t4 |C | = -2\u2014 .\t(4.9)\nVPST\tVNMO\nFigure 4.2: (a) NIP wave and the associated radius of curvature. (b) The N wave and the associated radius of curvature.\nCoefficient C is related to the NMO-velocity vNMO. Coefficient B on the other hand, has an analogous expression using the quantity vPST, the post-stack velocity.\nThe 3D CRS operator (4.1), depends on eight independent parameters: the horizontal slowness (the two components of the vector, a) and six independent components of the symmetric 2 x 2 matrices, B and C, containing second traveltime derivatives with respect to the midpoint and offset coordinates, respectively. In the 2D case of equation (4.7), the number of parameters reduces to three. All parameters are determined by means of coherence analysis similar to conventional stacking velocity analysis. For each of these parameters, the results can be displayed as a 3D volume, similar to the ZO (stack) volume.\n4.1.1\tEstimation of CRS parameters\nTo obtain stacked sections using equation (4.7), the CRS parameters must be estimated. To do it, the implementation of Mann (2002), based on three independent one-parameter searches is used in this thesis. In the (2D case), with the generation of an automatic CMP stack section, the parameters a, B and C are estimated step by step.\nCMP domain\nBy setting Ax to zero in equation (4.7) transforms the CRS stacking surface to the special case of a CMP gather:\nbCMP\n(Ax = 0, h) =\t+ Ch2,\n(4.10)\nAs can be seen, equation (4.10) has the same form as the standard CMP formula in equation (3.14). Parameter C is now determined automatically for each time sample by picking highest coherencies (i.e. automatic type of velocity analysis).\nZO domain and CRS parameter search\nIn the second step, the CRS stack performs a parameter search using the zero-offset approximation of the CRS traveltime formula. Setting the half-offset h to zero, equation (4.7) reduces to\nt2 (Ax, h = 0) = (to + aAx)2 + B (Ax)2 ,\t(4.11)\nwhere in this traveltime formula, the parameters a and B related with x and KN are unknown. In the short-offset approximation, we set KN = 0 (Muller; 1999). Geometrically this means, that N waves are assumed locally planar for small apertures, and equation (4.11) can be further simplified to yield a one-parametric equation\nt (Ax, h = 0) = (t0 + aAx).\n(4.12)\nThis equation depends only on the unknown parameter a related with the angle of emergence ^0. By means of equation (4.12), an initial angle of emergence is determined for every ZO time sample. In the same way as the automatic velocity scan, a discrete number of angles of emergence are tested.\nAfter vNMO (C) and x (a) are estimated, the KNIP is defined from C through equation (4.8)\nknip =\nCv0\n2t0 cos2 x\n(4.13)\nThe attribute KN (B) can be estimated using equation (4.11) because the parameters x and Knip are now known. It is neccesary to test a range of values and use coherency measure to select optimal values.\nThe kinematic wavefield attributes ^0, KNIP and KN are provided by the search algorithm for every ZO time sample. Each triplet defines a CRS stacking surface in the (Ax, h, t) domain. The initial CRS stacked section is obtained by summing the prestack data along these surfaces and assigning the result to the respective ZO time sample.\n4.2\tCRS Stack with Automatic Search\n4.2.1\tStacking Velocity Model and CRS Stacked Section\nIn this section the velocity model obtained from the C parameter using equation (4.9) is shown. Figure 4.3, shows this stacking velocity model. The C parameter employed has been obtained using automatic search and the multi-step CRS method as proposed by Muller (2003).\nNote that opposed to the conventional velocity analysis, the velocity is now estimated for each trace sample. Figure 4.5 shows the corresponding stacked section.\n4.3\tCRS Stack with Guided Search\n4.3.1\tStacking Velocity Model and CRS Stacked Section\nThe stacking velocity model depicted in Figure 4.4, has been obtained using the conventional velocity field (see Figure 3.25) as a guide to constrain the parametric search of C. The velocity field determined from this strategy is shown in Figure 4.4. Comparison between Figure 4.3 and Figure 4.4 shows that the latter velocity field is to be preferred (the velocity field in Figure 4.3 contains velocity distortions due to the strong water bottom multiples that can be seen between CMPs 400 and 800, from 4s and below). The stacked section obtained with these improved velocities is show in Figure 4.6.\nFigure 4.3: Stacking velocity model obtained from the conversion of C parameter using equation (4.9). The C parameter was obtained with automatic search.\n4.3. CRS Stack with Guided Search\t53\nFigure 4.4: Stacking velocity model obtained from conversion of guided C parameter.\n54\tChapter 4. CONVENTIONAL CRS PROCESSING\n141\nMulti-Step CRS|\nFigure 4.5: CRS stacked section without smoothed ^0 and Kn^p attributes. These attributes were obtained with automatic search.\n4.3. CRS Stack with Guided Search\t55\nCDP\nI 71\t141\t211\t281\t351\t421\t491\t561\t631\t701\t771\t841\t911\t981\t1051\t1121\t1191\t1261\t1331\t1401\t1471\t1541\t1611\t1681\t1751\t1821\t1891\t1961\t2031\nFigure 4.6: CRS stacked section obtained using the stacking velocity model as a restriction to search the C parameter. The velocity model used as a guide was constructed by standard velocity analysis.\n56\tChapter 4. CONVENTIONAL CRS PROCESSING\n5.\tSMOOTHING OF CRS PARAMETERS\n5.1\tFormulation\nIn this thesis a methodology of random-noise attenuation based on smoothening of the CRS parameters is investigated. The CRS parameters are, in an independent way, estimated at each sample of the stacked volume to be constructed. Due to noise in the data and also to the numerics of the search procedures, the resulting parameters suffer from fluctuations along reflection events, as well as non-physical values (outliers) at points of no event. In this way, a stable parameter estimation might not be possible for every ZO location. Moreover, the CRS parameters are generally determined by means of partial, one-parameter searches within subsets of the data (Mann et al.; 1999). As a consequence, these searches most often fail to detect the global coherency maximum for the entire CRS operator. Such inherent shortcoming of the search procedures, most often leads to outliers in the determined attributes, Duveneck (2004). The fluctuations and outliers may have adverse effects in the stack result, and on processes such as velocity estimations which depend on the CRS parameters. In summary, removing the best we can these unwanted outliers and fluctuations is a sensible thing to do. The presented methodology of smoothing the CRS parameters is justified by the following two reasons: (a) The first- and second-order spatial traveltime derivatives which define the CRS stacking operator remain locally constant along the wavelet and (b) From the paraxial ray theory, it is expected that these spatial traveltime derivatives should vary smoothly along a reflection event. All deviations from that expected behavior may be due to noise in the seismic data, as well as from shortcomings of the search strategy.\n5.1.1\tSmoothing Window\nThe smoothing algorithm applied here have been proposed, in the 2D and 3D cases, by Mann and Duveneck (2004) and by Kluver and Mann (2005) respectively. In both cases the algorithm consists of constructing, for each point on the ZO (stacked) volume, taken as a candidate of a reflection, a space-time window aligned to that reflection event within the ZO\nstacked data volume. Once the window is constructed, local statistics (median filtering and averaging based on stack coherency and amplitudes) is applied to the set of ZO points inside the window, with the aim of returning meaningful CRS parameter values to be assigned at the window center point. In the spatial directions, the window should not exceed the first projected Fresnel zone. In order not to mix the time information related to other coherent events, or valuable information with noise, the window should not be larger than the considered event wavelet. Finally, to stay inside the (candidate) reflection event, the window is tilted according to the slope of that event in the stacked section (2D case) or volume (3D case). The window slope is calculated from the angular CRS parameters at the window center from\na =\ndt\ndxm\n2 sin \u00a1o\nvo\n(5.1)\nwhich have been estimated by the CRS stack method (2D case). The following steps are performed for every sample in the ZO (stacked) section and CRS parameter, in order to handle fluctuations as well as outliers:\n1.\tCentered on the considered ZO sample, define a smoothing window with a temporal width of nt samples and a spatial width of nx traces (Figure 5.2).\n2.\tUsing the slope information (linear CRS parameters) at the central ZO sample given by equation (5.1), orient the window along the event, in order to frame the reflection event (Figures 5.3 and 5.4).\n3.\tReject samples below a user-defined coherence threshold in the constructed window (Figures 5.5).\n4.\tWith respect to the central ZO sample, reject all samples in the window with dip difference 0 beyond a user-defined threshold (Figure 5.5).\n5.\tApply a median filter to remove outliers and averaging around the median to remove fluctuations (separately for each attribute type).\n6.\tAssign the result to the corresponding ZO central sample. If there are no remaining parameters, use the original values of the central ZO sample (Figure 5.6).\n7.\tRepeat the procedure for each sample in the ZO section.\nThe Median Filter is an effective method that can suppress isolated noise. Specifically, the median filter replaces a sample by the median of all samples in the neighborhood. For example: a median is the middle point of an ascending-value sequence (Figure 5.1)\nFigure 5.1: Figure showing the results of a signal ordered by a median filter of size five. Top: Five samples are enclosed in the red ellipse. The sample with non-physical value (outlier) is represented in green. Bottom: The outlier is sorted on one side of the window. The middle point (fuchsia) of the ascending-value sequence is chosen.\nMedian = value of\nIV)\nth item term,\n(5.2)\nn correspond to the sample number, thus,\n(5,100, 6, 3, 4, 7,10),\t(5.3)\nwhen ordered, becomes\n(3, 4, 5, 6, 7,10,100).\t(5.4)\nThe median is 6.\nAn appropriate smoothing algorithm should, in principle yield physically meaningful attribute values without destroying any relevant information, see Duveneck (2004). Only samples on the same reflection event are considered for each smoothed attribute value. There is no mixing of intersecting events due to difference of slopes in different events, conflicting dip situations need no action and do not lead to wrong results. In this case, the attributes of each event will be smoothed separately.\nFigure 5.2: Centered on the considered ZO sample, define a smoothing window with a temporal width of nt samples and a spatial width of nx traces.\nFigure 5.3: Using the slope information (linear CRS parameters) at the central ZO sample, orient the window along the event, in order to frame the reflection event.\nFigure 5.4: Select all samples in window with respect to the central ZO sample.\nFigure 5.5: Reject samples of coherence and dip difference 0 beyond a user-defined threshold, in the constructed window.\nFigure 5.6: If there are no remaining parameters, use the original values of the central ZO sample. Repeat the procedure for each sample in the ZO section.\n5.1.2\tCentral ZO sample for different cases\nFor a better understanding, each case was summarized in table 5.1.2 to 5.1.2. The symbols &lt;and > used in each table mean that, the attribute values within the smoothing window are below or above, respectively, of our desired threshold. In all cases, it is assumed that the values for the central ZO sample of KNiP are very high compared to physical values and are not real. On the other hand, the values of KNiP are physical values for the remaining ZO samples in the window. It is worth remembering that 0 is the difference of inclination of the other samples with respect to the central ZO sample and a high value corresponds to an other event.\nWhen the central ZO sample of the smoothing window is in a region of the ZO section that has low signal to noise ratio, and its coherence is low or is below the desired range, the central sample will not be taken into account. A low coherence indicates that the kinematic wavefield attributes are unreliable or that the considered zero-offset sample is not located on a reflection event, see Duveneck (2004). In the same way samples adjacent to the central ZO sample belonging to the same smoothing window will not be taken into account if their coherence are low. In this case the original value is preserved.\nTable 5.1: It will leave the original value because only the central sample is selected.\nValues\tCoherence\t0\tChosen\nCentral ZO Sample\t>\t>\tYes\nRemaining ZO Samples\t>\t\tNot\nTable 5.2: It will leave the original value because no sample is selected.\nValues\tCoherence\tQ\tChosen\nCentral ZO Sample\t<\t>\tNot\nRemaining ZO Samples\t<\t\tNot\nTable 5.3: It will leave the original value because no sample is selected.\nValues\tCoherence\tQ\tChosen\nCentral ZO Sample\t<\t<\tNot\nRemaining ZO Samples\t<\t\tNot\nTable 5.4: It will leave the original value because only the central sample is selected.\nValues\tCoherence\tQ\tChosen\nCentral ZO Sample\t>\t>\tYes\nRemaining ZO Samples\t<\t\tNot\nTable 5.5: It will leave the original value because no sample is selected.\nValues\tCoherence\tQ\tChosen\nCentral ZO Sample\t<\t>\tNot\nRemaining ZO Samples\t>\t\tNot\nTable 5.6: It will leave the original value because only the central sample is selected.\nValues\tCoherence\tQ\tChosen\nCentral ZO Sample\t>\t<\tYes\nRemaining ZO Samples\t<\t\tNot\nTable 5.7: It will work with the value of samples adjacent to the central sample, because the central sample has low coherence value.______________________________________\nValues\tCoherence\tQ\tChosen\nCentral ZO Sample\t<\t<\tNot\nRemaining ZO Samples\t>\t\tYes\nTable 5.8: All samples will be considered except the central ZO sample of the attribute KNIP. As mentioned initially, it is assumed that the values of KNIP are not real for the central ZO sample, and for this reason, they are removed by the Median Filter.____________\nValues\tCoherence\t0\tChosen\nCentral ZO Sample\t>\t<\tYes\nRemaining ZO Samples\t>\t\tYes\n5.2\tSynthetic Data Test of Smoothed Parameters\nIn order to test the methodology of random-noise attenuation based on smoothing of the CRS parameters, I applied it to a synthetic marine dataset.\nThe synthetic data set was obtained by ray-tracing in the elastic isotropic model depicted in Figure 5.7. This geological model contains a reverse fault with an angle of 45\u00b0 located in the central part of the model, with a few horizontal layers at both sides of the fault. The velocity field varies from 1500 to 3700 m/s, see Figure 5.8. The acquisition set up is that of a 2.5D model. Namely, the model is homogeneous in the y-direction (cross line), acquisition line is along the horizontal, x-direction (in-line). The acquisition geometry comprises 370 shots spaced every 40 m and 240 receivers per shot spaced every 20 m. The sampling rate is 4 ms. Random noise was added to the data with a S/N ratio of 1/100 of the largest amplitude found in the trace. Other type of noise, slash noise was added to simulate the effects of instrument problems or electrical discharges, and occur across a range of 60 traces per shot at times from 1.5 and 4.5 seconds.\nThe effect of the smoothing of the parameters, fi0 and KNIP can be evaluated by means of the stacked sections shown in the next figures. In Figure 5.9(a) no attribute smoothing has been applied, while Figure 5.9(b) shows the stacked result with smoothed attributes and a clearer definition of the reflectors.\nIn this example, a smoothing window with a temporal extension of nt = 2 samples and a spatial extension of nx = 3 traces was employed. The coherence threshold was 0.005 and the maximum angle deviation allowed was A0 = 2\u00b0. The stacked result after attribute smoothing presents a significant improvement. We can see a better definition of the reflectors in the whole section, besides the amplitude of the signal corresponding to the random noise has decreased around the reflectors. When the central ZO sample of the smoothing window is located on parts only of noise that have low coherence and these values are below the user-defined threshold, the original value is not modified.\nFigure 5.7: 2.5D model used to generate the synthetic data. Acquisition line is highlighted in black.\n5.3\tCRS Stack of Marine Data with Automatic Search and Smoothed Parameters\nThe seismic processing flowchart carried out to obtain the different CRS stacked sections discussed in this chapter is depicted in Figure 5.10. As in the previous chapters the same pre-processed data was used.\nWe return again to the marine field data and apply now the smoothening technique. To obtain the smoothed KNIP and attributes, a smoothing window has been applied with a temporal extension of nt = 11 samples and a spatial extension of nx = 11 traces. The coherence threshold was 0.005 and the maximum angle deviation allowed was A = 2\u00b0. The smoothing process was applied four times until an optimal result was achieved. The stack result due to parameter smoothing presents a significant improvement.\n5.3.1\tStacking Velocity Model and CRS Stacked Section\nThe only difference between the stacking velocity model in Figure 5.11, with respect to, the velocity model in Figure 4.3, is that C parameter has been smoothed.\nFigure 5.8: Velocity profile of the synthetic model.\nFigure 5.13 shows the corresponding stacked section.\n5.4\tCRS Stack of Marine Data with Guided Search and Smoothed Parameters\n5.4.1\tStacking Velocity Model and CRS Stacked Section\nFigure 5.12 has been obtained employing the smoothed C parameter in combination with a velocity guide model (Figure 3.25).\nComparing the velocity models in Figure 4.3 and Figure 5.12 we can see, that the first one gives more inconsistent values than the second. As example, between the CMPs 400 to 800 after 4 seconds velocity values of 1500 m/s (represented in blue color) are irregularly distributed without relation to litological units but caused by waterbottom multiples.\nThus like before, velocity models obtained using a velocity guide are more stable. In addition, the velocity model depicted in Figure 5.12 contains less distorted velocity values, compared with the result of Figure 4.4.\nFinally, Figure 5.14 shows the corresponding stacked section obtained. It can be seen that the multi-step CRS stacked section (Figure 4.5) presents a significant improvement in S/N ratio, with respect to, the CMP stacked section (Figure 3.26).\nA comparison between the CRS stacked sections not using the stacking velocity model as a guide, i.e., Figure 4.5 and Figure 5.13, shows that Figure 5.13 which is stacked using the smoothed KNIP attribute has a better attenuation of random noise.\nRegarding the ZO stacked sections obtained using a stacking velocity model as a guide, i.e., Figure 4.6 and Figure 5.14, the section with the best S/N ratio is the one in Figure 5.14. The two stacked sections are very similar, however a small difference related to random noise attenuation is observed.\n\nBMW\nSsnait\n(a)\tCRS stack result, without smoothed and Knip sections.\n(b)\tCRS stack result, with smoothed\tand Knip sections.\nFigure 5.9: Synthetic marine data set.\nSpherical Divergence Corrections\n1\nMinimum Phase Spiking Deconvolution TV Spectral Whitening\nClassical Processing\nNMO Velocity Model\nGuided Velocity Search from NMO\nAutomatic Velocity Search\nGuided Velocity Search from NMO\nCMP\nStacked Section\nAutomatic Velocity Search\nFigure 5.10: Processing flowchart. In gray is shown the processing sequence carried out to obtain the CRS stacked section based on smoothed attributes.\n\u201e___.___.__!\t\u25a0 -\tH-L\n-4--1---1--i---i---i-r\nk---!---j--j---j---j-H\n---!\u201c........\ni - ; - -fe -L \u25a0 i \u2014\n\u2014---k*\n_j|\n4\u2014\nI\n-I--\n70\tChapter 5. SMOOTHING OF CRS PARAMETERS\n5.4. CRS Stack of Marine Data with Guided Search and Smoothed Parameters\t71\nCDP\nI 71\t141\t211\t281\t351\t421\t491\t561\t631\t701\t771\t841\t911\t981\t1051\t1121\t1191\t1261\t1331\t1401\t1471\t1541\t1611\t1681\t1751\t1821\t1891\t1961\t2031\nFigure 5.13: CRS stacked section created with smoothed ^0 and Kn^p attributes.\n72\tChapter 5. SMOOTHING OF CRS PARAMETERS\n2000\n4000\nSmoothed Multi S. CRS with Guide|\n2000\n\u25a04000\nFigure 5.14: CRS stacked section generated using the smoothed ^0 and KNIP attributes and the stacking velocity model as a restriction to search the C parameter. This velocity model was constructed in standard velocity analysis.\n5.4. CRS Stack of Marine Data with Guided Search and Smoothed Parameters\t73\n74\nChapter 5. SMOOTHING OF CRS PARAMETERS\n6.\tMIGRATION\nOn a seismic stacked section, the reflection point is located vertically below, only if the reflector is horizontal. If the reflector has a component of dip along the survey line, the reflection point is displaced in the up-dip direction; if the reflector has a component of dip across the survey line, the reflection point is displaced out of the plane of the section.\nAccording to Sheriff (2002), \u2019\u2019Migration is an inversion operation involving rearrangement of seismic information elements so that reflections and diffractions are plotted at their true locations.\u201d If an integral type of migration is used, its principle is to sum energy along the diffraction curve or scattering traveltime for a given point difractor and place it at the apex (Figure 6.1).\nThe objective of migration is to position more correctly the reflection events. Migration improves seismic interpretation because the corrected locations of the various geological structures. It also improves the resolution of seismic sections because diffractions patterns produced by point reflectors and faulted beds are collapsed. Time is still the vertical dimension in case of time migration, but in depth migration, by means of an appropriate velocity model, the migrated section gives directly the reflector depths.\n6.1\tReview of Kirchhoff Migration\nIn Kirchhoff migration acccording to Bancroft (2007), for every migrated sample, energy is summed along the diffraction, or hyperbolic paths, on the input section. The summed value becomes the amplitude value at the output location. Additional scaling and filtering may be required.\nFollowing the principle of Huygens, reflectors in the subsurface can be visualized as being made up of many points that act as secondary sources. Superposition of many hyperbolic traveltime responses represents a zero-offset section and the diffraction hyperbolas generated by the discontinuities, for example faults along the reflector, often stand out.\nIn a stratigraphic model (time migration), the migration equation will take the form\n(a) Point Difractor.\n(b) Scattering traveltime curve.\nFigure 6.1: Scattering traveltime curve from a fixed depth point, used to explain the Poststack migration. Source: GeoCLASS (2013)\nR(xo,t)=\tcos\t-d x, /t2 + 4(x - xo)2/crms(r), 0 dx\nJ 2^J (1/2)nC2rms(T)/t2 + 4(x - xo)2/c2rms(T)\n(6.1)\nwhere, R is the reflectivity, xo is the horizontal spatial axis of output image, x is the horizontal spatial axis of input image, t is the event time in the migrated position, and crms is the rms-velocities.\ncos p =\nT\n/t 2+4<x - xo)2/crm\u201e,(T)\n(6.2)\nIn order handle a locally horizontally layered earth model, Kirchhoff migration uses a smoothed version of rms-velocities obtained from the velocity analysis.\n6.2\tGeometrical Distortion\nOn a seismic stacked section, the reflection point is located beneath the mid-point in a CMP gather, only if the reflector is horizontal. If the reflector has a component of dip along the survey line, the reflection point is displaced in the up-dip direction; if the reflector has a component of dip across the survey line, the reflection point is displaced out of the plane of the section. In a homogeneous medium of constant seismic velocity, the seismic reflection\nFigure 6.2: (Left) Geological model of a planar-dipping reflector surface. (Right) Associated record surface derived from a non-migrated seismic section (Zero-offset section). Source: GeoCLASS (2013).\npoint is located on a semi-circle centered on the source-receiver position that has a radius that depends on the traveltime.\n6.2.1\tDipping Reflector\nFor a zero-offset measurement, the reflections coming from a dipping reflector travel perpendicular to the dipping interface. However, they are plotted in a stacked section as if they have traveled perpendicular to the surface, i.e. for the source-receiver pair in zero-offset distance located in a CMP, the position of the seismic reflection point in subsurface is displaced relative the vertical below the CMP. It is not possible to relate the positions in time and depth of a reflection point by simple vertical stretching. This is why the image of a dipping reflector obtains a wrong dip in the stacked section. For the case of a constant velocity model above the reflector, the image on the stacked section is also dipping, however with the dip angle different of the subsurface dip angle (Figure 6.2).\n6.2.2\tSyncline\nThe syncline is represented by a valley in stratified rocks in which the rocks dip toward a central depression. In a seismic stacked section it produces an effect called \u201dbow-tie\u201d (Figure 6.3).\n6.2.3\tPoint Difractor\nIn a homogeneous medium, point difractors produced by faults or other geological structures, appear in a stacked section as a diffraction hyperbola (Figure 6.4). This hyperbola represent\nFigure 6.3: (Left) A synclinal feature. (Right) A \u2019bow-tie\u2019 shape on the non-migrated seismic section, resulting of the reflection event. Source: GeoCLASS (2013).\nFigure 6.4: (Left) Reflections paths from a point difractor. (Right) Difraction curve generated by the dispersion of the enegy in the point difractor. Source: GeoCLASS (2013).\nrays from all directions generated by a point difractor. In a medium of variable velocity above the point difractor, the diffraction event will not be a hyperbola, it will be transformed to a curve of similar convex shape.\n6.3\tKirchhoff Time Migration Results\nPost-stack Kirchhoff migration, was employed to migrate the CMP and CRS stacked seismic sections. Besides the velocity field, the input parameters were chosen to be 80 Hz as maximum frequency to migrate and a maximum dip to migrate of 45\u00b0. In the migration test, we chose the CMP stacked section and the most optimal CRS stacked section (Smoothed parameters and Velocity guide). Figures 6.5 and 6.6 show the corresponding migrated sections. The PostSTM of the CRS stack employed with the smoothed attributes and the velocity model\nas guide, shows more continuous and clearer reflectors overall than the PostSTM of the CMP stack.\nFigure 6.7 shows enlarged images corresponding to the left area of the poststack time migration of the CMP and CRS stacked sections (Figure 6.6). Beside the general improvement of image quality, the CRS stack section shows details that are hardly visible in the CMP stack section. The unconformity that crosses the entire seismic section is clearly identified as explained in the next chapter. Similarly, the onlap is better identified in the PostSTM of the CRS stack.\nLikewise, Figure 6.8 shows enlarged images corresponding to the right rectangle of the poststack time migration of the CMP and CRS stacked sections. The mini-basin and internal reflectors of the anticline which was generated by the movement of salt, are better imaged in the PostSTM of the CRS stack.\nCDP\nI\t71\nI\tI\nKirchhoff Migration from CMP]\n1500\n-3500\n\u25a05500\nFigure 6.5: The CMP stacked seismic section in Figure 3.26 after post-stack Kirchhoff migration. The velocity model used to obtain the migration is represented in Figure 3.25\n80\tChapter 6. MIGRATION\nCDP\nI\t71\nI\tI\nKM from Smooth MS CRS with Guide\n-6500\nFigure 6.6: The seismic section in Figure 5.14 after post-stack Kirchhoff migration. The velocity model used to obtain the migration is represented in Figure 5.12\n6.3. Kirchhoff Time Migration Results\t81\n(a) PostSTM of the CMP stack\n(b) PostSTM of the CRS stack\nFigure 6.7: Zooms of poststack time migrated sections corresponding to the left area as presented in Figures 6.5 and 6.6.\n(a) PostSTM of the CMP stack\n(b) PostSTM of the CRS stack\nFigure 6.8: Zooms of poststack time migrated sections corresponding to the right area as presented in Figures 6.5 and 6.6.\n84\nChapter 6.\nMIGRATION\n7.\tSEISMIC INTERPRETATION\nThe role of the interpreter, in general a geologist or geophysicist, is to analyze the processed seismic data and create a geological model that represents the subsurface geology along the interest survey area. The seismic interpretation can be classified according to the focus, into two types: structural and stratigraphic. Stratigraphic interpretation looking for understanding how the layers were sedimented along the time. In structural interpretation, the objective is to identify the geological layers or, equivalently, the interfaces between the layers, as well as structures that truncates, fold or cut these layers, such as erosional surfaces, folding and faults.\nSheriff (2002) defines a seismic horizon as the surface that separates two different layers of rock, and this surface (even without having been identified) is associated with a reflection that spans a large area. A seismic horizon manifests itself in seismic data as a series of events (peaks or valleys of seismic amplitudes) that appear consistently from trace to trace. The mapping of the horizons of the data set is one of the most important tasks of seismic interpretation. The seismic horizons are also called reflectors. Seismic reflectors are the result of changes in the acoustic impedance of the different layers in the subsurface.\n7.1\tGeological Model\nFrom the time migrated sections of seismic line 214-2660 located in the Jequitinhonha Basin, structural interpretation was performed. Due to the seismic processing result of these research and to the quality of the seismic data, the events were very well visualized and selected to interpretation. It is important to mention, that the well stratigraphic data was not available for the seismic line interpreted on this study and because of this, the well correlation between seismic and the geological units was performed based on basin analysis.\nIn this sense, the criterion for seismic interpretation of reflectors is the lateral coherency of the seismic amplitude. For this, the stronger horizons were outlined following a polarity of wavelet (positive or negative). After that, they were correlated with deformed zones composed by faults and folds. The faults were identified due to the discontinuity of reflectors. By used of this methodology, the most important interfaces between the layers were defined.\nSix main reflectors were identified defining five major seismic stratigraphic zones, i.e., a region between two interpreted horizons. These reflectors were marked with a different color (green, orange, blue, fuchsia, black and yellow), and they may or may not represent a stratigraphic sequence. In terms of faults, these were marked in red. In this way, we defined between the green and orange horizons, a zone Z1, between orange and blue horizons a zone Z2, between blue and fuchsia horizons a zone Z3, between the fuchsia and black horizons a zone Z4, and between the black and yellow line horizons a zone Z5, as can be seen in Figures 7.1 and 7.2. Until now, the seismic stratigraphic interpretation has been mostly concerned with structures as faults, folds and to follow the main reflectors. However, analyzing in more detail each of the migrated sections, it can be concluded that it is possible to identify different stratigraphic features such as onlap or uncomformities present in the basin, in the migrated section obtained from the CRS stack. It can be seen that within each zone, patterns will reveal information about the sedimentation. The seismic section obtained with the CRS method allowed a better identification of the reflectors that could hardly be interpreted in conventional seismic section. As example the uncomformity.\nAfter thoroughly analyzing the pattern of deposition in each zone, it was defined the geometry of the stratigraphic layers between them. The sequence in which the layers were deposited within each zone, provided the understanding of the stratigraphic evolution in the area under study.\nElements of seismic stratigraphy as unconformity and onlap were recognized. The unconformity is located over the black reflector (Figure 7.3) and the onlaps were interpreted between the fuchsia and black reflector at 3.5 s TWT (Two-way Traveltime). Moreover, it was identified a possible mini-basin at (3.5 s TWT, 1541 CDP (where CDP means Common Depth Point)) generated by the effect of deformation due to direct contact with the fault zone. The observed anticlinal at (3.5 s TWT, 1261 CDP), is the product of a salt deformation front (Figure 7.4). This deformation front propagates northward generating salt domes.\n7.2\tStructural Framework and Seismic Stratigraphy\nThe seismic analysis of each of the areas of the geological model, provided information about the geological history of the region: the zones 1 and 2, were interpreted as a moment of regression in the basin. By comparing with the stratigraphic chart, it can be seen that in the Lower Eocene, it starts a change in the sedimentation pattern, from a retrogradational sedimentation to a progradational sedimentation, i.e., in the stratigraphic chart we have a well-defined regressive marine megasequence which coincides with the stratigraphic sequence represented by zones 1 and 2 (see Figure 7.2). To confirm that these areas are of regressive system tract, it can be arrange the layers by periods of time, consequently, the layers will appear flat and parallel, and just showing their lateral projection. This characterized the\nmarine environment as a regression.\nSimilarly, in the stratigraphic chart from the Urucutuca Formation, we have the transgressive marine megasequence, which in the geological model can be represented by zone 3, because it is possible to correlate the deposition pattern of this zone with the findings in the stratigraphic chart. Again, after rearranging the model after periods in time, it was observe that it is a transgressive system tract. The sequence of shallow carbonate platform, which corresponds to the Barra Nova Group, can not be neither proven nor defined using seismic data, however thanks to its stratigraphic disposition, probably it lies in zone 4.\nThe transitional sequence, characterized by evaporites Upper-Aptian also corresponds to the zone 4 because, this underlies the sequence transgressive marine (zone 3). Finally, the continental sequence or Macuri Member, which can not be characterized by sequence stratigraphy, defines the area 5 overlapping the basement.\nStructurally speaking, it can be observed in the seismic image a megarollover produced by a large extensional listric fault formed at the landward edge of the salt basin. This listric fault does not appear in this seismic section. Growth strata are also observed in the left part of the seismic image indicates that they grew as a result of downslope gravity spreading with compression occurring at the leading edge of the salt.\n\nFigure 7.1: Seismic interpretation on the PostSTM obtained from the CMP stacked section (Figure 3.26).\n88\tChapter 7. SEISMIC INTERPRETATION\nFigure 7.2: Seismic interpretation on the PostSTM obtained from the CRS stacked section (Figure 5.14).\n7.2. Structural Framework and Seismic Stratigraphy\t89\n(a) PostSTM of the CMP stack\n(b) PostSTM of the CRS stack\nFigure 7.3: Zooms of interpreted sections corresponding to the left area as presented in Figures 6.5 and 6.6.\n(a) PostSTM of the CMP stack\n(b) PostSTM of the CRS stack\nFigure 7.4: Zooms of interpreted sections corresponding to the right area as presented in Figures 6.5 and 6.6.\n92\nChapter 7. SEISMIC INTERPRETATION\n8.\tCONCLUSIONS\n\u2022\tThe present work has investigated how the smoothing of CRS attributes can attenuate random noise in seismic sections. The smoothing of the kinematic wavefield attributes differentiates from other methods regarding the attenuation of random noise in a stacked section. The algorithm uses locally valid statistics applied in small windows aligned with the reflection events. In synthetic and real data, random noise attenuation was achieved.\n\u2022\tThe signal to noise ratio of the seismic section obtained with the CRS stack method without using smoothed attributes and a velocity model as guide, was higher compared with the CMP stack method. However, in the CRS section, waterbottom multiples remained stronger than in the CMP section.\n\u2022\tThe optimal CRS stacked section was obtained using the smoothed attributes and a velocity model as a guide. Similarly, the corresponding PostSTM section, showed stronger and clearer horizons respecting the stratigraphy.\n\u2022\tThe marine section obtained after random-noise reduction showed a good S/N ratio. In the PostSTM section it was possible to map the major horizons. Because of this, seismic stratigraphic elements like onlap and unconformity, indicating periods of deposition and erosion, respectively could be identified. In the same way it was possible to outline the major normal faults present in the seismic section.\n94\nChapter 8.\nCONCLUSIONS\nBibliography\nANP (2013). Ag\u00eancia Nacional do Petr\u00f3leo, http://www.anp.gov.br. [Online; accessed 15-May-2013].\nBancroft, J. C. (2007). A Practical Understanding of Pre- and Poststack Migrations, Vol. 1 of 13, Society Of Exploration Geophysicists.\nBednar, J. B. (1983). Applications of median filtering to deconvolution, pulse estimation, and statistical editing of seismic data, Geophysics 48: 1598-1610.\nDavison, I. (2007). Geology and tectonics of the south atlantic brazilian salt basins, The Geological Society of London 272: 345-359.\nDPC and Assoc. (2000). Relatorio anual: Petroleum Systems of Brazil. Rio de Janeiro.\nDuncan, G. and Beresford, G. (1995). Some analyses of 2-D median f-k filters, Geophysics 60: 1157-1168.\nDuveneck, E. (2004). Tomographic determination of seismic velocity models with kinematic wavefield attributes. University of Karlsruhe, logos Verlag, Ph.D thesis .\nFomel, S. and Liu, Y. (2010). Seislet transform and seislet frame, Geophysics 25(75).\nGaglione, P., Trindade, L. and Nascimento, M. (1987). Avaliac\u00e3o geoqu\u00edmica das bacias marginais ao Sul da Bahia, Brasil, In: Congresso Brasileiro de Geoqu\u00edmica 2: 467-491.\nGeoCLASS (2013). Seismic Imaging, http://www.unigeo.no/class/new_geoclass_embed. html. [Online; accessed 5-June-2013].\nGulunay, N. (2000). Noncausal spatial prediction filtering for random noise reduction on 3-D poststack data, Geophysics 65: 1641-1653.\nIversen, E. (2006). Amplitude, Fresnel zone, and NMO velocity for PP and SS normalincidence reflections, Geophysics 71(2): W1-W14.\nKarsli, H., Dondurur, D. and Cif^B G. (2006). Application of complex-trace analysis to seismic data for random-noise suppression and temporal resolution improvement, Geophysics 71: V79-V86.\nKluver, T. and Mann, J. (2005). Smoothing and automated picking of kinematic wavefield attributes, Expanded Abstracts, 75th Ann. Internat. Mtg., Soc. Expl. Geophys, pp. 18941897.\nLu, W. and Liu, J. (2007). Random noise suppression based on discrete cosine transform, Expanded Abstracts, 77th Ann. Internat. Mtg., Soc. Expl. Geophys., pp. 2668-2672.\nMagoon, L. B. and Dow, W. G. (1994). The Petroleum System: From Source to Trap, AAPG Memoir 60, American Association Of Petroleum Geologists.\nMann, J. (2002). Extensions and Applications of the Common-Reflection-Surface Stack Method., PhD thesis, University of Karlsruhe.\nMann, J. and Duveneck, E. (2004). Event-consistent smoothing in generalized high-density velocity analysis, Expanded Abstracts, 74th Ann. Internat. Mtg., Soc. Expl. Geophys. Session ST 1.1.\nMann, J., Jager, R., Muller, T., Hocht, G. and Hubral, P. (1999). Common-reflection-surface stack - a real data example., J. Appl. Geoph. 42(3,4): 283-300.\nMi, Y. and Margrave, G. F. (2000). Median filtering in kirchhoff migration for noisy data, Expanded Abstracts, 70th Ann. Internat. Mtg., Soc. Expl. Geophys., pp. 822-825.\nMuoller, A. (2003). The 3D Common-Reflection-Surface Stack - Theory and Applica-tion.University of Karlsruhe, Ph.D thesis .\nMuller, T. (1999). The Common Reflection Surface Stack Method: Seismic Imaging without explicit knowledge of the velocity model., PhD thesis, University of Karlsruhe.\nNeelamani, R., Baumstein, A. I., Gillard, D. G., Hadidi, M. T. and Soroka, W. I. (2008). Coherent and random noise attenuation using the curvelet transform, The Leading Edge 27: 240-248.\nNewman, P. (1973). Divergence effects in a layered earth, Geophysics 38(3): 481-488.\nNorris, M. W. and Faichney, A. K. (2002). SEG Y rev 1 Data Exchange format, 1.0, Soc. Expl. Geophys.\nRistau, J. P. and Moon, W. M. (2001). Adaptive filtering of random noise in 2-D geophysical data, Geophysics 66: 342-349.\nSantos, C. F., Gontijo, R. C., Araujo, M. B. and Feuo, F. J. (1994). Bacias de cumuruxatiba e jequitinhonha, Boletim de Geociencias da Petrobras 8(1): 185-190.\nSheriff, R. E. (2002). Encyclopedic Dictionary of Exploration Geophysics, Vol. 13, 4 edn, Society of Exploration Geophysicists.\nStockwell, J. (2009). Geophysical Image Processing with Seismic Unix: GPGN 461/561 Lab.\nYilmaz, O. (2001). Seismic Data Analysis, Vols. 1 and 2, Soc. Expl. Geophys."}]}}}