{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.25239"}, {"@name": "filename", "#text": "9871_barbosa_lffm_me_guara.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNIVERSIDADE ESTADUAL PAULISTA\n\"J\u00daLIO DE MESQUITA FILHO\"\nCAMPUS DE GUARATINGUET\u00c1\nLU\u00cdS FELIPE FERREIRA MOTTA BARBOSA\nDrilling optimization of petroleum and natural gas wells: application of artificial intelligence\nGuaratinguet\u00e1-SP\n2019\nLu\u00eds Felipe Ferreira Motta Barbosa\nDrilling optimization of petroleum and natural gas wells: application of artificial intelligence\nDisserta\u00e7\u00e3o apresentada \u00e0 Faculdade de Engenharia do Campus de Guaratinguet\u00e1, Universidade Estadual Paulista, para a obten\u00e7\u00e3o do t\u00edtulo de Mestre em Engenharia Mec\u00e2nica na \u00e1rea de Energia.\nOrientador: Prof Dr. Jo\u00e3o Andrade de Car-\nvalho J\u00fanior\nCoorientador: Prof Dr. Andreas Nascimento\nGuaratinguet\u00e1-SP\n2019\nBarbosa, Lu\u00eds Felipe Ferreira Motta\nB238d Drilling optimization of petroleum and natural gas wells : application of artificial intelligence / Lu\u00eds Felipe Ferreira Motta Barbosa. - Guaratinguet\u00e1, 2019. 176 f : il.\nBibliografia: f. 144-155\nDisserta\u00e7\u00e3o (Mestrado) - Universidade Estadual Paulista, Faculdade de Engenharia de Guaratinguet\u00e1, 2019.\nOrientador: Prof. Dr. Jo\u00e3o Andrade de Carvalho J\u00fanior\nCoorientador: Prof. Dr. Andreas Nascimento\n1. M\u00e1quinas de perfura\u00e7\u00e3o 2. Po\u00e7os de petr\u00f3leo - Perfura\u00e7\u00e3o. 3. G\u00e1s natural 4. Ind\u00fastria petrol\u00edfera I. T\u00edtulo.\n__________________________________________________________________CDU 622.24.05 (043) P\u00e2mella Benevides Gon\u00e7alves\nBibliotec\u00e1ria/CRB-8/9203\nUNIVERSIDADE ESTADUAL PAULISTA\nCAMPUS DE GUARA TINGUET\u00c1\nunesp\nLUIS FELIPE FERREIRA MOTTA BARBOSA\nESTA DISSERTA\u00c7\u00c3O EOI JULGADA ADEQUADA PARA A OBTEN\u00c7\u00c3O DO T\u00cdTULO DE\n\u201cMESTRE EM ENGENHARIA MEC\u00c2NICA\u201d\nPROGRAMA: ENGENHARIA MEC\u00c2NICA AREA: ENERGIA\nAPROVADA EM SUA FORMA FINAL PELO PROGRAMA DF. P\u00d3S-GRADUA\u00c7\u00c3O\nProl*. Dr*. Ana Paula Rosifini Abes Claro\nCoordenadora\nJaneiro de 2019\nDADOS CURRICULARES\nLU\u00cdS FELIPE FERREIRA MOTTA BARBOSA\nNASCIMENTO\t05/06/1992 - Guaratinguet\u00e1 / SP\nFILIA\u00c7\u00c3O\tFernando C\u00e9sar Mendes Barbosa Ana Cristina Ferreira Motta Barbosa\n2010/2015\tCurso de Gradua\u00e7\u00e3o em Engenharia Mec\u00e2nica na Faculdade de Engenharia de Guaratinguet\u00e1, Universidade Estadual Paulista\n2017/2018\tCurso de P\u00f3s-Gradua\u00e7\u00e3o em Engenharia Mec\u00e2nica, n\u00edvel de Mestrado, na Faculdade de Engenharia de Guaratinguet\u00e1, Universidade Estadual Paulista\nACKNOWLEDGEMENTS\nI\twould like to express my gratitude to my supervisors Prof. Dr. Jo\u00e3o Andrade and Prof. Dr. Andreas Nascimento, for the support and guidance throughout the development of this study, to Dr. Andr\u00e9 Leibsohn from CENPES/Petrobras for inviting me for a technical visit and for conversations about drilling optimization,\nto Prof. Dr. Skalle P\u00e2l from Norwegian University of Science and Technology (NTNU) for his kind support in helping us to understand the drill-curves from Norway used in the current thesis,\nto Prof. Dra. Mar\u00edlia In\u00eas Mendes Barbosa from Universidade Federal de Uberl\u00e2ndia for explaining me some relevant topics related to petroleum geology,\nto M.Sc. Lu\u00eds C\u00e9sar Ferreira Motta Barbosa (UNESP, Department of Production) for his important advice on relevant aspects of scientific methodology,\nto the colleagues, especially M.Sc. Fellipe Sartori, and all employees from UNESP, School of Engineering, Guaratinguet\u00e1,\nto the Coordena\u00e7\u00e3o de Aperfei\u00e7oamento de Pessoal de N\u00edvel Superior - Brasil (CAPES) for the scholarship that I received,\nand, last but not least, to my parents and brothers for always supporting me.\nThis study was financed in part by the Coordena\u00e7\u00e3o de Aperfei\u00e7oamento de Pessoal de N\u00edvel\nSuperior - Brasil (CAPES) - Finance Code 001\nABSTRACT\nTo meet the increasing primary energy demand, more challenging petroleum reserves started being explored, such as the reservoirs from pre-salt formation close to the Brazilian and Angolan coasts. Historically, low penetration rates in drilling the pre-salt carbonates were reported in the literature, resulting in large capital expenditure on well's construction. Since the major part of exploration cost is associated with drilling, optimizing this activity is of major importance. In this context, the main objective of the present thesis is to investigate methods for real-time drilling optimization of oil and natural gas wells. A common way to optimize drilling activities is to determine the optimum operational variables (e.g. weight-on-bit and rotational speed) that maximizes the ROP. However, this may yield a decrease in drilling efficiency. An alternative to reduce problems related to drilling inefficiency, such as excessive bit wear and vibrations, is through the selection of operational variables able to minimize the specific energy (SE) spent to excavate a volumetric unit of rock. For that, it is necessary to employ accurate predictive models able to capture how the operational variables (weight-on-bit, rotational speed, mud flow and so on) influence not only on ROP but also on SE. Therefore, the present thesis employed a well-known machine learning method, called random forest, instead of analytical equations found in drilling engineering books. Thus, it was possible to obtain accurate predictive models for ROP and SE, to be used, later, as objective functions in optimization problems to determine the optimum parameters, weight-on-bit and rotational speed. Real-time drilling data from pre-salt region and Norwegian continental shelf were employed. First, several aspects related to training process of random forests were investigated. Among them, it was confirmed the possibility of predicting the ROP with accuracy by employing only four inputs: depth, weight-on-bit, rotational speed, and mud flow. The prediction of SE was carried out by coupling the mathematical formulation with predictive models of ROP and torque (if available). Optimization problems were analyzed with one objective function, as well as with multiple objective functions through the e-constraint technique. It was observed the sole maximization of ROP may lead to increase in the energy required to drill. However, by imposing the inequality SE(x)) &lt;SEacutai * e on the maximization of ROP, it was possible to reduce significantly the amount of observations whose ROP increased due to detriment of drilling efficiency. For the minimization of SE problems, it was observed a special care to be taken when simulating low-values for weigh-on-bit and rotational speed.\nKEYWORDS: Multi-objective optimization. Drilling efficiency. Rate of penetration. Machine learning. Random forest.\nRESUMO\nPara atender \u00e0 crescente demanda de energia prim\u00e1ria, come\u00e7aram a ser exploradas reservas de petr\u00f3leo em \u00e1reas mais desafiadoras, tais como os reservat\u00f3rios da forma\u00e7\u00e3o do pr\u00e9-sal pr\u00f3ximos \u00e0s costas brasileira e angolana. Historicamente, observa-se baixa taxa de penetra\u00e7\u00e3o na perfura\u00e7\u00e3o dos carbonatos do pr\u00e9-sal, resultando em altos custos na constru\u00e7\u00e3o de po\u00e7os. Como a maior parte dos custos de explora\u00e7\u00e3o est\u00e1 associado com perfura\u00e7\u00e3o, a otimiza\u00e7\u00e3o desta atividade \u00e9 de grande import\u00e2ncia. Neste contexto, o principal objetivo desta disserta\u00e7\u00e3o \u00e9 investigar m\u00e9todos de otimiza\u00e7\u00e3o em tempo-real de po\u00e7os de petr\u00f3leo e g\u00e1s natural. Uma forma comum de se otimizar a perfura\u00e7\u00e3o \u00e9 atrav\u00e9s da determina\u00e7\u00e3o dos par\u00e2metros operacionais (peso na broca e rota\u00e7\u00e3o) que maximizem a taxa de penetra\u00e7\u00e3o (rate of penetration, ROP). Contudo, isto pode acarretar na diminui\u00e7\u00e3o da efici\u00eancia do processo de perfura\u00e7\u00e3o. Assim, uma forma de diminuir problemas relacionadas a inefici\u00eancias da perfura\u00e7\u00e3o, tais como gasto excessivo da broca ou vibra\u00e7\u00f5es, \u00e9 atrav\u00e9s da sele\u00e7\u00e3o dos par\u00e2metros operacionais, minimizando a energia espec\u00edfica (specific energy, SE) gasta para escavar uma unidade volum\u00e9trica de rocha. Para tanto, \u00e9 necess\u00e1rio o emprego de modelos precisos que relacionem como as vari\u00e1veis operacionais (peso da broca, rota\u00e7\u00e3o, vaz\u00e3o do fluido de perfura\u00e7\u00e3o entre outros) influenciam, n\u00e3o somente o ROP, mas tamb\u00e9m a SE. Desde modo, a presente disserta\u00e7\u00e3o empregou um m\u00e9todo conhecido de aprendizagem de m\u00e1quinas, chamado de florestas aleat\u00f3rias, em vez das equa\u00e7\u00f5es anal\u00edticas comumente encontrados em livros de engenharia de perfura\u00e7\u00e3o. Assim, foi poss\u00edvel obter modelos de previs\u00e3o precisos para ROP e SE, para, depois, serem utilizados como fun\u00e7\u00f5es objetivas em problemas de otimiza\u00e7\u00e3o para sele\u00e7\u00e3o \u00f3tima dos par\u00e2metros (peso na broca e rota\u00e7\u00e3o). Dados de perfura\u00e7\u00e3o da regi\u00e3o do pr\u00e9-sal e da plataforma continental norueguesa foram utilizados. Primeiramente, investigou-se diversos aspectos relacionados ao treinamento das florestas aleat\u00f3rias. Entre eles, verificou-se a possibilidade de estimar com precis\u00e3o o ROP utilizando apenas quatro par\u00e2metros: profundidade, peso na broca, rota\u00e7\u00e3o e vaz\u00e3o de fluido. A previs\u00e3o da SE, por sua vez, se fez atrav\u00e9s do acoplamento da formula\u00e7\u00e3o matem\u00e1tica com os modelos preditivos do ROP e torque (quando dispon\u00edvel). Foram investigados problemas de otimiza\u00e7\u00e3o contendo tanto uma fun\u00e7\u00e3o objetiva quanto problemas com m\u00faltiplas fun\u00e7\u00f5es objetivas atrav\u00e9s da t\u00e9cnica e-constraint. Verificou-se que a maximiza\u00e7\u00e3o sozinha da taxa de penetra\u00e7\u00e3o pode acarretar em aumento da energia gasta para se perfurar. Contudo, ao impor como restri\u00e7\u00e3o a inequa\u00e7\u00e3o SE(x) &lt;SEactual * e ao problema da maximiza\u00e7\u00e3o da taxa de penetra\u00e7\u00e3o, foi poss\u00edvel diminuir consideravelmente a quantidade de observa\u00e7\u00f5es que o aumento do ROP se deu atrav\u00e9s do detrimento da efici\u00eancia da perfura\u00e7\u00e3o. Para o problema da minimiza\u00e7\u00e3o da SE, constatou um cuidado que se deve ter ao simular combina\u00e7\u00f5es de peso na broca e rota\u00e7\u00e3o com valores baixos.\nPALAVRAS-CHAVE: Otimiza\u00e7\u00e3o multiobjetiva. Efici\u00eancia da perfura\u00e7\u00e3o. Taxa de penetra\u00e7\u00e3o.\nAprendizagem de m\u00e1quinas. Florestas aleat\u00f3rias.\nLIST OF FIGURES\nFigure 1.1 World primary energy demand by fuel type in million of barrels of oil equivalent per day (mboe/d) ................................................................... 21\nFigure 1.2 Monthly prices of crude oil in USD/barrel traded in Dubai Fateh and West Texas Intermediate (WTI) ................................................................ 22\nFigure 1.3 a) Santos basin geology with pre-salt source rocks (carbonate reservoirs) beneath the thick layer of evaporites; b) potential drilling problems when drilling the evaporites ................................................................. 23\nFigure 1.4 Drilling optimization cycle ................................................. 24\nFigure 2.1 The rotary drilling process.................................................. 27\nFigure 2.2 Classification of drilling variables. The symbol / indicates that those vari-\nables are chosen for mathematical optimization.............................. 28\nFigure 2.3 Typical drill bits: a-b) roller cone bits; c-e) fixed cutter bits ........... 29\nFigure 2.4 Drilling variables that affect the ROP......................................\t31\nFigure 2.5 Drilling mechanical parameters influences' on penetration rate (ROP) ....\t32\nFigure 2.6 Schematic description of optimum zone........................................ 36\nFigure 2.7 Five levels of process control and optimization (time scales for each level) .\t38\nFigure 2.8 a) Typical drill-rate test data showing non-linear response below the minimum depth of cut and above the founder point; b) Bit weight (WOB) test carried during a run ............................................................................ 39\nFigure 2.9 Some possible objective functions for drilling optimization ................. 40\nFigure 2.10 Partitions and CART......................................................... 44\nFigure 2.11 Framework of conventional ensemble methods. The solid blue lines show the parallel flow of bagging, random subspace and Random Forest. The dashed red lines in generation and base prediction parts denote boosting ensemble framework................................................................................ 47\nFigure 2.12 Input space and objective space for the case of two objective functions ...\t51\nFigure 3.1 Approaches for ROP modeling ................................................. 57\nFigure 3.2 A compilation of 58 works found on the literature considering thesis and\npapers (publications in journals and congresses) using other methods different\nthan the traditional models for ROP prediction. Status: October 2018..................... 57\nFigure 3.3 Using neural networks to assess parametric analysis: a) effect of WOB, b)\nmud-weight (MW), and c) plastic viscosity on ROP ........................................ 63\nFigure 3.4 Contour plot for ROP versus normalized values of A) depth (X1) and weight\non bit (X2), B) depth (X1) and bit rotation speed (X3)....................... 64\nFigure 3.5 Variable importance: a) automated feature selection resulted applied by Es-kandarian, Bahrami and Kazemi (2017) with fscaret, b) based on random forest ROP predictor performed by Hegde et al. (2017)................................ 65\nFigure 3.6 Data Partition developed at UT Austin..................................... 67\nFigure 3.7 Possible approaches to treat measurement errors in drilling data that can be applied to drilling data analysis.................................................... 69\nFigure 3.8 Simplifying the multicriteria optimization into a single objective functions. Response surfaces form the basis for the objective function (OBJ).................... 73\nFigure 4.1 Raw recording of drill curves from Well H. The specific energy was calculated based on Taele\u2019s formulation......................................................... 79\nFigure 4.2 A sample of real-time drilling data considering the first approx. 8 hours of available recording \u2014 Well 4 from Norway............................................. 82\nFigure 4.3 Data Pre-Treatment Method................................................. 84\nFigure 4.4 After a change from not-drilling to rotary drilling, the transient state is identified. 88\nFigure 4.5 MAPE against the cut-off threshold, which enables to avoid the problem of small values in computing this relative metric....................................... 91\nFigure 4.6 Equidistant grid points between lower and upper limits of an variable x. . . .\t97\nFigure 4.7 Optimization workflow adopted in the current work......................... 98\nFigure 5.1 Comparison between ROP Models ............................................102\nFigure 5.2 Histograms of R-correlation on testing dataset............................105\nFigure 5.3 The initial population influenced by the random starting for the Well 8 and\n10. For both cases, the cardinality of possible inputs was 25............107\nFigure 5.4 Testing R-correlation - sensitive analysis of the train ratio.............109\nFigure 5.5 Cumulative out-of-bag MSE for ROP-prediction: random forests trained using the same procedure from the Experiment 01......................................110\nFigure 5.6 Data-driven models against coupled models for SE prediction...............111\nFigure 5.7 Histograms of SE calculated based on Teale\u2019s formulation, considering four levels of ROP-threshold - well 8.....................................................112\nFigure 5.8 Maximum value of SE for each well against the ROP-threshold...............113\nFigure 5.9 SE data-driven models: actual SE against prediction intervals on test dataset. 116\nFigure 5.10 Density scatter assessing the SE coupled-model based on Rabia\u2019s formulation for the Well 10 - coupling with ROP predictive-model.................................118\nFigure 5.11 Maximization of ROP and its influence on specific energy - Well D........123\nFigure 5.12 Maximization of ROP: histograms of difference between the optimized parameters and actual values ......................................................... 124\nFigure 5.13 Maximization of ROP: relative amount of observations with improvement in\nROP versus relative amount of observations with drilling-efficiency improved as consequence of WOB and RPM optimization...............................126\nFigure 5.14 Minimization of SE: histograms of difference between the optimized parameters and actual values - Well B..................................................127\nFigure 5.15 Minimization of SE: relative amount of observations with improvement in SE versus relative amount of observations with ROP improved as consequence of WOB and RPM optimization......................................................129\nFigure 5.16 Influence of e on the relative amount of observations that could be optimized for the problem of minimization of SE(x) subject to ROP(x) > ROP(x) * e.130\nFigure 5.17 Minimization of SE(x) subject to ROP(x) > ROP(x) * e - well D with not realistic optimum solutions..................................................132\nFigure 5.18 Minimization of SE(x) subject to ROP(x) > ROP(x) * e - optimum solutions for the well D with new lower limits...................................134\nFigure 5.19 Minimization of SE(x) subject to ROP(x) > ROP(x) * e - relative amount of optimized observations........................................................136\nFigure 5.20 Influence of e on the relative amount of observations that could be optimized for the problem of maximization of ROP(x) subject to SE(x) &lt;SE(x) * e 137\nFigure 5.21 Maximization of ROP(x) subject to SE(x) &lt;SE(x) * e - optimum solutions for the well D ........................................................... 138\nFigure 5.22 Maximization of ROP(x) subject to SE(x) &lt;SE(x) * e - relative amount of optimized observations........................................................140\nFigure A.1 Getting the sequence of the variable names in RTDD.cuve_info; showing an example for the well 6. The first line of RTDD.cuve_info indicates that the variable 'Time' is recorded in the first column; the variable 'DBTM' is recorded in the second column and so on..........................................156\nFigure A.2 Real-time drilling data of well 6 considering the first approx. 8 hours of available recording according to the informed sequence of variable names - state: \u201chow it is\u201d. It is possible to observe that the HKL is acting like the BPOS, and the TRQ like the RPMA..................................................159\nFigure A.3 Real-time drilling data of well 6 considering the first approx. 8 hours of available recording according to our suggestion for the variable names - Our suggestion for the sequence of the variable names................................160\nFigure A.4 Graphical Study of the real-time drilling data - well 6 - file 1......161\nFigure B.1 Raw recording of drill curves from Well A. The specific energy was calculated based on Rabia\u2019s formulation.....................................................162\nFigure B.2 Raw recording of drill curves from Well B. The specific energy was calculated\nbased on Taele\u2019s formulation.....................................................163\nFigure B.3 Raw recording of drill curves from Well D. The specific energy that was\ncalculated based on Rabia\u2019s formulation..........................................164\nFigure C.1 Parametric influence of Hampel filter on detecting outliers. Some missing\nvalues (not-a-number instances) are deteced as outliers..........................166\nFigure C.2 Relative amount of outliers for different levels of window half-width and thresholds (TH) - all drill curves from pre-salt.......................................167\nFigure C.3 Relative amount of outliers for different levels of window half-width and thresholds (TH) - all drill curves from Norway, excluding the well 2...................167\nFigure D.1 Visual approach to determine the thresholds for the automated operation recognition. For illustration purpose, drill curves from well 8 are plotted.\nSimilar analysis for all other wells was carried out.......................168\nFigure D.2 An example for a transient state correctly identified - well 6 - first change identified. .......................................................................... 169\nFigure D.3 Reducing the from 0.2m to 0.15m could improve the transient state recognition: a) the second change was not recognized when was 0.2 m; b) the second change was recognized after reducing the tolerance to 0.15 m - well 6 - eighth change identified.............................................................170\nFigure D.4 An example for a transient states identified from not-drilling to rotary drilling, and vice-verse - well 6 - sixteenth change identified..................................170\nFigure D.5 The transient state detection could avoid considering some observations as rotary drilling - well 6 - twenty-first change identified..............................171\nFigure E.1 Two dimensional histogram of ROP against WOB for the Well 3: a) filtered data after third step with all drilling states, b) after fourth step with only rotary drilling state, c) after validation step...............................................172\nFigure E.2 Two dimensional histogram of ROP against RPM for the Well 3: a) filtered data after third step with all drilling states, b) after fourth step with only rotary drilling state, c) after validation step...............................................173\nFigure E.3 Two dimensional histogram of ROP against WOB for the Well 4: a) filtered data after third step with all drilling states, b) after fourth step with only rotary drilling state, c) after validation step...............................................173\nLIST OF CODES\nCode 4.1 - General use of hampel function, adapted from Mathworks (2018a)............... 86\nCode 4.2 - Example of hyperparameters tuning with Bayesian optimization for the TreeBagger object. Adapted from Mathworks (2018e)............................................. 93\nCode 5.1 - Function to initialize the population. Source: Oluleye et al. (2014a)........106\nLIST OF TABLES\nTable 3.1 - ROP modeling using multiple regression carried out by Moraveji and Naderi (2016) ................................................................................ 59\nTable 3.2 - Some works that used Machine Learning Methods to predict the ROP. ....\t60\nTable 3.3 - The use ROP models to optimize the drilling variables, considering a singleobjective problem ..................................................................... 70\nTable4.1 - Overview of the drilling data from pre-salt formation. The abbreviation meanings are found in Annex A ......................................................... 77\nTable 4.2 - Amount of missing values in each variable (column). For illustration purpose, statistics only from the Well H is presented. This dataset has a total of 5 184 observations and 15 variables, therefore the total amount of values is 5 184 \u2022 15 = 77 760............................................................................ 78\nTable 4.3 - Amount of observation with k-variables as missing values - Well H.......... 78\nTable 4.4 - Relative amount of observations with k-variables as missing values ........ 79\nTable 4.5 - Real-time drilling data from Norway published by Donne (2017). The abbreviation meaning used in these dataset can be found in Annex B ......................... 81\nTable 4.6 - Rules to determine drilling modes for real-time drilling data in time domain .\t87\nTable 4.7 - Drilling parameters required for the development of the current work....... 94\nTable 5.1 - Data pre-treatment setting................................................. 99\nTable 5.2 - Amount of observations for each well from the original dataset to the final dataset after the data pre-treatment...................................................100\nTable 5.3 - Simple comparison between the Bourgoyne and Young Model and a random forest regression for ROP prediction, using the drilling data of the Well B. The standard deviation is given in parentheses.............................................101\nTable 5.4 - Inputs selected for each experiment. The inputs of the Experiment 02 consist\nof adding the listed variables to the group of the Experiment 01............104\nTable 5.5 - Average of evaluation metrics for ROP prediction on testing dataset........104\nTable 5.6 - Options for Feature Selection based on Binary Genetic Algorithm............106\nTable 5.7 - Best subsets obtained by binary genetic algorithm..........................108\nTable 5.8 - Drilling variables used to calculate the SE................................113\nTable 5.9 - Inputs selected for the not-coupled and coupled models to predict the SE. . . 114\nTable 5.10-SE prediction based on data-driven models without the core variables ROP\nand torque as inputs: average of evaluation metrics on train and test dataset. . 115\nTable 5.11-SE prediction based on data-driven models with the core variables ROP and\ntorque as inputs: average of evaluation metrics on test dataset........................117\nTable 5.12-Evaluation metrics on test datasets for SE coupled-models based on Rabia\nformulation: ROP predictive model against inverse-ROP predictive model . . 120\nTable 5.13-Evaluation metrics on test dataset for SE coupled-models: a comparison between Teale's and Rabia's formulation..........................................121\nTable 5.14-Maximization of ROP - some statistics about the difference between optimized\nand actual-variable values .......................................... 125\nTable 5.15-Minimization of SE - some statistics about the difference between optimized and actual variable-values ..................................................... 128\nTable 5.16-Problems identified in the third optimization problem................133\nTable 5.17-Minimization of SE(x) subject to ROP(x) > ROP(x) * e - some statistics\nabout the difference between optimized and actual variable-values ... 135\nTable 5.18-Maximization of ROP(x) subject to SE(x) &lt;SE(x) * e - some statistics about the difference between optimized and actual variable-values .............. 139\nTable 5.19-Elapsed time in seconds for training phase (including data pre-treatment) and grid-search in the optimization algorithm........................................141\nTable A.1-Sequence in which the variable names appear in the drilling data with 10 variables recorded (that is, the 2nd group). We highlighted the columns with the problem......................................................................157\nTable A.2-Suggestion for the variable names of the well 6. We believe that the sequence of the variable names for the well 6 should be the same as the wells 4, 5 and 7, which can be achieved by only sliding the RPM to the column # 6, and moving the yellow block downwards.......................................................158\nTable F.1 - Torque prediction based on random forests: average of evaluation metrics on train and test dataset...........................................................174\nTable A.1 -Mnemonics employed in drilling data from Pre-Salt ...................175\nTable B.1 - Mnemonics employed in drilling data from Norway ....................176\nLIST OF ABBREVIATIONS AND ACRONYMS\nANN\tArtificial Neural Networks\nCCS\tConfined Compressive Strength\nDSATS\tDrilling Systems Automation Technical Section\nECD\tEquivalent Circulating Density\nESD\tEquivalent Static Density\nGA\tGenetic Algorithm\nGBM\tGradient Boosting Machine\nHMSE\tHydro-Mechanical Specific Energy\nHP/HT\tHigh Pressure and High Temperature\nIEA\tInternational Energy Agency\nMAD\tMedian Absolute Deviation\nMAE\tMean Absolute Error\nMAPE\tMean Absolute Percentage Error\nMAPEa\tAdapted Mean Absolute Percentage Error\nMME/EPE\tMinit\u00e9rio de Minas e Energia - Empresa de Pesquisa Energ\u00e9tica\nMSE\tMean Squared Error\nMWD\tMeasurements While Drilling\nOPEC\tOrganization of the Petroleum Exporting Countries\nPSO\tParticle Swarm Optimization\nRF\tRandom Forests\nRMSE\tRoot Mean Squared Error\nROP\tRate of Penetration\nRTDD\tReal-Time Drilling Data\nSE\tSpecific Energy\nSPE\tSociety of Petroleum Engineers\nUCS\tUnconfined Compressive Strength\nWOB\tWeight on Bit\nWTI\tWest Texas Intermediate\nCONTENTS\n1\tINTRODUCTION........................................................ 21\n1.1\tCURRENT SCENARIO.................................................... 21\n1.1.1\tChallenges of Pre-Salt.............................................. 22\n1.2\tDRILLING OPTIMIZATION............................................... 23\n1.2.1\tDrilling Optimization Based on Predictive Models and Related Works .\t24\n1.3\tOBJECTIVES.......................................................... 26\n1.4\tWORK STRUCTURE...................................................... 26\n2\tTHEORETICAL BACKGROUND.............................................. 27\n2.1\tOVERVIEW OF DRILLING ENGINEERING ................................... 27\n2.1.1\tRotary Drilling..................................................... 27\n2.1.2\tDrilling Variables.................................................. 28\n2.1.3\tPerformance Indicators.............................................. 30\n2.1.3.1\tRate of Penetration................................................. 30\n2.1.3.2\tSpecific Energy .................................................... 33\n2.1.3.3\tDrilling Efficiency................................................. 34\n2.1.3.4\tSome indicators of drilling problems................................ 35\n2.1.3.5\tEconomics .......................................................... 36\n2.1.4\tOptimization of Controllable Drilling Variables .................... 37\n2.2\tREGRESSION MODELS BASED ON MACHINE LEARNING METHODS 40\n2.2.1\tRegression Analysis ................................................ 41\n2.2.2\tEnsemble Learning .................................................. 42\n2.2.3\tBase Learners ...................................................... 43\n2.2.4\tParallel Learning with Bagging and Random Forests................... 45\n2.2.5\tSequential Learning with Boosting................................... 46\n2.2.6\tOther Ensemble Methods.............................................. 47\n2.2.7\tHyperparameter Optimization ........................................ 48\n2.2.8\tFeature Selection................................................... 49\n2.3\tINTRODUCTION TO MULTI-OBJECTIVE OPTIMIZATION........................ 49\n2.3.1\tThe Single-Objective Optimization Problem........................... 49\n2.3.2\tThe Multi-Objective Optimization Problem............................ 50\n2.3.3\tMulti-Objective Optimization Techniques ............................ 51\n2.3.4\tDecision Making Techniques ......................................... 52\n2.3.4.1\tGlobal Criteria Method.............................................. 52\n2.3.4.2\tWeighted Sum Method ................................................ 53\n2.3.4.3\tThe e-constraint method........................................ 54\n2.3.5\tOptimization Techniques........................................ 54\n2.3.6\tBrief Remark on Multi-Objective Optimization Algorithms........ 55\n3\tMACHINE LEARNING METHODS APPLIED TO RATE OF PENE-\nTRATION PREDICTION AND OPTIMIZATION - A REVIEW ....\t56\n3.1\tMETHODS USED IN ROP PREDICTION................................. 56\n3.1.1\tTraditional Models............................................. 57\n3.1.2\tStatistical Models............................................. 59\n3.1.3\tMachine Learning Applied to Predict the ROP.................... 59\n3.2\tDISCUSSION ON ROP MODELS....................................... 61\n3.2.1\tMachine Learning Algorithms Outperforms Other Methods ......... 61\n3.2.2\tSensitive Analysis............................................. 62\n3.2.3\tFeature Extraction............................................. 64\n3.2.4\tImportance of Geological Formation in ROP Prediction .......... 64\n3.2.5\tData Partition ................................................ 66\n3.2.6\tDrilling Data ................................................. 66\n3.2.7\tHandling Measurement Errors.................................... 68\n3.3\tDRILLING OPTIMIZATION BASED ON PREDICTIVE MODELS ....\t70\n3.3.1\tSingle-Objective Optimization.................................. 70\n3.3.2\tMulti-Objective Optimization .................................. 71\n3.3.3\tThe Need of Changing the Current Mindset....................... 73\n3.4\tSUMMARY........................................................ 74\n4\tMETHODS ....................................................... 76\n4.1\tMATERIALS ..................................................... 76\n4.1.1\tDrilling Data from Pre-Salt ................................... 76\n4.1.2\tDrilling Data from Norway...................................... 80\n4.1.3\tSoftware and Hardware.......................................... 83\n4.2\tPREDICTION DRILLING PERFORMANCE-INDICATORS .................... 83\n4.2.1\tData Pre-Treatment ............................................ 83\n4.2.2\tTraining the Predictive Models ................................ 88\n4.2.3\tEvaluation Metrics ............................................ 89\n4.2.4\tHyperparameters Optimization .................................. 92\n4.2.5\tFeature Selection ............................................. 93\n4.3\tDRILLING PARAMETERS OPTIMIZATION .............................. 94\n4.3.1\tSingle-Objective Optimization ................................. 94\n4.3.2\tMulti-Objective Optimization .................................. 95\n4.3.2.1\tThird optimization problem..................................... 95\n4.3.2.2\tFourth optimization problem ................................... 95\n4.3.3\tGrid-Search Strategy........................................... 96\n4.3.4\tOptimization Workflow.......................................... 97\n5\tRESULTS AND DISCUSSION......................................... 99\n5.1\tRATE OF PENETRATION PREDICTION................................. 99\n5.1.1\tData Pre-Treatment Setting..................................... 99\n5.1.2\tSimple Comparison between ROP Models...........................100\n5.1.3\tSelection of Most Important Inputs in the Prediction Task......102\n5.1.3.1\tDriller\u2019s Approach.............................................103\n5.1.3.2\tEvolutionary Feature Selection.................................105\n5.1.4\tRatio Influence of Training Dataset to Overall Dataset.........108\n5.1.5\tCumulative MSE of Random Forests...............................109\n5.2\tSPECIFIC ENERGY PREDICTION.....................................110\n5.2.1\tCalculating SE ............................................... 111\n5.2.2\tData-driven models for the Specific Energy.....................114\n5.2.3\tCoupled Models for the Specific Energy.........................117\n5.2.3.1\tRabia\u2019s Model..................................................118\n5.2.3.2\tTeale\u2019s Model..................................................120\n5.2.4\tFinal Remark Regarding SE modeling ........................... 121\n5.3\tDRILLING PARAMETERS OPTIMIZATION...............................122\n5.3.1\tSingle-Objective Optimization..................................122\n5.3.1.1\tFirst Optimization Problem - maximization of ROP ..............122\n5.3.1.2\tSecond Optimization Problem - minimization of SE...............126\n5.3.2\tMulti-objective optimization ................................. 129\n5.3.2.1\tThird Optimization Problem - minimization of SE, transforming maximiza-\ntion of ROP into an inequality.................................129\n5.3.2.2\tFourth Optimization Problem - maximization of ROP, transforming minimiza-\ntion of SE into an inequality..................................136\n5.3.3\tOn the Implementation\u2019s Feasibility of Proposed Optimization Methods 140\n6\tCONCLUSIONS....................................................142\nREFERENCES ................................................... 144\nAPPENDIX A - NEW SUGGESTION FOR THE VARIABLE NAMES\nOF THE WELL 6 FROM NORWAY......................156\nAPPENDIX B - DRILL-CURVES FROM PRE-SALT ...................... 162\nAPPENDIX C - DATA PRE-TREATMENT ANALYSIS OF HAMPEL FILTER ................................... 165\nAPPENDIX D - DATA PRE-TREATMENT ANALYSIS OF OPERATION RECOGNITION ......................... 168\nAPPENDIX E - DATA PRE-TREATMENT ANALYSIS OF VALIDATION DRILL CURVES ........................ 172\nAPPENDIX F - TORQUE PREDICTION................174\nANNEX A - ABBREVIATIONS FOR REAL-TIME DRILLING DATA FROM PRE-SALT ............................ 175\nANNEX B - ABBREVIATIONS FOR REAL-TIME DRILLING DATA\nFROM NORWAY ........................ 176\n21\n1\tINTRODUCTION\n1.1\tCURRENT SCENARIO\nThe energy supply is continuously increasing. From 1973 to 2015, the growth of world total primary energy supply was 124% (IEA, 2017a). Despite the increasing interest in renewable energies, the fossil fuels still have relevance as sources of primary energy. The Organization of the Petroleum Exporting Countries (OPEC) expects that the oil and natural gas demand increases on short-, medium- and long-term, as seen in Figure 1.1; for 2040, it is expected the oil and natural gas meet around 52% of world energy demand (OPEC, 2017).\nFigure 1.1 - World primary energy demand by fuel type in million of barrels of oil equivalent per day (mboe/d)\nIn 2014, the oil companies underwent a new scenario, which led to a considerable fall of oil prices, as can be seen in Figure 1.2. Many researchers claim that the reason for the oil plunge was the United States (US) shale oil boom (BYRNE; LORUSSO; XU, 2018; KIM, 2018; KHAN, 2017). However, another study stated that the reason behind this fall is the weakening global oil demand (PREST, 2018). Despite this controversy, it is hard to believe that a sudden change in world energy matrix will occur in next years or medium-term future. The International Energy Agency mentioned that the era of oil is not over, and, in a long-term future, energy supply expansion will be led by natural gas and renewable energies (IEA, 2017b). Since last year, the oil prices have been increasing.\nTo supply the future demand, investments in oil and gas exploration are required. With\npre-salt discoveries, Brazil has become one of most important non-OPEC countries in terms\nof oil and gas production (OPEC, 2017), attracting the attention of the world. Several foreign\noil companies participated in the recent bidding rounds of Brazilian pre-salt (NUNES; LIMA,\n2017). For example, one of these companies was Equinor (former Statoil), that plans to invest in\nBrazil US 15 billions dollars until 2030 (FURLAN, 2018).\n22\nFigure 1.2 - Monthly prices of crude oil in USD/barrel traded in Dubai Fateh and West Texas Intermediate (WTI)\nSource: IndexMundi (2018a) and IndexMundi (2018b).\nThe production of petroleum will sharply increase in Brazil, reaching 5.2 millions of barrel per day by 2026, and pre-salt fields will be responsible for 74% of the total production (MME/EPE, 2017, p. 154-155). Due to several difficulties in drilling, optimization is crucial to the future exploration and development of pre-salt areas.\n1.1.1\tChallenges of Pre-Salt\nThe oil and gas industry has started exploring reservoirs in more challenging environments, such as the petroleum reserves from pre-salt formation close to the Brazilian and Angolan coasts (NASCIMENTO, 2016).\nWellbore construction in these areas is associated with several challenges. For example, Brazilian pre-salt reservoirs are located about 300 km from the coast in ultradeep waters. The varying composition of thick salt layer (evaporite) brings several challenges related to drilling, because each composition has different creep rates, leading to several problems (see Figure 1.3). Beneath the evaporite interval, the heterogeneous nature of layered carbonates with silica nodes affects drilling progress of pre-salt reservoirs (FRAGA et al., 2015; BEASLEY et al., 2010). Historically, low penetration rates were reported in drilling the pre-salt carbonates, resulting large capital expenditure on well\u2019s construction (NASCIMENTO et al., 2016).\nTherefore, optimization of drilling operations is of major importance, and one way to\nachieve it is by finding the optimum combination of drilling parameters that can enhance\nthe overall efficiency. Nascimento (2016) reported potential savings of millions of dollar by\noptimizing drilling activities in pre-salt regions.\n23\nFigure 1.3 - a) Santos basin geology with pre-salt source rocks (carbonate reservoirs) beneath the thick layer of evaporites; b) potential drilling problems when drilling the evaporites\n1.2\tDRILLING OPTIMIZATION\nAccording to Lyons and Plisga (2004, p. 4.363), \u201cthe objective of optimizing drilling practices is to safely deliver a product capable of highest production capacity in a cost-effective manner\u201d . The authors stated also that the drilling optimization must consider different aspects, namely, health, safety and environment (HSE), and production capability as well. That means, the selection of drilling actions must be taken considering the whole process.\nThe major part of exploration cost is from drilling, and this has direct impact on profitability of existing fields and cost of exploration (SKJERPEN et al., 2018). According to Lyons and Plisga (2004, p. 4.367), \u201cmost of well drilling cost is time dependent rather than product cost dependent\u201d. Therefore, one of the main goals of drilling optimization is to reduce the total time, and enhance drilling efficiency.\nThe Figure 1.4 illustrates a drilling optimization cycle, which consists of well planning, followed by the implementation of wellbore construction. Then, post-run evaluations are responsible to identify good and bad practices, providing valuable information for the next well to be drilled, completing this cycle. Even if all phases are carefully carried out, unforeseen events may occur, so that corrections in real-time will be required. The understanding observed trends can yield positive impacts (LYONS; PLISGA, 2004).\nSuch trends can be obtained through drilling data analysis, which should be an integral\npart of well planning and operations. According to Staveley and Thow (2010), this is not the case\ndespite the high costs of measuring and collecting drilling data. In order to provide important\ncontributions to this industry, many researchers are studying methods to use drilling data for\n24\noptimization purposes.\nThe presented thesis deals with development of real-time optimization methods of some controllable drilling variables, especially the weight on bit and rotating speed, based on data analysis, as explained in the following section.\n1.2.1\tDrilling Optimization Based on Predictive Models and Related Works\nTo formulate a optimization problem for the drilling activities, it is required to have accurate predictive models. Such models have the goal to assess how some important variables (e.g. drill bits, rotating speed, weight on bit) affect the drilling performance. Possible performance indicators are the rate of penetration and the specific energy, both called here as drilling-performance indicators. These predictive models has the goal to map how the decision space (containing the variables to be optimizes) influence on the objective space (e.g. rate of penetration).\nThe prediction of ROP as function of drilling variables paves the way to formulate the optimization problem as maximization of ROP, or minimization of total time or cost per feet drilled. The accuracy of ROP model is crucial for drilling optimization (SOARES; GRAY, 2018). However, understanding how the drilling variables really affect the ROP is an open question in drilling engineering (MITCHELL; MISKA, 2011). Despite many efforts (theoretical and experimental), modeling the ROP as a mathematical function (i.e. traditional models) of some variables is not so trivial, because this is highly non-linear problem. Soares, Daigle and Gray (2016) exposed limitations and deficiencies of traditional ROP modeling, based on analytical equations. Therefore, machine learning techniques (e.g. neural networks, support vector machine, random forests) appears to be a more reasonable approach to model the ROP (HEGDE et al., 2017).\n25\nAnother important performance indicator is the specific energy, first proposed by Teale (1965). The concept of specific energy measures the amount of energy employed to destroy a unit volume of rock. As consequence, the drilling efficiency can be assessed from the energy-efficiency point of view. Many researches highlighted the use of specific energy in drilling-optimization tasks (PESSIER; FEAR, 1992; AMADI; IYALLA, 2012; BEVILACQUA; CIARAPICA; MARCHETTI, 2013; MENG et al., 2014; CHEN et al., 2016).\nThe following works developed predictive models of drilling-performance indicators for optimization purposes (ARABJAMALOEI; SHADIZADEH, 2011; AWOTUNDE; MUTASIEM, 2014; BATAEE; IRAWAN; KAMYAB, 2014; HEGDE; GRAY, 2017; HEGDE; GRAY, 2018; HEGDE; DAIGLE; GRAY, 2018). A common approach of these works was to employ, as objective function, the maximization of ROP. Other objective functions tested were: minimization of drilling cost (BAHARI; SEYED, 2009), minimization of total time (AWOTUNDE; MUTASIEM, 2014), and minimization of torque and specific energy (HEGDE; GRAY, 2018). In general, the drilling variables to be optimized were weight on bit and rotating speed. Some of the mentioned works added also a third variable to be optimized, which were e.g. mud flow or mud weight.\nAll these mentioned works proposed a single-objective optimization problem. Only few works (GANDELMAN, 2012; GURIA; GOLI; PATHAK, 2014; PAYETTE et al., 2017) tried to optimize some controllable drilling-variables (e.g. weight on bit and rotating speed), considering simultaneous multiple-objectives. We consider the thesis from Gandelman (2012) as the only work that proposed a multi-objetive optimization based on predictive models trained with machine learning techniques. To be more specific, the author employed artificial neural networks to model the ROP, which was coupled with specific energy equation. In his study, the goal was to find a optimum combination of operation conditions (bit weight and rotating speed), which could achieve a ROP-desired value and, at the same time, spend as less as possible energy. The author mentioned the possibility of applying this approach in real-time optimization.\nIn the presented thesis, some procedures in obtaining predictive models for drillingperformance indicators are investigated, as well as how these models can used in optimization tasks. The works from Gandelman (2012), Hegde and Gray (2018) inspired the development of optimization approach adopted in the current. Hegde and Gray (2018) showed that the common approach of trying to maximize the ROP may decrease the drilling efficiency, because it may lead to increases in specific energy and torque. As a natural extension of Hegde\u2019s work is to adopted a multi-objective optimization, where both objectives can be set: maximization of ROP and minimization of specific energy, as done by Gandelman (2012). One difference between the current and from Gandelman is how the specific energy is calculated. In the current work, the specific energy is coupled not only with the predictive model of ROP, but also with torque, as proposed by Hegde and Gray (2018).\n26\n1.3\tOBJECTIVES\nThe present thesis aims to apply machine learning methods for real-time drilling optimization. For that, two objects of study can be formulated. The first object frames the research question of how predictive models of so-called performance indicators, especially rate of penetration and specific energy, can be obtained based on machine learning methods. To be more specific, the first object of study consists of:\n\u2022\treviewing the state-of-art of machine learning techniques applied to rate of penetration prediction;\n\u2022\tproposing a systematic procedure for data pre-treatment prior to training the predictive models;\n\u2022\tstudying the influence of most important drilling parameters;\n\u2022\tcomparing the coupled specific-energy models against a simpler version based on exclusively data-driven models, as commonly done for the rate of penetration.\nThe second object of study covers the investigation of different procedures of drilling optimization based on the predictive models. To be more specific, the second object of study consists of:\n\u2022\tcomparing different objective functions of a single-objective optimization problem, especially the maximization of ROP against the minimization of specific energy;\n\u2022\tinvestigating the feasibility of a multi-objective optimization framework, especially based on e-constraint method;\n1.4\tWORK STRUCTURE\nAfter the introduction chapter, the chapter 2 presents a briefly background about drilling engineering, machine learning methods for regression and multi-objective optimization. The review of state-of-art methods to model the ROP is presented in chapter 3. The chapter 4 presents the materials and methods employed in the current work. In chapter 5, the results are presented, follwed by the conclusion chapter 6. Appendixes and Annexes were added to support the development of the current work.\n27\n2\tTHEORETICAL BACKGROUND\nThis chapter aims to briefly present the basic concepts which are necessary for the development of this work. This chapter have three main parts. The first one deals with fundamentals of drilling engineering. The second part presents some machine learning methods for regression problems. The third part gives an overview of multi-objective optimization.\n2.1\tOVERVIEW OF DRILLING ENGINEERING\n2.1.1\tRotary Drilling\nThe standard oil well drilling method is rotary-drilling. The main components of rotarydrilling are shown in Figure 2.1.\nFigure 2.1 - The rotary drilling process\nDenick\nSwivel\nDrillpipe\nAnnulus\nDrill collars\nBell nipple Blowout preventer Emergency flowline\nConductor casing Earthen pit\nSource: Mitchell and Miska (2011)\nMitchell and Miska (2011) provided a gentle introduction to rotary-drilling, which is\nsummarized as following: a drill bit uses the downward force and rotation speed to break the rock\ninto small pieces (cuttings). The downforce (commonly known as weight on bit) is generated by\nthe weight of pipes (drill collars) above the drilling bit, and the rotation is provided normally by\na surface equipment that rotates the drillstring, transmitting rotation to the bit. A fluid (drilling\nfluid or commonly known as mud) is pumped into the hollow drillstring to the bottom of the\n28\nhole. Then, the fluid passes through orifices of drillbit, and returns to surface transporting the cuttings through the annular space. At surface, the drilling fluid is treated, separating the cuttings from the fluid. Finally, the treated fluid is reused.\n2.1.2\tDrilling Variables\nThe drilling variables can be classified as alterable or unalterable as shown in Figure 2.2. This classification is not strict, because there is an interdependence among them. From experience and research, six groups of variables can be used to mathematical optimization (LUMMUS, 1970). With recent advances in directional and horizontal wells, the wellbore trajectory is an important aspect to be considered in modern drilling operations. Therefore, this parameter should be included in such lists nowadays. In the following paragraphs, the most common types of drillbits are explained briefly, as well as some properties of drilling fluids.\nFigure 2.2 - Classification of drilling variables. The symbol / indicates that those variables are chosen for mathematical optimization.\nAlterable\nUnalterable\n\nMud\nType\nSolids Contents\nViscosity Fluid Loss Density\nHydraulics\nPump Pressure Jet Velocity Circulating Rate Annular Velocity\nBit type\nWeight on bit Rotary speed\nZ\n*\tWeather\n*\tLocation\n*\tRig Conditions\n*\tRig Flexibility\n*\tCorrosive borehole gases\n*\tBottom-hole temperature\n*\tRound-trip time\n*\tRock properties\n\u25a0 Characteristic hole problems\n*\tCrew Efficiency Formation to be drilled\nZ Depth\nSource: adapted from Lummus (1970)\nThe rotary-drilling method employs a drillbit to produce a general cylindrical hole, known as wellbore. The cutting elements (tooth or cutter) are responsible to break apart the rock. According to the cutting mechanism, the drill bits are classified into the following groups: the roller cone bits, the fixed cutter bits, and the hybrid bits (MA; CHEN; ZHAO, 2016).\nThe roller cone bits have normally three cones, but it is possible to see other arrangements\n(single, two or four cones). The cones roll as the bit rotates, yielding to a rock-failure mode of\nfracturing or crushing. Each cone has teeth, which are the cutting elements. The teeth can be\nmilled directly in the cone steel (Figure 2.3-a). To improve the durability of drill bits, teeth of\nsintered tungsten carbide can be employed. This type of roller cone bits are knows as TCI (see\nFigure 2.3-b) (MA; CHEN; ZHAO, 2016).\n29\nFigure 2.3 - Typical drill bits: a-b) roller cone bits; c-e) fixed cutter bits\nthread\nthread\n(a) Milled Toth Bit\n(c) PDC Bit\n(d) Impregnated Bit\n(e) Natural Diamond Bit\n(b) Tungsten Carbide Insert Bit\nbit leg\n.-tooth\n*\nSource: adapted from Ma, Chen and Zhao (2016)\nThe cutter mechanisms can be much simpler, when employing the fixed cutter elements. Depending on the manufacture, the fixed cutter bits can be classified into four classes (MA; CHEN; ZHAO, 2016):\n\u2022\tthe drag bits were the first type used in rotary-drilling. However, this type of bit can drill only soft formations, being not often employed nowadays in the oil industry;\n\u2022\tthe polycrystalline diamond cutter (PDC) bits are widely employed. The cutting elements consist of sintered tungsten carbide cylinder with one flat surface, which is coated with a synthetic diamond material. This type of drillbits are employed in pre-salt regions (NASCIMENTO, 2016);\n\u2022\timpregnated bit employs the thermal stable polycrystalline (TSP) diamond cutters.\n\u2022\tnatural diamond bit is very similiar to impregnated bits. The diamond bits employ natural industrial-grade diamond bit in the bit body matrix. It can withstand hard abrasive formations.\nThe third group of drill bits is a hybrid type, which combines both rolling cutters and fixed\ncutter elements. The goal of this type of bit is to reduce drilling time in complex applications\n(e.g. hard abrasive formations) (MA; CHEN; ZHAO, 2016), also used in pre-salt regions\n(NASCIMENTO, 2016).\n30\nThe main goals of drilling fluids are: to cool the drill bit, to maintain stable the wellbore (avoiding collapse), to clean the hole, to transport drill cuttings. Some variables are specific to drilling engineering field, which requires a brief explanation.\nThe mud weight (MW) is a synonym of the drilling fluid density, normally reported in Ibm/gal (also known as pound-per-gallon ppg), kg/m3 or g/cm3. The density controls the hydrostatic pressure (SCHLUMBERGER, 2018a).\nZamora and Roy (2000) developed a new concept of equivalent density for high pressure and high temperature (HP/HT) wells, where drilling fluids undergo changes in density. The authors have proposed the term equivalent static density (ESD) for static wells, and equivalent circulating density (ECD) for circulating wells. The ECD plays a important role in avoiding kicks and losses (SCHLUMBERGER, 2018b).\n2.1.3\tPerformance Indicators\nIn the current work, the so-called performance indicators are those metrics that can be employed as objective function in the optimization problem of the controllable drilling parameters optimization (such as bit weight, rotary speed and mud flow). A special attention is given to two performance indicators: rate of penetration and specific energy.\n2.1.3.1\tRate of Penetration\nThe rate of penetration (ROP) is an important drilling performance indicator. According to Mitchell and Miska (2011, p. 352), the drilling variables that affect most the ROP are: bit type, formation characteristics, drilling-fluid properties, bit operating conditions (bit weight and rotary speed), bit tooth wear, and bit hydraulics. In addition to these variables, Anemangely et al. (2018) added the personal efficiency and rig efficiency as important parameters that affect the ROP, as seen in Figure 2.4.\nThe manner in which the drilling variables affects the ROP is very complex, and not well understood (MITCHELL; MISKA, 2011). However, it is of interesting to model the ROP as function of the drilling variables, because it enables to optimize drilling process by finding the optimum controllable drilling variables. The Chapter 3 covers different methods to model the ROP as function of the most important drilling variables.\nFigure 2.4 - Drilling variables that affect the ROP.\n31\n32\nNumerous studies analyzed the effect of bit weight and rotary speed on penetration rate (DUPRIEST; KOEDERITZ, 2005; EREN; OZBAYOGLU, 2010; MITCHELL; MISKA, 2011; GANDELMAN, 2012; SOARES; DAIGLE; GRAY, 2016). The describing of the bit mechanics provided in this section is a summary from the book of Mitchell and Miska (2011).\nIn Figure 2.5-a, it is depicted a plot of penetration rate vs. bit weight obtained experimentally, when all other variables are held constant. Significant rate of penetration is obtained after exceeding the threshold formation stress, increasing linearly with weight-on-bit (WOB) for low-to-moderate values of bit weight (segment ab from Figure 2.5). A linear curve with stepper slope is observed at higher values of WOB (segment bc). This occurs due to a change of rock-mode failure from scraping or grinding to shearing, increasing the drilling efficiency. However, after the point C, slight improvements in ROP is obtained with increasing WOB (segment cd). It can be observed in some cases a decrease in ROP at even higher values of WOB (segment de). This behaviour is called bit foundering. Two facts can explain this poor response of ROP at higher WOB. One fact is a higher rate of cuttings generation, decreasing the efficiency of hole cleaning. Another reason is the lack of room for fluid bypass (MITCHELL; MISKA,\n2011).\nA typical plot of ROP against rotary speed with all drilling parameters held constant is illustrated in Figure 2.5-b. The ROP increases linearly with increasing rotary speed (segment ab). At higher values of rotary speed, issues of bottomhole cleaning occur (segment bc), reducing the drilling efficiency (MITCHELL; MISKA, 2011). For more details about the bit mechanisms, the readers can refer especially to the other works from Dupriest and Koederitz (2005), Gandelman (2012).\n33\n2.1.3.2\tSpecific Energy\nThe concept of specific energy measures the energy efficiency of drilling process. Teale (1965) originally defined the specific energy (known as MSE or SE)1 as the amount of energy required to destroy a unit of volume of rock for rotary drilling. The author derived the specific energy equation, SE, by dividing the amount of axial and torsional work by the volume of rock drilled. In Taele\u2019s formulation, the work is done by thrust (i.e. weight on bit WOB in [lbf ]) and torque, T in [in.lbf or ft.lbf ]. The SE is expressed by:\nWOB 120.n.N.T\nAb + Ab.ROP\n[in.lbf /in3]\n(2.1)\nwhere N denotes the rotation speed [rev/min], Ab is the bit area [in2], and ROP the penetration rate [in/hr or ft/hr], according to unit of torque T. The unit of specific energy is [in.lbf /in3],\ni.e. the same unit of pressure [psi]. In the International System of Units, the SE is commonly measured in [MJ/m3], or in terms of pressure [MPa].\nThe equation 2.1 requires torque on the bit. However, this parameters is not always available, because it requires measurement-while-drilling system (MITCHELL; MISKA, 2011). For this reason, Pessier and Fear (1992) introduced the sliding friction y to calculate the torque as function of weight on bit, as following:\nT fdb.WOB\\\nT=\n(2.2)\nwhere db is the drill bit diameter. Substituting the equation 2.1 by equation 2.2 yields:\nse = wob(\t+\n13.33^N\\\ndb.ROP )\n(2.3)\nIn order to use the model of Pessier and Fear (1992), the sliding friction y needs to be estimated. An alternative was proposed by Rabia (1982), who presented a specific energy model without torque as input. The simplified model is:\nSE d WRON\t[Mjm\t(24)\nwhen the unit of variables is: N [rev/min], WOB [kg], db [mm], and ROP [m/hr]. Rabia (1982) presented also this equation in Imperial Units:\nSE=*(1\u00b0^\t[lbf'i^\t(25)\nwhen N is given in [rev/min], WOB in [lbf], db in [in], and ROP in [ft/hr].\nMSE denotes mechanical specific energy, as well as mean squared error, which is a common statistic metric for assessing the predictive models. To avoid any misunderstanding, we prefer to name the concept of specific energy as SE. In additional, Teale called this concept as specific energy in his paper from 1965.\n1\n34\nThe values obtained from the previous formulations may be substantially higher than the material\u2019s strength. Dupriest and Koederitz (2005) mentioned the importance to adjust the SE to the same magnitude of material\u2019s strength. The authors adapted the original formulation from Taele in order to improve the usefulness of SE in field operations. Their model can be expressed\nby:\nSEad3\n\u2014 EFFm .SE \u2014 EFFm\n(WOB\nAb\n120n.N.T\\\nAb.ROP )\n(2.6)\n+\nwhere SEadj is the adjusted specific energy, the EFFm is the mechanical efficiency factor. Dupriest and Koederitz (2005) mentioned the value of EFFm can be from 0.3 to 0.4.\nAll the previous models consider that the work is done by axial force and torque applied to the drill bit. Therefore, they are also known as mechanical specific equations. The hydraulic power is not taken into account despite the importance of drilling fluid for process. Mohan, Adil and Samuel (2014) extended the original Taele\u2019s formulation by adding the hydraulic work done by the bit. The authors named this new concept as hydromechanical specific energy (HMSE):\nHMSE \u2014\nWOBe.ROP + 120n.N.T + n.^PbQ\nAb.ROP\n(2.7)\nwhere all parameters are the actually values on drill bit, i.e., WOBe is the effective weight on bit. N is the rotation speed, and T is torque on the bit. The term APb denotes the pressure drop across the bit, n is a dummy factor for energy reduction and Q is the flow rate.\nRecently, some new specific mechanical energy models were developed. Chen et al. (2016) proposed a new formulation for SE in slide and horizontal drilling, adapting the original formulation for positive displacement motor. Al-Sudani (2017) presented new approach based on control engineering to simulate the bit behavior and to predict the drilling efficiency by estimating the transferred and wasted mechanical energy.\n2.1.3.3\tDrilling Efficiency\nThe amount of energy to destroy a rock is correlated to material\u2019s strength. Teale\u2019s experiment has showed that the values of SE were roughly equal to compressive strength of rock. Two common properties are used to measure the compressive strength: unconfined compressive strength (UCS) and confined compressive strength (CCS). Both measure the maximum axial compressive stress that a sample of material can withstand. When the confining stress is zero, the condition of this compression test is unconfined, therefore the obtained value is UCS. When a confining stress is applied, the rock is said to be confined, therefore the respective compressive strength is CCS.\nKnowing this rock property is useful, because it provides a reference point for drilling\nefficiency. When drilling at maximum efficiency, it is expected all energy applied to bit is\ntransferred to destroy the rock. In this case, the specific energy is equal to confined compressive\nstrength. When drilling dysfunction occurs, part of energy is lost. Dupriest and Koederitz (2005)\n35\nshowed the monitoring SE in real-time boosted the drilling efficiency of several wells drilled, because drilling inefficiencies could be detected in real-time. Amadi and Iyalla (2012) achieved cost reduction in deepwater development by applying mechanical specific energy optimization techniques in real-time.\nA study on drilling parameters optimization from Chen et al. (2016) proposed that the minimum specific energy is equal to confined compressive strength (CCS):\nmin(SE) = CCS\n(2.8)\nIn this case, the drilling efficiency, n, is at maximum. In a general case, the drilling efficiency is given by:\nCCS\nn =\n(2.9)\nDupriest and Koederitz (2005) showed that, in real drilling operations, the n ranges from 0.3 to 0.4. For that reason, the authors proposed the mechanical efficiency factor EFFM (equation 2.6).\nIn the case of hydromechanical formulation (MOHAN; ADIL; SAMUEL, 2014), the drilling efficiency is expressed by:\n_ CCS n = HMSE\n(2.10)\nTo assess the rock strength properties (UCS or CCS), uni-axial or tri-axial compressive tests can be carried. The downside of these tests is the need to have rock samples, so that any attempt to monitor the rock strength while drilling is not possible. An alternative is to estimate the rock properties from p-wave velocity with empirical equations. Since P-wave velocity is closely related to physico-mechanical properties of rock and is non-destructive test, this measurement enables to estimate the rock properties in situ conditions (e.g. while drilling) (SARKAR; VISHAL; SINGH, 2012; SHARMA; SINGH, 2008). Empirical equations for rock strength from p-wave velocity was investigated also under different degrees of saturation (KARAKUL; ULUSAY, 2013).\nHamada et al. (2018) proposed a new method to determine the rock strength based only on drilling parameters such as drill string rotational torque, bit depth, and string rotational speed. The authors called this new concept as \u201cequivalent strength\u201d (EST).\n2.1.3.4\tSome indicators of drilling problems\nVibration is a challenge for drillers. Several problems are attributed to the drillstring\nvibration, such as lower penetration rate, drillstring components\u2019 failure, excessive bit and\nstabilizer wear, bit failure and so on. Depening on type of vibration, a specific term is employed\nto describe the phenomena. According to Ghasemloonia, Geoff Rideout and Butt (2015, p. 151),\n36\n\u201cbit bouncing, stick-slip and whirling are extreme examples of coupled vibration dominated by axial, torsional and lateral motions, respectively\u201d.\nGhasemloonia, Geoff Rideout and Butt (2015) identified several strategies for vibration isolation, which are:\n\u2022\tproper design of drillstring configuration (Bottom-Hole-Assembly length and stabilizer location) to stay far away from resonance state;\n\u2022\tpassive isolators;\n\u2022\tactive controllers;\n\u2022\treal-time drilling input parameters optimization based on \u201cMeasurement While Drilling\u201d tools.\nWith \u201cMeasurements-while-drilling\u201d (MWD) tools, it is possible monitor the controllable drilling variables in order to avoid or reduce vibration. Ghasemloonia, Geoff Rideout and Butt (2015) appointed this solution as one of the best way to mitigate the problem of vibration. In Figure 2.6, it is shown that certain combinations of bit weight and rotary speed can mitigate some drilling vibrations problems.\n2.1.3.5\tEconomics\nOne of the main goal of drilling optimization is to minimize the drilling costs. For that, the selection of a suitable bit is of major importance. According to Mitchell and Miska (2011), criteria for bit selection are:\n37\n\u2022\tcost-per-foot for a single bit run;\n\u2022\trun-cycle speed (RCS) which measures the effective ROP by including the effect of trip time and nonrotating time;\n\u2022\tbreak-even-analysis to determine if it is economically feasible replacing a current bit by a more expensive new bit;\n\u2022\tto estimate the termination of a bit run.\n2.1.4\tOptimization of Controllable Drilling Variables\nThe Figure 2.7 depicts a process control hierarchy, normally applied in industrial process, with several features (optimization, control, monitoring and data acquisition). In Level 5, planning and scheduling operate normally over long time periods. In Level 4, the Real-Time Optimization provides the optimal set points (called supervisory control). Changes in set-points for multivariable process control are made in Level 3b. One technique to implement it is the model predictive control. The regulatory control acts in Level 3a for loop control. The Level 2 covers safety environmental/equipment protection, such as alarm and shutdown systems. In the Level 1, data acquisition and on-line analysis occur (SEBORG et al., 2011).\nGandelman (2012) used the definition from Seborg et al. (2011) for real-time optimization to identify what would be real-time optimization for drilling activities. Here we extended Gandelman\u2019s comparison for other common optimization approaches employed in oil and gas industry, which are: historical drilling data; drilling tests; and (near) real-time approaches; closed-loop control.\nBy analogy with the fivel levels of process control from Seborg et al. (2011), the Level 5 covers the historical drilling data analysis. This approach enables to capture trends between the variables and drilling performance indicators. This knowledge obtained from previous wellbore construction can be employed in planning and scheduling phase for new nearby wells to be drilled, or to comparable formations. This optimization process is commonly employed by drillers (LYONS; PLISGA, 2004). The cumulative experience gained by rig crew and drilling companies in a specific regions yields a better understanding of this region. As consequence, best practices are employed, for example to avoid problems which may result in large non-productive time. The report from Vesconte, Tinkhof and Hardman (2014) is an example of such optimization procedure.\nIn industrial process, the optimum set point can vary very often within time range from\nhours to days, requiring real-time optimization (SEBORG et al., 2011). Gandelman (2012)\nmentioned that the same occurs in drilling activities of oil and gas wells. In this case, real-time\noptimization aims to determine the optimum drilling variables while drilling. This approach\nenables to adapt in (near) real-time to the changes of down-hole conditions. According to\nGandelman (2012), the following issues require actions to set the drilling process again to its\n38\nFigure 2.7 - Five levels of process control and optimization (time scales for each level)\nSource: Seborg et al. (2011).\noptimum point: lithology changes, hole cleaning problems, weather changes (especially for offshore operations), operating problems with pumps and topdrive.\nOne way to implement real-time drilling optimization is through pre-operational tests. In this case, the ROP response is monitored when varying mainly the bit weight and rotary drilling, while other parameters are held constant. The so-called drilloff test enables to carry out such analysis in a fast way, by applying a large weight to the bit and then decreasing the bit weight, while the rotary speed is held constant (DUPRIEST; KOEDERITZ, 2005). The value of WOB which maximizes the ROP is selected as optimum value (MITCHELL; MISKA, 2011). A dynamic approach for pre-operation tests was later proposed (NASCIMENTO et al., 2016; NASCIMENTO et al., 2015a), and further developed (DUTRA, 2016). Some examples found in the literature of drilling tests are shown in Figure 2.8.\nIn order to implement control techniques in closed-loop, sophisticates models for drilling\nperformance indicators are required. One key aspect for the control technique is a reliable and\naccurate ROP modeling (SOARES; GRAY, 2018). In Chapter 3, it is shown the machine learning\ntechniques have the ability to do so.\n39\nFigure 2.8 - a) Typical drill-rate test data showing non-linear response below the minimum depth of cut and above the founder point; b) Bit weight (WOB) test carried during a run\nSource: a) Dupriest and Koederitz (2005); b) Bevilacqua, Ciarapica and Marchetti (2013)\nSome studies reported control techniques applied for the following drilling activities: for the problem of vibration and shock (DONG; CHEN, 2016), and managed pressure drilling (GODHAVN et al., 2011). To further develop the automation in drilling, the Society of Petroleum Engineers (SPE) is organizing an international student competition as part of Drilling Systems Automation Technical Section (DSATS), called Drillbotics 2. Student teams must design and build a small drill rig, which has to drill autonomously a rock sample by applying control engineering techniques. Bilgesu et al. (2017) presented the winner solution from the 2016 competition, where real-time interactive drill-off tests were combined with artificial intelligence.\nSeveral drilling performance indicators can be employed as objective functions. The Figure 2.9 illustrates eight possible objective functions for drilling optimization. These functions can be employed solely, or in combination. These functions were obtained mainly from the following works (HEGDE; GRAY, 2018; HEGDE; GRAY, 2017; GURIA; GOLI; PATHAK, 2014; GANDELMAN, 2012; MITCHELL; MISKA, 2011; MITCHELL; MISKA, 2007; DUPRIEST; KOEDERITZ, 2005; LYONS; PLISGA, 2004; LUMMUS, 1970).\n2\nHomepage on:&lt;https://drillbotics.com/>\n40\nFigure 2.9 - Some possible objective functions for drilling optimization\nSource: own authorship.\n2.2\tREGRESSION MODELS BASED ON MACHINE LEARNING METHODS\nOne field of Artificial Intelligence that is widely known as machine learning consists basically of algorithms that are able to learn from previous examples, enabling prediction for novel inputs. The initial phase of artificial intelligence is very close to development of artificial neural networks (PONTES et al., 2010). For example, McCulloch and Pitts (1943) described mathematically the neuron. Later, Rosenblatt (1958) developed a theory, called perceptron for a hypothetical nervous system, or machine.\nHowever, it was only in the early 1990s that the field began to have widespread practical impact. Over the last decade in particular, there has been a rapid increase in the number of successful applications, ranging from web search to autonomous vehicles, and from medical imaging to speech recognition. This has been driven by the increased availability of inexpensive computers (BISHOP, 2013, p. 1-2).\nIn order to have an idea about the amount of machine learning algorithms, Fernandez-Delgado et al. (2014) compared a total of 179 classifiers from 17 different families. The authors applied some well-known methods from artificial intelligence (e.g. neural networks, support vector machines, decision trees, boosting, bagging and random forests), as well as from statistics field (e.g. generalized linear models, partial least squares, logistic and multinominal regression).\nAs seen, the amount of machine learning techniques is vast. This can hinder the application of these methods by those who have expertise in other fields (e.g. physicists, engineers or biological scientists). Many softwares (Matlab, Statistica, Weka, Mathematica) and open sources packages in programming languages (e.g. R or Python) have already implemented machine learning algorithms, so that they are easily accessible. However, the lack of background knowledge around the learning algorithms can lead to unsuccessful results. A work developed in this School of Engineering by Pontes et al. (2010) analyzed several publications that applied\n41\nneural networks to model machining processes surface roughness. The authors showed that those studies were carried out mainly by engineers, and some of them did not follow the good practices recommended by acknowledged scholars in neurocomputing and statistics. It is not hard to imagine that the same may happen in other areas. Therefore it is important to understand the basics of the machine learning methods.\nThe basics of regression models is presented based on the works from Hastie, Tibshirani and Friedman (2009), Friedman (2006). The machine learning paradigm is presented from the perspective of ensemble models; the review articles from Sagi and Rokach (2018), Ren, Zhang and Suganthan (2016) are good source of information about ensemble models.\n2.2.1\tRegression Analysis\nLet y denote \u201coutput\u201d or \u201cresponse\u201d variable, and x the \u201cinput\u201d or \u201cpredictor\u201d variables. The goal of a predictive or machine learning problem is to predict (estimate) y given an input vector x. If the output is a continuous variable, i.e. y E R, the prediction task is a regression problem. If y is a set of classes (labels or categorical values), then estimating the output is a classification problem. In the current work, we deal with regression problem when trying to estimate the rate of penetration, specific energy or any other continuous drilling variable.\nThe goal of regression is to map a point x in the space of all input variables (called also as feature space) to a point y in the space of response values (FRIEDMAN, 2006). The predicted value y can be expressed by a general function\ny = f (x, O),\ty e R\t(2.11)\nwhere f (\u2022) is the regression function and 0 is the regression function\u2019s parameter set (REN; ZHANG; SUGANTHAN, 2016).\nThe main goal is to produce a prediction model f (\u2022) with high accuracy. For that, many methods can be applied to obtain a good predicting function, such as neural networks, decision trees, kernels methods, linear/logistic regression and so on (FRIEDMAN, 2006). In machine learning, the use of previous examples from a specific problem enables to teach a predictive model how to map the input space X to output space Y, i.e. f : X Y .In the learning phase, the parameters set of regression function 0 is obtained. After learning, the model can predict the output for new observations. The data base employed in learning phase is called as \u201ctraining\u201d data set\nT>\ntrain\n{yi, x^ N\n(2.12)\nand has N observations where the output y has been jointly measured with the inputs variables\nx (FRIEDMAN, 2006).\nIn order to know whether the model f (\u2022) is good or not, evaluation metrics are employed\nto assess the predictive model accuracy or its lack of accuracy. According to Friedman (2006,\n42\np. 176), \u201cthe \u2018loss\u2019 criterion reflects the cost of mistakes: L(y, y) is the loss or cost of predicting a value y for the response when its true value is the output\u201d. The goal of learning is to define the set of parameters of the predicting function 0 by minimizing the loss functions (HASTIE; TIBSHIRANI; FRIEDMAN, 2009). For regression-type problems, the absolute error L(y, y) = |y \u2014 y| is a common cost function, as well as the squared-error L(y, y) = (y \u2014 y)2, which yields to much simpler algorithms of minimization (FRIEDMAN, 2006).\n2.2.2\tEnsemble Learning\nEnsemble is a general term for methods that combine multiple predictors (i.e. multiple learners). The idea behind of ensemble methods is that the error of a single model can be compensated by other models. As consequence, the overall prediction performance of the ensemble is better than the estimate of a single model. That is why ensemble models are considered state-of-art techniques for machine learning challenges (SAGI; ROKACH, 2018). For example, Chen and Guestrin (2016) reported that their package (XGBoost) was employed in many winning solutions of machine learning challenges hosted at the homepage Kaggle in 2015.\nThe theory of ensemble methods is bias-variance-covariance decomposition. A key element of ensembles is the diversity in several forms: data diversity, parameter diversity and structural diversity (REN; ZHANG; SUGANTHAN, 2016).\nUsing the notation of Sagi and Rokach (2018), an ensemble learning model uses an aggregation function G(-) that aggregates K inducers (or base learners), {fi, f2,..., fk}, towards predicting a single output\ny = G(fi,f2,...,fk)\t(2.13)\nBuilding an ensemble model consists of selecting a training method for the base learners and choosing an aggregation process (SAGI; ROKACH, 2018).\nThe ensemble methods can be classified by how the base learners are obtained: in a sequential approach or in parallel. Sequential ensemble methods generate sequentially the base learners (e.g. gradient boosting). In this case, the learning process of k-th base learner fk depends on the performance of previous base learner fk-1. In parallel ensemble methods (e.g. bagging), the base learners are trained independently from each other. Therefore, this approach yields parallel ensemble models (REN; ZHANG; SUGANTHAN, 2016).\nWhen an ensemble has all learners of the same type, this ensemble is said to be homogeneous. When different learning techniques (e.g. neural networks and decision trees) are employed to obtain the base learners, it yields to heterogeneous ensembles (REN; ZHANG; SUGANTHAN, 2016; MENDES-MOREIRA et al., 2012).\nThe following section presents a classical method to obtain the base learners for an ensemble models, namely the classification and regression tree. Then, we present two classical\n43\napproaches (bagging and boosting) to aggregate the base learners in an ensemble are presented, showing briefly some recent advances in ensemble studies.\n2.2.3\tBase Learners\nThe decision tree \u201care conceptually simple yet powerful\u201d (HASTIE; TIBSHIRANI; FRIEDMAN, 2009, p. 305). Trees are at the heart of some classical ensemble methods, such as random forest and gradient boosting machines. Therefore, an overview about tree-based models is given, because they are the base learners of aforementioned ensemble methods.\nThe regression models based on decision trees have mainly of two steps in the learning phase (HASTIE; TIBSHIRANI; FRIEDMAN, 2009): partition of input space into a set of rectangles; in the second step, a suitable model is fitted in each region (e.g. a constant value). Extensive details about the tree-based models are given by Hastie, Tibshirani and Friedman (2009), whose work serves the basis to present a classical method to grow a tree, known as Classification And Regression Trees (CART). The Figure 2.10 illustrates the process of recursive binary partition adopted by CART. A fake data was used to illustration the idea of decision tree based on CART. A general partition can have some complex regions to be described. The feature space partition can be simplified by the recursive binary splitting. The variable and split-point are determined when the best fit from all possible combinations is achieved. The corresponding prediction surface and decision tree are presented. Each region has a constant value. The terminal nodes in the tree represents the leafs.\nNow, let us focus on how a tree can be mathematically formulated, following the comprehensive introduction and formulation given by Hastie, Tibshirani and Friedman (2009). The authors mentioned that the training algorithm has to automatically determine how the tree should grow by determining the splitting variables and split values, and also tree\u2019s topology (shape). Let Xi denote an ith vector input, such as Xi = (xi1} xi2,..., xip) with p inputs. If the feature space is partitioned into M regions R1,R2,..., RM, and the response is modeled as a constant cm in each region. According to the authors, this tree can expressed by:\nM\nf (x) =\tcmI(x e Rm)\t(2.14)\nm=1\nhere I(\u2022) is the indicator function, having the value 1 if the argument (x e R) is true or 0 otherwise. The best Cm is the average of yi in the region Rm, if the criterion of minimization of the sum of squares \u00a3 (yi - f (x^)2 is adopted (HASTIE; TIBSHIRANI; FRIEDMAN, 2009).\nAs finding the best binary partition by minimizing the sum of squares is generally computationally unfeasible, a greedy algorithm is proceeded (HASTIE; TIBSHIRANI; FRIEDMAN, 2009). For that, the binary partition occurs by obtaining a pair of half-planes as follows (HASTIE;\n44\nFigure 2.10 - Partitions and CART\nSome resulting regions can be complicated to be described\nSource: adapted from Hastie, Tibshirani and Friedman (2009).\nTIBSHIRANI; FRIEDMAN, 2009):\nRi(j,s) = {X\\X3 &lt;s}\tand R2(j,s) = {X\\X3\t(2.15)\nwhere j denotes a splitting variable j and s a split point. The authors explained that the goal is to determine a splitting variable j and split point s that solve\nE\nmin\nj,s\nmin\nC1\n(yi - Ca)2\n(2.16)\nFor any j and s, the inner minimization is solved by (HASTIE; TIBSHIRANI; FRIED-\n45\nMAN, 2009):\nci = ave(yi|xi e Ri(j, s)) and C2 = ave(y|x\u00bb G R2(j, s))\t(2.17)\nThe determination of the best pair (j, s) is feasible by scanning through all of the inputs, because the determination of the split point s can be done quickly for each splitting variable. The splitting process can be repeated on all resulting regions (HASTIE; TIBSHIRANI; FRIEDMAN, 2009).\nHastie, Tibshirani and Friedman (2009) discussed how large a tree should be grown. If the resulting tree is too large, it might overfit the training data, so that the obtained tree may not predict accurately new inputs. However, if the resulting tree is too small, important structures may not be captured. One approach to tune the tree size is to test iteratively several tree sizes, and then check which one best fits the data. Another approach is to grow a large tree and then prune it. Hastie, Tibshirani and Friedman (2009) detailed a method of pruning based on cost-complexity.\nOther methods of training tree-based models are detailed in a review from Kotsiantis (2013). Although it is not the intention of the current work to provide deep details about tree-models, it is interesting to mention some features of these models, reported by Breiman (1996), Hastie, Tibshirani and Friedman (2009).\n\u2022\tthe instability of trees is one major concern resulted from their high variance. This high variance occurs due to hierarchical nature of trees\u2019 growths. Even small changes in the data may result in a very different tree (HASTIE; TIBSHIRANI; FRIEDMAN, 2009). However, this same instability improves the accuracy of ensembles models obtained by a method called \u201cbagging\u201d, as reported by Breiman (1996);\n\u2022\ttree-based models can handle missing values. One approach is to create a new category for \u201cmissing\u201d. Another approach is more general. It is based on the construction of surrogate variables, by trying to evaluate correlations between missing predictor and other observed predictors (HASTIE; TIBSHIRANI; FRIEDMAN, 2009);\n2.2.4\tParallel Learning with Bagging and Random Forests\nBagging is acronym for \u201cboosting aggregating\u201d originally presented by Breiman (1996). The idea behind of bagging is to generate multiple predictors based on different learning sets obtained by bootstraps replicates. The boostrapping forms replicate data-sets drawn at random with replacement from the original data set Dtrain. This means, each {yi, Xi} may appear repeated times or not at all in a particular learning set Dt\u2122in obtained by bootstrapping from the original Dtrain. After training the predictors, the aggregation averages the response over all predictors when predicting a numerical.\nBreiman (1996) stated that \u201cfor unstable procedures bagging works well\u201d, improving the prediction accuracy. This is because a small change in the training data set yields to a\n46\nsignificant change in the prediction function f (\u2022). Examples of unstable procedures are trees, neural networks, and their variance decrease with bagging strategy (SAGI; ROKACH, 2018). However, Breiman (1996) mentioned that bagging decreases the accuracy when the base learners are stable procedures (e.g. k-nearst neighbor methods).\nThe Figure 2.11 illustrated two conventional ensemble methods. The solid blue lines show the flow of bagging method, and the dashed red lines show the flow of boosting. In the illustration, X is the original dataset, X(i), i G {1, 2,..., M} are the generated data set, f(i) are the base predictors and fen is the aggregation function.\nBreiman (2001a) exploited even more the randomness in developing the random forests. The author combined the bagging procedure with random selection of splitting variable in the growth process of the tree. This method is knows as random forests, and is \u201cprobably the most popular ensemble method developed\u201d (SAGI; ROKACH, 2018, p. 9). Random forests are obtained by following the three main steps (SAGI; ROKACH, 2018; BREIMAN, 2001a):\n\u2022\teach new training set is drawn randomly from the original training set with replacement (boostrap samples);\n\u2022\ta tree is grown on the new training set using random feature selection, and is not pruned.\nThe CART methodology without pruning can be employed or any other training algorithm;\n\u2022\tin regression problems, the random forest predictor is formed by taking average over all trees.\nThe bagging process enables to estimate the generalization capability of an ensemble without a testing dataset. About one-third of the observations is left out in each bootstrap training set (BREIMAN, 2001a). Estimating the generalization error of an ensemble based on out-of-bag observations provides a good estimation of the model accuracy. This approach provides an alternative to cross-validation process in assessing the model accuracy. Wolpert and Macready (1999) developed methods to estimate the generalization error for bagging predictors.\n2.2.5\tSequential Learning with Boosting\nBoosting methods can convert the prediction of many \u201cweak learners\u201d (slightly better than random guessing) into strong learners (SAGI; ROKACH, 2018; HASTIE; TIBSHIRANI; FRIEDMAN, 2009). The process of boosting is more complex than bagging. One classical method is the AdaBoost algorithm (FREUND; SCHAPIRE, 1997), which stands for Adaptive Boosting, and is a well-known method for classification problems. The idea behind of AdaBoost is to fit a sequence of learners to weighted version of the training data. In the fitting process of kth weak learner f(k), more weight is given to observations miss-classified by the previous weak learner f(k-1). In this case, the kth weak learner focus on the deficits from the previous learner.\nFriedman (2001) presented Gradient Boosting Machines as an optimization problem for the boosting method. In these machines, the new models are consecutively fitted, so that the\n47\nFigure 2.11 - Framework of conventional ensemble methods. The solid blue lines show the parallel flow of bagging, random subspace and Random Forest. The dashed red lines in generation and base prediction parts denote boosting ensemble framework.\nSource: adapted from Ren, Zhang and Suganthan (2016).\nresponse accuracy of the ensemble improves. \u201cThe principle idea behind this algorithm is to construct the new base-learners to be maximally correlated with the negative gradient of the loss function, associated with the whole ensemble\u201d (NATEKIN; KNOLL, 2013).\nChen and Guestrin (2016) presented their package for machine learning problems called XGBoost, which is a scalable tree boosting system. One of the most important factors behind the success of this method is its scalability to problems with billions of examples. This was achieved due modifications in tree growing process and the introduction of a novel sparsity-aware algorithm for parallel tree learning.\n2.2.6\tOther Ensemble Methods\nAlthough it is not the main objective of this current work to develop new machine learning algorithms, it is worth of mentioning some recent advances in ensemble methods. Besides the conventional ensemble methods (bagging and boosting), there are other ensemble techniques, as reviewed by Ren, Zhang and Suganthan (2016):\n\u2022\tThe decomposition based ensemble methods - applied to time series forecasting;\n\u2022\tThe negative correlation learning based ensemble methods - ability to introduce strong diversity among base learners without having to change the dataset for the base learners;\n\u2022\tThe multi-objective optimization based ensemble methods - use of state-of-art techniques of multi-objective optimization in the learning phase of an ensemble. For example, it can\n48\nbe used to tune some parameters related to base learners;\n\u2022\tThe fuzzy ensemble methods - they combine the high accuracy of ensemble methods with the ability of fuzzy logic and fuzzy sets for imperfect data management;\n\u2022\tThe multiple kernel learning based ensemble methods - it brings together different kernels (e.g. support vector machines) into an strong predictor;\n\u2022\tThe deep learning based ensemble methods can improve the accuracy. Deep structures have multiple layers of non-linear functions, and can learn high-level abstraction for challenging tasks (e.g. vision recognition).\n2.2.7\tHyperparameter Optimization\nMost machine learning algorithms have parameters to be tuned in order to provide a good generalization capability. \u201cUnfortunately, this tuning is often a \u2018black art\u2019 that requires expert experience, unwritten rules of thumb, or sometimes brute-force search\u201d (SNOEK; LAROCHELLE; ADAMS, 2012). For example, when training a random forest, some hyperparameters to be tuned are: the amount of trees, the amount of variables to be selected at random for each decision split, the deep of tree base learners, the method to grow the tree base learners (BREIMAN, 2001a; HASTIE; TIBSHIRANI; FRIEDMAN, 2009). For gradient boosting trees, the learning rate is of major importance (FRIEDMAN, 2001).\nAn common approach to optimize the hyperparameters is to perform grid search. However, this approach suffers from spending too much effort in exploring unimportant dimensions. By grid searching, the global optima may not be achieved. To overcome these drawbacks from grid search, Bergstra and Bengio (2012) investigated the random search to optimize the hyperparameters of machine learning methods. The authors concluded that randomly chose trials are more efficient for hyperparameter optimization, especially in multi-dimension searching space.\nSnoek, Larochelle and Adams (2012) presented an automatic way to hyperparameters optimization problem with Bayesian Optimization. This method considers that an algorithm\u2019s generalization performance is a sample from a Gaussian Process, enabling to efficient use the information from previous experiments in order to determine the next try. The authors showed that this procedure could even outperform expert-level performance in optimizing the machine learning algorithms.\nOther methods for global optimization can be employed to determine the optimum hyper-\nparameters. Biology inspired algorithms, such as genetic algorithm and particle swarm, exploit\nthe information from previous results in order to determine the next possible trials. Open sources\npackages enables to apply these techniques. For example, the \u201cOptunity\u201d (CLAESEN et al.,\n2014) implements several optimization methods, including grid search, random search, particle\nswarm optimization and several others. The package \u201cGA\u201d implements a wide range of genetic\n49\nalgorithm methods in programming language R (SCRUCCA, 2013). Another example is the package \u201cDEAP\u201d (Distributed Evolutionary Algorithms in Python) (FORTIN et al., 2012). We just mentioned three packages, but it is possible to find many other packages and libraries.\n2.2.8\tFeature Selection\nFeature selection is a process of selecting an subset of features (input variables) to feed a machine learning algorithm. By selecting a small subset of relevant features, the following benefits can be achieved: faster learning process, simpler model and better accuracy (XUE et al.,\n2016). However, the main drawback is that the search space can be very huge.\nInstead of \u201cbrute force\u201d (extensive search), other approaches can be employed to overcome the challenge of finding the best subset of features. Guyon and Elisseeff (2003) stated that greedy search strategies (forward selection and backward elimination) can be computationally advantageous and robust against overfitting. The forward selection incorporates progressively the variables that improve the accuracy of model. In backward elimination, the model starts with all inputs, and then eliminates progressively the least promising inputs.\nVery similar to hyperparamter optimization, it is possible to employ evolutionary computation approaches (e.g. genetic algorithm or particle swarm optimization) to obtain an optimum subset of features (XUE et al., 2016). These approaches have the ability to reach the global optima, or to obtain a result that is near to the optimum point.\n2.3\tINTRODUCTION TO MULTI-OBJECTIVE OPTIMIZATION\nIf it is desired to determine the optimum values of the controllable drilling parameters (e.g. weight on bit and rotary speed), then several combinations of these parameters needs to be evaluated, assessing the respective impact on drilling performance indicators (i.e. objective functions).\nThe common approach is to determine the optimum combination of e.g. WOB and rotary speed that maximizes the ROP. In this case, maximization of ROP is the only objective function, leading to a single-objective optimization problem. If multiple drilling performance indicators are taken into account, e.g. maximizing ROP and maximizing bit-life, a multi-objective optimization needs to be formulated. This is because more than one objective is considered, and they may be contradictory to each other.\nHere, we present the general frameworks of the single-objective optimization problem and the multi-objective optimization problem.\n2.3.1\tThe Single-Objective Optimization Problem\nDepending on the problem, we seek to either maximize or minimize an objective function f (x). Cui et al. (2017) showed that the general problem of single-objective optimization can be\n50\ndefined as a minimization problem, because with the transform\nmax f (x) O min ( \u2014 f (x))\t(2.18)\nit is possible to transform a maximization problem into a minimization problem and vice verse.\nAccording to Chiandussi et al. (2012), a general single-objective optimization can be defined as the minimization objective function f (x), subject to inequality constraints gi(x) &lt;0, i = {1, 2,... ,p} and equality constraints hj (x) = 0, j = {1, 2,..., q}.\nLet us suppose that we wish to determine the optimum solution x* that minimizes a given objective function f. This function may have several local minima, so that the employed optimization algorithm may achieve a local minimum point of f instead of converging to the global optima. The Global Optimization methods try to find the global optimum solution, avoiding the problem of being trapped in local minima (CHIANDUSSI et al., 2012).\n2.3.2\tThe Multi-Objective Optimization Problem\nA multi-objective problem aims to optimize simultaneously multiple objective functions, and can be formulated by the equation (ZHOU et al., 2011):\nminimize F(x) = [fi(x),f2(x),...,fm(x)]T\n(2.19) s.t. x G Q\nwhere the decision variable x belongs to the decision space Q. In the case of m-objective functions, the objective space belongs to a m\u2014dimensional vector space Rm.\nThe objectives in equation 2.19 are often contradictory to each other, i.e. an improvement of one objective may lead to deterioration of another. As consequence, there is no single optimum solution able to optimize all objectives simultaneously. In multi-objective problems, a set of optimal solutions are obtained instead of a single one solution. This set is called Pareto optimal solutions (ZHOU et al., 2011).\nSeveral works explain the concept of Pareto optimality (ANTONIO; COELLO, 2017; CUI et al., 2017; CHIANDUSSI et al., 2012; ZHOU et al., 2011). Here, we present the definition of Pareto optimal solutions based on Zhou et al. (2011); extensive details about the definitions regarding multi-objective optimization can be found in Chiandussi et al. (2012).\nDefinition 1 (Zhou et al. (2011)) A vector u = (u1, u2,..., um)T is said to dominate another vector v = (v1,v2,..., vm)T, denoted as u\tv, if 'di G {1,2,..., m},ui &lt;vi and u = v.\nDefinition 2 (Zhou et al. (2011)) A feasible solution x* G Q of the problem 2.19 is called\nPareto Optimal Solution, if $ y G Q such that F (y) F (x*). The set of all the Pareto Optimal\nSolutions is called Pareto Set (PS), denoted as PS = {x G Q| $ y G Q, F(y) F(x)}. The\nimage of the PS in the objective space is called the Pareto Front (PF), denoted as PF =\n{F(x)| x G PS}.\n51\nFigure 2.12 - Input space and objective space for the case of two objective functions\nA general multi-objective optimization problem can be subject to inequalities and equalities (ANTONIO; COELLO, 2017; CUI et al., 2017; ZHOU et al., 2011). In this case, the search space Q can be formulated as follows (ZHOU et al., 2011):\ngi(x) &lt;o,\ti = {1,2,...,p}\nQ \\ hj (x) = 0, j = {1, 2,...,q}\n(2.20)\nxmr &lt;xi &lt;x\ti = {1,2,..., n}\nii\nwhere Q is a n\u2014dimensional search space for the decision variable x, determined by the upper bound xmax = [xmax, xmax,..., xmax]T and the lower bound xmin = [x\u2122ir, x\u2122ir,..., xrmin]T, p inequalities gi(x) &lt;0, i = {1, 2,... ,p}, and q equalities hj(x) = 0, j = {1, 2,..., q}. These constraints lead to two regions: a feasiable region and infeasible region. For the special case p = q = 0, the multi-objective optimization problem is said to be unconstrained (CUI et al.,\n2017).\nThe Figure 2.12 illustrates the input space and objective space for the case of two objective functions. We can observe that the feasible solution A is a good solution for a objective function f1, but the solutions B and F are better than A with respect to the objective f2. The solutions A and B dominate all other feasible solutions (C, D and F). However, the solution A does not dominate B and vice verse. In this example, the Pareto Set is formed by the non-dominated solutions A and B (CUI et al., 2017).\n2.3.3\tMulti-Objective Optimization Techniques\nThe aim of multi-objective problem is to find good compromise solutions (or trade-offs). The solution of a multi-objective optimization problem consists basically of two main steps\n52\n(CHIANDUSSI et al., 2012): one step is to generate the Pareto Set; another step is how the decision maker selects one or more optimum solutions from the Pareto Set. The search process and decision making can be combined in several ways. The works (CHIANDUSSI et al., 2012; MARLER; ARORA, 2004; HWANG; MASUD, 1979; COHON; MARKS, 1975) classified the multi-objective decision making into four groups according to the stage at which the information is needed for decision maker:\n\u2022\tNo Articulation of Preference Information;\n\u2022\tA Priori Articulation of Preference Information - the decision maker takes decision prior searching, e.g. by pre-ordering objectives;\n\u2022\tA Posteriori Articulation of Preference Information - first a search is carried out without any prior preference of the decision maker;\n\u2022\tProgressive Articulation of Preference Information - interactive methods which integrate search and decision making.\nIn the following section, we present some decision making techniques that aggregate multiple objectives into a single objective function. By having a single objective function, it is possible to apply standard optimization engines. The main advantage of this approach is its simplicity (MARLER; ARORA, 2004). This approach is employed in the current work.\n2.3.4\tDecision Making Techniques\nTo access several methods for decision making with multiple objective functions, the readers can refer to Marler and Arora (2004). In this current work, we present three decision making techniques:\n\u2022\tthe Global Criteria Method (no articulation of preference), what can be extended for Weighted Global Criteria Methods (a priori articulation of preference);\n\u2022\tWeighted Sum Method (a prior articulation of preference articulation);\n\u2022\tThe e-constraint method (a posteriori articulation of preference).\n2.3.4.1\tGlobal Criteria Method\nThe Global Criteria Method seeks to minimize a global criterion which measures how close a solution is to the ideal vector F\u00b0 (CHIANDUSSI et al., 2012). The ideal vector, which is also known as utopia point (MARLER; ARORA, 2004), can be defined as follows.\nDefinition 3 (Chiandussi et al. (2012)) The optimum value for the i-th objective funtion is denoted as f0. The ideal vector, denoted as F0 = [f0, f\u00b0..., /m]T, is the ideal solution where all m objective functions achieve separately their optimum values.\n53\nChiandussi et al. (2012) formulated the function of global criterion as follows:\nf (x) = E (f)p\n(2.21)\nwhere m is the amount of objective functions. Common values for the exponent are p = 1 or p = 2, but this parameter can assume any other value. The value of p has a great impact on optimum solutions (CHIANDUSSI et al., 2012).\nAnother global criteria method is based on Lp-metrics, which measure the relative distance to the ideal vector (CHIANDUSSI et al., 2012):\nW) =\nfi - fi(x) ff\npl1 /p\n\u2022>\n(2.22)\nE\n1 \" p\nThe previous equations 2.21 2.22 are mathematical functions with no articulation of preference information (MARLER; ARORA, 2004), but they can be written as Weighted Global Criteria. That is, the decision maker can set different weights for each objective function. In this case, the so-called Weighted Global Criteria is a method with a priori articulation of preference information. For more details see Marler and Arora (2004).\nThe main advantages of the global criteria methods are their simplicity and effectiveness. The downsides of them are computational effort to define the desired goal, and the utopia point must be in the feasible region (CHIANDUSSI et al., 2012).\n2.3.4.2\tWeighted Sum Method\nAnother way to transform the vector F into a scalar objective function is to perform a weighted sum of the objective functions (CUI et al., 2017; MARLER; ARORA, 2004). The scalar objective function is expressed as following (CHIANDUSSI et al., 2012):\nm\nmin\taifi(x),\ts.t. x G Q\t(2.23)\ni= 1\nwhere ai > 0 for all i. By varying these weights, ai, it is possible to obtain the Pareto Set (CHIANDUSSI et al., 2012). This was demonstrated by Zadeh (1963).\nThe objective function 2.23 is a linear combination of the objectives functions. Therefore, it is possible to find some authors (CHIANDUSSI et al., 2012) calling this method as Linear Combination of Weights.\nThe simplicity inherent in solving a scalar objective function is the main advantage\nof linear combination weights. However, the magnitude of weights plays a key role in this\nmethod. Therefore, the decision maker must carefully determine them. Another drawback of\nthis approach is the inability of equation 2.23 to generate optimum solutions in a concave Pareto\nFront (CHIANDUSSI et al., 2012).\n54\n2.3.4.3\tThe e-constraint method\nHaimes, Lasdon and Wismer (1971) formulated the optimization problem of two objective functions as a constraint optimization problem, calling this method as ^-constraint formulation. In addition to sum approach, this technique \u201cis probably the best known technique to solve multi-criteria optimization problems\u201d (CHIANDUSSI et al., 2012, p. 919).\nIn multiple objective functions, the so-called --constraint method consists of optimizing only one objective function, while all other objective functions are transformed into inequalities fixed by a threshold e. We can substitute the general problem of multi-objective optimization (equation 2.19) by the e-constraint problem (CHIANDUSSI et al., 2012):\nmin fj (x)\ns.t. fk(x) &lt;Ek,\nk = {1,2,...,rn},k = j\n(2.24)\nAccording to Chiandussi et al. (2012), the main disadvantages of the --constraint method are: its possible high computational cost and the need of setting the preliminary individual values -i. On the other hand, the main advantage of this techniques is the relative simplicity of implementing it, being therefore popular particularly in the engineering field.\nThe proposed optimization method in the current work employed the ^-constraint technique. However, other decision making techniques could also have been employed. For future works, it is worth of investigating other strategies in the solution of multi-objective problems applied to the drilling engineering.\n2.3.5\tOptimization Techniques\nAccording to Cui et al. (2017), two kinds of methods can be employed to solve optimization problems: (a) analytical method and (b) numerical method. The analytical method reaches the exact solution, but it may not solve real problems. Numerical methods employ iterative calculation procedures in order to reach an approximate solution. With numerical methods, the objective functions can be black box models, such as those any machine learning methods seen in Section 2.2.\nThe numerical optimization methods can be split into two main groups (CUI et al., 2017): classical methods and intelligent methods. The classical methods (e.g. Newton iteration, simplex) have high searching efficiency and fast convergence, but they normally require gradient information. On the other hand, the Intelligent Methods employ heuristic search algorithms based on phenomena from the nature. It is possible to classify the intelligent optimization methods into four groups (BEHERA; SAHOO; PATI, 2015; CUI et al., 2017): biology inspired algorithms, physics inspired algorithms, geography inspired algorithms, and social-culture inspired algorithms.\nIn the drilling optimization problem, it is possible to perform the same optimization approaches seen for Hyperparameter Optimization (Section 2.2.7) and Feature Selection (Section\n55\n2.2.8). For this present study, we selected the grid search strategy. However, any other techniques could be employed, such as random search, and intelligent optimization methods (e.g. genetic algorithm, particle swarm optimization, differential evolution algorithm). The main characteristics of these techniques are the following:\n\u2022\tthe main advantage of the grid-search is its simplicity in implementation. However, the computational cost may be high. The global optima is not guaranteed to be reached. Another drawback is the inefficient search strategy, because too much effort is employed in not so important variable (BERGSTRA; BENGIO, 2012);\n\u2022\tthe main advantage of random search is the computational efficiency (BERGSTRA; BENGIO, 2012). With this approach is possible to carry out an extensive in the decision space Q. However, it is not guaranteed to find a optimum solution.\n\u2022\tthe so-called Biology inspired algorithms for optimization problems are based on evolutionary theorem from Darwin and swarm behaviour of particles and animals (CUI et al., 2017; BEHERA; SAHOO; PATI, 2015). For more details about genetic algorithms, the readers can refer to a comprehensive overview given by Roberts et al. (2017). For more details about particle swarm optimization, Zhang, Wang and Ji (2015) provided a comprehensive survey, showing also its application.\n2.3.6\tBrief Remark on Multi-Objective Optimization Algorithms\nThe intelligent optimization methods for multiple objectives are state-of-art solutions to approximate the Pareto Front in several complex problems. Some algorithms for multi-objective problems are Non-dominated Sorting Genetic Algorithm (NSGA-II), Multiple Objective Particle Swarm Optimization (MOPSO), Nondominated Neighbor Immune Algorithm (NNIA) (ANTONIO; COELLO, 2017; CUI et al., 2017; CHIANDUSSI et al., 2012; ZHOU et al., 2011).\nSuch algorithms are global optimization methods. However, in multi-objective optimization, the term of global solution is unclear, because there is usually a set of optimum solutions (Pareto Set).\nThe possibility of having several optimum solutions paves the way to implement a more sophisticate selection of optimum drilling variables. For the case of drilling, it is normally desired to optimize the drilling variables, without applying too oft changes. Abrupt changes in drilling controllable variables are neither possible nor desired (GANDELMAN, 2012). A more sophisticate selection of optimum drilling variables can avoid oft changes in magnitude of drilling variables. However, avoiding this problem goes beyond the scope of the current work.\n56\n3\tMACHINE LEARNING METHODS APPLIED TO RATE OF PENETRATION PREDICTION AND OPTIMIZATION - A REVIEW\nThis chapter reviewed the current progress on using machine learning methods and statistics methods to estimate the Rate of Penetration (ROP). A preliminary version of this study was presented in a Conference (BARBOSA et al., 2018). That paper reviewed partially the use non-traditional models to predict the ROP; 11 studies from a total of 45 works were analyzed. In additional, that work was restricted to ROP modeling. The current chapter extended the previous work: (i) by increasing the compilation of works from 45 to 58, and (ii) by showing how the ROP-models can be employed to optimize the controllable drilling variables.\nSome reviews have recently covered the applicability of artificial intelligence methods in drilling engineering. However, none of them focused exclusively on current progress of applying machine learning techniques to predict the ROP. Bello et al. (2016) reviewed the application of artificial intelligence in several fields related to oil and gas industry, for example: reservoir simulation, seismic pattern recognition, reservoir characterization, permeability and porosity prediction, drill bit diagnosis, well production optimization and so on. The review from Agwu et al. (2018) covered the application of artificial intelligence techniques applied to drilling fluid engineering. Rahmanifard and Plaksina (2018) reviewed several techniques of artificial intelligence, giving a special attention to heuristic optimization methods, such as genetic algorithm, particle swarm and differential evolution. Rahmanifard and Plaksina (2018) showed also how these techniques were applied in themes related to oil and gas industry in general (e.g. minimum miscibility pressure, oil production rate, and volume of CO2 sequestration). To the best author knowledge, no trial has been already attempted to review the current progress on machine learning techniques applied to rate of penetration prediction and optimization.\n3.1\tMETHODS USED IN ROP PREDICTION\nHegde et al. (2017) classified the ROP models into two groups: traditional (physics-based) models and data-driven models (regression models and machine learning methods). In the current work, the data-driven models were split into statistical models and machine learning models. The resulting classification is shown in Figure 3.1, and is the same general classification adopted by Breiman (2001b).\n57\nFigure 3.1 - Approaches for ROP modeling\nSource: adapted from Breiman (2001b)\nThis chapter focus on those works that used non-traditional models to predict the ROP. The use of machine learning to predict drilling parameters started in 1990s. Arehart (1990) employed neural networks to predict an important drill bit parameter (bit wear). Laboratory data for the training process was employed. Later, Bilgesu et al. (1997) published the first work that applied artificial neural networks to predict the ROP. After a long period without further development in this area, researchers have been publishing several works since 2010, as shown in Figure 3.2.\nFigure 3.2 - A compilation of 58 works found on the literature considering thesis and papers (publications in journals and congresses) using other methods different than the traditional models for ROP prediction. Status: October 2018.\nSource: an update from Barbosa et al. (2018).\n3.1.1\tTraditional Models\nHere, those ROP models which try to establish mathematical equations among the drilling\nvariables are called as traditional models. This is because most of these models appeared in the\ninitial phase of the scientific research of drilling optimization (EREN; OZBAYOGLU, 2010). In\nadditional, those models do not rely solely on the drilling data, as the machine learning models\ndo. As consequence, it is possible to find out other researchers (HEGDE et al., 2017) calling\n58\nthem as physics-based models, or as simple as drilling models (HARELAND; HOBEROCK, 1993). Recently, Soares and Gray (2018) called these models as analytical models.\nThere are many models describing the effects of several parameters on ROP. Eren and Ozbayoglu (2010) provided a literature survey, explaining some traditional models. The readers can also refer to other works that provided an extensive review about the ROP models (SOARES; GRAY, 2018; SOARES; DAIGLE; GRAY, 2016; NASCIMENTO, 2016; MITCHELL; MISKA, 2011; HARELAND; HOBEROCK, 1993).\nSome of traditional models which are worth of citing, because they are used in some papers for comparison purpose with data-driven models, are the following: Graham and Muench (1959), Maurer (1962), Bingham (1965), Young (1969), Bourgoyne and Young (1974), Warren (1987), Hareland and Rampersad (1994). One of the most important studies on drilling optimization was developed by Bourgoyne and Young (1974), where a multiple regression analysis of the drilling data was conducted to achieve minimum drilling costs by maximizing the ROP in a typical operation.\nAs already mentioned, the actual relationship among the drilling variables is not very well understood (MITCHELL; MISKA, 2011). Therefore, some efforts (DENG et al., 2016; MOTAHHARI; HARELAND; JAMES, 2010) have been made to better understand the relationship between the drilling variables and how they affect the ROP. Deng et al. (2016) proposed a theoretical model for determining the ROP for roller cone bit, and this model was validated with lab drilling results. The authors used the rock dynamic compressive strength instead of static compressive strength, what increased the accuracy of the theoretical model.\nSome researchers have recently tried to obtain ROP-models for specific wells drilled based on traditional models. Such studies consisted of fitting the empirical coefficients from the ROP-models, tailored to drill curves available. One example of application of an traditional ROP model was carried out by Nascimento et al. (2015b). The authors employed the Bourgoyne and Young ROP model (BYM) for presalt layers. This study showed that normalizing the factor of BYM formulation and allowing a wider range of applicable drillability coefficients could decrease the relative error of the ROP prediction from 46% to 27%, respectively. Bahari et al. (2008) employed genetic algorithm to determine the coefficients of Bourgoyne and Young model to predict the ROP. Formighieri and Filho (2016) estimated these coefficients with Markov Chain Monte Carlo simulation. In additional, other works employed the traditional models to predict the ROP (SOARES; DAIGLE; GRAY, 2016; KUTAS et al., 2015; GANDELMAN, 2012; EREN; OZBAYOGLU, 2010).\nROP modeling is not restricted to drilling of oil and gas wells. Basarir, Tutluoglu and\nKarpuz (2014) mentioned other ROP models, applied to rock excavation and tunnel boring,\nshowing the correlation between the rock properties and the ROP.\n59\n3.1.2\tStatistical Models\nMultiple regression can be applied to model the ROP as functions of drilling parameters. In this case, the dependent variable (ROP) is a function of independent variables (X1,X2,..., XK), where K represents the amount of inputs into the ROP model. When modeling the ROP with this approach, a specific regression method must be selected. Moraveji and Naderi (2016) applied the full quadratic form of multiple regression with linear, quadratic and interaction coefficients. The authors modeled the ROP as function of six drilling parameters, as listed in the Table 3.1.\nTable 3.1 - ROP modeling using multiple regression carried out by Moraveji and Naderi (2016)\nDrilling Data Source\tAmount of Inputs\tModel\tAccuracy %\n1732 observations from one southern Iranian gas field\t6\tFull quadratic form of multiple regression\tR2 =71.5 R =71.1\nSource: adapted from Moraveji and Naderi (2016), Barbosa et al. (2018)\nThere are also other works (ESKANDARIAN; BAHRAMI; KAZEMI, 2017; HEGDE et al., 2017; ARABJAMALOEI; SHADIZADEH, 2011) that employed multiple regression, with either linear coefficients or both linear and non-linear coefficients. Their purpose, however, was to compare different techniques of modeling the ROP (e.g. multiple regression with machine learning techniques), or to select the most important features in ROP prediction.\nIn this review, the work from Moraveji and Naderi (2016) is the only one found that focused on estimating the ROP with statistical regression models. The downside of pre-selecting a specific regression method for any real-world problem was discussed by Breiman (2001b). Breiman compared two different cultures in the use of statistical modeling: one called \u201cdata models\u201d, and another called \u201calgorithmic models\u201d. The first assumes the data is generated by a given stochastic data model (as done by Moraveji and Naderi (2016)), and the last approach is based on algorithms (such as neural networks, decision trees) that are able to learn from data, adapting themselves to the problem. Breiman (2001b) mentioned if the goal is to use data to solve real-world problems, then it is necessary \u201cto move away exclusive dependence on data models and adopt a more diverse set of tool\u201d, such as machine learning techniques. Perhaps, this is the reason why most of works preferred to use machine learning methods to obtain ROP-models, instead of multiple-regression methods.\n3.1.3\tMachine Learning Applied to Predict the ROP\nHere the Table 3.2 is reproduced from Barbosa et al. (2018). A summary of 10 works was\ngiven, focusing mainly on those studies that compared the ROP prediction with machine learning\ntechniques with other methods, which serves as the basis for the upcoming discussions.\n60\nTable 3.2 - Some works that used Machine Learning Methods to predict the ROP.\n(continued)\nAuthors\tDrilling Data Source (amount\tof points used)\tMachine Learning Method(a)\tAmounts of Inputs\tCompared with other methods?\tML was the best?\tTesting Accuracy of ML %\nBilgesu et al. (1997)\tLaboratory Data from rig floor simulator (8000)\tNeural Networks SLFN\t(a)\t- 10 (b)\t- 6\tX\t\t(a)\tR =98.2 (b)\tR =95.5\n\tUSA - Field Data from several wells (500)\tNeural Networks SLFN\t(a)\t- 10 (b)\t- 8\tX\t\t(a)\tR = 96.5 (b)\tR =98.0\nArabjamaloei and Shadizadeh (2011)\tIran - 35 wells drilled in Ah-waz\toilfield (330)\tNeural Networks SLFN\t7\tYes,\twith multiple regression and BYM\t/\tR2 = 74.0\nAmar and Ibrahim (2012)\tMediterranean Sea - Offshore, provided by Eren\tand Ozbayoglu\tNeural Networks RBF and ELM\t7\tYes,\twith BYM\t/\tAPRE = 9.6\nBasarir, Tutluoglu and Karpuz (2014)\tTurkey - 7 boreholes drilled in 6 different regions\tAdaptive neuro-fuzzy inference system (ANFIS)\t4\tYes, with linear and nonlinear multiple regression\t/\tRMSE = 0.33# (validation)\nBataee, Irawan and Kamyab (2014)\t15 wells (1810 points for training)\tNeural Networks MLP\t5\tYes,\twith Bingham, BYM, Warren\t/\tR2 = 85.7 (validation)\nAnsari, Hosseini and Amirpour (2017)\tPersian Gulf - 19 wells (248)\tSupport vector regression\t8\tafter feature selection\tX\t\tR =90.6\nBezminabadi\tIran - Azade-\tNeural Net-\t(a) - 5\tYes, with mul-\t/\t(a) R = 75\netal. (2017)\tgan Oilfield\tworks SFLN\t(b) - 9\ttivariate nonlinear regression\t\t(b) R = 86\n61\nTable 3.2 Some works that used Machine Learning Methods to predict the ROP.\n(conclusion)\nAuthors\tDrilling Data Source (amount\tof points used)\tMachine Learning Method (a)\tAmounts of Inputs\tCompared with other methods?\tML was the best?\tTesting Accuracy of ML %\nEskandarian,\tIran - 5 wells\t3 methods\t4 and 6\tYes, with lin-\t/\tR2 = 80.1\nBahrami\tin South West\t-\tCubist,\tafter feature\tear multiple\toverall\t(10 fold cross-\nand Kazemi\t(226)\tRF\tand\tselection\tregression\tMON-\tvalidation)\n(2017)\t\tMON-MLP\tof 13 non-\t\tMLP\t\n\t\t\tconstant\t\t\t\n\t\t\tvariables\t\t\t\nHegde et al.\tUSA - 1 verti-\tRF\t4\tYes,\twith\t/\t- 13\n(2017)\tcal well\t\t\t(Bingham,\t\tNormalized\n\t\t\t\tMotahhari,\t\tError (Me-\n\t\t\t\tHareland)\t\tdian for all\n\t\t\t\tand\tlinear\t\tformation)\n\t\t\t\tregression\t\t\nDiaz et al.\tSouth Korea - 1\tNeural Net-\t7\tafter\tYes,\twith\t/\tR2\t=\n(2018)\twell (7034)\tworks MLP\tfeature\tBYM\t\t(90, 99)\n\t\t\tselection\t\t\t\n(a) APRE: absolute percent relative error; ELM: extreme learning machines; MLP: multi-layer perceptron (with more than one hidden-layer); MON-MLP: monotone multi-layer perceptron; SFLN: single hidden-layer networks (a MLP with one hidden-layer); RBF: radial basis function networks\nSource: Barbosa et al. (2018)\n3.2\tDISCUSSION ON ROP MODELS\nHere, the original work (BARBOSA et al., 2018) was extended, by detailing especially the Section 3.2.4 (The importance of geological formation), the Section 3.2.5 (Data Partition), and the Section 3.2.6 (Drilling Data).\n3.2.1\tMachine Learning Algorithms Outperforms Other Methods\nIn Table 3.2, we can observe that 8 out of 10 works compared machine learning with other techniques (traditional models and/or regression models). All these comparative works showed that the use of learning algorithms provided a better ROP prediction. The reason for that is the capability of those models to capture non-linear relationship among the variables.\nIn this selected sample of works (Table 3.2), most of them applied neural networks to\npredict the ROP. However, it is not possible yet to affirm which method is preferred or more\nemployed in this type of study due to the small amount of works that were deeply analyzed.\nOther methods, such as support vector regression and Random Forest (RF), were employed also\nin the ROP prediction tasks.\n62\nThe use of Artificial Neural Networks (ANN) resulted in predictive models with good generalization capability as seen in Table 3.2. However, these models are complex. For that reason, ANNs are commonly referred as black-boxes, because it is not easy to understand them. On the other hand, it is possible to employ some techniques from which understandable rules can be extracted. A fake example of these rules are: if WOB is low, then ROP is low; if WOB is high, then ROP is high. Eskandarian, Bahrami and Kazemi (2017) employed Random Forest to model the ROP. The authors could split the ROP values into three levels: low, medium and high. In this case, some rules of thumb could be extracted for each ROP level. The work from Basarir, Tutluoglu and Karpuz (2014) emplyed the Adaptive Neuro-Fuzzy Inference System (ANFIS). With this technique, the authors could understand some simple rules about how the drilling variables affected the ROP.\n3.2.2\tSensitive Analysis\nThe rule extraction is one way to assess the influence of the drilling variables on the ROP. Another way is to perform sensitive analysis1, i.e. varying some drilling variables, while others remain unchanged. Eskandarian, Bahrami and Kazemi (2017) performed this analysis, helping the authors to understand the relationship among the variables, as seen in Figure 3.3. By analyzing the plots, the authors determined the range of controllable drilling parameters at which ROP is near to the maximum point. Another study carried out similar analyses as well (ARABJAMALOEI; SHADIZADEH, 2011).\nMoraveji and Naderi (2016) performed an extensive sensitive analysis, after obtaining a ROP-model based on multiple regression methods (see Table 3.1). Just to illustrate the sensitive analysis, we added the Figure 3.4. This figure shows the interaction effects of Depth (D) against other two other variables: a) depth vs. weight on bit; b) depth vs. rotation speed. In let figure, we can observe that:\nthe reduction of penetration rate by increasing weight on bit (bit floundering effect) occurs because of less efficient hole cleaning and cutting transport at higher rates of cuttings generation or excessive bit tooth wear as a result of complete penetration into the formation being drilled (MORAVEJI; NADERI, 2016, p. 835-838).\nThe Figure 3.4 B illustrates the interaction D x drill bit rotation speed. \u201cThe reduction of penetration rate by increasing bit rotation speed occurs because of reduced stability and increased size of the wellbore\u201d (MORAVEJI; NADERI, 2016, p. 838). The readers can refer to the original work to assess the complete parametric analysis.\n1 We changed the original name of this Section from \u201cParametric Influence\u201d to \u201cSensitive Analysis\u201d. The\nreason for this change is to avoid any confusion to the reader, who may associate the term parametric with\nhyperparameters of machine learning methods. However, the objective of this section is clearly different; it aims\nto present some methods to assess how the some inputs (e.g. WOB and RPM) affect the output (ROP).\n63\nFigure 3.3 - Using neural networks to assess parametric analysis: a) effect of WOB, b) mudweight (MW), and c) plastic viscosity on ROP\nSource: Eskandarian, Bahrami and Kazemi (2017)\n64\nFigure 3.4 - Contour plot for ROP versus normalized values of A) depth (X1) and weight on bit (X2), B) depth (X1) and bit rotation speed (X3)\nSource: Moraveji and Naderi (2016)\n3.2.3\tFeature Extraction\nSome studies (ANSARI; HOSSEINI; AMIRPOUR, 2017; BEZMINABADI et al., 2017; ESKANDARIAN; BAHRAMI; KAZEMI, 2017; BILGESU et al., 1997) analyzed which combination of inputs provided a better ROP prediction. This type of analysis is commonly known as feature selection, where, through some method, only those variables with significant impact on the prediction are selected. Eskandarian, Bahrami and Kazemi (2017) showed a comprehensive way of assessing the most important parameters for modeling the ROP, as shown in Figure 3.5. In that case, the authors used an open-source package called fscaret (SZLEK; MENDYK, 2018), which is written in R-programming language and provided an automated way to assess the most important drilling parameters on ROP prediction. Hegde et al. (2017) showed also the possibility to perform a similar analysis with random forests, by using the variable importance.\nHowever, it is possible to find some studies that only mentioned the use of the best combination of inputs (DIAZ et al., 2018; ARABJAMALOEI; SHADIZADEH, 2011). Other used a set of inputs, based drilling engineering knowledge, not providing any further discussion on the selection of the variables (AMAR; IBRAHIM, 2012).\n3.2.4\tImportance of Geological Formation in ROP Prediction\nIt was found four possible approaches regarding the use of geological formation on ROP\nprediction. The first approach does not take into account any parameter related to geological\nformation or lithology. In the second approach only part of the inputs are related somehow to\nthe drilled formation. The third approach emphasizes the importance of the formation on ROP\nprediction. In the fourth approach, drilling data is split for each geological formation or lithology.\nBilgesu et al. (1997) reported the possibility to obtain reliable predictive ROP models by\nonly using surface parameters (weight on bit, drill bit rotation, mud flow rate, and so on). The\n65\nFigure 3.5 - Variable importance: a) automated feature selection resulted applied by Eskandar-ian, Bahrami and Kazemi (2017) with fscaret, b) based on random forest ROP predictor performed by Hegde et al. (2017)\nImportance of input drilling variables for Lodgepole Limestone\n0.5\nVVOB\tRPM\tFlow\tUCS\nb)\nSource: a) Eskandarian, Bahrami and Kazemi (2017), b) Hegde et al. (2017)\nauthors trained two networks on the data from rig floor simulator. The case (a) had 10 inputs, and (b) 6 inputs after excluding bit tooth, bearing wear, formation abrasiveness and drillability. Even without any parameter related to the drilled formation or to bit status, the use of neural networks resulted in a good prediction capability for the ROP values (see Table 3.2). Other studies predicted the ROP also without any parameter related to formation (ESKANDARIAN; BAHRAMI; KAZEMI, 2017; BATAEE; IRAWAN; KAMYAB, 2014)\nMany examples of the second approach can be found (DIAZ et al., 2018; ANSARI; HOSSEINI; AMIRPOUR, 2017; BEZMINABADI et al., 2017; HEGDE et al., 2017; AMAR; IBRAHIM, 2012; ARABJAMALOEI; SHADIZADEH, 2011). In this approach, some parameters related to formation properties or lithology are used as inputs to predict ROP values.\nSome studies emphasized the importance of the formation on ROP prediction (ANE-MANGELY et al., 2018; BASARIR; TUTLUOGLU; KARPUZ, 2014)2. In this approach, a combination of surface drilling data and petrophysical logs provides accurate ROP-models.\nThe fourth approach is based on splitting the drilling data for each formation. Gandelman (2012) built neural networks to predict ROP with high accuracy by having artificial neural networks for each lithology. In this case, there is a unique ROP-model for each lithology. A similar approach was employed by Hegde et al. (2017), but the authors employed random forests to predict the ROP instead of neural networks. Another difference between both studies is the data partition. While Gandelman (2012) randomly partitioned the drilling data for each formation into training and testing sets, Hegde et al. (2017) used the initial phase of drilling to train the\nThis article was added in this review after submitting the preliminary conference paper. Therefore this is not include in Table 3.2.\n2\n66\nROP model. The rest of drilling data of each section was used to validate the ROP-models; this process is detailed in following Section 3.2.5.\n3.2.5\tData Partition\nA common approach of those works from the Table 3.2 was to split the drilling data into two data set: one for training (when required, part of this training set was used in the validation process during the training) and another for testing, which assesses the generalization capability of the predictive model. This data partition is randomly carried out, and can be applied as post-analysis or prior to drilling a well with similar conditions of those used to build the ROP models.\nHegde et al. (2017) proposed another way to partition the data into training and testing data set, so that it can be used in a real-time environment. The trained model can be employed to optimize the drilling activities by finding out the optimum values of the controllable drilling variables, such as weight on bit and bit rotation speed, which maximize the ROP (HEGDE; GRAY, 2017).\nThe proposed method by Hegde et al. (2017) is based on splitting the drilling data into several data sets for each lithology. In the initial phase of a formation or lithology section, the drilling data are used to build the ROP model, i.e., the training data set is the initial data of this section. After training an expert model based on Random Forests Trees for this respective formation, this model is able to predict the ROP for the rest of the length of this section with better accuracy than the traditional ROP-models. When a new formation is encountered, then a new model is trained until it reaches a good prediction capability for the section ahead, and this process goes on. When using Random Forests, it is possible to predict the generalization error of the model by using out-of-bag error prediction.\nRecently, a detailed study about this approach was published (SOARES; GRAY, 2018). Except for these trials, originated in the same university, we found no works that tried to build the ROP model while the drilling data are generated and sent to the rig crew. An illustration of this process is given in the Figure 3.6. In the current work, this process was named after the university where the studies were developed.\n3.2.6\tDrilling Data\nIn preliminary analysis, it was possible to observe that most of works used drilling data from two sources: drilling daily reports (ANSARI; HOSSEINI; AMIRPOUR, 2017; ESKANDARIAN; BAHRAMI; KAZEMI, 2017) or real-time drilling data (DIAZ et al., 2018; HEGDE et al., 2017; GANDELMAN, 2012).\nThe drilling data from daily reports are important source of information. However, the downside when using daily reports is that only few observations are available to build predictive models based on machine learning. For example, if it is required a data set with more than\n67\nFigure 3.6 - Data Partition developed at UT Austin\n\tFormation\tROP\tWOB RPM\t\t\nDepth\tA\t\t\t\t\n\t\t~r\t\t\t\n\tB\t\t\t\t\n\t\t\t\t\t\n\tC\t\t\t\t\n\t\tJ\t\t\t\nFLOW Pump Pres.\t\t\tData Partition after Hegde\t\n\t\t\t\tTrainin9\tExpert mode!\n\t\t\t\tfor fot i 11 a Liu11 A Testing\n8\t\t\t\tTraining Expert model for formation B\n\t\t\t\tTesting\n\t\t\t\tTraining\t, 3\tExpert model\n\t\t\t\t_\t.\tfor formation C \u2022\nSource: after Hegde et al. (2017)\nhundred points, it will not always be possible to analyze drilling daily reports from an individual well. While Diaz et al. (2018) used real-time drilling data from a drilled well with length of 4.6 km in South Korea with a total of 7043 observations, Ansari, Hosseini and Amirpour (2017) used drilling daily reports and needed to gather information from 19 wells drilled in Persian Gulf in order to have available 248 points. The difference in the amount of observations has a direct impact on training the predictive ROP model.\nThe real-time drilling data (RTDD) can be stored in time domain or in depth domain. When using drilling data in time domain, the raw recording can also have data during non-productive time. As consequence, manipulations are required to identify when the hole was being drilled prior to assessing how the drilling variables affect the drilling rate, what is the main goal of obtaining a ROP model. To properly identify the main drilling activities (e.g., rotary drilling, sliding, tripping connection), some works (MATHIS et al., 2007; TAVARES, 2006) reported so-called automated operation recognition systems.\nOne of the few works that used RTDD in time domain to predict drilling parameters was carried out by Fruhwirth, Thonhauser and Mathis (2006). However, the authors estimated the pump pressure instead ROP. In their work, there was available only information about data partition regarding the procedures for training, validation and testing; there was no mention about how different drilling operations were recognized. Gandelman (2012) reported also the use of RTDD in time domain, in his study of ROP prediction and optimization. The author detailed the data pre-treatment process employed in order to validate the drill-curves, but he did not mention about the existence of non-productive time in the original data set. Some sampling rates of drill curves employed in the previous works were 1s (FRUHWIRTH; THONHAUSER; MATHIS, 2006), 5s (DONNE, 2017), or 15s - 30s (GANDELMAN, 2012).\nThe depth domain is the common way of geologists to plot the logs against the depth. Using the depth as index simplifies the data preparation, since only observations while drilling\n68\nare used in modeling. Some sampling rates found of RTDD when stored in depth domain were 0.25 ft (HEGDE et al., 2017; HEGDE; GRAY, 2017) or 0.5 ft (NASCIMENTO et al., 2015b).\n3.2.7\tHandling Measurement Errors\nSome researches (OTALVORA et al., 2016; ARNAOUT et al., 2013) reported some common measurement errors in drilling data, and proposed methods to determine quality indexes in real-time of streaming data. For our purpose, the best description of the real-time measurement problems was given by Arnaout et al. (2013). The authors classified the measurement errors in the three categories:\n\u2022\tTime problems: missing timestamp, invalid time format, wrong time zone, incorrect or no time synchronization;\n\u2022\tDepth Problems: bit depth/hole depth resets, heave compensation (floating rigs);\n\u2022\tData Channel Problems: wrong channel description, wrong units, calibration, gaps (missing values and null values), different frequencies, outliers and drifting values.\nMost of works drew their attention to two types of problems from the category \u201cData Channel Problems\u201d which are: outliers3and gaps. To treat the outliers, it is required first to identify them, and then to apply a suitable treatment for them (i.e. replace the identified outliers by a suitable value or not consider the whole observation with an outlier). The problem of the gaps (missing values or null values) can be very challenging to be treated, because the original values is unknown and any attempt to treat or impute the data has high risk (LITTLE; RUBIN, 2002).\nNoises (i.e. error in data), or considering a broader concept of outliers (i.e. discordant), make difficult the task of obtaining machine learning models, and increases the training time (GARCIA; CARVALHO; LORENA, 2013; QUINLAN, 1986). Therefore, the reduction of noises in data brings together benefits to the learning process of data-driven models (GARCIA; CARVALHO; LORENA, 2013). There are many methods to identify and treat both outliers and noises (SALGADO et al., 2016; AGGARWAL, 2013). Some different approaches to treat measurement errors in drilling datasets were found in the literature, and a summary of them is illustrated in Figure 3.7.\nAt this point of this review, it was found that only some works mentioned how outliers were treated. This type of error can be handled: with a manual approach (HEGDE; GRAY, 2017; GANDELMAN, 2012; ARABJAMALOEI; SHADIZADEH, 2011), or with filter to smooth\n3 Sometimes, the terms noises and outliers can be confusing. The readers can refer to Salgado et al. (2016) in order to understand the difference between them. To sum up, noises are mislabeled examples or errors in the values of attributes. Outlier is a broader concept, because this term includes errors and discordant data (also called abnormalities, discordants, deviants and anomalies). Such discordant data is not necessarily an error in the measurement, but a deviation from a population.\n69\nFigure 3.7 - Possible approaches to treat measurement errors in drilling data that can be applied to drilling data analysis\nDrilling data - possible measurement errors (e.g. noises and missing values)\nNo treatment\nManual Approach\nAutomate Approach\nRaw recording to build ROP models\nExclusion of incomplete observations and observations with visible outliers\nIdentification and Treatment of outliers and missing values with systematic methods (Digital Signal Processing or Statistic Methods)\n\nr\n\nr\n\n\nJ\nSource: own authorship.\nthe recording, eliminating noises (DIAZ et al., 2018; ANEMANGELY et al., 2018). A manual approach is subject to human interpretation, and can be very time-consuming job, especially when analyzing many drill curves. However, it can be suitable when analyzing a small dataset, because those observations which are visible outliers can be simple removed from the data set, as done by Hegde and Gray (2017).\nInstead of the manual approach, the automate approach employs robust techniques to identify whether a observation is indeed an outlier or not. Few works applied filter to smooth drill recording, reducing noises in data, as consequence some outliers. Some filters employed were low-pass parabolic filter (DIAZ et al., 2018), and Savitzky-Golay filter (ANEMANGELY et al., 2018). Robust techniques to identify mainly outliers, for example median absolute deviation, were not used in the ROP studies.\nAnother important issue is the completeness of drilling data. It is not rare to encounter drilling data with \u201cgaps\u201d in their recordings. A gap is when a failure in data transmission occurs, so that measurements of one or more drilling variables are not transmitted for a period of time (ARNAOUT et al., 2013). Having this in mind, it is not difficulty to suppose that some of 58 studies had faced this type of problem when training a ROP model. However the common approach was to omit this problem.\nOne exception was the Gandelman\u2019s study, who mentioned the problem of missing data. His approach was to use complete-cases. The downside of this approach is to cause a substantial loss of information (LITTLE; RUBIN, 2002). Gandelman (2012) detailed the data pre-treatment process employed to validate the drill recordings, eliminating possible error measurements. One rule employed by the author to validate the drill curves was the following: ROP could only be above zero, if, and only if, the WOB and RPM were both above zero. Otherwise, this observation would not be considered as a valid one. The author mentioned the reduction of dataset from 43 524 observations (200 hours of drilling activities) to 23 949 valid observations (160 hours).\n70\n3.3\tDRILLING OPTIMIZATION BASED ON PREDICTIVE MODELS\nROP models can be employed in drilling optimization. Two approaches were employed in the previous works. The first has the goal to determine the values of the controllable drilling parameters that resulted, usually, in the maximum value of the ROP. This approach led to a single objective optimization problem. A more sophisticate method takes in account that maximizing the ROP may induce drilling dysfunctions. To avoid or mitigate the drilling problems, some works formulated a multi-objective optimization problem. The following section covers both approaches.\n3.3.1\tSingle-Objective Optimization\nAttempts to formal optimize drilling variables (WOB, RPM and bit hydraulics) are not new. One example is the work from Tansev (1975), where multiple logarithmic regression of field data were employed to model the ROP and bit life. With both prediction models, the controllable variables could be optimized in order to minimize the cost per foot, subject to controllable variables\u2019 bounds. In the last decade, some works employed predictive models to formulate optimization problems. A summary about these works is given in the Table 3.3.\nTable 3.3 - The use ROP models to optimize the drilling variables, considering a single-objective problem\nAuthor\tObj. Function\tConstrained?\tOpt. Method\tOpt. Parameters\nBahari and Seyed (2009)(a)\tmin. Cost\tZ\ttrust region\tWOB, RPM\nArabjamaloei and Shadizadeh (2011)\tmax. ROP\tZ\tgenetic algorithm\t(b) WOB, RPM, bit hydraulic\nAwotunde and Mu-tasiem (2014)(c)\tmax ROP min. Total Time\tZ\tdifferential evolution\tWOB, RPM, mud flow rate\nBataee, Irawan and Kamyab (2014)\tmax. ROP\tZ\tnot mentioned\tWOB, RPM, mud weight\nHegde and Gray (2017)\tmax. ROP\tZ\tbrute force\tWOB, RPM, mud flow rate\nHegde and Gray (2018)(c)\tmax ROP min. Torque min. SE\tZ\tparticle swarm (PSO)\tWOB, RPM, mud flow rate\nconsidering the optimization problem of operating conditions WOB and RPM. The authors studied also the optimization of hydraulics and bit tooth wear. (b) Only added those variables whose optimization were detailed. (c) These studies investigated different objective function for the single-objective optimization problem. Source: own authorship\nBahari and Seyed (2009) studied the optimization the controllable drilling variables (WOB\n71\nand RPM) by minimizing the cost per foot drilled, subject to operating ranges recommended by manufacturing companies and limited to the maximum applicable mechanical energy. The basis of his method is the Bourgoyne and Young model to predict the ROP. The single-objective problem was solved by constrained optimization algorithm called trust region (COLEMAN; LI, 1996).\nArabjamaloei and Shadizadeh (2011) employed genetic algorithm in order to find which values of the controllable variables maximize the ROP. Bataee, Irawan and Kamyab (2014) studied also the optimization of ROP, but the authors did not mention which optimization method was employed.\nAwotunde and Mutasiem (2014) employed the Warren model to model the ROP. The authors compared two objectives functions in single-optimization framework: maximization of ROP and minimization of total-time (drilling time, tripping and bit-change time). At shallow depths, the maximization of ROP yields to lowest total time, but, at deeper depths, the minimization of total time yields to the lowest overall time. As global optimizer, the differential evolution (STORN; PRICE, 1997) was employed.\nHegde and Gray (2017) performed the so-called \u201cbrute-force\u201d algorithm to optimize the drilling performance indicators (e.g. rate of penetration). In this study, a single objective optimization was formulated, whose goal was to maximize the ROP subject to constraints from two sources. According to the authors, the magnitude of drilling variables are limited due to design restrictions. The other limitation comes from the data. That is, it is not reliable to predict ROP values when the inputs are out of the range from the data set used in training phase. This extrapolation leads to high uncertainty around the ROP estimation. As already mentioned, this method could be employed in a real-time environment, because the ROP model could be trained while the drilling takes place.\nLater, Hegde and Gray (2018) analyzed other objective functions: minimization of torque, minimization of the specific energy, or maximization of ROP. The authors concluded that the minimizing the specific energy was the better approach. In this study, a particle swarm optimization (PSO), able to deal with constraints, was employed.\n3.3.2\tMulti-Objective Optimization\nNot many works proposed a multi-objective optimization problem for the drilling activities, expect for the following works Gandelman (2012), Guria, Goli and Pathak (2014), Payette et al. (2017).\nGandelman (2012) developed neural networks for different Brazilian rock formations (12\nin total), to be used latter in real-time optimization of mechanical drilling variables (WOB and\nRPM). His optimization approach considered two objective functions at the same time: min SE\nand min E, where SE represented the mechanical specific energy, and E a function error\nbetween the predicted ROPpredict = f (WOB, RPM) and a desired ROPset, which the driller\nset. The goal of this optimization was determine the optimum WOB and RPM that achieved a\n72\ndesired ROP, trying, at the same time, to spend as less as possible energy in the process. This method could be classified as \u25a0-constraint optimization, where the goal was to minimize the SE subject to a constraint (ROPpredict \u2014 ROPset) &lt;\u25a0, where the decision variables x E Q were within the design limits of drill equipment.\nAmong other things, Gandelman (2012) tested two optimization methods: particle swarm optimization, and an own developed exhaustive search. This last approach combined if-then rules with the grid search in the feasible region Q of the decision variables. The author selected the bit weight and rotary speedy as the variables to be optimized. For each iteration, 195 000 combinations of WOB and RPM were tested. The author concluded that this method was the only one able to determine the optimum combination of WOB and RPM.\nGuria, Goli and Pathak (2014) reported another work of drilling optimization with multiple objectives. The authors employed the Bourgoyne and Young formulation for ROP prediction and tooth wear. With these predictive models, a multi-objective optimization involving conflicting objectives was developed. The objective functions were: (i) maximization of the drilling depth, (ii) minimization of the drilling time, (iii) minimization of the drilling cost. The controllable drilling-variables used in this optimization study were four: equivalent circulation mud density, drill bit rotation speed, weight on bit, Reynolds number of circulating mud through drill bit nozzles. The authors employed the non-dominated sorting genetic algorithm (NSGA-II), as optimization technique.\nIn the drilling advisory presented by Payette et al. (2017), no ROP model was actually obtained, so that this work actually goes beyond the scope of this review. However, it is worth of mentioning the adopted strategy to simplify the multi-objective optimization problem. Up to three different objectives (ROP, SE and stick-slip risk) are aggregated into a single scalar function. It facilitates the optimization task. The Figure 3.8 illustrates the aggregation process of different objective functions into a single one.\n73\nFigure 3.8 - Simplifying the multicriteria optimization into a single objective functions. Response surfaces form the basis for the objective function (OBJ).\nMechanical Specific Energy (MSE)\nRate of Penetration (ROP)\nStick-Slip Estimate (TSE)\n<5 + ROP! ROP\u201e OBJ (MSE, SS, ROP) =  ------------------------.\nd + MSE IMSEO + SS/SSO (<5 factor to be determined).\nMSE - Avoid Low WOB and High RPM\nROP - Avoid Low WOB and Low RPM\nStick-Slip (TSE) - Avoid High WOB\nObjective Function (OBJ)\nObjective Function (OBJ) -Favor Medium WOB\nand High RPM\nand Low RPM\nSource: adapted from Payette et al. (2017)\n3.3.3\tThe Need of Changing the Current Mindset\nWang and Salehi (2015), Hegde and Gray (2017) mentioned the need of changing mindset to optimize the drilling process. The term set-it-and-forget-it indicates a typical approach to determine the values of controllable parameters while drilling. However, if controllable drilling variables are not changed during the drilling process, it is not possible to determine whether the process is at its optimum point or not.\nDetermining the optimum parameters can be facilitated by more often implementation of\ntests, such as drill-off or drill-rate tests (DUPRIEST; KOEDERITZ, 2005; NASCIMENTO et\nal., 2016; PAYETTE et al., 2017). Nascimento et al. (2016) proposed a method to plot ROP\nagainst WOB curves while not only performing pre-operational test, but also during normal\ndrilling activities.\nPayette et al. (2017) showed that through drilling advisory systems it is possible to optimize\n74\nthe drilling process. Theses systems encourage the rig crew to change the controllable parameters within an operational range. These systems provide information about how each variable affects the ROP, as well as nonlinear effects on ROP.\nDespite the efforts employed in collecting huge amount of drilling data, comprehensive analysis does not take part as the best practices of drilling engineering, even knowing that simple plan of activities can boost the results (STAVELEY; THOW, 2010). It is possible to find discussion that reports wastes of 60% in the drilling engineering, what is unacceptable in most of industries (BOND et al., 1998). One way of boosting the efficiency is to avoid or, at least, mitigate drilling dysfunctions that lead to non-productive time.\nOne technique from artificial intelligence, called case-based reasoning, can have a great impact in detecting drilling problems, and proposing the respective solutions by combing data analysis of historical and real-time data. This approach enables the identification and mitigation of events that lead to non-productive time (SKALLE; AAMODT; ERIKGUNDERSEN, 2013). For that, knowledge is extracted from past events provided from data fusion from historical data and rig crew experience. So it is possible to identify the most likely causes of the drilling problems as well as the respective solutions. This process resembles the method employed by rig crew, facilitating the knowledge transfer. A detailed review of this method for drilling optimization is given by Shokouhi, Skalle and Aamodt (2014). Yuan et al. (2009) showed also the possibility to use case-based reasoning to optimize the drilling parameters, such as the optimum drill bit and what values of drilling variables maximize the ROP.\n3.4\tSUMMARY\nRegarding the ROP models, we observed the following issues:\n\u2022\tAs seen in the Table 3.2, the works that compared different methods to predict the ROP concluded that the machine learning methods outperformed other methods (regression or traditional models) in this type of task;\n\u2022\tMachine learning algorithms are normally black-boxes models, but, depending on the algorithm employed, it is possible to extract rules that represents the relationship among the drilling variables. These rules can be help the drill crew to select the optimum drilling variables;\n\u2022\tValuable information can be obtained with sensitive analyses as well. With such analysis, partial plots (e.g. ROP vs. WOB) can provide graphs that would help identifying the drilling conditions, as done by Eskandarian, Bahrami and Kazemi (2017) (See Figure 3.3);\n\u2022\tMost of works carried out historical analysis for wells drilled in a similar region, what can be employed as post-analyses or prior to drilling a similar well. However, few tries obtained ROP-models while the drilling (SOARES; GRAY, 2018; HEGDE et al., 2017; HEGDE; GRAY, 2017);\n75\n\u2022\tIt was also seen that not many works tried to formally treat possible measurement errors in the dataset.\nRegarding the optimization based on data-driven models, it was possible to observe:\n\u2022\tmaximizing ROP is a common approach adopted. However, this is not always the best approach, because drilling dysfunctions can occur at higher drilling rate. Therefore, other metrics need to be taken into account, yielding a multi-objective optimization problem;\n\u2022\tA multi-objective optimization seems to be a more reasonable approach in the drilling optimization, due to the complexity of drilling process;\n\u2022\tApplying decision making techniques for multiple-objective functions (e.g. global criteria method, \u25a0-constraint method) enables a easier implementation of a multi-objective optimization problem.\n76\n4\tMETHODS\nThis chapter covers three parts. It is presented, first, the material used in the development of this current work. Then, we describe the method employed to develop predicting models for drilling performance indicators, such as rate of penetration and specific energy, covering also the data pre-treatment employed in the current work. The third part covers how the obtained models can be used to optimize the drilling controllable variable such as weight on bit and rotating drillbit speed.\n4.1\tMATERIALS\nDrilling data from pre-salt region used by Nascimento (2016) were employed in the current work. In order to have the results reproducible by other researchers, we employed an open dataset from Norwegian wells, which was published by Donne (2017). The describing of both datasets are given in next sections.\n4.1.1\tDrilling Data from Pre-Salt\nDrilling data from pre-salt layer were used for the development and test of the methods to be developed in this current work. These data were studied previously by Nascimento (2016), Dutra (2016). The readers can refer to these works in order to obtain details about the geological characteristics of drilling data. In this present work, we used drilling data of four wells drilled in the carbonate formation of pre-salt (a total of 1 212 km). These drill-curves have as index the depth, recorded at the sampling rate of 0.1524 m (0.5 ft). In Table 4.1, a summary of those drilling data is given.\nIn the original recording of the drilling data from pre-salt formation, missing values (or null values) were observed, especially for those parameters measured by downhole equipment, such as collar rotating speed or vibration. Prior to performing drilling data analysis, a driller engineering can select those variables that he believes to be the most important in ROP analysis, and then exclude the other parameters. This approach can reduce the amount of missing values, helping the further data cleansing process. However, it hinders more elaborate analyses such as feature selection in order to identify the most important parameters in ROP predictive model, as explained in the following paragraphs.\n77\nTable 4.1 - Overview of the drilling data from pre-salt formation. The abbreviation meanings are found in Annex A\nWell\tDrilling Variables\t\tHole Depth (m)\t\tPoints #\n\t#\tdescription\tinitial\tfinal\t\nA\t14\tDEPT, DHAP, DHAT, ECD, GR_CAL, ROP5, CRPM, TVDE, BLKP, HKLA, RPM, SPPA, SWOB, TFLO\t3 999\t4 194\t1 326\nB\t24\tDEPT, BLKP, PVEL, ROP, DWOB, SWOB, HKLA, SHKR, SHKRSK, SHOCKS_ACC, DTOR, CRPM, VIB_LAT, RPM, STICK, TRPM, TFLO, SPPA, VIB_X, SHKL, ROP5, STICKRATIO, STUCK, ECD\t3 422\t3 507\t509\nD\t26\tDEPT, BLKA, BLKP, CDEPTH, HKLA, ROP5, SPPA, SWOB, DHAP, DHAT, ECD, GR, SHKL, AJAM, CRPM, SHKRSK, SHOCKS_ACC, STICK, STUCK, TRPM, VIB_LAT, VIB_X,\t4 403\t4 546\t927\nH\t15\tDEPT, DHAP, DHAT, ECD, GR_CAL, SHKL, ROP5, RPM, SPPA, STOR, SWOB, TFLO, CRPM, SHKRSK, TRPM\t5 050\t5 840\t5 184\nSource: dataset from Nascimento (2016).\nSome statistics about the missing values in the drilling data from Well H are given in the Tables 4.2-4.3. Many variables have up to 20% missing values, and trying to use only complete cases would result in data set with roughly 30% of the original information. This approach of analysis which considers only complete-case data would causes substantially loss of information, especially if we observe that about the half of observations have only 1 to 3 missing values (see Tables 4.3- 4.4).\nAs explained by Little and Rubin (2002), the \u201ccomplete-case analysis may be justified in terms of simplicity when the loss of precision and the bias is minimal, so that the pay-off of exploiting the information in the incomplete cases will be minimal\u201d. Therefore, this simple approach of discarding incomplete observations is not appropriate in the analysis of this dataset from pre-salt formation. Sophisticated techniques from statistics field, such as likelihood-based approached to the analysis of incomplete data Little and Rubin (2002), or from Digital Signal Processing (DSP) science can be applied to treat the stored data before building the ROP predictive models. In the current work, the strategy to treat measurement errors is presented in the Section 4.2.1.\n78\nTable 4.2 - Amount of missing values in each variable (column). For illustration purpose, statistics only from the Well H is presented. This dataset has a total of 5 184 observations and 15 variables, therefore the total amount of values is 5 184 \u2022 15 = 77 760.\nVariable\tAmount of missing values\t\n\t#\t%\nDEPT\t0\t0\nDHAP\t782\t15.08\nDHAT\t1 327\t25.60\nECD\t813\t15.68\nGR_CAL\t571\t11.01\nSHKL\t1 297\t25.02\nROP5\t58\t1.19\nRPM\t31\t0.60\nSPPA\t21\t0.41\nSTOR\t31\t0.60\nSWOB\t31\t0.60\nTFLO\t44\t0.85\nCRPM\t1 741\t33.58\nSHKRSK\t1 746\t33.68\nTRPM\t1 721\t33.20\nTotal\t10 214\t13.14\nSource: own authorship.\nTable 4.3 - Amount of observation with k-variables as missing values - Well H\nk\t#\t%\n0\t1 597\t30.81\n1\t999\t19.27\n2\t723\t13.95\n3\t831\t16.03\n4\t456\t8.80\n5\t278\t5.36\n6\t137\t2.64\n7\t87\t1.68\n8\t56\t1.08\n9\t17\t0.33\n10\t3\t0.06\nSource: own authorship.\n79\nTable 4.4 - Relative amount of observations with k-variables as missing values\nk\tWell A %\tWellB %\tWellD %\tWellH %\n0\t37.86\t23.73\t80.69\t30.81\n1 - 3\t51.66\t47.25\t13.38\t49.25\n> 4\t10.48\t29.02\t5.93\t19.95\nSource: own authorship.\nThe Figure 4.1 illustrates one of four wells drilled in pre-salt region, with raw recordings. The drill crew experienced low rates of penetration due to the hardness and abrasiveness of carbonate formation, requiring recurrent drill bit changes (NASCIMENTO, 2016; DUTRA,\n2016). To calculate the specific energy, the original formulation from Taele was employed (equation 2.1). We added other drill-curves from pre-salt in Appendix B.\nFigure 4.1 - Raw recording of drill curves from Well H. The specific energy was calculated based on Taele\u2019s formulation.\n..N(rpm)\n\u2666\tTFLO\n\u2022\tECD\n\u25a0 SE (GPa)\nFlow (gpm)\nS 10\t11\t12\nSource: own authorship.\n80\n4.1.2\tDrilling Data from Norway\nDonne (2017) published drill curves from Norway that he used in his Master\u2019s Thesis. The drilling data are anonymous, i.e. the file names were randomly given by Donne, preserving the confidentially of the data. The use of this dataset enables the readers to reproduce the proposed methods in this current work.\nThis dataset contains real-time drilling data (RTDD) of 10 wells drilled in an Norwegian continental shelf field, called Statfjord (EQUINOR, 2018). Donne selected 10 wells from more 100 wells drilled available in their data-bank. The criterion for this selection was the data quality. These data are in time domain base, recorded at the sampling rate of 5 s. An overview of this dataset is given in the Table 4.5. The selected drill curves for the development of the current work are, in general, free of the missing data problem.\nConsidering the amount of variables recorded for each well drilled in the RTDD in the original files, we can classify them into three different groups, as shown in the Table 4.5. In present work, we used drilling data of all wells, expect the drill-curves from the well 2 which has long period of missing values (over 50 minutes), as well as calibration problems. Those types of errors go beyond the scope of this work and therefore the well 2 was not considered in this work. We found wrong channel descriptions in the data of the well 6, however it was possible to recover the data, as explained in Appendix A. The drill curves from the third group have actually 36 variables, however nine of them contain only not-a-number values, being therefore not taken into account.\nUnlike pre-salt drill curves, the drilling data from Norway were recorded in time domain base. A sample of those drilling data is given in the Figure 4.2. We observed an continuous measurement of all variables for all wells. That is, all drill curves from Norway have in their recordings all possible drilling operations, including tripping connection, rotary drilling, reaming and so on (see Figure 4.2). For this reason, it is necessary to employ operation recognition techniques (MATHIS et al., 2007) to identify when a hole was being drilled in fact.\nTable 4.5 - Real-time drilling data from Norway published by Donne (2017). The abbreviation meaning used in these dataset can be found in Annex B\nGroup\tDrilling Variables\t\tWell\t\t\tHole depth (m)\t\tPoints #\tSelected?\n\t#\tdescription\t#\tFormation\tEncountered Lithology\tInitial\tFinal\t\t\n<Z>\t8\tTime, DBTM, DMEA, ROP,\t1\tViking, Brent\tmarlstones\t2 553\t2 637\t5 973\t/\n\t\tWOB, RPM, BPOS\t2\tBrent\tclaystone, coal, claystones\t3 597\t3 770\t14 992\tX\n\t10\tTime, DBTM, DMEA, ROP,\t3\tCromer, Viking,\tcalcitucite, claystones\t3 100\t3 420\t10 933\t/\n\t\tWOB, HKL, BPOS, TRQ,\t\tBrent, Dunlin\t\t\t\t\t\nc\t\tRPMB, RPMA\t\t\t\t\t\t\t\n(N\t\t\t4\tViking, Brent\tcoal, limestone, silstone, sandstones, claystones\t4 300\t4 800\t13 659\t/\n\t\t\t\t\t\t\t\t\t\n\t\t\t5\tNot Available\tclaystones, marlstones\t2 500\t3 000\t20 210\t/\n\t\t\t6\tViking, Brent, Dunlin, Statfjord\tclaystones, sandstones\t2 700\t3 100\t14 737\t/\n\t\t\t7\tViking, Brent,\tclaystones, silstones,\t3 002\t3 640\t32 837\t/\n\t\t\t\tDunlin, Statfjord\tlimestones, sandstones\t\t\t\t\n\t27\t2nd Group + SPP, CEPP, KLP,\t8\tBrent, Dunlin\tsandstones, shale, silstones\t2 600\t2 800\t17 107\t/\ncn\t\tCHP, CFI, CTVL, TVA, TPVT, MFO, MFO, MFI, MDO, MDI, MTO, MTI, ECDB, ECDM, GAS\t9\tBrent\tcoal, claystones, calcitucite, silstones\t4 338\t4 700\t5 013\t/\n\t\t\t10\tViking, Brent, Dunlin\tcoal, silstones, claystones\t2 600\t2 900\t14 417\t/\nSource: dataset available in the work of Donne (2017)\n81\nFigure 4.2 - A sample of real-time drilling data considering the first approx. 8 hours of available recording \u2014 Well 4 from Norway\nElapsed time - approx. 8h 20min\n4250\n----'DBIM' 'M'\n-----'DMEA' 'M\n'ROP' M HP.'\n4300\n4350\n4400\n4450\n4500\n4550\n-----'WOB' 'TON'\n-100\n32000\n---RPMA' RIM\n----IRQ KNNI\n24000\n16000\nS000\nOSi H\n----\u2019EPOS'M\nI\nSource: dataset available in the work of Donne (2017)\n\n82\n83\n4.1.3\tSoftware and Hardware\nThe current work employed MATLAB\u00ae software, version R2017b, in order build the predictive models and to use them to optimize the drilling variables. The main packages and toolboxes employed were: Global Optimization Toolbox\u2122, Statistics and Machine Learning Toolbox\u2122, Parallel Computing Toolbox\u2122, and Signal Processing Toolbox\u2122. The simulations were performed in a simple notebook with Intel\u00ae Core\u2122 i5-4210U CPU 1.70 GHz, memoryRAM of 4 GB, and operating at 64 bits.\n4.2\tPREDICTION DRILLING PERFORMANCE-INDICATORS\nHere, we present the adopted training method to obtain predictive models of the drilling performance indicators. This workflow can be employed to predict the rate of penetration or specific energy. With some adjustments, this method can also be applied to predict any other drilling parameters.\n4.2.1\tData Pre-Treatment\nMeasurement errors can occur in drilling data provided from down-hole and even surface equipment. These errors can lead e.g. to observations with noisy data and missing values. As not many works treated formally these problems, as seen in the Chapter 3, a systematic approach for data pre-treatment is presented in this section (see Figure 4.3). The proposed approach is able to treat both problem in drilling data, outliers and missing values, regardless of domain used to record the drilling data. It can be applied to both common drilling data indexes: depth basis domain (pre-salt recordings) and time basis domain (Norwegian recordings).\nA simple assumption of independent data channels was adopted. This enables to apply some common approaches to treat outliers and missing values in studies on energy forecasting (GONZALEZ-ORDIANO et al., 2017; GUAN et al., 2013).\n@ Plot Drill-Curves\nThe data pre-treatment process starts with a manual step, where the drill-curves are plotted. This enables to identify if there are gross errors in the drilling data. If there are such errors, any attempt to perform data analysis will be prejudiced. For this reason, the drilling data from the Well 2 was not considered in this study (see Section 4.1.2).\nIn additional, cross-analysis with drill reports can be carried out. This enables to extract\nimportant information about: the events occurred during drilling, drill bits employed, bottom-\nhole-assembly, drilling dysfunctions. Gandelman (2012) carefully proceeded a pre-treatment\nanalysis of data. In his work, a special attention was given to exclude from drilling data those\nobservations if the drill bit had signs of great wear.\nIn the current work, such cross-analysis could be partially performed. For drilling data\nfrom pre-salt, information about drill bits and some important drill events were extracted from\n84\nFigure 4.3 - Data Pre-Treatment Method\nSource: own authorship.\n85\nNascimento (2016). For drilling data from Norway, information about drill bits are not available in the original work from Donne (2017). However, the author provided details about the geological formation.\n@ Hampel Filter\nThe first step to treating outliers is having a robust method to find them. Leys et al. (2013) showed that the use of mean plus/minus a coefficient (normally three) standard deviation is very sensitive to outliers, while the use of Median Absolute Deviation (MAD) is a more robust measure of dispersion. Therefore, we chose the MAD in order to identify outliers. This method was popularized by Hampel (1974).\nLet Xj be a vector, {xx, x2,..., xj}, of j elements. The Mj (Xj) represents the median of Xj. When j is odd, then Mj (Xj) is the simply middle order statistic of Xj. When j is even, it is possible to use the average of the order statistics with ranks (j/2) and (j/2) + 1 (ROUSSEEUW; CROUX, 1993).\nThe scaled Median Absolute Deviation (MAD) is defined as follows (ROUSSEEUW; CROUX, 1993; LEYS et al., 2013):\nMAD = b * M(xi - Mj(Xj)|, |x2 - Mj(Xj)|,..., |xj - Mj(Xj)|)\nMAD = b * Mi(\\xi - Mj(Xj)|)\t.\nwhere Mi is the median of the absolute difference between each element of Xi and Mj (Xj) for i = 1, 2,..., j. When assuming the condition of normality, the MAD is scaled by a factor b = 1.4826 (LEYS et al., 2013).\nThe rejection criterion is median plus/minus a coefficient multiplied by the MAD, which can be expressed by (LEYS et al., 2013):\nM - TH * MAD &lt;xi &lt;M + TH * MAD\n(Xi - M)\nMAD\n> | \u00b1 TH |\n(4.2)\nwhere M is the median M = Mj (Xj), MAD is the scaled absolute deviation around the median and TH is the coefficient to determine the lower and upper limit for the outlier detection. The value of TH must be defined, and this \u201cremains the unavoidable subjective aspect of the decision\u201d (LEYS et al., 2013, p. 765). It is recommended to use plus/minus 2.5 * MAD (moderately conservative), but other values can be applied such as TH = 3 (very conservative) or TH = 2 (poorly conservative) (LEYS et al., 2013).\nA moving median absolute deviation can be calculated over a sliding window across the\nneighbours elements of xi. For that, it is only necessary to suppose that the vector Xj is obtained\nby this sliding window within a vector Xn with n elements, where j &lt;n. In Matlab, this method\nis implemented by the function hampel (MATHWORKS, 2018a). For each element xi, the\nwindow is centered about the element in the current position. As shown in the Code 4.1, we can\n86\nset the amount of neighbors, numNeighbors, on each either side of the center element x,, when using the function hampel. This implies that the window size is j = 2k + 1, i.e. it is always an odd number. The thresholds TH is another parameter that can be set. To determine the values of both parameters (number of neighbors and threshold), the influence of them was investigated in the Appendix C.\nCode 4.1 - General use of hampel function, adapted from Mathworks (2018a)\n1\t%\tInputs\n2\t%\tx - a matrix with drill curves\n3\t%\tnumNeighbors - the number of neighbors on either side of each sample in ...\n\t\tthe window\n4\t% %\tTH - threshold (standard deviations) for outlier detecting\n6\t%\tOutputs\n7\t%\ty - matrix with filtered data\n8\t%\tisOutlier - logical matrix of detected outliers\n9\t%\txmedian - local median for each observation\n10\t%\txsigma - MAD value for each observation\n11\t[y,isOutlier,xmedian,xsigma] = hampel(x, numNeighbors, TH)\t\nWhen an outlier is detected, it is possible to replace the detected outlier by a suitable value. Here, the hampel function replaces the identified outlier by the center value given by the moving median (MATHWORKS, 2018a).\n(3) Treating Missing Values\nIn this step, the linear interpolation is employed to impute the missing values. In this case, it is adopted the assumption of data channels independence. In Matlab, the function fillmissing enables to implement several methods to impute missing values, including the linear interpolation (MATHWORKS, 2018b).\n@ Index While Drilling\nExamples of drilling activities are (THONHAUSER, 2004): bottom hole assembly (BHA) runs, tripping, making connection, ream and wash, circulating, drilling in rotating or sliding mode. If the drilling data is recorded in time domain, it is possible to have drill curves recorded with all possible drilling activities. Once, the current study aims to model how some drilling variables affect the performance indicators (ROP and SE), it is important to split drill curves with time domain into two main states: drilling and not-drilling states. Some works presented automated operation recognition methods, which provide important information for this task (MATHIS et al., 2007; TAVARES, 2006).\nAccording to Mathis et al. (2007), the rotary drilling occurs if three conditions are satisfied:\ni) bit must be on bottom, ii) circulation must be present, and iii) drillstring is rotating. If drillstring\nis not rotating, then sliding drilling is occurring.\nIn order to implement the aforementioned operation recognition, it is necessary to extract\nsome rules from drill curves that have time as index (see Figure 4.2). The bit can be considered on\n87\nbottom if the measured bit depth (DBTM) is equal to hole depth (DMEA). The measurement of drill flow rate enables to determine if the circulation is present (second condition). The recording of drillstring rotation indicates if the drillstring is rotating or not (third condition). The necessary conditions to identify the effective drilling operations are summarized in the Table 4.6. These rules are simple, and have not the purpose to identify some drilling situations, such as ream and wash or run in hole/out of hole. To overcome noisy data, thresholds e for each condition are employed. A visual approach was employed to determine the values of these thresholds, which is presented in the Appendix D.\nTable 4.6 - Rules to determine drilling modes for real-time drilling data in time domain\nMode\tNecessary Conditions\t\n\tAccording to Mathis et al. (2007)\tImplementation\nRotary Drilling\ti)\tbit on bottom ii)\tcirculating present iii)\tdrillsting rotating\ti)\tDBTM - DTMEA &lt;\u00a31 ii)\tFlow > \u00a32 iii)\tRPM > e3\nSliding Drilling\ti)\tbit on bottom ii)\tcirculating present iii)\tdrillsting not rotating\ti)\tDBTM - DTMEA &lt;\u00a31 ii)\tFlow > \u00a32 iii)\tRPM &lt;\u00a33\nSource: own authorship.\nBased on the rules from the Table 4.6, the drilling data is split into three groups: rotary drilling, sliding drilling, and not-drilling. In addition to these three states, another important state is added, namely the \u201ctransient\u201d. The transient state is a fine tuning of indexes obtained by the automated operation recognition. Two rules are employed to define a transient state. The first one considers as transient state those observations near to the operational limit for the block position. Let BPOS denote the block position and e4 the limit for the block position. If the block position BPOSi of the i-th observation lies out of the interval [min(BPOS) + e4, max(BOPS) \u2014 e4], then this observation is considered a \u201ctransient state\u201d.\nAnother rule employed to recognize transient state is the following: if a change from not-drilling to drilling state is encountered, then a transient state is identified. A transient state from this change is only computed if the ROP value for the not-drilling state is bellow a threshold (5 m/h). When a change is confirmed, the drilling state for the next observations is considered as transient, as illustrated in Figure 4.4. The current work considers a period of 2 minutes for the transient state. The Appendix D details the transient state recognition, explaining some decision made.\n88\nFigure 4.4 - After a change from not-drilling to rotary drilling, the transient state is identified.\nchange\nnot-drilling\trotary drilling\n(a) abrupt change\nchange\nnot-drilling\ttransient\trotary drilling\n(b) transient state identified\nSource: own authorship.\n@ Validate Drill Curves\nEven treating outliers and missing values, invalid observations may still be in recorded data. It is physically not possible to have ROP above zero when WOB is null (GANDELMAN,\n2012). Therefore, invalid observations will be discarded in the final step of the data pre-treatment. Two rules are employed to check whether and observation is valid or not:\nFirst rule: if ROP > 0 and WOB &lt;0 then, the observation is invalid.\n(4.3) Second rule: if WOB > limit then, the observation is invalid.\nBoth rules are checked independently. The second rule avoids too high values of WOB. In the case of Norway, the WOB is considered too high if WOB is above 45 ton. For the dirll curves from pre-salt region, the adopted threshold is 100 klbf; Gandelman (2012) mentioned a limit of 90 ton for the WOB. The Appendix E illustrates the impact of validation process on the resulting drill curves.\n4.2.2\tTraining the Predictive Models\nAfter the data pre-treatment process, we can train predictive models for the drilling\nperformance parameters. For that, we employ a common approach of splitting at random the\noriginal dataset into two others datasets, not overlapping each other. One is called training\ndataset, and another called testing dataset. The predictive models for drilling performance\n89\nindicators (ROP or SE) are trained on the training dataset. Then, the generalization capability of the obtained model is assessed on the testing dataset.\nWe chose mainly random forests to train the predictive models, because of two reasons. The first one is their good capability to model real-world problems (BREIMAN, 2001a), as well as problems tailored to drilling engineering (HEGDE et al., 2017; HEGDE; GRAY, 2018; SOARES; GRAY, 2018). The second reason is the code simplicity of not having to normalize the drill-curves, i.e. bring all variables to the same scale. Normalization is required for other state-of-art machine learning methods, such as artificial neural networks, support vector machines. Strobl et al. (2007) reported an problem of random forests when having variables in different scales. This leads to biased feature importance measures, which, however, can be solved by employing bootstrapping samples without replacement.\nThere are two different functions in Matlab to train ensemble learners based on tree-models. One function is TreeBagger, resulting in an object with the same name. Another function is fitrensemble, that can generate three objects (called \u201cSuperclasses\u201d).\nThe use of TreeBagger enables to implement either bagged trees or random forests. In addition, the use of this class enables to implement a probabilistic prediction with the function quantilePredict (MATHWORKS, 2018c). This function is based on Quantile Regression Forest proposed by Meinshausen (2006).\nAnother function from Matlab that implements ensemble learners for regression problems is the function fitrensemble. With that, three objects (\u201cSuperclasses\u201d) can be obtained (MATHWORKS, 2018d):\n\u2022\tRegressionBaggedEnsemble - it implements either bagged trees or random forests, but probabilistic prediction is not possible to be carried;\n\u2022\tRegressionEnsemble - it implements gradient boosting machines with the algorithm least-squares regression (LS_Boost) from Friedman (2001);\n\u2022\tRegressionPartitionedEnsemble - it assess the generalization error capability for the previous algorithms with cross-validation process.\n4.2.3\tEvaluation Metrics\nThe current study employs the following metrics to assess the generalization capability of the learned models: R-squared, root mean squared error (RMSE), mean squared error (MSE), mean absolute error (MAE), and mean absolute percentage error (MAPE). There are several other metrics to evaluate regression machine learning models; the work from Botchkarev (2018) serves the basis for this section.\n90\nThe Pearson\u2019s correlation coefficient can be estimated by (GUYON; ELISSEEFF, 2003):\nR =\nn\ny\ni=1\nnn\n^(yi- y)2^(yi- y)\n-i=1\ti=1\n1/2\n(4.4)\n2\nwhere y is a vector n elements, representing the actual value (e.g. ROP measured values), yi is the actual value of the element i from the vector y. The mean of y is given by y = ^21 Vi/n. The predicted value for i-th observation is y^, and y V1 yi/n represents the mean of the predicted vector y.\nThe squared of correlation coefficient R (equation 4.4) can be also employed as evaluation metric. It is also common to compute the R-squared based on a different formula, as done for example by Nascimento et al. (2015b). Botchkarev (2018) called this other form to compute the R-squared as \u201ccoefficient of determination\u201d.\nThe mean squared error (MSE) is calculated as the mean of squared sum of residuals:\n1 n\nMSE = -V(y - yi)2\t(4.5)\nn\nThe root mean squared error (RMSE) can be calculated as the square root of MSE:\nRMSE = y/ MSE\t(4.6)\nThe mean absolute error (MAE) expresses the mean of absolute residuals between the predict yi and the actual yi:\n1n\nMAE =-V |y - yi|\t(4.7)\nn\ni=1\nHegde et al. (2017) evaluated the predictive ROP models with another metric, called normalized error rate. Botchkarev (2018) presented several metrics that compute relative error. One of them was the mean absolute percentage error (MAPE), defined as:\nMAPE = \u2014 V |yi - yi|\t(4.8)\nn\tvyA\nOne problem may occur when using relative metrics, such as the MAPE. Let us suppose\nan variable within a common range for the ROP values, i.e. from 0 to 50m/h. It is possible to\nexist an valid observation whose actual value is near to zero, e.g. 0.01m/h. If the predictive\nmodel estimates an value of 0.10m/h for this observations, the absolute error is 0.09m/h. This\ncan be considered either an good prediction or very bad estimation, depending on the metric\nemployed. In terms of absolute difference or means squared error, this difference is small, so that\n91\nthe predicted output can be considered as an good estimation, since the model could estimate an output also near to zero. However, in relative term, the predicted value is ten times higher then the actual value, and the relative absolute difference is MAPE = (|0.10-0.01|/0.01)*100 = 900%.\nThis problem happened, especially, for the drill-curves from Norway, since the data pre-treatment process is not failure free. For example, the drilling data for Well 5 had some observations considered as valid and belonging to rotary drilling state whose ROP values were around 10-9m/h. For such values, it is very likely to obatin very high relative errors. Since the MAPE is an mean metric, even an small quantity of outliers can corrupt this metric; the problem of mean statistics is better discussed in the work from Leys et al. (2013). As an alternative, a simple way to overcome this problem is to compute the MAPE if, only if, the actual value is above an threshold. In the Figure 4.5, we illustrate the influence of the threshold on the MAPE. We observed that not considering actual values below to 0.1m/h, the adjusted MAPE was around 106 smaller than the original MAPE, resulting in an useful metric.\nTo generate the Figure 4.5, we first employed the data pre-treatment process, using the same setting of thresholds employed in the development of the results (see Chapter 5). Then, we trained a random forest with 100 trees to predict the ROP. The learning process occurred on half of observations from the data set drew at random, leaving out other 50% of observations to assess the generalization capability. Four inputs were employed in obtaining this predictive model, namely the depth, drillstring rotary speed, weight on bit and torque. The MAPE was calculated on the training dataset and the testing dataset.\nIn the current work, when we use the adapted MAPE, a subscript, a, is added to the acronym, resulting: MAPEa.\nFigure 4.5 - MAPE against the cut-off threshold, which enables to avoid the problem of small values in computing this relative metric.\nSource: own authorship.\n92\n4.2.4\tHyperparameters Optimization\nAs discussed in the Section 2.2.7, ensemble models have several internal parameters (called hyperparameters) that influence on the prediction performance. In order to tune the hyperparameters, some possible approaches are: grid search, random search or Bayesian optimization. The function fitrensemble has already implemented these optimization methods.\nThe TreeBagger function has not an optimizer implemented. In this case, an algorithm needs to be developed in order to tune the hyperparameters. The Code 4.2 is an example of optimization of two hyperparameter of a random forest: \u2018numPTS\u2019 (the amount of variables to be randomly split) and the depth of the trees in the forest, given by the fields \u2018minLS\u2019 (minimum leaf size). For that, two objects from optimizableVariable class are created, and gathered in the single variable \u2018hyperRF\u2019. Then, the Bayesian optimization function is called. The bayesopt function attempts to minimize the function handle oobErrorRF, that returns the out-of-bag mean-squared-error. In this case, the acquisition function of Bayesian optimizer is expected-improvement-plus. The readers may refer to works from Snoek, Larochelle and Adams (2012), Gelbart, Snoek and Adams (2014) for more details about the acquisition functions.\n93\nCode 4.2 - Example of hyperparameters tuning with Bayesian optimization for the\nTreeBagger object. Adapted from Mathworks (2018e).\n1\t% complexity (depth) of the trees in the forest\n2\tminLS = optimizableVariable('minLS', [1,30], 'Type', 'integer');\n3\n4\t% the number of predictors to sample at each node\n5\t% where 'numInputs' is the amount of inputs selected\n6\tnumPTS = optimizableVariable('numPTS', [1,numInputs-1], 'Type', 'integer');\n7\n8\t%% 2x1 array OptimizableVariable objects\n9\thyperRF = [minLS; numPTS];\n10\n11\t%% Calling bayesopt to optimize the function handle '@oobErrorRF'\n12\tBayOpt = bayesopt(@(params)oobErrorRF(params,...\n13\tnumTrees,...\n14\tdataTrain,...\n15\ty),...\n16\thyperRF,...\n17\t'AcquisitionFunctionName', 'expected-improvement-plus\n18\t'Verbose',0);\n19\n20\t%% Defining the Objective function\n21\tfunction oobEr = oobErrorRF(params, numTrees, dataTrain, y)\n22\t%\tINPUTS:\n23\t%\t-\tparams: class of\toptimizableVariable\n24\t%\t-\tnumTrees: number\tof trees of the random\tforest\n25\t%\t-\tdataTrain: a table having X and Y variables\n26\t%\t-\ty: a string with\tthe y-variable name\n27\t%\tOUTPUT:\n28\t%\t- oobEr: mean squared error for out-of-bag observations in the ...\ntraining data\n29\trandomForest = TreeBagger(numTrees, dataTrain,y,...\n30\t'Method','regression',...\n31\t'OOBPrediction','on',...\n32\t'MinLeafSize',params.minLS,...\n33\t'NumPredictorstoSample',params.numPTS);\n34\toobEr = oobError(randomForest,'Mode','ensemble');\n35\tend\n4.2.5\tFeature Selection\nTwo approaches are employed in the current work to select the most important drilling variables to predict the performance indicators (ROP and SE). One method is so-called \u201cdrillerapproach\u201d, which tries to mimic how an expert driller would train predictive models for drilling parameters. In this case, the driller selects as inputs those drilling variables that he believes to be the most important to model (e.g. the ROP). Another approach employs evolutionary optimization algorithm to determine the best combination of drilling variables.\nTo develop the current work, there are some essential variables, because, without them it, is not possible to train predictive models for ROP nor SE for drilling optimization tasks (see Table 4.7). The bit hydraulic plays an important role in drilling process, but it is possible to carry\n94\nout the current study without them. Other information, such as vibration or rock strength, can provide important insights, such the estimation of rock strength. However, we believe that such recordings are not as essential as the surface parameters, since we aim to develop methods to optimize the WOB and rotating speed.\nTable 4.7 - Drilling parameters required for the development of the current work.\nDrilling Parameter\tImportance\nROP and mechanical parameters (WOB, RPM, Torque)\t\u2022 \u2022\u2022 essential\nhydraulic parameters (mud weight, mud flow, annular pressure)\t\u2022 \u2022O important\nvibration (e.g. stick-slip) and geological formation (e.g. p-wave velocity, which enables to compute the rock strength properties - UCS)\t\u2022 OO complement\nSource: own authorship.\n4.3\tDRILLING PARAMETERS OPTIMIZATION\nThe goal of the current work is to find the optimum magnitude of controllable drilling variables, especially the bit weight and rotating speed. For that, trained models of so-called performance indicators (e.g. rate of penetration or specific energy) are employed as objective function(s), either in single-objective optimization framework or in multi-objective optimization. First we present the single-objective optimization problem adopted in the current work, followed by the multi-objective optimization. A total of four optimization problems are studied, two in a single-objective optimization framework and other two in a multi-objective optimization framework\n4.3.1\tSingle-Objective Optimization\nWe saw in the review Chapter 3 that most of the cited works formulated single-objective optimization problems for drilling optimization studies, using the maximization of rate of penetration as the objective function. In the current work, we investigated also the minimization of specific energy, formulating the following problems:\n\u2022\tthe first optimization problem consists of maximizing the rate of penetration;\n\u2022\tthe second optimization problem consists of minimizing the specific energy.\nFor both cases, we assessed the influence of optimizing the drilling variables not only on\nthe objective function itself, but also on the another function. For example, if the problem is set\nas maximization of rate of penetration (ROP), we assessed the improvement of ROP and also the\ninfluence of maximizing ROP on specific energy.\n95\n4.3.2\tMulti-Objective Optimization\nSince optimizing solely ROP can decrease the drilling efficiency, one reasonable way to optimize the drilling variables is to consider also the concept of specify energy, as done by Gandelman (2012), Hegde and Gray (2018). The current work analyzed two multi-objective optimization problems based on the \u25a0-constraint technique, as explained in next sections.\n4.3.2.1\tThird optimization problem\nThe third optimization problem considers also both functions, ROP and SE. The multiobjective optimization problem was formulated based on the \u25a0-constraint technique, as follows:\nmin SE(x)\n(4.9) s.t. ROP(x) > ROPactuai * \u25a0\nwhere x is a vector from the searching space (i.e., WOB and RPM) subject to .r'mn &lt;xi &lt;x i = {1, 2} , ROP(x) is the estimated ROP-value for any x, ROPactual is the actual ROP-value, and \u25a0 determines the magnitude of acceptable predicted-ROP. If \u25a0 > 1, we seek to decrease SE and, at the same time, improve the ROP. If \u25a0 = 1, the optimum pair of WOB and RPM is the one that can reduce the SE-value, maintaining the drill rate. If \u25a0 &lt;1, the minimization of SE accepts an decrease in ROP.\nIt is not expected, for some observations, that both objectives can be achieved (improvements in ROP and drilling efficiency) at the same time. If we employ only \u25a0 > 1, not every observation will have an optimum solution. Therefore, the following stepwise algorithm was proposed:\na)\tfirst, an optimum solution is determined as the one that can improve the drilling efficiency and ROP at the same time. In this case, we have a > 1;\nb)\tif there is no optimum solution that satisfies the previous condition, then it is accepted that minimization of SE resulted to, at least, the same ROP-value. In this case, we have\nb = 1;\nc)\tif there is still no optimum solution, then an decrease in ROP is accepted, i.e.,\t&lt;1.\nThis algorithm requires suitable values for the a and ec. The sensitive analysis, carried\nout in the next chapter 5, helped us in determining these values.\n4.3.2.2\tFourth optimization problem\nThe fourth optimization problem considers also both functions, ROP and SE. The multi-\nobjective optimization problem was formulated based on the \u25a0-constraint technique, as follows:\n96\nmax ROP(x)\ns.t. SE(x) &lt;SEactuai * e\n(4.10)\nThe main goal of this problem is to optimize the ROP. If e &lt;1, it is desired to improve the ROP and, at the same time, improve the drilling efficiency, expressed by decrease in SE-value. If e =1, the optimum pair of WOB and RPM is the one that can increase the ROP, maintaining, at least, the SE-value. If e > 1, maximizing ROP accepts an decrease in drilling efficiency, expressed by higher SE-values.\nIf we employ only e &lt;1, not every observation will not have an optimum solution. Therefore, the following decision workflow was proposed:\na)\tfirst, an optimum solution is determined as the one that can improve the ROP and SE at the same time. In this case, we have Ea &lt;1;\nb)\tif there is no optimum solution that satisfy the previous condition, then it is accepted an improvement in ROP, maintaining, at least, the SE-value. In this case, we have Eb = 1;\nc)\tif there is still no optimum possible solution, then an decrease in drilling efficiency is accepted, i.e., ec > 1.\n4.3.3\tGrid-Search Strategy\nSeveral techniques can be employed to search the optimum solution in the decision space. Gandelman (2012) investigated two approaches: one was a grid search in combination with if-then rules, and another the particle swarm optimization (PSO). Hegde, Daigle and Gray (2018) have recently investigated several optimization techniques for the problem of maximization of ROP, including: eyeball method, random search, simplex (amoeba) method, differential evolution, and PSO.\nThe current work employed the approach of grid search, as explained in the following paragraphs. The implementation of this approach is simple, but it can be very expensive in terms of computational costs, depending on how fine is the adopted grid.\nLet us consider a optimization problem with only one variable to be optimized, denoted by x. Let us suppose the variable x is continuous, and this variable must lay within the interval [xmin, xmax]. If we split this interval with k-grid points, the amount of possible values of x are k + 2. In this case, the searching space X is defined as\nX G {x1,x2, ... ,xn}\n(4.11)\nwhere n = k + 2, x1 = xmin. If the grid is uniform, i.e., equidistant grid points, any element x,\n97\nfrom X can be obtained as following:\nxi \u2014 xmin\t* s\n(4.12)\nwhere i = {1, 2,..., n} and s denotes \u201cstep\u201d, which can be calculated s = (xmax-xmin)/(k+1).\nThe Figure 4.6 illustrates an generic variable x with k = 4 equidistant grid points.\nFigure 4.6 - Equidistant grid points between lower and upper limits of an variable x.\nstep\nki\tk2\tk3\tk4\nxmin X1\txmax x6\nX2\tX3\tX4\tX5\nSource: own authorship.\nIf more variables need to be optimized, the searching space of each individual variables can be split in any k grid points. Then, it is possible to create all combinations of all variables to be optimized. If j represents the amount of variables to be optimized and all variables have the\nsame value of k grid points, the amount of points in the search space becomes (k + 2)j. In the\ncurrent work, we employed k = 98, resulting in 104 possible combinations of WOB and RPM to be assessed, for each observation.\n4.3.4\tOptimization Workflow\nThe current work developed the optimization problems, aiming to investigate different approaches for decision-making. To speed up the simulations, the investigation of several combinations of WOB and RPM on objectives functions, e.g. ROP and SE, was carried out apart from the decision making. The Figure 4.7 illustrates the employed workflow employed in the optimization studies. First, the influence of several pairs of WOB and RPM on the ROP and Torque (if available) based on predictive models were computed. Then, the predictive values of ROP and torque in combination with pairs of WOB and RPM were used as inputs in SE-formulation. This process was done for each observation, resulting in matrixes (k +\n2)j x observations. For some cases, the obtained matrixes had the magnitude of 104x104. After obtaining such matrixes, they could be used to assess different optimization problems, speeding up this step, since it was not required anymore to map again how decision space influenced on objective space (ROP and SE).\nThe downside of this approach is the difficulty in assessing the computational effort. It\ncould be possible to check the elapsed time required to generate the matrixes of ROP, Torque\nand SE. However, a more realistic measure of simulation time can be achieved by checking\nelapsed time during the whole optimization process: from training the predictive models to the\ndecision-making algorithm, passing through the search step and evaluation on the respective\nobjective functions.\n98\nHowever, assessing the computational effort was not the main goal of the current work. Instead, the main goal was to assess different ways to formulate drilling optimization problems. Therefore, the described workflow was adopted.\nFigure 4.7 - Optimization workflow adopted in the current work.\nGrid-search\nDecision-making\nROP (WOB,RPM) predictive model\nTorque (WOB,RPM) predictive model\nSE (WOB, RPM, ROP, Torque) coupled-model\nA\nSingle-objective optimization problem\n>\nMulti-objective optimization problem\nJ\nSource: own authorship.\n99\n5\tRESULTS AND DISCUSSION\nThis chapter presents the results, starting with the analysis for predictive models of the so-called drilling performance indicators, namely the rate of penetration and the specific energy. Then, this chapter covers the use of these predictive models in a real-time optimization of controllable drilling variables.\n5.1\tRATE OF PENETRATION PREDICTION\n5.1.1\tData Pre-Treatment Setting\nThe data pre-treatment method, presented in Section 4.2.1, was the first step prior to building the predictive models. The parameters for the data pre-treatment used in the further analysis are listed in the Table 5.1. The hampel filter parameters were determined based on the influence of them on the amount of the detected outliers, and its influence on the missing values (see Appendix C). The Appendix D illustrates the analysis performed to determine the threshold for the automated operation recognition. The Appendix E illustrates the importance of validation of observations (the last step of the data pre-treatment).\nTable 5.1 - Data pre-treatment setting\nParameter\tValue\tUnit\nHampel\t\t\nNumber of Neighbors\t5\t-\nThreshold\t3\t-\nOperation Recognition\t\t\n\u00a3i - bit on bottom\t0.15\tm\n\u00a32 - circulation\t100\tlpm\n\u00a33 - drillstring rotating\t10\trpm\n\u00a34 - transient (lower and upper limit for the block position)\t0.5\tm\ntransient period - after a change from not-drilling to rotary drilling\t2\tmin\nValidation\t\t\n2nd rule for Norway\t45\tton\n2nd rule for Pre-Salt\t100\tklbf\nSource: own authorship.\nThe Table 5.2 gives an overview of the amount of observations resulted from the data pre-treatment process, highlighting the automated operation recognition step and the validation step. The data pre-treatment for the Well 1 from Norway resulted in a small dataset. For this\n100\nreason, this dataset will not be considered any more for the following analysis in the current work.\nSome drill-curves from Pre-Salt, namely the Wells A and D, were employed partially. For the Well A, we will use the drill-curve from the section from 4 127 m to 4 185 m in the following analysis, discarding the drill-curves from the previous run. For the Well D, a data transmission loss occurred at the final of dataset. As consequence, we will not consider the final section of this dataset from here on. These observations are better explained in the Appendix B.\nTable 5.2 - Amount of observations for each well from the original dataset to the final dataset after the data pre-treatment.\nWell\tOriginal\tOperation Recognition\t\t\t\tNot Valid\t\tFinal\tSelected?\n\t\tRotary\tSliding\tTransient\tNot-Drilling\t1st rule\t2nd rule\t\t\t\nPre-Salt\t\t\t\t\t\t\t\t\t\nA (a)\t1 326\t-\t-\t-\t-\t860\t0\t466\t/\nB\t509\t-\t-\t-\t-\t0\t0\t509\t/\nD (b)\t927\t-\t-\t-\t-\t0\t0\t927\t/\nH\t5 184\t-\t-\t-\t-\t140\t0\t5 044\t/\nNorway\t\t\t\t\t\t\t\t\t\n1\t5 973\t204\t2 483\t313\t2 973\t160\t0\t44\tX\n3\t10 933\t5 561\t911\t727\t3 734\t0\t23\t5 538\t/\n4\t13 659\t7 499\t140\t1 167\t4 853\t26\t21\t7 452\t/\n5\t20 210\t3 623\t7 279\t826\t8 482\t126\t20\t3 477\t/\n6\t14 737\t6 278\t2 337\t1 266\t4 856\t78\t104\t6 096\t/\n7\t32 837\t10 940\t766\t2 479\t18 652\t646\t193\t10 101\t/\n8\t17 107\t4 724\t6 245\t700\t5 438\t24\t0\t4 700\t/\n9\t5 013\t3 057\t0\t507\t1 449\t9\t0\t3 048\t/\n10\t14 417\t8 253\t0\t854\t5 310\t27\t0\t8 226\t/\nthis dataset will be partially considered, i.e., only the section from 4 127 m (depth) to 4 185 m will be used. (b) Drill-curves for this dataset will not be considered after the depth of 4 537 m. See Appendix B for more details. For both cases, the amount of observations at the final stage from data pre-treatment is smaller than appeared in this table.\nSource: own authorship.\n5.1.2\tSimple Comparison between ROP Models\nAs seen in the Chapter 3, the use of machine learning results in more accurate ROP models\nthan those ROP models obtained by the traditional models (analytic equations). In this section,\nwe compared a well-known ROP model proposed by Bourgoyne and Young (1974) with a\ndata-driven model, learned from historical drilling data.\nNascimento (2016) predicted the ROP for the first run of Well B, based on the following\nmodels: Cunningham, Maurer and Bourgoyne &amp; Young. The last model could better fit the drill-\n101\nTable 5.3 - Simple comparison between the Bourgoyne and Young Model and a random forest regression for ROP prediction, using the drilling data of the Well B. The standard deviation is given in parentheses.\nWork\tTrain\t\t\t\t\tTest\t\t\t\n\tMAPE (%)\tMAE\tMSE\tOOB\tR\tMAPE (%)\tMAE\tMSE\tR\nNascimento (2016)\t\t\t\t\t\t\t\t\t\nBYM\t36.5\t-\t-\t-\t-\t-\t-\t-\t-\nBYM Optimized\t23.1\t-\t-\t-\t-\t-\t-\t-\t-\nCurrent Work\t\t\t\t\t\t\t\t\t\nRandom Forest\t10.5\t0.272\t0.158\t0.335\t0.911\t15.5\t0.404\t0.339\t0.776\n\t(0.4)\t(0.013)\t(0.013)\t(0.028)\t(0.008)\t(0.8)\t(0.023)\t(0.055)\t(0.029)\nSource: own authorship.\ncurves. In additional, the author proposed some adjustments for the Bourgoyne &amp; Young model, adapting this model for pre-salt region. Among other adjustments, the author employed a wider coefficients ranges. As consequence, the relative error decreased from 36.52% to 23.1%. There is no mention about leaving out any part of this dataset to assess the generalization capability. Therefore, we classified the reported relative errors as training errors, since the relative errors were calculated on observations employed to build the predictive models.\nThe ROP model based on Bourgoyne &amp; Young without adjustments from (NASCIMENTO, 2016) enables to perform the following comparison, as seen in the Figure 5.1. Here, we compared the Bourgoyne &amp; Young model obtained in that work with a random forest regression, using only four variables as inputs: depth, surface weight on bit, drillstring rotary speed and total flow rate of all active pumps. The number of variables selected at random for each decision split was changed from the default condition (one third of number of inputs, i.e. one variable) to two. After leaving out a random 50% of observations, we trained random forests with 100 trees on the remaining 50%, and used the left-out 50% as a test set. We repeated this procedure 100 times, and at each time with a different data partition, but maintaining the 50-50 data partition. We computed the average of training and testing errors for each well, as well as the standard deviation (values shown in parentheses). The results are presented in the Table 5.3.\nThe current work employes a systematic data pre-treatment before analyzing the drillcurves. In the work from Nascimento (2016), the data cleanness process was not detailed. Therefore, we called this comparison as a simple one, since this difference in data pre-treatment may be a source of bias. However, in this simple comparison, we observed a better estimation capability of the machine learning algorithm over the Bourgoyne &amp; Young model to predict the ROP, as expected according to the literature review (see Chapter 3). Another advantage was the better accuracy obtained with simpler ROP models in terms of amount inputs, since we\n102\nemployed only four inputs to train random forests, which are easily accessible in drill rigs.\nFigure 5.1 - Comparison between ROP Models\nDepth-based inters al [in]\nROP field\nROP modeled\n(a)\tBourgoyne and Young model not optimized\n3420\t3430\t3440\t3450\t3460\t3470\t3480\t3490\t3500\t3510\nDepth (m)\n(b)\tRandom Forest - Training Set\nSource: a) Nascimento (2016); b-c) own authorship. To plot the regression between the actual ROP and the predicted ROP, we have employed the function dscatter developed by Eilers and Goeman (2004).\n5.1.3\tSelection of Most Important Inputs in the Prediction Task\nSome works detailed the process of selecting inputs in the task of ROP prediction (ANE-MANGELY et al., 2018; ESKANDARIAN; BAHRAMI; KAZEMI, 2017; HEGDE et al., 2017).\n103\nIn the current work, three experiments based on different strategies were carried out. The goal was to investigate the selection of the most important drilling parameters, as following:\na)\tExperiment 01 - the driller\u2019s approach with only four inputs which are easily accessible in drill rigs (e.g. depth, weight on bit, rotary speed, total flow rate);\nb)\tExperiment 02 - the previous surface variables, plus two more variables (e.g. pump pressure);\nc)\tExperiment 03 - binary genetic algorithm, where all drilling variables are possible candidates to model the ROP.\nIt is important to note that the rock strength was not considered in ROP modeling, as Hegde et al. (2017) did by estimating UCS with log-curves. Estimating this parameter was not possible due to lack of sonic-logs in the drill-curves employed in the current work. However, Bilgesu et al. (1997) showed the possibility of prediction the ROP without any parameter related to the drilled formation (e.g. formation abrasiveness and drillability) or to bit status (e.g. bit tooth, bearing wear). Therefore, omitting the information of bit status and formation does not invalidate the current work.\n5.1.3.1\tDriller\u2019s Approach\nThe first two approaches are called here as driller's approach, because it tries to mimic an expert driller dealing with the task of ROP modeling. In this case, the driller, based on his knowledge, selects the inputs which he believes to be the most important drilling parameters for ROP modeling. Here, it is important to note that such expert could select as many as possible variables to model the ROP due to the complex nature of drilling. However, in our experiments, the driller would be encouraged to do the opposite, i.e., to add as few as possible variables, being able to exclude even the very important parameters, such as the drillbit type or rock strength. To convince him, the work from Bilgesu et al. (1997) would be of a great value.\nTwo experiments were carried out based on this approach. The Experiment 01 one employed only four inputs, which are easily accessible in drill rigs. In the Experiment 02, we employed six inputs, by adding two more variables to the selected inputs from the Experiment 01. The variables selected in these experiments are listed in Table 5.4.\nFor both experiments, the configuration of random forests was the same. The number of variables to be selected at random for each decision split was set to two. We trained random forests with 100 trees on 80% of observations selected at random. The left-out 20% was used as a test set. We repeated this procedure 100 times for each well, splitting randomly the drilling data into training and testing dataset at each time, but maintaining the same 80-20 proportion. Then, we averaged the training and testing errors, computing also the standard deviation. For clarity, only the average values of metrics on the testing dataset are shown in the Table 5.5. We performed a paired-sample T-Test for each metric in order to determine whether adding\n104\ntwo extra-inputs improved the generalization capability or not. A significance level of 1% was considered.\nTable 5.4 - Inputs selected for each experiment. The inputs of the Experiment 02 consist of adding the listed variables to the group of the Experiment 01.\nWell\tExperiment 01 4 inputs\tExperiment 02 Adding two more inputs\nPre-Salt\t\t\nA\tDepth, SWOB, RPM, TFLO\tECD, SPPA\nB\tDepth, SWOB, RPM, TFLO\tECD, SPPA\nD (a)\tDepth, SWOB, CRPM\tECD, SPPA\nH\tDepth, SWOB, RPM, TFLO\tECD, SPPA\nNorway\t\t\n3-10\tDMEA, WOB, RPMA, TRQ\tHKL, BPOS\n(a) the measurement of TFLO, total flow rate, is not available. Therefore, it was leaft out. Source: own authorship.\nTable 5.5 - Average of evaluation metrics for ROP prediction on testing dataset.\nWell\tExperiment 01\t\t\t\tExperiment 02\t\t\t\n\tMAPEa\tMAE\tMSE\tR\tMAPEa\tMAE\tMSE\tR\nPre-Salt\t\t\t\t\t\t\t\t\nA\t0.111\t0.150\t0.042\t0.938\t0.115 \u00ab\t0.152 \u00ab\t0.040 -\t0.942 \u00ab\nB\t0.136\t0.353\t0.254\t0.839\t0.147 X\t0.385 X\t0.297 X\t0.808 X\nD\t0.154\t0.564\t0.677\t0.979\t0.178 X\t0.701 X\t1.014 X\t0.971 X\nH\t0.210\t0.628\t1.147\t0.980\t0.218 X\t0.663 X\t1.230 X\t0.978 \u00ab\nNorway\t\t\t\t\t\t\t\t\n3\t0.405\t2.995\t27.383\t0.934\t0.336 /\t2.819 /\t24.455 /\t0.942 /\n4\t0.082\t1.890\t11.634\t0.948\t0.089 \u00ab\t1.791 /\t10.689 /\t0.953 /\n5\t0.612\t4.596\t53.436\t0.896\t0.411 /\t4.003 /\t41.904 /\t0.919 /\n6\t0.057\t1.065\t6.053\t0.935\t0.055 \u00ab\t1.001 /\t5.480 /\t0.942 /\n7\t0.121\t1.111\t7.188\t0.978\t0.133 \u00ab\t1.061 /\t6.272 /\t0.981 /\n8\t0.086\t0.759\t3.095\t0.971\t0.093 X\t0.731 /\t3.112 \u00ab\t0.971 \u00ab\n9\t0.539\t8.443\t149.324\t0.895\t0.465 \u00ab\t8.119 /\t137.677 /\t0.905 /\n10\t0.235\t1.604\t8.516\t0.944\t0.207 /\t1.411 /\t7.063 /\t0.954 /\nThe symbols /, X, \u00ab mean, respectively, that the Experiment 02 resulted in a better prediction of ROP than the Experiment 01, worst, or not statistically different. Tests performed at the 1% significance level. Source: own authorship.\nIn order to understand the paired-sample T-Test, we plotted histograms of R-correlation on testing dataset, comparing both experiments against each other, as seen in the Figure 5.2. The\n105\npaired-sample T-Test enables to statistically determine whether adding two extra-inputs improved the generalization capability or not. For the case of Well D, adding two more inputs resulted in worst generalization capability according to the selected metric. In this case, the p-value was 3.4169e-24, so that we could reject the null-hypothesis (the sample\u2019s mean of Experiment 02 was not less than the sample\u2019s mean of Experiment 01). However, the opposite occurred for the Well 10, since adding two more variables improved the model accuracy. With a p-value of 9.4259e-22, we could reject the null-hypothesis (the sample\u2019s mean of the Experiment 02 was not greater than the sample\u2019s mean of the Experiment 01).\nFigure 5.2 - Histograms of R-correlation on testing dataset.\n(a)\tExperiment 02 worst than 01\t(b) Experiment 02 better than 01\nSource: own authorship.\nThis difference illustrates the difficulty in selecting manually the inputs. While adding more variables to model the ROP for the drill-curves from Pre-Salt decreased the prediction accuracy, extra inputs improved, in most cases, the prediction accuracy for Norwegian drilling data. Therefore, it is worth investigating sophisticated techniques to determine the best combination of inputs.\n5.1.3.2\tEvolutionary Feature Selection\nIn the Chapter 2, a brief overview of some possible approaches to select the best (or a good one) subset of features was given. Here, the Binary Genetic Algorithm is employed to determine the selection of the best inputs. This method can be implemented with a Matlab function called, ga, by setting the population type to \u2018bitstring\u2019. The employed code resembles the one developed by Oluleye et al. (2014a), Oluleye et al. (2014b). In the current work, the fitness score was the out-of-bag estimation of MSE. Generally, the GA resulted in small subsets with one to three variables. Seldom, the mutation process led to an empty chromosome, i.e. without any inputs. When this case occurred, the fitness function returned an out-of-bag MSE value of 100 (much higher than the average for all wells, except for the Wells 5 and 9, which both require an even higher penalization).\n106\nTo run this simulation, random forests were employed with the same configuration from the Experiments 01 and 02, expect for the amount of weak learners, which was reduced from 100 to 30 in order to speed up the simulations. The configuration of Binary Genetic Algorithm is listed in the Table 5.6.\nTable 5.6 - Options for Feature Selection based on Binary Genetic Algorithm\nVariables\tSetting\nBinary Genetic Algorithm\t\npopulation type\t\u2018bitstring\u2019\npopulation size\t50\ngenerations\t50\nparents selection\ttournament selection with size 2\namount of elite children\t2\ncrossover function\tscattered\ncrossover fraction\t0.80\nmutation\tuniforme distribution\nmutation fraction\t0.15\nSearching Space\t\npossible features\tall inputs\nSource: own authorship.\nThe initial population was created based on an function proposed by (OLULEYE et al., 2014a), as seen in the Code 5.1. The initial step has an great impact in this evolutionary algorithm. This could be could adapted by setting a fix cut-off value instead of a random value RD, avoiding the problem of starting a population with only few inputs or too many inputs (see Figure 5.3). An alternative for RD is to set a constant values, e.g. 0.5. For this case, the expected mean for the amount of inputs selected in the initial population is the half of genome\u2019s cardinality, since the function rand generates uniformly distributed random numbers between 0 to 1. However, the current Experiment 03 employed the proposed function from Oluleye et al. (2014a) to initialize the population.\nCode 5.1 - Function to initialize the population. Source: Oluleye et al. (2014a)\n1\tfunction [pop] = PopFunction(GenomeLength,\u2014,options)\n2\tRD = rand;\n3\tpop = (rand(options.PopulationSize, GenomeLength)> RD); % Initial Population\n4\tend\n107\nFigure 5.3 - The initial population influenced by the random starting for the Well 8 and 10. For both cases, the cardinality of possible inputs was 25.\n0\t10\t20\t30\t40\t50\nGeneration\nGeneration\n(a) Well 8 - Initial population smaller than the half of genome\u2019s cardinality\n(b)\tWell 10 - Initial population higher than the half of genome\u2019s cardinality\nSource: own authorship.\nThe best subsets obtained for each well is listed in the Table 5.7. The out-of-bag errors of the optimum solution indicate a better prediction capability than those models from the Experiments 01 and 02. However, the obtained subsets are not useful, as explained in the following paragraph.\nAs can be seen in the Table 5.7, all cases have an common input related to the depth. Sometimes, similar variables related to the depth was selected in the optimum subset (the Well D is an example). Other variables which, in principle, are not directly related to the rate of penetration were selected in the optimum subset of features, e.g. the block position. In additional, it is also important to note the fact of not having anymore those variables, which are believed to be important for the ROP modeling, such as the weight on bit and rotary speed for many wells. Since a ROP model without these controllable variables does not enable to optimize them (the main objective of the current work), such subsets will not be considered in the following analysis.\nTherefore, the obtained subsets are not useful for the current work purpose. Perhaps, a\nbetter pre-selection of the possible candidates to used be as inputs in the prediction of ROP could\nimprove the subset selection.\n108\nTable 5.7 - Best subsets obtained by binary genetic algorithm.\nWell\tOptimum Subset\tAmount of Inputs\tOOB - MSE\tSimulation Time\nPre-Salt\t\t\t\t\nA\tDepth, BLKP\t2\t0.017\t258 s\nB\tDepth, BLKP\t2\t0.096\t236 s\nD\tDepth, CDEPTH, STUCK\t3\t0.255\t289 s\nH\tDepth\t1\t0.522\t983 s\nNorway\t\t\t\t\n3\tDBTM, DMEA, BPOS, RPMB\t4\t18.10\t1493 s\n4\tDBTM, DMEA, BPOS, HKL\t4\t8.65\t1 791 s\n5\tDBTM, DMEA, RPM\t3\t35.32\t910s\n6\tDBTM\t1\t2.90\t1 139 s\n7\tDBTM, DMEA, BPOS, HKL\t4\t4.73\t2 618 s\n8\tDMEA, CTVL\t2\t0.94\t954 s\n9\tDBTM, DMEA, BPOS, HKL, CTVL\t5\t98.02\t789 s\n10\tDMEA, BPOS, CTVL\t3\t3.65\t2 032 s\nSource: own authorship.\n5.1.4\tRatio Influence of Training Dataset to Overall Dataset\nHere is investigated the influence of amount of training dataset on the performance of the ROP predictive model for each well. For that, we employed the same procedure from the Experiment 01, varying only the amount of observations in the learning phase. The term train ratio denotes the relative amount of observation employed in the training phase to the overall amount of observations in the dataset. For clarity, boxplots only for the R-correlation are shown in the Figure 5.4.\nAs expected, an improvement in the ROP models accuracy was observed as more observations were available in the training phase. While some predictive models achieved good generalization capability with small values of train ratio (e.g. Well H, 7 and 8), other models required a higher train ratio (e.g. Well A and B). In general, a train ratio of 60 % or even 40 % provided an acceptable prediction accuracy.\n109\nWell-A\nFigure 5.4 - Testing R-correlation - sensitive analysis of the train ratio.\nWell-B\nWell-D\nWell-H\n1\n0.95\n0.85\nWell-3\nWell-4\nWell-5\nWell-6\nWell-7\ntrain ratio (%)\nWell-8\ntrain ratio (%)\nWell-9\ntrain ratio (%)\nWell-10\ntrain ratio (%)\nSource: own authorship.\n5.1.5\tCumulative MSE of Random Forests\nThe cumulative mean-squared error from out-of-bag observations were investigated, and shown in the graphs forms (see Figure 5.5). Such analysis enables us to quantify how the prediction performance of random forests behaves as the amount of trees increases. We observed a error-convergence at 20 trees. After that, adding more trees to random forests did not improve the accuracy of ensemble models. Therefore, it is possible to reduce the amount of trees as done when selecting the optimum subset based on binary genetic algorithm (Section 5.1.3.2) in order to speed up the simulations.\n110\nFigure 5.5 - Cumulative out-of-bag MSE for ROP-prediction: random forests trained using the same procedure from the Experiment 01.\nWell -A\nWell -B\nWell -D\n0.4\t\t1\t\t20\t\nLU \u00ab 0.2\tI\tLU 0.5\tV\tLU 10\tL\n0\t\t0\t\t0\t\n400\nLU\n200\n20\n0\n10\nLU\nCO\n0\t50\t100\nNumber of Learners\nWell -H\n0\t50\t100\nNumber of Learners\nWell -3\n0\t50\t100\nNumber of Learners\nWell -4\n\t\t200\t\t\t100\t\nI\tMSE\t100\tL\u2014\tMSE\t50\tI\n\t\t0\t1 1\t\t0\t1\n0\t50\t100\nNumber of Learners\nWell -5\n0\t50\t100\nNumber of Learners\nWell -6\nLU\n20\n40\n200\nLU\n20\nLU\nCO\n100\n0\t50\t100\nNumber of Learners\nWell -7\n40\n0\t50\t100\nNumber of Learners\nWell -8\n0\t50\t100\nNumber of Learners\nWell -9\n0\t50\t100\nNumber of Learners\nWell -10\n\t\t1000\t\t\t100\t\nI\tMSE\t500\tt\tMSE\t50\t\n\t,\t1\t\t0\t1 1\t\t0\t\n0\n0\t50\t100\nNumber of Learners\n0\t50\t100\nNumber of Learners\n0\t50\t100\nNumber of Learners\nL\n0\nJ\n0\n\n0\ntrainRatio - 40\ntrainRatio - 60\ntrainRatio - 80\nSource:own authorship.\n5.2\tSPECIFIC ENERGY PREDICTION\nAs seen in the drill-curves from pre-salts (e.g. Appendix B), the calculated specific energy was much higher than rock strength. Silva (2016) tested carbonates cores from pre-salt Santos Basin; the average rock strength from pre-salt carbonates was UCS 43 MPa. However, this difference is not necessary a problem, and the specific energy can be employed to assess the drilling efficiency. Hegde and Gray (2018, p. 399) stated, \u201cfor purposes of cost function, the value of MSE1 is not as important as the relative change in MSE in this analysis\u201d. Therefore, we can employ the specific energy as a cost function in drilling optimization, i.e., the less energy is spent, the more efficiency the formation is being drilled.\nIn the current work, we employ the acronym of SE for the concept of (mechanical) specific energy, avoiding any misunderstanding\n1\n111\nGandelman (2012) used the estimated ROP to calculate the specific energy in his study on real-time drilling optimization. Hegde and Gray (2018) employed a similar approach, but instead of coupling the SE model with only a predictive ROP model, the authors calculated the SE based on estimated ROP and estimated Torque. The main idea of the mentioned models were to compute how changes in the controllable drilling variables (e.g. WOB and RPM) would affect the ROP. Then, the SE was calculated based on estimated values of ROP with the respective new values for the inputs, by using the Teale\u2019s formulation. Hegde and Gray (2018) called the resulting SE models as \u201ccoupled-model\u201d.\nSince the specific energy is calculated on several drilling variables, it is not common to predict the SE based on exclusively data-driven models, as done for the ROP. In literature, it was not found any work trying to estimate the SE based on exclusively data-driven models. Therefore, we investigated both approaches to model the SE, namely:\n\u2022\texclusively data-driven SE models;\n\u2022\tcoupled models, such as done by Hegde and Gray (2018), Gandelman (2012).\nThe goal of the comparing both approaches, illustrated in Figure 5.6, is to determine which one is more suitable to be used in the drilling optimization problem. Before presenting the results of the predictive and coupled models, we discuss some aspects regarding specific-energy calculation in the following section.\nFigure 5.6 - Data-driven models against coupled models for SE prediction\nSource: own authorship.\n5.2.1\tCalculating SE\nWe observed that some calculated values of the specific energy, especially, for the Nor-\nwegian wells, were too high, i.e., above 1030 MPa. This happened, because the drill-curves,\nespecially from Norway, had some observations considered as rotary drilling with ROP values\n112\nnear to zero. According to Teale\u2019s formulation, a ROP-value near to zero leads to\n120 * n * RPM * Torque lim -------------------\nrop+0\tAb * ROP\n(5.1)\nAs consequence, we can say lim SE =&lt;x>, since the term ^OB is not affected directly by the ROP value.\nOne way to avoid too high SE values is to adopted a ROP-threshold. In this case, the SE is calculated only if the ROP of the respective observations is greater than or equal to a threshold. This threshold received the name of ROP-threshold. In Figure 5.7, we plotted histograms of the calculated SE, considering four levels of ROP-threshold: without threshold (0 m/h), 0.1 m/h, 0.5 m/h and 2 m/h. We observed an decrease in the maximum value of SE as the ROP-thresholds increased. Even small values of ROP-thresholds decreased substantially the maximum values of SE. This happened not only for the Well 8 illustrated in Figure 5.7, but also for other Norwegian wells. This becomes clear in Figure 5.8, where we plotted the maximum calculated SE value for each well against the respective ROP-threshold.\nFigure 5.7 - Histograms of SE calculated based on Teale\u2019s formulation, considering four levels of ROP-threshold-well 8\nSource: own authorship.\n113\nFigure 5.8 - Maximum value of SE for each well against the ROP-threshold\n10'\nio\n10\n.30 -\n10\n10\ncc CL\nIO40\nIO20\nWell8 =\nWell9 =\nWell10 F\n10\n10\n1\n5\n4\nWellA WellB WellD WellH Well3 Well4 Well5 Well6 Well7\n100\n0\n10 p o\nC/5\n<t>\n2\t3\nROP-Threshold [m/h]\nSource: own authorship.\nTo calculate the specific energy, we selected a suitable SE model for each well, respecting the availability of drilling variables present in data-sets. For example, if the torque is not available, the Teale\u2019s equation cannot be directly applied. In this case, Rabia\u2019s model or Pessier-Fear\u2019s equation are possible alternatives to be considered (see the Section 2.1.3.2 for more details). The employed SE models and drilling variables used to calculate this parameter are listed in the Table 5.8.\nTable 5.8 - Drilling variables used to calculate the SE\nWell\tSE Formulation\tVariables used\t\t\t\tROP-Threshold [m/h]\n\t\tWOB\tTorque\tRPM\tROP\t\nPre-Salt\t\t\t\t\t\t\nA\tRabia\tSWOB\t-\tRPM\tROP5\t-\nB\tTeale\tDWOB\tDTOR\tRPM\tROP5\t-\nD\tRabia\tSWOB\t-\tCRPM\tROP5\t-\nH(a)\tTeale\tSWOB\tSTOR\tRPM\tROP5\t-\nNorway\t\t\t\t\t\t\n3-10\tTeale\tWOB\tTRQ\tRPM\tROP\t0.5\nfor the Section 5.2.2, the Teale\u2019s formulation was employed for the Well H. However, for drilling optimization problems from the Section 5.3, the specific energy was estimated based on Rabia\u2019s formulation, because of the low accuracy in torque prediction for the Well H, resulting in a poor estimation for SE values. Source: own authorship.\n114\n5.2.2\tData-driven models for the Specific Energy\nThe rate of penetration and torque are integral parts of the specific energy formulation. The magnitude of these variables depends also on the controllable drilling variable(s) to be optimized (in the current work, they are weight-on-bit and rotating speed). However, a SE model without the core variables as inputs (ROP and torque) simplifies, obviously, SE modeling and the implementation of drilling optimization as well. Modeling the SE becomes simpler because we will not need to couple the SE model with other predictive models (ROP and, optionally, torque), as done previously by Gandelman (2012), Hegde and Gray (2018).\nTherefore, we tried to predict the SE based exclusively on data-driven models. We followed the same approach of ROP modeling. That is, we selected only some easily-accessible variables in drill rigs as inputs, mainly: depth, RPM, WOB, total-flow (if available). The selected inputs for each well are listed in the Table 5.9.\nWe trained random forests with 100 trees on 80% of observations drew at random, leaving out 20% to assess the generalization capability of the SE models. The number of variables to be selected at random for each decision split was set again to two. We repeated this procedure 100 times, splitting, at each time, the dataset into training and testing datasets at random, but maintaining the 80-20 partition. The average metrics of the obtained SE data-driven models were presented in the Table 5.10.\nTable 5.9 - Inputs selected for the not-coupled and coupled models to predict the SE.\nWell\tSE data-driven models\t\t\tSE Model\n\t4 inputs\t5 inputs\t6 inputs\t\nPre-Salt\t\t\t\t\nA\tDepth, SWOB, RPM, TFLO\tROP5\t-\tRabia\nB\tDepth, SWOB, RPM, TFLO\tROP5\tROP5 and Torque\tTeale\nD (a)\tDepth, SWOB, CRPM\tROP5\t-\tRabia\nH\tDepth, SWOB, RPM, TFLO\tROP5\tROP5 and Torque\tTeale\nNorway\t\t\t\t\n3-7 (a)\tDMEA, WOB, RPMB\tROP\tROP and Torque\tTeale\n8-10\tDMEA, WOB, RPMB, MFI\tROP\tROP and Torque\tTeale\nthe of total flow rate is not available. Therefore, it was leaft out. Source: own authorship.\n115\nTable 5.10 - SE prediction based on data-driven models without the core variables ROP and torque as inputs: average of evaluation metrics on train and test dataset.\nWell\tTrain dataset\t\t\t\tTest dataset\t\t\t\n\tMAPEa\tMAE\tMSE\tR\tMAPEa\tMAE\tMSE\tR\nPre-Salt\t\t\t\t\t\t\t\t\nA\t0.109\t323.286\t2.845E+05\t0.977\t0.175\t497.989\t6.364E+05\t0.951\nB\t0.097\t123.268\t2.794E+04\t0.932\t0.148\t186.958\t6.305E+04\t0.823\nD\t0.154\t623.541\t1.566E+06\t0.961\t0.225\t981.082\t3.679E+06\t0.902\nH\t0.766\t585.716\t1.355E+06\t0.948\t1.179\t855.727\t2.769E+06\t0.882\nNorway\t\t\t\t\t\t\t\t\n3\t0.126\t219.523\t1.224E+06\t0.844\t0.183\t305.845\t2.131E+06\t0.650\n4\t0.038\t30.891\t3.214E+04\t0.880\t0.057\t44.620\t5.518E+04\t0.772\n5\t0.257\t423.138\t2.966E+06\t0.865\t0.369\t596.903\t5.548E+06\t0.661\n6\t0.040\t47.247\t2.362E+05\t0.818\t0.055\t63.023\t3.498E+05\t0.670\n7\t0.050\t46.803\t1.727E+05\t0.866\t0.068\t62.466\t2.827E+05\t0.746\n8\t0.050\t138.573\t2.993E+05\t0.926\t0.076\t204.556\t6.165E+05\t0.839\n9\t0.209\t245.887\t2.532E+06\t0.920\t0.291\t333.278\t4.634E+06\t0.810\n10\t0.094\t103.920\t3.742E+05\t0.870\t0.134\t147.917\t6.812E+05\t0.709\nSource: own authorship.\nSince random forest were trained with the TreeBagger function, it was possible to estimate the mean and the uncertainty around the estimated mean. This function implements the quantile random forests regression, proposed by Meinshausen (2006). In Figure 5.9, we plotted the actual SE against the predicted mean, as well as the prediction intervals of 50% in red and 90% in blue. We used the left-out observations during the learning phase. For clarity, we selected only two wells, one from each region.\n116\nFigure 5.9 - SE data-driven models: actual SE against prediction intervals on test dataset.\n05\nD_\n103\nLU\nCO\n3510\ni\n3490\ni\n3440\n\u2022 SE Actual\nSE Predicted - mean\n\u25a0\tCl 50\n\u25a0\tCl 90\ni\n3480\ni\n3500\ni\n3430\ni i\n3460\t3470\nDepth (m)\n10\u2018\n3420\n(a) Well B\n(b) Well 10 Source: own authorship.\nWe observed a high variance of the SE values. This can be a possible reason for not\nobtaining SE models as accurate as ROP models. By comparing the R-coefficient between\ndatasets from Norway and pre-salt, we observed a better accuracy of SE models for pre-salt\nregion. Perhaps, this difference is due to the data spikes of SE values from Norwegian drill-curves,\noriginated from the automated operation recognition, increasing the calculated errors.\n117\nBefore testing the coupled SE models, we trained SE-predictive models with more inputs. The extra inputs were the core variables from SE formulation, i.e., ROP and torque. For the case of 5 inputs with only ROP as an extra input, we observed an substantial improvement in the prediction accuracy, as expected, since the ROP is an integral component of SE formulation. As consequence, having ROP as one of inputs improved the prediction of SE. We trained also SE-predictive models based on random forests by adding ROP and torque, the case of 6 inputs.\nFor both cases (5 and 6 inputs), we followed the same training and testing procedure as we did to obtain the SE models based on exclusively data-driven models with 4 inputs. For clarity, only the evaluation metrics on test datasets are shown in the Table 5.11. We analyzed through T-Test whether adding torque as input increased the model accuracy or not. While adding the torque as input improved the prediction accuracy for some cases (e.g. Well H), for other cases, it did not improve (e.g. Well 5). We observed also some indifferent results (e.g. Well 10). Therefore, a general pattern was not recognized.\nTable 5.11 - SE prediction based on data-driven models with the core variables ROP and torque as inputs: average of evaluation metrics on test dataset.\nWell\t5 inputs (with ROP)\t\t\t6 inputs (with ROP and Torque)\t\t\t\t\n\tMAPEa\tMAE\tMSE\tR\tMAPEa\tMAE\tMSE\tR\nPre-Salt\t\t\t\t\t\t\t\t\nA\t0.149\t307.494\t2.640E+05\t0.980\t-\t-\t-\t-\nB\t0.063\t80.751\t1.248E+04\t0.971\t0.065 \u00ab\t81.615 \u00ab\t1.325E+04 \u00ab\t0.971 \u00ab\nD\t0.162\t442.116\t8.338E+05\t0.981\t-\t-\t-\t-\nH\t1.060\t648.908\t1.938E+06\t0.919\t0.319 /\t278.769 /\t5.422E+05/\t0.982 /\nNorway\t\t\t\t\t\t\t\t\n3\t0.029\t54.892\t1.548E+05\t0.984\t0.032 X\t64.759 X\t2.260E+05 X\t0.979 X\n4\t0.014\t11.825\t1.511E+04\t0.959\t0.013 \u00ab\t11.930 \u00ab\t1.595E+04 \u00ab\t0.951 \u00ab\n5\t0.050\t91.643\t4.484E+05\t0.983\t0.065 X\t113.997 X\t5.211E+05 \u00ab\t0.980 \u00ab\n6\t0.016\t24.771\t2.049E+05\t0.942\t0.014 /\t21.567 \u00ab\t1.926E+05 \u00ab\t0.948 \u00ab\n7\t0.022\t15.699\t3.151E+04\t0.983\t0.017 /\t16.500 \u00ab\t4.664E+04 \u00ab\t0.977 \u00ab\n8\t0.019\t53.269\t9.179E+04\t0.983\t0.020 X\t57.075 \u00ab\t1.169E+05 \u00ab\t0.978 X\n9\t0.089\t127.231\t1.033E+06\t0.979\t0.103 X\t138.639 \u00ab\t1.072E+06 \u00ab\t0.973 \u00ab\n10\t0.041\t40.626\t5.092E+04\t0.987\t0.035 /\t38.305 \u00ab\t7.972E+04 X\t0.980 X\nThe symbols /, X, \u00ab mean, respectively, that the experiment with 6 inputs resulted in a better prediction of SE than the experiment with 5 inputs, worst, or not statistically different. Tests performed at the 1% significance level. Source: own authorship.\n5.2.3\tCoupled Models for the Specific Energy\nWe investigated the approach of coupling the SE formulation with predictive models of the core variables (ROP and torque), as done by Gandelman (2012), Hegde and Gray (2018). To be\n118\nmore specific, we investigated the calculation accuracy of SE values based on predictive models. For that, two coupled models were analyzed:\n\u2022\tSE-coupled models based on Rabia\u2019s formulation (ROP as coupling model);\n\u2022\tSE-coupled models based on Teale\u2019s formulation (ROP and torque as coupling models)\n5.2.3.1\tRabia\u2019s Model\nTwo experiments were conducted to assess the SE coupled-models based on Rabia\u2019s formulation. In the first one, the SE calculation is coupled with ROP model and, in another, coupled with inverse-ROP model (i.e. with a predictive model of ROP-1).\nAs already mentioned, the drill-curves from Norway were recorded in time domain. For this reason, a simple method to automatically identify the operations was employed in the current work. This led to some observations considered as rotary drilling operation, but with ROP values near to zero. As consequence, ROP values near to zero yielded too high SE values. For these observations, a small difference between the predicted ROP and the actual ROP can yield high difference between the actual SE (calculated on field data) and predicted SE (calculated on predicted ROP values). The Figure 5.10 illustrates that low values of ROP yielded too high residuals between the actual SE (calculated on field data) and coupled SE (calculated on predicted ROP). In the left bottom plot, we observed that a small quantity of observations with too high residuals corrupted the calculation of R-coefficient. In right bottom plot, we observed that the majority of observations had a small difference between the SE-predicted and SE-actual values.\nFigure 5.10 - Density scatter assessing the SE coupled-model based on Rabia\u2019s formulation for the Well 10 - coupling with ROP predictive-model.\nROP actual\nR = 0.58364\n6000\nLU\n4000\n2000\n0\n2000\t4000\nSE actual\n\u25a0o a o\nQ\nQ. m CZ)\nR = 0.58364\n0\t100 200 300 400 500\nSE actual\n6000\nSource: own authorship. The function dscatter developed by Eilers and Goeman (2004) was used.\n119\nFor this reason, we investigated also an alternative for SE-coupled models. The alternative consists of obtaining predictive models for the inverse-ROP, that is, ROP-1. In this case, the Rabia\u2019s formulation for the specific energy becomes:\nSEC = 2.35\n(WOB.NX \\ db )\n* ROP-1\n(5.2)\nwhere SEC denotes the SE-coupled model and ROP-1 denotes the predictive model for ROP-1.\nFor both experiments, we followed the same training and testing procedure of the previous predictive models. We trained random forests with 100 trees, with two variables to be selected at random for each node split. The predictive models were trained to estimate: (i) in the first-case the ROP, (ii) in the second case, the inverse-ROP. The selected inputs for ROP models were the same from Experiment 01 (see Table 5.4), except for Norwegian wells; we left out the torque. Then, ROP-values estimated on predictive models were used to compute the \u201cpredicted SE\u201d. We compared the \u201cpredicted SE\u201d with \u201cactual SE\u201d, calculated on the field data. Random forests were trained on 80% of observations, and the left-out 20% assessed the generalization capability. We repeated the training and testing procedure 100 times. The comparison between both approaches is presented in the Table 5.12.\n120\nTable 5.12 - Evaluation metrics on test datasets for SE coupled-models based on Rabia formulation: ROP predictive model against inverse-ROP predictive model\nWell\tCoupled with ROP model\t\t\t\tCoupled with ROP 1 model\t\t\t\n\tMAPEa\tMAE\tMSE\tR\tMAPE(a)\tMAE\tMSE\tR\nPre-Salt\t\t\t\t\t\t\t\t\nA\t0.105\t465.017\t3.882E+07\t0.952\t0.113 X\t454.044 \u00ab\t3.268E+07 Z\t0.956 \u00ab\nB\t0.128\t272.384\t1.541E+07\t0.927\t0.134 X\t265.393 \u00ab\t1.432E+07 Z\t0.929 \u00ab\nD\t0.129\t844.732\t6.484E+08\t0.919\t0.149 X\t817.526 \u00ab\t4.794E+08 Z\t0.927 Z\nH\t0.173\t1331.401\t9.487E+09\t0.931\t0.201 X\t1137.798 Z\t5.581E+09 Z\t0.952 Z\nNorway\t\t\t\t\t\t\t\t\n3\t0.092\t77.571\t2.896E+08\t0.483\t0.186 X\t91.761 X\t2.181E+08 Z\t0.665 Z\n4\t0.045\t16.321\t8.763E+06\t0.603\t0.059 X\t17.664 X\t6.589E+06 Z\t0.710 Z\n5\t0.152\t120.127\t3.752E+08\t0.451\t0.339 X\t137.996 X\t2.977E+08 \u00ab\t0.606 Z\n6\t0.031\t11.671\t3.234E+07\t0.692\t0.053 X\t15.376 X\t3.525E+07 \u00ab\t0.702 \u00ab\n7\t0.032\t12.174\t4.158E+07\t0.463\t0.064 X\t14.978 X\t3.338E+07 \u00ab\t0.579 Z\n8\t0.055\t82.992\t2.119E+08\t0.803\t0.078 X\t85.523 \u00ab\t1.501E+08 Z\t0.856 Z\n9\t0.119\t111.667\t3.589E+08\t0.383\t0.309 X\t122.419 X\t2.196E+08 Z\t0.700 Z\n10\t0.071\t57.883\t5.156E+08\t0.432\t0.138 X\t66.634 X\t3.529E+08 Z\t0.684 Z\n(a) we calculated the normal MAPE instead the adapted MAPE. In this case, the comparison between two approaches based on this parameter is not reliable. We added it only for illustration purpose.\nThe symbols /, X, \u00ab mean, respectively, that the coupling the SE models with inverse-ROP resulted in a better prediction accuracy of SE than coupling with ROP, worst, or not statistically different. Tests performed at the 1% significance level.\nSource: own authorship.\nAs seen in the Table 5.12, coupling the SE calculation with the inverse-ROP improved the R-coefficient and MSE in the majority of cases. However, the opposite happened for the MAE, i.e., the calculation of SE based on the inverse-ROP decreased the prediction accuracy. We assessed the MAPE differently for both cases: for one case we employed the adjusted MAPE and for another the not-adjusted MAPE. As consequence, a comparison between them is not reliable, and this metric was listed in the Table 5.12 only for illustration purpose.\n5.2.3.2\tTeale\u2019s Model\nSE-coupled models based on Teale\u2019s formulation requires two coupling-predictive models: ROP and torque. This approach of coupling the SE calculation with two predictive models was adopted by Hegde and Gray (2018). By doing so, the authors considered that changes in bit weight and rotating speed would influence not only the ROP, but also the torque. As consequence, varying the controllable variables (WOB, RPM and mud flow in their case) would influence on ROP, torque and SE as well.\nWe compared first the actual values of SE calculated on field data with partial-predicted values. The partial-predicted values for SE were calculated on combination of field data and\n121\npredicted values only for the parameters ROP and torque2. The same train and testing procedure from the previous sections was adopted. The SE-predictive accuracy between both formulations,\ni.e. Rabia and Teale, were compared. The results are presented in the Table 5.13. In the following section, a discussion is carried out, explaining which of SE-modeling strategies was adopted for the optimization problems.\nTable 5.13 - Evaluation metrics on test dataset for SE coupled-models: a comparison between Teale\u2019s and Rabia\u2019s formulation.\nWell\tRabia\u2019s formulation coupled with ROP\t\t\t\tTeale\u2019s formulation\t\t\t\n\tMAPEa\tMAE\tMSE\tR\tMAPEa\tMAE\tMSE\tR\nPre-Salt\t\t\t\t\t\t\t\t\nA\t0.105\t465.017\t3.882E+07\t0.952\t-\t-\t-\t-\nB\t0.128\t272.384\t1.541E+07\t0.927\t0.154 X\t211.615 /\t8.217E+06 /\t0.765 X\nD\t0.129\t844.732\t6.484E+08\t0.919\t-\t-\t-\t-\nH\t0.173\t1331.401\t9.487E+09\t0.931\t1.007 X\t1046.770 /\t4.641E+09 /\t0.812 X\nNorway\t\t\t\t\t\t\t\t\n3\t0.092\t77.571\t2.896E+08\t0.483\t0.099 X\t281.781 X\t3.322E+09 X\t0.564 /\n4\t0.045\t16.321\t8.763E+06\t0.603\t0.048 X\t42.856 X\t9.410E+07 X\t0.745 /\n5\t0.152\t120.127\t3.752E+08\t0.451\t0.155 \u00ab\t552.038 X\t5.645E+09 X\t0.566 /\n6\t0.031\t11.671\t3.234E+07\t0.692\t0.036 X\t56.448 X\t6.690E+08 X\t0.444 X\n7\t0.032\t12.174\t4.158E+07\t0.463\t0.037 X\t54.613 X\t8.077E+08 X\t0.644 /\n8\t0.055\t82.992\t2.119E+08\t0.803\t0.062 X\t223.048 X\t8.699E+08 X\t0.767 X\n9\t0.119\t111.667\t3.589E+08\t0.383\t0.129 X\t409.596 X\t7.448E+09 X\t0.636 /\n10\t0.071\t57.883\t5.156E+08\t0.432\t0.094 X\t145.968 X\t1.673E+09 X\t0.491 /\nThe symbols /, X, \u00ab mean, respectively, that the coupled models based on Teale\u2019s formulation resulted in a better prediction accuracy than the coupled models based on Rabia\u2019s formulation, worst, or not statistically different. Tests performed at the 1% significance level.\nSource: own authorship.\n5.2.4\tFinal Remark Regarding SE modeling\nTwo decisions needed to be taken prior running the optimization routines. One was to decide how the SE would be estimated. That is, if we would follow the strategy of data-driven models or coupled models. We chose to estimate the SE based on coupled models, following the previous works from Gandelman (2012), Hegde and Gray (2018). For future works, it is interesting to compare both strategies in the optimization problems.\nThe second decision was related to the selection of specific energy model. Unlike the Rabia\u2019s formulation, the Teale\u2019s equation considers the torque on SE calculation. Therefore, the current work preferred the Teale\u2019s formulation over Rabia\u2019s formulation for the SE calculation.\n2\nWe evaluated the prediction accuracy of torque models, and presented the results in the Appendix F\n122\nFor those wells with torque-recording available, we employed the Teale\u2019s equation, except for the Well H. The reason for it was the low accuracy in torque prediction for the Well H: the average of MAPEa was around 44% on test dataset (see Appendix F). We believed the reason for this low accuracy was resulted from too high variance of torque recording for this well (see the drill-curves in Figure 4.1). As consequence, high residuals between actual-torque values and predicted-torque values lead to high MAPEa for the SE-coupled model based on Teale\u2019s formulation (see Table 5.13). Therefore, the specific energy for the well H was calculated based on Rabia\u2019s formulation in the optimization section.\n5.3\tDRILLING PARAMETERS OPTIMIZATION\n5.3.1\tSingle-Objective Optimization\nHere, the drilling optimization of a single-objective at time was investigated, comparing maximization of ROP and minimization of SE. The optimization technique employed was the grid-search.\n5.3.1.1\tFirst Optimization Problem - maximization of ROP\nAs seen in the review Chapter 3, a common of approach of real-time drilling optimization was to find an optimum combination of controllable inputs that could maximize the ROP. Therefore, the maximization of ROP is first analyzed. The controllable variables to be optimized were the rotating speed and weight-on-bit. In this case, it was important to set suitable lower and upper bounds on the controllable variables. The searching space is constrained by (i) equipment limits of drill-rigs (GANDELMAN, 2012; HEGDE et al., 2017), (ii) data limits (HEGDE et al.,\n2017). The minimum and maximum values of both variables were set as lower and upper bounds on the controllable variables. For each variable to be optimized, the searching space was split in equidistant grid points. We employed k = 98 grid points for each variable, resulting a total of (98 + 2)2 = 104 possible combinations of WOB and RPM for each observations.\nIt was assessed also how hypothetically optimizing the ROP would influence the SE. According to specific energy formulation, it is expected an decrease of SE values as ROP increases. However, drilling dysfunction(s) may occur with ROP improvement, as consequence, more energy can be required to drill the formation, as explained by Dupriest and Koederitz (2005). This was observed for some drill-curves from pre-salt, as seen in the plots for the Well D (see the Figure 5.11). For some sections, an improvement of ROP would be only possible with an increase in the energy spent, which may not be desired. In the left bottom plot, histograms of ROP-actual values (in blue) are shown, as well as the ROP-optimized values (in red). In the right bottom plot, histograms of SE-actual values are shown together with SE with optimized variables (WOB, RPM and ROP).\n123\nSource: own authorship. The specific energy was calculated based on Rabias\u2019 formulation.\nIn the previous Figure 5.11, the histograms could not provide valuable information, e.g. about how much the ROP has increased. Therefore, we compared, for each instance, the difference between the ROP-optimized values (provided from optimization routine) and ROP-actual values (from drill-curves). In a case of improvement in ROP, this difference is positive. In a case of decrease in ROP, this difference is negative. The same comparison was done for SE, and the variables to be optimized (WOB and RPM). For illustration purpose, two examples are shown in Figure 5.12. One example was for the Well A, where maximizing ROP decreased generally the drilling efficiency. Another example illustrated the opposite, i.e., the improvement of ROP resulted also in a improvement of drilling efficiency. Some statistics related to these differences are given in the Table 5.14 for all wells.\n124\nFigure 5.12 - Maximization of ROP: histograms of difference between the optimized parameters\nand actual values\n(a) Well A\n(b) Well H\nSource: own authorship.\nTable 5.14 - Maximization of ROP - some statistics about the difference between optimized and actual-variable values\nWell ROP_opt - ROP_actual\tSE_opt - SE_actual\tWOB_opt - WOB_actual RPM_opt - RPM_actual\n\tmin\tmean\tmedian\tmax\tmin\tmean\tmedian\tmax\tmin\tmean\tmedian\tmax\tmin\tmean\tmedian\tmax\nPre-Salt\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nA\t-0.54\t0.38\t0.41\t0.93\t-6 825\t-237\t40\t4835\t-4.8\t3.1\t2.7\t13.7\t-14.1\t-1.7\t-0.1\t30.4\nB\t-1.64\t0.66\t0.76\t1.82\t-1 830\t-494\t-386\t352\t-31.1\t-1.8\t-1.0\t32.3\t-71.5\t-17.6\t-39.9\t70.4\nD\t-3.36\t1.67\t1.40\t5.92\t-25 723\t-1615\t-59\t11 146\t-58.3\t3.6\t-0.5\t81.3\t-84.3\t2.5\t0.3\t119.4\nH\t-7.39\t7.26\t6.16\t18.89\t-66 828\t-6935\t-4295\t100\t-66.5\t-25.7\t-26.5\t11.4\t-141.4\t-95.4\t-103.5\t44.8\nNorway\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n3\t-24.71\t11.83\t9.25\t51.84\t-34 436\t-499\t-140\t170\t-7.2\t3.0\t2.0\t13.8\t-55.0\t0.4\t-0.5\t26.6\n4\t-12.64\t8.39\t6.45\t65.90\t-9 544\t-116\t-57\t164\t-5.3\t0.9\t0.3\t11.8\t-12.9\t-1.2\t-1.2\t130.4\n5\t-23.62\t20.12\t17.80\t65.39\t-4 1078\t-813\t-230\t500\t-11.3\t2.4\t2.6\t8.5\t-58.0\t9.2\t2.2\t125.3\n6\t-13.18\t1.90\t0.81\t39.99\t-30 513\t-47\t0\t236\t-8.7\t1.6\t0.4\t8.6\t-22.6\t-1.2\t0.3\t106.4\n7\t-11.19\t6.36\t0.99\t49.96\t-21 452\t-165\t-5\t316\t-5.1\t1.7\t0.9\t8.9\t-31.3\t0.7\t0.2\t136.0\n8\t-7.55\t1.83\t0.75\t27.88\t-21 120\t-464\t-165\t700\t-6.2\t1.0\t0.7\t9.0\t-60.6\t-7.9\t-2.1\t51.0\n9\t-24.60\t13.98\t8.30\t96.83\t-55 628\t-450\t-27\t148\t-6.9\t2.0\t1.1\t17.1\t-21.1\t1.2\t0.0\t73.8\n10\t-15.55\t5.03\t3.94\t32.59\t-26 524\t-151\t-6\t345\t-8.3\t4.2\t4.7\t10.3\t-43.4\t10.0\t-0.2\t41.7\nSource:own authorship.\n125\n126\nOne statistic interesting to analyze is the relative amount of observations, which could be optimized by the routine of maximization of ROP. The same can done to assess the improvement in drilling efficiency, expressed by decreases in SE values. In Figure 5.13, we plotted the relative amount of observations with improvement in ROP by the relative amount of observations with drilling efficiency improved as consequence of WOB and RPM optimization. Based on this metric, we observed the best result was for the Well H, because almost all observations could have its ROP and drilling efficiency improved at the same time. However, we observed a cluster with the wells A, D, 6 and 10, where maximization ROP would not necessarily mean an improvement in drilling efficiency for most instances.\nFigure 5.13 - Maximization of ROP: relative amount of observations with improvement in ROP versus relative amount of observations with drilling-efficiency improved as consequence of WOB and RPM optimization\nSource: own authorship.\n\t\t\t\tB\tX5 5 o L 4\n\t\t\t8 \u2022 z z z z\tz z z z\t\n\t\t\t\t9 o\t\n\t\tz z z z z\t\to7\t\n\tz z z z z\t\t\t\t10 A D\n\u2713 \u2713 z \u2713 z\t\t\t\t\u2022- 6\u2019\t7 A\nROP - relative amount of optimized observations\n5.3.1.2\tSecond Optimization Problem - minimization of SE\nAs done in the work from Hegde and Gray (2018), we investigated also the minimization of SE. We approached it the same way as we did in optimization the ROP. The only difference was the objective function employed. Instead of maximizing the ROP, the objective function was the minimizing of SE. That is, the optimum pair of controllable drilling parameters, WOB and RPM, was the one that resulted in the minimum value of SE for each observation.\nFor almost all instances, we observed that the grid search strategy could find combinations\nof WOB and RPM whose SE-estimated values were less than the SE-actual values. While the\noptimum pair of WOB and RPM resulted also in improvement of ROP for some instances,\nminimizing SE yielded lower penetration rates for other instances. In Figure 5.14, histograms\nwere plotted, showing the difference between the optimized parameters and actual parameters\nfor the well B.\n127\nFigure 5.14 - Minimization of SE: histograms of difference between the optimized parameters\nand actual values - Well B\nSome statistics about the difference between optimized and actual parameters are listed in the Table 5.15. It was observed an decrease in the ROP as consequence of minimizing SE for some wells (e.g. A, 4, 6 and 7). It becomes clearer in the Figure 5.15, where the relative amount of observations with SE improved was plotted against the relative amount of observations with ROP improved as consequence of minimizing SE.\nWe observed, however, the minimization of SE resulted in unrealistic optimum solutions. That is, low values of WOB and RPM (near to zero) were determined as optimum solutions. In the Section 5.3.2.1, a discussion about this problem is carried out, explaining some possible solutions.\nTable 5.15 - Minimization of SE - some statistics about the difference between optimized and actual variable-values\nWell SE_opt - SE_actual\tROP_opt - ROP_actual\tWOB_opt - WOB_actual RPM_opt - RPM_actual\n\tmin\tmean\tmedian\tmax\tmin\tmean\tmedian\tmax\tmin\tmean\tmedian\tmax\tmin\tmean\tmedian\tmax\nPre-Salt\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nA\t-12 276\t-3 820\t-2 917\t-10\t-1.53\t-0.20\t-0.15\t0.41\t-14.8\t-8.6\t-8.9\t0.0\t-44.9\t-33.3\t-30.5\t0.0\nB\t-1 924\t-642\t-569\t219\t-2.12\t0.50\t0.64\t1.68\t-31.1\t-6.3\t-5.6\t31.0\t-80.8\t-40.7\t-70.3\t12.7\nD\t-26 940\t-4 448\t-2 665\t-86\t-6.57\t0.50\t0.32\t4.82\t-91.4\t-33.0\t-29.4\t0.0\t-181.8\t-109.5\t-118.6\t0.0\nH\t-66 828\t-6 957\t-4 313\t0\t-12.38\t7.19\t6.14\t18.89\t-66.5\t-27.5\t-27.1\t0.0\t-141.4\t-98.0\t-104.3\t0.0\nNorway\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n3\t-34 579\t-525\t-165\t170\t-24.71\t10.10\t8.07\t51.79\t-7.2\t2.3\t1.4\t11.2\t-55.0\t-11.4\t-6.8\t26.6\n4\t-9 936\t-466\t-391\t-175\t-26.82\t-2.02\t-3.62\t47.14\t-4.9\t1.1\t0.1\t10.8\t-140.3\t-128.1\t-128.9\t0.0\n5\t-41 140\t-1 068\t-454\t196\t-41.70\t7.60\t3.61\t47.03\t-11.1\t2.5\t3.4\t7.8\t-126.5\t-102.2\t-116.1\t0.0\n6\t-30 747\t-287\t-234\t-20\t-18.45\t-0.49\t-0.88\t31.37\t-9.4\t-0.6\t-0.5\t3.4\t-112.1\t-104.2\t-104.2\t0.0\n7\t-21 789\t-455\t-299\t-28\t-28.54\t-8.97\t-13.24\t36.50\t-4.7\t0.6\t0.1\t7.8\t-164.2\t-126.2\t-133.4\t0.0\n8\t-21 477\t-614\t-328\t234\t-7.58\t1.41\t0.51\t27.69\t-10.0\t1.3\t0.6\t9.0\t-62.8\t-28.7\t-13.1\t47.9\n9\t-55 814\t-583\t-158\t-1\t-41.61\t5.28\t0.67\t87.94\t-10.8\t0.5\t0.1\t17.5\t-74.5\t-70.8\t-72.3\t0.0\n10\t-26 703\t-276\t-108\t176\t-15.55\t2.95\t2.19\t30.79\t-12.7\t2.5\t1.7\t10.9\t-45.4\t-23.6\t-39.4\t1.5\nSource:own authorship.\n128\n129\nFigure 5.15 - Minimization of SE: relative amount of observations with improvement in SE versus relative amount of observations with ROP improved as consequence of WOB and RPM optimization\nSource: own authorship.\n9 7 \u25a0\too 4\tA\to &lt;/ 1 9\t. 10 /\t\n\t\t\to\tz z z z z z\t\n\t\tz z z z Lr\t\t\n\tz' z zz z ,z\t\t\t\n\u2713 z z z Lr\t\t\t\t\nROP - relative amount of optimized observations\n5.3.2\tMulti-objective optimization\nThe current work tried to optimize the controllable drilling variables (RPM and WOB) based on the following objective functions:\n\u2022\tminimization of SE;\n\u2022\tmaximization of ROP;\nIn the previous sections, it was observed that the functions SE and ROP could be either conflicting to each other or not. Therefore, it is required to apply the formal formulation of multi-objective optimization problems for those instances that both objectives are not possible to be achieved at the same time. In the following sections, the results from the stepwise algorithms are presented, which were proposed to handle this multi-objective optimization problem with.\n5.3.2.1\tThird Optimization Problem - minimization of SE, transforming maximization of ROP into an inequality\nThe third optimization problem was formulated with the ^-constraint technique, expressed\nby the equation (4.9). The idea behind the third optimization problem is to minimize the specific\nenergy, transforming the maximization of ROP into an inequality.\nThe downside of the e-constraint technique is to determine a suitable e-value. One way to\nassess the influence of e-value on the optimization problem is to count the relative amount of\nobservations that could be optimized, respecting the inequality and lower and upper limits of\ncontrollable drilling variables, as seen in Figure 5.16. In this plot, e is based on the formulation\n130\npresented in the equation (4.9). For example, if e =1, then the feasible objective space is subject to ROP(x*) > ROPacutai * e. In this case, an observation is considered optimized if there is at least one optimum solution x* whose predicted-SE is less the actual-SE and meets the inequality condition given by ROP(x*) > ROPacutal * e. The higher the e is, the more difficult is the task of finding an optimum solution, because the feasible region becomes smaller, as observed in Figure 5.16.\nFigure 5.16 - Influence of e on the relative amount of observations that could be optimized for the problem of minimization of SE(x) subject to ROP(x) > ROP(x) * e.\nSource: own authorship.\nAs observed in the Figure 5.16, it is not always possible to find an optimum pair of WOB and RPM that optimizes both objective functions at the same time. For this reason, we developed the stepwise algorithm explained in the Section 4.3.2.1. It starts searching for an optimum solution that can improve the drilling efficiency and drilling rate. If no solution is found, then we search for an solution that is able to minimize the SE, maintaining, at least, the ROP-value. If there is still no optimum solution, then an decrease in ROP-value is accepted. We set the values of ea = 1.5, eb = 1.0 and ec = 0.75. That is, first, we want to minimize the SE and increase the ROP by at least 50%. In the third and last case, an decrease in ROP of up to 25% is accepted.\nFor the second and third optimization problems (main objective was minimization of SE), we observed unrealistic-optimum solutions. To be more specific, we observed SE-optimum\n131\nvalues near to zero, WOB- and RPM-optimum values near to zero. Such solutions are in fact not realistic, because it is expected that low WOB and RPM results also in low-ROP values. As consequence, both objectives (min SE and max ROP) are expected to not be achieved for too low values of WOB-RPM. Therefore, we analyzed further these optimization problems in the following paragraphs.\nA proposal for new lower-limits in the searching space\nThe actual values of the drilling parameters, including ROP, SE, WOB and RPM, were analyzed and compared with the optimized values. For example, Figure 5.17 shows in blue the actual values and in red the optimized values for the Well D. We selected this well as an example to illustrate all possible problems occurred in the drilling optimization in second and third problem (mais objective was minimization of SE). The problems were: SE-optimum values near to zero and WOB- and RPM-optimum values near to zero.\nBefore explaining why this problem occurred, it is important to remember, that the SE was estimated based on Rabia\u2019s formulation for the wells A, D, H. For some observations, solutions considered as optimum had WOB and RPM near to zero. This might happen because the SE equation from Rabia\u2019s formulation is direct proportional to WOB and RPM. If a pair of low WOB and RPM lies in a feasible region Q, then this pair can be considered as an optimum solution, since its SE value is very low. As consequence, it reaches the goal of minimizing the SE. The Teale\u2019s equation behaves similar when given low values of WOB and RPM as inputs. This explains for the second optimization problem (minimization of SE) why low values of WOB-RPM could be considered as optimum solutions\nTo understand why unrealistic solutions also happened in the third optimization problem, it is required to look at the predictive models for the ROP. The predictive models did not predict low ROP values when given low WOB and RPM. Let us suppose the following example. A ROP model learned that an instance (e.g. with depth of 1000m) had an output y given an pair of WOB and RPM as input. However, this model did not actually learn how this output would be for the same depth (e.g. 1 000m) with a very different pair of WOB and RPM, even this pair occurred in a different section (e.g. 1 200m) and was used in the learning phase, being therefore considered as a feasible one. Since the depth is also used as input, the learned ROP model may predict an unrealistic ROP value for this different pair of WOB and RPM. This unrealistic value might be e.g. too far away from 0 m/h.\n132\nFigure 5.17 - Minimization of SE(x) subject to ROP(x) > ROP(x) * e - well D with not realistic optimum solutions.\n0\t100\t200\t300\t400\t500\t600\t700\t800\t900\nObservations\nObservations\nObservations\nSource: own authorship.\nThis shows a special needs to taken when predicting ROP values with very different inputs from the training phase. Some possible solutions to avoid unrealistic optimum solutions are:\n\u2022\tto adopt new lower limits for WOB and RPM, avoiding too low-values of WOB and RPM;\n\u2022\tto adopt a moving lower and upper bounds for the WOB and RPM. This can avoid the problem of predicting values with very different inputs used in the learning phase;\n\u2022\tto employ data-driven models to estimate SE, instead of using SE coupled-models as done in the current work;\n133\n\u2022\tto add another constraint in the optimization problem, for example, SE(x) > UCS. By imposing this inequality, it is not accept optimum solution with estimated SE-values (i.e., the energy to destroy the rock) less than the rock strength, which is physically not possible;\n\u2022\tsince there is no standard in the literature regarding data pre-treatment of drill curves, it always worth of investigating other methods for data cleanness.\nFor simplicity, only one strategy was investigated, which consists of avoiding values of WOB and RPM near to zero. In the Table 5.16, the current lower and upper limits employed until now are listed, as well as the new proposed limits. To determine the new lower bounds, we visually analyzed the results from all wells, as we did in the Figure 5.17. A summary of the detected problems is also given in the Table 5.16, when using the current limits employed until here.\nTable 5.16 - Problems identified in the third optimization problem\nWell\tOptimized values near to zero\t\t\tCurrent limits - range\t\tNew limits\t\n\tWOB\tRPM\tSE\tRPM\tWOB\tRPM min\tWOB min\nPre-Salt\t\t\t\t\t\t\t\nA\tx\t\t\t[80.1 -125.0]\t[0.4 - 15.2]\t81.0\t3.0\nB\tx\t\t\t[78.2 - 159.0]\t[0.1 - 34.2]\t79.0\t3.0\nD\tx\tx\tx\t[1.5-183.3]\t[0.9 - 92.3]\t50.0\t5.0\nH\tx\tx\tx\t[30.6-171.9]\t[0.2 - 66.7]\t50.0\t5.0\nNorway\t\t\t\t\t\t\t\n3\t\t\t\t[219.9 - 278.4]\t[0.4 - 14.5]\t220.0\t1.5\n4\t\tx\t\t[29.3 - 169.6]\t[0.1 - 15.1]\t50.0\t1.5\n5\t\t\t\t[167.5 - 294.0]\t[0.0- 12.1]\t168.0\t1.0\n6\t\t\t\t[192.1 - 304.2]\t[0.0 - 10.4]\t193.0\t1.0\n7\t\tx\t\t[16.4 - 180.6]\t[0.0- 10.1]\t50.0\t1.0\n8\tx\t\t\t[227.3 - 290.6]\t[0.0- 11.8]\t228.0\t1.0\n9\t\t\t\t[117.2 - 192.7]\t[0.1 - 20.0]\t118.0\t2.0\n10\t\t\t\t[118.8 = 164.3]\t[0.0 - 15.7]\t119.0\t1.5\nSource: own authorship.\nSimulations based on new lower limits in search space\nTo speed up the simulations based on new lower bounds, the grid-search was not performed\nagain. Instead, we simply left out those combinations of WOB and RPM out of the new range.\nAs consequence, the matrixes of SE and RPM were adapted to the new limits. This enabled\nto speed up the analysis, since it was not required to map again how several different pairs of\nWOB-RPM would influence on the ROP and SE.\n134\nBy assessing the influence of e on the amount of observations optimized, it was noticed a very similar behaviour from the Figure 5.16. Therefore, this plot with new lower bounds was omitted.\nIn the Figure 5.18, the optimum solutions was plotted against the actual-values again for the well D. Some differences can be observed between the solution with new limits (Figure 5.18) and the previous solutions (Figure 5.17). First, SE-optimized values were not near to zero anymore. This occurred because the minimum-allowed values of RPM and WOB for the well D were 50 rpm and 5 klbf, respectively. However, it is possible to note an preference on the minimum values for WOB and RPM as optimum solutions. In the Table 5.17, some statistics are listed, presenting the results for all wells.\nFigure 5.18 - Minimization of SE(x) subject to ROP(x) > ROP(x) * e - optimum solutions for the well D with new lower limits.\nObservations\nObservations\nObservations\nObservations\nSource: own authorship.\nTable 5.17 - Minimization of SE(x) subject to ROP(x) > ROP(x) * e - some statistics about the difference between optimized and actual variable-values\nWell\tRelative amount of optimized observations\t\t\t\tSE opt\t- SE actual\tROP opt - ROP actual\t\tWOB opt - WOB actual\t\tRPM opt - RPM actual\t\n\t% =0.75\tEb = 1\t\u00a3c = 1.25\tnot-optimized\tmean\tmedian\tmean\tmedian\tmean\tmedian\tmean\tmedian\nPre-Salt\t\t\t\t\t\t\t\t\t\t\t\t\nA\t18.9%\t55.8%\t13.3%\t12.0%\t-2821\t-1974\t0.09\t0.05\t-5.0\t-5.3\t-9.8\t-8.6\nB\t31.6%\t55.0%\t10.0%\t3.3%\t-654\t-569\t0.58\t0.68\t-5.9\t-5.6\t-39.4\t-69.3\nD\t31.0%\t55.1%\t12.7%\t1.3%\t-4018\t-2280\t0.76\t0.35\t-24.5\t-22.2\t-48.3\t-64.3\nH\t73.8%\t20.5%\t4.6%\t1.2%\t-6647\t-3829\t2.15\t2.15\t-18.5\t-20.2\t-70.0\t-79.5\nNorway\t\t\t\t\t\t\t\t\t\t\t\t\n3\t29.1%\t59.6%\t6.9%\t4.5%\t-541\t-175\t11.22\t8.46\t2.5\t1.6\t-5.9\t-0.9\n4\t10.7%\t80.2%\t8.4%\t0.7%\t-259\t-141\t4.33\t2.02\t0.9\t-0.3\t-49.2\t-31.9\n5\t44.8%\t43.9%\t3.5%\t7.8%\t-988\t-373\t14.08\t14.24\t2.5\t2.8\t-48.8\t-58.4\n6\t3.2%\t68.2%\t28.4%\t0.1%\t-188\t-168\t0.26\t0.13\t-0.2\t-0.2\t-57.2\t-96.1\n7\t14.6%\t59.9%\t23.4%\t2.1%\t-232\t-55\t1.88\t0.37\t1.0\t0.4\t-28.7\t-27.4\n8\t12.4%\t62.1%\t17.9%\t7.6%\t-624\t-328\t1.69\t0.77\t1.5\t0.9\t-24.1\t-11.7\n9\t16.3%\t62.3%\t20.6%\t0.8%\t-555\t-137\t7.43\t3.43\t0.9\t0.4\t-54.3\t-70.6\n10\t15.7%\t65.8%\t10.2%\t8.3%\t-291\t-105\t3.71\t2.67\t3.1\t2.4\t-21.9\t-38.7\nSource: own authorship.\n135\n136\nBy imposing the inequality ROP(x) > ROPactual * e on the minimization problem of SE, it was observed an increase in the amount of optimum solutions that could also improve the ROP. In Figure 5.19, we observe that, for all wells, more than 70% of observations could have its SE and ROP improved at the same time. In the problem of solely minimizing SE, many observations would have its ROP decreased (see the previous Figure 5.15 from the second optimization problem).\nFigure 5.19 - Minimization of SE(x) subject to ROP(x) > ROP(x) * e - relative amount of optimized observations.\no \u2022\to 7\t9\t\t\u2022 \u2022 \u00b0 o\to\tH z z z\n8\u00b0\t\tOio\tB 3\tz Z Z Z Z z\t\nC A\t\t\tz z z z z\t\t\n\t\tz z z z z\t\t\t\n\tz z z z z\t\t\t\t\n\u2713 \u2713 z z z\t\t\t\t\t\n70%\t75%\t80%\t85%\t90%\t95%\t100%\nROP - relative amount of optimized observations\nSource: own authorship.\n5.3.2.2\tFourth Optimization Problem - maximization of ROP, transforming minimization of SE into an inequality\nAnother multi-objective optimization problem was investigated. At this time, the main goal was to maximize the ROP, while the minimization of SE was transformed into an inequality. The new lower limits for WOB and RPM, given in the Table 5.16, were employed in this section. First, it was assessed the influence of e on the amount of observations that could be optimized. As the e decreases and becomes less than one, finding optimum solutions able to improve the ROP and drilling efficiency at the same time becomes more difficult, as seen in the Figure 5.20.\nSince it is not always possible to find an optimum pair of WOB and RPM able to optimize both functions at the same time, a stepwise algorithm for this fourth optimization problem was developed (see the Section 4.3.2.2). It starts searching for an optimum solutions that can improve the ROP and drilling efficiency at the same time. If no solution is found, then we search for an solution that is able to improve the ROP, maintaining, at least, the current SE value. If there is still no optimum solution, then an decrease in drilling efficiency (expressed by an increase SE value) is accepted. In the fourth optimization problem, we set the values of ea = 0.75, eb = 1.0 and ec = 1.25. That is, first, we want to maximize the ROP and increase the drilling efficiency\n137\nby at least 25%. In the third and last case, it is accepted and decrease in drilling efficiency up to 25%.\nFigure 5.20 - Influence of e on the relative amount of observations that could be optimized for the problem of maximization of ROP(x) subject to SE(x) &lt;SE(x) * e\nSource: own authorship.\nIn the Figure 5.18, the optimum solutions was plotted against the actual values again for the well D. Some differences can be observed between the first optimization problem (solely maximization of ROP - see the Figure 5.11) and this fourth optimization problem (maximization of ROP, transforming the minimization of SE into an inequality).\nAn interesting fact occurred for the observations from 0 to 100 and, partially, from 400700. For such observations, substantial improvement in ROP would be possible without having to deteriorate the drilling efficiency, after implementing the stepwise algorithm in the fourth optimization problem with the constraint SE(x) &lt;SEactual * e in the objective space. In the first optimization problem (only maximization of ROP), the optimum solutions of WOB-RPM would provide higher ROP values than the fourth problem, but the drilling efficiency would decrease.\n138\n- Maximization of ROP(x) subject to SE(x) &lt;SE(x) * e - optimum solutions\nfor the well D\nFigure 5.21\nObservations\nT\nT\nT\nT\nT\nT\nT\nT\n105\nCO CL\n\nLU\nCO\nSE-actual SE(ROP-opt.)\ni i i i\n500\t600\t700\t800\t900\ni i i\ti\n100\t200\t300\t400\n100 L\n0\n200\nT\nT\nT\nT\nT\nCL \u25a1c\nT\nT\nT\n100 -\nT^nll I\tIIMl ------RPM-;\nJ I I I\n100\t200\t300\t400\t500\t600\nObservations\ni\n700\nactual\n\u2014 RPM-opt\ni\t~l\n800\t900\n0\n0\nSource: own authorship.\nThe results from the fourth optimization problem are presented in the Table 5.18. Differently from the third problem, fewer observations could not be optimized in the fourth problem. By analyzing the optimum RPM-values, we observed the third optimization problem led to greater reduction of rotating speed than the fourth optimization problem. In the Figure 5.22, we observe that imposing the inequality SE(x) &lt;SEactual * e increased the number observations that could have the ROP and SE improved at the same time, in comparison with the first optimization problem (only maximization of ROP - see Figure 5.13).\nTable 5.18 - Maximization of ROP(x) subject to SE(x) &lt;SE(x) * e - some statistics about the difference between optimized and actual variable-values\nWell\tRelative amount of optimized observations\t\t\t\tROP_opt - ROP_actual\t\tSE_opt\t- SE_actual\tWOB opt - WOB actual\t\tRPM opt - RPM actual\t\n\t% =0.75\t\u00a3&amp; = 1\t\u00a3c = 1.25\tnot-optimized\tmean\tmedian\tmean\tmedian\tmean\tmedian\tmean\tmedian\nPre-Salt\t\t\t\t\t\t\t\t\t\t\t\t\nA\t61.5%\t13.3%\t6.3%\t18.9%\t0.29\t0.20\t-1405\t-1452\t-0.3\t0.1\t-4.5\t-5.1\nB\t73.3%\t13.4%\t1.0%\t12.4%\t0.81\t0.85\t-580\t-460\t-0.9\t0.3\t-21.2\t-40.2\nD\t83.1%\t3.0%\t2.4%\t11.5%\t1.65\t1.26\t-3114\t-1524\t-11.5\t-12.3\t-2.2\t-0.8\nH\t93.2%\t1.1%\t0.4%\t5.3%\t3.24\t3.29\t-4848\t-2336\t6.8\t12.6\t-14.2\t-9.4\nNorway\t\t\t\t\t\t\t\t\t\t\t\t\n3\t43.4%\t45.3%\t2.5%\t8.8%\t12.79\t9.82\t-548\t-169\t3.1\t2.6\t-0.4\t-0.5\n4\t55.8%\t35.1%\t2.3%\t6.8%\t7.60\t4.86\t-197\t-126\t0.9\t-0.3\t-24.2\t-4.9\n5\t60.6%\t28.1%\t0.1%\t11.1%\t19.00\t17.81\t-881\t-279\t2.4\t2.7\t2.4\t0.8\n6\t24.3%\t47.2%\t12.1%\t16.5%\t1.81\t0.58\t-133\t-24\t0.4\t0.1\t-25.2\t-0.6\n7\t21.5%\t53.0%\t7.2%\t18.3%\t7.43\t1.29\t-219\t-15\t1.8\t0.9\t-3.8\t-1.0\n8\t32.4%\t42.1%\t3.3%\t22.2%\t2.36\t1.28\t-636\t-354\t1.7\t1.2\t-12.9\t-11.4\n9\t57.9%\t20.7%\t4.8%\t16.6%\t15.01\t6.75\t-593\t-133\t2.2\t1.5\t-26.3\t-1.4\n10\t33.9%\t47.7%\t7.6%\t10.9%\t5.24\t3.80\t-229\t-39\t4.1\t4.5\t-3.3\t-0.6\nSource: own authorship.\n139\n140\nFigure 5.22 - Maximization of ROP(x) subject to SE(x) &lt;SE(x) * e - relative amount of optimized observations.\nROP - relative amount of optimized observations\nSource: own authorship.\n5.3.3\tOn the Implementation's Feasibility of Proposed Optimization Methods\nBoth multi-objective optimization problems proposed here require the actual values of an instance to determine the optimum solution. In theory, this is not possible, since the optimization process should be carried out before the implementation, as consequence, before knowing the actual values. However, an alternative can be applied in practice, which consists of estimating suitable values for ROP and SE to be used in the comparison steps in the optimization routine (i.e., third and fourth optimization problems). Such suitable values can be obtained based on previous instances, e.g., through a simple moving averaging or any forecasting method. For sake of simplicity, the current work did not deal with such problem, and assumed this information is already available for the optimization algorithm.\nTo overcome the mentioned challenge, Hegde and Gray (2018) formulated single-objective problems, which do not require any comparison. Gandelman (2012) proposed a target value for ROP, which could be set by a driller and was used in his searching algorithm based on if-then rules.\nThe elapsed time for the optimization algorithm was accessed to estimate its feasibility. It was measured the required time to train the predictive models, as well as the required time to perform the grid-search for each observation. The results are listed in the Table 5.19. In the first two columns, the elapsed time was computed considering both data pre-treatment process and training time. For that, we ran a simulation apart from the optimization code, but with the same configuration used in that routines. For each well, we trained ten times the predictive models, considering the whole process, i.e., from the data pre-treatment to the training phase. The average of elapsed time are listed in these first two columns. Even if another data partition had been employed (e.g. the strategy proposed by Hegde et al. (2017), Soares and Gray (2018) to\n141\nobtain predictive models in real-time), the training time would not have been restrictive, because this step took less than a few seconds.\nTable 5.19-Elapsed time in seconds for training phase (including data pre-treatment) and grid-search in the optimization algorithm\nWell\tAverage train time (seconds)\t\tGrid-search (seconds/observations)\t\t\n\tROP\tTorque\tROP\tTorque\tSE\nPre-Salt\t\t\t\t\t\nA\t0.241\t-\t0.479\t-\t0.006\nB\t0.311\t0.641\t0.498\t0.498\t0.007\nD\t0.445\t-\t0.476\t-\t0.007\nH\t1.455\t-\t0.408\t-\t0.005\nNorway\t\t\t\t\t\n3\t1.684\t1.778\t0.508\t0.5083\t0.005\n4\t2.414\t2.604\t0.491\t0.4914\t0.004\n5\t1.122\t1.249\t0.473\t0.4733\t0.005\n6\t2.063\t1.992\t0.503\t0.5031\t0.004\n7\t3.065\t3.272\t0.513\t0.5131\t0.004\n8\t1.620\t1.609\t0.510\t0.5104\t0.006\n9\t1.028\t1.081\t0.512\t0.5124\t0.005\n10\t2.569\t2.715\t0.556\t0.5557\t0.005\nSource: own authorship.\nThe most time intensive aspect of developed algorithms was the grid-search, since 104 possible combinations of WOB and RPM were tested for each objective function and each instance. By analyzing the elapsed time to perform the grid-search, we observed that around 0.5 second was required to predicted all possible combinations for each predictive model (ROP and/or torque). As consequence, the evaluation of a considerable amount of combinations did not take longer than 1.2 second per observation. As discussed by Hegde, Daigle and Gray (2018, p. 9), \u201cthe frequency of drilling-parameter change can be in the range of every 50 to 100 ft of drilling or every 10 minutes of drilling\u201d. Therefore, the elapsed time to perform the grid-search would not hinder the implementation of this searching strategy, because the required time to map the decision space into the objective space would cause a delay of only a second in most cases.\n142\n6\tCONCLUSIONS\nThe current work investigated the possibility of employing machine learning algorithms to optimize drilling operational variables, especially weight-on-bit (WOB) and rotating drillbit speed (RPM), considering maximization of rate of penetration (ROP) and/or minimization of specific energy (SE).\nFor that, real-time drilling data from pre-salt region and Norwegian continental shelf were employed. Random forests could learn the complex relationship among the drilling variables to estimate ROP, as expected according to the literature review carried out in the chapter 3. It was observed that using surface operational variables as inputs (depth, WOB, RPM and mud flow) resulted in predictive models with acceptable accuracy to predict ROP. Such variables are easily accessed at drill rigs. Besides that, the employment of them as inputs in the predictive models enables the optimization of them, as already in some previous works (GANDELMAN, 2012; HEGDE; GRAY, 2017; HEGDE; DAIGLE; GRAY, 2018; HEGDE; GRAY, 2018). The use of binary genetic algorithm was employed to obtain the best subset of inputs. However, the obtained optimum subsets of inputs could not be used further in the drilling optimization studies.\nExtensive analysis was done regarding the prediction of specific energy (SE). To be more specific, two approaches were compared: one used exclusively data-driven models, as commonly done to estimate ROP, and another with coupled models, following the previous works from Gandelman (2012), Hegde and Gray (2018). Data-driven models could very accurately estimate the SE after adding the ROP as input, as expected according to the Teale\u2019s formulation. We assessed also the accuracy of coupling the SE calculation with predictive models for ROP and torque (if available). We observed, especially for Norwegian drill-curves, high residuals between actual values and estimated values for those observations whose ROP-values were near to zero. For the optimization problems, we followed the approach adopted by previous works (GANDELMAN, 2012; HEGDE; GRAY, 2018) to estimate the SE based on coupled models. For future works, it is interesting to investigate the employment of data-driven models to map the influence of drilling parameters on SE.\nThe obtained predictive models for ROP and SE were employed in optimization problems as objective functions. Four optimization problems were formulated: two in single-objective framework and other two in multi-objective framework. It was observed that maximization of ROP alone was not necessary a good optimization strategy, because the drilling efficiency could decrease (or more energy could be required). By imposing an inequality of SE(x) &lt;SEactual * e on maximization of ROP, this problem could be avoided in many cases. The implementation of the stepwise strategy, which consisted of varying e value, was tested with three e-values. As extension of the proposed algorithm, it is possible to implement the same idea in an iterative loop, assessing several e-values. By doing so, it is expected to increase the amount of observations whose optimum solutions are able to improve both objective functions. However, it is necessary\n143\nto assess the computational effort.\nThe current work focused on optimizing two controllable drilling variables (WOB and RPM). However, the stepwise algorithm can be employed also to optimize more drilling variables at the same time, for example by adding the mud flow to WOB-RPM, as done in some works (AWOTUNDE; MUTASIEM, 2014; HEGDE; GRAY, 2017; HEGDE; GRAY, 2018). It is possible to add other parameters to be optimizes, such as mud weight (BATAEE; IRAWAN; KAMYAB, 2014), bit hydraulic (ARABJAMALOEI; SHADIZADEH, 2011) or any other hydraulic/drilling fluid parameters.\nFor future works, more efforts are required to overcome the problem of having, as optimum, solutions pairs of WOB and RPM near to zero when the minimization of SE is employed as objective function. The present thesis investigated one possible solution for that, which consisted of increasing the lower bounds for WOB and RPM in order to avoid too low values. However, it is worth of studying other strategies regarding the definition of searching space, including the employment of a moving widow to determine the lower and upper bounds for WOB and RPM. A similar alternative can be adopted by adding another constraint in the objective space. This constraint can be formulated as following: the energy spent to drill a rock formation can be not less than the rock strength. Besides that, another solution can be the employment of data-driven models to map how WOB and RPM influence on objective space of SE, since random forests could accurately estimate the SE. Finally, investigating other methods for data cleanness is always worth, because there is no standard in the literature regarding data pre-treatment of drill curves.\n144\nREFERENCES\nAGGARWAL, C. C. Outlier Analysis. New York, NY: Springer New York, 2013.\nAGWU, O. E. et al. Artificial intelligence techniques and their applications in drilling fluid engineering: A review. Journal of Petroleum Science and Engineering, v. 167, p. 300-315, 2018.\nAL-SUDANI, J. A. Real-time monitoring of mechanical specific energy and bit wear using control engineering systems. Journal of Petroleum Science and Engineering, v. 149, p. 171182, 2017.\nAMADI, W. K.; IYALLA, I. Application of mechanical specific energy techniques in reducing drilling cost in deepwater development. In: SPE DEEPWATER DRILLING AND COMPLETIONS CONFERENCE, 2012, Galveston, Texas. Proceedings... Galveston, Texas: Society of Petroleum Engineers, 2012.\nAMAR, K.; IBRAHIM, A. Rate of penetration prediction and optimization using advances in artificial neural networks, a comparative study. In: INTERNATIONAL JOINT CONFERENCE ON COMPUTATIONAL INTELLIGENCE (NCTA), 4., 2012, Barcelona. Proceedings... Barcelona: SciTePress, 2012. p. 647-652.\nANEMANGELY, M. et al. Drilling rate prediction from petrophysical logs and mud logging data using an optimized multilayer perceptron neural network. Journal of Geophysics and Engineering, IOP Publishing, v. 15, n. 4, p. 1146-1159, 2018.\nANSARI, H. R.; HOSSEINI, M. J. S.; AMIRPOUR, M. Drilling rate of penetration prediction through committee support vector regression based on imperialist competitive algorithm. Carbonates and Evaporites, v. 32, n. 2, p. 205-213, 2017.\nANTONIO, L. M.; COELLO, C. A. C. Coevolutionary multi-objective evolutionary algorithms: A survey of the state-of-the-art. IEEE Transactions on Evolutionary Computation, p. 1-16, 2017. (Preprint).\nARABJAMALOEI, R.; SHADIZADEH, S. Modeling and optimizing rate of penetration using intelligent systems in an iranian southern oil field (ahwaz oil field). Petroleum Science and Technology, v. 29, n. 16, p. 1637-1648, 2011.\nAREHART, R. Drill-bit diagnosis with neural networks. SPE Computer Applications, v. 2, n. 04, p. 24-28, 1990. SPE-19558-PA.\nARNAOUT, A. et al. Intelligent data quality control of real-time rig data. In: SPE MIDDLE EAST INTELLIGENT ENERGY CONFERENCE AND EXHIBITION, 2013, Manama, Bahrain. Proceedings... Manama, Bahrain: Society of Petroleum Engineers, 2013. SPE-167437-MS.\nAWOTUNDE, A. A.; MUTASIEM, M. A. Efficient drilling time optimization with differential\nevolution. In: SPE NIGERIA ANNUAL INTERNATIONAL CONFERENCE AND EXHIBI-\nTION, 2014, Lagos, Nigeria. Proceedings... Lagos, Nigeria: Society of Petroleum Engineers,\n2014. SPE-172419-MS.\n145\nBAHARI, A.; SEYED, A. B. Drilling cost optimization in a hydrocarbon field by combination of comparative and mathematical methods. Petroleum Science, v. 6, n. 4, p. 451-463, 2009.\nBAHARI, M. et al. Determining bourgoyne and young model coefficients using genetic algorithm to predict drilling rate. Journal of Applied Sciences, v. 8, n. 17, p. 3050-3054, 2008.\nBARBOSA, L. F. F. M. et al. Machine learning methods applied to rate of penetration prediction - a technical review. In: RIO OIL &amp; GAS EXPO AND CONFERENCE, 2018, Rio de Janeiro, Brazil. Proceedings... Rio de Janeiro, Brazil: Brazilian Petroleum, Gas and Biofuels Institute (IBP), 2018. IBP1871_18.\nBASARIR, H.; TUTLUOGLU, L.; KARPUZ, C. Penetration rate prediction for diamond bit drilling by adaptive neuro-fuzzy inference system and multiple regressions. Engineering Geology, v. 173, p. 1-9, 2014.\nBATAEE, M.; IRAWAN, S.; KAMYAB, M. Artificial neural network model for prediction of drilling rate of penetration and optimization of parameters. Journal of the Japan Petroleum Institute, v. 57, n. 2, p. 65-70, 2014.\nBEASLEY, C. et al. Brazil\u2019s presalt play. Oilfield Review, v. 22, n. 3, p. 28-37, 2010.\nBEHERA, S.; SAHOO, S.; PATI, B. A review on optimization algorithms and application to wind energy integration to grid. Renewable and Sustainable Energy Reviews, v. 48, p. 214-227,\n2015.\nBELLO, O. et al. Application of artificial intelligence techniques in drilling system design and operations: A state of the art review and future research pathways. In: SPE NIGERIA ANNUAL INTERNATIONAL CONFERENCE AND EXHIBITION, 2016, Lagos, Nigeria. Proceedings... Lagos, Nigeria: Society of Petroleum Engineers, 2016. SPE-184320-MS.\nBERGSTRA, J.; BENGIO, Y. Random search for hyper-parameter optimization. Journal of Machine Learning Research, v. 13, p. 281-305, 2012.\nBEVILACQUA, M.; CIARAPICA, F. E.; MARCHETTI, B. Acquisition, processing and evaluation of down hole data for monitoring efficiency of drilling processes. Journal of Petroleum Science Research, v. 2, n. 2, p. 49-56, 2013.\nBEZMINABADI, S. N. et al. Effect of rock properties on rop modeling using statistical and intelligent methods: A case study of an oil well in southwest of iran. Archives of Mining Sciences, v. 62, n. 1, 2017.\nBILGESU, H. et al. A real-time interactive drill-off test utilizing artificial intelligence algorithm for dsats drilling automation university competition. In: SPE WESTERN REGIONAL MEETING, 2017, Bakersfield, California. Proceedings... Bakersfield, California: Society of Petroleum Engineers, 2017. SPE-185730-MS.\nBILGESU, H. I. et al. A new approach for the prediction of rate of penetration (rop) values. In: SPE EASTERN REGIONAL MEETING, 1997, Lexington, Kentucky. Proceedings... Lexington, Kentucky: Society of Petroleum Engineers, 1997. SPE-39231-MS.\nBINGHAM, M. G. A New Approach to Interpreting Rock Drillability. [S.l.]: Petroleum Publishing Company, 1965. 93 p.\n146\nBISHOP, C. M. Model-based machine learning. Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences, The Royal Society, v. 371, n. 1984, 2013.\nBOND, D. F. et al. Applying technical limit methodology for step change in understanding and performance. SPE Drilling &amp; Completion, v. 13, n. 03, p. 197 - 203, 1998.\nBOTCHKAREV, A. Evaluating performance of regression machine learning models using multiple error metrics in azure machine learning studio. SSRN Electronic Journal, 2018. Available at:&lt;https://www.ssrn.com/abstract=3177507>. Accessed: sep. 2018.\nBOURGOYNE, A.; YOUNG, F. A multiple regression approach to optimal drilling and abnormal pressure detection. Society of Petroleum Engineers Journal, v. 14, n. 04, p. 371 - 384, 1974.\nBREIMAN, L. Bagging predictors. Machine Learning, v. 24, n. 2, p. 123-140, 1996.\nBREIMAN, L. Random forests. Machine Learning, v. 45, n. 1, p. 5-32, 2001.\nBREIMAN, L. Statistical modeling: The two cultures (with comments and a rejoinder by the author). Statistical Science, v. 16, n. 3, p. 199-231, 2001.\nBYRNE, J. P.; LORUSSO, M.; XU, B. Oil prices, fundamentals and expectations. Energy Economics, 2018. (Article in press, DOI:10.1016/j.eneco.2018.05.011).\nCHEN, T.; GUESTRIN, C. XGBoost: A scalable tree boosting system. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '16, ACM Press, New York, New York, USA, p. 785-794, mar 2016. Available at:&lt;http://arxiv.org/abs/1603.02754>. Accessed: aug. 2018.\nCHEN, X. et al. Real-time optimization of drilling parameters based on mechanical specific energy for rotating drilling with positive displacement motor in the hard formation. Journal of Natural Gas Science and Engineering, v. 35, p. 686-694, 2016.\nCHIANDUSSI, G. et al. Comparison of multi-objective optimization methodologies for engineering applications. Computers &amp; Mathematics with Applications, v. 63, n. 5, p. 912-942,\n2012.\nCLAESEN, M. et al. Easy Hyperparameter Search Using Optunity. ArXiv e-prints, dez. 2014. Available at:&lt;http://arxiv.org/abs/1412.1114>. Accessed: sep. 2018.\nCOHON, J. L.; MARKS, D. H. A review and evaluation of multiobjective programing techniques. Water Resources Research, v. 11, n. 2, p. 208-220, 1975.\nCOLEMAN, T. F.; LI, Y. An interior trust region approach for nonlinear minimization subject to bounds. SIAM Journal on Optimization, v. 6, n. 2, p. 418-445, 1996.\nCUI, Y. et al. Review: Multi-objective optimization methods and application in energy saving. Energy, v. 125, p. 681-704, 2017.\nDENG, Y. et al. Theoretical and experimental study on the penetration rate for roller cone bits based on the rock dynamic strength and drilling parameters. Journal of Natural Gas Science and Engineering, v. 36, p. 117-123, 2016.\n147\nDIAZ, M. B. et al. Drilling data from an enhanced geothermal project and its pre-processing for rop forecasting improvement. Geothermics, v. 72, p. 348-357, 2018.\nDONG, G.; CHEN, P A review of the evaluation, control, and application technologies for drill string vibrations and shocks in oil and gas well. Shock and Vibration, v. 2016, p. 1-34, 2016. Article ID 7418635.\nDONNE, C. P. J. Parameter Detection in real time Drilling Data: Create a matlab agent to forecast changes in formation hardness. 138 p. Master\u2019s Thesis (Petroleum Engineering Master) \u2014 Faculty of Engineering Department of Geoscience and Petroleum, Norwegian University of Science and Technology, Trondheim, Norway, 2017. Available at:&lt;http://hdl.handle.net/11250/ 2450329>. Accessed: 15 nov. 2017.\nDUPRIEST, F. E.; KOEDERITZ, W. L. Maximizing drill rates with real-time surveillance of mechanical specific energy. In: SPE/IADC DRILLING CONFERENCE, 2005, Amsterdam, The Netherlands. Proceedings... Amsterdam, The Netherlands: Society of Petroleum Engineers, 2005.\nDUTRA, B. M. Novas metodologias e m\u00e9todo de an\u00e1lise de dados de perfura\u00e7\u00e3o de po\u00e7os de petr\u00f3leo e g\u00e1s natural, e de implementa\u00e7\u00e3o de curvas de drill-rate test em tempo real visando otimiza\u00e7\u00e3o do processo. 57 f. Trabalho de Gradua\u00e7\u00e3o (Engenharia Mec\u00e2nica) \u2014 Faculdade de Engenharia de Guaratinguet\u00e1, Universidade Estadual Paulista (UNESP), 2016. Available at:&lt;http://hdl.handle.net/11449/155378.> Accessed: 11 mar. 2017.\nEILERS, P H. C.; GOEMAN, J. J. Enhancing scatterplots with smoothed densities. Bioinformatics, v. 20, n. 5, p. 623-628, 2004.\nEQUINOR. The Statfjord area. 2018. Available at:&lt;https://www.equinor.com/en/what-we-do/ norwegian-continental-shelf-platforms/statfjord.html>. Accessed: 23 jul. 2018.\nEREN, T.; OZBAYOGLU, M. E. Real time optimization of drilling parameters during drilling operations. In: SPE OIL AND GAS INDIA CONFERENCE AND EXHIBITION, 2010, Mumbai, India. Proceedings... Mumbai, India: Society of Petroleum Engineers, 2010. SPE-129126-MS.\nESKANDARIAN, S.; BAHRAMI, P.; KAZEMI, P. A comprehensive data mining approach to estimate the rate of penetration: Application of neural network, rule based models and feature ranking. Journal of Petroleum Science and Engineering, v. 156, p. 605-615, 2017.\nFERN\u00c1NDEZ-DELGADO, M. et al. Do we need hundreds of classifiers to solve real world classification problems? Journal of Machine Learning Research, v. 15, p. 3133-3181, 2014.\nFORMIGHIERI, S.; FILHO, P J. d. F. Estimation of bourgoyne and young model coefficients using markov chain monte carlo simulation. In: 2015 WINTER SIMULATION CONFERENCE (WSC), 2015, Huntington Beach, CA, USA. Proceedings... Huntington Beach, CA, USA: IEEE,\n2016.\tp. 1172-1183.\nFORTIN, F.-A. et al. DEAP: Evolutionary algorithms made easy. Journal of Machine Learning Research, v. 13, p. 2171-2175, 2012.\nFRAGA, C. T. d. C. et al. Brazilian pre-salt: An impressive journey from plans and challenges to concrete results. In: OFFSHORE TECHNOLOGY CONFERENCE, 2015, Houston, TX. Proceedings... Houston, TX: Offshore Technology Conference, 2015. SPE-25710-MS.\n148\nFREUND, Y.; SCHAPIRE, R. E. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, v. 55, n. 1, p. 119-139, 1997.\nFRIEDMAN, J. H. Greedy function approximation: A gradient boosting machine. The Annals of Statistics, v. 29, n. 5, p. 1189-1232, 2001.\nFRIEDMAN, J. H. Recent advances in predictive (machine) learning. Journal of Classification, v. 23, n. 2, p. 175-197, 2006.\nFRUHWIRTH, R. K.; THONHAUSER, G.; MATHIS, W. Hybrid simulation using neural networks to predict drilling hydraulics in real time. In: SPE ANNUAL TECHNICAL CONFERENCE AND EXHIBITION, 2006, San Antonio, Texas. Proceedings... San Antonio, Texas: Society of Petroleum Engineers, 2006. SPE-103217-MS.\nFURLAN, F. Eles v\u00e3o fundo no investimento. Exame, p. 44-46, jul 2018.\nGANDELMAN, R. A. Predi\u00e7\u00e3o da ROP e Otimiza\u00e7\u00e3o em Tempo Real de Par\u00e2metros Operacionais na Perfura\u00e7\u00e3ode de Po\u00e7os de Petr\u00f3leo Offshore. 175 f. Disserta\u00e7\u00e3o (Metrado em Tecnologia de Processos Qu\u00edmicos e Bioqu\u00edmicos) \u2014 Escola de Qu\u00edmica, Universidade Federal do Rio de Janeiro, Rio de Janeiro, RJ - Brasil, 2012.\nGARCIA, L. P. E; CARVALHO, A. C. P. L. F. de; LORENA, A. C. Noisy data set identification. In: Hybrid Artificial Intelligent Systems. [S.l.]: Springer Berlin Heidelberg, 2013. p. 629-638.\nGELBART, M. A.; SNOEK, J.; ADAMS, R. P. Bayesian Optimization with Unknown Constraints. ArXiv e-prints, mar. 2014. Available at:&lt;https://arxiv.org/abs/1403.5607v1>. Accessed: 23 oct. 2018.\nGHASEMLOONIA, A.; Geoff Rideout, D.; BUTT, S. D. A review of drillstring vibration modeling and suppression methods. Journal of Petroleum Science and Engineering, v. 131, p. 150-164, 2015.\nGODHAVN, J.-M. et al. Drilling seeking automatic control solutions. IFAC Proceedings Volumes, IFAC, v. 44, n. 1, p. 10842-10850, jan 2011.\nGONZ\u00c1LEZ-ORDIANO, J. \u00c1. et al. Photovoltaic power forecasting using simple data-driven models without weather data. Computer Science - Research and Development, v. 32, n. 1-2, p. 237-246, 2017.\nGRAHAM, J.; MUENCH, N. Analytical determination of optimum bit weight and rotary speed combinations. In: FALL MEETING OF THE SOCIETY OF PETROLEUM ENGINEERS OF AIME, 1959, Dallas, Texas. Proceedings... Dallas, Texas: Society of Petroleum Engineers, 1959. SPE-1349-G.\nGUAN, C. et al. Very short-term load forecasting: Multilevel wavelet neural networks with data pre-filtering. IEEE Transactions on Power Systems, v. 28, n. 1, p. 30-41, 2013.\nGURIA, C.; GOLI, K. K.; PATHAK, A. K. Multi-objective optimization of oil well drilling using elitist non-dominated sorting genetic algorithm. Petroleum Science, v. 11, n. 1, p. 97-110,\n2014.\nGUYON, I.; ELISSEEFF, A. An introduction to variable and feature selection. Journal of Machine Learning Research, v. 3, n. 3, p. 1157-1182, 2003.\n149\nHAIMES, Y. Y.; LASDON, L. S.; WISMER, D. A. On a bicriterion formulation of the problems of integrated system identification and system optimization. IEEE Transactions on Systems, Man, and Cybernetics, SMC-1, n. 3, p. 296-297, 1971.\nHAMADA, Y. et al. Continuous depth profile of the rock strength in the nankai accretionary prism based on drilling performance parameters. Scientific Reports, Springer US, v. 8, n. 1, p. 2622, 2018.\nHAMPEL, F. R. The influence curve and its role in robust estimation. Journal of the American Statistical Association, v. 69, n. 346, p. 383-393, 1974.\nHARELAND, G.; HOBEROCK, L. Use of drilling parameters to predict in-situ stress bounds. In: SPE/IADC DRILLING CONFERENCE, 1993, Amsterdam, Netherlands. Proceedings... Amsterdam, Netherlands: Society of Petroleum Engineers, 1993. SPE-25727-MS.\nHARELAND, G.; RAMPERSAD, P. Drag - bit model including wear. In: SPE LATIN AMER-ICA/CARIBBEAN PETROLEUM ENGINEERING CONFERENCE, 1994, Buenos Aires, Argentina. Proceedings... Buenos Aires, Argentina: Society of Petroleum Engineers, 1994. SPE-26957-MS.\nHASTIE, T.; TIBSHIRANI, R.; FRIEDMAN, J. The Elements of Statistical Learning. 12. ed. New York, NY: Springer New York, 2009. (Springer Series in Statistics).\nHEGDE, C.; DAIGLE, H.; GRAY, K. E. Performance comparison of algorithms for real-time rate-of-penetration optimization in drilling using data-driven models. SPE Journal, jul 2018. (Preprint, DOI: 10.2118/191141-PA).\nHEGDE, C. et al. Analysis of rate of penetration (rop) prediction in drilling using physics-based and data-driven models. Journal of Petroleum Science and Engineering, v. 159, p. 295-306,\n2017.\nHEGDE, C.; GRAY, K. Use of machine learning and data analytics to increase drilling efficiency for nearby wells. Journal of Natural Gas Science and Engineering, v. 40, p. 327-335, 2017.\nHEGDE, C.; GRAY, K. Evaluation of coupled machine learning models for drilling optimization. Journal of Natural Gas Science and Engineering, v. 56, p. 397-407, 2018.\nHWANG, C.-L.; MASUD, A. S. M. Multiple Objective Decision Making \u2014 Methods and Applications. Berlin, Heidelberg: Springer Berlin Heidelberg, 1979. v. 164. 358 p. (Lecture Notes in Economics and Mathematical Systems, v. 164).\nINDEXMUNDI. Crude Oil (petroleum); Dubai Fateh Monthly Price - US Dollars per Barrel. 2018. Available at:&lt;https://www.indexmundi.com/commodities/?commodity= crude-oil-dubai&amp;months=60>. Accessed: 27 jul. 2018.\nINDEXMUNDI. Crude Oil (petroleum); West Texas Intermediate Monthly Price - US Dollars per Barrel. 2018. Available at:&lt;https://www.indexmundi.com/commodities/?commodity= crude-oil-west-texas-intermediate>. Accessed: 27 jul. 2018.\nINTERNATIONAL ENERGY AGENCY. Key World Energy Statistics 2017. 2017. 97 p. Available at:&lt;https://www.iea.org/publications/freepublications/publication/KeyWorld2017. pdf>. Accessed: jul. 2018.\n150\nINTERNATIONAL ENERGY AGENCY. World Energy Outlook 2017. 2017. Available at:&lt;https://www.iea.org/weo2017/>. Accessed: jul. 2018.\nKARAKUL, H.; ULUSAY, R. Empirical correlations for predicting strength properties of rocks from p-wave velocity under different degrees of saturation. Rock Mechanics and Rock Engineering, v. 46, n. 5, p. 981-999, 2013.\nKHAN, M. I. Falling oil prices: Causes, consequences and policy implications. Journal of Petroleum Science and Engineering, v. 149, p. 409-427, 2017.\nKIM, M. S. Impacts of supply and demand factors on declining oil prices. Energy, v. 155, p. 1059-1065, 2018.\nKOTSIANTIS, S. B. Decision trees: a recent overview. Artificial Intelligence Review, v. 39, n. 4, p. 261-283, 2013.\nKUTAS, D. T. et al. A study of the applicability of bourgoyne &amp; young rop model and fitting reliability through regression. In: INTERNATIONAL PETROLEUM TECHNOLOGY CONFERENCE, 2015, Doha, Qatar. Proceedings... Doha, Qatar: International Petroleum Technology Conference, 2015. IPTC-18521-MS.\nLEYS, C. et al. Detecting outliers: Do not use standard deviation around the mean, use absolute deviation around the median. Journal of Experimental Social Psychology, v. 49, n. 4, p. 764766, 2013.\nLITTLE, R. J. A.; RUBIN, D. B. Statistical Analysis with Missing Data. 2nd. ed. Hoboken, NJ - EUA: John Wiley and Sons, Inc., 2002.\nLUMMUS, J. L. Drilling optimization. Journal of Petroleum Technology, v. 22, n. 11, p. 1379-1388, 1970.\nLYONS, W. C.; PLISGA, G. J. Standard Handbook of Petroleum and Natural Gas Engineering. 2nd. ed. [S.l.]: Gulf Professional Publishing, 2004.\nMA, T.; CHEN, P.; ZHAO, J. Overview on vertical and directional drilling technologies for the exploration and exploitation of deep petroleum resources. Geomechanics and Geophysics for Geo-Energy and Geo-Resources, Springer International Publishing, v. 2, n. 4, p. 365-395,\n2016.\nMARLER, R.; ARORA, J. Survey of multi-objective optimization methods for engineering.\nStructural and Multidisciplinary Optimization, v. 26, n. 6, p. 369-395, 2004.\nMATHIS, W. et al. Use of real-time rig-sensor data to improve daily drilling reporting, benchmarking, and planning: A case study. SPE Drilling &amp; Completion, v. 22, n. 03, p. 217-226, 2007.\nMATHWORKS. Function: hampel. 2018. Available at:&lt;https://www.mathworks.com/help/ signal/ref/hampel.html>. Accessed: 19 oct. 2018.\nMATHWORKS. Function. 2018. Available at:&lt;https://www.mathworks.com/help/matlab/ref/ fillmissing.html>. Accessed: 19 oct. 2018.\nMATHWORKS. Function: quantilepredict. 2018. Available at:&lt;https://www.mathworks.com/ help/stats/treebagger.quantilepredict.html>. Accessed: 23 oct. 2018.\n151\nMATHWORKS. Function: fitrensemble. 2018. Available at:&lt;https://www.mathworks.com/ help/stats/fitrensemble.html>. Accessed: 23 oct. 2018.\nMATHWORKS. Tune Random Forest Using Quantile Error and Bayesian Optimization.\t2018. Available at:\t<https://www.mathworks.com/help/stats/\ntune-random-forest-using-quantile-error-and-bayesian-optimization.html>.\tAccessed:\n23 oct. 2018.\nMAURER, W. The \u201cperfect - cleaning\u201d theory of rotary drilling. Journal of Petroleum Technology, v. 14, n. 11, p. 1270-1274, 1962. SPE-408-PA.\nMCCULLOCH, W. S.; PITTS, W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics, v. 5, n. 4, p. 115-133, 1943.\nMEINSHAUSEN, N. Quantile regression forests. Journal of Machine Learning Research, v. 7, p. 983-999, 2006.\nMENDES-MOREIRA, J. et al. Ensemble approaches for regression. ACM Computing Surveys, v. 45, n. 1, p. 1-40, 2012.\nMENG, C. U. I. et al. Maximizing drilling performance with real-time surveillance system based on parameters optimization algorithm. Advances in Petroleum Exploration and Development, v. 8, n. 1,p. 15-24, 2014.\nMINIST\u00c9RIO DE MINAS E ENERGIA. EMPRESA DE PESQUISA ENERG\u00c9TICA. Plano Decenal de Expans\u00e3o de Energia 2026. Bras\u00edlia, 2017. 271 p.\nMITCHELL, R. F.; MISKA, S. Z. Drilling engineering. In: COLE\u00e7\u00e3O, E. da (Ed.). Petroleum Engineering Handbook. [S.l.]: Society of Petroleum Engineers, 2007. Volume 2.\nMITCHELL, R. F.; MISKA, S. Z. Fundamentals of Drilling Engineering. Richardson, TX -EUA: Society of Petroleum Engineers, 2011.\nMOHAN, K.; ADIL, F.; SAMUEL, R. Comprehensive hydromechanical specific energy calculation for drilling efficiency. Journal of Energy Resources Technology, v. 137, n. 1, p. 012904, 2014.\nMORAVEJI, M. K.; NADERI, M. Drilling rate of penetration prediction and optimization using response surface methodology and bat algorithm. Journal of Natural Gas Science and Engineering, v. 31, p. 829-841, 2016.\nMOTAHHARI, H.; HARELAND, G.; JAMES, J. Improved drilling efficiency technique using integrated pdm and pdc bit parameters. Journal of Canadian Petroleum Technology, v. 49, n. 10, p. 45-52, 2010.\nNASCIMENTO, A. Mathematical Modeling for Drilling Optimization in Pre-salt Sections: a Focus on South Atlantic Ocean Operations. 135 f. Tese (Doutorado em Engenharia Mec\u00e2nica) \u2014 Faculdade de Engenharia de Guaratinguet\u00e1, Universidade Estadual Paulista (UNESP), 2016.\nNASCIMENTO, A. et al. Reverse engineering: A new well monitoring and analysis methodology approaching playing-back drill-rate tests in real-time for drilling optimization. Journal of Energy Resources Technology, v. 139, n. 1, p. 12902-12902-5, 2016.\n152\nNASCIMENTO, A. et al. Dynamic drill-rate test approach appplied to a pre-salt case study. In: SPE LATIN AMERICAN AND CARIBBEAN PETROLEUM ENGINEERING CONFERENCE,\n2015,\tQuito, Ecuador. Proceedings... Quito, Ecuador: Society of Petroleum Engineers, 2015. SPE-177141-MS.\nNASCIMENTO, A. et al. Mathematical modeling applied to drilling engineering: An application of bourgoyne and young rop model to a presalt case study. Mathematical Problems in Engineering, v. 2015, p. 9, 2015. Article ID 631290.\nNATEKIN, A.; KNOLL, A. Gradient boosting machines, a tutorial. Frontiers in Neurorobotics, v. 7,p. 23,2013.\nNUNES, F.; LIMA, D. Licita\u00e7\u00f5es de \u00f3leo e g\u00e1s atraem 32 companhias. O Estado de S\u00e3o Paulo,\n2017.\t24 set. 2017. Se\u00e7\u00e3o Economia B5.\nOLULEYE, B. et al. A genetic algorithm-based feature selection. International Journal of Electronics Communication and Computer Engineering, v. 5, n. 4, p. 899-905, 2014.\nOLULEYE, B. et al. Zernike moments and genetic algorithm : Tutorial and application. British Journal of Mathematics &amp; Computer Science, v. 4, n. 15, p. 2217-2236, 2014.\nORGANIZATION OF THE PETROLEUM EXPORTING COUNTRIES. 2017 OPEC World Oil Outlook 2040. 2017. Available at:&lt;http://www.opec.org>. Accessed: jul. 2018.\nOTALVORA, W. C. et al. A comprehensive approach to measure the realtime data quality using key performance indicators. In: SPE ANNUAL TECHNICAL CONFERENCE AND EXHIBITION, 2016, Dubai, UAE. Proceedings... Dubai, UAE: Society of Petroleum Engineers,\n2016.\tSPE-181315-MS.\nPAYETTE, G. S. et al. Real-time well-site based surveillance and optimization platform for drilling: Technology, basic workflows and field results. In: SPE/IADC DRILLING CONFERENCE AND EXHIBITION, 2017, Hague, The Netherlands. Proceedings... Hague, The Netherlands: Society of Petroleum Engineers, 2017. SPE-184615-MS.\nPESSIER, R.; FEAR, M. Quantifying common drilling problems with mechanical specific energy and a bit-specific coefficient of sliding friction. In: SPE ANNUAL TECHNICAL CONFERENCE AND EXHIBITION, 1992, Washington, D.C. Proceedings... Washington, D.C: Society of Petroleum Engineers, 1992.\nPONTES, F. J. et al. Artificial neural networks for machining processes surface roughness modeling. The International Journal of Advanced Manufacturing Technology, v. 49, n. 912, p. 879-902, 2010.\nPREST, B. C. Explanations for the 2014 oil price decline: Supply or demand? Energy Economics, v. 74, p. 63-75, 2018.\nQUINLAN, J. R. The effect of noise on concept learning. In: Machine Learning: Artificial Intelligence Approach, Volume 2. [S.l.]: Morgan Kaufmann Publishers Inc., 1986. cap. 6, p. 149-166.\nRABIA, H. Specific energy as a criterion for drill performance prediction. International Journal of Rock Mechanics and Mining Sciences and, v. 19, n. 1, p. 39-42, 1982.\n153\nRAHMANIFARD, H.; PLAKSINA, T. Application of artificial intelligence techniques in the petroleum industry: a review. Artificial Intelligence Review, Springer Netherlands, p. 1-24,\n2018.\nREN, Y.; ZHANG, L.; SUGANTHAN, P. Ensemble classification and regression-recent developments, applications and future directions [review article]. IEEE Computational Intelligence Magazine, v. 11, n. 1, p. 41-53, 2016.\nROBERTS, J. J. et al. GAtoolbox: a matlab - based genetic algorithm toolbox for function optimization. In: THE 12TH LATIN-AMERICAN CONGRESS ON ELECTRICITY GENERATION AND TRANSMISSION - CLAGTEE 2017, 12., 2017, Mar del Plata. Proceedings... Mar del Plata, 2017. p. 1-12.\nROSENBLATT, F. The perceptron: A probabilistic model for information storage and organization in the brain. Psychological Review, v. 65, n. 6, p. 386-408, 1958.\nROUSSEEUW, P. J.; CROUX, C. Alternatives to the median absolute deviation. Journal of the American Statistical Association, v. 88, n. 424, p. 1273-1283, 1993.\nSAGI, O.; ROKACH, L. Ensemble learning: A survey. WIREs Data Mining and Knowledge Discovery, v. 8, n. 4, p. e1249, 2018.\nSALGADO, C. M. et al. Noise versus outliers. In: ____. Secondary Analysis of Electronic\nHealth Records. Cham: Springer International Publishing, 2016. p. 163-183.\nSARKAR, K.; VISHAL, V.; SINGH, T. N. An empirical correlation of index geomechanical parameters with the compressional wave velocity. Geotechnical and Geological Engineering, v. 30, n. 2, p. 469-479, 2012.\nSCHLUMBERGER. Oilfield Glossary: mud weight. 2018. Available at:&lt;https://www.glossary. oilfield.slb.com/en/Terms/m/mud_weight.aspx>. Accessed: 16 aug. 2018.\nSCHLUMBERGER. Oilfield Glossary: equivalent circulating density. 2018. Available at:&lt;https://www.glossary.oilfield.slb.com/Terms/e/equivalent_circulating_density.aspx>. Accessed: 16 aug. 2018.\nSCRUCCA, L. GA: A package for genetic algorithms in R. Journal of Statistical Software, v. 53, n. 4, p. 213-266, 2013.\nSEBORG, D. E. et al. Process Dynamics and Control. [S.l.]: John Wiley &amp; Sons Inc, 2011.\nSHARMA, P. K.; SINGH, T. N. A correlation between p-wave velocity, impact strength index, slake durability index and uniaxial compressive strength. Bulletin of Engineering Geology and the Environment, v. 67, n. 1, p. 17-22, 2008.\nSHOKOUHI, S. V.; SKALLE, P.; AAMODT, A. An overview of case-based reasoning applications in drilling engineering. Artificial Intelligence Review, v. 41, n. 3, p. 317-329, 2014.\nSILVA, C. F. D. An\u00e1lise geomec\u00e2nica dos carbonatos do pr\u00e9-sal da bacia de santos. 139 f.\nDisserta\u00e7\u00e3o (Mestrado em Engenharia Civil) \u2014 Pontif\u00edcia Universidade Cat\u00f3lica do Rio de\nJaneiro, Rio de Janeiro, Brazil, nov 2016. Available at:&lt;http://www.maxwell.vrac.puc-rio.br/\nBusca_etds.php?strSecao=resultado&amp;nrSeq=30291@1>. Accessed: 5 aug. 2018.\n154\nSKALLE, P. Drilling data some doubts. 2018. [e-mail]. Message received by the author on 28 April 2018.\nSKALLE, P.; AAMODT, A.; ERIKGUNDERSEN, O. Experience transfer for process improvement. Engineering Applications of Artificial Intelligence, v. 26, n. 9, p. 2206-2214, 2013.\nSKJERPEN, T. et al. Modelling and forecasting rig rates on the norwegian continental shelf. Resource and Energy Economics, v. 53, p. 220-239, 2018.\nSNOEK, J.; LAROCHELLE, H.; ADAMS, R. P. Practical Bayesian Optimization of Machine Learning Algorithms. ArXiv e-prints, jun. 2012. Available at:&lt;https://arxiv.org/abs/1206. 2944v2>. Accessed: 22 sep. 2018.\nSOARES, C.; DAIGLE, H.; GRAY, K. Evaluation of pdc bit rop models and the effect of rock strength on model coefficients. Journal of Natural Gas Science and Engineering, v. 34, p. 1225-1236, 2016.\nSOARES, C.; GRAY, K. Real-time predictive capabilities of analytical and machine learning rate of penetration (rop) models. Journal of Petroleum Science and Engineering, n. July, p. 1-26, 2018. (Article in press, DOI: 10.1016/j.petrol.2018.08.083).\nSTAVELEY, C.; THOW, P. Increasing drilling efficiencies through improved collaboration and analysis of real-time and historical drilling data. In: SPE INTELLIGENT ENERGY CONFERENCE AND EXHIBITION, 2010, Utrecht, The Netherland. Proceedings... Utrecht, The Netherlands: Society of Petroleum Engineers, 2010. SPE-128722-MS.\nSTORN, R.; PRICE, K. Differential evolution - a simple and efficient heuristic for global optimization over continuous spaces. Journal of Global Optimization, v. 11, n. 4, p. 341-359, 1997.\nSTROBL, C. et al. Bias in random forest variable importance measures: Illustrations, sources and a solution. BMC Bioinformatics, v. 8, n. 1, p. 25, 2007.\nSZLEK, J.; MENDYK, A. CRAN-R project fscaret: Automated feature selection from \u2019caret\u2019.\n2018.\tAvailable at:&lt;https://CRAN.R-project.org/package=fscaret>.\nTANSEV, E. A heuristic approach to drilling optimization. In: Proceedings... Dallas, Texas: Society of Petroleum Engineers, 1975. p. 18.\nTAVARES, R. M. Interpreta\u00e7\u00e3o e An\u00e1lise de Dados de Perfura\u00e7\u00e3o em Po\u00e7os de Petr\u00f3leo. 145 f. Disserta\u00e7\u00e3o (Mestrado em Ci\u00eancias e Engenharia de Petr\u00f3leo) \u2014 Universidade Estadual de Campinas, Faculdade de Engenharia Mec\u00e2nica e Instituto de Geocie\u00eancias, 2006. Available at:&lt;http://repositorio.unicamp.br/bitstream/REPOSIP/263676/1/Tavares_RogerioMartins_M. pdf>. Accessed: sep. 2018.\nTEALE, R. The concept of specific energy in rock drilling. International Journal of Rock Mechanics and Mining Sciences &amp; Geomechanics Abstracts, v. 2, n. 1, p. 57-73, 1965.\nTHONHAUSER, G. Using real-time data for automated drilling performance analysis. OIL\nGAS European Magazine, v. 4, p. 170-173, 2004.\n155\nVESCONTE, M.-J. L.; TINKHOF, R.; HARDMAN, P. The majnoon field: A case study of drilling operations in a remote area of iraq. In: IADC/SPE DRILLING CONFERENCE AND EXHIBITION, 2014, Fort Worth, Texas. Proceedings... Fort Worth, Texas: Society of Petroleum Engineers, 2014. SPE-167949-MS.\nWANG, Y.; SALEHI, S. Application of real-time field data to optimize drilling hydraulics using neural network approach. Journal of Energy Resources Technology, v. 137, n. 6, p. 062903-062903-9, 2015.\nWARREN, T. Penetration rate performance of roller cone bits. SPE Drilling Engineering, v. 2, n. 01, p. 9-18, 1987. SPE-13259-PA.\nWOLPERT, D. H.; MACREADY, W. G. An efficient method to estimate bagging\u2019s generalization error. Machine Learning, v. 35, n. 1, p. 41-55, 1999.\nXUE, B. et al. A survey on evolutionary computation approaches to feature selection. IEEE Transactions on Evolutionary Computation, v. 20, n. 4, p. 606-626, 2016.\nYOUNG, F. Computerized drilling control. Journal of Petroleum Technology, v. 21, n. 04, p. 483-496, 1969.\nYUAN, P et al. Application of case-based reasoning method on drilling parameter optimization. In: 2009 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SOFTWARE ENGINEERING, 2009, Wuhan, China. Proceedings... Wuhan, China, 2009.\nZADEH, L. Optimality and non-scalar-valued performance criteria. IEEE Transactions on Automatic Control, v. 8, n. 1, p. 59-60, 1963.\nZAMORA, M.; ROY, S. The top 10 reasons to rethink hydraulics and rheology. In: IADC/SPE ASIA PACIFIC DRILLING TECHNOLOGY, 2000, Kuala Lumpur, Malaysia. Proceedings... [S.l.]: Society of Petroleum Engineers, 2000.\nZHANG, Y.; WANG, S.; JI, G. A comprehensive survey on particle swarm optimization algorithm and its applications. Mathematical Problems in Engineering, v. 2015, p. 1-38, 2015. Article ID 931256.\nZHOU, A. et al. Multiobjective evolutionary algorithms: A survey of the state of the art. Swarm and Evolutionary Computation, v. 1, n. 1, p. 32-49, 2011.\nZHU, X.; TANG, L.; YANG, Q. A literature review of approaches for stick-slip vibration suppression in oilwell drillstring. Advances in Mechanical Engineering, v. 6, 2014. Article ID 967952.\n156\nAPPENDIX A - NEW SUGGESTION FOR THE VARIABLE NAMES OF THE WELL 6 FROM NORWAY\nConsidering the amount of variables recorded for each well drilled in the data Real-Time Drilling Data (RTDD.mat) used by (DONNE, 2017), it is possible to classify them into three different groups:\n\u2022\tfirst group - with 8 variables recorded (wells 1-2)\n\u2022\tsecond group - with 10 variables recorded (wells 3-7)\n\u2022\tthird group - with 36 variables recorded (wells 8-10)\nThe sequence in which the variable names appear in the RTDD.cuve_info (see. Figure A.1) were listed in the Table A.1, where it is possible to observe, that the wells 4, 5 and 7 have the same sequence of the variables. The well 3 has a different sequence, but it does not lead to a problem, because the curves shape of the well 3 is similar to the curves obtained for the wells 4, 5 and 7. A problem only occurs when we plot the curves from the well 6, following the variable names given in the RTDD.cuve_info of the file Well6.mat.\nIt was observed that the drilling curves of all wells, except the 6, have a common pattern. We assume that this \u201ccommon pattern\u201d is the right one. This assumption is the basis for the\nFigure A.1 - Getting the sequence of the variable names in RTDD.cuve_info; showing an example for the well 6. The first line of RTDD.cuve_info indicates that the variable 'Time' is recorded in the first column; the variable 'DBTM' is recorded in the second column and so on\n\u2756 \u2666a\nCurrent Folder\nSource: own authorship.\n157\nTable A.1 - Sequence in which the variable names appear in the drilling data with 10 variables recorded (that is, the 2nd group). We highlighted the columns with the problem\nColumn\nDate\t\t# 1\t#2\t#3\t#4\t#5\t#6\t#7\t#8\t#9\t# 10\nwell 3\t02-Apr-2003\t'Time'\t'DBTM'\t'DMEA\t'ROP'\t'WOB'\t'RPMB'\t'HKL'\t'EPOS'\t'TRQ'\t'RPMA'\nwell 4\t16-Jan-2 004\t'Time'\t'DBTM'\t'DMEA'\t'ROP'\t'WOB'\t'RPM\"\t'EPOS'\tHKL'\t'TRQ'\t'RPMA'\nwell 5\t19-Jun-ia93\t'Time'\t'DBTM'\t'DMEA'\t'ROP'\t'WOB'\t'RPM\"\t'EPOS'\tHKL'\t'TRQ'\t'RPMA'\nwell 6\t17-Apr-2005\t'Time'\t'DBTM'\t'DMEA'\t'ROP'\t'WOB'\t'EPOS'\t'HKL'\tTRQ'\t'RPMA'\t\u25a0RPM\nwell 7\t14-Nov-20O4\t'Time'\t'DBTM'\t'DMEA'\t'ROP'\t'WOB'\t'RPM\"\t'EPOS'\tHKL'\t'TRQ'\t'RPMA'\nSource: own authorship.\nfollowing comparison. An example of this \u201ccommon pattern\u201d is given in Figure 4.2, where the curves of the well 4 are plotted.\nWe believe that this assumption is right, because, when the block position goes down, the measured depth of the well increases, and the ROP values indicate also that the well is being drilled. When the block position goes up, the measured depth of the well remains the same, and the ROP goes to zero, as expected. The other parameters, such as hock load, WOB, RPM and torque seem to be adequate for both states, drilling and not-drilling.\nThe plots of all wells have all the same pattern, except the well 6. If we now compare the common pattern (Figure 4.2) with the curves of the well 6 (Figure A.2), according to the sequence of variables presented in RTDD.cuve_info, we realize that the hock load is acting like the block position, and the torque is acting like rpm. Following the suggestion presented in the Table A.2 results in the same curves pattern from all other wells (Figure A.3, which was called here as the \u201ccommon pattern\u201d. The bit rotation magnitude is now around 300 rpm, the same magnitude found in the original graphical study of the real-time drilling data (see Figure A.4).\nBy observing the previous curves, it is possible to conclude that the curves pattern of the well 6 would be the same of other wells, if the sequence of variables were according to the suggestion presented in the Table A.2.\n158\nTable A.2 - Suggestion for the variable names of the well 6. We believe that the sequence of the variable names for the well 6 should be the same as the wells 4, 5 and 7, which can be achieved by only sliding the RPM to the column # 6, and moving the yellow block downwards\nHow it is\t\t\tOur suggestion Variable\t\t\nColumn #\tVariable\tUnit\t\t\t\n1\t'Time'\t's'\tTime\t\t\n2\tDBTM'\tM'\tDBTM\t\t\n3\tDMEA'\tMr\tDMEA\t\t\n4\tROP\u2019\t\u2019MZHR'\tROP\t\t\n5\tWOR1\t'TON1\tWOB\t\t\n\t\u2019EPOS\u2019\t\t\t\t\n6\t\t\u2019M\u2019\tRPM\t\t\n7\tHKL\u2019\t_______\t'TON1\t\t&lt;BPOS^\t\n8\tTRQ'\t\t\tHKL\t\n9\t'RPMA'\t'RPM1\t\tTRQ\t\n10\t\u2019RPM\u2019\t'RPM'\t\tu RPMA_>\t\nSource: own authorship.\nFigure A.2 - Real-time drilling data of well 6 considering the first approx. 8 hours of available recording according to the informed sequence of variable names - state: \u201chow it is\u201d. It is possible to observe that the HKL is acting like the BPOS, and the TRQ like the RPMA.\nSource: dataset available in the work of Donne (2017)\n159\nFigure A.3 - Real-time drilling data of well 6 considering the first approx. 8 hours of available recording according to our suggestion for the variable names - Our suggestion for the sequence of the variable names\nSource: dataset available in the work of Donne (2017)\n160\n161\nFigure A.4 - Graphical Study of the real-time drilling data - well 6 - file 1.\nSource: Donne (2017, Appendix VII, pp. XXXII)\n162\nAPPENDIX B - DRILL-CURVES FROM PRE-SALT\nThe remaining drill-curves from pre-salt not shown in the Chapter 4 are presented in Figure B.1, Figure B.2 and Figure B.3 for respectively Well A, B and D.\nFigure B.1 - Raw recording of drill curves from Well A. The specific energy was calculated based on Rabia\u2019s formulation.\nSource: own authorship.\nIn the Figure B.1, it is possible to observe, at the depth of 4 127 m, an abrupt change in\nthe magnitude of drilling variables. This change coincides with a bit change (NASCIMENTO,\n2016). It will be considered that after this change, the carbonate formation started to be drilled.\nTherefore, the depth of 4 127 m is considered as an cut-off for this dataset. That is, everything\n163\nabove it is discarded. It is also possible to observe that the WOB recording went to round - 130 klbf in the section from 4165 m to 4174 m. In drill-reports, no events related to hydraulics were reports for this well (NASCIMENTO, 2016).\nFigure B.2 - Raw recording of drill curves from Well B. The specific energy was calculated based on Taele\u2019s formulation.\nSource: own authorship.\nSome missing values are present in the dataset from Well B, as seen Figure B.2. However, it is believed that the proposed data pre-treatment method is able to handle this issue, since there is not any long period of missing values. In this well, an kick event was reported at the depth 3 436 - 3 447 m (NASCIMENTO, 2016).\n164\nFigure B.3 - Raw recording of drill curves from Well D. The specific energy that was calculated\nbased on Rabia\u2019s formulation.\nSource: own authorship.\nIn the Well D, a loss event was reported at the depth of 4 543 m 4 546 m (NASCIMENTO, 2016). Three meters above it, a data transmission loss of ECD occurred. The data transmission loss occurred also for some other variables, such as the downhole annular pressure and gammaray. For this reason, the drill-curves from this dataset is considered until this data transmission loss occurs (i.e. until 4 537 m).\n165\nAPPENDIX C - DATA PRE-TREATMENT ANALYSIS OF HAMPEL FILTER\nIn Matlab, there is a function called filloutliers to identified and replace the outliers. For that, several techniques can be employed to identify the outliers, including the moving median absolute deviation. Other function from Matlab is hampel that employs the hampel filter (i.e. moving median absolute deviation).\nThe main difference between both functions is that not-a-number (NaN) instances can be treated as outliers only in the hampel function. With hampel filter, some NaN are identified as outliers, and then replaced by the center value of the moving median. The filloutliers does not identified NaN as outliers. The second difference is the amount of identified outliers differs according to window width. With hampel function, the amount of detected outliers normally decreases with a wider window, while the amount of detected outliers increases with wider window for filloutliers.\nIn the current work, the hampel function is applied in the data pre-treatment process. Two parameters are required to be set: the amount of neighbors in the moving window, and the threshold for outlier detection. The Figure C.1 shows the influence of both parametrics on the amount of outliers detected and on the amount of missing values for pre-salt wells. The amount of detected outliers normally decreases with a higher number of neighbors in the moving window. On the other hand, the amount of missing values (NaN) treated increases with the wider moving window. The higher the threshold TH, the less outliers are identified. However, the threshold has no influence on the amount of NaN treated as outliers.\nThe relative amount of outliers for all drill-curves from pre-salt are shown in Figure C.2 with box-plots. For the drilling data from Norway, such box-plots are in the Figure C.3, where a similar behaviour to pre-salt data can be observed. Based on the analysis of these curves, the selected parameters for the current work are:\n\u2022 number of neighbors in the moving window: 5;\nthreshold: 3.\n166\nFigure\nC.1 - Parametric influence of Hampel filter on detecting outliers. Some missing values (not-a-number instances) are deteced as outliers.\n12\nWell A\n0.15\nRelative Amount of\tRelative Amount\tRelative Amount of\tRelative Amount\nMissing Values\tof Outliers\tMissing Values\tof Outliers\n08 L 0\n11\ni.1\n09\nTH = 2 \u25a0\u25a0\u25a0\u25a0X\u2014 TH = 2.5\tTH = 3\n\nXXX-XMX-XXmX 00C >C DOOO\n20\nX-X-X-X..\n\u2019G>O., -\n5\t10\t15\nWindown Half-Width\n(a)\nWell D\n08\n06\n04\n02\nTH = 2.5\tTH = 3\nTH = 2\n20\n5\t10\t15\nWindown Half-Width\n0 L\n0\n03\n02 01\n0\n\tRelative amount of Missing Values\t\n\t\t\nRelative amount of Missing Values after Hampel Filter\t\t\t\t ft a a a\n0\t5\t10\t15\t20\nWindown Half-Width\n(c)\n\u00a3Z\n0.1\nE CD\n<\n0.05\nCD\ncc\nWell B\n\t\n1\u20140\u2014 TH = 2 \u2014-X\u2014\u25a0\tTH = 2.5 -0- th = 3|\n0\n0\t5\t10\t15\t20\nWindown Half-Width\n0.08\no\n4_. W\nC CD\n0.06\nO ct\nE >\n0.04\n> w\n\u25a0tt w\n\u2014\n0.02\nCE\n0\nRelative amount of Missing Values\nRelative amount of Missing Values after Hampel Filter\n0\t5\t10\t15\t20\nWindown Half-Width\n0.2\n\u00a7\t0.15\no w\nE CD\n0.1\ncti o\n0.05\no\nc\nZ5\no\nE\n<\nCD\n>\nCD\nCE\n(b)\nWell H\nI \u2014 -Q\u2014 TH = 2 \u2014X\u2014 TH = 2.5\u20140\" TH = 3 I\n0\n0\t5\t10\t15\t20\nWindown Half-Width\n0.15\nCD\n0.1 ct >\nCD\nC\n0.05\n0\nRelative amount of Missing Values\nRelative amount of Missing Values after Hampel Filter\nH 888 \u00a9 S ft 8 8SSSSBS'\n0\t5\t10\t15\t20\nWindown Half-Width\n(d)\nSource: own authorship.\n167\nFigure C.2 - Relative amount of outliers for different levels of window half-width and thresholds (TH) - all drill curves from pre-salt.\nRelative Amount of Outliers\tRelative Amount of Outliers\n3\t5\t10 15 20\nWindow Half-Width\nTH = 2.5\n3\t5 10 15 20\nWindow Half-Width\n(b)\nSource: own authorship.\nTH = 3\n3\t5 10 15 20\n(a)\nWindow Half-Width\n(C)\nC.3 - Relative amount of outliers for different levels of window half-width and thresholds\n(TH) - all drill curves from Norway, excluding the well 2.\n3\t5\t10 15 20\nWindow Half-Width\n3\t5 10 15 20\nWindow Half-Width\n(b)\nSource: own authorship.\n3\t5\t10 15 20\nWindow Half-Width\n(a)\n(c)\n168\nAPPENDIX D - DATA PRE-TREATMENT ANALYSIS OF OPERATION RECOGNITION\nThe key element for the automated operation recognition is the definition of the threshold e for each condition: (i) bit on bottom hole, (ii) circulation is present, and (iii) drillstring is rotating. The Figure D.1 illustrates the visual analysis performed to determine the thresholds for each condition. With a little trial and error, the following values for the thresholds were set: \u00a31 = 0.15 (m), e2 = 100 (Ipm) and e3 = 10 (rpm) for the first condition, second condition and third condition respectively. For Norwegian drill curves from the second group (without hydraulic parameters recorded), it is not possible to determine the presence of circulation, so that the drill states are determined by the first and third conditions.\nFigure D.1 - Visual approach to determine the thresholds for the automated operation recognition. For illustration purpose, drill curves from well 8 are plotted. Similar analysis for all other wells was carried out.\n(a)\n(b)\n(c)\nSource: own authorship.\nThe following plots illustrate some common results obtained with the transient recognition\n169\ncode. Such plots were extensively analyzed in order to validate the rules employed to identify transient states. The Figure D.2 shows one of many examples when a change from not-drilling to rotary drilling was correctly recognized.\nFigure D.2 - An example for a transient state correctly identified - well 6 - first change identified.\ndata index\nSource: own authorship.\nIn the Figure D.3, the first change was correctly recognized, but the second transient state could not be recognized when \u00a31 = 0.2m. After reducing this threshold to \u00a31 = 0.15m, the second change was recognized as a transient state.\nThe Figure D.4 illustrates an interesting aspect of the automatic transient recognition. The code was developed to identify a change only in one way, i.e. from not-drilling to rotary drilling. Even though, a change in another direction, from rotary-drilling to not-drilling, was identified.\n170\nFigure D.3 - Reducing the sx from 0.2m to 0.15m could improve the transient state recognition:\na)\tthe second change was not recognized when was 0.2 m; b) the second change was recognized after reducing the tolerance to 0.15 m - well 6 - eighth change identified.\ndata index\n(a) \u00a3i = 0.2m\n30\nS' 20\nE,\nCL\n0\n6370\t6380\t6390\t6400\t6410\t6420\t6430\t6440\t6450\ndata index\n(b) e1 = 0.15m\nSource: own authorship.\nFigure D.4 - An example for a transient states identified from not-drilling to rotary drilling, and vice-verse - well 6 - sixteenth change identified.\ndata index\tx104\nSource: own authorship.\nThe rules to identify the drilling modes are not free of errors. In Figure D.5, a long period of clearly not-drilling state had some observations considered as rotary-drilling. However, the\n171\ntransient recognition code identified them as a change from not-drilling to drilling, and then changed the index to transient state. In this case, the transient state is acting to correct rotary drilling state wrongly identified.\nFigure D.5 - The transient state detection could avoid considering some observations as rotary drilling - well 6 - twenty-first change identified.\n1\nWell 6\n0.5\n\u2014\t-\u2022--not-drilling\n\u2014\t-\u2022---transient\n----------rotary\nO\ncc\n-0.5\n-1\n1.436\t1.437\t1.438\t1.439\t1.44\t1.441\t1.442\t1.443\t1.444\ndata index\tx104\nSource: own authorship.\nDespite several transient states could be correctly recognized, the developed code was not able to identify all possible transient states, especially when often changes from drilling to not-drilling occurred. However, we believe that the rotary drilling state can be systematically obtained, based on rules related to drilling engineering discipline, which is the main purpose of the data pre-treatment process presented in the current work.\n172\nAPPENDIX E - DATA PRE-TREATMENT ANALYSIS OF VALIDATION DRILL CURVES\nThe validation is the last step of data pre-treatment. After hampel filter and, for Norway dataset, automated operation recognition, some observations may still be invalid due to measurement errors. Two rules are employed to check whether an observation is valid or not:\n\u2022\tfirst rule: an observation is invalid if ROP value is above zero and WOB is less or equal than zero;\n\u2022\tsecond rule: an observation is invalid if WOB values is too high. In the case of Norway, the WOB is considered too high if WOB is above 45 ton. For the drill curves from pre-salt region, the threshold is 100 ton.\nThe validation step has a great impact on the drill curves from Norway. To illustrate it, some plots (two-dimensional histograms) are generated for the wells 3 and 4. Both drill curves has not the flow rate measured, so that the automated operation recognition can only be partially performed (the condition for presence of circulation cannot be checked). The plots in the Figure E.1 show two-dimensional histogram of ROP against WOB for the Well 3. After getting the instances considered as rotary drilling, it is possible to observe a small cluster with high values of WOB and ROP near to zero. After the validation step, this small cluster is not considered anymore as rotary drilling.\nFigure E.1 - Two dimensional histogram of ROP against WOB for the Well 3: a) filtered data after step @ with all drilling states, b) after step @ with only rotary drilling state, c) after validation step (5).\n-50\t0\t50\t100\nWOB\n(a) filtered\n100\nWell 3\n80\n60\n40\n20\n0\n0\nCL\nO cc\n100\n80\nWell 3\nCL\no cc\n60\n40\n20\n0\n0\t5\t10\t15\n50\nWOB\nWOB\n(b) rotary drilling\n(c) validated\nSource: own authorship.\n173\nFigure E.2 - Two dimensional histogram of ROP against RPM for the Well 3: a) filtered data after step @ with all drilling states, b) after step @ with only rotary drilling state, c) after validation step (5).\nWell 3\n100\nWell 3\n100\n100\nCL o Ct\n80\n60\n40\n20\n0\nI i\n0 100\n80\n0. 60 o\n20\nCL\nO\nCt\n80\n60\n40\n200\nRPMA\n50\t100\t150\nRPMA\n20\n0 L\n60\nWell 3\n80 100 120\nRPMA\n(c) validated\n(a) filtered\n(b) rotary drilling\n0 L\n0\nSource: own authorship.\nIn the Figure E.2, it is possible to observe a small cluster with low values of RPM and ROP. After the validation step, this cluster was eliminated. This fact is interesting because the validation rules based on other parameters (WOB and ROP) could identify this small cluster. The Figure E.3 illustrates the validation step applying both rules. All plots in this Appendix were generated with a function, called dscatter, developed by Eilers and Goeman (2004).\nFigure E.3 - Two dimensional histogram of ROP against WOB for the Well 4: a) filtered data after step @ with all drilling states, b) after step (T) with only rotary drilling state, c) after validation step (5).\nWOB\n(a) filtered\n80\n60\nCL\n40 Ct\n20\n0 L-\n-50\nWell 4\n0\t50\t100\nWOB\nCL\n80\n60\n40\n20\n0\nWell 4\n0 10\nWOB\n(c) validated\n20\n(b) rotary drilling\nSource: own authorship.\n174\nAPPENDIX F - TORQUE PREDICTION\nWe investigated the estimate accuracy of torque predictive models based on random forest regression, using only four variables as inputs: depth, surface weight on bit, drillstring rotary speed and total flow rate of all active pumps (if available). We followed the same train and test procedure employed to obtain other predictive models in the current works, such as the ROP. The number of variables selected at random for each decision split was set to two. After leaving out a random 20% of observations, we trained random forests with 100 trees on the remaining 80%, and used the left-out 20% as a test set. We repeated this procedure 100 times, and at each time with a different data partition, but maintaining the 80-20 data-partition. We computed the average of training and testing errors for each well, as well as the standard deviation (values shown in parentheses). For clarity, only the average of evaluation metrics are shown in the Table F.1.\nTable F.1 - Torque prediction based on random forests: average of evaluation metrics on train and test dataset.\nWell\tTrain dataset\t\t\t\tTest dataset\t\t\t\n\tMAPEa\tMAE\tMSE\tR\tMAPEa\tMAE\tMSE\tR\nPre-Salt\t\t\t\t\t\t\t\t\nA\t-\t-\t-\t-\t-\t-\t-\t-\nB\t0.023\t0.093\t0.018\t0.912\t0.035\t0.140\t0.038\t0.790\nD\t-\t-\t-\t-\t-\t-\t-\t-\nH\t0.294\t1.038\t3.072\t0.905\t0.437\t1.519\t6.340\t0.759\nNorway\t\t\t\t\t\t\t\t\n3\t0.008\t127.573\t5.193E+04\t0.994\t0.013\t194.994\t1.153E+05\t0.987\n4\t0.005\t96.046\t5.051E+04\t0.978\t0.008\t146.604\t1.127E+05\t0.949\n5\t0.007\t95.025\t6.205E+04\t0.953\t0.011\t143.052\t1.311E+05\t0.899\n6\t0.008\t68.931\t2.420E+04\t0.973\t0.011\t102.686\t4.318E+04\t0.953\n7\t0.009\t132.091\t5.269E+04\t0.985\t0.013\t198.930\t1.149E+05\t0.967\n8\t0.007\t99.877\t2.865E+04\t0.987\t0.011\t148.646\t5.986E+04\t0.973\n9\t0.014\t338.704\t2.561E+05\t0.983\t0.021\t522.945\t5.924E+05\t0.959\n10\t0.023\t334.674\t2.537E+05\t0.970\t0.034\t505.713\t5.529E+05\t0.932\nSource: own authorship.\n175\nANNEX A - ABBREVIATIONS FOR REAL-TIME DRILLING DATA FROM PRE-SALT\nTable A.1 - Mnemonics employed in drilling data from Pre-Salt\nMnemonic\tDescription\tUnit\nAJAM\tAnti-Jams Detected\t-\nBLKA\tBlock Acceleration\tm/s2\nBLKP\tHeight of block above rig floor\tm\nCDEPTH\tComposite Depth\tm\nCRPM\tCollar Rotational Speed\tc/min\nDEPT\tDepth Index\tm\nDHAP\tDownhole Annulus Pressure\tpsi\nDHAT\tDownhole Annulus Temperature\tdegC\nDTOR\tDownhole Torque (MWD)\tft.lbf\nDWOB\tDownhole Weight on Bit\tlbf\nECD\tEquivalent Circulating Density\tlbm/gal\nGR\tGamma Ray\tgAPI\nGR_CAL\tCalibrated Gamma Ray\tgAPI\nHKLA\tAverage Hookload\tlbf\nPVEL\tPipe Velocity\tm/h\nROP\tRate of Penetration\tm/h\nROP5\tRate of Penetration Averaged over the last 5 ft\tm/h\nRPM\tRotational Speed\tc/min\nSHKL\tTotal Shock Level\t-\nSHKR\tShock Rate\t1/s\nSHKRSK\tShock Risk\t-\nSHOCKS_ACC\tTotal shocks accumulated over tool life time\t-\nSPPA\tStandpipe Pressure\tpsi\nSTICK\tStick Slip Indicator\tc/min\nSTICKRATIO\tStick Ratio\t-\nSTOR\tSurface Torque\tft.lbf\nSTUCK\tPercent Time Stuck Below 5 RPM Indicator\t-\nSWOB\tSurface Weight on Bit\tklbf\nTFLO\tTotal Flow Rate of all active pumps\tgal/min\nTRPM\tMWD Turbine Rotation Speed\tc/min\nTVDE\tTrue Vertical Depth\tm\nVIB_LAT\tTransverse RMS Vibration\tgn\nVIB_X\tRMS Vibration X-Axis\tgn\nSource: Nascimento (2016).\n176\nANNEX B - ABBREVIATIONS FOR REAL-TIME DRILLING DATA FROM NORWAY\nTable B.1 - Mnemonics employed in drilling data from Norway\nMnemonic\tDescription\tUnit\nBPOS\tBlock Position\tm\nCEPP\tCement Pump Pressure - Time Based\tbar\nCFI\tCement Flow In - Time Based\tl/min\nCHP\tChoke Pressure - Time Based\tbar\nCTVL\tCementing Total Volume Pumped - Time Based\tm3\nDBTM\tBit Depth (MD)\tm\nDEPT\tBit Depth\tm\nDMEA\tHole depth (MD)\tm\nECDB\tEffective Circulating Density at Bit - Time Based\tg/cm3\nECDM\tMeasured Effective Circulating Density at bit\tg/cm3\nGAS\tTotal gas in mud - Time Based\t%\nHKL\tHookLoad - Time Based\ttonne\nKLP\tKill Line Pressure - Time Based\tbar\nMDI\tMud Density in average - Time Based\tg/cm3\nMDO\tMud Density out average - Time Based\tg/cm3\nMFI\tMud Flow in average - Time Based\tl/min\nMFO\tMud Flow out average - Time Based\tl/min\nMTI\tMud Temperature in - Time Based\tdegC\nMTO\tMud Temperature Out - Time Based\tdegC\nROP\tRate of Penetration\tm/h\nRPM\tAverage Rotary Speed\trev/min\nRPMA\tString RPM average\trpm\nRPMB\tBit RPM average\trpm\nSPP\tStand Pipe Pressure average - Time Based\tbar\nSPPA\tAverage Standpipe Pressure\tkPa\nSWOB\tWeight on Bit\t1000 kgf\nTPVT\tTrip pit volume totaliser - Time Based\t3 m3\nTRQ\tTorque - Time Based\tkN.m\nTVA\tActive Tank Volume\t3 m3\nWOB\tWeight on bit - Time Based\ttonne\nSource: Skalle (2018)."}]}}}