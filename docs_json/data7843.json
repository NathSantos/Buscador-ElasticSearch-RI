{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.10782"}, {"@name": "filename", "#text": "15944_000594748.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNIVERSIDADE FEDERAL DO RIO GRANDE DO SUL\nINSTITUTO DE INFORMA?TICA\n\nPROGRAMA DE PO?S-GRADUAC?A?O EM COMPUTAC?A?O\n\nCLARISSA CASSALES MARQUEZAN\n\nIntegrated Cluster Environmnet\n\n(ICE) - Plataforma de Gerenciamento\ne de Acesso a Mu?ltiplos Clusters\n\nDissertac?a?o apresentada como requisito parcial\npara a obtenc?a?o do grau de\nMestre em Cie?ncia da Computac?a?o\n\nProf. Dr. Philippe O. A. Navaux\nOrientador\n\nProf. Dr. Alexandre da Silva Carissimi\nCo-orientador\n\nPorto Alegre, agosto de 2006\n\n\n\nCIP \u2013 CATALOGAC?A?O NA PUBLICAC?A?O\n\nMarquezan, Clarissa Cassales\n\nIntegrated Cluster Environmnet (ICE) - Plataforma de\nGerenciamento e de Acesso a Mu?ltiplos Clusters / Clarissa\nCassales Marquezan. \u2013 Porto Alegre: PPGC da UFRGS, 2006.\n\n97 f.: il.\n\nDissertac?a?o (mestrado) \u2013 Universidade Federal do Rio\nGrande do Sul. Programa de Po?s-Graduac?a?o em Com-\nputac?a?o, Porto Alegre, BR\u2013RS, 2006. Orientador: Philippe\nO. A. Navaux; Co-orientador: Alexandre da Silva Carissimi.\n\n1. Mu?ltiplos clusters. 2. Gerenciamento. 3. Extensibili-\ndade. 4. Transpare?ncia. 5. Interoperabilidade. 6. Web Servi-\nces. I. Navaux, Philippe O. A.. II. Carissimi, Alexandre da\nSilva. III. T??tulo.\n\nUNIVERSIDADE FEDERAL DO RIO GRANDE DO SUL\nReitor: Prof. Jose? Carlos Ferraz Hennemann\nPro?-Reitor de Coordenac?a?o Acade?mica: Prof. Pedro Cezar Dutra Fonseca\nPro?-Reitora de Po?s-Graduac?a?o: Profa. Valqu??ria Linck Bassani\nDiretor do Instituto de Informa?tica: Prof. Fla?vio Rech Wagner\nCoordenador do PPGC: Prof. Carlos Alberto Heuser\nBiblioteca?ria-chefe do Instituto de Informa?tica: Beatriz Regina Bastos Haro\n\n\n\n\u201dUm amigo e? algue?m que sabe tudo a seu respeito e gosta de voce? assim\n\nmesmo.\u201dElbert Hubbard\n\n\n\nAGRADECIMENTOS\n\nEm primeiro lugar quero agradecer a? minha fam??lia pelo apoio irrestrito, incen-\ntivo e vibrac?a?o com as conquistas que tive ate? hoje e tenho certeza que ela vai estar\nsempre comigo. Tambe?m agradec?o pela pacie?ncia e compreensa?o que tiveram nos\nmomentos em que na?o pude estar junto. Em especial agradec?o a?s minhas irma?s,\nLuciana, Anna Lucia e Gabriela, ao meu pai e a? minha ma?e, voce?s sa?o realmente\nmuito importantes pra mim.\n\nAgradec?o ao meu orientador, prof. Philippe Olivier Alexandre Navaux, com\nquem trabalho em pesquisa desde a iniciac?a?o cient??fica. Quero agradecer pelo in-\nvestimento que fez em mim, por ter sempre me incentivado, mostrado os melhores\ncaminhos a seguir para atingi os objetivos. Agradec?o todo o conhecimento que o prof.\nNavaux me ajudou a formar, na?o somente conhecimento acade?mico, mas tambe?m\no conhecimento de vida, de como interagir com as pessoas, de como conduzir a\npesquisa, de como motivar e incentivar as pessoas a evolu??rem.\n\nTambe?m agradec?o ao meu co-orientador, prof. Alexandre Carissimi da Silva,\ncom quem comecei a trabalhar em pesquisa no mestrado. Um agradecimento por ter\nsempre me lembrado de manter o foco no meu trabalho de mestrado, de na?o dispersar\nminha atenc?a?o com trabalhos paralelos. Essas recomendac?o?es foram realmente muito\nimportantes para mim. Agradec?o tambe?m pelas discusso?es te?cnicas, pelas correc?o?es\nde rumo do trabalho e pelo incentivo.\n\nExistem pessoas que participaram ativamente do meu trabalho de mestrado,\nas quais na?o posso deixar de agradecer: Lucas Schnorr, Rodrigo da Rosa Righi,\nNicolas Maillard e Alexandre Ilha. As discusso?es que tivemos, as trocas de ide?ias\nforam muito importantes para o amadurecimento e para a conclusa?o deste trabalho.\nAinda quando agiram como \u2019advogados do diabo\u2019 foram perfeitos, pois me fizeram\ncorrer atra?s de respostas e de soluc?o?es.\n\nAgradec?o tambe?m a uma pessoa que na?o contribuiu diretamente no meu tra-\nbalho de mestrado, mas as oportunidades que ele me proporcionou contribu??ram a\naquisic?a?o e utilizac?a?o de conhecimento nesta dissertac?ao?. Muito obrigada ao prof.\nLisandro Zanbenedetti Granville.\n\nNa?o posso deixar de agradecer a compreensa?o do meu chefe na Divisa?o de Redes e\nSuporte (DRS) do CPD da UFRGS, Leandro Rey, possibilitando-me uma grande fle-\nxibilidade de hora?rio para que eu pudesse terminar a dissertac?a?o. Agradec?o tambe?m,\naos colegas de trabalho na DRS, pelo incentivo.\n\nAos amigos Rafael Ennes Silva e Priscilla Kurtz um agradecimento pelo compa-\nnheirismo durante os va?rios finais de semana, noites e madrugadas que passamos na\nsala 209 terminando nossas dissertac?o?es e trabalho de conclusa?o, no caso da Priscilla.\nForam dias e noites de grande trabalho, mas tambe?m de muita diversa?o.\n\n\n\nAgradec?o aos amigos 99, principalmente o Diego Contessa (Cac?ula) e o Daniel\nGaspary (Chewie), por sempre me motivarem, seja ao vivo ou pelo ICQ ou MSN.\nAos amigos que esta?o longe, muitos em outros continentes (Karina Roggia e Tiago\nFiorezi), agradec?o pelo carinho e tambe?m pelo incentivo remoto. Aos amigos das\na?ureas e?pocas do Labcom pelas conversas, momentos divertidos e pela amizade.\n\nAos meus amigos, ou melhor, a? minha fam??lia do Coral Procergs, pela pacie?ncia\ne compreensa?o nos momentos que tive de me afastar dos ensaios para terminar a\ndissertac?a?o. Quero que voce?s saibam que participar deste grupo me da? motivac?a?o\npara a vida e para o trabalho. Voce?s sa?o muito importantes para mim.\n\nAgradec?o o incentivo, algumas vezes na?o ortodoxo, dos companheiros e amigos\nda sala 209, os churrascos, os momentos de descontrac?a?o em bares conhecidos da\ncidade de Porto Alegre, e no famoso bar perto do Campus do Vale. E Hermann,\neu terminei a dissertac?a?o antes que tu! (Existiam apostas de que eu na?o terminaria\nantes dele, hehehe.)\n\nTambe?m agradec?o aos amigos de pedaladas por me proporcionarem passeios para\ndistrair um pouco a mente dos percalc?os do trabalho.\n\nNa?o poderia deixar de agradecer a compreensa?o, amizade e incentivo dos meus\namigos de Rosa?rio do Sul. Em especial a?s minhas amigas Ana Paula e Maria Jose?\nque, por muitas vezes, na?o pude estar junto delas, mas que sabem que a nossa\namizade esta? acima da presenc?a f??sica.\n\nEnfim, existem muitas pessoas importantes na minha vida e que contribu??ram\npara a minha formac?a?o e vida pessoal. A todas elas, na?o citadas nominalmente,\nagradec?o com a mesma intensidade e vibrac?a?o.\n\nMuito obrigada!!!\n\n\n\nSUMA?RIO\n\nLISTA DE ABREVIATURAS E SIGLAS . . . . . . . . . . . . . . . . . . . 8\n\nLISTA DE FIGURAS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n\nLISTA DE TABELAS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n\nRESUMO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n\nABSTRACT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n\n1 INTRODUC?A?O . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n1.1 Objetivos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n1.2 Organizac?a?o . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n\n2 ESTADO DA ARTE EM GERENCIAMENTO DE SISTEMAS DE\n\nALTO DESEMPENHO . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n2.1 Sistemas Distribu??dos . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n2.2 Sistemas de Alto Desempenho . . . . . . . . . . . . . . . . . . . . . 19\n2.2.1 Clusters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.2.2 Grids . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.2.3 Intersecc?a?o entre clusters e grids: sistemas Multicluster . . . . . . . . 26\n2.3 Resumo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n\n3 PROPOSTA DE AMBIENTE INTEGRADO PARA CLUSTERS: ICE 29\n3.1 ICE como um Sistema Distribu??do . . . . . . . . . . . . . . . . . . 31\n3.2 Arquitetura ICE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n3.2.1 Middleware de Servic?os . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n3.2.2 Portal Web . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n3.2.3 Cena?rio de Aplicac?a?o da Arquitetura ICE . . . . . . . . . . . . . . . . 37\n3.3 Resumo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n\n4 DESENVOLVIMENTO DO PROTO?TIPO DO AMBIENTE ICE . . . 39\n4.1 Deciso?es de Projeto . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n4.1.1 Definic?a?o do Middleware Empregado . . . . . . . . . . . . . . . . . . 39\n4.1.2 Ana?lise dos Padro?es e Especificac?o?es . . . . . . . . . . . . . . . . . . . 41\n4.2 Descric?a?o do Proto?tipo Implementado . . . . . . . . . . . . . . . . 43\n4.2.1 Tecnologias Empregadas . . . . . . . . . . . . . . . . . . . . . . . . . 44\n4.2.2 Middleware de Servic?o para Gerenciamento de Aplicac?o?es . . . . . . . 45\n4.2.3 Portal Web . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n\n\n\n4.3 Resumo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n\n5 AVALIAC?A?O DO PROTO?TIPO ICE . . . . . . . . . . . . . . . . . . . 71\n5.1 Avaliac?a?o Qualitativa . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n5.1.1 Metodologia . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n5.1.2 Comparac?a?o entre HPC2N, M3C e ICE . . . . . . . . . . . . . . . . . 72\n5.2 Avaliac?a?o Quantitativa . . . . . . . . . . . . . . . . . . . . . . . . . 74\n5.2.1 Definic?a?o do escopo das medic?o?es . . . . . . . . . . . . . . . . . . . . 74\n5.2.2 Metodologia . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n5.2.3 Plataforma . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n5.2.4 Experimentos com a operac?a?o de submissa?o de aplicac?o?es . . . . . . . 77\n5.2.5 Experimentos com a operac?a?o de visualizac?a?o de scripts de submissa?o 80\n5.2.6 Experimentos com a operac?a?o de finalizac?a?o de aplicac?o?es . . . . . . . 82\n5.2.7 Experimentos com a operac?a?o de visualizac?a?o de status . . . . . . . . 83\n5.2.8 Experimentos com a operac?a?o de recuperac?a?o das sa??das padra?o . . . 83\n5.3 Resumo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\n\n6 CONCLUSA?O . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\n6.1 Trabalhos em Paralelo . . . . . . . . . . . . . . . . . . . . . . . . . . 87\n6.2 Trabalhos Futuros . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n\nREFERE?NCIAS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\n\n\n\nLISTA DE ABREVIATURAS E SIGLAS\n\nC3 Cornell Checkpoint (pre)Compiler\n\nC3 Cluster Command and Control\n\nCORBA Commom Object Request Broker Architecture\n\nDCOM Distributed Component Object Model\n\nER Entidade Relacionamento\n\nGGF Global Grid Forum\n\nGMA Grid Monitoring Architecture\n\nGPPD Grupo de Processamento Paralelo e Distribu??do\n\nGRAM Grid Resource Allocation and Management\n\nGSI Grid Security Infrastructure\n\nGT Globus Toolkit\n\nHPC High Performance Computing\n\nHPC2N High Performance Computing Center North\n\nHTTP Hypertext Transfer Protocol\n\nICE Integrated Cluster Environment\n\nIOR Internet-wide Object Reference\n\nJSP Java Server Pages\n\nM3C Managing and Monitoring Multiple Clusters\n\nMPP Massive Parallel Processing\n\nMTBF MeanTime Between Failures\n\nMVC Model View Controller\n\nOASIS Organization for the Advancement of Structured Information Standards\n\nOGSA Open Grid Service Architecture\n\nOGSI Open Grid Service Infrastructure\n\nOpenPBS Open Portable Batch System\n\nOpenSCE Open Scalable Cluster Environment\n\n\n\nORB Object Request Broker\n\nOSCAR Open Source Cluster Application Resource\n\nP2P Peer-to-Peer\n\nPDA Personal Digital Assistants\n\nPUNCH Purdue University Network Computing Hubs\n\nQAME QoS-Aware Management Environment\n\nRMI Remote Method Invocation\n\nRPC Remote Procedure Call\n\nSCMS Smile Cluster Management System\n\nSGBD Sistema de Gerenciamento de Base de dados\n\nSGE Sun Grid Engine\n\nSI Service Implementation\n\nSM Service Module\n\nSMM System Management Module\n\nSNMP Simple Network Management Protocol\n\nSOA Service Oriented Architecture\n\nSOAP Simple Object Access Protocol\n\nUDDI Universal Description Discovery and Integration\n\nURI Identificador Universal de Recursos\n\nUSI Unified Service Interface\n\nVPN Virtual Private Network\n\nW3C World Wide Web Consortium\n\nWS Web Services\n\nWSDL Web Services Description Language\n\nWSGRAM Web Services Grid Resource Allocation and Management\n\n\n\nLISTA DE FIGURAS\n\nFigura 2.1: Lista de aplicac?o?es existentes nas ma?quinas que fazem parte do\nTop 500 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n\nFigura 3.1: Visa?o geral do cena?rio de utilizac?a?o do ICE . . . . . . . . . . . . 32\nFigura 3.2: Arquitetura ICE . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\nFigura 3.3: Instanciac?a?o da Arquitetura ICE . . . . . . . . . . . . . . . . . . 37\n\nFigura 4.1: Arquitetura do Globus Toolkit v4 - Figura retirada do draft (GLO-\nBUS Toolkit 4.0 RELEASE MANUALS, 2005) . . . . . . . . . . 42\n\nFigura 4.2: Proto?tipo ICE Implementado . . . . . . . . . . . . . . . . . . . . 44\nFigura 4.3: JMF - Job Management Framework . . . . . . . . . . . . . . . . . 51\nFigura 4.4: Diagrama de classes para o pacote de classes auxiliares . . . . . . 52\nFigura 4.5: Diagrama de classes para as implementac?o?es do OpenPBS-SI e\n\nOAR-SI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\nFigura 4.6: Elementos XML da requisic?a?o das operac?o?es de submissa?o e vi-\n\nsualizac?a?o de scripts . . . . . . . . . . . . . . . . . . . . . . . . . 55\nFigura 4.7: Exemplo de retorno da operac?a?o de submissa?o. (a) Submissa?o\n\ncom OpenPBS (b) Submissa?o com OAR . . . . . . . . . . . . . . 55\nFigura 4.8: Exemplo de retorno da operac?a?o de submissa?o contendo erro. . . 56\nFigura 4.9: Elementos XML de retorno da operac?a?o de visualizac?a?o de scripts. 56\nFigura 4.10: Exemplo de retorno da operac?a?o de visualizac?a?o em um cluster\n\ncom OpenPBS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\nFigura 4.11: Exemplo de retorno da operac?a?o de visualizac?a?o em um cluster\n\ncom OAR. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\nFigura 4.12: Elementos XML de requisic?a?o e retorno da operac?a?o de finalizac?a?o. 58\nFigura 4.13: Exemplo de retorno da operac?a?o de verificac?a?o de estado das filas\n\ndo gerenciador OAR. . . . . . . . . . . . . . . . . . . . . . . . . . 59\nFigura 4.14: Elementos XML da requisic?a?o e resposta da operac?a?o de recu-\n\nperac?a?o de arquivos de sa??da. . . . . . . . . . . . . . . . . . . . . 60\nFigura 4.15: Diagrama de classes do JM-SM . . . . . . . . . . . . . . . . . . . 61\nFigura 4.16: Diagrama Entidade Relacionamento (ER) do ambiente ICE . . . 62\nFigura 4.17: Snapshot Portal Web - Configurac?a?o de operac?o?es . . . . . . . . . 63\nFigura 4.18: Snapshot Portal Web - Pa?gina principal da configurac?a?o de grupos 64\nFigura 4.19: Snapshot Portal Web - Associac?a?o de clusters a grupos . . . . . . 64\nFigura 4.20: Snapshot Portal Web - Associac?a?o de funcionalidades a grupos . . 65\nFigura 4.21: Snapshot Portal Web - Associac?a?o de funcionalidades a clusters . 66\nFigura 4.22: Snapshot Portal Web - Pa?gina principal do menu Job Management 67\nFigura 4.23: Snapshot Portal Web - Pa?gina de submissa?o de aplicac?o?es . . . . 67\n\n\n\nFigura 4.24: ER da funcionalidade de Job Management . . . . . . . . . . . . . 68\nFigura 4.25: Exemplo 1 de visualizac?a?o de scripts de submissa?o . . . . . . . . 68\nFigura 4.26: Exemplo 2 de visualizac?a?o de scripts de submissa?o . . . . . . . . 69\n\nFigura 5.1: Cena?rio de aquisic?a?o das medidas de overhead . . . . . . . . . . . 75\nFigura 5.2: Gra?fico Operac?a?o de Submissa?o - OpenPBS . . . . . . . . . . . . 77\nFigura 5.3: Gra?fico Operac?a?o de Submissa?o - OAR . . . . . . . . . . . . . . . 78\nFigura 5.4: Gra?fico Operac?a?o de Visualizac?a?o de Scripts - OpenPBS . . . . . 80\nFigura 5.5: Gra?fico Operac?a?o de Visualizac?a?o de Scripts - OAR . . . . . . . . 81\n\n\n\nLISTA DE TABELAS\n\nTabela 3.1: Descric?a?o dos perfis atualmente definidos no ambiente ICE . . . . 36\n\nTabela 4.1: Comparac?a?o entre CORBA e Web Services . . . . . . . . . . . . . 40\nTabela 4.2: Operac?o?es da JM-USI . . . . . . . . . . . . . . . . . . . . . . . . 46\n\nTabela 5.1: Comparac?a?o entre o ambiente ICE e algumas ferramentas relaci-\nonadas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n\nTabela 5.2: Descric?a?o das variac?o?es de para?metros para submissa?o de aplicac?o?es. 76\nTabela 5.3: Descric?a?o do cluster utilizado para os experimentos . . . . . . . . 77\nTabela 5.4: Desvio padra?o para operac?a?o de submissa?o . . . . . . . . . . . . . 79\nTabela 5.5: Desvio padra?o para operac?a?o de verificac?a?o de scripts . . . . . . . 81\nTabela 5.6: Desempenho da operac?a?o de finalizac?a?o de aplicac?o?es . . . . . . . 82\nTabela 5.7: Desempenho da operac?a?o de verificac?a?o do status das aplicac?o?es . 83\nTabela 5.8: Desempenho da operac?a?o de recuperac?a?o das sa??das padra?o . . . . 84\n\n\n\nRESUMO\n\nFacilitar o gerenciamento e o acesso a sistemas de alto desempenho vem sendo\numa a?rea de pesquisa explorada nos u?ltimos anos. Isto acontece uma vez que se\nverifica o aumento do nu?mero de usua?rios, muitos pertencentes a outras a?reas, como\npor exemplo, biologia, geologia, hidrologia, etc e, desta forma, e? preciso facilitar\nos meios de interac?a?o destes usua?rios com tais sistemas, assim como melhorar as\nte?cnicas de gerenciamento dos mesmos. Ale?m do aumento do nu?mero e da mul-\ntidisciplinaridade desses usua?rios, existe tambe?m o fato de que grande parte deles\ntem acesso a diferentes tipos de sistemas de alto desempenho. Em geral, estes sis-\ntemas possuem ferramentas na?o padronizadas, sendo que cada uma apresenta uma\ninterface e um conjunto de ac?o?es e comandos a serem realizados para que possam\ndispor de suas funcionalidades. Este trabalho propo?e a definic?a?o de uma arquite-\ntura de gerenciamento e acesso a mu?ltiplos clusters, que seja capaz de ser facilmente\nextens??vel, transparente, interopera?vel e de fa?cil utilizac?a?o, configurac?a?o e manu-\ntenc?a?o. Como resultado da arquitetura proposta, foi desenvolvido um proto?tipo,\ndenominado ICE - Integrated Cluster Environment. Os principais objetivos da ar-\nquitetura e do ambiente ICE sa?o: (i) capacidade de uniformizac?a?o do modo como as\nferramentas de clusters sa?o utilizadas e, tambe?m, uniformizac?a?o na maneira como\nos clusters sa?o acessados; (ii) transpare?ncia na forma de acesso e uso dos clusters; e\n(iii) capacidade de extensibilidade em dois n??veis: o primeiro refere-se a? extensibili-\ndade do nu?mero de funcionalidades (servic?os) providos pelo sistema e o segundo esta?\nrelacionado a? capacidade do sistema lidar com o uso de diferentes ferramentas que\npossuem a mesma funcionalidade. Ale?m da descric?a?o da arquitetura e do proto?tipo,\nneste trabalho, tambe?m e? realizada uma avaliac?a?o do ambiente ICE. Essa avaliac?a?o\nfoi dividida em dois momentos. O primeiro traz a comparac?a?o das caracter??sticas\ndo ambiente proposto com algumas ferramentas relacionadas. No segundo momento\nsa?o apresentados alguns experimentos que visam identificar o overhead inserido pelo\nambiente ICE na execuc?a?o das operac?o?es do mo?dulo de gerenciamento de aplicac?o?es,\ndesenvolvido e descrito neste trabalho.\n\nPalavras-chave: Mu?ltiplos clusters, gerenciamento, extensibilidade, transpare?ncia,\ninteroperabilidade, Web Services.\n\n\n\nABSTRACT\n\nIntegrated Cluster Environmnet (ICE): Management and Access\nPlatform for Multiple Clusters\n\nSome researches have been done over the last years in order to improve the man-\nagement and access of high performance systems. One of the motivations of these\nresearches is the continuously increase in the number of users who, not rarely, belong\nto other areas, such as biology, geology, hydrology, etc; so it is necessary to provide\nsome access and also management facilities in these kinds of systems. Further-\nmore, the users also have access to different kinds of high performance systems, and\nthey have to deal with distinct tools of their underlying, which are not standardize.\nTherefore, the users need to learn the specificities of each tool in each high perfor-\nmace system that they have permission to access. Aiming to solve this problem,\nthis work proposes an architecture to provide access and management of multiple\nclusters with extensibility, transparance, interoperability, user-friendly, manageabil-\nity and maintainability. As a result of the proposed architecture, a prototype called\nICE - Integrated Cluster Environment - was developed. The main goals of the archi-\ntecture and the ICE environment are: (i) the capability of uniforming the manner\nthe cluster tools are used and accessed; (ii) cluster access and transparence use; and\n(iii) two extensibility levels: the first one refers to capability of extending the number\nof functionalities/services provided by the environment and the second one concerns\nto the capability of extending the number of tools, with the same functionality, the\nsystem is able to manage. Beyond the architecture and prototype description, this\nresearch presents the evaluation of ICE environment, which is divided in two parts.\nThe first one brings the comparison of the features between ICE and some related\nwork. The second part shows some experiments that intend to verify the overhead\ninserted by ICE environment when performing the tasks of the job management\nmodule, also developed and explained in this work.\n\nKeywords: multiple clusters, management, extensibility, transparence, interopera-\nbility, Web Services.\n\n\n\n15\n\n1 INTRODUC?A?O\n\nOs sistemas distribu??dos esta?o presentes em quase todas as ac?o?es realizadas nos\ntempos atuais. Desde a operac?a?o de verificar o saldo banca?rio, o pagamento de uma\nconta atrave?s do carta?o de cre?dito, ate? a verificac?a?o da previsa?o do tempo (a qual\ne? atingida atrave?s do uso de sistemas de alto desempenho). Sistemas distribu??dos\ncompreendem uma gama muito grande de cena?rios, como por exemplo: a Internet,\nintranets, redes locais de universidades e empresas, redes sem fio etc. No escopo\ndeste trabalho sera?o considerados os sistemas distribu??dos cujo foco e? a obtenc?a?o\nde melhor desempenho das aplicac?o?es. Tais sistemas sa?o chamados de Sistemas de\nAlto Desempenho (HPC - High Performance Computing). Em geral sa?o formados\npor ma?quinas de redes locais, que podem ou na?o estar ligadas a outras redes.\n\nCada vez mais, o gerenciamento desse tipo de sistema torna-se uma tarefa com-\nplexa, que requer um nu?mero maior de varia?veis e ferramentas. Pode-se dizer que\ndentro da a?rea de HPC existem tre?s grandes a?reas de utilizac?a?o: clusters, grids\ne mu?ltiplos clusters. Para cada uma destas a?reas existem diversas ferramentas\npara gerenciamento. Algumas delas sa?o: OSCAR (LIGNERIS; et al., 2003; OS-\nCAR - OPEN SOURCE CLUSTER APPLICATION RESOURCES, 2005), PUNCH\n(ADABALA; KAPADIA; FORTES, 2000; PARK; et al., 2000), ROCKS (PAPADO-\nPOULOS; KATZ; BRUNO, 2001), OpenSCE (UTHAYOPAS; ANGSKUN; MANE-\nESILP, 2001, 2002; OPENSCE - SCALABLE CLUSTER ENVIRONMENT, 2005),\nferramenta de gerenciamento de clusters atrave?s de SNMP (ALVES et al., 2004;\nALVES; MARQUEZAN; GRANVILLE, 2004; ALVES et al., 2005), entre outras no\ncena?rio de clusters; e Globus (FOSTER; KESSELMAN, 1997; GLOBUS - WEL-\nCOME TO THE GLOBUS TOOLKIT HOMEPAGE, 2005), Condor (GONZ; et\nal., 2002; THAIN; TANNENBAUM; LIVYN, 2003), GridRM (BAKER; SMITH,\n2003), GridSphere (NOVOTNY; RUSSELL; WEHRENS, 2004), entre va?rias outras\nno escopo de gerenciamento de grids. No cena?rio de gerenciamento de mu?ltiplos\nclusters na?o existe a mesma variedade de ferramentas como encontrado nos demais\ncena?rios. Exemplos de ferramentas voltadas para o gerenciamento de mu?ltiplos\nclusters sa?o: M3C (BRIM; et al., 2001) e HPC2N (ELMROTH; NYLE?N; OSCARS-\nSON, 2005). Tambe?m identifica-se que as ferramentas que compo?em este u?ltimo\ncena?rio na?o apresentam caracter??sticas importantes de sistemas distribu??dos, como\npor exemplo: transpare?ncia de acesso, extensibilidade, uniformizac?a?o das operac?o?es,\ncompleteza, interoperabilidade, capacidade de incorporac?a?o dos sistemas de geren-\nciamento legados e construc?a?o de ferramentas amiga?veis para os usua?rios.\n\nDadas as caracter??sticas de sistemas distribu??dos ainda na?o disponibilizadas nas\nferramentas de gerenciamento de mu?ltiplos clusters, propo?e-se o ambiente ICE -\nIntegrated Cluster Environment.\n\n\n\n16\n\n1.1 Objetivos\n\nOs objetivos deste trabalho sa?o: (i) definic?a?o de uma arquitetura de gerenci-\namento e acesso a mu?ltiplos clusters que seja capaz de ser facilmente extens??vel,\ntransparente, interopera?vel e de fa?cil utilizac?a?o, configurac?a?o e manutenc?a?o; (ii) im-\nplementac?a?o de um proto?tipo seguindo esta arquitetura; e (iii) validac?a?o das ide?ias\ncontidas na arquitetura e no proto?tipo implementado. A principal questa?o do tra-\nbalho desenvolvido e? permitir que os usua?rios lidem com as funcionalidades dos\nclusters, como por exemplo gerenciamento de aplicac?o?es e monitoramento de recur-\nsos, em alto n??vel, enquanto as especificidades de cada ferramenta sera?o abstra??das\ne providas pela camada definida no trabalho. Uma alternativa seria a utilizac?a?o\ndas ferramentas de grid para prover essas abstrac?o?es. Entretanto, essas ferramentas\ninserem um alto grau de complexidade, e dependendo do tipo de ferramenta de grid\nempregada a execuc?a?o de aplicac?o?es verdadeiramente paralelas, e na?o do tipo bag of\ntasks, podem ser afetadas pela forma como elas sa?o distribu??das nos recursos.\n\nNo contexto do trabalho que e? apresentado nesta dissertac?a?o defende-se a ide?ia\nde trazer os conceitos da a?rea de grid, como por exemplo arquiteturas orientadas a\nservic?os e interoperabilidade, para a a?rea de mu?ltiplos clusters, mantendo a simplici-\ndade do cena?rio e provendo as facilidades que as ferramentas de grid disponibilizam\npara os usua?rios e administradores.\n\n1.2 Organizac?a?o\n\nEste trabalho esta? organizado como descrito a seguir.\nO Cap??tulo 2 possui o levantamento do estado da arte do gerenciamento de sis-\n\ntemas distribu??dos, mais especificamente focando em sistemas de alto desempenho\n(HPC - High Performance Computing). Neste escopo sera?o apresentados tre?s gran-\ndes a?reas: clusters, grids e mu?ltiplos clusters. Para cada uma dessas a?reas sera?o\napresentados os cena?rios de utilizac?a?o os problemas de gerenciamento e algumas\nferramentas para lidar com esses problemas.\n\nO Cap??tulo 3 apresenta a proposta de desenvolvimento do ambiente ICE. Um\nambiente voltado para o gerenciamento e acesso de mu?ltiplos clusters. Suas prin-\ncipais caracter??sticas sa?o transpare?ncia, extensibilidade e interoperabilidade. Seu\nescopo de utilizac?a?o e arquitetura sa?o descritos nas subsec?o?es desse cap??tulo.\n\nNo Cap??tulo 4 e? feita a descric?a?o do proto?tipo implementado com base nas de-\nfinic?o?es e na arquitetura do ambiente ICE, propostos no cap??tulo anterior. Aqui\nsa?o detalhados os componentes do ambiente, seus relacionamentos, o modelo de\ninformac?a?o e, como resultado final, sa?o apresentadas telas do proto?tipo ICE.\n\nO Cap??tulo 5 conte?m a avaliac?a?o do ambiente proposto e da implementac?a?o do\nproto?tipo. Este cap??tulo esta? dividido em dois momentos. Primeiramente e? realizada\numa comparac?a?o entre o ambiente ICE e algumas ferramentas relacionadas. Em um\nsegundo momento e? descrita a avaliac?a?o quantitativa do proto?tipo desenvolvido,\nonde foi medido o overhead inserido pelo proto?tipo no front-end do cluster utilizado\npara testes.\n\nFinalmente no Cap??tulo 6 sa?o apresentadas as considerac?o?es finais sobre este\ntrabalho e sa?o destacados alguns trabalhos relacionados ao ambiente ICE que ve?m\nsendo desenvolvidos em paralelo ao andamento desta dissertac?a?o, assim como tra-\nbalhos futuros que podem ser desenvolvidos com base no ambiente ICE.\n\n\n\n17\n\n2 ESTADO DA ARTE EM GERENCIAMENTO DE\n\nSISTEMAS DE ALTO DESEMPENHO\n\nNeste cap??tulo sera?o discutidas as ide?ias existentes na a?rea de gerenciamento de\nsistemas de alto desempenho (HPC - High Performance Computing). Para que se\npossa abordar com maior riqueza de detalhes este to?pico, sera? realizada uma breve\napresentac?a?o de sistemas distribu??dos, suas caracter??sticas e alguns middlewares co-\nmumente utilizados para construc?a?o de tais sistemas. Essa caracterizac?a?o inicial\nsera? importante para que se possa compreender os problemas que existem na cons-\ntruc?a?o de ambientes de gerenciamento de sistemas de HPC. De certa forma, pode-se\ndizer que eles sa?o uma especializac?a?o de sistemas distribu??dos, visto que sa?o forma-\ndos por hardware e software interligados por uma rede de comunicac?a?o. A principal\ndiferenc?a esta? em sua especializac?a?o. Sistemas de alto desempenho tem o objetivo\nespec??fico de solucionar problemas no menor tempo poss??vel. Eficie?ncia e efica?cia sa?o\npara?metros considerados nesse tipo de contexto. Seu gerenciamento requer cuida-\ndos, como por exemplo: menor intrusa?o poss??vel para que o desempenho do sistema\nna?o seja afetado; cuidados espec??ficos na alocac?a?o de recursos para usua?rios; moni-\ntoramento dos recursos do sistema HPC assim como das aplicac?o?es que esta?o em\nexecuc?a?o; etc. Em sistemas distribu??dos esses problemas de gerenciamento tambe?m\naparecem, mas na?o sa?o cruciais. Algumas te?cnicas e soluc?o?es de gerenciamento de\nsistemas distribu??dos e HPC sera?o apresentadas a seguir.\n\n2.1 Sistemas Distribu??dos\n\nSistemas distribu??dos esta?o presentes em praticamente todos os segmentos da\nsociedade. Estes tipos de sistemas sa?o caracterizados por componentes de software\ne de hardware, localizados em computadores interligados por uma rede, que se co-\nmunicam e coordenam suas ac?o?es atrave?s de troca de mensagens (COULOURIS;\nDOLLIMORE; KINDBERG, 2005). Como exemplos de sistemas distribu??dos tem-\nse: a Internet; as intranets de corporac?o?es, universidades, e de redes dome?sticas; a\ncomputac?a?o mo?vel (desde telefones celulares a PDAs, pagers, etc); e a computac?a?o\nob??quoa (COULOURIS; DOLLIMORE; KINDBERG, 2005).\n\nDe modo geral, sistemas distribu??dos abrangem uma quantidade ampla de a?reas\nde pesquisa, desenvolvimento e nego?cios dentro da computac?a?o. Cada qual com\num determinado objetivo, como por exemplo, o come?rcio eletro?nico (e-business ou\ne-commerce). Nesse tipo de nego?cio, o objetivo e? manter os sistemas o mais tempo\nposs??vel em funcionamento, ale?m de tentar integrar os diferentes sistemas de forne-\ncedores e compradores para obtenc?a?o de maiores lucros. Um sistema de e-commerce\n\n\n\n18\n\nna?o dispon??vel implica em perdas financeiras para a empresa. Em contra-partida\na esses tipos de sistemas voltados para empresas, existem sistemas distribu??dos\nacade?micos cuja finalidade e? manter uma rede de dados e servic?os para seus usua?rios\n(no caso professores, alunos e funciona?rios). Enfim, sa?o inu?meros os tipos de siste-\nmas distribu??dos e sua aplicac?a?o cotidiana.\n\nEntretanto, o desenvolvimento e projeto de sistemas distribu??dos desperta alguns\ndesafios. De acordo com Coulouris em (COULOURIS; DOLLIMORE; KINDBERG,\n2005) os principais desafios a serem considerados sa?o: heterogeneidade, capacidade\nde extensibilidade (openness), seguranc?a, escalabilidade, tolera?ncia a falhas, con-\ncorre?ncia e transpare?ncia. E? bastante complexo o desenvolvimento de um sistema\ndistribu??do que consiga satisfazer a contento todos esses desafios. Em geral, eles\nsolucionam alguns deles e outros sa?o preteridos muitas vezes em raza?o do objetivo\nfinal do sistema distribu??do projetado. Por exemplo, em um sistema distribu??do\nde tempo real as caracter??sticas mais relevantes sa?o a transpare?ncia, concorre?ncia e\ntolera?ncia a falhas. Nesse caso, procurar soluc?o?es o?timas para extensibilidade na?o\ne? ta?o relevante. A seguir sa?o descritos com maiores detalhes cada um dos desafios\napontados em (COULOURIS; DOLLIMORE; KINDBERG, 2005).\n\nHeterogeneidade - Este conceito esta? ligado a? variedade de redes de comunicac?a?o,\nhardware dos computadores, sistemas operacionais, linguagens de programac?a?o,\nimplementac?o?es de diferentes desenvolvedores. Para tentar lidar com a hetero-\ngeneidade dos sistemas sa?o desenvolvidos middlewares, os quais sa?o camadas\nde software que proporcionam abstrac?a?o e mascaramento da heterogeneidade.\nAle?m disso, middlewares tambe?m prove?em um modelo de uniformizac?a?o na\nforma como os sistemas distribu??dos sa?o utilizados.\n\nExtensibilidade - A extensibilidade em um sistema define sua capacidade de agre-\ngar novas funcionalidades ou ferramentas, assim como sua capacidade de ser\nreimplementado. Esse conceito, no que se refere a sistemas distribu??dos e? ba-\nsicamente determinado pela capacidade de inserc?a?o de novos servic?os e de sua\ndisponibilizac?a?o para diferentes programas clientes. A extensibilidade pode\nser atingida atrave?s da especificac?a?o de interfaces dos componentes do sistema\ne de sua publicac?a?o.\n\nSeguranc?a - Existem tre?s componentes de seguranc?a para manter as informac?o?es\ndos recursos em um sistema distribu??do: (i) confidencialidade, protec?a?o contra\nusua?rios na?o qualificados e na?o autorizados; (ii) integridade, protec?a?o contra\nalterac?a?o ou corrupc?a?o dos dados; e (iii) disponibilidade, protec?a?o contra as\ninterfere?ncias do meio no acesso aos recursos.\n\nEscalabilidade - Caracter??stica que um sistema possui de se manter eficiente mesmo\ncom o aumento no nu?mero de usua?rios e de recursos. O desenvolvimento de\nsistemas distribu??dos escala?veis apresenta os seguintes desafios: controle do\ncusto dos recursos f??sicos; controle da perda de desempenho; prevenc?a?o da\nescassez de recursos de software e prevenc?a?o de gargalos.\n\nTratamento de falhas - Falhas em sistemas distribu??dos sa?o parciais, isto e?, alguns\ncomponentes falham mas outros continuam funcionando. Existem algumas\nte?cnicas para o tratamento de falhas: detecc?a?o, mascaramento, tolera?ncia,\nrecuperac?a?o de falhas e redunda?ncia.\n\n\n\n19\n\nConcorre?ncia - Em sistemas distribu??dos tanto servic?os quanto aplicac?o?es possuem\nrecursos que podem ser compartilhados por seus clientes. Nesse caso, e? preciso\ngarantir que o sistema funcione corretamente em um ambiente concorrente.\nPara isto, mecanismos de sincronizac?a?o que mantenham os dados consistentes\ndevem ser adotados.\n\nTranspare?ncia - Caracter??stica que faz com que usua?rios e aplicac?o?es de um sistema\ndistribu??do tenham uma visa?o u?nica do sistema ao inve?s de uma ide?ia de\num sistema formado por diferentes componentes. Existem oito formas de\ntranspare?ncia, sendo elas transpare?ncia de: acesso, localizac?a?o, concorre?ncia,\nreplicac?a?o, falha, mobilidade, desempenho e escalabilidade.\n\nPara a construc?a?o de um sistema distribu??do, que seja capaz de suportar total\nou parcialmente as caracter??sticas detalhadas acima, e? preciso a existe?ncia de um\nmiddleware. Esse componente e? capaz de lidar com as especificidades do sistema\ncomo um todo e apresentar aos usua?rios (sejam pessoas ou outras aplicac?o?es) uma\nabstrac?a?o em alto n??vel dos recursos do sistema distribu??do (COULOURIS; DOL-\nLIMORE; KINDBERG, 2005). Middlewares como CORBA (SIEGEL, 1996), RMI\n(RMI - JAVA REMOTE METHOD INVOCATION, 2005), DCOM (GRIMES, 1997)\ne recentemente Web Services (CERAMI, 2002) te?m sido desenvolvidos no intuito de\nprover essas abstrac?o?es.\n\nConsiderando que sistemas de alto desempenho sa?o uma especificac?a?o de sis-\ntemas distribu??dos, a construc?a?o de ambientes de gerenciamento e de acesso aos\nrecursos desse cena?rio tambe?m empregam middlewares que oferec?am as abstrac?o?es\nnecessa?rias. Muitas vezes existem diferenciac?o?es bem claras dos tipos de ambientes\nde gerenciamento e acesso em HPC e em sistemas distribu??dos. Mas de forma geral\nos objetivos da construc?a?o de ambientes de gerenciamento e de acesso a sistemas\nHPC sa?o exatamente os mesmos existentes em sistemas distribu??dos. A seguir, sera?o\napresentados alguns tipos de sistemas HPC e algumas ferramentas de gerenciamento\ne acesso empregadas na a?rea.\n\n2.2 Sistemas de Alto Desempenho\n\nSistemas de alto desempenho sa?o tipicamente empregados na soluc?a?o de proble-\nmas que precisam de uma grande quantidade de ca?lculos ou enta?o casos que existe\numa grande quantidade de dados para serem processados. O objetivo e? alcanc?ar a\nresoluc?a?o desses problemas em um tempo menor ou enta?o com um grau de precisa?o\nou riqueza de detalhes maior. A linha de evoluc?a?o dos sistemas de alto desempenho\nfoi marcada pela utilizac?a?o de ma?quinas massivamente paralelas (MPP - Massive\nParallel Processing), ma?quinas vetoriais, clusters, constelac?o?es e grids (BUYYA,\n1999).\n\nAlguns exemplos de campos de aplicac?a?o de sistemas HPC sa?o:\n\n\u2022 f??sica e engenharias em geral: resoluc?a?o de simulac?o?es de corpos celestes, si-\nmulac?o?es de equac?o?es e sistemas em geral;\n\n\u2022 hidrologia: simulac?a?o de impactos ambientais nos aqu??feros, simulac?a?o de cons-\ntruc?a?o de equipamentos para usinas hidrele?tricas, outros tipos de simulac?o?es\nligados aos recursos h??dricos;\n\n\n\n20\n\nFigura 2.1: Lista de aplicac?o?es existentes nas ma?quinas que fazem parte do Top 500\n\n\u2022 geoprocessamento: simulac?a?o da existe?ncia de petro?leo em uma determinada\nregia?o;\n\n\u2022 meteorologia: previsa?o do tempo, simulac?a?o de mudanc?as clima?ticas;\n\n\u2022 medicina e bio-informa?tica: simulac?a?o de efeitos de reme?dios, simulac?a?o de\ncomposic?a?o de novos medicamentos;\n\n\u2022 computac?a?o: simulac?a?o de circuitos eletro?nicos, processamento de imagens e\nna renderizac?a?o de imagens, simulac?a?o de arquiteturas de computadores, entre\noutras.\n\nA Figura 2.1 apresenta algumas aplicac?o?es que sa?o executadas nas ma?quinas que\nfazem parte do Top500 (TOP500 SUPERCOMPUTER SITES, 2005). Essa e? uma\nlista dos 500 supercomputadores mais poderosos do mundo.\n\nAtrave?s dessa figura pode-se observar que existem aplicac?o?es bastante variadas\nnas ma?quinas pertencentes a lista do Top500. Esta variedade cobre aplicac?o?es que\nva?o desde cient??ficas, como por exemplo: geo-f??sica (9,4%), benckmarking (2,6%),\npesquisas de clima e tempo (3,4%), a aplicac?o?es mais comerciais, como por exemplo:\nfinanceiras (8,8%), telecomunicac?o?es (3,2%) e automotiva (1,0%).\n\nPode-se perceber que o escopo de utilizac?a?o de sistema de HPC na?o esta? mais\nrestrito ao campo da computac?a?o. Isto faz com que seja necessa?ria a criac?a?o de\nambientes e mecanismos que facilitem sua utilizac?a?o. Outro fator e? o tamanho\nque esse tipo de sistema tem assumido. Atualmente existem ma?quinas formadas\npor milhares de no?s (elementos processadores). O gerenciamento manual desse tipo\nde sistemas torna-se invia?vel. Portanto, tambe?m existe uma necessidade de prover\nplataformas capazes de facilitar a utilizac?a?o e manipulac?a?o desses sistemas.\n\nAtualmente, boa parte dos trabalhos em HPC concentram-se em dois tipos de\nsistemas: clusters e grids. Segundo a definic?a?o apresentada em (BAKER, 2000),\nclusters sa?o sistemas computacionais locais que encerram um conjunto de computa-\ndores independentes inter-conectados por uma rede. Um cluster e? local no sentido\nde que todos os seus componentes e sub-sistemas esta?o localizados dentro de um\nu?nico dom??nio administrativo, tipicamente localizados em uma sala e gerenciados\ncomo um simples computador. Em contrapartida, grids assumem um cara?ter de\n\n\n\n21\n\nsistemas de larga escala. Grids se caracterizam pelo foco na construc?a?o de sistemas\nde larga escala que sejam capazes de coordenar o compartilhamento de recursos e\nque tenham a capacidade de resolver problemas em organizac?o?es virtuais dina?micas\ne multi-institucionais (FOSTER; KESSELMAN; TUECKE, 2001). Ainda segundo\nAhmar Abbas (ABBAS, 2004) a computac?a?o em grid pode juntar em um u?nico\nescopo todos os esforc?os realizados nas a?reas de computac?a?o de alto desempenho,\npeer-to-peer (P2P) e Internet. A seguir esses dois tipos de sistemas sa?o descritos,\nsendo que sa?o apresentados os problemas de gerenciamento existentes e algumas\nsoluc?o?es para tais problemas.\n\n2.2.1 Clusters\n\nApesar do cena?rio de clusters ser uma a?rea bem desenvolvida e consolidada, com\num grande nu?mero de ferramentas e ambientes disponibilizados, na?o existe uma pa-\ndronizac?a?o na forma como eles foram desenvolvidos. Mais do que isto, na?o existe\numa padronizac?a?o do que e? gerenciamento em clusters. Por exemplo, quando se fala\nem gerenciamento de redes, e mais especificamente em um modelo de gerenciamento\nde redes tem-se a ligac?a?o direta ao framework SNMP (CASE; et al., 1990). Em clus-\nters na?o existe uma metodologia, taxonomia, ou padra?o na a?rea de gerenciamento.\n\nUma tentativa de delimitar essa a?rea e? apresentada em (STERLING, 2000). Se-\ngundo Thomas Sterling, os softwares que compo?e um cluster podem ser divididos\nem: ambientes de programac?a?o de aplicac?o?es e softwares de gerenciamento de recur-\nsos. Este u?ltimo componente pode ser dividido nas categorias de software listadas\nabaixo.\n\n\u2022 Instalac?a?o e configurac?a?o - Esta categoria lida com os desafios de desenvolvi-\nmento de software que sejam capazes de implementar e manter imagens comuns\nentre os no?s do cluster e que sejam de fa?cil utilizac?a?o. Este e? um problema a\nser bastante considerado quando se trabalha com clusters formados dos cen-\ntenas de no?s. Exemplos de ferramentas que possuem essas caracter??sticas sa?o:\nC3 (Cluster Command and Control) (FLANERY; et al., 2000), System Imager\n(SYSTEM IMAGER, 2005), SSI (VALLEE; et al., 2005), entre outros.\n\n\u2022 Escalonamento e alocac?a?o - A colocac?a?o das aplicac?o?es nos recursos distribu??dos\ndos clusters requer ferramentas que sejam capazes de alocar os componen-\ntes de software nos no?s e que escalonem o tempo de sua execuc?a?o. Segundo\n(STERLING, 2000), a alocac?a?o pode ser realizada em diferentes n??veis de gra-\nnularidade. Pode ser alocac?a?o: de trabalhos, transac?o?es, processos ou threads.\nAlguns exemplos de ferramentas desenvolvidas sa?o: OpenPBS (PORTABLE\nBATCH SYSTEM, 2005), OAR (CAPIT; et al., 2003, 2005), CCS (KELLER;\nREINEFELD, 1998), Maui (MAUI SCHEDULER OPEN CLUSTER SOFT-\nWARE, 2005), CADEO (CERA; ROSA RIGHI; PASIN, 2005), etc.\n\n\u2022 Administrac?a?o do sistema - Para a supervisa?o do funcionamento dos sistemas\nde clusters e? necessa?rio ferramentas que sejam capaz de prover: gerenciamento\ndas contas de usua?rios, filas de trabalhos; seguranc?a; backups; armazenamento\nde dados; log de informac?o?es; terminais para usua?rios; entre outras ativida-\ndes simples de manutenc?a?o do sistema. Exemplos de ferramentas que ten-\ntam prover essas facilidades administrativas sa?o: OSCAR (LIGNERIS; et al.,\n2003; OSCAR - OPEN SOURCE CLUSTER APPLICATION RESOURCES,\n\n\n\n22\n\n2005), PUNCH (ADABALA; KAPADIA; FORTES, 2000; PARK; et al., 2000),\nROCKS (PAPADOPOULOS; KATZ; BRUNO, 2001), entre outros.\n\n\u2022 Monitoramento e diagno?sticos - Nessa categoria, considera-se ferramentas que\npossam ser usadas no monitoramento do estado e das operac?o?es dos elemen-\ntos de sistema. Como exemplo, dessas ferramentas te?m-se: Ganglia (SA-\nCERDOTI; et al., 2003), SCMS/RMS (UTHAYOPAS; PHATANAPHEROM,\n2001), Supermom (SOTTILE; MINNICH, 2002), entre outros.\n\n\u2022 Armazenamentos secunda?rios distribu??dos - Grande parte das computac?o?es\nnecessitam acessar fontes de armazenamento secunda?rio, isto inclui o acesso\na discos locais e remotos atrave?s do sistema de arquivos. Para prover esses\nmecanismos de acesso, muitos sistemas foram desenvolvidos, como por exem-\nplo: dNFSp (KASSICK et al., 2005; A?VILA et al., 2004), PVFS (HADDAD,\n2000), iPVFS (OU; HE, 2005), etc.\n\n\u2022 Disponibilidade - Na medida que o cluster se torna mais escala?vel, o seu MTBF\n(MeanTime Between Failures) diminui. Isto faz com que sejam necessa?rias\nmedidas para garantir a continuidade da operac?a?o do sistema e minimizar o\ntempo que os recursos esta?o indispon??veis. Alguns exemplos de ferramentas\nempregadas com o intuito de prover mecanismos de reabilitac?a?o do sistema e\ndetecc?a?o e recuperac?a?o de falhas sa?o: C3 (Cornell Checkpoint (pre)Compiler)\n(SCHULZ; et al., 2004; BRONEVETSKY; et al., 2004), CONDOR (THAIN;\nLIVNY, 2003), entre outros.\n\nAtrave?s da descric?a?o dos campos que envolvem o conceito de gerenciamento em\nclusters, e da apresentac?a?o de va?rias ferramentas em cada uma de suas categorias,\npode-se perceber que na?o existe uma padronizac?a?o. O que existem sa?o diversas fer-\nramentas, desenvolvidas muitas vezes para suprir as necessidades de cada grupo de\npesquisa. Isto leva a existe?ncia de uma heterogeneidade de ferramentas de gerenci-\namento de clusters muito grande. Ale?m disso, muitas delas na?o foram projetadas\nlevando em considerac?a?o questo?es de interoperabilidade e de facilidade de uso.\n\nNo intuito de facilitar o gerenciamento dos clusters e tambe?m a forma como\nos seus usua?rios utilizam seus recursos, foram desenvolvidos alguns ambiente e\nplataformas de gerenciamento de clusters. A seguir, sera?o descritas as ferramen-\ntas: OSCAR, OpenSCE (UTHAYOPAS; ANGSKUN; MANEESILP, 2001, 2002;\nOPENSCE - SCALABLE CLUSTER ENVIRONMENT, 2005), ROCKS e o traba-\nlho que tenta integrar o gerenciamento de clusters com SNMP (ALVES et al., 2004;\nALVES; MARQUEZAN; GRANVILLE, 2004; ALVES et al., 2005).\n\n2.2.1.1 OSCAR - Open Source Cluster Application Resource\n\nOSCAR e? uma ferramenta que visa a construc?a?o de um cluster que possua suas\nferramentas integradas em um u?nico ambiente. Seu objetivo e? permitir que usua?rios\ne administradores de cluster possam criar, manter e utilizar clusters baseados em\nplataforma Linux. O OSCAR e? uma colec?a?o de ferramentas comumente usadas\nem clusters, as quais sa?o disponibilizadas em forma de arquivos tar que devem\nser instalados no front-end. O OSCAR e? composto pelos seguintes mo?dulos: (i)\nnu?cleo da infra-estrutura e do gerenciamento, (ii) administrac?a?o e configurac?a?o, (iii)\nservic?os e ferramentas de HPC e (iv) seguranc?a. Algumas ferramentas que fazem\n\n\n\n23\n\nparte do OSCAR sa?o: C3, System Imager, Ganglia, OpenPBS, MPI (DONGARRA;\net al., 1995), PVM (SUNDERAM, 1990), entre outras. Para utilizac?a?o do OSCAR\ne? preciso um n??vel aprofundado de conhecimento da arquitetura e dos sistemas de\nclusters.\n\n2.2.1.2 OpenSCE - Open Scalable Cluster Environment\n\nO projeto OpenSCE e? caracterizado por utilizar ferramentas pro?prias, ou seja,\nque foram desenvolvidas pelo mesmo grupo que da? suporte ao projeto. O OpenSCE e?\num software constitu??do pelos seguintes tipos de ferramentas: (i) administrativas e de\nmonitoramento (Beowulf Builder, Ksix, SQMS), (ii) um sistema de gerenciamento de\nfilas (SCMS), um sistema Web de monitoramento (SCMSWeb), uma ferramenta de\nvisualizac?a?o e depurac?a?o de aplicac?o?es (MPView) e uma biblioteca de programac?a?o\nparalela que e? baseada no MPI (MPITH). O ambiente OpenSCE pode ser uma boa\nalternativa para gerenciamento de cluster quando este esta? sendo montado desde o\nin??cio. Entretanto, quando ja? existe uma infra-estrutura montada, com ferramentas\ndiferentes das existentes no OpenSCE, pode-se tornar muito custosa a troca de todas\nas ferramentas. Mais do que isso, e? preciso levar em considerac?a?o que os usua?rios\ndeste cluster tera?o que se readaptar a?s novas ferramentas, e muitas vezes a curva de\naprendizado na?o compensa o investimento.\n\n2.2.1.3 NPACI Rocks Toolkit\n\nOs trabalhos realizados no desenvolvimento do NPACI Rocks buscam encontrar\nsoluc?o?es para as dificuldades que existem na construc?a?o de clusters que sejam ge-\nrencia?veis. De forma resumida, Rocks e? uma distribuic?a?o Linux voltada para clusters\nbaseada no Red Hat (RED HAT - THE OPEN SOURCE LEADER, 2005). Ale?m\ndisso, possui alguns pacotes adicionais e configurac?o?es programadas para automati-\nzar a montagem de um cluster Linux de alto desempenho. O sistema e? baseado em\numa arquitetura tradicional de clusters: front-end, uma rede de interconexa?o Ether-\nnet (adicionalmente e? poss??vel uma rede de alto desempenho - Myrinet, por exem-\nplo) e os no?s. Na distribuic?a?o NPACI Rocks foi desenvolvido uma infra-estrutura\nde configurac?a?o com propriedades bem definidas baseadas em padro?es de facto, o\nque inclui: XML (com parsers padra?o ), RedHat Kickstart, HTTP, CGI, base de\ndados SQL e construtores de grafos para facilmente definir as ferramentas do cluster\n(PAPADOPOULOS; KATZ; BRUNO, 2001). A ide?ia principal do projeto e? tor-\nnar o uso de clusters fa?cil (ROCKS CLUSTER DISTRIBUTION: USERS GUIDE,\n2005). Como apresentado em (BRUNO; et al., 2004), o objetivo do desenvolvimento\ndo Rocks e? permitir que pessoas que na?o sejam experientes em clusters consigam\nfacilmente montar e gerenciar seus clusters.\n\n2.2.1.4 Clusters + SNMP\n\nEsta ferramenta de gerenciamento de clusters baseado em SNMP foi desenvol-\nvida no intuito de integrar o gerenciamento de clusters dentro de plataformas de\ngerenciamento de redes. Visto que padronizac?a?o e? um problema nesta a?rea e que\nos clusters podem apresentar uma visa?o u?nica de todo o sistema, pode-se gerenciar\nclusters como se eles fossem mais um dispositivo da rede. Desta forma, consegue-se\ninserir a tarefa de gerenciamento de clusters juntamente com o gerenciamento de\nredes. A vantagem desta abordagem e? o aproveitamento de diversas ferramentas e\n\n\n\n24\n\nplataformas de gerenciamento ja? desenvolvidas no escopo de redes no contexto de\nclusters. Seguindo o framework SNMP, padra?o de facto em gerenciamento de redes,\nforam desenvolvidos: MIBs de gerenciamento do front-end e dos no?s, agentes que\nseguem esta MIB e um gerente. A ferramenta desenvolvida possui suporte: para\nmonitoramento dos recursos dos clusters e das aplicac?o?es que esta?o executando;\npara escalonamento das aplicac?o?es; para configurac?a?o da pol??tica de alocac?a?o do\ncluster. Este ambiente foi integrado na plataforma de gerenciamento QAME (QoS-\nAware Management Environment) (GRANVILLE; TAROUCO, 2001), mostrando\nque pode-se integrar o gerenciamento de clusters e redes.\n\n2.2.1.5 Resumo sobre ambientes de gerenciamento de clusters\n\nExiste um conjunto de ferramentas de gerenciamento de clusters bastante grande.\nNesta sec?a?o tentou-se mostrar alguns ambientes que oferecem um conjunto maior de\nfuncionalidades. Mesmo assim, pode-se perceber que o OSCAR e o Rocks Toolkit\nsa?o ferramentas mais voltadas para a parte de configurac?a?o de clusters, direcionadas\npara o momento de estabelecimento e configurac?a?o dos cluster em si. Enquanto\nisto, as ferramentas OpenSCE e Cluster + SNMP sa?o mais voltadas para o uso de\nclusters e monitoramento de seus recursos e aplicac?o?es.\n\n2.2.2 Grids\n\nSegundo Ahmar Abbas (ABBAS, 2004) existem os tipos de grids apresentados\na seguir.\n\n\u2022 Grids Departamentais (Departamental Grids)- Sa?o constru??dos para resolver\nproblemas de um grupo particular dentro de uma empresa. Os recursos na?o\nsa?o compartilhados por outros grupos da mesma instituic?a?o.\n\n\u2022 Grids Empresariais (Enterprise Grids) - Sa?o formados por recursos espalhados\npela empresa e que prove?em servic?os para todos os usua?rios dentro da empresa.\n\n\u2022 Grids Extra-empresariais (Extraprise Grids) - Caracteriza-se por ser estabe-\nlecido entre companhias, seus parceiros e seus clientes. Os recursos sa?o dis-\nponibilizados atrave?s de uma rede virtual privada (VPN - Virtual Private\nNetwork ).\n\n\u2022 Grids Globais (Global Grids) - Sa?o formados atrave?s da Internet. Podem ser\nformados no intuito de facilitar os nego?cios entre instituic?o?es.\n\n\u2022 Grids Computacionais (Compute Grids) - Sa?o criados com o objetivo exclusivo\nde prover acesso a recursos computacionais. Eles sa?o divididos de acordo com\no tipo de hardware empregado, os quais podem ser: desktops, servidores e\nbaseados em sistemas de alto desempenho.\n\n\u2022 Grids de Dados (Data Grids) - Este tipo de grid e? otimizado para trabalhar\ncom operac?o?es orientadas a dados.\n\n\u2022 Utility Grids - Sa?o definidos como sendo recursos computacionais que sa?o\nmantidos e gerenciados por um provedor de servic?o.\n\nComo pode-se perceber existem muitas formas diferentes de encarar a utilizac?a?o\nde grids. Isto faz com que aparec?am diferentes viso?es das definic?o?es e padro?es a\n\n\n\n25\n\nserem adotados na a?rea de grids (BAKER; et al., 2005). No que diz respeito a parte\nde gerenciamento de grids, existem muitos aspectos que devem ser considerados.\nAlguns deles sa?o descritos a seguir.\n\n1. Seguranc?a - E? preciso garantir que somente usua?rios que fac?am parte do grid\ntenham acesso aos recursos, ale?m disso e? preciso restringir acesso de alguns\nusua?rios a determinados servic?os existentes em grids. Neste escopo, o GSI\n(Grid Security Infrastructure), promovido pelo GGF (Global Grid Forum), e?\num padra?o bem estabelecido e que trata dos problemas de seguranc?a em grid\n(WELCH; et al., 2003).\n\n2. Monitoramento - Dado o fato de grids serem estruturas extremamente dis-\ntribu??das e complexas, e? preciso que essas estruturas sejam monitoradas. Se-\ngundo Maozhen Li e Mark Baker (LI; BAKER, 2005), o objetivo do monito-\nramento de grids e? a medic?a?o e a publicac?a?o do estado dos recursos em um\ncerto per??odo de tempo. O GMA (Grid Monitoring Architecture), proposto\npelo GGF, e? uma tentativa de criac?a?o de um mecanismo padronizado para\nobtenc?a?o e disponibilizac?a?o das informac?o?es de monitoramento de grids (TI-\nERNEY; et al., 2002; LI; BAKER, 2005). Alguns exemplos de ferramentas que\nimplementam o GMA sa?o: GridRM (BAKER; SMITH, 2003), HRIC (ZOU;\net al., 2005) e R-GMA (COOKE; et al., 2003).\n\n3. Escalonamento e gerenciamento de recursos - As aplicac?o?es dos usua?rios sa?o\ndisparadas em ma?quinas que esta?o localizadas em diferentes dom??nios admi-\nnistrativos. E? preciso a existe?ncia de ambientes capazes de gerenciar essas\naplicac?o?es e escalona?-las. Ferramentas como por exemplo: Globus (FOSTER;\nKESSELMAN, 1997; GLOBUS - WELCOME TO THE GLOBUS TOOL-\nKIT HOMEPAGE, 2005), Condor (GONZ; et al., 2002; THAIN; TANNEN-\nBAUM; LIVYN, 2003), Legion (GRIMSHAW; NATRAJAN, 2005), OurGrid\n(ANDRADE; et al., 2003), UNICORE (BENEDYCZAK; et al., 2005), SGE\n(GENTZSCH, 2001), entre outros.\n\n4. Facilidade de uso - Para que os desenvolvedores de aplicac?o?es de grid tenham\nfacilidades de acesso e utilizac?a?o de grids foi criado o conceito de Portais\nde Grid. Um portal de grid e? um gateway baseado em tecnologia Web que\nprove? facilidades de acesso a uma variedade de recursos. Segundo Li e Baker\n(LI; BAKER, 2005) existem duas gerac?o?es de portais. Na primeira gerac?a?o\nos portais eram constru??dos utilizando uma arquitetura baseada em tre?s ca-\nmadas. Exemplos de portais desta gerac?a?o sa?o: GridPort (THOMAS; et al.,\n2001; DAHAN; et al., 2004), GridSpeed (SUZUMURA; et al., 2004), Genius\n(ANDRONICO; et al., 2003), Ninf (NAKADA; et al., 2004), entre outros. A\nsegunda gerac?a?o de portais de grid e? caracterizada por ser constru??da a partir\nde portlets, os quais sa?o componentes de software escritos em Java, gerenciados\npor portlet containers, e que sa?o responsa?veis por gerenciar as requisic?o?es dos\nusua?rios e pela gerac?a?o dina?mica de conteu?do (LI; BAKER, 2005). Exemplos\nde portais da segunda gerac?a?o sa?o: PortalLab (LI; et al., 2003) e GridSphere\n(NOVOTNY; RUSSELL; WEHRENS, 2004),\n\nAtrave?s da descric?a?o apresentada acima sobre alguns aspectos que devem ser\nconsiderados no gerenciamento de grids e da apresentac?a?o de algumas das ferra-\n\n\n\n26\n\nmentas dispon??veis, e? poss??vel perceber que o cena?rio de grids e? bastante complexo\ne ainda em esta?gio de evoluc?a?o.\n\nA utilizac?a?o de grids e? um passo natural para os usua?rios de clusters. Atual-\nmente, e? cada vez mais necessa?ria a utilizac?a?o de uma quantidade maior de recursos\ncomputacionais para solucionar os problemas existentes. Desta forma, e? bastante\nplaus??vel que se integre recursos existentes em diferentes instituic?o?es, visando reduzir\no custo de aquisic?a?o de toda uma infra-estrutura computacional.\n\nNo entanto, existe um custo de adaptac?a?o de ferramentas e de reeducac?a?o dos\nusua?rios de clusters que muitas vezes na?o e? considerado. Nem todos os centros\nde pesquisa, corporac?o?es e empresas, esta?o prontas para migrarem suas aplicac?o?es e\nusua?rios de um mundo baseado em clusters para um baseado em grids. Considerando\neste cena?rio, existe um meio termo entre o contexto de grids e o de clusters. Este\ncontexto e? descrito a seguir.\n\n2.2.3 Intersecc?a?o entre clusters e grids: sistemas Multicluster\n\nNem todos os centros de pesquisa e instituic?o?es em geral, que possuem mu?ltiplos\nclusters, aderem ao cena?rio de grids para aumentar o seu potencial de processa-\nmento, armazenamento, etc. Na?o e? raro que em uma mesma instituic?a?o existam\nva?rios clusters que possuem seu funcionamento completamente isolado um do ou-\ntro. Essa situac?a?o geralmente acontece, porque na maioria das vezes esses clusters\nsa?o adquiridos em diferentes pontos do tempo.\n\nExistem trabalhos no sentido de integrar os diferentes clusters como se eles for-\nmassem uma u?nica ma?quina, o que se chamou de sistemas multiclusters (BAR-\nRETO; A?VILA; NAVAUX, 2000; AUMAGE, 2002). Multiclusters podem ser enca-\nrados sob a visa?o dos usua?rios que utilizam os recursos ou sob a visa?o do adminis-\ntrador desses clusters. No caso dos usua?rios a ide?ia de multicluster faz com que seja\nnecessa?ria a criac?a?o de ferramentas que de?em o suporte para a comunicac?a?o entre\nos diferentes clusters de forma amiga?vel. No caso de gerenciamento de mu?ltiplos\nclusters, na?o e? preciso a existe?ncia dessa infra-estrutura de comunicac?a?o. Basta que\nse tenha acesso aos diferentes clusters. A seguir sera?o abordados os aspectos de\ngerenciamento e acesso a mu?ltiplos clusters.\n\nA heterogeneidade e? a caracter??stica que permeia o ambiente de mu?ltiplos clus-\nters. Para gerenciar e acessar esses recursos e? preciso, primeiramente, lidar com as\ndiferentes ferramentas instaladas em cada um. Essa heterogeneidade passa a ser\numa dificuldade enfrentada por seus usua?rios, pois eles te?m que aprender a lidar\ncom cada uma dessas ferramentas para desempenharem suas atividades.\n\nPara usua?rios acostumados com a cie?ncia da computac?a?o isto pode na?o repre-\nsentar um empecilho. No entanto, para usua?rios que pertencem a outras a?reas de\natuac?a?o a dificuldade de ter de se acostumar e aprender os detalhes e sema?ntica do\ngrande nu?mero de ferramentas passa a ser um problema considera?vel. No intuito\nde facilitar o gerenciamento e o acesso de mu?ltiplos clusters foram desenvolvidas\nalgumas ferramentas. Duas dessas ferramentas sera?o apresentadas a seguir.\n\n2.2.3.1 M3C Managing and Monitoring Multiple Clusters\n\nO M3C (BRIM; et al., 2001) proporciona uma interface gra?fica Web para admi-\nnistrac?a?o de clusters e tambe?m um framework para o desenvolvimento dos sistemas\nde gerenciamento das camadas inferiores. Ele foi projetado para ser extens??vel, uma\nvez que novas funcionalidades de clusters podem ser inseridas no ambiente atrave?s\n\n\n\n27\n\nda aplicac?a?o do framework. Embora apresente a capacidade de estender o conjunto\nde funcionalidades, o M3C na?o tem suporte para a extensa?o das ferramentas para\ncada funcionalidade. Ou seja, ele na?o e? capaz de lidar com diferentes ferramentas\npara uma mesma funcionalidade. O M3C foi implementado utilizando Java Applets\ne Servlets e tambe?m utiliza arquivos que armazenam informac?o?es sobre os recur-\nsos dos clusters. Este ambiente apresenta suporte para: monitoramento dos no?s,\nreserva de no?s e particionamento de clusters. Questo?es de seguranc?a sa?o tratadas\nutilizando o protocolo HTTPS para encriptac?a?o dos dados transmitidos, e realizando\nverificac?o?es de quais clusters cada usua?rio pode utilizar. O M3C apresenta-se como\num ambiente contendo basicamente funcionalidades de acesso e monitoramento de\nmu?ltiplos clusters, ale?m disto, por ser implementado em Java possui um certo grau\nde independe?ncia de plataforma.\n\n2.2.3.2 HPC2N - High Performance Computing Center North\n\nO HPC2N (ELMROTH; NYLE?N; OSCARSSON, 2005) foi desenvolvido para ser\nutilizado em sistemas de alto desempenho. Ele foi projetado para ser um ambiente\ncom foco nos usua?rios, provendo funcionalidades para lidar com suas aplicac?o?es e su-\nporte para monitoramento. O acesso ao HPC2N e? proporcionado atrave?s da Internet\nutilizando a tecnologia CGI. As comunicac?o?es entre o servidor HPC2N e os nave-\ngadores dos usua?rios sa?o realizadas utilizando o protocolo HTTPS e a autenticac?a?o\ndos usua?rios e? feita atrave?s do protocolo Kerberos (COULOURIS; DOLLIMORE;\nKINDBERG, 2005). Diferentemente do M3C, o HPC2N na?o apresenta nenhum su-\nporte para ser estendido. Ou seja, na?o e? poss??vel inserir novas funcionalidades e\ntambe?m nem inserir novas ferramentas nesse ambiente.\n\n2.2.3.3 Problemas em Aberto no Cena?rio de Gerenciamento de Mu?ltiplos Clusters\n\nPor se tratar de um ambiente heteroge?neo, alguns aspectos ligados a prover\nfacilidades para os usua?rios devem ser considerados na criac?a?o de ambientes para\ngerenciamento e acesso de mu?ltiplos clusters. Alguns aspectos importantes sa?o:\n\n\u2022 transpare?ncia de acesso;\n\n\u2022 extensibilidade;\n\n\u2022 uniformizac?a?o das operac?o?es;\n\n\u2022 completeza;\n\n\u2022 interoperabilidade;\n\n\u2022 capacidade de incorporac?a?o dos sistemas de gerenciamento legados;\n\n\u2022 construc?a?o de ferramentas amiga?veis para os usua?rios.\n\nAnalisando as ferramentas de gerenciamento e acesso de mu?ltiplos clusters apre-\nsentadas acima percebe-se que elas na?o possuem suporte para todos os aspectos des-\ncritos acima. Transpare?ncia de acesso e? provida tanto pelo ambiente M3C quanto\npelo HPC2N. Extensibilidade e? provida somente pelo M3C, e ainda de forma par-\ncial. Uniformizac?a?o das operac?o?es esta? relacionada com a caracter??stica de extensi-\nbilidade, pois implica na possibilidade de lidar com diferentes ferramentas mas com\n\n\n\n28\n\na mesma funcionalidade. Nenhum dos ambientes proporcionam essa caracter??stica.\nDa mesma forma como na?o apresentam completeza (capacidade de lidar com di-\nferentes funcionalidades de clusters), interoperabilidade, capacidade de lidar com\nsistemas legados. Os ambientes M3C e HPC2N apresentam interfaces gra?ficas que\nfacilitam as operac?o?es dos usua?rios. Enfim, esses ambientes promovem facilidades no\ngerenciamento e acesso a mu?ltiplos clusters, mas ainda na?o esta?o suficientemente ma-\nduros para prover caracter??sticas fundamentais como extensibilidade, uniformizac?a?o,\ninteroperabilidade e suporte a sistemas legados.\n\n2.3 Resumo\n\nNeste cap??tulo foram apresentadas as principais caracter??sticas de sistemas dis-\ntribu??dos e de sistemas de alto desempenho. Como visto, sistemas de alto desem-\npenho podem ser considerados como uma especializac?a?o de sistemas distribu??dos.\nEles apresentam, em geral, os mesmos problemas de gerenciamento, facilidade de\nutilizac?a?o, so? que possuem um fim mais espec??fico - resolver problemas de forma\neficiente. Dentro de sistemas HPC, te?m-se clusters e grids como os cena?rios mais\nutilizados pelos usua?rios. O gerenciamento desse tipo de sistema apresenta desafios.\nE? preciso prover aos usua?rios e administradores ferramentas de fa?cil utilizac?a?o e que\nconsigam gerenciar as funcionalidades desses cena?rios. Na a?rea de gerenciamento\nde clusters existem muitos trabalhos consolidados e bem estabelecidos, enquanto\nna a?rea de grids ainda existem discusso?es e campo aberto para inovac?o?es e novas\nabordagens. Entretanto, tambe?m foi apresentado neste cap??tulo que existe uma\nintersecc?a?o entre clusters e grids, denominada de multiclusters. Essa intersecc?a?o\napresenta algumas ferramentas de gerenciamento, mas elas ainda na?o prove?em ca-\nracter??sticas importantes para um escopo como este, distribu??do e heteroge?neo.\n\n\n\n29\n\n3 PROPOSTA DE AMBIENTE INTEGRADO PARA\n\nCLUSTERS: ICE\n\nO ambiente ICE (Integrated Cluster Environment) (MARQUEZAN et al., 2006)\ne? proposto com o intuito de prover as caracter??sticas de gerenciamento de mu?ltiplos\nclusters que ainda na?o foram contempladas pelas plataformas ja? existentes, como\napresentado na Cap??tulo 2. Sendo assim, os objetivos do ambiente ICE sa?o prover\nas caracter??sticas descritas abaixo.\n\n\u2022 Extensibilidade - O ambiente tem que ser capaz de incorporar novas funciona-\nlidades sem que isso impacte na sua execuc?a?o em geral. Por funcionalidades\nentende-se os servic?os tipicamente disponibilizados para os usua?rios dos clus-\nters ou aqueles utilizados pelos pro?prios administradores. Exemplos de funcio-\nnalidades sa?o: monitoramento dos recursos de um cluster, monitoramento das\naplicac?o?es, gerenciamento das aplicac?o?es dos usua?rios, ac?o?es administrativas\nnos componentes dos clusters (no?s, front-end e rede de intercomunicac?a?o), etc.\nMas ale?m de prover extensibilidade no n??vel das funcionalidades do sistema, o\nambiente ICE tambe?m deve visar a extensibilidade de ferramentas. Isso signi-\nfica que o ambiente deve suportar a utilizac?a?o de qualquer ferramenta, e que\nna?o esta? restrito a um conjunto fixo de ferramentas.\n\n\u2022 Transpare?ncia - A proposta do ambiente ICE e? prover transpare?ncia de acesso\na?s ferramentas e tambe?m transpare?ncia na forma de utilizac?a?o dessas ferra-\nmentas. Dessa forma os usua?rios podera?o acessar as ferramentas sem ter a\nnoc?a?o de quais exatamente esta?o utilizando. A mesma ide?ia se aplica para\nexecuc?a?o das suas operac?o?es, isto e?, os usua?rios na?o ira?o lidar diretamente\ncom o formato dos para?metros e nem com os comandos de cada uma delas.\n\n\u2022 Uniformizac?a?o das operac?o?es - Atrave?s de sua arquitetura o ambiente ICE se\npropo?e a uniformizar a forma como as operac?o?es das ferramentas integradas\nsa?o realizadas. O objetivo e? fazer com que os usua?rios do sistema executem\nas mesmas ac?o?es independentemente do tipo de ferramenta que esta? instalada\nnos clusters aos quais eles te?m acesso.\n\n\u2022 Completeza - O ambiente proposto visa abranger as atividades tipicamente\nexecutadas em um cluster, como por exemplo: gerenciamento de aplicac?o?es\n(submissa?o, te?rmino, visualizac?a?o) monitoramento de recursos e aplicac?o?es e\nintervenc?o?es administrativas. Pretende-se que o usua?rio acesse o ambiente\nICE e atrave?s dele consiga fazer todas as tarefas que anteriormente ele fazia\natrave?s de um terminal. Para isso a definic?a?o da arquitetura ICE procura ser\n\n\n\n30\n\no mais flex??vel poss??vel para permitir que diferentes tipos de atividades sejam\ninclu??das na plataforma.\n\n\u2022 Interoperabilidade - Para que o ambiente ICE seja capaz de gerenciar mu?ltiplos\nclusters, cada um com diferentes ferramentas, e? preciso que ele seja capaz de\nlidar com os sistemas legados desses clusters. Essa e? uma caracter??stica fun-\ndamental e que diferencia o ambiente ICE dos demais trabalhos realizados no\nmesmo escopo. O ICE e? capaz de ser instalado sem que isso interfira na infra-\nestrutura existente no cluster. Ale?m disso, o ambiente ICE e? independente\nde plataforma de hardware e software. Ele e? capaz de lidar com essas espe-\ncificidades de maneira transparente. Portanto, dentro do ambiente pode-se\ngerenciar clusters baseados em diferentes arquiteturas de hardware e sistemas\noperacionais.\n\n\u2022 Facilidade de uso - Uma caracter??stica tambe?m importante do ambiente ICE\ne? prover facilidade de uso aos seus usua?rios. Esse ambiente permite que seus\nusua?rios trabalhem com as ferramentas existentes nos clusters sem ter que\nlidar com os para?metros e comandos espec??ficos das mesmas. Atrave?s da apre-\nsentac?a?o gra?fica, eles podem realizar suas atividades sem ter que aprender a\nusar as ferramentas. No cena?rio de mu?ltiplos clusters essa caracter??stica e? im-\nportante. Ao inve?s de aprender a lidar com todas as ferramentas dos clusters,\naos quais os usua?rios tem acesso, eles aprendem a lidar somente com o ambi-\nente ICE. Esse, por sua vez, apresenta um ponto u?nico de acesso aos usua?rios e\ntrata toda a complexidade das ferramentas sem a intervenc?a?o de seus usua?rios.\n\nO pu?blico alvo do ambiente ICE sa?o usua?rios que na?o sa?o nativos da a?rea da\ncie?ncia da computac?a?o e mais especificamente da a?rea de alto desempenho, como\npor exemplo, pesquisadores nas a?reas de f??sica, bio-informa?tica, geo-processamento,\netc. Esse tipo de usua?rio utiliza os recursos que os sistemas HPC disponibilizam, mas\nna?o sa?o seus objetivos saber exatamente como as coisas funcionam e nem lidar com\nas especificidades das ferramentas que executam as tarefas que eles precisam. Por\nexemplo, usua?rios da a?rea de recursos h??dricos necessitam de clusters para executa-\nrem suas simulac?o?es, mas na?o e? seu interesse saber como funciona um gerenciador de\naplicac?o?es (como o OpenPBS (PORTABLE BATCH SYSTEM, 2005)) ou uma fer-\nramenta de monitoramento (como o Ganglia (SACERDOTI; et al., 2003)). Muitas\nvezes esse tipo de usua?rios tem acesso a diferentes sistemas de HPC. Para cada um\ndeles seria necessa?rio aprender o funcionamento das ferramentas. E? para atender\na?s necessidades desse tipo de usua?rios que o ambiente ICE torna-se mais indicado.\nEntretanto, isto na?o significa que usua?rios da a?rea de computac?a?o de alto desem-\npenho na?o possam tirar proveito do ambiente. Esse tipo de usua?rio, em geral com\nmaior conhecimento das ferramentas empregadas, pode se beneficiar das facilidades\nde acesso e de visualizac?a?o que o ambiente ICE proporciona.\n\nOutra caracter??stica do ambiente ICE e? a filosofia de incorporar e buscar adap-\ntar padro?es e especificac?o?es ao contexto de gerenciamento de mu?ltiplos clusters. A\nide?ia e? evitar criar novas infra-estruturas, protocolos e especificac?o?es. O objetivo e?\nfazer com que os sistemas de clusters que ja? existem sejam integrados em um u?nico\nambiente sem que isso exija a utilizac?a?o de mecanismos e middlewares que res-\ntrinjam extensibilidade e interoperabilidade do ambiente ICE. Organizac?o?es, como\npor exemplo, W3C (W3C ARCHITECTURE DOMAIN - WEB SERVICES AC-\nTIVITY, 2005) e OASIS (OASIS-WS - OASIS COMMITTEES BY CATEGORY:\n\n\n\n31\n\nWEB SERVICES, 2005), tem trabalhado na padronizac?a?o de protocolos e em espe-\ncificac?o?es para criac?a?o de sistemas inter-opera?veis. Exemplo destes esforc?os sa?o as\nespecificac?o?es ligadas a Web services. Outras organizac?o?es como por exemplo GGF\n(GLOBAL GRID FORUM, 2005) esta?o trabalhando na definic?a?o de especificac?o?es\ne padronizac?o?es na a?rea de grids. A filosofia que se pretende adotar no ambiente\nICE e? aproveitar estas iniciativas so? que adaptando-as para o cena?rio de mu?ltiplos\nclusters.\n\nO contexto de grid e de mu?ltiplos clusters e? semelhante em alguns aspectos. Am-\nbos lidam com recursos que esta?o dispersos fisicamente, o que exige a inserc?a?o de um\ncerto grau de seguranc?a no sistema. O acesso aos recursos tem que ser transparente e\ndeve existir uma maneira de uniformizar a utilizac?a?o das ferramentas dos diferentes\nrecursos participantes. Entretanto, o cena?rio de grids requer mais mecanismos de\ncontroles. Em grids e? preciso levar em considerac?a?o questo?es como: dinamicidade\nde recursos, manter canais de comunicac?a?o entre recursos alocados em dom??nios\nadministrativos diferentes, manter informac?o?es de controle de onde esta?o sendo exe-\ncutadas as aplicac?o?es dentre os diversos dom??nios, entre outros (LI; BAKER, 2005).\nTodos esses controles sa?o decorrentes do fato dos recursos que fazem parte dos grids\nserem alocados de forma transparente e independente. Isto e?, o usua?rio solicita um\ndeterminado nu?mero de recursos independentemente de sua localizac?a?o f??sica. No\ncontexto de mu?ltiplos clusters, ao qual o ambiente ICE se destina, o usua?rio sabe\nonde esta?o os recursos que ele esta? solicitando. Dessa forma, na?o e? preciso manter\ntoda a infra-estrutura de controle de localizac?a?o de recursos neste contexto. Baseado\nnas semelhanc?as e distinc?o?es entre estes dois cena?rios percebeu-se que alguns con-\nceitos, especificac?o?es e padro?es do mundo de grid podem ser mapeados e utilizados\nno gerenciamento de mu?ltiplos clusters. Esses reaproveitamentos sera?o abordados\ncom mais detalhes no Cap??tulo 4.\n\nA seguir sera?o apresentados os cena?rios distribu??dos nos quais o ambiente ICE\npode ser adotado e o modelo da arquitetura projetada para o ambiente ICE.\n\n3.1 ICE como um Sistema Distribu??do\n\nAntes de compreender a arquitetura projetada para a plataforma ICE e? preciso\nentender o grau de distribuic?a?o inserido neste contexto. O primeiro ponto a ser\nconsiderado e? o escopo em que o ambiente ICE esta? inserido. Ele foi definido para\nser empregado em um cena?rio composto por mu?ltiplos clusters, entretanto o acesso\na estes diferentes clusters e? realizado atrave?s de um u?nico ponto, o qual esconde a\ncomplexidade de lidar com diferentes clusters distribu??dos em diferentes dom??nios\nadministrativos. A Figura 3.1 apresenta este cena?rio de utilizac?a?o do ambiente ICE.\n\nOs clusters gerenciados pelo ambiente ICE podem estar em quaisquer dom??nios\nadministrativos, assim como os usua?rios que os acessam. Como a Figura 3.1 mostra,\nexistem interac?o?es entre usua?rios e o ambiente ICE e entre esse e os clusters gerenci-\nados. Esses dois tipos de interac?o?es possuem caracter??sticas diferentes. No primeiro\ncaso trata-se de um sistema Web. Sendo assim, e? preciso lidar com as questo?es\nrelacionadas a aplicac?o?es Web, como por exemplo: separac?a?o entre a apresentac?a?o\ndas informac?o?es da lo?gica do sistema (modelo de aplicac?a?o em 3 camadas), questo?es\nde seguranc?a no servidor Web, entre outras. No segundo caso, trata-se de um mid-\ndleware para gerenciamento das atividades em clusters. Questo?es de seguranc?a,\nuniformizac?a?o do acesso, interoperabilidade e flexibilidade devem ser consideradas\n\n\n\n32\n\nCluster 3Cluster 1 Cluster 2\n\nICE\n\nUsu\u00e1rio A Usu\u00e1rio B Usu\u00e1rio C\n\nDom\u00ednio\nAdministrativo 1\n\nDom\u00ednio\nAdministrativo 2\n\nDom\u00ednio\nAdministrativo 3\n\nFigura 3.1: Visa?o geral do cena?rio de utilizac?a?o do ICE\n\nnas deciso?es de definic?a?o dessa parte do sistema.\n\nO segundo ponto considerado relaciona-se com o fato do ambiente ICE na?o ser\napenas um Portal Web ou um sistema rodando no front-end de um cluster. O\nambiente ICE e? a unia?o entre o ponto u?nico de acesso dos usua?rios - Portal Web -\ncom o middleware definido para o gerenciamento e acesso das funcionalidades dos\nclusters.\n\n3.2 Arquitetura ICE\n\nNo momento que se compreende o cena?rio no qual o ambiente ICE sera? utilizado\npode-se perceber que a arquitetura desse sistema deve ser o mais flex??vel poss??vel\npara poder lidar com a heterogeneidade de seu contexto.\n\nUma caracter??stica principal da arquitetura ICE e? sua modularidade. O obje-\ntivo e? que se possa inserir novas funcionalidades e novas ferramentas sem que isso\naltere o modelo do ambiente. A ide?ia por tra?s da arquitetura do ambiente ICE e?\nfazer com que existam mo?dulos ba?sicos do sistema e uma infra-estrutura para pro-\nver servic?os de clusters. Na visa?o do ambiente ICE, cada funcionalidade existente\nem um cluster, como por exemplo: monitoramento de recursos, gerenciamento de\naplicac?o?es e recursos atrave?s do uso de escalonadores, e? potencialmente um servic?o\na ser disponibilizado.\n\nComo apresentado na Sec?a?o 3.1, esse ambiente e? divido em dois contextos: ponto\nu?nico de acesso (Portal Web) e o middleware para lidar com o gerenciamento e\nacesso aos clusters. De modo geral o mapeamento da arquitetura ICE para esses\ncontextos pode ser feita da seguinte forma: os mo?dulos ba?sicos sa?o mapeados para\na infra-estrutura necessa?ria para modelagem e construc?a?o do Portal Web; enquanto\na infra-estrutura para prover os servic?os e? mapeada para o middleware.\n\nNa concepc?a?o da arquitetura ICE, optou-se por utilizar o modelo de arquite-\ntura orientada a servic?os (SOA - Service Oriented Architecture) (MCGOVERN; et\n\n\n\n33\n\nal., 2003) para definic?a?o do middleware que viabiliza a infra-estrutura de servic?os\nnos clusters. Essa decisa?o foi tomada dadas as caracter??sticas que este modelo de\narquitetura proporciona a?s aplicac?o?es que a adotam (MCGOVERN; et al., 2003):\n\n\u2022 os servic?os sa?o descobertos e dinamicamente localizados;\n\n\u2022 os servic?os sa?o auto-contidos, modulares e apresentam um baixo acoplamento;\n\n\u2022 os servic?os possuem interoperabilidade;\n\n\u2022 os servic?os apresentam transpare?ncia de localizac?a?o e podem ser compostos\ncom outros servic?os;\n\n\u2022 a arquitetura orientada a servic?os suporta a caracter??stica de auto-cura (self-\nhealing), ou seja, e? capaz de identificar problemas em sua estrutura e tomar\nmedidas para trata?-las.\n\nA maior vantagem em utilizar uma arquitetura orientada a servic?os e? poder\nseparar a implementac?a?o de um servic?o de sua interface. Essa caracter??stica e? fun-\ndamental para a modelagem e o desenvolvimento do ambiente ICE.\n\nA Figura 3.2 apresenta a arquitetura definida para o ambiente ICE, a qual esta?\ndividida em dois componentes principais: Middleware de Servic?os e o Portal Web.\nO Middleware de Servic?os e? formado por tre?s mo?dulos: Unified Service Interface\n(USI), Service Implementation (SI) e Service Module (SM). Atrave?s da Figura 3.2\npode-se perceber que o SM tambe?m faz parte do Portal Web. Esse mo?dulo sera?\ndetalhado no decorrer desta sec?a?o e sera?o esclarecidas as razo?es pelas quais ele faz\nparte dos dois componentes. Ainda formam o Portal Web os mo?dulos: Security\nModule (SecM) e System Management Module (SMM). A seguir cada componente\ne seus respectivos mo?dulos sera?o descritos detalhadamente.\n\nFigura 3.2: Arquitetura ICE\n\n\n\n34\n\n3.2.1 Middleware de Servic?os\n\nNo Midleware de Servic?os (os mo?dulos cinza escuro dentro da a?rea achurada\nna Figura 3.2) sa?o considerados os aspectos ligados a arquitetura SOA utilizada\nno ambiente ICE. Esse modelo se caracteriza pela existe?ncia de um provedor, um\nconsumidor e um registro de servic?os. Mapeando essa estrutura para o contexto do\nambiente ICE te?m-se como provedor de servic?os os mo?dulos SI nos front-ends dos\nclusters, os consumidores sa?o os mo?dulos SM e o registro de servic?os esta? no repo-\nsito?rio do Portal Web. Segundo a definic?a?o da arquitetura SOA (MCGOVERN; et\nal., 2003; ALONSO; et al., 2004) e? preciso que exista uma forma de descrever esses\nservic?os. Essa descric?a?o, no escopo do ambiente ICE e? o mo?dulo USI. Os mo?dulos\nque compo?em o Middleware de Servic?os sa?o estruturas conceituais. Atrave?s da\ninstanciac?a?o das mesmas e? que pode-se efetivamente definir e disponibilizar funcio-\nnalidades no ambiente ICE. Por questo?es de melhor compreensa?o seus mo?dulos sera?o\napresentados na seguinte ordem: USI, SI e SM.\n\nAo mo?dulo Unified Service Interface (USI) e? atribu??da a func?a?o de servir\ncomo elemento de definic?a?o da interface do servic?o a ser fornecido por um cluster. A\ndefinic?a?o de uma interface implica na especificac?a?o das operac?o?es desse servic?o, de\nseus para?metros e da sema?ntica que lhe sera? atribu??da. Atrave?s de uma USI pode-se\nuniformizar o acesso a diferentes ferramentas que possuam a mesma funcionalidade.\nO processo de criac?a?o de uma USI consiste na ana?lise de ferramentas semelhantes,\nque sa?o tipicamente utilizadas no cena?rio de clusters, e na descoberta de carac-\nter??sticas em comum entre elas. Esse processo e? necessa?rio para que o ambiente ICE\nmantenha compatibilidade com os sistemas ja? empregados nos clusters e que na?o se\ncriem operac?o?es e para?metros que na?o podera?o ser mapeados para as ferramentas\nexistentes nos mesmos. A intersecc?a?o gerada por essa ana?lise deve conter pelo me-\nnos um conjunto m??nimo de operac?o?es e para?metros utilizadas pelos usua?rios dessa\nfuncionalidade e ao mesmo tempo deve conter o ma?ximo de caracter??sticas em co-\nmum das ferramentas analisadas. Todo este processo de ana?lise e definic?a?o pode se\ntornar bastante emp??rico dependendo do tipo de funcionalidade que se esta? tentando\nespecificar. Como um dos objetivos do ambiente ICE e? a utilizac?a?o de padro?es e\nespecificac?o?es ja? existentes, recomenda-se que a definic?a?o de USIs seja baseada em\nalguma especificac?a?o em vigor.\n\nO mo?dulo Service Implementation (SI) e? o elemento que prove? os servic?os\ndentro da arquitetura ICE. Para que se possa modelar um SI e? preciso que exista\numa USI definida. Para uma mesma USI pode-se definir diferentes SIs, isto e?, para\ncada ferramenta com a mesma funcionalidade pode-se implementar um SI. E? impor-\ntante ressaltar que existem situac?o?es nas quais na?o e? poss??vel haver o mapeamento\ndireto entre as operac?o?es de uma USI para os comandos e para?metros da ferramenta\nque esta? sendo integrada no ambiente. Neste caso, cabe ao mo?dulo SI tratar essas\nsituac?o?es, fazendo as adaptac?o?es necessa?rias sem que elas interfiram no funciona-\nmento da ferramenta em si. Na?o interferir no funcionamento e? um requisito que\ndeve ser seguido para que se possa atingir a capacidade de integrac?a?o de sistemas\nlegados que o ambiente visa. A combinac?a?o de USI mais SIs garante a capacidade\nde extensibilidade de ferramentas visada pelo ambiente ICE.\n\nO Middleware de Servic?os ainda e? formado pelo Service Module (SM). Como\napresentado anteriormente, o SM esta? presente tanto no Portal Web quanto nesse\ncomponente. Aqui, ele assume as responsabilidades de consumidor de servic?os. Da\nmesma forma como a construc?a?o do SI depende de uma USI, o SM tambe?m deve\n\n\n\n35\n\nseguir a USI definida para a funcionalidade em questa?o. A caixa preenchida em\ncinza escuro no mo?dulo Service Module da Figura 3.2 ilustra a diferenc?a entre as\nfunc?o?es que ele assume em cada componente. A porc?a?o consumidora de servic?os\ndo SM monta a requisic?a?o para uma determinada operac?a?o atrave?s das informac?o?es\nrecebidas pela parte gra?fica do SM, pertencente ao Portal Web. Ao receber a res-\nposta do provedor de servic?os, deve tratar as informac?o?es entregando-as para serem\nnovamente apresentadas na interface Web. Para cada USI e? preciso o desenvolvi-\nmento de somente um SM a ser integrado no Portal Web, pois a forma de acesso\ndas operac?o?es deve ser uniforme e transparente.\n\n3.2.2 Portal Web\n\nPortal Web e? o componente cujo foco principal e? encapsular o acesso a?s funci-\nonalidades dos clusters atrave?s de um u?nico ponto. Por questo?es de flexibilidade\ne acessibilidade decidiu-se que esse componente sera? uma aplicac?a?o Web baseada\nno modelo de tre?s camadas (ALONSO; et al., 2004) e no modelo MVC (Model\nView-Controller ) (HANSEN; FOSSUM, 2005). Atrave?s desses modelos e? poss??vel,\nrespectivamente, concentrar a lo?gica do sistema em um middleware, resguardando\nas informac?o?es e recursos do sistema; e tambe?m separar a lo?gica do sistema de sua\napresentac?a?o. Como ilustrado na Figura 3.2, o Portal Web e? composto por tre?s\nmo?dulos, os quais sa?o descritos abaixo.\n\nO Security Module (SecM) trata das questo?es de autenticac?a?o e de autorizac?a?o\ndos usua?rios do ambiente ICE. Somente usua?rios autenticados podem utilizar esse\nambiente. Ale?m disso, esses usua?rios possuem restric?o?es de acesso. Eles podem\nacessar somente a?reas nas quais esta?o autorizados para tanto. O processo de au-\ntorizac?a?o esta? ligado a? ide?ia de perfis e grupos de usua?rios. A primeira ide?ia esta?\nrelacionada a questo?es de autorizac?a?o no Portal Web, enquanto a segunda esta? ligada\naos front-ends dos clusters e consequ?entemente ao middleware de servic?os. Maiores\ninformac?o?es sobre o esquema de seguranc?a definido para o ambiente ICE podem ser\nencontradas em (ILHA, 2005).\n\nO System Management Module (SMM) foi definido no intuito de concentrar\nas atividades de gerenciamento e configurac?a?o do pro?prio ambiente ICE. Ele possui\nas seguintes atribuic?o?es:\n\n\u2022 gerenciar os perfis dos usua?rios, isto inclui a definic?a?o de perfis e das permisso?es\nde acesso a?s a?reas do ambiente ICE que cada tipo de perfil possuira?;\n\n\u2022 coordenar o processo de autenticac?a?o e autorizac?a?o dos usua?rios, para tanto\nsera?o utilizadas as estruturas de seguranc?a definidas no mo?dulo SecM;\n\n\u2022 gerenciar as informac?o?es dos clusters que esta?o sob controle do ambiente ICE;\n\n\u2022 manipular as funcionalidades oferecidas pelo ICE, isto implica a inserc?a?o,\nremoc?a?o e alterac?a?o das funcionalidades existentes no ambiente; o que im-\npacta diretamente nos mo?dulos de servic?os (SM);\n\n\u2022 gerenciar os relacionamentos entre usua?rios, clusters e funcionalidades desses\nclusters;\n\n\u2022 tratar da apresentac?a?o das pa?ginas web, uma vez que as pa?ginas sa?o geradas\ndinamicamente de acordo com (i) o perfil dos usua?rios, (ii) os clusters que eles\n\n\n\n36\n\nte?m acesso e ainda (iii) quais funcionalidades disponibilizadas nesses clusters\nque eles podem acessar.\n\nComo destacado acima, a ide?ia de perfil de usua?rios e? um ponto relevante dentro\ndo Portal Web. E? atrave?s dos perfis que se definem as pol??ticas de acesso do ambiente\nICE. Essas pol??ticas esta?o ligadas a permisso?es: de gerenciamento do sistema como\num todo, de gerenciamento das informac?o?es dos clusters inseridos no ambiente, de\nautorizac?a?o para utilizac?a?o de clusters e de suas funcionalidades. A Tabela 3.1\napresenta os perfis atualmente definidos no ambiente ICE.\n\nTabela 3.1: Descric?a?o dos perfis atualmente definidos no ambiente ICE\nPerfil Descric?a?o das capacidades dentro do ICE\nICE ROOT Gerenciamento de usua?rios, clusters e funcionalidades\n\n(inserc?a?o, remoc?a?o e alterac?o?es)\nEspecificac?a?o das funcionalidades dos clusters (SM)\n\nCLUSTER ROOT Gerenciamento dos usua?rios dos clusters\nAssociac?a?o de funcionalidades a clusters\nAssociac?a?o de usua?rios a clusters\nAssociac?a?o de usua?rios a?s funcionalidades dos clusters\nManutenc?a?o dos relacionamentos entre usua?rios,\nclusters e funcionalidades\n\nUSER Utilizac?a?o das funcionalidades associadas ao usua?rio\n\nNo ambiente ICE os perfis sa?o atribu??dos para cada usua?rio em relac?a?o a cada\ncluster que ele tem permissa?o de utilizac?a?o. A excec?a?o e? o perfil ICE ROOT, pois\nele na?o esta? ligado a nenhum cluster e pode ser associado a qualquer usua?rio que\npossuir as permisso?es de administrador do ambiente ICE. Atrave?s da abordagem de\nassociac?a?o de perfis de acordo com os clusters acess??veis, e? poss??vel que um mesmo\nusua?rio tenha diferentes perfis entre os diferentes clusters. Tambe?m e? poss??vel que no\nmesmo cluster esse usua?rio apresente diferentes perfis. Por exemplo, considerando\nos usua?rios apresentados na Figura 3.1, e? poss??vel que o Usua?rio A possua o perfil\nCLUSTER ROOT no Cluster 2 e o perfil USER no Cluster 1 ; mas nada impede que\nele tambe?m possua o perfil USER tambe?m no Cluster 2. Enfim, de forma resumida\npode-se dizer que o perfil ICE ROOT esta? relacionado com as ac?o?es de configurac?a?o\ndo ambiente ICE, o perfil CLUSTER ROOT esta? ligado a?s questo?es de preparac?a?o\ndas informac?o?es dos clusters para serem integrados no ambiente ICE, enquanto o\nperfil USER esta? relacionado com as funcionalidades, ou seja SMs que os usua?rio\ntera?o acesso.\n\nO Service Module (SM) e? um mo?dulo conceitual, cujo objetivo e? servir de\nframework para a incorporac?a?o de funcionalidades no sistema. Como apresentado\nanteriormente, esse mo?dulo esta? presente tambe?m no Middleware de Servic?os. A\ncaixa cinza mais clara no mo?dulo Service Module da Figura 3.2 ilustra a porc?a?o\npertencente ao Portal Web desse mo?dulo. Nele, o SM assume as atribuic?o?es de prover\nas abstrac?o?es gra?ficas e facilidade de uso para os usua?rios da funcionalidade em\nquesta?o. Esta porc?a?o gra?fica e? criada atrave?s dos para?metros e operac?o?es existentes\nna USI definida para a funcionalidade.\n\n\n\n37\n\n3.2.3 Cena?rio de Aplicac?a?o da Arquitetura ICE\n\nPara que se possa compreender melhor como cada mo?dulo da arquitetura ICE\ne? empregado e como ela pode ser estendida a Figura 3.3 ilustra um cena?rio de\nutilizac?a?o do ambiente ICE.\n\nFigura 3.3: Instanciac?a?o da Arquitetura ICE\n\nNa Figura 3.3 esta?o definidos dois mo?dulos de servic?o: Resource Monitoring\n(RM-SM) e Job Management (JM-SM). Esses mo?dulos seguem, respectivamente, as\ninterfaces de servic?os definidas em RM-USI e JM-USI. No contexto de utilizac?a?o\napresentado na Figura 3.3 existem tre?s clusters. O Cluster I possui suporte para as\nduas funcionalidades, enquanto o Cluster II possui suporte apenas para a funciona-\nlidade de Resource Monitoring e o Cluster III apenas para a funcionalidade de Job\nManagement.\n\nComo em um cena?rio comum em HPC, cada cluster apresenta o seu conjunto de\nferramentas. Para que se possa integrar esses clusters no ambiente de gerenciamento\nICE e? preciso preservar esta diversidade. A aplicac?a?o da arquitetura ICE nesse\ncontexto garante essa caracter??stica. A Figura 3.3 mostra que para as mesmas\nfuncionalidades e? poss??vel integrar ferramentas diferentes em clusters distintos. Cada\ncluster que prove? uma funcionalidade (servic?o) tem que ter um SI implementado de\nacordo com a USI da funcionalidade em questa?o. Desta forma, existe para a RM-\nUSI o mo?dulo RM-SI no Cluster I e no Cluster II, enquanto para a JM-USI existem\ndois SIs, localizados no Cluster I e Cluster III.\n\nA motivac?a?o para apresentac?a?o da Figura 3.3 e? ilustrar o potencial de extensibili-\ndade, transpare?ncia e uniformizac?a?o que a arquitetura do ambiente ICE proporciona\n\n\n\n38\n\nno gerenciamento e acesso de mu?ltiplos clusters. O objetivo final do ambiente ICE e?\nprover servic?os de: monitoramento de recursos, monitoramento de aplicac?o?es, geren-\nciamento de aplicac?o?es, depurac?a?o de aplicac?o?es e gerenciamento de configurac?a?o de\nclusters. Sendo que essa na?o e? uma lista fechada de funcionalidades que se pretende\ninserir nesse ambiente.\n\n3.3 Resumo\n\nO ambiente ICE e? uma plataforma de gerenciamento e de acesso a mu?ltiplos\nclusters. Os principais objetivos desse ambiente sa?o prover: (i) extensibilidade das\nfuncionalidades agregadas na plataforma, e extensibilidade das ferramentas que po-\ndem ser integradas; (ii) transpare?ncia de acesso e de uso das ferramentas existentes\nnos clusters; (iii) uniformizac?a?o da forma como as operac?o?es das ferramentas dos\nclusters sa?o executadas; (iv) completeza, ou seja, ser capaz de incorporar todos os\ntipos de servic?os que um cluster pode disponibilizar; (v) interoperabilidade, garan-\ntindo que sistemas legados sejam incorporados ao ambiente; (vi) facilidade de uso,\npermitindo que os usua?rios possam interagir com uma interface gra?fica amiga?vel.\n\nPara que se consiga atingir estes objetivos a arquitetura do ambiente ICE foi pro-\njetada para ser modular e baseada no modelo SOA (Service Oriented Architecture).\nAtrave?s desse modelo e? poss??vel garantir uma independe?ncia entre especificac?a?o dos\nservic?os e a forma como eles sa?o implementados. Esse tipo de caracter??stica e? fun-\ndamental para que se consiga prover extensibilidade, transpare?ncia e uniformizac?a?o.\n\nA arquitetura ICE esta? dividida em dois componentes: Middleware de Servic?os\ne Portal Web. O primeiro componente e? formado pelos mo?dulos de definic?a?o de\num servic?o (USI - Unified Service Interface), provedor de servic?os (SI - Service\nImplementation) e consumidor de servic?os (SM - Service Module). O segundo com-\nponente e? formado pelos mo?dulos de gerenciamento do pro?prio ambiente (SMM -\nSystem Management Module), de seguranc?a do sistema (SecM - Security Module)\ne por um mo?dulo de servic?os (SM - Service Module). Esse u?ltimo mo?dulo possui\nfunc?o?es nos dois componentes da arquitetura ICE, sendo que no Portal Web ele\nassume um cara?ter mais de apresentac?a?o gra?fica das informac?o?es e no Middleware\nde Servic?os possui o cara?ter de consumidor de servic?os.\n\nAtrave?s da arquitetura proposta e? poss??vel o desenvolvimento de um ambiente de\ngerenciamento e de acesso a mu?ltiplos clusters que e? capaz de incorporar os sistemas\nlegados dos clusters, ser estendido para ser usado com diferentes funcionalidades e\nferramentas, ser transparente e de fa?cil utilizac?a?o. O pro?ximo cap??tulo apresenta\nalgumas deciso?es de implementac?o?es tomadas, ale?m de descrever o proto?tipo imple-\nmentado para validar a arquitetura proposta.\n\n\n\n39\n\n4 DESENVOLVIMENTO DO PROTO?TIPO DO AM-\n\nBIENTE ICE\n\nEste cap??tulo descreve o desenvolvimento do proto?tipo do ambiente ICE, o qual\nsegue a arquitetura proposta no Cap??tulo 3. Sera?o apresentadas as deciso?es de\nprojeto, os mo?dulos que foram implementados e a forma como esse processo foi\nrealizado.\n\n4.1 Deciso?es de Projeto\n\nA primeira decisa?o de projeto a ser considerada foi qual middleware deveria ser\nutilizado para o desenvolvimento da infra-estrutura de servic?os. Dado o fato de que\no Middleware de Servic?o segue uma arquitetura SOA foi necessa?rio analisar plata-\nformas compat??veis com essa abordagem. Como apresentado no Cap??tulo 2, existem\nalguns middlewares para o desenvolvimento de sistemas distribu??dos. Dentre estes,\nescolheu-se CORBA e Web Services para serem analisados visto que eles podem ser\nconsiderados os middlewares mais representativos (COULOURIS; DOLLIMORE;\nKINDBERG, 2005).\n\nO segundo aspecto levado em considerac?a?o para o desenvolvimento do ambiente\nICE esta? relacionado com a definic?a?o de que padro?es e especificac?o?es poderiam ser in-\ncorporadas ao ambiente ICE. Foram analisados: o padra?o de facto em infra-estrutura\npara grid - Globus Toolkit (GLOBUS - WELCOME TO THE GLOBUS TOOLKIT\nHOMEPAGE, 2005), e as especificac?o?es OGSA (Open Grid Service Architecture) e\nOGSI (Open Grid Service Infrastructure) (LI; BAKER, 2005).\n\nA seguir sa?o apresentadas as considerac?o?es sobre as ana?lises destes pontos e as\ndeciso?es tomadas para o desenvolvimento do proto?tipo do ambiente ICE.\n\n4.1.1 Definic?a?o do Middleware Empregado\n\nCORBA e? um middleware amplamente usado na construc?a?o de sistemas dis-\ntribu??dos, sendo que inu?meras aplicac?o?es ja? foram implementadas sobre essa plata-\nforma (ALONSO; et al., 2004). Apesar de na?o apresentar uma arquitetura SOA,\nCORBA possui algumas caracter??sticas da mesma, como por exemplo: prover in-\nteroperabilidade (mesmo que em contextos menores (COULOURIS; DOLLIMORE;\nKINDBERG, 2005)), sistema de descoberta de servic?os e capacidade de isolar o fun-\ncionamento dos objetos de sua API. Essa u?ltima caracter??stica e? fundamental em\numa arquitetura SOA (como visto na Sec?a?o 3.2). Entretanto, CORBA na?o permite\nque os usua?rios acessem a lo?gica dos nego?cios facilmente atrave?s da Internet (MC-\nGOVERN; et al., 2003). A tecnologia Web Services, por sua vez, e? um middleware\n\n\n\n40\n\nbaseado em uma arquitetura SOA. Ela na?o apresenta todas as caracter??sticas dessa\narquitetura (MCGOVERN; et al., 2003), mas prove? suporte para grande parte delas,\nou pelo menos para as mais importantes.\n\nA comparac?a?o ra?pida entre CORBA e Web Services apresentada em (COULOU-\nRIS; DOLLIMORE; KINDBERG, 2005) ilustra as principais diferenc?as entre esses\nmiddleware. A Tabela 4.1 mostra essas diferenc?as.\n\nTabela 4.1: Comparac?a?o entre CORBA e Web Services\nAspecto CORBA Web Services\n\nNomeac?a?o Servic?o de nomeac?a?o CORBA DNS\nFormato da Refere?ncia IOR URL\n\n(Internet-wide Object Reference)\nAtivac?a?o e Localizac?a?o Integrados Separados\nFacilidade de Uso Software complexo que Infra-estrutura ja?\n\nrequer instalac?a?o e suporte instalada\n(HTTP + XML)\n\nEficie?ncia Definido para ser eficiente Menos eficiente\n(dados bina?rios) (dados textuais)\n\nO primeiro ponto que os distingue e? quanto ao esquema de nomeac?a?o utilizado.\nCORBA baseia-se em uma estrutura de nomeac?a?o pro?pria, enquanto Web Services\nutiliza DNS para localizac?a?o dos seus servic?os. Essa e? uma diferenc?a importante,\npois a adoc?a?o de Web Services na?o requer a inserc?a?o de novas estruturas ou formatos\npara identificac?a?o de servic?os. Ale?m disso, por ser baseado em DNS, Web Services\npossuem toda uma infra-estrutura de nomeac?a?o legada para serem utilizados sem\nmaiores problemas na Internet (visto que DNS e? um servic?o que funciona efetiva-\nmente nesse meio). O segundo aspecto esta? relacionado a? forma como os servic?os sa?o\nreferenciados. Atrave?s da Tabela 4.1 percebe-se que Web Services seguem o padra?o\nutilizado na Internet, enquanto CORBA emprega um esquema pro?prio. Com relac?a?o\na ativac?a?o e localizac?a?o dos servic?os, Web Services trata esses eventos de forma se-\nparada, enquanto em CORBA esse processo e? realizado em um mesmo instante. O\naspecto de facilidade de uso e? um ponto que os diferencia significantemente. Para\nutilizac?a?o de Web Services na?o e? preciso a instalac?a?o e configurac?a?o de softwares\ncomplexos e grandes. Como ele e? baseado em padro?es da Internet, a sua infra-\nestrutura ja? esta? normalmente instalada na maioria (ou totalidade) das ma?quinas.\nEm contra-partida, para utilizac?a?o de CORBA e? preciso a instalac?a?o de softwares\nespec??ficos e que na?o sa?o disponibilizados de forma padra?o nas ma?quinas. Quanto ao\nquesito eficie?ncia, CORBA possui um desempenho melhor visto que utiliza formatos\nbina?rios, enquanto Web Services empregam XML que e? um formato textual. Atual-\nmente existem iniciativas da criac?a?o de XML bina?rio (W3C-XML BINARY - XML\nBINARY CHARACTERIZATION WORKING GROUP PUBLIC PAGE, 2005), o\nque solucionaria o de?fiti de eficie?ncia que Web Services possui.\n\nConsiderando os aspectos ressaltados pela comparac?a?o direta entre estes mid-\ndlewares, os objetivos que se pretende atingir com o ambiente ICE e a arquitetura\ndesse ambiente, optou-se pela utilizac?a?o de Web Services como infra-estrutura para o\ndesenvolvimento do Middleware de Servic?o. A tecnologia Web Service na?o e? unita?ria,\nela e? formada por tecnologias como por exemplo, SOAP para a construc?a?o das men-\n\n\n\n41\n\nsagens a serem trocadas entre os provedores e os consumidores de servic?os, WSDL\npara a descric?a?o dos servic?os e UDDI para a localizac?a?o dos servic?os. Neste trabalho\nutilizou-se apenas a tecnologia SOAP para a troca de informac?o?es entre as entidades\nenvolvidas.\n\n4.1.2 Ana?lise dos Padro?es e Especificac?o?es\n\nComo apresentado no Cap??tulo 3, uma das filosofias do ambiente ICE e? a uti-\nlizac?a?o de padro?es e especificac?o?es dispon??veis. Na a?rea de gerenciamento e de acesso\na mu?ltiplos clusters na?o existem trabalhos pontuais que busquem um certo grau\nde padronizac?a?o de me?todos, ferramentas, etc. Entretanto, na a?rea de grids exis-\ntem muito esforc?os neste sentido. Alguns exemplos de grupos que trabalham com\neste foco sa?o: GGF (Global Grid Force) (GLOBAL GRID FORUM, 2005), Globus\nAliance (THE GLOBUS ALLIANCE, 2005), OASIS (OASIS - ADVANCING E-\nBUSINESS STANDARDS SINCE 1993, 2005), W3C (W3C WORLD WIDE WEB -\nLEADING THE WEB TO ITS FULL POTENTIAL..., 2005), entre outros. Os dois\nu?ltimos grupos apresentados na?o colaboram diretamente para a?rea de grids, mas os\npadro?es gerados por eles sa?o muitas vezes empregados nesta a?rea.\n\nO gerenciamento e o acesso de mu?ltiplos clusters possui caracter??sticas em co-\nmum com a a?rea de clusters. Ambas te?m que lidar com: mu?ltiplos dom??nios ad-\nministrativos, heterogeneidade de sistemas e ferramentas, localizac?a?o dos recursos,\nseguranc?a no acesso a esses recursos, entre outros. Entretanto, a forma como es-\ntes aspectos sa?o tratados nestes escopos e? diferente. No gerenciamento e acesso a\nmu?ltiplos clusters os usua?rios sabem exatamente que recursos eles esta?o utilizando,\npodem na?o saber onde eles esta?o, mas sabem quem sa?o estes recursos. Em grids\nos usua?rios na?o sabem quem sa?o e nem onde esta?o os recursos que eles solicitaram.\nEssa pequena diferenc?a faz com que, no cena?rio de grids, sejam necessa?rios grandes\nmecanismos de controle para prover esse tipo de transpare?ncia aos seus usua?rios.\nOutra diferenc?a que tambe?m implica em n??veis de controle mais pesados, e? a dina-\nmicidade de um cena?rio de grid. Neste, os recursos sa?o vola?teis, ou seja, as ma?quinas\nque fazem no grid em um determinado momento podem na?o fazer mais parte no\nmomento seguinte, enquanto que em um cena?rio de mu?ltiplos clusters esses recursos\nsa?o esta?ticos. Mesmo com essas diferenc?as estruturais ainda e? poss??vel adaptar as\nide?ias da a?rea de grid para o contexto do ambiente ICE. Ale?m disso, pode-se tentar\nincorporar ferramentas ja? existentes no cena?rio de grid no ambiente ICE. Seguindo\nesta ide?ia analisou-se a possibilidade de utilizac?a?o de mo?dulos do Globus Toolkit\ndentro do ambiente ICE.\n\nO Globus Toolkit (GT) tem sido desenvolvido desde o final dos anos 90 com\no objetivo de dar suporte para o desenvolvimento de aplicac?o?es e infra-estruturas\nde sistemas distribu??dos orientados a servic?o. Alguns componentes ba?sicos do GT\nesta?o relacionados com: seguranc?a, gerenciamento e acesso de recursos, migrac?a?o\ne gerenciamento de dados, descobrimento de recursos, entre outros. Atualmente o\nGT esta? em sua versa?o 4, a qual e? toda baseada em Web services. A Figura 4.1\napresenta os mo?dulos que compo?em o GT4.\n\nSeguindo a ide?ia de aproveitar o que ja? existe na a?rea de alto desempenho para\nser integrado ao ambiente ICE, pensou-se na utilizac?a?o do mo?dulo de alocac?a?o e\ngerenciamento de recursos - GRAM (Grid Resource Allocation and Management).\nEsse mo?dulo do GT4 e? responsa?vel pela submissa?o de processos no grid. Ele faz\no interfaceamento com os escalonadores de aplicac?o?es instalados nos recursos com-\n\n\n\n42\n\nFigura 4.1: Arquitetura do Globus Toolkit v4 - Figura retirada do draft (GLOBUS\nToolkit 4.0 RELEASE MANUALS, 2005)\n\n\n\n43\n\nputacionais. Entretanto analisando o toolkit, percebeu-se que na?o e? poss??vel isolar\neste mo?dulo e integra?-lo no ambiente ICE. Isto na?o e? poss??vel pois para utilizar o\nGRAM e? preciso ter todo o nu?cleo de componentes ba?sicos do GT4. Eles servem,\nde forma geral, para prover a infra-estrutura de controle para gerenciamento das\ninformac?o?es que mante?m o recurso participando do grid. Isto implica na inserc?a?o de\ncomunicac?o?es, protocolos e outras abstrac?o?es que na?o sa?o necessa?rias no contexto\nde clusters. Sendo assim, para evitar essa sobrecarga desnecessa?ria decidiu-se na?o\nintegrar o GRAM no ambiente ICE.\n\nDa mesma forma como ocorre no caso do GRAM, os outros mo?dulos do GT\ntambe?m so? podem ser utilizados caso a infra-estrutura ba?sica do GT esteja presente.\nIsto faz com que a utilizac?a?o do GT para evitar novas implementac?o?es na?o seja apro-\npriado no contexto do ambiente ICE. No entanto, as ide?ias por tra?s deste middleware\npara grid podem ser mapeadas para clusters, como por exemplo o esquema de se-\nguranc?a utilizado no GT, o qual e? baseado no GSI (Grid Security Infrastructure)\n(WELCH; et al., 2003) - atualmente um padra?o do GGF.\n\nOutro exemplo de adaptac?a?o poss??vel e? utilizar os conceitos e especificac?o?es do\nOGSA (Open Grid Service Architecture) (FOSTER; et al., 2002; ABBAS, 2004)\nimplementando-os para o cena?rio de mu?ltiplos clusters. Atrave?s da utilizac?a?o das\nespecificac?o?es, como por exemplo GMA (Grid Monitoring Architecture), e? poss??vel\ndesenvolver um sistema para mu?ltiplos clusters que segue interfaces bem definidas.\nSe no futuro o ambiente ICE for migrado para um contexto de grid, a interface de\nseus servic?os ja? estara? de acordo com os padro?es utilizados.\n\n4.2 Descric?a?o do Proto?tipo Implementado\n\nA partir das deciso?es de projeto tomadas, principalmente da definic?a?o de que\nmiddleware seria usado para o desenvolvimento dos mo?dulos de servic?o, partiu-se\npara a definic?a?o de quais componentes fariam parte do proto?tipo.\n\nO proto?tipo resultante deste trabalho possui a implementac?a?o de uma insta?ncia\ndo Middleware de Servic?os, ou seja, foi disponibilizada uma funcionalidade de clus-\nter, e foi implementado o mo?dulo de gerenciamento do sistema (SMM) no Portal\nWeb. O mo?dulo de seguranc?a (SecM) projetado na arquitetura ICE foi implemen-\ntado no trabalho de Conclusa?o de Curso do aluno Alexandre Ilha (ILHA, 2005).\n\nComo descrito na Sec?a?o 3.2.3, esta?o previstas va?rias funcionalidades dentro do\nambiente ICE. No contexto deste trabalho, foi implementada a funcionalidade de\ngerenciamento de aplicac?o?es (Job Management). No entanto, existem trabalhos de\noutros participantes do GPPD (Grupo de Processamento Paralelo e Distribu??do) de\ndesenvolvimento de outros mo?dulos do Middleware de Servic?os. Exemplos dessas\niniciativas sa?o os servic?os para: monitoramento de aplicac?o?es e de recursos, e para\nconfigurac?o?es administrativas dos clusters. A Figura 4.2 apresenta a estrutura atual\ndo ambiente ICE. Os mo?dulos implementados no escopo deste trabalho sa?o ilus-\ntrados pelas caixas mais escuras, enquanto os desenvolvidos por outras pessoas sa?o\nilustrados pelas caixas mais claras.\n\nAle?m de apresentar os mo?dulos do ambiente ICE implementados, a Figura 4.2\ntambe?m indica os clusters que foram integrados dentro do ambiente ICE: gppd e o\nfrontal-minuano. Como indicado na figura, cada cluster possui um tipo de ferra-\nmenta de gerenciamento. Essas ferramentas sa?o, respectivamente: OpenPBS (Open\nPortable Batch System) (PORTABLE BATCH SYSTEM, 2005) e OAR (CAPIT; et\n\n\n\n44\n\nFigura 4.2: Proto?tipo ICE Implementado\n\nal., 2005). Estes clusters pertencem ao GPPD.\n\n4.2.1 Tecnologias Empregadas\n\nPara implementac?a?o do proto?tipo foram adotadas as tecnologias descritas abaixo,\nem cada um dos componentes da arquitetura.\n\n\u2022 Middleware de Servic?o - Para o desenvolvimento dos Web services optou-se\npela utilizac?a?o da tecnologia Apache Axis (versa?o 2) (APACHE AXIS2, 2005).\nEssa escolha tambe?m levou a? utilizac?a?o do container Tomcat (versa?o 5.0.30)\n(APACHE TOMCAT - THE APACHE SOFTWARE FOUNDATION, 2006)\ne do Java (j2sdk-1.4.2) (JAVA PLATFORM, STANDARD EDITION , JAVA\nSE). Estas u?ltimas tecnologias foram empregadas pois sa?o pre?-requisitos para\nutilizac?a?o do Axis2. E? importante ressaltar que o desenvolvimento do Mid-\ndleware de Servic?o poderia ter utilizado qualquer outra tecnologia, uma vez\nque Web services sa?o independente de plataforma e linguagem.\n\n\u2022 Portal Web - Esse componente possui tre?s pontos distintos: apresentac?a?o das\ninformac?o?es atrave?s de pa?ginas Web, controle e separac?a?o da lo?gica do sistema\ne o papel de consumidor de servic?os. A apresentac?a?o foi implementada atrave?s\nda tecnologia JSP (Java Server Pages) (JAVASERVER PAGES TECHNO-\nLOGY, 2006). A lo?gica do sistema esta? separada das pa?ginas Web devido\na utilizac?a?o de Java Servlets (JAVA SERVLET TECHNOLOGY, 2006). As\npa?ginas JSP na?o lidam diretamente com a intelige?ncia do sistema, elas fazem\nrequisic?o?es para Servlets, os quais interagem com os recursos e servic?os ne-\n\n\n\n45\n\ncessa?rios. E para finalizar, os consumidores dos mo?dulos de servic?o (SM) sa?o\nimplementados utilizando Apache Axis (versa?o 2) e tambe?m na?o sa?o acessados\ndiretamente pelas pa?ginas JSP. Este acesso tambe?m e? feito atrave?s de Ser-\nvlets. Para o armazenamento das informac?o?es foi utilizado o SGBD (Sistema\nde Gerenciamento de Base de dados) PostgreSQL versa?o 8.1 (POSTGRESQL\nGLOBAL DEVELOPMENT GROUP, 2006).\n\nA seguir, a implementac?a?o de cada componente da arquitetura ICE e? descrita em\ndetalhes. Sa?o apresentadas as caracter??sticas de cada mo?dulo, suas funcionalidades\ne especificidades, assim como as interac?o?es entre esses mo?dulos. Inicialmente sera?\ndescrito o Middleware de Servic?o implementado para funcionalidade de gerencia-\nmento de aplicac?o?es Job Management e em seguida sera? detalhada a implementac?a?o\ndo Portal Web.\n\n4.2.2 Middleware de Servic?o para Gerenciamento de Aplicac?o?es\n\nNeste trabalho o Middleware de Servic?os foi instanciado para que fosse poss??vel a\ndisponibilizac?a?o da funcionalidade de gerenciamento de aplicac?o?es junto ao ambiente\nICE. Primeiramente sera? descrita a USI definida para o gerenciamento de aplicac?o?es\n(Job Management Unified Service Interface - JM-USI), em seguida sera?o apresen-\ntados os provedores de servic?os desenvolvidos para essa interface (Job Management\nService Implementation - JM-SI). Finalmente sera?o descritas as func?o?es referentes\nao consumidor dos servic?os desta funcionalidade (Job Management Service Module\n- JM-SM).\n\n4.2.2.1 JM-USI - Job Management Unified Service Interface\n\nA USI para o gerenciamento de aplicac?o?es foi definida considerando alguns\npara?metros tipicamente utilizados pelos usua?rios de clusters. Para se chegar nestes\npara?metros buscou-se suportar os para?metros utilizados pelo GRAM do GT4 (GLO-\nBUS Toolkit 4.0 RELEASE MANUALS, 2005; GT 4.0 WS GRAM, 2005). De certa\nforma, pode-se dizer que a API disponibilizada pelo GRAM tenta prover as princi-\npais operac?o?es e para?metros existentes nos escalonadores de aplicac?o?es. Alguns dos\nprincipais para?metros utilizados no GRAM foram incorporados na funcionalidade\nde gerenciamento de aplicac?o?es do ambiente ICE.\n\nPara finalizar a ana?lise das possibilidades de operac?o?es e para?metros que podem\nser disponibilizados em uma interface uniformizada, foram estudadas as ferramentas\nde escalonamento: OpenPBS, SGE, CCS e OAR. Essas ferramentas foram escolhidas\npois esta?o dispon??veis nos clusters do GPPD e de instituic?o?es de pesquisas parceiras\ndo grupo. Desta forma, essa infra-estrutura poderia ser utilizada no momento da\navaliac?a?o do proto?tipo que foi desenvolvido. Atrave?s da ana?lise dessas ferramentas,\nfoi poss??vel ter uma noc?a?o melhor das facilidades que elas ofereciam e poder ter\num maior conhecimento acerca do que poderia ser disponibilizado aos usua?rios do\nambiente ICE que utilizam a funcionalidade de gerenciamento de aplciac?o?es.\n\nSendo assim a definic?a?o da USI para esta funcionalidade foi baseada nas ca-\nracter??sticas disponibilizadas pelo toolkit de grid mais utilizado - o Globus Toolkit\n- e nas potencialidades oferecidas pelos escalonadores estudados. Como resultado\nte?m-se a JM-USI denominada JobManagementProviderInterface. A Tabela 4.2\ndescreve as operac?o?es que fazem parte desta USI.\n\nUma questa?o que passa por todas as operac?o?es da JM-USI e? a seguranc?a. Na?o\n\n\n\n46\n\nTabela 4.2: Operac?o?es da JM-USI\nOperac?a?o Descric?a?o/Func?a?o\n\njobSubmissionOperation Submissa?o de aplicac?o?es\njobFinalizationOperation Finalizac?a?o de aplicac?o?es\njobStatusVerificationOperation Verificac?a?o do estado das\n\naplicac?o?es, o que pode\ncorresponder a: finalizada,\nem execuc?a?o, em espera,\nou enta?o ainda na fila para\nser submetida\n\njobOutputRetrievalOperation Recuperac?a?o da sa??da de uma\naplicac?a?o (padra?o ou de erros)\n\nsubmissionScriptVerificationOperation Apresentac?a?o do script de\nsubmissa?o da aplicac?a?o de\nacordo com o escalonador\ndo cluster em uso\n\ne? poss??vel permitir que usua?rios na?o autenticados e na?o autorizados utilizem as\noperac?o?es dos servic?os disponibilizados nos front-ends dos clusters. De forma resu-\nmida pode-se descrever como medidas de seguranc?a do ambiente ICE a utilizac?a?o\nde HTTPS para as comunicac?o?es; o emprego de mecanismo de mapeamento entre\nas identidades dos usua?rios, os quais podem assumir uma identidade no ambiente\nICE e diferentes identidades nos clusters aos quais possuem acesso; e mecanismos\nde autenticac?a?o mu?tua entre o Portal ICE e o front-end que esta? sendo acessado.\nA construc?a?o do mo?dulo de seguranc?a segue a definic?a?o do Middleware de Servic?os,\nisto e?, foram definidos os elementos: USI, SI e SM.\n\nEstas questo?es de seguranc?a interferem na definic?a?o dos para?metros das operac?o?es\nde qualquer servic?o que for criado para ser integrado ao ambiente ICE. Desta forma,\nindependentemente da funcionalidade que se esta? inserindo no ambiente, e? preciso\nque todas as suas operac?o?es possuam a identificac?a?o do usua?rio que a esta? solici-\ntando. Todo o processo de autenticac?a?o e autorizac?a?o e? realizado pelo servic?o de\nseguranc?a definido e desenvolvido para o ambiente ICE. Essa caracter??stica mostra\na modularidade que este ambiente possui.\n\nA seguir os para?metros de cada uma das operac?o?es da JM-USI sa?o descritos nas\ntabelas abaixo.\n\n\u2022 jobSubmissionOperation()\n\nPara?metros de entrada\n\n\n\n47\n\nusername: Conte?m a identificac?a?o do usua?rio. Esta? rela-\ncionado com o sistema de seguranc?a de cada\ncluster, mas na interface do servic?o JM-USI\neste fator e? transparente.\n\nbasedir: Informa o direto?rio a partir de onde as\naplicac?o?es e os arquivos do usua?rio sera?o en-\ncontrados durante o processo de submissa?o\nda aplicac?a?o.\n\nparam: Possui os para?metros que devem ser passados\npara a aplicac?a?o.\n\nmain appname: Representa o nome da aplicac?a?o que deve ser\nexecutada.\n\nnumnodes: Indica o nu?mero total de no?s que devem ser\nreservados.\n\nnumproc: Possui o nu?mero de processos que devem ser\nlanc?ados. Esse para?metro deve ser utilizado\nno lanc?amento de aplicac?o?es paralelas.\n\nqueue: Indica a fila onde a aplicac?a?o deve ser\nlanc?ada. De acordo com o tipo de escalo-\nnador pode assumir outra sema?ntica que na?o\na de fila, mas continuara? indicando o local a\npartir de onde a aplicac?a?o sera? lanc?ada.\n\nwalltime: Representa o tempo da reserva dos no?s.\njoinout: Especifica se a sa??da padra?o e a de erro devem\n\nser colocadas em um u?nico arquivo.\noutfile: Conte?m o nome do arquivo para onde sera?\n\nredirecionada a sa??da padra?o.\nerrfile: Possui o nome do arquivo para onde sera? re-\n\ndirecionada a sa??da de erro padra?o.\n\n\n\n48\n\njobtype: Especifica que tipo de aplicac?a?o sera? subme-\ntida. Elas podem ser sequ?enciais ou para-\nlelas. No caso das aplicac?o?es paralelas elas\nainda sa?o identificadas de acordo com o tipo\nde biblioteca paralela utilizada.\n\nnumbatchiteration: E? poss??vel configurar a execuc?a?o da mesma\naplicac?a?o um determinado nu?mero de vezes.\nIsto e?, existe a possibilidade de disparar uma\naplicac?a?o para ser executada como um pool\nde execuc?o?es. O nu?mero de vezes que a\naplicac?a?o sera? executada e? designado por este\npara?metro.\n\nmultiplescripts: Serve como complemento do para?metro ante-\nrior. Indica se as va?rias execuc?o?es da mesma\naplicac?a?o devem ser lanc?adas como jobs in-\ndependentes para o escalonador ou na?o. Isto\ne?, deve-se escolher entre gerar tantos scripts\nquantas foram as iterac?o?es, ou enta?o se deve\nser gerado apenas um script, e as repetic?o?es\nda execuc?a?o da mesma aplicac?a?o devem ser\ngerenciadas dentro desse script u?nico. E?\nimportante ressaltar que essa definic?a?o tem\nimpacto direto sob o para?metro relativo ao\ntempo da reserva que esta? sendo solicitada\npara a aplicac?a?o (walltime). Em caso de\ngerac?a?o de apenas um u?nico script, e? preciso\nque o tempo da reserva leve em considerac?a?o\no tempo necessa?rio para o te?rmino de todas\nas iterac?o?es.\n\nPara?metros de sa??da\n\njobid: Conte?m a identificac?a?o da aplicac?a?o que foi sub-\nmetida.\n\nerrorcode: Campo destinado a conter o valor de qualquer tipo\nde erro que ocorra durante o processamento e a\nmontagem do script de submissa?o da aplicac?a?o,\nassim como qualquer tipo de erro ocorrido no mo-\nmento da submissa?o da aplicac?a?o atrave?s do esca-\nlonador utilizado no cluster.\n\n\u2022 finalizeJobOperation()\n\nPara?metros de entrada\n\nusername: Ide?ntico ao para?metro da operac?a?o de submissa?o.\njobid: Identificac?a?o da aplicac?a?o que deve ser finalizada.\n\n\n\n49\n\nPara?metros de sa??da\n\nfin output: Possui a sa??da, em modo texto, da ordem de fina-\nlizac?a?o da aplicac?a?o\n\nerrorcode: Campo destinado a conter o valor de qualquer tipo\nde erro que ocorra durante a ac?a?o de finalizac?a?o\nda aplicac?a?o atrave?s do escalonador utilizado no\ncluster.\n\n\u2022 verifyJobStatusOperation()\n\nPara?metros de entrada\n\nusername: Ide?ntico ao para?metro da operac?a?o de submissa?o.\n\nPara?metros de sa??da\n\nstatus: Conte?m o estado em que as aplicac?o?es se encon-\ntram.\n\nerrorcode: Campo destinado a conter o valor de qualquer tipo\nde erro que ocorra durante a ac?a?o de verificac?a?o do\nestado da aplicac?a?o.\n\n\u2022 jobOutputRetrievalOperation()\n\nPara?metros de entrada\n\nusername: Ide?ntico ao para?metro da operac?a?o de submissa?o.\nbasedir: Informa o direto?rio a partir de onde os arquivos\n\nreferentes ao job solicitado esta?o armazenados.\nfile: Indica no nome do arquivo que deve ser recupe-\n\nrado.\n\nPara?metros de sa??da\n\narchive: Conte?m os dados do arquivo solicitado.\nerrorcode: Campo destinado a conter o valor de qualquer tipo\n\nde erro que ocorra durante a ac?a?o de recuperac?a?o\ndos dados do arquivo solicitado.\n\n\u2022 verifySubmissionScriptOperation()\n\nPara?metros de entrada - Possui exatamente os mesmo para?metros de entrada que\na operac?a?o de submissa?o.\n\n\n\n50\n\nPara?metros de sa??da\n\nscript: Conte?m os dados que formam o script de sub-\nmissa?o de uma aplicac?a?o, de acordo com o esca-\nlonador em uso no cluster.\n\nerrorcode: Campo destinado a conter o valor de qualquer tipo\nde erro que ocorra durante a gerac?a?o do script de\nsubmissa?o.\n\nAnalisando rapidamente a definic?a?o da JM-USI pode-se pensar em iguala?-la ao\nWSDL do servic?o de gerenciamento de aplicac?o?es. Entretanto esta equiparac?a?o na?o\npode ser feita. Pela definic?a?o da arquitetura ICE, uma USI e? a definic?a?o de uma\nfuncionalidade, ou seja, de um servic?o, a qual possui as operac?o?es e os para?metros\ndo mesmo. WSLD e? a linguagem de descric?a?o de um Web Service, a qual possui\nsua sintaxe baseada em XML e tags espec??ficas que informam, por exemplo, a forma\ncomo sera? realizada a comunicac?a?o (one-way ou em estilo RPC) e ainda o enderec?o\ndo provedor do servic?o. Essas duas caracter??sticas do WSDL sa?o os pontos que o\ndiferem completamente de uma USI. Outro ponto que os distingue e? o fato da JM-\nUSI na?o estar atrelada a? tecnologia de Web Services, ela pode ser mapeada para\nqualquer tecnologia que possua caracter??sticas de arquiteturas SOA.\n\nAtrave?s das operac?o?es apresentadas acima e de seus para?metros e? poss??vel re-\nalizar todas as ac?o?es ba?sicas de gerenciamento de aplicac?o?es. A JM-USI definida\ndisponibiliza aos seus usua?rios facilidades para lanc?amento de aplicac?o?es. Exemplos\ndessas facilidades sa?o o lanc?amento de mu?ltiplas execuc?o?es da mesma aplicac?a?o e o\nupload de arquivos.\n\nE? importante ressaltar que podem ocorrer casos em que as operac?o?es e os pa-\nra?metros definidos na JM-USI na?o possam ser diretamente mapeados para as ca-\nracter??sticas dos escalonadores e gerenciadores utilizados nos clusters. Esse tipo\nde situac?a?o deve ser tratada pelas implementac?o?es espec??ficas da JM-USI, ou seja,\ndevem ser tratadas em cada implementac?a?o do mo?dulo JM-SI.\n\n4.2.2.2 JM-SI - Job Management Service Implementation\n\nNeste ponto sera?o detalhadas as implementac?o?es do servic?o de gerenciamento de\naplicac?o?es (JM-SI) para os escalonadores OpenPBS e OAR. Ale?m disso sera? apre-\nsentado o framework definido para dar suporte no desenvolvimento dos diferentes\nJM-SIs. Esse framework garante a caracter??stica de extensibilidade, que podera? ser\ncomprovada durante a descric?a?o das implementac?o?es espec??ficas.\n\nO Job Management Framework (JMF), nome atribu??do ao framework de-\nfinido, pode ser visualizado na Figura 4.3. Essa figura ilustra o diagrama de classes,\nbaseado na modelagem UML (UML - UNIFIED MODELING LANGUAGE, 2006),\nque formam a estrutura ba?sica da implementac?a?o do servic?o de gerenciamento de\naplicac?o?es.\n\nComo pode-se perceber na Figura 4.3 existem classes e pacotes ja? definidos, que\nservem como base para as implementac?o?es futuras e existem as classes que devem\nser implementadas. Para tanto e? necessa?rio que se utilize os mecanismos de heranc?a\npresentes no modelo de programac?a?o Orientado a Objetos. A seguir cada pacote e\nclasse do JMF sera?o descritas e contextualizadas.\n\n\n\n51\n\nJobManagementSI\n\nJobManagementProviderSI\n\nICESecurity\n\nJobManagementProviderInterface\n\n+jobSubmissionOperation()\n\n+finalizeJobOperation()\n\n+verifyJobStatusOperation()\n\n+jobOutputRetrievalOperation()\n\n+verifySubmissionScriptOperation()\n\nJob\n\n+generateSubmissionScript()\n\n+launchSubmissionScript()\n\nJobManagementProviderToBeImplemented\n\nJobToBeImplemented\n\nUserAuthentication\n\n+confirmAuthentication()\n\n+setUserInformation()\n\nUserAutheticationToBeImplemented\n\nJobManagementProvider\n\n+user: UserAuthetication\n\n+job: Job\n\n+jobSubmissionOperation()\n\n+finalizeJobOperation()\n\n+verifyJobStatusOperation()\n\n+jobOutputRetrievalOperation()\n\n+verifySubmissionScriptOperation()\n\nFigura 4.3: JMF - Job Management Framework\n\nAntes de permitir que qualquer usua?rio tenha acesso para utilizar os recursos\ndo servic?o, e? preciso garantir requisitos de seguranc?a, como por exemplo, a auten-\nticac?a?o do usua?rio que esta? solicitando o servic?o. Este procedimento de verificac?a?o\nde identidade do usua?rio na?o esta? restrito apenas ao servic?o de gerenciamento de\naplicac?o?es. Na verdade ele deve ser acionado sempre que um servic?o for solici-\ntado. No intuito de garantir que somente usua?rios autenticados estara?o utilizando\nos servic?os do ambiente ICE foi definido o pacote ICESecurity. Esse pacote e? for-\nmado pela classe abstrata UserAuthentication, que possui os me?todos abstratos\nsetUserInformation() e confirmAuthentication(). Optou-se por definir essa\nclasse e seus me?todos como abstratos para que fosse poss??vel extende?-la e imple-\nmentar seus me?todos de acordo com o sistema de autenticac?a?o de cada cluster.\nPor exemplo, alguns clusters autenticam seus usua?rios atrave?s de mecanismos de\nlogin dos sistemas UNIX, enquanto isso, existem outros que utilizam LDAP para\nautenticar seus usua?rios.\n\nA definic?a?o de classes extens??veis e? fundamental, uma vez que o objetivo desse\nframework e? prover uma estrutura organizacional m??nima para que os desenvolvedo-\nres dos servic?os sejam capaz de estende?-lo e adapta?-lo a?s suas necessidades. Sendo\nassim, a classe UserAutheticationToBeImplemented, apresentada na Figura 4.3,\nrepresenta justamente a classe que contera? a implementac?a?o do sistema de auten-\nticac?a?o de um cluster espec??fico.\n\nO pacote JobManagementSI (na Figura 4.3) tem a func?a?o de encapsular os pa-\ncotes e classes referentes a? implementac?a?o do JM-SI. Dentro dele existe o pacote\nJobManagementProviderSI, o qual possui os elementos ba?sicos de um JM-SI. Ele e?\nformado pela interface JobManagementProviderInterface, e pelas classes abstra-\ntas Job e JobManagementProvider. A interface possui a assinatura das operac?o?es\ndo servic?o de gerenciamento de aplicac?o?es, detalhadas na sec?a?o 4.2.2.1.\n\nA classe abstrata Job possui os atributos e os me?todos que devem ser utilizados\n\n\n\n52\n\nsobre as informac?o?es que caracterizam uma aplicac?a?o. Essa classe sera? utilizada\npelas operac?o?es de submissa?o de aplicac?o?es e de verificac?a?o do script de submissa?o\ngerado pelo JM-SI de um cluster espec??fico. Por questo?es de simplificac?a?o os atri-\nbutos que qualificam esta classe na?o sa?o apresentados na Figura 4.3. Os me?todos,\ntambe?m abstratos, generateSubmissionScript() e launchSubmissionScript()\ndevem ser implementados de acordo com o tipo de ferramenta de escalonamento\nde aplicac?o?es instalada em cada cluster. A classe JobToBeImlemented, que na?o\nfaz parte do pacote JobManagementProviderSI, devera? estender e implementar es-\nses me?todos. A classe abstrata JobManagementProvider esta? associada a?s classes\nUserAuthentication e Job, atrave?s dos respectivos atributos: user e job. Estas\nassociac?o?es sa?o importantes pois atrave?s delas e? poss??vel autenticar o usua?rio e aces-\nsar as informac?o?es de aplicac?a?o de forma transparente e extens??vel. Ale?m destes\natributos esta classe possui os me?todos abstratos correspondentes a interface que ele\nesta? estendendo. A implementac?a?o das operac?o?es do servic?o deve ser feita na classe\nque sera? capaz de lidar com especificidades de cada ferramenta de escalonamento\nde aplicac?o?es. Nesse caso a classe JobManagementProviderToBeImplemented, como\nindicado na Figura 4.3.\n\nVisando o reuso de co?digo definiu-se o pacote JobManagementUtil, ilustrado na\nFigura 4.4, o qual e? formado pela classe JobManagementAuxiliaryTools e pelas in-\nterfaces JobManagementErrorCode e JobManagementConstants. A primeira possui\nos co?digos de erros definidos para a funcionalidade de gerenciamento de aplicac?o?es do\nambiente ICE. A segunda interface possui as constantes necessa?rias para o desenvol-\nvimento dos provedores de Web Services. A classe JobManagementAuxiliaryTools\npossui me?todos que foram desenvolvidos para ajudarem na construc?a?o das imple-\nmentac?o?es espec??ficas da JM-USI. Vale ressaltar que esse pacote na?o e? utilizado\napenas nos JM-SIs, mas tambe?m e? empregado no desenvolvimento do JM-SM.\n\nFigura 4.4: Diagrama de classes para o pacote de classes auxiliares\n\nTendo como base o JMF e o pacote com ferramentas auxiliares passou-se para\no segundo passo do desenvolvimento do JM-SI: as implementac?o?es para cada ferra-\nmenta de gerenciamento de aplicac?o?es. A Figura 4.5 apresenta o diagrama de classes\n\n\n\n53\n\ndas implementac?o?es do JM-SI para as ferramentas OpenPBS e OAR.\n\nPor uma questa?o de organizac?a?o decidiu-se criar um pacote para cada imple-\nmentac?a?o dentro do pacote JobManagementSI. A Figura 4.5 apresenta os pacotes\nOpenPBSProviderSI e OARProviderSI. Dado o fato dos escalonadores OpenPBS\ne OAR possuirem fortes similaridades, as implementac?o?es de seus provedores de\nservic?os tornaram-se bastante semelhantes. Em virtude disso, sera? descrita a im-\nplementac?a?o do OpenPBS JM-SI, a qual e? equivalente a implementac?a?o do OAR\nJM-SI. Os pontos que as diferem sera?o ressaltados quando necessa?rio.\n\nPode-se observar na Figura 4.5 que as implementac?o?es seguem o JMF definido,\nestendendo as classes necessa?rias e adicionando outras. As classes necessa?rias sa?o:\nOpenPBSJobManagementProvider e OpenPBSJob. Na primeira classe sa?o efetiva-\nmente implementados os provedores dos Web Services. Eles ira?o receber as men-\nsagens atrave?s do container Tomcat processa?-las, executando a operac?a?o solicitada\n(nesse caso executanto a chamada do me?todo que implementa a operac?a?o) e construir\na mensagem SOAP de resposta a? solicitac?a?o. As comunicac?o?es entre os consumido-\nres do JM-SM (localizados junto ao Portal Web) e os provedores dos servic?os nos\nfront-ends e? realizada utilizando o estilo SOAP-RPC, o qual e? caracterizado por\nempregar mensagens s??ncronas. Na segunda classe necessa?ria sa?o implementados os\nme?todos utilizados para o processamento das operac?o?es de submissa?o de aplicac?o?es\ne visualizac?a?o dos scripts de submissa?o. As demais operac?o?es definidas no JM-USI\nna?o demandaram a criac?a?o de classes extras, visto que elas apresentam um com-\nplexidade bem inferior as duas citadas anteriormente. Na Figura 4.5 tambe?m esta?\nindicado a utilizac?a?o dos pacotes ICESecurity e JobManagementUtil que colaboram\nna modularizac?a?o e simplicidade do ambiente ICE.\n\nA seguir sera?o detalhadas as operac?o?es e sera?o descritas as estruturas de classes\ndefinidas para as implementac?o?es das operac?o?es mais complexas.\n\nOperac?a?o de Submissa?o de Aplicac?o?es\n\nAtrave?s da ana?lise da Figura 4.5 percebe-se que as classes OpenPBSJob e OARJob\npossuem, ale?m dos me?todos herdados da classe Job, me?todos que geram as in-\nformac?o?es comuns a todos os tipos de aplicac?o?es a serem lanc?adas. Por exemplo, o\nme?todo definePartialAppCall() e? utilizado em ambas implementac?o?es espec??ficas\npara montar a chamada da aplicac?a?o com seus para?metros (caso sejam especifica-\ndos). Entretanto, existem alguns detalhes na montagem do script de submissa?o\nque devem considerar qual o tipo de aplicac?a?o que sera? lanc?ada. Nesse caso foram\ndefinidas classes mais espec??ficas para aplicac?o?es: sequ?enciais e paralelas, sendo que\nesta? u?ltima dependera? do tipo de biblioteca ou linguagem paralela que sera? em-\npregada. No ambiente ICE existe suporte para lanc?amento de aplicac?o?es paralelas\nbaseadas em duas bibliotecas: MPI (DONGARRA; et al., 1995) (implementac?a?o\nMPICH) e DECK (BARRETO et al., 2000). Desta forma foram definidas as classes\nOpenPBSSeqJob, OpenPBSMPICHParallelJob e OpenPBSDECKParallelJob, as quais\nestendem a classe OpenPBSJob. Como apresentado na Figura 4.5 essas classes pos-\nsuem os me?todos necessa?rios para gerac?a?o das especificidades de lanc?amento de\ncada tipo de aplicac?a?o. Nessa figura tambe?m percebe-se que esta mesma estrutura\nde classes e? aplicada no caso do gerenciador OAR.\n\nA Figura 4.6 ilustra o XML contendo a requisic?a?o que chega no provedor de\n\n\n\n5\n4\n\nFigura 4.5: Diagrama de classes para as implementac?o?es do OpenPBS-SI e OAR-SI\n\n\n\n55\n\nservic?os do JM-SI. As informac?o?es existentes nessa requisic?a?o sa?o as mesmas tanto\npara a operac?a?o de submissa?o quanto para a de visualizac?a?o dos scripts. A diferenc?a\ne? que no caso da primeira operac?a?o os dois me?todos generateSubmissionScript()\ne launchSubmissionScript() sa?o invocados, enquanto que na outra operac?a?o so? o\nprimeiro e? chamado. A utilizac?a?o desses me?todos aciona os outros me?todos apre-\nsentados na Figura 4.5.\n\nFigura 4.6: Elementos XML da requisic?a?o das operac?o?es de submissa?o e visualizac?a?o\nde scripts\n\nPara que os consumidores do mo?dulo JM-SM possam compreender o retorno\ndessas operac?o?es, foram definidos alguns elementos XML que padronizam a forma\nde lidar com as informac?o?es de retorno dos servic?os. A seguir sera?o apresentados os\nelementos XML e exemplos de sua aplicac?a?o.\n\nA Figura 4.7 possui o retorno da submissa?o de uma aplicac?a?o no escalonador\nOpenPBS, Figura 4.7 (a); e no OAR, Figura 4.7 (b). Nesse exemplo pode-se perceber\nque a aplicac?a?o conseguiu ser submetida aos gerenciadores com sucesso, visto que a\ninformac?a?o retornada e? a identificac?a?o do job submetido.\n\nFigura 4.7: Exemplo de retorno da operac?a?o de submissa?o. (a) Submissa?o com\nOpenPBS (b) Submissa?o com OAR\n\nJa? a Figura 4.8 apresenta o retorno de um erro identificado antes do processo de\nsubmissa?o a? ferramenta de gerenciamento de aplicac?o?es do cluster. Neste exemplo,\no usua?rio na?o esta? devidamente autenticado para utilizar os recursos do cluster em\nquesta?o.\n\n\n\n56\n\nFigura 4.8: Exemplo de retorno da operac?a?o de submissa?o contendo erro.\n\nEssa mesma estrutura de retorno de erro e? empregada nas demais operac?o?es,\nsendo que o que pode variar e? o tipo de erro que esta? sendo reportado.\n\nOperac?a?o Visualizac?a?o dos Scripts de Submissa?o\n\nComo apresentado anteriormente, as diferenc?as em termos de diagrama de clas-\nses e o funcionamento das operac?o?es de submissa?o e visualizac?a?o sa?o pequenas. Mas\nexistem diferenc?as em relac?a?o aos elementos XML de retorno. A seguir sera?o deta-\nlhados os elementos XML para a operac?a?o de visualizac?a?o dos scripts de submissa?o.\n\nNa Figura 4.9 sa?o ilustrados os elementos ba?sicos de retorno: script, content.\nComo a JM-USI permite que mais de um script seja montado para a mesma aplicac?a?o,\na operac?a?o de visualizac?a?o tem suporte para retornar as informac?o?es de mais de um\nscript, facilitando a identificac?a?o dessa multiplicidade no JM-SM.\n\nFigura 4.9: Elementos XML de retorno da operac?a?o de visualizac?a?o de scripts.\n\nO elemento script delimita as informac?o?es dos eventuais diferentes componentes\nda mensagem de retorno, enquanto o elemento name indica o nome do script que\ndeveria ser submetido e o content representa cada linha do script.\n\nAbaixo sa?o apresentados alguns exemplos de poss??veis mensagens de retorno\ndessa operac?a?o. A Figura 4.10 e? um exemplo da visualizac?a?o de um script de\nsubmissa?o de uma aplicac?a?o MPI que deve ser lanc?ada em 2 scripts diferentes.\nNesse exemplo, a operac?a?o de visualizac?a?o foi requisitada no cluster que possui\ncomo gerenciador de aplicac?o?es o OpenPBS.\n\nA Figura 4.11 possui a visualizac?a?o de um script gerado no cluster que opera\ncom o gerenciador OAR. Nesse exemplo, simula-se o lanc?amento de uma aplicac?a?o\nDECK que devera? ser executada 5 vezes mas apenas um script devera? ser gerado.\n\nComparando os dois exemplos e? poss??vel verificar que os dois escalonadores apre-\nsentam caracter??sticas bastante semelhantes. Dessa forma, tanto na operac?a?o de\nsubmissa?o quanto na de visualizac?a?o de scripts na?o foram necessa?rias grandes mu-\ndanc?as na estrutura de desenvolvimento. As diferenc?as se concentraram na forma\n\n\n\n57\n\nFigura 4.10: Exemplo de retorno da operac?a?o de visualizac?a?o em um cluster com\nOpenPBS.\n\nFigura 4.11: Exemplo de retorno da operac?a?o de visualizac?a?o em um cluster com\nOAR.\n\ncomo as aplicac?o?es sa?o lanc?adas (no caso da submissa?o) e nos para?metros que for-\nmam o script de submissa?o, como mostraram os exemplos apresentados acima.\n\nAnalisando a Figura 4.5 e? poss??vel perceber que na?o existem classes e pacotes\nespec??ficos para o desenvolvimento das operac?o?es de finalizac?a?o de aplicac?o?es, veri-\nficac?a?o do estado e recuperac?a?o dos arquivos das sa??das padra?o. Essa caracter??stica\nocorre visto que a aquisic?a?o e as interac?o?es com os gerenciadores de aplicac?o?es sa?o\nsimples. Para essas operac?o?es na?o e? necessa?rio a criac?a?o de scripts, basta receber\nprocessar o conteu?do dos para?metros recebidos pelo provedor e gerar os comandos\nque interagem com as ferramentas de gerenciamento de aplicac?o?es. A seguir sera?o\napresentados os elementos XML das mensagens de requisic?a?o e resposta de cada\numa das operac?o?es ainda na?o descritas.\n\n\n\n58\n\nOperac?a?o de Finalizac?a?o\n\nBaseado nas definic?o?es da JM-USI, a Figura 4.12 (a) apresenta os elementos XML\nque formam a mensagem de requisic?a?o de te?rmino de uma aplicac?a?o submetida.\nAtrave?s da utilizac?a?o do elemento jobid uma aplicac?a?o e? finalizada.\n\nFigura 4.12: Elementos XML de requisic?a?o e retorno da operac?a?o de finalizac?a?o.\n\nNa implementac?a?o dessa operac?a?o, o comando de finalizac?a?o do gerenciador do\ncluster e? chamado e o elemento jobid e? passado como para?metro. Caso algum\nerro seja detectado antes do comando ser chamado enta?o o provedor retornara? a\nmensagem de erro ja? descrita anteriormente. Caso contra?rio ele informara? o sucesso\nda finalizac?a?o, como ilustrado na Figura 4.12 (b), ou podera? retornar a mensagem\nde erro passada pelo gerenciador do cluster, como apresentado na Figura 4.12 (c).\n\nOperac?a?o de Verificac?a?o de Status\n\nA mensagem de requisic?a?o dessa operac?a?o conte?m somente a identificac?a?o do\nusua?rio. Como apresentado na USI, outros para?metros na?o sa?o necessa?rios. A\nFigura 4.13 apresenta um exemplo de uma mensagem de retorno contendo o estado\nde uma aplicac?a?o submetida em um cluster que utiliza OAR.\n\nEsta informac?a?o, quando recebida pelo JM-SM, devera? ser tratada para ser apre-\nsentada aos usua?rios de uma forma mais fa?cil e clara.\n\nOperac?a?o de Recuperac?a?o das Sa??das\n\nEsta operac?a?o e? utilizada tanto para recuperar o conteu?do dos arquivos com a\nsa??da padra?o como a sa??da padra?o de erro. Atrave?s dos elementos basedir e file,\nilustrados na Figura 4.14 (a), pode-se definir qual devera? ser o arquivo recuperado.\nNa Figura 4.14 (b) te?m-se o retorno de um erro ocorrido no momento da recu-\nperac?a?o do arquivo solicitado. A Figura 4.14 (c) apresenta um exemplo de retorno\nde mensagem com o conteu?do da sa??da padra?o de uma aplicac?a?o.\n\nNesse caso de recuperac?a?o de arquivos sempre sera?o recuperadas informac?o?es em\nmodo texto. Por isso na?o sa?o necessa?rios cuidados especiais com relac?a?o a formac?a?o\n\n\n\n59\n\nFigura 4.13: Exemplo de retorno da operac?a?o de verificac?a?o de estado das filas do\ngerenciador OAR.\n\nda mensagem de retorno.\n\nResumindo a implementac?a?o dos JM-SIs pode-se dizer que os dois tipos de es-\ncalonadores sa?o bastante semelhantes. Esta caracter??stica facilitou o processo de\ndesenvolvimento dos JM-SIs uma vez que na?o foi necessa?rio a criac?a?o de mecanismo\ncomplexos de mapeamento entre a JM-USI e os JM-SIs. Dentre as operac?o?es de\ngerenciamento de aplicac?o?es disponibilizadas no ambiente ICE, a submissa?o foi a\nque demandou mecanismos mais complexos e extensos de implementac?a?o.\n\n4.2.2.3 Job Management Service Module\n\nComo descrito no Cap??tulo 3 o componente Service Module possui uma parte\nde sua implementac?a?o no Middleware de Servic?os e outra parte no Portal Web.\nNeste ponto sera?o apresentadas as caracter??sticas de implementac?a?o do componente\nJM-SM referente aos consumidores de Web Services.\n\nAssim como os provedores de servic?os, os consumidores foram desenvolvidos\nutilizando a tecnologia Apache Axis 2. Entretanto, tambe?m foi necessa?rio utilizar\nServlets java para repassar o resultado dos provedores de servic?os para os mo?dulos\ndo JM-SM dentro do Portal Web. A Figura 4.15 ilustra o diagrama de classes\ndefinido para organizar as classes e me?todos empregados no desenvolvimentos dos\nconsumidores.\n\nNo intuito de organizar a implementac?a?o, foi definido o pacote JobManagementSM.\nComo pode ser visto na Figura 4.15, as classes dentro desse pacote utilizam os\nrecursos ja? definidos no pacote JobManagementUtil. Dentro do pacote que organiza\no JM-SM foi definido o pacote JobManagementSMConsumer. Ele foi criado com o\nintuito de separar toda e qualquer implementac?a?o relacionada a tecnologia Web\nService do restante da lo?gica do JM-SM. Com essa filosofia pode-se simplesmente\nmudar o tipo de tecnologia empregado na comunicac?a?o e preservar o restante do\nfuncionamento do JM-SM.\n\nO pacote JobManagementSMConsumer e? formado pelas classes que lidam com os\n\n\n\n60\n\nFigura 4.14: Elementos XML da requisic?a?o e resposta da operac?a?o de recuperac?a?o\nde arquivos de sa??da.\n\nprovedores de servic?os existentes no diferentes clusters integrados no sistema. Para\ncada operac?a?o disponibilizada na JM-USI foram definidas classes que preparam as\nmensagens a serem enviadas aos provedores (buildxxxxxxOperationPayload())\ne que efetivamente acessam os servic?os (callxxxxxOperation()). Visando uma\nmelhor modelagem do sistema foi definida uma classe que trata das especificidades da\nsubmissa?o de aplicac?o?es (JobSubmission). As classes que tratam da chamada para a\nsubmissa?o de aplicac?o?es (JobSubmissionOperation()) e a de verificac?a?o dos scripts\nde submissa?o (VerifySubmissionScriptOperation()) herdam as caracter??sticas da\nclasse JobSubmission.\n\nAinda no pacote JobManagementSM existe a classe WSConnections. E? atrave?s\ndessa classe que o JM-SM se comunica com o Portal Web. Esta classe e? instanci-\nada dentro do Portal Web a partir das pa?ginas JSP\u2019s e e? responsa?vel por isolar as\nchamadas e primitivas empregadas em Web Services existentes nas classes do pa-\ncote JobManagementSMConsumer. Entretanto, para cada operac?a?o existe um me?todo\ncorrespondente na classe WSConnections. Nesses me?todos e? que as informac?o?es re-\ntornadas sera?o manipuladas e por fim armazenadas no banco de dados.\n\nComo Web Service e? uma tecnologia stateless foi preciso a definic?a?o de algumas\ntabelas para o armazenamento das informac?o?es retornadas, para que futuramente\nse pudesse acessa?-las. Esta estrutura de tabelas sera? apresentada juntamente com o\ndiagrama entidade relacionamento (ER) do Portal Web a seguir.\n\n4.2.3 Portal Web\n\nPara iniciar a descric?a?o da implementac?a?o dos mo?dulos que compo?e o Portal\nWeb sera? apresentado o modelo de dados adotado nesse ambiente. Em seguida sera?o\ndescritas as implementac?o?es dos mo?dulos System Management Module (SMM) e a\nparte referente ao Service Module (SM) do Portal.\n\nO modelo de informac?a?o do ambiente ICE e? ilustrado na Figura 4.16. Ele esta? ba-\nseado no modelo Entidade Relacionamento (ER). As entidades e suas caracter??sticas\nrelevantes sera?o descritas a seguir.\n\n\n\n61\n\nFigura 4.15: Diagrama de classes do JM-SM\n\nPara compreender a forma como o Portal Web foi implementado e? preciso en-\ntender alguns elementos ba?sicos do ICE e os seus relacionamentos. Cada usua?rio\ncadastrado possui um grupo com o nome exatamente igual ao seu usua?rio. Esta\nestrutura se reflete nas entidades User, Group e UsersPerGroup. E? poss??vel que um\nusua?rio fac?a parte de mais de um grupo, mas o grupo que possui o nome exatamente\nigual ao usua?rio deve ser unita?rio. Esse tipo de associac?a?o e? similar ao que ocorre\nnos sistemas do tipo Unix e Linux. A partir dessa associac?a?o a manipulac?a?o dos\nrelacionamentos dos usua?rios com as demais entidades sera? realizada atrave?s do(s)\ngrupo(s) ao(s) qual(is) ele esta? associado.\n\nAle?m do usua?rio estar associado a um grupo, e? preciso que esse grupo esteja as-\nsociado a um perfil. As entidades Profile e ProfileAssociatedToGroup ilustram\nesse requisito. Atrave?s do perfil de um usua?rio e? que se podera? definir quais sa?o os di-\nreitos que este usua?rio tera? dentro do ambiente ICE. A princ??pio ja? existem tre?s perfis\nba?sicos: ICE ROOT, CLUSTER ROOT e USER, descritos na Sec?a?o 3.2.2, mas o\nmodelo de dados e o ambiente foram projetados para suportarem definic?o?es de novos\nperfis. Entretanto, como o ambiente ICE e? voltado para o gerenciamento e suporte\nde utilizac?a?o de mu?ltiplos clusters e? poss??vel que o usua?rio apresente diferentes per-\nfis de acordo com o sistema de alto desempenho que esta? utilizando. Para garantir\nessa caracter??stica te?m-se as entidades Cluster e ClusterAccessAssociation. Se-\n\n\n\n62\n\nFigura 4.16: Diagrama Entidade Relacionamento (ER) do ambiente ICE\n\nguindo a linha de relacionamentos apresentados na Figura 4.16, para um usua?rio,\nassociado a um grupo, que esta? associado a um perfil, que esta? associado a um\ncluster, podem existir diferentes funcionalidades.\n\nO ambiente ICE permite que sejam definidas diversos tipos de funcionalidades\nde clusters. Neste trabalho esta? sendo disponibilizada a funcionalidade de gerencia-\nmento de aplicac?o?es, mas outras como monitoramento de recursos, de aplicac?o?es en-\ntre outras que podem ser incorporadas. Uma funcionalidade e? formada por operac?o?es\nque sa?o formadas por para?metros. As entidades listadas a seguir representam es-\ntas associac?o?es: Parameter, Operation, Funcionality, OperationParameters,\nFunctionalityOperations. Uma ou mais funcionalidades podem estar associadas\na um ou mais clusters. A entidade FunctiolalityPerCluster ilustra esta situac?a?o\nna Figura 4.16.\n\nCom as associac?o?es apresentadas ate? o momento e? poss??vel definir as permisso?es\nde acesso dos usua?rios a?s funcionalidades de cada cluster. Dentro do ambiente ICE\npara que um usua?rio esteja devidamente autorizado a utilizar alguma funcionalidade\ne? preciso que ele possua um grupo, um perfil, um cluster e uma funcionalidade asso-\nciados. Isto e? representado na entidade ClusterFunctionalityUsagePermission.\n\nO gerenciamento dos dados do modelo de informac?a?o do ICE e? realizado pelo\nSMM. No momento em que usua?rio acessa o Portal Web, identificando-se atrave?s\nde um login e senha, o SMM verifica quais os clusters, perfis e funcionalidades que\nesse usua?rio possui permissa?o de utilizac?a?o. A partir dessa verificac?a?o e? montada\na pa?gina Web que sera? enviada ao browser do usua?rio. A Figura 4.17 ilustra um\nusua?rio que tem perfil de administrador do ICE (ICE ROOT) e do cluster gppd\n(CLUSTER ROOT) (cluster pertencente ao Grupo de Processamento Paralelo e\nDistribu??do do Instituto de Informa?tica da UFRGS), ale?m disso ele tambe?m possui\no perfil de usua?rio comum (USER).\n\nNa Figura 4.17 tem-se a sobreposic?a?o de duas telas. A que esta? em segundo\nplano e? a pa?gina principal do menu de operac?o?es. A partir dela e? poss??vel inserir\nnovas operac?o?es, remover e visualizar as existentes, assim como altera?-las. A tela\nem primeiro plano ilustra exatamente a pa?gina de alterac?a?o das informac?o?es de uma\noperac?a?o, no caso a Job Submission, pertencente a? funcionalidade de gerenciamento\nde aplicac?o?es (Job Management).\n\nA? esquerda das telas existe o menu principal. Esse e? o menu montado a partir\n\n\n\n63\n\nFigura 4.17: Snapshot Portal Web - Configurac?a?o de operac?o?es\n\ndo tipo de perfil que o usua?rio possui. O menu ICE Configuration representa as\nopc?o?es que existem para os usua?rio que possuem o perfil ICE ROOT. O menu ICE\nCluster Configuration representa as possibilidades de configurac?a?o disponibilizadas\npelo perfil CLUSTER ROOT. E, finalmente, o menu Common User representa o\nperfil de usua?rio comuns (USER). A estrutura de telas apresentada na Figura 4.17\ne suas opc?o?es e? ide?ntica para os demais itens do menu ICE Configuration.\n\nFoi definido que usua?rios com direito de configurac?a?o de ambiente ICE so? po-\ndem inserir usua?rios administrativos, isto e?, administradores do ICE e de clusters.\nUsua?rios comuns so? podera?o ser cadastrados pelos administradores dos clusters. Fo-\nram criadas restric?o?es para fazer com que os administradores de clusters so? tivessem\nacesso para configurar os requisitos dos clusters os quais sa?o responsa?veis. Dessa\nforma se um usua?rio tem acesso a mais de um cluster que e? gerenciado por diferentes\nadministradores e? preciso que cada administrador o cadastre como usua?rio de seu\ncluster.\n\nO gerenciamento de grupos e? feito exclusivamente pelos administradores dos\nclusters. A Figura 4.18 apresenta a tela principal da configurac?a?o de grupos.\n\nE? neste momento que os administradores de clusters podem associar usua?rios\n(Users), perfis (Profile), clusters (Resource) e funcionalidades (Functionality) aos\ngrupos. Atrave?s do preenchimento dos formula?rios disponibilizados nessa etapa de\nconfigurac?a?o do ambiente ICE e? que as tabelas de dados, geradas a partir do modelo\nER apresentado na Figura 4.16, sera?o atualizados. Os processos associac?o?es de\nrecursos e funcionalidades a grupos sa?o os mais complexos.\n\nPara estabelecer o relacionamento entre um grupo e um cluster sa?o preciso dois\npassos. A Figura 4.19 mostra ao fundo o primeiro passo e mais na frente o segundo\npasso.\n\nA associac?a?o de um recurso a um usua?rio implica que esse usua?rio esteja as-\nsociado a um grupo, o qual deve estar associado a um perfil. No primeiro passo\n\n\n\n64\n\nFigura 4.18: Snapshot Portal Web - Pa?gina principal da configurac?a?o de grupos\n\nFigura 4.19: Snapshot Portal Web - Associac?a?o de clusters a grupos\n\n\n\n65\n\nFigura 4.20: Snapshot Portal Web - Associac?a?o de funcionalidades a grupos\n\no administrador pode escolher qual perfil do grupo vai associar a um determinado\ncluster. No segundo passo sa?o apresentados os clusters que esse grupo tem acesso e\na quais clusters esse grupo ja? esta? associado.\n\nNa associac?a?o de funcionalidades a grupos sa?o necessa?rios os mesmos passos\nanteriores e mais um terceiro. A Figura 4.20 ilustra esse u?ltimo passo.\n\nDepois de definido qual o perfil e qual o recurso, o administrador devera? indicar\nqual a funcionalidade que sera? associada. No passo tre?s, apresentado na Figura 4.20,\nsa?o disponibilizadas somente as funcionalidades associadas com o cluster escolhido.\nA associac?a?o entre cluster e funcionalidade e? estabelecida no menu Resource do\nadministrador do ambiente ICE, ela e? ilustrada na Figura 4.21.\n\nNessa figura sa?o disponibilizadas aos administradores as funcionalidades provi-\ndas pelo ambiente. O administrador deve selecionar as que deseja prover em cada\ncluster e deve indicar o enderec?o do provedor dos servic?os. Nesse ponto acontece a\nligac?a?o entre o Portal Web e o mo?dulos JM-SIs existentes nos front-ends dos clusters.\n\nOs snapshots apresentados neste trabalho resumem as telas mais importantes do\nambiente ICE. Resumidamente pode-se dizer que os itens nos menus referentes ao\nICE ROOT e ao CLUSTER ROOT tem a funcionalidade de configurar o ambiente\nICE para que ele possa ser utilizado pelos usua?rios dos clusters gerenciados neste\nambiente. Como as informac?o?es disponibilizadas aos usua?rios sa?o todas dina?micas\ntornam-se necessa?rias essas ac?o?es de configurac?a?o do ambiente realizadas dentro do\nSMM.\n\nAle?m das operac?o?es realizadas pelo SMM ainda existem aquelas executadas pelos\n\n\n\n66\n\nFigura 4.21: Snapshot Portal Web - Associac?a?o de funcionalidades a clusters\n\nSMs. No caso deste trabalho tem-se as ac?o?es relacionadas ao SM-JM. Analisando os\nsnapshots apresentados acima pode-se perceber que no menu principal do ambiente\nICE tambe?m existe o menu Common User, relacionado com o perfil USER. Isto\nsignifica que o usua?rio com perfil USER no cluster gppd possui a permissa?o de\nexecuc?a?o da funcionalidade de gerenciamento de aplicac?o?es (Job Management). A\nFigura 4.22 ilustra a pa?gina principal do menu de gerenciamento de aplicac?o?es.\n\nAtrave?s dessa pa?gina e? poss??vel submeter aplicac?o?es, gerar um script de visu-\nalizac?a?o de teste, finalizar uma aplicac?a?o ou enta?o recuperar os arquivos de sa??da\npadra?o e sa??da de erro padra?o de uma aplicac?a?o que esteja rodando ou que tenha sido\nfinalizada. A tabela da Figura 4.22 apresenta as aplicac?o?es que estavam associadas\nao usua?rio naquele momento. E? poss??vel perceber que ele possu??a uma aplicac?a?o\nque estava sendo executada (12444.gppd.gppd) e outra que estava ainda na fila do\ngerenciador do cluster gppd (12456.gppd.gppd). Nesse caso o gerenciador instalado\nnesse cluster e? a ferramenta OpenPBS, mas como se pode perceber esta informac?a?o\nna?o e? necessa?ria para o usua?rio do ambiente ICE.\n\nAs operac?o?es disponibilizadas na Figura 4.22 sa?o exatamente as mesmas definidas\nna JM-USI. Entretanto, algumas delas na?o aparecem explicitamente. A operac?a?o de\nverificac?a?o de estado das aplicac?o?es na?o e? disponibilizada atrave?s de um bota?o, como\npor exemplo, a operac?a?o de submissa?o. Entretanto, a tabela ilustrada na pa?gina\nWeb dessa figura e? formada atrave?s da consulta a esta operac?a?o. As operac?o?es de\nfinalizac?a?o e recuperac?a?o das sa??das padra?o tambe?m sa?o disponibilizadas atrave?s\ndessa tabela. A operac?a?o de submissa?o de uma aplicac?a?o e? ilustrada na Figura 4.23.\n\nOs para?metros informados sera?o processados pelo SM-JM do Portal Web, sendo\nque o consumidor de servic?os do Middleware de Servic?os sera? contactado e dessa\nforma a requisic?a?o ao Web service do cluster em questa?o sera? acionado. A mensagem\nde retorno do provedor de servic?os sera? tratada e os dados devidamente apresentados\nao usua?rio. Caso algum erro ocorra o usua?rio recebera? uma pa?gina especificando\nesse erro. Caso contra?rio, as informac?o?es da aplicac?a?o sera?o armazenadas em uma\n\n\n\n67\n\nFigura 4.22: Snapshot Portal Web - Pa?gina principal do menu Job Management\n\nFigura 4.23: Snapshot Portal Web - Pa?gina de submissa?o de aplicac?o?es\n\n\n\n68\n\nFigura 4.24: ER da funcionalidade de Job Management\n\ntabela que foi acrescentada no modelo de informac?a?o do ambiente. A Figura 4.24\napresenta as entidades e relacionamentos definidos para armazenar as informac?o?es\nrelacionadas com a funcionalidade de submissa?o de aplicac?o?es.\n\nDado o fato dos Web Services na?o manterem o estado de suas operac?o?es foi\nnecessa?ria a definic?a?o da entidade JobInformation. Ela esta? relacionada com a en-\ntidade ClusterAccessAssociation pois uma aplicac?a?o para ser submetida deve estar\nassociada a um usua?rio com o perfil que permita esse tipo de operac?a?o em um\ndeterminado cluster.\n\nPara visualizar como funcionam as opc?o?es de submissa?o de aplicac?o?es e ter cer-\nteza de que o script que devera? ser submetido condiz com a sema?ntica que o usua?rio\ndeseja foi definida a operac?a?o de visualizac?a?o de scripts. Para utilizar essa operac?a?o\no usua?rio deve preencher o um formula?rio ide?ntico ao formula?rio da operac?a?o de\nsubmissa?o. Entretanto, ao inve?s de submeter uma aplicac?a?o ele recebera? o conteu?do\ndo script que devera? ser submetido ao gerenciador do cluster. As Figuras 4.25 e 4.26\nilustram exemplos de visualizac?a?o de scripts, apresentando algumas das opc?o?es de\nsubmissa?o disponibilizadas no ambiente.\n\nFigura 4.25: Exemplo 1 de visualizac?a?o de scripts de submissa?o\n\nNesse primeiro exemplo foi solicitada a visualizac?a?o de script para o lanc?amento\nde uma aplicac?a?o paralela utilizando a biblioteca MPICH, onde deveriam ser alo-\ncados 2 no?s mas deve ser disparado apenas 1 processo. Atrave?s da interface Web\nespecificou-se que essa aplicac?a?o deveria ser executada 2 vezes (referente ao campo\n\n\n\n69\n\nFigura 4.26: Exemplo 2 de visualizac?a?o de scripts de submissa?o\n\nBatch iterations na Figura 4.23) e que na?o ela na?o deveria ser disparada em mu?ltiplos\narquivos (referente ao campo Multiple scrips na Figura 4.23). A diferenc?a entre os\nexemplos da Figura 4.25 e 4.26 esta? no fato de que a segunda habilita a criac?a?o de\ndiferentes scripts para cada uma das iterac?o?es especificadas.\n\nComparando as informac?o?es apresentadas na interface Web com as informac?o?es\noriginais recebidas no consumidor (comparando as figuras da Sec?a?o 4.2.2.2) percebe-\nse que em alguns casos o XML recebido no consumidor e? apresentado praticamente\nsem alterac?o?es na pa?gina Web, como no caso da visualizac?a?o de scripts. Em com-\npensac?a?o, existem casos em que o conteu?do do XML e? completamente adaptado\npara facilitar sua apresentac?a?o aos usua?rios, como no caso da verificac?a?o do estado\ndas aplicac?o?es submetidas.\n\nDe acordo com o projeto do ambiente ICE e? poss??vel a adic?a?o de outras operac?o?es\nna funcionalidade de gerenciamento de aplicac?o?es sem que isto altere o que ja? esta?\ndisponibilizado na ferramenta.\n\n4.3 Resumo\n\nNeste cap??tulo foram apresentadas as deciso?es de projeto e a descric?a?o da im-\nplementac?a?o do proto?tipo desenvolvido. No que diz respeito a?s deciso?es de projeto\ndiscutiu-se qual seria o middleware adotado e quais deveriam ser os padro?es atu-\nais que poderiam ser empregados no ambiente ICE. Atrave?s de uma comparac?a?o\nentre dois bem documentados e estabelecidos middlewares (Corba e Web Services)\noptou-se por utilizar Web Services na implementac?a?o do Middlware de Servic?os do\nambiente ICE. Com relac?a?o aos padro?es que poderiam ser utilizados no ambiente\noptou-se por na?o utilizar o Globus e seu mo?dulo de gerenciamento de recursos (WS-\nGRAM). Essa decisa?o foi tomada pois verificou-se que na?o poss??vel utilizar apenas\no mo?dulo WSGRAM. Para utiliza?-lo e? preciso instalar tambe?m os mo?dulos princi-\n\n\n\n70\n\npais do Globus, o que corresponde a praticamente todo o Globus, como mostrado\nna Sec?a?o 4.1.2. Depois desta ana?lise inicial passou-se para a descric?a?o em si da\nimplementac?a?o do proto?tipo. Foram apresentados cada um dos componentes do\nambiente e seus mo?dulos. Para tanto foram empregados exemplos de estruturas\nXML que descrevem o funcionamento do Middleware de Servic?os assim como foram\napresentados o modelo de informac?a?o e alguns snapshots do Portal Web. Atrave?s\nda leitura deste cap??tulo pode-se perceber que o ambiente ICE possui uma comple-\nxidade em seus relacionamentos e interligac?o?es de mo?dulos. Entretanto, acredita-se\nque essa caracter??stica na?o compromete a capacidade de extensibilidade do ambiente\ne transpare?ncia de uso propostos no ambiente. Ao contra?rio, a modularidade de seus\ncomponentes e a arquitetura definidas facilitam o oferecimento dessas caracter??sticas.\n\n\n\n71\n\n5 AVALIAC?A?O DO PROTO?TIPO ICE\n\nEste cap??tulo esta? dividido em duas partes. A primeira trata de uma comparac?a?o\nentre o ambiente ICE, proposto neste trabalho, e algumas ferramentas relacionadas.\nA segunda possui uma ana?lise quantitativa do ambiente desenvolvido. Sera?o apre-\nsentados gra?ficos avaliando o overhead inserido pelo ambiente ICE.\n\n5.1 Avaliac?a?o Qualitativa\n\nA avaliac?a?o qualitativa foi realizada atrave?s da comparac?a?o das caracter??sticas\nde ferramentas de gerenciamento de alto desempenho com as caracter??sticas do am-\nbiente ICE. Esta comparac?a?o na?o foi realizada entre todos os ambientes porque,\ncomo apresentado no Cap??tulo 2, existem escopos diferentes de emprego das ferra-\nmentas (clusters, grids e mu?ltiplos clusters). Sendo assim, as ferramentas de clusters\ne grids na?o podem ser diretamente comparadas ao ambiente ICE, o qual e? voltado\npara mu?ltiplos clusters. Isto faz com que seja realizada uma ana?lise qualitativa entre\no ambiente ICE e as ferramentas HPC2N e M3C, apresentadas no Cap??tulo 2.\n\nO objetivo desta ana?lise qualitativa e? verificar qual a capacidade que esses ambi-\nentes apresentam para prover facilidades aos usua?rios e desenvolvedores dos sistemas,\nconsiderando os desafios existentes na construc?a?o de sistemas distribu??dos.\n\n5.1.1 Metodologia\n\nA metodologia utilizada, para realizar a comparac?a?o entre o ambiente ICE e os\ntrabalhos relacionados na a?rea de gerenciamento de mu?ltipos clusters, esta? baseada\nnos desafios apresentados por Coulouris em (COULOURIS; DOLLIMORE; KIND-\nBERG, 2005) sobre a construc?a?o de sistemas distribu??dos. A lista dos crite?rios de\navaliac?a?o e? apresentada abaixo.\n\n\u2022 Heterogeneidade - A comparac?a?o entre os ambientes, considerando este que-\nsito, foi realizada seguindo as caracter??sticas listadas abaixo.\n\n1. Independe?ncia de plataforma: considera se o ambiente e? capaz de operar\nsobre diferentes plataformas de hardware e de sistemas operacionais.\n\n2. Independe?ncia de linguagem: avalia se os mo?dulos que compo?em o am-\nbiente podem ser desenvolvidos em qualquer linguagem de programac?a?o.\n\n3. Interoperabilidade: compara a capacidade que o middleware, empregado\nno desenvolvimento do ambiente, possui para integrar sistemas legados e\npara lidar com as diferenc?as que existem entre os mo?dulos que compo?em\no sistema.\n\n\n\n72\n\n\u2022 Openness - Este crite?rio esta? relacionado com a extensibilidade do sistema.\nNeste trabalho foram considerados dois tipos de extensibilidade, descritas\nabaixo.\n\n1. Extensibilidade de funcionalidades: esta? relacionada com a capacidade\nque o ambiente apresenta para prover mecanismos de inserc?a?o de novas\nfuncionalidades.\n\n2. Extensibilidade na integrac?a?o de ferramentas: considera o suporte dis-\npon??vel para prover abstrac?o?es para inserc?a?o de novas ferramentas que\napresentam a mesma funcionalidade. Por exemplo, se ja? existe uma fer-\nramenta integrada no sistema para o gerenciamento de aplicac?o?es, este\ncrite?rio mede quais os recursos que os ambientes apresentam para inserir\numa nova ferramenta de gerenciamento, sem que isso altere o funciona-\nmento global do ambiente.\n\n\u2022 Transpare?ncia - Sa?o considerados os seguintes tipos de transpare?ncia: acesso,\nlocalizac?a?o, concorre?ncia, replicac?a?o, falha, mobilidade, desempenho e escala-\nbilidade.\n\n\u2022 Tratamento de falhas - Considera a capacidade que o ambiente apresenta para\nlidar com as falhas de seus componentes.\n\n\u2022 Escalabilidade - Avalia a capacidade que o ambiente tem de lidar com o au-\nmento do nu?mero de usua?rios e recursos, sem que isso afete o seu desempenho.\n\n\u2022 Concorre?ncia - Considera a modelagem de seguranc?a no acesso aos recursos,\nquando o ambiente e? concorrente e existe a possibilidade de ocorrer condic?o?es\nde corrida, deadlocks, etc.\n\n\u2022 Seguranc?a - A ana?lise deste crite?rio foi baseada na existe?ncia de canais de\ncomunicac?a?o com encriptac?a?o e na existe?ncia de autenticac?a?o de usua?rios.\n\n5.1.2 Comparac?a?o entre HPC2N, M3C e ICE\n\nA tabela 5.1 apresenta a existe?ncia ou na?o dos crite?rios avaliados em cada uma\ndas ferramentas: HPC2N, M3C e ICE.\n\nOs primeiros cinco crite?rios da Tabela 5.1 sa?o relacionados com as caracter??sticas\nde heterogeneidade e openness dos sistemas distribu??dos. O ambiente ICE prove? es-\ntes cinco crite?rios devido a decisa?o de utilizar como middleware Web services. O\nambiente M3C pode apresentar independe?ncia de plataforma, uma vez que foi de-\nsenvolvido utilizando Applets e Servlets Java. Este ambiente tambe?m pode prover\nextensibilidade de funcionalidades, visto que ele pode permitir que os seus usua?rios\ninsiram novas funcionalidades no sistema. Entretanto o M3C na?o proporciona um\nframework para lidar com as diferentes ferramentas que possuem a mesma funciona-\nlidade e nem a capacidade de lidar com os sistemas legados dos clusters. Ao contra?rio\ndos dois primeiros ambientes discutidos, o HPC2N na?o prove? caracter??sticas de hete-\nrogeneidade e nem de openness porque e? restrito a um conjunto fechado de ferramen-\ntas. Ale?m disso, ele foi desenvolvido utilizando tecnologias que na?o proporcionam\na capacidade de serem interopera?veis e, tambe?m, na?o disponibilizam um framework\npara que ele se torne extens??vel.\n\n\n\n73\n\nTabela 5.1: Comparac?a?o entre o ambiente ICE e algumas ferramentas relacionadas\n\nPara?metros de Comparac?a?o HPC2N M3C ICE\n1 Independe?ncia de plataforma x x\n2 Independe?ncia de linguagem x\n3 Interoperabilidade x\n4 Extensibilidade de funcionalidades x x\n5 Extensibilidade de integrac?a?o de ferramentas x\n6 Transpare?ncia de acesso x x x\n7 Transpare?ncia de localizac?a?o\n8 Transpare?ncia de concorre?ncia x x x\n9 Transpare?ncia de replicac?a?o\n10 Transpare?ncia de falhas\n11 Transpare?ncia de mobilidade x x x\n12 Transpare?ncia de desempenho\n13 Transpare?ncia de escalabilidade x x\n14 Tratamento de falhas\n15 Escalabilidade - - -\n16 Concorre?ncia x x x\n17 Seguranc?a x x x\n\nTodos os ambientes comparados apresentam transpare?ncia de acesso, concorre?ncia\ne mobilidade. Seus usua?rios podem acessa?-los sem levar em considerac?a?o quais sa?o\nos passos e operac?o?es realizados para que se alcance, efetivamente, o dispositivo.\nVa?rios usua?rios podem acessar estes ambientes de forma concorrente atrave?s de seus\nbrowsers. Eles tambe?m podem mudar sua localizac?a?o f??sica sem afetar os sistemas\naqui comparados. Entretanto, nenhum dos ambientes apresentam transpare?ncia de\nlocalizac?a?o, visto que eles sabem quais clusters esta?o utilizando. Os crite?rios de\ntranspare?ncia de replicac?a?o e falhas, da mesma forma como o tratamento de falhas,\nna?o sa?o providos por estes ambientes, pois seus mo?dulos na?o foram desenvolvidos\npara identificarem e lidarem com as eventuais falhas que possam ocorrer nos com-\nponentes que os formam.\n\nCom relac?a?o ao crite?rio de escalabilidade, na?o se pode fazer nenhuma afirmac?a?o,\nja? que na?o foram realizados estudos e experimentos capazes de estabelecer a esca-\nlabilidade destes ambientes. Levando em considerac?a?o o fato dos tre?s ambientes\nserem baseados em plataformas Web e que sa?o executados sob servidores Web, tais\ncomo Apache e Tomcat, pode-se especular que suas escalabilidades podem ser limi-\ntadas pela configurac?a?o desses servidores. Da mesma forma como a escalabilidade,\no crite?rio de concorre?ncia esta? relacionado com a infra-estrutura sobre a qual os\nambientes ICE, M3C e HPC2N sa?o executados. Cada acesso a estes ambientes e?,\nprimeiramente, tratado pelos servidores Web, sendo que a concorre?ncia e? tratada\nnestes servidores. Considerando o aspecto de seguranc?a, te?m-se os tre?s ambientes\nutilizando HTTPS para garantir a seguranc?a do canal de comunicac?a?o. Entretanto,\ncada um apresenta um conjunto de te?cnicas distintas para garantir as caracter??sticas\nde autenticac?a?o e autorizac?a?o de seus usua?rios.\n\nFinalmente, analisando a Tabela 5.1, pode-se perceber que o ambiente ICE pos-\n\n\n\n74\n\nsui suporte para quase todos os crite?rios de sistemas distribu??dos, considerados nesta\ncomparac?a?o. Comparado com os outros ambientes de gerenciamento de mu?ltiplos\nclusters, apresentados neste trabalho, pode-se dizer que o ambiente ICE e? o que\npossui mais recursos. As caracter??sticas que mais o distinguem das demais ferra-\nmentas sa?o sua capacidade de extensibilidade e openness. Em um cena?rio onde e?\npreciso prover facilidade de uso para os usua?rios de mu?ltiplos clusters, cujo custo\nde implantac?a?o da soluc?a?o seja o menos oneroso, tem-se o ambiente ICE como uma\nboa opc?a?o.\n\n5.2 Avaliac?a?o Quantitativa\n\nO objetivo dos testes quantitativos com o ambiente ICE foi verificar qual o\noverhead inserido pela infra-estrutura deste ambiente nos processos que eram, tipi-\ncamente, executados atrave?s de linha de comando pelos usua?rios.\n\nForam realizados experimentos com as cinco operac?o?es providas pela JM-USI:\n\n\u2022 submissa?o de aplicac?o?es;\n\n\u2022 verificac?a?o do script de submissa?o gerado pelo JM-SI da respectiva ferramenta;\n\n\u2022 finalizac?a?o de aplicac?o?es;\n\n\u2022 verificac?a?o do estado das filas de execuc?a?o das ferramentas;\n\n\u2022 recuperac?a?o dos arquivos de sa??da (padra?o ou de erro).\n\nA seguir sa?o apresentadas algumas informac?o?es que caracterizam como foi condu-\nzida a avaliac?a?o quantitativa do ambiente ICE. Em primeiro lugar, sera? apresentado\nexatamente o que foi medido, em seguida qual a metodologia de medic?a?o e por fim\nos resultados encontrados para cada uma das operac?o?es suportadas no mo?dulo de\ngerenciamento de aplicac?o?es do ambiente ICE.\n\n5.2.1 Definic?a?o do escopo das medic?o?es\n\nO overhead observado leva em considerac?a?o apenas o tempo de processamento\ndentro do front-end do cluster empregado nos testes. A Figura 5.1 ilustra os ele-\nmentos que fizeram parte da aquisic?a?o das medidas apresentadas nesta sec?a?o.\n\nAs as tre?s entidades que foram empregadas na realizac?a?o desses testes sa?o carac-\nterizadas a seguir.\n\n\u2022 Ferramenta de Gerenciamento: corresponde a? ferramenta de gerenciamento de\naplicac?o?es, instalada no cluster onde as medidas esta?o sendo realizadas.\n\n\u2022 Provedor JM-SI: representa as implementac?o?es do JM-SI. No caso dos experi-\nmentos aqui apresentados existe o OpenPBS JM-SI e o OAR JM-SI.\n\n\u2022 Consumidor standalone: consiste em uma aplicac?a?o que consulta o provedor\nde servic?os da JM-SI. Esta aplicac?a?o na?o esta? integrada ao ambiente ICE, por\nisso foi considerada standalone. Ela e? utilizada para acessar tanto o OpenPBS\nJM-SI quanto o OAR JM-SI. Entretanto, para evitar a interfere?ncia da rede\nde comunicac?a?o, ela foi instalada no front-end utilizado para os testes.\n\n\n\n75\n\nFigura 5.1: Cena?rio de aquisic?a?o das medidas de overhead\n\nO consumidor standalone faz as requisic?o?es das operac?o?es do servic?o de gerencia-\nmento de aplicac?o?es ao provedor da respectiva JM-SI. Ao receber estas requisic?o?es o\nJM-SI faz o tratamento das informac?o?es e realiza os passos necessa?rios, interagindo\ncom a ferramenta de gerenciamento. Apo?s esta interac?a?o, retorna para o consumidor\nos dados resultantes da execuc?a?o da operac?a?o.\n\nNos testes que foram realizados, o que se mediu foi a soma dos tempos T1, T2\ne T3 indicados na Figura 5.1. T1 representa o tempo despendido pelo provedor\npara reconhecer os para?metros da operac?a?o e traduzi-los para serem solicitados a?\nferramenta de gerenciamento. T2 consiste no tempo que o provedor tem que esperar\npara receber os dados da operac?a?o executada. T3 e?, por fim, o tempo que o provedor\ngasta para processar os dados e montar a mensagem de retorno ao consumidor.\nNestes experimentos, na?o foi considerado o tempo gasto pelo container Tomcat\npara receber a requisic?a?o e encaminha?-la ao devido provedor de servic?os, assim\ncomo, tambe?m, na?o foi considerado o tempo que este mesmo elemento leva para\nencaminhar a resposta do servic?o solicitado.\n\nPara que se pudesse identificar qual o overhead inserido pelo ambiente ICE foi\nrealizado o seguinte ca?lculo:\n\nOverhead = Tice ? Tf erramenta\n\nonde Tice representa o tempo total (T1+T2+T3) de execuc?a?o de uma operac?a?o do\nprovedor JM-SI, e Tferramenta representa o tempo de total execuc?a?o de uma ac?a?o\nda ferramenta sem intervenc?a?o do ambiente ICE. Desta forma, durante as ana?lises\no overhead e? apresentado em termos absoluto, ou seja, quantos milisegundos de\noverhead foi observado.\n\n5.2.2 Metodologia\n\nForam realizados experimentos e ana?lises para todas as operac?o?es definidas na\nJM-USI e implementadas na JM-SI. Para cada uma destas ana?lises foram executadas\n300 iterac?o?es. Definiu-se este tamanho de amostra depois de sucessivas rodadas de\nexecuc?a?o com diferentes tamanhos de amostras. Atrave?s da ana?lise dos desvios\n\n\n\n76\n\npadro?es encontrados percebeu-se que amostras a partir de 300 iterac?o?es mantinham\no desvio padra?o constante. Os valores apresentados nos gra?ficos correspondem a?s\nme?dias encontradas de acordo com esta amostra. Ale?m dos gra?ficos com as me?dias,\ntambe?m sera?o apresentadas algumas tabelas com o desvio padra?o e a representac?a?o\npercentual desse desvio em relac?a?o a? me?dia encontrada. Ainda foram realizados\ntestes utilizando, diretamente, os comandos dos gerenciadores de aplicac?o?es. Estes\ntestes tambe?m seguiram a metodologia de aquisic?a?o de valores relatada acima.\n\nA aquisic?a?o do tempo, dentro da implementac?a?o dos provedores JM-SI, foi reali-\nzada atrave?s da chamada a? primitiva System.currentTimeMillis() logo no in??cio\nde cada operac?a?o e no final das mesmas, exatamente antes de retornar a resposta aos\nconsumidores. Esta primitiva faz parte da linguagem Java, e retorna o tempo em mi-\nlisegundos no momento de sua chamada. Para que se possa ter o tempo de execuc?a?o\nda operac?a?o, faz-se a subtrac?a?o do tempo final menos o inicial. Para aquisic?a?o dos\ntempos, no caso da execuc?a?o direta das ferramentas, foi utilizado o comando time,\nque retorna o tempo de cpu em segundos utilizado por uma aplicac?a?o. Este tempo\nem segundos foi convertido para milisegundos no intuito de uniformizar as medic?o?es\nrealizadas neste trabalho.\n\nNas ana?lises feitas, com as operac?o?es de submissa?o de aplicac?o?es e de visualizac?a?o\nde scripts de submissa?o, foram realizadas variac?o?es na forma como os para?metros\ndas aplicac?o?es podem ser utilizados. Estas variac?o?es consideram os para?metros de:\nmu?ltiplas execuc?o?es de mesma aplicac?a?o e no caso de serem solicitadas mu?ltiplas\nexecuc?o?es, e? preciso que sejam criados diferentes scripts. Ale?m disso tambe?m foram\ntestadas aplicac?o?es sequ?enciais e paralelas com as bibliotecas MPICH e DECK. A\nnomenclatura utilizada nas legendas dos gra?ficos dos experimentos destas operac?o?es\ne? apresenta na Tabela 5.2.\n\nTabela 5.2: Descric?a?o das variac?o?es de para?metros para submissa?o de aplicac?o?es.\nOpc?o?es Descric?a?o\nDECK Aplicac?a?o paralela baseada na biblioteca DECK\nMPICH Aplicac?a?o paralela baseada na biblioteca MPICH\nSeq Aplicac?a?o sequ?encial\nMultiple Indica se a aplicac?a?o foi executada mais de uma vez.\n\nNo caso dos testes realizados, quando habilitado,\nsignifica que a aplicac?a?o foi executada cinco vezes.\n\nSingle Indica que a aplicac?a?o foi executada uma u?nica vez.\nArc Indica que somente um script foi gerado,\n\nindependentemente do nu?mero de vezes\nque a aplicac?a?o sera? executada\n\nArcs Indica que foram gerados tantos scripts quantas foram as\nvezes que a aplicac?a?o devera? ser executada. Neste caso,\nquando habilitado, significa que foram gerados cinco\nscripts de submissa?o da mesma aplicac?a?o.\n\n5.2.3 Plataforma\n\nOs experimentos foram realizados no cluster frontal-minuano pertencente ao\nGPPD, o qual tem suas principais caracter??sticas apresentadas na Tabela 5.3. Neste\n\n\n\n77\n\ncluster foram instaladas as duas ferramentas de gerenciamento de aplicac?o?es: OpenPBS\ne OAR.\n\nTabela 5.3: Descric?a?o do cluster utilizado para os experimentos\nCaracter??stica Frontal-minuano\n\nSistema Operacional Linux, kernel 2.6.12\nDistribuic?a?o Debian Sarge\nProcessador Pentium III 598.998 MHz\nCache 512 KB\nMemo?ria RAM 256 MB\nSwap 494 MB\n\nDecidiu-se realizar os experimentos em um u?nico cluster para que se pudesse\ncomparar, diretamente, a intrusa?o do ambiente ICE em cada uma das ferramentas\nde gerenciamento de aplicac?o?es suportadas.\n\n5.2.4 Experimentos com a operac?a?o de submissa?o de aplicac?o?es\n\nO primeiro experimento realizado considerou a operac?a?o de submissa?o de aplicac?o?es.\nOs gra?ficos da Figura 5.2 ilustram os tempos de submissa?o encontrados com a im-\nplementac?a?o OpenPBS JM-SI.\n\nFigura 5.2: Gra?fico Operac?a?o de Submissa?o - OpenPBS\n\nNo caso dos testes apresentados na Figura 5.2, o tempo medido para gerac?a?o\ne submissa?o de um u?nico script manteve-se em me?dia entre 147 e 153 milisegun-\ndos, enquanto a gerac?a?o e submissa?o de mu?ltiplos scripts manteve-se em torno de\n730 e 740 milisegundos. O tempo me?dio de submissa?o de uma aplicac?a?o, atrave?s\ndos comandos do gerenciador OpenPBS, manteve-se na casa de 56,1 milisegundos.\nObservando os gra?ficos dessa figura pode-se perceber que a submissa?o de um u?nico\nscript apresentou um comportamento bastante homogeneo, independentemente do\ntipo de aplicac?a?o que estava sendo lanc?ada. No caso do disparo de mu?ltiplos scripts\n\n\n\n78\n\nde execuc?a?o da mesma aplicac?a?o, houve uma pequena diminuic?a?o no tempo da\ngerac?a?o para aplicac?o?es MPICH. Este comportamento pode ter sido causado devido\na?s condic?o?es do front-end, onde, possivelmente, devem ter ocorrido variac?o?es na sua\ncarga de trabalho que acabou se refletindo nos testes realizados. Esta hipo?tese e?\nreforc?ada quando se analisa o desvio padra?o deste experimento, que pode ser encon-\ntrado na Tabela 5.4. Pode-se perceber que o desvio padra?o, nos casos de submissa?o\nde mu?ltiplos scripts para a biblioteca DECK e para aplicac?o?es sequ?enciais, manteve-\nse na casa de 18 milisegundos, enquanto para a biblioteca MPICH o desvio padra?o\nencontrado foi de aproximadamente 19 milisegundos. Com estes valores, pode-se\nconsiderar que o tempo de execuc?a?o em me?dia foi menor do que nos demais, entre-\ntanto apresentou uma variac?a?o maior. Ale?m das informac?o?es de desvio padra?o, a\nTabela 5.4 tambe?m apresenta o percentual de quanto cada desvio padra?o representa\nem relac?a?o a? respectiva me?dia do experimento.\n\nComparando os valores das me?dias encontradas, pode-se dizer que o tempo de\nprocessamento de uma submissa?o de aplicac?o?es no ambiente ICE e?, em me?dia, tre?s\nvezes o tempo necessa?rio para o disparo direto. Sendo assim, o ambiente ICE insere\num overhead de duas vezes o valor alcanc?ado na submissa?o direta. Por exemplo,\nna submissa?o de uma aplicac?a?o a ser lanc?ada em u?nico script (em geral o tempo\ngasto, independentemente se e? uma aplicac?a?o sequ?encial ou paralela, com ou sem\nmu?ltiplas execuc?o?es dentro do mesmo script) o overhead do ambiente ICE e? de\naproximadamente 90,9 milisegundos.\n\nConsiderar este valor de overhead, sem levar em considerac?a?o a facilidade de uso\nque o ambiente ICE traz, na?o e? muito encorajador. Entretanto, apesar de possuir\num tempo de processamento maior que o tempo de submissa?o direta, via OpenPBS,\nainda pode ser mais vantajoso para os usua?rios perderem alguns milisegundos na\nsubmissa?o e contarem com a transpare?ncia e facilidade de uso que o ambiente ICE\noferece.\n\nOs gra?ficos da Figura 5.3 ilustram os tempos de submissa?o encontrados com a\nimplementac?a?o OAR JM-SI.\n\nFigura 5.3: Gra?fico Operac?a?o de Submissa?o - OAR\n\n\n\n79\n\nAnalisando os gra?ficos da Figura 5.3, percebe-se que, de maneira geral, o compor-\ntamento do ambiente ICE, com a implementac?a?o OAR JM-SI, mostrou-se similar\nao OpenPBS JM-SI. A diferenc?a esta? no fato de que os tempos medidos na pri-\nmeira implementac?a?o foram, consideravelmente, maiores do que na segunda. Esta\ndiferenc?a existe dadas as caracter??sticas das ferramentas de gerenciamento sobre as\nquais foram implementadas as JM-SIs. Muitas das informac?o?es que o OAR pos-\nsui esta?o armazenadas em um banco de dados MySQL, enquanto isso o OpenPBS\nutiliza arquivos. Ale?m disso, as caracter??sticas de implementac?a?o de cada uma sa?o\nbastante diferentes. Tudo isso faz com que elas possuam tempos de execuc?a?o bem\ndistintos. Esses tempos na?o sa?o maiores somente na comparac?a?o entre as imple-\nmentac?o?es do JM-SI, mas tambe?m na comparac?a?o direta entre as ferramentas. A\nferramenta OpenPBS apresenta o tempo de submissa?o na casa de 56,1 milisegundos,\nenquanto a OAR possui tempo de execuc?a?o 1863,53 milisegundos.\n\nObservando os tempos encontrados com o OAR JM-SI, que ficaram em torno de\n1930 milisegundos no caso da gerac?a?o e submissa?o de um u?nico script, tem-se um\ndesempenho bem pro?ximo ao da pro?pria ferramenta. Isto faz com que os usua?rios\ndisponham da facilidade de utilizac?a?o da ferramenta de gerenciamento de aplicac?o?es\nque o ambiente ICE disponibiliza na?o sendo penalizado com um overhead significa-\ntivo. Por exemplo, para aplicac?o?es sequ?enciais lanc?adas em um u?nico arquivo tem-se\num overhead de aproximadamente 66,47 milisegundos.\n\nNa Tabela 5.4 tambe?m sa?o apresentados os valores de desvio padra?o e o per-\ncentual de desvio padra?o encontrado para os testes de submissa?o da implementac?a?o\nOAR JM-USI. Pode-se perceber que os valores dos desvios padra?o mantiveram-se\nesta?veis quando comparados entre os tipos de experimentos realizados. Por exem-\nplo, no caso de mu?ltiplos scripts, os desvios padra?o ficaram perto de 2 milisegundos,\nenquanto que para um u?nico script ele se manteve em 4 milisegundos.\n\nTabela 5.4: Desvio padra?o para operac?a?o de submissa?o\nOpenPBS OAR\n\nVariac?o?es Desvio Padra?o Percentual Desvio Padra?o Percentual\nFerramenta 2,89 5,11 12,95 0,69\nDECKMultipleArc 7,32 4,95 104,2 5,39\nDECKMultipleArcs 18,92 2,42 1543,61 10,61\nDeckSingleArc 6,35 4,3 149,19 7,75\nMPIMultipleArc 7,33 4,96 108,13 5,6\nMPIMultipleArcs 19,18 2,6 1508,67 10,34\nMPISingleArc 6,7 4,55 117,65 6,1\nSeqMultipleArc 6,17 4,14 105,28 5,45\nSeqMultipleArcs 18,16 2,32 1722,46 11,67\nSeqSingleArc 5,69 3,71 123,69 6,4\n\nAtrave?s das ana?lises realizadas acima, sobre os resultados encontrados nos expe-\nrimentos, verificou-se que o ambiente ICE insere um overhead no processo de sub-\nmissa?o de aplicac?o?es. Este overhead foi mais acentuado no caso da implementac?a?o\nOpenPBS JM-SI (90,9 milisegundos, que um tempo representa aproximadamente 2\nvezes mais tempo do que a execuc?a?o isolada da ferramenta) e foi bastante suavizado\n\n\n\n80\n\nna implementac?a?o OAR JM-SI (66,47 milisegundos, que representa 3,6% do tempo\nde execuc?a?o da ferramenta isolada). Estes experimentos na?o podem ser analisados\nde forma pontual, ou seja, sem levar em considerac?a?o as caracter??sticas do ambiente\nICE. Eles servem como um indicativo do custo a ser pago pelas facilidades de uso\nque esta?o sendo inseridas no uso do cluster.\n\n5.2.5 Experimentos com a operac?a?o de visualizac?a?o de scripts de sub-\nmissa?o\n\nA operac?a?o de visualizac?a?o de scripts de submissa?o na?o possui um comando\ncorrespondente nas ferramentas de gerenciamento utilizadas neste trabalho. Isto\ntambe?m se deve ao fato de que sa?o os usua?rios que montam os scripts de submissa?o,\ne sendo assim, eles ja? conhecem o seu conteu?do. No ambiente ICE os usua?rios\nna?o lidam com os detalhes de mais baixo n??vel, mas podem necessitar a verificac?a?o\nda sema?ntica e a correc?a?o dos scripts que lanc?ara?o suas aplicac?o?es, como ja? ar-\ngumentado na Sec?a?o 4.2.2.1. As Figuras 5.4 e 5.5 apresentam os tempos me?dios\nde processamento da operac?a?o de visualizac?a?o de scripts, respectivamente, para as\nimplementac?o?es OpenPBS JM-SI e OAR JM-SI.\n\nFigura 5.4: Gra?fico Operac?a?o de Visualizac?a?o de Scripts - OpenPBS\n\nAnalisando os gra?ficos das Figuras 5.4 e 5.5, e? poss??vel perceber que os tempos\nme?dios de processamento da operac?a?o de verificac?a?o de scripts, nas duas imple-\nmentac?o?es, aproximaram-se bem mais do que no caso da operac?a?o de submissa?o. Os\ntempos me?dios para a gerac?a?o de scripts u?nicos ficou em torno de 12 milisegundos\npara a implementac?a?o OpenPBS JM-SI e em torno de 11 segundos para a OAR\nJM-SI. No caso da verificac?a?o dos mu?ltiplos scripts, o tempo me?dio de execuc?a?o\nficou na casa de 15 e 14 milisegundos respectivamente.\n\nComparando a execuc?a?o das duas implementac?o?es, pode-se perceber que, em\ngeral, existe uma diferenc?a de 1 milisegundo. Esta diferenc?a se deve a?s diferenc?as\nque existem no processo de traduc?a?o dos para?metros para as estruturas de cada\nferramenta.\n\nNos gra?ficos da Figura 5.4, ainda pode-se perceber uma pequena variac?a?o dos\n\n\n\n81\n\nFigura 5.5: Gra?fico Operac?a?o de Visualizac?a?o de Scripts - OAR\n\ntempos me?dios no caso da verificac?a?o de um u?nico script. Mais uma vez essa al-\nterac?a?o pode ter sido causada pela carga do cluster frontal-minuano.\n\nA Tabela 5.5 apresenta os valores de desvio padra?o e percentual de desvio padra?o\nverificados nos experimentos com esta operac?a?o para as duas implementac?o?es. Ana-\nlisando os valores encontrados, pode-se perceber que na?o houve nenhuma variac?a?o\nmuito acentuada dos tempos de execuc?a?o desta operac?a?o.\n\nTabela 5.5: Desvio padra?o para operac?a?o de verificac?a?o de scripts\n\nOpenPBS OAR\nVariac?o?es Desvio Padra?o Percentual Desvio Padra?o Percentual\nDECKMultipleArc 1,09 8,94 0,89 7,57\nDECKMultipleArcs 2,18 13,75 1,26 8,76\nDeckSingleArc 1,49 11,54 0,8 6,74\nMPIMultipleArc 1,35 10,01 0,88 7,39\nMPIMultipleArcs 1,95 12,57 1,21 8,55\nMPISingleArc 1,32 10,75 0,9 7,69\nSeqMultipleArc 1,29 9,85 0,79 6,73\nSeqMultipleArcs 1,86 12,01 1,18 8,36\nSeqSingleArc 1,5 12,31 0,79 6,75\n\nDe maneira geral, pode-se dizer que os tempos encontrados na execuc?a?o desta\noperac?a?o sa?o satisfato?rios. A vantagem de poder verificar o conteu?do e a sema?ntica\ndo script de submissa?o, e esta operac?a?o ser executada em um intervalo de tempo\npequeno, so? traz ganhos para o ambiente ICE.\n\n\n\n82\n\n5.2.6 Experimentos com a operac?a?o de finalizac?a?o de aplicac?o?es\n\nA Tabela 5.6 apresenta os tempos me?dios, desvio padra?o e o percentual do desvio\npadra?o em relac?a?o a? me?dia. Foram realizados experimentos com a submissa?o direta\nvia OpenPBS, via OAR e atrave?s das implementac?o?es JM-SI sobre cada uma das\nferramentas.\n\nTabela 5.6: Desempenho da operac?a?o de finalizac?a?o de aplicac?o?es\n\nMe?dia Desvio Padra?o Percentual\nOpenPBS JM-SI 138,96 3,61 2,59\nOpenPBS 50,5 2,54 5,03\nOAR JM-SI 2070,76 408,85 19,74\nOAR 1989,19 405,42 20,38\n\nA primeira constatac?a?o que se pode fazer, analisando esta tabela, e? a grande\ndiferenc?a de tempos entre as ferramentas. Ao utilizar o OpenPBS diretamente o\ntempo me?dio de finalizac?a?o e? 50,5 milisegundos, enquanto com o OAR o tempo me?dio\nfica em 1989,19 milisegundos. Isto ocorre em vista das diferenc?as das ferramentas\n(ver Sec?a?o 5.2.4).\n\nComparando os resultados de cada ferramenta com a respectiva infra-estrutura\nno ambiente ICE, tem-se as situac?o?es apresentadas a seguir. No caso da comparac?a?o\nentre o gerenciador OpenPBS e o OpenPBS JM-SI, pode-se visualizar a diferenc?a\nque existe nos tempos me?dios de finalizac?a?o. Enquanto o gerenciador apresenta\no tempo me?dio de 50,5 milisegundos, a infra-estrutura ICE possui o tempo me?dio\nde 138,96 milisegundos. Isto mostra que o tempo total de finalizac?a?o no ambiente\nICE, considerando a infra-estrutura para a ferramenta OpenPBS, e? em geral tre?s\nvezes maior que o tempo de execuc?a?o da ferramenta de forma isolada. O overhead\nverificado foi de 88,46 milisegundos. Apesar deste nu?mero parecer um pouco elevado,\ne? preciso lembrar que se tratam de milisegundos e que o maior objetivo do ambiente\nICE e? prover facilidades de uso aos seus usua?rios. Portanto, mais uma vez se torna\ninteressante gastar 138,96 milisegundos para finalizar uma aplicac?a?o, havendo a\npossibilidade de na?o ter que lidar com os comandos espec??ficos do gerenciador de\naplicac?a?o.\n\nConsiderando o gerenciador OAR e o OAR JM-SI, pode-se perceber, atrave?s\ndos dados da Tabela 5.6, que a infra-estrutura ICE apresenta um tempo me?dio de\nexecuc?a?o bem pro?ximo ao do gerenciador. A finalizac?a?o direta, via OAR, levou em\nme?dia 1989,76 milisegundos, enquanto a finalizac?a?o atrave?s do ambiente ICE, via\no OAR JM-SI, levou em me?dia 2070,76 milisegundos. Esta diferenc?a implica em\noverhead de 81 milisegundos. Este valor mostra que a maior parte do tempo de\nprocessamento da infra-estrutura ICE, nesta implementac?a?o, e? gasto pela chamada\nao comando do gerenciador OAR.\n\nAnalisando o desvio padra?o encontrado nos experimentos, e? poss??vel notar, que\nno caso da ferramenta OAR, existe uma variac?a?o considera?vel que fica na casa de\n20% em relac?a?o a? me?dia observada, tanto na execuc?a?o direta da ferramenta quanto\nna implementac?a?o OAr JM-SI. No caso do OpenPBS, obteve-se uma estabilidade\nmaior, ou seja, os tempos de execuc?a?o da amostra na?o tiveram uma variac?a?o muito\ngrande. Ela ficou na casa de 3,61 milisegundos para a finalizac?a?o atrave?s da im-\n\n\n\n83\n\nplementac?a?o OpenPBS JM-SI e 2,54 milisegundos atrave?s da operac?a?o direta da\nferramenta OpenPBS. Em termos percentuais, estes valores representam uma va-\nriac?a?o nos tempos de execuc?a?o das amostras de 2,59% e 5,03% em relac?a?o a? me?dia,\nrespectivamente, aos tipos de experimentos.\n\nDa mesma forma como constatado nas demais operac?o?es, percebe-se que o overhead,\nimposto pelo ambiente ICE, pode ser tolerado visto a facilidade que ele insere.\n\n5.2.7 Experimentos com a operac?a?o de visualizac?a?o de status\n\nA visualizac?a?o do status das aplicac?o?es consiste na listagem de todas as aplicac?o?es\nque esta?o presentes nas filas dos gerenciadores. A Tabela 5.7 possui os dados ob-\ntidos com os experimentos de visualizac?a?o dos status das aplicac?o?es para ambas\nferramentas e implementac?o?es das JM-SIs.\n\nTabela 5.7: Desempenho da operac?a?o de verificac?a?o do status das aplicac?o?es\n\nMe?dia Desvio Padra?o Percentual\nOpenPBS JM-SI 123,22 3,9 3,17\nOpenPBS 36,34 0,99 2,73\nOAR JM-SI 857,67 6,77 0,79\nOAR 765,92 12,95 1,69\n\nAtrave?s da ana?lise dos tempos das ferramentas de gerenciamento percebe-se que\no gerenciador OpenPBS apresenta um desempenho superior ao verificado com o\nOAR. Eles possuem, respectivamente, os tempos me?dios de execuc?a?o de 36,34 e\n765,92 milisegundos.\n\nAssim como em experimentos anteriores, a ana?lise dos experimentos sobre a\nplataforma OpenPBS mostrou, mais uma vez, que a implementac?a?o OpenPBS JM-\nSI apresentou um tempo de execuc?a?o me?dio tre?s vezes maior do que o da execuc?a?o\ndireta. Os valores mostrados na Tabela 5.7 mostram que a implementac?a?o OpenPBS\nJM-SI apresentou um tempo me?dio de 123,22 milisegundos, enquanto a execuc?a?o\ndireta utilizou 36,34 milisegundos. O overhead medido ficou em 86,88 milisegundos.\n\nNo caso dos experimentos com a ferramenta OAR, verificou-se que o tempo\nde execuc?a?o dessa operac?a?o, diretamente pelo OAR, foi de 765,92 milisegundos,\nenquanto o tempo de execuc?a?o, via implementac?a?o OAR JM-SI, foi igual a 857,67\nmilisegundos. O overhead inserido foi de 91,75 milisegundos.\n\nComparando os tempos das execuc?o?es diretas das ferramentas com as imple-\nmentac?o?es das JM-SI, pode-se observar que se obteve o mesmo comportamento da\noperac?a?o de finalizac?a?o. Isto e?, a implementac?a?o OpenPBS JM-SI apresentou uma\ndiferenc?a de tempo de execuc?a?o maior, se comparada com a verificac?a?o do estado, di-\nretamente via ferramenta, do que na implementac?a?o OAR JM-SI. E da mesma forma\ncomo as demais operac?o?es comparadas com as execuc?o?es diretas das ferramentas,\npode-se considerar que os tempos despendidos pelas implementac?o?es JM-SI, para\noperac?a?o de verificac?a?o dos estado das filas, e? compensador.\n\n5.2.8 Experimentos com a operac?a?o de recuperac?a?o das sa??das padra?o\n\nA operac?a?o de recuperac?a?o de informac?a?o das sa??das padra?o na?o possui corres-\npondente nos gerenciadores, visto que o arquivo pode ser visualizado pelo usua?rio\n\n\n\n84\n\nem sua pro?pria conta. Sendo assim, a Tabela 5.8 apresenta os resultados alcanc?ados\ncom a avaliac?a?o da execuc?a?o das implementac?o?es JM-SI do ICE para cada uma das\nferramentas.\n\nTabela 5.8: Desempenho da operac?a?o de recuperac?a?o das sa??das padra?o\n\nMe?dia Desvio Padra?o Percentual\nOpenPBS JM-SI 11,28 2,54 22,5\nOAR JM-SI 10,74 0,74 6,93\n\nAnalisando os tempos me?dios apresentados na Tabela 5.8, verifica-se que os\ndois JM-SI apresentam um resultado muito semelhante. Como neste caso a infra-\nestrutura ICE na?o precisa interagir com os gerenciadores, a diferenc?a de tempo exis-\ntente entre eles e? decorrente, unicamente, das diferenc?as entre as implementac?o?es das\nJM-SIs e tambe?m da carga do front-end no momento dos experimentos. No caso do\nOpenPBS JM-SI sa?o gastos em me?dia 11,28 milisegundos, enquanto no OAR JM-SI\nsa?o necessa?rios 10,74 milisegundos para recuperar a informac?a?o dos arquivos.\n\nPara evitar que o tamanho do arquivo recuperado interferisse nas medic?o?es re-\nalizadas, optou-se por utilizar um arquivo vazio. Assim o tempo gasto para ler as\nlinhas dos arquivos na?o foi computada neste experimento. Os resultados apresen-\ntados na Tabela 5.8 representam exatamente o overhead que a infra-estrutura ICE\nnecessita para recuperar arquivos.\n\n5.3 Resumo\n\nEste cap??tulo foi dividido em dois momentos. O primeiro conte?m uma ana?lise\ncomparativa entre o ambiente ICE, proposto neste trabalho, e algumas ferramentas\nrelacionadas que possuem o mesmo escopo de aplicac?a?o. Para tanto foram escolhi-\ndas duas ferramentas, que se enquadravam nestas caracter??sticas, para serem com-\nparadas com o ICE, as quais sa?o: HPC2N e M3C. A comparac?a?o teve como base\nos crite?rios estabelecidos por Coulouris em (COULOURIS; DOLLIMORE; KIND-\nBERG, 2005) como sendo os desafios da construc?a?o de um sistema distribu??do.\nAlguns dos crite?rios adotados foram: transpare?ncia, extensibilidade, portabilidade,\nseguranc?a entre outros. No segundo momento foi apresentada uma ana?lise quantita-\ntiva do ambiente ICE, onde foram verificados os tempos de execuc?a?o dos provedores\ndo servic?o de gerenciamento de aplicac?o?es, implementados e disponibilizados no am-\nbiente. Conforme esperado, o ambiente ICE inseriu um certo overhead na execuc?a?o\ndas operac?o?es, se comparado com a execuc?a?o das operac?o?es diretamente atrave?s da\nferramenta. Em alguns casos, o aumento foi significativo, principalmente nos experi-\nmentos realizados sobre a ferramenta OpenPBS. Entretanto, esse aumento no tempo\nde processamento na?o chega ser um fator limitante para a utilizac?a?o do ambiente\nICE, visto que os objetivos principais do ambiente ICE sa?o prover: transpare?ncia\ndas operac?o?es de mais baixo n??vel a seus usua?rios, extensibilidade e flexibilidade.\nPortanto, o overhead das operac?o?es, disponibilizadas por ele, na?o e? um crite?rio deci-\nsivo para definir a adoc?a?o ou na?o do ambiente ICE. Ele serve como um indicativo do\ncusto/benef??cio que se deseja oferecer aos usua?rios do ambiente de alto desempenho.\n\n\n\n85\n\n6 CONCLUSA?O\n\nO ambiente ICE - Integrated Cluster Environment - foi proposto com base em\naspectos que ainda na?o tinham sido considerados pelas ferramentas atuais de ge-\nrenciamento de mu?ltiplos clusters, como por exemplo: interoperabilidade, extensi-\nbilidade, integrac?a?o de sistemas legados, transpare?ncia, entre outros. O foco deste\nambiente e? prover gerenciamento e acesso a mu?ltiplos clusters de forma transpa-\nrente, extens??vel e interopera?vel. Como apresentado no Cap??tulo 3, o ambiente ICE\ntem uma se?rie de objetivos, mas se pode considerar que aqueles que o distinguem\ndos demais ambientes sa?o: (i) capacidade de uniformizac?a?o do modo como as ferra-\nmentas de clusters sa?o utilizadas e, tambe?m, a uniformizac?a?o na maneira como os\nclusters sa?o acessados; (ii) transpare?ncia de acesso e uso dos clusters; e (iii) capa-\ncidade de extensibilidade em dois n??veis: o primeiro refere-se a? extensibilidade do\nnu?mero de funcionalidades (servic?os) providas pelo sistema e o segundo esta? relaci-\nonado com a capacidade do sistema lidar com o uso de diferentes ferramentas que\npossuem a mesma funcionalidade. Estas principais capacidades podem ser providas\npelo ambiente ICE devido ao tipo de arquitetura e ao tipo de middleware adotados\nneste ambiente. Optou-se por utilizar uma arquitetura orientada a servic?os (SOA) e\ncomo middleware utilizou-se Web Services. As principais razo?es para estas escolhas\nsa?o: o fato da arquitetura SOA poder separar a implementac?a?o de um servic?o de\nsua interface; e Web Services ser uma tecnologia baseada em arquitetura SOA e em\npadro?es Web, os quais ja? esta?o estabelecidos e amplamente utilizados. Estas ca-\nracter??sticas sa?o fundamentais para a modelagem e o desenvolvimento do ambiente\nICE. E? importante ressaltar que o ambiente ICE na?o e? apenas um portal ou enta?o\num sistema rodando no front-end de um cluster. O ambiente ICE e? a unia?o entre o\nponto u?nico de acesso dos usua?rios com o middlware definido para o gerenciamento\ne acesso das funcionalidades dos clusters.\n\nUma caracter??stica principal da arquitetura ICE e? sua modularidade. O objetivo\ne? que se possam inserir novas funcionalidades e novas ferramentas sem que isso al-\ntere o modelo do ambiente ICE. A ide?ia, por tra?s da arquitetura do ambiente ICE,\ne? fazer com que existam mo?dulos ba?sicos do sistema e uma infra-estrutura capaz de\nprover servic?os de clusters. Com base nestas caracter??sticas, definiu-se a arquitetura\ndo ambiente ICE, a qual e? formada por dois componentes: Middleware de Servic?os\ne Portal Web. No Middleware de Servic?os sa?o considerados os aspectos ligados a?\narquitetura SOA empregada no ambiente ICE. Este componente e? formado pelos\nseguintes mo?dulos: Unified Service Interface (USI), Service Implementation (SI), e\nService Module (SM). Uma USI e? um mo?dulo conceitual, onde o servic?o e? especi-\nficado em alto n??vel. O SI e? um mo?dulo que deve ser desenvolvido de acordo com\numa USI. Ele e? a implementac?a?o do provedor de um servic?o. O SM caracteriza-se\n\n\n\n86\n\npor ser a implementac?a?o do consumidor de um servic?o, tambe?m especificado por\numa USI e que fara? as requisic?o?es ao respectivo SI. O Portal Web e? formado por\ntre?s mo?dulos: Service Management Module (SMM), Security Module (SecM) e Ser-\nvice Module (SM). O SMM e? responsa?vel pela lo?gica de controle do sistema Web.\nNo SecM sa?o definidas as ac?o?es para o controle de autenticac?a?o e autorizac?a?o do\nambiente ICE. O SM e? responsa?vel pela apresentac?a?o, no Portal Web, dos dados\nprovenientes da porc?a?o SM pertencente ao Middleware de Servic?o. Para cada fun-\ncionalidade de cluster, que se deseja inserir no ambiente ICE, e? preciso a criac?a?o da\ninfra-estrutura de servic?os e o registro das informac?o?es desta nova funcionalidade no\nPortal Web.\n\nO suporte para extensibilidade, transpare?ncia e capacidade de integrac?a?o com\nsistemas legados, projetado na arquitetura ICE, po?de ser comprovado na imple-\nmentac?a?o de um proto?tipo do ambiente ICE (Cap??tulo 4). Neste proto?tipo foram\ndesenvolvidas as estruturas ba?sicas do Portal Web e foi provido o suporte para a fun-\ncionalidade de gerenciamento de aplicac?o?es (Job Management - JM). Foi definida\numa USI para esta funcionalidade (JM-USI) e foram desenvolvidos dois provedo-\nres deste servic?o (JM-SIs) e um consumidor (JM-SM). Os JM-SIs desenvolvidos\nlevaram em considerac?a?o a integrac?a?o dos clusters existentes no Grupo de Proces-\nsamento Paralelo e Distribu??do (GPPD) do Instituto de Informa?tica da UFRGS. O\ncluster denominado gppd possui o OpenPBS como ferramenta de gerenciamento de\naplicac?o?es, enquanto o cluster denominado frontal-minuano possui a ferramenta\nOAR para tal finalidade.\n\nNo Cap??tulo 4 foram explorados os detalhes da definic?a?o da USI desta funcionali-\ndade; foi especificado um framework para dar suporte a? extensa?o da funcionalidade\nde gerenciamento de aplicac?o?es para diferentes ferramentas, o qual foi denominado\nJob Management Framework (JMF); foram detalhadas as implementac?o?es dos pro-\nvedores deste servic?o, denominadas OpenPBS JM-SI e OAR JM-SI, e do consumidor,\ndenominado (JM-SM). Ale?m da descric?a?o completa dos componentes do Middleware\nde Servic?os, neste cap??tulo, tambe?m foram apresentadas as estruturas que formam\no Portal Web; o modelo de informac?a?o definido para armazenar os dados e os relaci-\nonamentos dos mo?dulos que compo?em o ambiente ICE; e foram ilustradas algumas\ntelas do proto?tipo desenvolvido com alguns dos processos de configurac?a?o e uti-\nlizac?a?o, atualmente disponibilizados neste ambiente.\n\nNo intuito de comparar o ambiente ICE com alguns ambientes voltados para o\nmesmo fim (gerenciamento de mu?ltiplos clusters), foram realizadas comparac?o?es\nentre estes ambientes. Estas comparac?o?es levaram em considerac?a?o os desafios\npara a construc?a?o de sistemas distribu??dos apresentados por Coulouris em (COU-\nLOURIS; DOLLIMORE; KINDBERG, 2005). A partir desta comparac?a?o direta,\npo?de-se verificar que o ambiente ICE, dentre os ambientes comparados (M3C e\nHPC2N), possui o maior grau de extensibilidade, interoperabilidade e capacidade\nde lidar com sistemas legados. Ale?m da comparac?a?o das caracter??sticas do ambi-\nente tambe?m verificou-se qual o overhead inserido pela infra-estrutura do ambiente\nICE nos processos de gerenciamento de aplicac?o?es. A comparac?a?o foi realizada en-\ntre a execuc?a?o direta dos comandos das ferramentas OpenPBS e OAR, instalados\nno cluster frontal-minuano, e a execuc?a?o das operac?o?es das respectivas imple-\nmentac?o?es dos mo?dulos JM-SIs, instalados no mesmo cluster. Apesar de existir a\npossibilidade de utilizac?a?o dos dois clusters do GPPD, optou-se por instalar a ferra-\nmenta OpenPBS tambe?m no cluster frontal-minuano para que se pudesse realizar\n\n\n\n87\n\na comparac?a?o direta entre as ferramentas e as implementac?o?es JM-SI.\nConforme esperado, verificou-se a existe?ncia de um overhead, que em alguns\n\ncasos mostrou-se significativo. Analisando os resultados, pode-se dizer, de maneira\ngeral, que a implementac?a?o OpenPBS JM-SI apresenta um tempo de execuc?a?o tre?s\nvezes maior, se comparado com a execuc?a?o via ferramenta OpenPBS diretamente.\nConsiderando os experimentos que utilizaram a ferramenta OAR percebeu-se um\naumento no tempo de execuc?a?o. Entretanto, este aumento na?o ocorreu somente no\ntempo de execuc?a?o da implementac?a?o OAR JM-SI. A execuc?a?o direta das operac?o?es\ndo OAR possuem um tempo maior comparando-se com o OpenPBS. Isto se deve a?s\ndiferenc?as de construc?a?o e concepc?a?o dessas ferramentas. Atrave?s dos experimentos\nrealizados, percebeu-se que o tempo de execuc?a?o das implementac?o?es JM-SI, assim\ncomo o overhead inserido pelo ambiente ICE, dependem muito da ferramenta de\ngerenciamento de aplicac?o?es sobre a qual o mo?dulo e? constru??do. Outra conclusa?o\nesta? na relac?a?o custo/benef??cio que o ambiente ICE proporciona aos seus usua?rios.\nAcredita-se que, ainda, e? mais vantajoso para os usua?rios gastarem um pouco mais\nde tempo utilizando o ambiente ICE do que realizando as operac?o?es diretamente\natrave?s das ferramentas, onde, apesar de economizarem alguns segundos, teriam\nque lidar com as especificidades de cada ferramenta.\n\nEnfim, atrave?s da definic?a?o do ambiente ICE, de sua arquitetura bastante mo-\ndular e extens??vel e do desenvolvimento de um proto?tipo, po?de-se constatar que e?\nvia?vel a construc?a?o de um sistema de gerenciamento e acesso a mu?ltiplos clusters,\nque seja capaz de lidar com as especificidades de diferentes clusters e de suas di-\nferentes ferramentas de maneira transparente e interopera?vel. Ale?m disso, tambe?m\nverificou-se que na?o houve a necessidade de mudar a infra-estrutura ja? estabelecida\nno cluster do GPPD, onde o ambiente ICE esta? em operac?a?o. Esta caracter??stica\ne? bastante relevante, pois isso, mais uma vez, mostra a flexibilidade da arquitetura\nproposta e da implementac?a?o realizada.\n\nA partir da infra-estrutura ba?sica, definida e implementada nesta dissertac?a?o,\nverificou-se a existe?ncia de espac?o para estender o ambiente, inserindo novas funci-\nonalidades e suportando diferentes ferramentas. Sendo assim, foram desenvolvidos\nalguns trabalhos em paralelo com base no trabalho descrito nesta dissertac?a?o, e\ntambe?m foram identificados outros trabalhos para serem futuramente realizados. A\nseguir esses trabalhos sa?o apresentados.\n\n6.1 Trabalhos em Paralelo\n\nDentre os trabalhos em paralelo, que esta?o sendo realizados, citam-se os seguin-\ntes:\n\n\u2022 incorporac?a?o dos mecanismos de seguranc?a desenvolvidos no trabalho realizado\npor Alexandre Ilha em (ILHA, 2005), onde um framework de seguranc?a para\no ambiente ICE foi definido com base na arquitetura proposta neste trabalho;\n\n\u2022 incorporac?a?o da funcionalidade de monitoramento de aplicac?o?es e recursos de\nclusters;\n\n\u2022 sistema de upload de arquivos para os front-end dos clusters.\n\n\u2022 implementac?a?o do ambiente ICE, levando em considerac?a?o o modelo MVC\n(Model View Controller );\n\n\n\n88\n\n\u2022 porte da implementac?a?o atual para uma versa?o mais robusta utilizando tec-\nnologias J2EE;\n\nAs quatro u?ltimas atividades listadas, assim como o desenvolvimento do mo?dulo\nde gerenciamento de aplicac?o?es desta dissertac?a?o, foram realizadas no a?mbito do\nprojeto Java-WSPAD (Java - Web Services para Processamento de Alto Desempe-\nnho) (PORTAL DO PROJETO JAVA-WSPAD, 2006), cujo obejtivo e? a construc?a?o\nde uma plataforma para a computac?a?o distribu??da de alto desempenho, baseada em\nWeb Services e Peer-to-Peer.\n\nAtrave?s do desenvolvimento destes trabalhos, os integrantes do grupo GPPD\nconseguiram inserir, na plataforma ba?sica do ambiente ICE, outras funcionalidades\nde maneira bastante modular. Estas novas funcionalidades contribuem para que se\nconsiga ter o ambiente completo de gerenciamento e acesso de mu?ltiplos clusters\nalmejado na proposta desta dissertac?a?o.\n\n6.2 Trabalhos Futuros\n\nComo trabalhos futuros, alguns podem ser citados:\n\n\u2022 prover suporte para um nu?mero maior de ferramentas de gerenciamento de\nclusters;\n\n\u2022 prover suporte para lanc?amento de aplicac?o?es paralelas, baseadas em ou-\ntras bibliotecas e ambientes paralelos, como por exemplo: LAN-MPI, PVM,\ncJAVA (SILVA; LOBOSCO; AMORIM, 2003; LOBOSCO; LOQUES; AMO-\nRIM, 2005), etc;\n\n\u2022 definic?a?o de servic?os de gerenciamento administrativo de clusters, isto e?, per-\nmitir que os administradores dos clusters possam realizar intervenc?o?es de con-\nfigurac?a?o nos clusters por eles gerenciados a partir do ambiente ICE;\n\nAinda como um trabalho futuro, mas na?o ligado diretamente a? implementac?a?o\ndo ambiente, pretende-se colocar este ambiente em um centro de pesquisa formado,\nbasicamente, por usua?rios que na?o sa?o nativos da a?rea de computac?a?o. O objetivo\ndesta avaliac?a?o e? perceber quais as dificuldades que esses usua?rios possuem ao inte-\nragir com o ambiente ICE e, atrave?s do feedback dos mesmos, melhora?-lo. Enfim,\nde maneira geral, pode-se dizer que o ambiente ICE possui uma base so?lida para\nser estendido e melhorado a fim de se tornar um ambiente amplamente utilizado no\ncena?rio de mu?ltiplos cluster.\n\n\n\n89\n\nREFERE?NCIAS\n\nABBAS, A. (Ed.). Grid Computing: a practical guide to technology and applica-\ntions. [S.l.]: Charles River Media, 2004. 408p.\n\nADABALA, S.; KAPADIA, N. H.; FORTES, J. A. B. Performance and intero-\nperability issues in incorporating cluster management systems within a wide-area\nnetwork-computing environment. In: ACM/IEEE CONFERENCE ON SUPER-\nCOMPUTING, 2000, Dallas, Texas, USA. Proceedings. . . Washington: IEEE\nComputer Society, 2000. 1 CD-ROM.\n\nALONSO, G. et al. Web Services: conepts, architectures and applications. [S.l.]:\nSpringer, 2004. 354p.\n\nALVES, R. S.; MARQUEZAN, C. C.; GRANVILLE, L. Z. Experiences in the Im-\nplementation of an SNMP-Based High Performance Cluster Management System.\nIn: IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS, ISCC 9.,\n2004, Alexandria, Egito. Proceedings. . . [S.l.]: IEEE Computer Society, 2004.\n\nALVES, R. S.; MARQUEZAN, C. C.; GRANVILLE, L. Z.; NAVAUX, P. O. A.\nHigh Performance Cluster Management Based on SNMP: experiences on integra-\ntion between network patterns and cluster management concepts. In: INTERNATI-\nONAL CONFERENCE ON TELECOMMUNICATIONS, ICT, 2004, Fortaleza. Te-\nlecommunications and Networking - ICT, 2004: Proceedings. Berlin: Sprin-\nger, 2004. p.782\u2013791. (Lecture Notes in Computer Science, v.3124).\n\nALVES, R. S.; MARQUEZAN, C. C.; GRANVILLE, L. Z.; NAVAUX, P. O. A. In-\ntegrac?a?o do Gerenciamento de Clusters de Alto Desempenho com o Gerenciamento\nde Redes atrave?s de Soluc?a?o baseada em SNMP. In: SIMPo?SIO BRASILEIRO DE\nREDES DE COMPUTADORES, SBRC, 23., 2005, Fortaleza, Brasil. Anais. . . For-\ntaleza: Sociedade Brasileira de Computac?a?o, 2005. p.3\u201316.\n\nANDRADE, N. et al. OurGrid: an approach to easily assemble grids with equitable\nresource sharing. In: JOB SCHEDULING STRATEGIES FOR PARALLEL PRO-\nCESSING, 2003. Proceedings. . . Berlin: Springer, 2003. p.61\u201386. (Lecture Notes\nin Computer Science, v.2862).\n\nANDRONICO, G. et al. The GENIUS web portal: grid computing made easy. In:\nINTERNATIONAL SYMPOSIUM ON INFORMATION TECHNOLOGY. ITCC,\n2003. Proceedings. . . [S.l.]: IEEE Computer Society, 2003. p.425\u2013431.\n\n\n\n90\n\nAPACHE AXIS2, A. W. to. Dispon??vel em: ?http://ws.apache.org/axis2/?.\nAcesso em: nov. 2005.\n\nAPACHE TOMCAT - The Apache Software Foundation. Dispon??vel em: ?http:\n//tomcat.apache.org/?. Acesso em: maio 2006.\n\nAUMAGE, O. Heterogeneous Multi-Cluster Networking with the Madeleine III\nCommunication Library. In: INTERNATIONAL PARALLEL AND DISTRIBU-\nTED PROCESSING SYMPOSIUM, IPDPS, 2002. Proceedings. . . [S.l.]:IEEE\nComputer Society, 2002.\n\nBAKER, M. Cluster Computing White Paper. Dispon??vel em: ?http://dsg.\nport.ac.uk/?mab/Links/tfcc/WhitePaper/final-paper.pdf?. Acesso em: dez.\n2005.\n\nBAKER, M. et al. Emerging Grid Standards. IEEE Computer, [S.l.], v.38, n.4,\np.43\u201350, Apr. 2005.\n\nBAKER, M.; SMITH, G. GridRM: an extensible resource monitoring system.\nIn: IEEE INTERNATIONAL CONFERENCE ON CLUSTER COMPUTING,\n2003, Tsim Sha Tsui, Kowloon, Hong Kong. Proceedings. . . [S.l.: s.n.], 2003.\np.207\u2013 214. Dispon??vel em: ?http://ieeexplore.ieee.org/iel5/8878/28041/\n01253317.pdf?tp=&amp;arnumber=1253317&amp;isnumber=28041?. Acesso em: dez. 2005.\n\nBARRETO, M.; A?VILA, R.; NAVAUX, P. The MultiCluster Model to the Integra-\nted Use of Multiple Workstation Clusters. In: WORKSHOP ON PERSONAL COM-\nPUTER BASED NETWORKS OF WORKSTATIONS, 3., 2000, Cancun. Procee-\ndings. . . Berlin: Springer-Verlag, 2000. p.71\u201380. (Lecture Notes in Computer Sci-\nence, v.1800).\n\nBARRETO, M.; A?VILA, R.; OLIVEIRA, F. de; CASSALI, R.; NAVAUX,\nP. DECK: an enviroment for parallel programming on clusters of multipro-\ncessors. In: SYMPOSIUM ON COMPUTER ARCHITECTURE AND HIGH-\nPERFORMANCE COMPUTING - SBAC-PAD, 12., 2000, Sa?o Pedro, SP. Pro-\nceedings. . . Sa?o Carlos: UFSCAR, 2000. p.321\u2013329.\n\nBENEDYCZAK, K. et al. UNICORE as Uniform Grid Environment for Life Sci-\nences. In: EUROPEAN GRID CONFERENCE, ADVANCES IN GRID COMPU-\nTING - EGC, 2005, Amsterdam, Netherlands. Proceedings. . . [S.l.]: Springer,\n2005. p.364\u2013373. (Lecture Notes in Computer Science, v.3470).\n\nBRIM, M. et al. M3C: managing and monitoring multiple clusters. In: INTERNATI-\nONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, CCGRID,\n2001, Brisbane, Australia. Proceedings. . . [S.l.]: IEEE Computer Society, 2001.\np.386\u2013393.\n\nBRONEVETSKY, G. et al. Application-level checkpointing for shared memory\nprograms. In: INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUP-\nPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, 11.,\n2004, Boston, MA, USA. Proceedings. . . New York: ACM Press, 2004. p.235\u2013247.\n\n\n\n91\n\nBRUNO, G. et al. Rolls: modifying a standard system installer to sup-\nport user-customizable cluster frontend appliances. In: IEEE INTERNA-\nTIONAL CONFERENCE ON CLUSTER COMPUTING, 2004, San Diego,\nCalifornia, USA. Proceedings. . . [S.l.: s.n.], 2004. p.421\u2013430. Dispon??vel\nem: ?http://www.rocksclusters.org/rocks-documentation/4.1/papers/\ncluster2004-roll.pdf?. Acesso em: dez. 2005.\n\nBUYYA, R. (Ed.). High Performance Cluster Computing: architectures and\nsystems. Upper Saddle River: Prentice Hall PTR, 1999. 849p.\n\nCAPIT, N. et al. Expe?riences autour d\u2019une nouvelle approche de conception\nd\u2019un gestionnaire de travaux pour grappe. [S.l.]: HAL - CCSd - CNRS, 2003.\n\nCAPIT, N. et al. A batch scheduler with high level components. In: INTERNA-\nTIONAL SYMPOSIUM ON CLUSTER COMPUTING AND GRID, CCGRID, 5.,\n2005. Proceedings. . . [S.l.: s.n.], 2005.\n\nCASE, J. et al. A Simple Network Management Protocol (SNMP): IETF\nRFC 1098. Dispon??vel em: ?http://www.ietf.org/rfc/rfc1098.txt?number=\n1098?. Acesso em: dez. 2005.\n\nCERA, M. C.; ROSA RIGHI, R. da; PASIN, M. Alocac?a?o Dina?mica e Transparente\nde Computadores Ociosos em Java. In: WORKSHOP EM SISTEMAS COMPU-\nTACIONAIS DE ALTO DESEMPENHO, WSCAD, 6., 2005, Rio de Janeiro, RJ.\nAnais. . . Rio de Janeiro: Sociedade Brasileira de Computac?a?o, 2005.\n\nCERAMI, E. Web Services Essentials. [S.l.]: O\u2019Reilly &amp; Associates, 2002.\n\nCOOKE, A. et al. R-GMA An Information Integration System for Grid Monito-\nring. In: INTERNATIONAL CONFERENCE ON COOPERATIVE INFORMA-\nTION SYSTEMS, COOPIS, 11., 2003, Catania, Sicily, Italy. Proceedings. . .\n[S.l.: s.n.], 2003. Dispon??vel em: ?http://scholar.google.com/url?sa=U&amp;q=http:\n//www.macs.hw.ac.uk/dis4g/publications/coopis.pdf?. Acesso em: dez. 2005.\n\nCOULOURIS, G.; DOLLIMORE, J.; KINDBERG, T. (Ed.). Distributed Sys-\ntems - Concepts and Design. Fourth Edition. [S.l.]: Addison Wesley, 2005.\n832p.\n\nDAHAN, M. et al. Grid Portal Toolkit 3.0 (GridPort). In: INTERNATIONAL\nSYMPOSIUM ON HIGH-PERFORMANCE DISTRIBUTED COMPUTING, 13.,\nHPDC, 2004, Honolulu, Hawaii, USA. Proceedings. . . [S.l.]: IEEE Computer So-\nciety, 2004. p.272\u2013273.\n\nDONGARRA, J. et al. An Introduction to the MPI Standard. Knoxville, USA:\nUniversity of Tennessee, 1995. (Technical report, CS-95-274).\n\nELMROTH, E.; NYLE?N, M.; OSCARSSON, R. A User-Centric Cluster and Grid\nComputing Portal. In: ICPP WORKSHOPS, 2005. Proceedings. . . [S.l.]:IEEE\nComputer Society, 2005. p.103\u2013110.\n\nFLANERY, R. et al. Cluster command and control (CS) tools suite. In: KACSUK,\nP.; KOTSIS, G. (Ed.). Distributed and parallel systems: from instruction pa-\nrallelism to cluster computing. Norwell, MA, USA: [S.l.]: Springer, 2000. p.205\u2013214.\n\n\n\n92\n\nFOSTER, I. et al. The Physiology of the Grid: an open grid services architecture\nfor distributed systems integration. [S.l.:s.n.], 2002.\n\nFOSTER, I.; KESSELMAN, C. Globus: a metacomputing infrastructure toolkit.\nThe International Journal of Supercomputer Applications and High Per-\nformance Computing, [S.l.], v.11, n.2, p.115\u2013128, Summer 1997.\n\nFOSTER, I.; KESSELMAN, C.; TUECKE, S. The Anatomy of the Grid: enabling\nscalable virtual organizations. International Journal of High Performance\nComputing Applications, Thousand Oaks, CA, USA, v.15, n.3, p.200\u2013222, 2001.\n\nGENTZSCH, W. Sun Grid Engine: towards creating a compute power grid. In: IE-\nEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND\nTHE GRID, 1., 2001, Brisbane, Australia. Proceedings. . . [S.l.]: IEEE Computer\nSociety, 2001. p.35\u201336.\n\nGLOBAL Grid Forum. Dispon??vel em: ?http://www.gridforum.org/?. Acesso em:\nnov. 2005.\n\nGLOBUS - Welcome to the Globus Toolkit Homepage. Dispon??vel em: ?http://\nwww.globus.org/toolkit/?. Acesso em: nov. 2005.\n\nGLOBUS Toolkit 4.0 Release Manuals. Dispon??vel em: ?http://www.globus.org/\ntoolkit/docs/4.0/key/?. Acesso em: nov. 2005.\n\nGONZ, F. J. et al. Condor grid computing from mobile handheld devices. SIGMO-\nBILE Mob. Comput. Commun. Rev., New York, NY, USA, v.6, n.2, p.18\u201327,\n2002.\n\nGRANVILLE, L.; TAROUCO, L. QAME - QoS-aware management environ-\nment. In: COMPUTER SOFTWARE AND APPLICATIONS CONFERENCE,\nCOMPSAC, 25., 2001, Chicago, Illinois, USA. Proceedings. . . [S.l.: s.n.], 2001.\np.269\u2013274. Dispon??vel em: ?http://ieeexplore.ieee.org/iel5/7609/20754/\n00960627.pdf?tp=&amp;arnumber=960627&amp;isnumber=20754?. Acesso em: dez. 2005.\n\nGRIMES, R. Professional DCOM Programming. [S.l.]: Birmingham, UK:\nWrox, 1997.\n\nGRIMSHAW, A. S.; NATRAJAN, A. Legion: lessons learned building a grid ope-\nrating system. Proceedings of the IEEE, [S.l.], v.93, n.3, p.589\u2013603, 2005.\n\nGT 4.0 WS GRAM. Dispon??vel em: ?http://www-unix.globus.org/toolkit/\ndocs/4.0/execution/wsgram/?. Acesso em: dez. 2005.\n\nHADDAD, I. F. PVFS: a parallel virtual file system for linux clusters. Linux Jour-\nnal, Seattle, WA, USA, v.2000, n.80es, p.5, 2000.\n\nHANSEN, S.; FOSSUM, T. V. Refactoring model-view-controller. Journal of\nComputing Sciences in Colleges, USA, v.21, n.1, p.120\u2013129, 2005.\n\nILHA, A. S. Uso de Web Services no Controle de Acesso a Clusters.\n2005. Trabalho de Conclusa?o (Cie?ncia da Computac?a?o) - Instituto de Informa?tica,\nUFRGS, Porto Alegre.\n\n\n\n93\n\nJAVA Platform, Standard Edition (Java SE). Dispon??vel em: ?http://java.sun.\ncom/javase/index.jsp?. Acesso em: maio 2006.\n\nJAVA SERVLET Technology. Dispon??vel em: ?http://java.sun.com/products/\nservlet/?. Acesso em: maio 2006.\n\nJAVASERVER Pages Technology. Dispon??vel em: ?http://java.sun.com/\nproducts/jsp/?. Acesso em: maio 2006.\n\nKASSICK, R.; MACHADO, C.; HERMANN, E.; A?VILA, R.; NAVAUX, P.; DEN-\nNEULIN., Y. Evaluating the performance of the dNFSP file system. In: IEE-\nE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND\nTHE GRID, CCGRID, 5., 2005, Cardiff, UK. Proceedings. . . [S.l.: s.n.], 2005.\n\nKELLER, A.; REINEFELD, A. CCS resource management in networked HPC sys-\ntems. In: HETEROGENEOUS COMPUTING WORKSHOP, HCW, 7., 1998, Or-\nlando, Florida. Proceedings. . . [S.l.: s.n.], 1998. p.44\u201356.\n\nLI, M.; BAKER, M. The Grid Core Technologies. [S.l.]: John Wiley &amp; Sons,\n2005. 423p.\n\nLI, M. et al. PortalLab: a web services toolkit for building semantic grid portals.\nIn: INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE\nGRID, 3., CCGRID, 2003, Tokyo, Japan. Proceedings. . . [S.l.]: IEEE Computer\nSociety, 2003. p.190\u2013197.\n\nLIGNERIS, B. des et al. Open Source Cluster Application Resources (OS-\nCAR): design, implementation and interest for the Computer scientific community.\nWhite paper. Dispon??vel em: ?http://www.ncassr.org/projects/cluster-sec/\npapers/oscar03.pdf?. Acesso em: dez. 2005.\n\nLOBOSCO, M.; LOQUES, O.; AMORIM, C. L. de. Reducing Memory Sharing\nOverheads in Distributed JVMs. In: INTERNATIONAL CONFERENCE HIGH\nPERFORMANCE COMPUTING AND COMMUNICATIONS, HPCC, 1., 2005,\nSorrento, Italy. Proceedings. . . [S.l.]: Springer, 2005. p.629\u2013639. (Lecture Notes\nin Computer Science, v.3726).\n\nMARQUEZAN, C. C.; ROSA RIGHI, R. da; SCHNORR, L.; CARISSIMI, A.;\nMAILLARD, N.; NAVAUX, P. O. A. ICE: a service oriented approach to uniform\nthe access and management of cluster environments. In: IEEE INTERNATIONAL\nSYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, CCGRID, 6., 2006,\nSingapore. Proceedings. . . [S.l.]:IEEE Computer Society, 2006. 1 CD-ROM.\n\nMAUI Scheduler Open Cluster Software. Dispon??vel em: ?http://mauischeduler.\nsourceforge.net/?. Acesso em: dez. 2005.\n\nMCGOVERN, J. et al. Java Web Services Architecture. [S.l.]: Morgan Kauf-\nmann, 2003. 833p.\n\nNAKADA, H. et al. The design and implementation of a fault-tolerant RPC\nsystem: ninf-c. In: INTERNATIONAL CONFERENCE ON HIGH PERFOR-\nMANCE COMPUTING AND GRID IN ASIA PACIFIC REGION, 7., 2004,\n\n\n\n94\n\nOmiya Sonic City, Tokyo Area, Japan. Proceedings. . . [S.l.: s.n.], 2004. p.9\u2013\n18. Dispon??vel em: ?http://ieeexplore.ieee.org/iel5/9244/29307/01324011.\npdf?tp=&amp;arnumber=1324011&amp;isnumber=29307?. Acesso em: dez. 2005.\n\nNOVOTNY, J.; RUSSELL, M.; WEHRENS, O. GridSphere: an advanced portal\nframework. In: EUROMICRO CONFERENCE, 30., 2004, Rennes, France. Proce-\nedings. . . [S.l.]: IEEE Computer Society, 2004. p.412\u2013419.\n\nOASIS - Advancing E-Business Standards Since 1993. Dispon??vel em: ?http://www.\noasis-open.org/home/index.php?. Acesso em: nov. 2005.\n\nOASIS-WS - OASIS Committees by Category: web services. Dispon??vel em: ?http:\n//www.oasis-open.org/committees/tc cat.php?cat=ws?. Acesso em: nov. 2005.\n\nOPENSCE - Scalable Cluster Environment. Dispon??vel em: ?http://opensce.org?.\nAcesso em: dez. 2005.\n\nOSCAR - Open Source Cluster Application Resources. Dispon??vel em: ?http://\noscar.openclustergroup.org/?. Acesso em: dez. 2005.\n\nOU, L.; HE, X. Design and Evaluation of a High Performance Parallel File System.\nIn: ANNUAL IEEE CONFERENCE ON LOCAL COMPUTER NETWORKS, 30.,\nLCN, 2005, Sydney, Australia. Proceedings. . . [S.l.]: IEEE Computer Society,\n2005. p.100\u2013105.\n\nPAPADOPOULOS, P. M.; KATZ, M. J.; BRUNO, G. NPACI Rocks Clusters: tools\nfor easily deploying and maintaining manageable high-performance linux clusters.\nIn: RECENT ADVANCES IN PARALLEL VIRTUAL MACHINE AND MESSAGE\nPASSING INTERFACE, PVM/MPI, 8., 2001, Santorini/Thera, Greece. Proce-\nedings. . . [S.l.]: Springer, 2001. p.10\u201311. (Lecture Notes in Computer Science,\nv.2131).\n\nPARK, I. et al. Towards an integrated, web-executable parallel programming tool\nenvironment. In: ACM/IEEE CONFERENCE ON SUPERCOMPUTING, 2000,\nDallas, Texas, USA. Proceedings. . . Washington: IEEE Computer Society, 2000.\n1 CD-ROM.\n\nPORTABLE Batch System. Dispon??vel em: ?http://www.openpbs.org/?. Acesso\nem: nov. 2005.\n\nPORTAL do Projeto Java-WSPad. Dispon??vel em: ?http://www.lcp.coppe.ufrj.\nbr:9673/JavaWSPad?. Acesso em: jul. 2006.\n\nPOSTGRESQL Global Development Group. Dispon??vel em: ?http://www.\npostgresql.org/?. Acesso em: maio 2006.\n\nRED HAT - The Open Source Leader. Dispon??vel em: ?http://www.redhat.com/?.\nAcesso em: dez. 2005.\n\nRMI - Java Remote Method Invocation. Dispon??vel em: ?http://java.sun.com/\nj2se/1.4.2/docs/guide/rmi/spec/rmiTOC.html?. Acesso em: dez. 2005.\n\n\n\n95\n\nROCKS Cluster Distribution: users guide. Dispon??vel em: ?http:\n//www.rocksclusters.org/rocks-documentation/4.1/introduction.html?.\nAcesso em: dez. 2005.\n\nSACERDOTI, F. D. et al. Wide Area Cluster Monitoring with Ganglia. In: IEEE\nINTERNATIONAL CONFERENCE ON CLUSTER COMPUTING, CLUSTER,\n2003, Hong Kong. Proceedings. . . [S.l.: s.n.], 2003. p.289\u2013298.\n\nSCHULZ, M. et al. Implementation and Evaluation of a Scalable Application-Level\nCheckpoint-Recovery Scheme for MPI Programs. In: ACM/IEEE CONFERENCE\nON SUPERCOMPUTING, 2004, Washington, DC, USA. Proceedings. . . [S.l.]:\nIEEE Computer Society, 2004. 1 CD-ROM.\n\nSIEGEL, J. CORBA Fundamentals and Programming. [S.l.]: John Wiley &amp;\nSons, 1996.\n\nSILVA, A. F. da; LOBOSCO, M.; AMORIM, C. L. de. An Evaluation of cJava\nSystem Architecture. In: SYMPOSIUM ON COMPUTER ARCHITECTURE AND\nHIGH PERFORMANCE COMPUTING, SBAC-PAD, 15., 2003, Sa?o Paulo, SP, BR.\nProceedings. . . [S.l.]: IEEE Computer Society, 2003. p.91\u201399.\n\nSOTTILE, M. J.; MINNICH, R. G. Supermon: a high-speed cluster monitoring\nsystem. In: IEEE INTERNATIONAL CONFERENCE ON CLUSTER COMPU-\nTING, 2002, Chicago, Illinois. Proceedings. . . [S.l.]: IEEE Computer Society,\n2002. p.39\u201346.\n\nSTERLING, T. An Introduction to PC Clusters for High Performance\nComputing. Cap??tulo 1 do white-paper entitulado Cluster Computing White Pa-\nper, editado por Mark Baker. Dispon??vel em: ?http://dsg.port.ac.uk/?mab/\nLinks/tfcc/WhitePaper/final-paper.pdf?. Acesso em: dez. 2005.\n\nSUNDERAM, V. PVM: a framework for parallel distributed computing. Concur-\nrency: Practice and Experience, Chichester, UK, v.2, n.4, p.315\u2013339, 1990.\n\nSUZUMURA, T. et al. GridSpeed: a web-based grid portal generation server.\nIn: INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COM-\nPUTING AND GRID IN ASIA PACIFIC REGION, 7., 2004, Omiya So-\nnic City, Tokyo Area, Japan. Proceedings. . . [S.l.: s.n.], 2004. p.26\u201333. Dis-\npon??vel em: ?http://ieeexplore.ieee.org/iel5/9244/29307/01324013.pdf?\ntp=&amp;arnumber=1324013&amp;isnumber=29307?. Acesso em: dez. 2005.\n\nSYSTEM Imager. Dispon??vel em: ?http://www.systemimager.org/?. Acesso em:\ndez. 2005.\n\nTHAIN, D.; LIVNY, M. Building Reliable Clients and Servers. In: FOSTER, I.;\nKESSELMAN, C. (Ed.). The Grid: blueprint for a new computing infrastructure.\n[S.l.]: Morgan Kaufmann, 2003.\n\nTHAIN, D.; TANNENBAUM, T.; LIVYN, L. Condor and the Grid. Cap??tulo 11\ndo livro entitulado G?rid Computing - Making the Global Infrastructure a Reality.?.\nEditado por F. Berman, A. Hey e G. Fox. Publicado por John Wiley &amp; Sons. Dis-\npon??vel em: ?http://scholar.google.com/url?sa=U&amp;q=http://searchoracle.\n\n\n\n96\n\ntechtarget.com/searchOracle/downloads/Grid Computing Chap11.pdf?.\nAcesso em: dez. 2005.\n\nTHE GLOBUS Alliance. Dispon??vel em: ?http://www.globus.org/alliance/?.\nAcesso em: nov. 2005.\n\nTHOMAS, M. et al. The GridPort Toolkit: a system for building grid portals. In:\nINTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE DISTRIBUTED\nCOMPUTING, HPDC, 10., 2001, San Francisco, CA, USA. Proceedings. . . [S.l.]:\nIEEE Computer Society, 2001. p.216\u2013227.\n\nTIERNEY, B. et al. A Grid Monitoring Architecture. White paper. Dispon??vel\nem: ?http://www-didc.lbl.gov/GGF-PERF/GMA-WG/papers/GWD-GP-16-3.pdf?.\nAcesso em: dez. 2005.\n\nTOP500 Supercomputer Sites. Dispon??vel em: ?http://www.top500.org/?. Acesso\nem: dez. 2005.\n\nUML - Unified Modeling Language. Dispon??vel em: ?http://www.uml.org/?.\nAcesso em: maio 2006.\n\nUTHAYOPAS, P.; ANGSKUN, T.; MANEESILP, J. SCE: a fully integrated soft-\nware tool for beowulf cluster system. In: LINUX CLUSTER: THE HPC REVO-\nLUTION, A CONFERENCE FOR HIGH-PERFORMANCE LINUX CLUSTER\nUSERS AND SYSTEM ADMINISTRATORS, 2001, Ubana,Illinois, USA. Procee-\ndings. . . [S.l.: s.n.], 2001.\n\nUTHAYOPAS, P.; ANGSKUN, T.; MANEESILP, J. On the Building of the\nNext Generation Integrated Environment for Beowulf Clusters. In: INTERNATIO-\nNAL SYMPOSIUM ON PARALLEL ARCHITECTURES, ALGORITHMS AND\nNETWORKS, I-SPAN, 2002, Makati City, Metro Manila, Philippines. Procee-\ndings. . . [S.l.: s.n.], 2002. p.159\u2013164.\n\nUTHAYOPAS, P.; PHATANAPHEROM, S. Fast and Scalable Real-Time Monito-\nring System for Beowulf Clusters. In: EUROPEAN PVM/MPI USER\u2019S GROUP\nMEETING ON RECENT ADVANCES IN PARALLEL VIRTUAL MACHINE\nAND MESSAGE PASSING INTERFACE, PVM/MPI, 8., 2001. Proceedings. . .\nLondon: Springer-Verlag, 2001. p.201\u2013208. (Lecture Notes in Computer Science,\nv.2131).\n\nVALLEE, G. et al. SSI-OSCAR: a cluster distribution for high performance compu-\nting using a single system image. In: INTERNATIONAL SYMPOSIUM ON HIGH\nPERFORMANCE COMPUTING SYSTEMS AND APPLICATIONS, HPCS, 19.,\n2005, Guelph,Ontario, Canada?. Proceedings. . . [S.l.: s.n.], 2005. p.319\u2013325.\n\nW3C Architecture Domain - Web Services Activity. Dispon??vel em: ?http://www.\nw3.org/2002/ws/?. Acesso em: nov. 2005.\n\nW3C World Wide Web - Leading the Web to Its Full Potential... Dispon??vel em:\n?http://www.w3.org/?. Acesso em: nov. 2005.\n\nW3C-XML BINARY - XML Binary Characterization Working Group Public Page.\nDispon??vel em: ?http://www.w3.org/XML/Binary/?. Acesso em: dez. 2005.\n\n\n\n97\n\nWELCH, V. et al. Security for Grid Services. In: IEEE INTERNATIONAL SYM-\nPOSIUM ON HIGH PERFORMANCE DISTRIBUTED COMPUTING, 12., 2003,\nSeatle, Washington. Proceedings. . . [S.l.: s.n.], 2003. p.48\u201357.\n\nZOU, H. et al. HRIC: hybrid resource information service architecture based on gma.\nIn: IEEE INTERNATIONAL CONFERENCE ON E-BUSINESS ENGINEERING,\nICEBE, 2005, Beijing, China. Proceedings. . . [S.l.: s.n.], 2005. p.541\u2013544.\n\nA?VILA, R.; NAVAUX, P.; LOMBARD, P.; LEBRE, A.; DENNEULIN, Y. Per-\nformance evaluation of a prototype distributed NFS server. In: SYMPOSIUM ON\nCOMPUTER ARCHITECTURE AND HIGH PERFORMANCE COMPUTING,\nSBAC-PAD, 16., 2004, Foz do Iguac?u, PR, BR. Proceedings. . . [S.l.]: IEEE Com-\nputer Society, 2004. p.100\u2013105."}]}}}