{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.06340"}, {"@name": "filename", "#text": "10868_Bertolini_AndreCarlos_D.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNICAMP\nANDR\u00c9 CARLOS BERTOLINI\nPROBABILISTIC HISTORY MATCHING METHODOLOGY\nFOR REAL-TIME RESERVOIR SURVEILLANCE\nMETODOLOGIA DE AJUSTE DE HIST\u00d3RICO\nPROBABIL\u00cdSTICO PARA MONITORAMENTO CONT\u00cdNUO DE\nRESERVAT\u00d3RIOS\nCAMPINAS\n2015\nii\n\nUNICAMP\tUNIVERSIDADE ESTADUAL DE CAMPINAS FACULDADE DE ENGENHARIA MEC\u00c2NICA E INSTITUTO DE GEOCI\u00caNCIAS ANDR\u00c9 CARLOS BERTOLINI\nPROBABILISTIC HISTORY MATCHING METHODOLOGY FOR\nREAL-TIME RESERVOIR SURVEILLANCE\nMETODOLOGIA DE AJUSTE DE HIST\u00d3RICO PROBABIL\u00cdSTICO PARA MONITORAMENTO CONT\u00cdNUO DE RESERVAT\u00d3RIOS\nThesis presented to the Mechanical Engineering Faculty and Geosciences Institute of the University of Campinas in partial fulfillment of the requirements for the degree of Doctor in Petroleum Sciences and Engineering in the area of Reservoirs and Management.\nTese apresentada \u00e0 Faculdade de Engenharia Mec\u00e2nica e Instituto de Geoci\u00eancias da Universidade Estadual de Campinas como parte dos requisitos exigidos para a obten\u00e7\u00e3o do t\u00edtulo de Doutor em Ci\u00eancias e Engenharia de Petr\u00f3leo na \u00e1rea de Reservat\u00f3rios e Gest\u00e3o.\nOrientador: Prof. Dr. Denis Jos\u00e9 Schiozer\nEste exemplar corresponde \u00e0 vers\u00e3o final da tese defendida pelo aluno Andr\u00e9 Carlos\nFicha catalogr\u00e1fica Universidade Estadual de Campinas Biblioteca da \u00c1rea de Engenharia e Arquitetura Elizangela Aparecida dos Santos Souza - CRB 8/8098\nBertolini, Andr\u00e9 Carlos, 1980-\nB462p Probabilistic history matching methodology for real-time reservoir surveillance / Andr\u00e9 Carlos Bertolini. - Campinas, SP : [s.n ], 2015.\nOrientador: Denis Jos\u00e9 Schiozer.\nTese (doutorado) - Universidade Estadual de Campinas, Faculdade de Engenharia Mec\u00e2nica e Instituto de Geoci\u00eancias.\n1. Reservat\u00f3rios - Simula\u00e7\u00e3o. 2. Incerteza. 3. Probabil\u00edstica. 4. Controle em tempo real. 5. Avalia\u00e7\u00e3o. I. Schiozer, Denis Jos\u00e9,1963-, II. Universidade Estadual de Campinas. Faculdade de Engenharia Mec\u00e2nica. III. T\u00edtulo.\nInforma\u00e7\u00f5es para Biblioteca Digital\nT\u00edtulo em outro idioma: Metodologia de ajuste de hist\u00f3rico probabil\u00edstico para monitoramento cont\u00ednuo de reservat\u00f3rios\nPalavras-chave em ingl\u00eas:\nReservoirs - Simulation\nUncertainty\nProbabilistic\nReal-time control\nEvaluation\n\u00c1rea de concentra\u00e7\u00e3o: Reservat\u00f3rios e Gest\u00e3o\nTitula\u00e7\u00e3o: Doutorem Ci\u00eancias e Engenharia de Petr\u00f3leo\nBanca examinadora:\nOsvair Vidal Trevisan\nRos\u00e2ngela Barros Zanoni Lopes Moreno\nR\u00e9gis Kruel Romeu\nDaniel Nunes de Miranda Filho\nData de defesa: 15-05-2015\nPrograma de P\u00f3s-Gradua\u00e7\u00e3o: Ci\u00eancias e Engenharia de Petr\u00f3leo\nUIMICAMP\nUNIVERSIDADE ESTADUAL DE CAMPINAS\nFACULDADE DE ENGENHARIA MEC\u00c2NICA\nE INSTITUTO DE GEOCI\u00caNCIAS\nTESE DE DOUTORADO\nPROBABILISTIC HISTORY MATCHING METHODOLOGY FOR\nREAL-TIME RESERVOIR SURVEILLANCE\nAutor: Andr\u00e9 Carlos Bertolini\nOrientador: Prof. Dr. Denis Jos\u00e9 Schiozer\nA banca examihadora cqmposta pelos membros abaixo aprovou esta tese:\nV.\n\nProf. Dr. Denis Jps\u00e9^S\u00e7hiozer, Presidente FEM/UNICAM\nProf. Dr. Osvair Vidal Trevisan\nFEM/UNICAMP \u201e\n\n\nProf.3 Dra. Ros\u00e2ngela Barros Zanoni Lopes Moreno FEM/UNICAMP\nDr. R\u00e9gis Kruel Ropie PETROBRAS\nDr. Daniel .Nunes de Miranda Filho'\nPETROBRAS\nI\nCampinas, 15 de maio de 2015.\nvi\nDEDICATION\nThis thesis is dedicated to my immediate family members: my mother, father, grandmother, brother, sister and especially my spouse for her patience. Thank you for all of your endless support, sacrifice, patience and love.\nviii\nACKNOWLEDGEMENTS\nI would like to express my deep gratitude and appreciation to Denis Jos\u00e9 Schiozer for his guidance, support and encouragement throughout my Master and PhD programs.\nI also wish to thank my colleagues and staff of the Petroleum Engineering Department (DEP), CEPETRO, UNISIM and all co-workers from Schlumberger.\nFinally, I would like to thank my family members, especially my parents Jos\u00e9 Eduardo and Luzia, my grandmother Rosina for the impressive and wise lessons, my brother Alexandre, and my sister Sandra. Without them, I would not have made it this far in life. They have been there for me every step of the way, loving me unconditionally, and supporting me through all tough decisions.\nI dedicate this work to my wife Fernanda, for without her full love, support, and sacrifice I would never would have achieved my full potential.\nX\n\u201cIf you can\u2019t explain it simply, you don\u2019t understand it well enough. \u201d\nAlbert Einstein\nxii\nABSTRACT\nThis work focuses on probabilistic real-time history matching to improve reservoir forecast over time. The proposed methodology uses a rigorous model evaluation, which is synchronized with history data acquisition frequency. A continuous model evaluation allows a quick model deficiency identification and reaction to start a model reparametrization process as needed. In addition, the methodology includes an uncertainty quantification technique, which uses the dynamic data to reduce reservoir uncertainties, and a step to include measurement errors and observed data tolerance margin. The real-time history matching workflow is composed of nine steps. It starts with a set of representative models selected through a probabilistic approach, the uncertainties of the reservoir and an acceptance history data range. The models are run and the results compared with the history data. The following steps are uncertainty reduction and a second model evaluation to guarantee an improved history matching. The models are then filtered to discard any model outside the acceptance range, and then used to make reservoir forecast. In the final step, the workflow searches for new data observed. The methodology also presents a novel and efficient way to support reservoir surveillance through graphical indicators of matching quality. To better control the results of all the methods, which supports the proposed methodology, a synthetic reservoir model was used in the entire work. In addition, the proposed methodology was applied in the UNISIM-I-H model, which is based on the Namorado field, located in the Campos Basin, Brazil. The performed study cases were shown that the proposed history matching procedure assimilates continuously the observed reservoir data, evaluates the model performances through quality indicators and maintains a set of calibrated reservoir models in real-time.\nKeywords: History matching, reservoir simulation, uncertainty, probabilistic approach, real-time and reservoir evaluation.\nxiv\nRESUMO\nEste trabalho prop\u00f5e uma metodologia de ajuste de hist\u00f3rico probabil\u00edstico em tempo real a fim de melhorar a previs\u00e3o do reservat\u00f3rio ao longo do tempo. A metodologia proposta utiliza uma avalia\u00e7\u00e3o rigorosa nos modelos sincronizada com a frequ\u00eancia de aquisi\u00e7\u00e3o de dados hist\u00f3ricos. Esta avalia\u00e7\u00e3o cont\u00ednua permite uma r\u00e1pida identifica\u00e7\u00e3o de defici\u00eancia do modelo e rea\u00e7\u00e3o para iniciar um processo de recaracteriza\u00e7\u00e3o conforme necess\u00e1rio. Al\u00e9m disso, a metodologia inclui uma t\u00e9cnica de quantifica\u00e7\u00e3o de incertezas utilizando os dados din\u00e2micos para reduzir as incertezas do reservat\u00f3rio, e um passo para incluir erros de medi\u00e7\u00e3o e margens de toler\u00e2ncia para os dados hist\u00f3ricos. O fluxo de trabalho da metodologia \u00e9 composto por nove etapas. O fluxo come\u00e7a com um conjunto de modelos representativos selecionados atrav\u00e9s de uma abordagem probabil\u00edstica, as incertezas do reservat\u00f3rio, e um intervalo de aceita\u00e7\u00e3o dos dados hist\u00f3ricos. Os modelos s\u00e3o simulados e os resultados comparados com os dados hist\u00f3ricos. Os passos seguintes s\u00e3o a redu\u00e7\u00e3o da incerteza e uma segunda avalia\u00e7\u00e3o do modelo para garantir um melhor ajuste de hist\u00f3rico. Depois, os modelos s\u00e3o filtrados para descartar aqueles que estejam fora da faixa de aceita\u00e7\u00e3o e, em seguida, usados para fazer previs\u00f5es do reservat\u00f3rio. O \u00faltimo passo \u00e9 a verifica\u00e7\u00e3o de novos dados observados, que \u00e9 sincronizada com a aquisi\u00e7\u00e3o de dados. O m\u00e9todo tamb\u00e9m apresenta uma maneira inovadora e eficiente para apoiar o monitoramento do reservat\u00f3rio atrav\u00e9s de indicadores gr\u00e1ficos da qualidade do ajuste. Um modelo de reservat\u00f3rio sint\u00e9tico foi usado em todo o trabalho a fim de controlar os resultados de todos os m\u00e9todos que apoiam a metodologia proposta. Al\u00e9m disso, a metodologia foi aplicada no modelo UNISIM-IH, baseado no campo de Namorado, localizado na Bacia de Campos, Brasil. Os estudos de caso realizados mostraram que a metodologia proposta assimila continuamente os dados observados do reservat\u00f3rio, avalia o desempenho do modelo, e mant\u00e9m um conjunto de modelos de reservat\u00f3rios calibrados em tempo real.\nPalavras Chave: Ajuste de hist\u00f3rico, simula\u00e7\u00e3o de reservat\u00f3rios, incertezas, abordagem probabil\u00edstica, tempo real e avalia\u00e7\u00e3o de reservat\u00f3rios.\nxvi\nTABLE OF CONTENT\n1.\tINTRODUCTION..................................................................1\n1.1.\tObjective...............................................................4\n1.2.\tReservoir simulation models.............................................4\n1.3.\tDescription of the work.................................................5\n2.\tARTICLE 1: Influence of the Objective Function in the History Matching Process.11\n3.\tARTICLE 2: A Methodology to Evaluate and Reduce Reservoir Uncertainties using\nMultivariate Distribution....................................................23\n4.\tARTICLE 3: Principal Component Analysis for Reservoir Uncertainty Reduction..39\n5.\tARTICLE 4: Use of a Probabilistic Approach to Perform History Matching Tracking over\nSimulation Time..............................................................53\n6.\tCONCLUSIONS..................................................................93\n7.\tFUTURE WORK..................................................................97\nREFERENCE........................................................................99\nxviii\n1.\tINTRODUCTION\nReservoir management practice relies on use of financial, technological and human resources, while minimizing capital investment and operating expense to maximize economic recovery of oil and gas from a reservoir (Thakur, 1996). It is based on a series of decisions that enables oil and gas companies to meet their technical and business objectives. The initial concept considers reservoir engineering the major technical subject of reservoir management. Over the years, other factors were included: automation with computers, synergy between geoscientists and reservoir engineers, detailed reservoir description with geological and geophysical data (Craig et al., 1977). Management, economics, legal and environmental considerations are included in modern reservoir management.\nReservoir surveillance requires a model of the reservoir system and the ability to predict the consequences of implementing possible and alternative strategies. The reliability of reservoir forecast is closely related to the amount of reservoir information and the understanding of its behavior. Reservoir characterization, a vital part of the model creation process, involves generating an editable mathematical subsurface model. It is a continuous process that must be updated as new information is gathered from the asset. The details and type of mathematical reservoir modeling depends on data gathering. The traditional sequence, while working with reservoir characterization, is first the acquisition and interpretation of data from different disciplines. Secondly, data integration, which is used to build the initial reservoir model. Finally, the calibration of the model is the last step.\nNumerical reservoir simulation is widely used in the industry for reservoir forecast. It is a more sophisticated method, compared with decline curve and material balance methods. It can represent the physics of fluid flow in porous media. In general, the model is calibrated to reproduce the past observed dynamic performance of the reservoir and is expected to reliably predict future performance. This method allows integration of the full data set, which might include logging and core well data, seismic survey, well testing data, geological and fluid properties. Numerical solutions handle the highest level of complexity, but require more information from the reservoir. The acquisition and interpretation of new information commonly\nrequire time and expertise for model preparation and simulation execution. These challenging characteristics remain similar over the entire simulation period. The common reasons for model updating are the availability of new observed data, or more frequently, irreconcilable conflicts between the model simulation and the measurement data.\nOne of the biggest challenges in building a simulation model is the history matching (HM) process, which is the last stage in the reservoir characterization sequence. It is an inverse problem, which adjusts reservoir attributes by history matching production data. The desired output are known and the inputs are unknown. The solutions are not unique, or exact solutions do not exist for real cases (Oliver et al., 2008) because the models are approximations of the real reservoir. The history data used as the observed reservoir response to some stimulus are subject to noise and error, which also may prohibit an exact solution.\nTraditionally, the model properties modifications are manually performed through a try and error approach or through computed assisted process. Assisted HM normally uses mathematical functions to describe how close the model is to the history data. They are normally faster than the manual method, since they tend to search the solution space effectively, respecting the geologic model.\nAn inefficient HM evaluation criteria can also contribute to poor reservoir forecast over time. Often, a rigorous method does not exist to regularly validate the HM. For instance, when the calibrated model cannot capture the water breakthrough or the bottom-hole pressure (BHP) trend, a reservoir evaluation tool must identify such model deficiencies early on. If the model deficiencies is not identified by the model evaluation, the initial calibrated models will continue providing production forecasts over the years without any update, probably leading to erroneous forecasts. Faced with this risk, the desired approach is a rigorous model evaluation, combined with model assessment and updating as needed.\nApart from the HM challenges, the quality of the observed data and of the reservoir characterization must be considered in every reservoir simulation study. Tolerance margins and measurement errors from the observed data leads to the concept of an acceptance range (AR). The range varies according to (1) the quality of the measurements, which is related to sensor specifications, flow conditions in the well and measurement conditions, and (2) the field characterization quality and the desired HM quality. Considering the ranges during the HM evaluation, they avoid restricted model filtering based only on a fixed dataset (conventional HM).\nIn the literature, most history matching articles and applications focus on the initial field development phase and they are performed once, at a specific period. The majority of the published methods do not continuously evaluate the mismatch over time, and they either do not account for the possibility of assimilation of future information or consider uncertainty to be resolved before any HM process. They neglects the potentially significant value imparted by that information.\nThe proposed HM approach works in synchrony with the data acquisition frequency and with a quality evaluation tool. Each new information is added into the HM evaluation while still incorporating the reduction of reservoir uncertainty through the information over time.\nHM methods and uncertainty quantification tools keep evolving as more and new reservoir measurement become available and computer power increases. Manual and assisted HM approaches have been published over the years, using different mathematical tools and focusing on different reservoir applications. The ultimate goal of HM is to enhance the confidence in predictions. This work was developed to support a real-time HM process, focusing on model evaluation and updating, and uncertainty analysis over time. The proposed method integrates a probabilistic reservoir model building and a rigorous model assessment to filter and modify them as needed. The method is synchronized with the history data acquisition allowing a real-time HM process.\nThe thesis is structured with four articles. The first three articles were developed based on the needs to support the real-time history matching. The first article shows that more attention must be given to the objective function used in the history matching process due to its influence on the performance of the optimization method. The work provided a performance comparison between different objective functions, which are frequently used in assisted history matching processes. The selected function is then used in the second article to evaluate the mismatch. Article 2 proposes a new process to evaluate and reduce reservoir uncertainties using multivariate analysis incorporating the interaction between reservoir properties. The method uses a Latin Hypercube (LHC) to sample the reservoir attribute range and a smoothed mismatch data set. The attribute interval, which minimizes the mismatch, is identified through polynomial fitting. Evaluation and an uncertainty reduction tools were also the subject of article 3. The third article uses Principal Component Analysis (PCA) to reduce the interpretable dataset dimension. Using smoothed mismatch from the principal component and polynomial fitting, the method was able to\nreduce the reservoir uncertainties and improves HM. The fourth article is the core of the thesis. It uses all the findings and methods developed in the previous articles and proposes the real-time HM procedure. The novel method works continuously with nine steps to incorporate the new information, evaluate the HM and manage the uncertainty quantification using the acceptance range concept.\n1.1.\tObjective\nThe objective of this thesis is to develop a methodology to provide reliable reservoir simulation models for a better reservoir forecast at each time period by incorporating new observed data into the real-time history matching. The methodology must achieve the following:\n1.\tInclude measurement errors and a tolerance margin into the history data before the HM evaluation. Reservoir measurements and reservoir characterization are subject to errors, and the desired HM quality must be accounted while evaluating a reservoir model;\n2.\tSynchronize the history data sampling frequency with the HM workflow, capturing the reservoir trends along the production period in the model. New observed dynamic data provide additional reservoir information and helps the reduction of reservoir uncertainties. Every new important data must be assimilated and incorporated, while history matching the model;\n3.\tProvide quality indicator and an efficient way to evaluate the reservoir model performance over time. Nowadays, reservoir surveillance is performed by evaluating several data and quality indicators, so the real-time HM method must allow a practical and efficient way to assess the reservoir response.\n1.2.\tReservoir simulation models\nThe methods and analysis described in the articles are applied to two reservoir simulation models, which are available at the UNISIM website (www.unisim.cepetro.unicamp.br). The first reservoir is an upscaled model (validation model) from a synthetic refined reservoir (Bertolini and Schiozer, 2011 and Bertolini et al., 2015). The history data used in the objective function\ncalculations were obtained from the refined model. Although it is a synthetic upscaled reservoir, the true reservoir attribute values to match the history data are unknown. The upscaled model contains a similar heterogeneity to the refined model. It is divided into five regions with different geometries, area and volume, and different geological properties. The model presents four uncertain attributes per region. The attributes are horizontal permeability, vertical permeability, coefficient and the maximum value of the water relative permeability on Corey\u2019s equation. The first simulation model has a total of 20 uncertain attributes.\nThe second reservoir model is called UNISIM-I-H (Avansi and Schiozer, 2014 and 2015). The geological model has 3.5 million active cells and uses core and well logging data, 2D and 3D seismic data provided by Brazilian National Petroleum Agency - ANP and Petrobras (released public data). It uses structural, facies and petrophysical models from the Namorado field, located in the Campos Basin, Brazil (www.unisim.cepetro.unicamp.br/unisim-i/index.php/category-unisim-i-h). Based on the geological model in a high-resolution grid, an upscaling procedure to a medium reservoir scale was necessary to decrease the computational effort. A simulation grid cell resolution was defined with 100 x 100 x 8m blocks to reflect reservoir behavior and heterogeneities. It was discretized into a corner point grid (81 x 58 x 20 cells, with 36,739 active total cells). The model presents 18 uncertain attributes. They are 12 porosity multipliers for each regions, one horizontal permeability multiplier, one vertical permeability multiplier for the entire reservoir, water-oil contact, and two coefficients which correlate porosity with horizontal permeability. The production strategy was defined with 25 wells (4 vertical producers, 10 horizontal producers and 11 injectors). The vertical wells NA1D, NA2, NA3D and RJS19 were the pilot vertical wells in this field. They produced for 4 years and then were shut down for one year. Production resumed in the sixth year with all 14 producers and 11 injection wells for six more years.\n1.3.\tDescription of the work\nThe thesis is structured with four scientific articles summarized in this section, highlighting the main contributions and how they are connected. The articles in full extension are presented in the following chapters.\nAndr\u00e9 Carlos Bertolini, C\u00e9lio Maschio and Denis Jos\u00e9 Schiozer.\nJournal of Petroleum Science and Engineering, May, Volume 78, Issue 1, July 2011, Pages 32-41.\nThe first article shows the influence of the objective function in the HM process. An assisted HM process always requires two distinct parts: a parameterization to select the uncertain attributes of the model and an automatic procedure that minimizes the distance between the observed production and the simulation model curves. This article focuses in the second part, where an objective function is necessary to mathematically represent the quality of the model. Eight global objective functions were evaluated and different initial reservoir attribute sets were tested to increase reliability.\nThe method was applied in the validation model containing 20 uncertain attributes and the sequential quadratic programming (SQP) was the chosen optimization process. Partial objective functions (POF) considered in this application were: oil production, water production and bottom-hole pressure.\nThe results showed that the simple error (SE) and the squared error (SqE) functions were the best two performers. The main difference was the optimization speed of the matching. SqE function obtained a faster mismatch reduction along the number of simulations. On the other hand, SE function achieved the highest global HM, considering the same limit of simulations runs. The main contributions of this article to the thesis are as following: (1) to show that more attention is needed by the objective function used in the HM process due to its influence on the performance of the optimization method. Although the quality of the matching does not guarantee a good model, assisted procedures frequently rely on a good performance of the optimization method, so the choice of the objective function is important; (2) to indicate the need for different equations to account for the mismatch between history and simulated data, including the objective function SqE. This function was further improved through the additional of a positive sign (simulated data below the history data) or a negative sign (simulated data above the history data), a normalization step, and then used in the following articles.\n1.3.2.\tArticle 2: \u201cA Methodology to Evaluate and Reduce Reservoir Uncertainties using Multivariate Distribution\u201d\nAndr\u00e9 Carlos Bertolini, C\u00e9lio Maschio and Denis Jos\u00e9 Schiozer.\nJournal of Petroleum Science and Engineering, Volume 128, April 2015, Pages 1-14\nThe second article presents a new process to evaluate and reduce reservoir uncertainties using multivariate analysis, incorporating the interaction between reservoir properties. The Latin Hypercube (LHC) sampling technique was applied on the first stage of the method to provide the variability of the reservoir uncertain attributes. On the second stage, the gap between history and simulated data was associated with a combination of attribute variation. The process uses a smooth mismatch data set from the selected objective functions and polynomial fitting to identify the attribute interval which minimizes the mismatch. The objective function SqE function from article 1 was used to evaluate the mismatch between history and simulated data.\nThe methodology deliverables were a reduced reservoir attributes range, which provided a set of simulation models with improved history matching; and a multivariate sensitivity matrix. The matrix showed the relationship between the expected reservoir behavior and reservoir uncertain attributes. The method was firstly applied in the validation model with 20 uncertainty attributes described in article 1, and subsequently in the UNISIM-I-H reservoir model which is based on the Namorado field, Campos basin, Brazil.\nThe contribution of this article was a method that provides a set of improved simulation models and a reduced uncertainty range, even with a limited number of simulation runs and without proxy model. The method supports the real-time HM subject (article 4). Applying it synchronously with new data incorporation reduces the reservoir uncertainty over time.\n1.3.3.\tArticle 3: \u201cPrincipal Component Analysis for Reservoir Uncertainty Reduction\u201d\nAndr\u00e9 Carlos Bertolini and Denis Jos\u00e9 Schiozer.\nJournal of the Brazilian Society of Mechanical Sciences and Engineering, p. 1-11, 2015.\nSimilarly to article 2, this work focuses on reservoir uncertainty reduction. It is noticed from the previous article that big dataset interpretation might become a complex task. The data integration and mainly its proper use is a challenge, especially in full field models with larger\nnumber of wells and functions. The method described in article 2 is still valid for full field models, although the number of simulated measurements to properly characterize the reservoir might reach high numbers and turn its application impractical. It becomes critical with a high number of wells and when more measurements become available to analyze reservoir performance. As an alternative to overcome this issue, article 3 works with Principal Component Analysis (PCA) to reduce the interpretable dataset dimension.\nUsing the validation synthetic reservoir model with 20 uncertainty attributes, the PCA method was applied and its results showed that five principal components covered approximately 95% of the problem variability (from 15 original simulated measurements). This significant dataset dimension reduction facilitated the reservoir interpretation. Reservoir uncertainties were reduced and most of the simulated measurements considered in the application had a history matching improvement. Ultimately, the models used for reservoir forecast were better calibrated for reservoir management.\nThe main contribution of this work to the thesis was the new uncertainty evaluation method capable of reducing the dimension of the problem by providing a set of improved simulation models and a reduced uncertainty range. It also supports the real-time HM subject, allowing a reservoir uncertainty reduction over time.\n1.3.4.\tArticle 4: \u201cUse of a Probabilistic Approach to Perform History Matching Tracking over Simulation Time\u201d\nAndr\u00e9 Carlos Bertolini and Denis Jos\u00e9 Schiozer.\nSubmitted to Journal of Petroleum Science and Engineering\nArticle 4 focuses on real-time history matching. We propose a sequence of steps to regularly evaluate the numerical model performance over time. Working with a numerical model carries challenging characteristics to maintain calibrated models over time. The reservoir model may not be updated in time for several reasons, such as are time, cost and expertise. Another process that commonly contributes to an irregular model updating over time is the HM evaluation criteria. Often, a rigorous method does not exist to regularly validate the HM. Faced with this risk, the desired approach is a continuous model evaluation, combined with model updating and model reassessment as needed.\nIt is proposed a real time probabilistic history matching workflow to regularly evaluate the model performance over time. This new method is composed of nine steps, and works with an acceptance range applied to the history dataset. It is associated with matching quality indicators, which allow a practical and efficient way to provide support for reservoir decisions.\nWe used both reservoir models to validate the method. The reservoir models were evaluated against the acceptance range annually. The method managed to maintain a set of calibrated models for the simulation period and the reservoir uncertainties were quantified using the multivariate analysis method presented in article 2. The uncertainty reduction tool narrowed reservoir attribute ranges, using observed dynamic data. The annual results showed the importance of real time evaluation and reservoir model updating to guarantee calibrated reservoir models over time.\nThe pillars to support the real-time HM methodology were described in the previous articles through objective functions, uncertainty reduction methods and reservoir evaluation tools. The integration of these methods, tools and analysis were performed on article 4. This article provides the main contribution of the thesis. It is the core article of the real-time history matching. The nine-step workflow proposes a new methodology to add new information into the HM evaluation while still incorporating the reduction of reservoir uncertainty through new information over time.\n10\n2.\tARTICLE 1: Influence of the Objective Function in the History\nMatching Process\nAndr\u00e9 Carlos Bertolini, C\u00e9lio Maschio and Denis Jos\u00e9 Schiozer\nJournal of Petroleum Science and Engineering, May, Volume 78, Issue 1, July 2011,\nPages 32-41\n12\nContents lists available at ScienceDirect\nJournal of Petroleum Science and Engineering\njournal homepage: www.elsevier.com/locate/petrol\nInfluence of the objective function in the history matching process\nAndr\u00e9 Carlos Bertolini *, Denis Jos\u00e9 Schiozer * 1\nUNICAMP, Brazil\nARTICLE INFO\tABSTRACT\nArticle history: Received 19 January 2010 Accepted 10 April 2011 Available online 1 May 2011\tAn assisted history matching process always requires two distinct parts: a parameterization to select the uncertain attributes of the model and an automatic procedure that minimizes the distance between the observed production and the simulation model curves. The focus of this work is the second part, where an objective function is necessary to represent mathematically the quality of the model. However, due to the\nKeywords: history matching simulation objective function reservoir\tcomplexity of the models, this function is frequently a combination of several functions that represent the quality of the match in several wells and less attention is given to the influence of the objective function in the optimization process. This paper proposes a study to show the influence of a global objective function on the history matching process using a synthetic reservoir model with 20 uncertain attributes. Results of the quality matching index of eight different global objective functions are compared at the end of the process. The optimized simulation models, generated by the optimization phase with different global objective functions, are compared with the base model and production history. \u00a9 2011 Elsevier B.V. All rights reserved.\n1.\tIntroduction\nThe objective of the history matching process is the calibration of the numerical simulation models of petroleum fields. The objective of the history matching is to get better predictions; however, when the process is done, it is not possible to compare with the prediction so the quality of the model is frequently measured by the quality of the matching. The idea is that the production prediction is more reliable when the simulator results are coherent with the past observed data. The focus of this work is to show the behavior of the objective function that measure the quality of matching and the influence of this objective function in the optimization process.\nUsually, the history matching process requires great computational effort. It is an inverse problem and is complex due to the high number of uncertainties in the reservoir characterization phase.\nSeveral techniques have been applied to minimize the computational effort to simulate all possible scenarios of the reservoir. The computational effort is also linked to the efficiency of the process used to optimize an objective function that represents the quality of the history matching.\nThis function is, in general, a weighted combination of all of the partial objective functions (POF) that need to be minimized and that represent the production and pressure history of the field. These\n* Corresponding author. Tel.: +55 21 81098648.\nE-mail addresses: acberto@dep.fem.unicamp.br (A.C. Bertolini), denis@dep.fem.unicamp.br (D.J. Schiozer).\n1 Tel.: +55 19 35213339.\n0920-4105/$ - see front matter \u00a9 2011 Elsevier B.V. All rights reserved. doi:10.1016/j.petrol.2011.04.012\npartial functions may have different units and several orders of magnitude due to the different variables and rates of the wells and diverse quality of the initial history matching for each function.\nIn general, less attention is given to the weights attributed to partial objective functions for the construction of the global objective function (GOF). This paper shows the influence of the objective function in the history matching process. Eight GOF are used in the assisted process. Different initial reservoir attributes sets are tested to increase reliability and to avoid the influence of optimization algorithm in the final results. In this sense, it is important to verify whether the choice of the objective function can bring a significant reduction in the number of simulations and, consequently, in the total time required for the process.\n1.1. Objectives\nThe objectives of this paper are: (1) the study of the influence of different types of global objective functions in the history matching process and (2) the verification of the possible improvement that the choice of the objective function can bring to optimization step of the assisted history matching process.\n2.\tLiterature review\nThere are several studies involving assisted history matching and many types of analyses with different objective functions (OF). In general, the OF is described without a previous explanation of its functionality and performance. The paper written by L. Kent Thomas (Thomas et al., 1971) minimizes, in a least-square sense, the error between the set of observed and calculated performance data in the\noptimization process based on Gauss-Newton. Eq. (1) shows the objective function:\nE = E wM^-p^f\t(1)\nwhere pkbs is the observed data, pkalc is the calculated data and wk the weight factors.\nThe described algorithm was capable of improving the linear and nonlinear function correlation with a reasonable number of simulations; however, a study of the global objective function was not shown. In a similar way, Chen et al. (1973) and Maschio &amp; Schiozer (2005) used the squared variation between historical and simulated data presented in Eq. (1). Chen demonstrated a significant saving in computing time using reservoir properties as a continuous function of position rather than as a uniform function in a certain number of zones. Maschio &amp; Schiozer (2005) presented a methodology using a direct search optimization technique, in order to accelerate the history matching process. Three methods were integrated: independent objective function, multiple starting points and linear search.\nWatson &amp; Lee (1986) showed an algorithm based on Marquardt's modification of the Gauss-Newton method for minimization of leastsquare functions. The performance of the algorithm is evaluated by history matching actual production data using an analytical dual porosity model.\nCullick et al. (2006) studied proxy model performance using a neural network to accelerate the history matching. The paper demonstrated that the neural network is an excellent proxy for the numerical simulator over the trained parameter space. The objective function was also squared. However, in order to emphasize the importance of particular data or time, a weight is assigned. In order to consider data with different absolute ranges, there is a scaling factor. The objective function is defined in Eq. (2).\nob=\tw ( h ('\t(2)\nwhere, i is the data type, t is time, w(i) is the weight for the ith data, w(i,t) is the weight for the ith data at the time t, sim(i,t) is simulated data, hist(i,t) is historical data and scale(i) is scale for the ith data type.\nIn the history matching process, Gomez et al. (1999) used the squared objective function normalized in the process of global optimization known as \u201ctunneling\u201d. He concluded that the method is an alternative to immediate reformulation of the problem if the first minimum found does not represent an acceptable match.\nDean et al. (2008) presented that the prior knowledge of each model w in the ensemble can be probabilistically expressed through a prior probability density function p(w). Bayes theorem allows an update with prior beliefs by calculating a posterior probability, using the likelihood. The prior beliefs change as we compare the model output with the observed data.\nThe maximum likelihood estimate of w is defined to be the model which maximizes the likelihood function or equivalently, minimizes the objective function. They concluded, under the assumptions that data measurement errors are independent Gaussians, that the leastsquares estimate is equivalent to the maximum likelihood estimate. However, the objective function is, in general, merely described, without any further study of its efficiency and functionality.\n3.\tMethodology\nFig. 1 represents the process used in this study that starts with the selection of the uncertain attributes, followed by the construction of the base simulation model, the variation limits for each attribute and, finally, the optimization process, using a different global objective function (GOF).\nFig. 1. Proposed methodology flowchart.\nThe base model is the reference for the history matching process. The definition of each attribute's variation interval is defined through the uncertainty limits of the geological characterization. At the end of this phase, a geological simulation model and the variation range of the uncertain attributes are obtained.\nThe global objective functions are then selected to be used in the optimization process. The GOF are described in Table 1, where the index s represents simulated data, h, historical data, b, base model data, m, total number of partial objective functions (POF), n, total number of data, ws, simple weight, wsD, dynamic simple weight, wq, quadratic weight, and wqD, dynamic quadratic weight.\nThe proposed methodology uses different global objective functions to test the performance in the matching process. The evaluation of the history matching during the optimization process is made through the GOF.\nAfter the optimization process, a comparison function is tested according to the history matching objectives. The outputs of the optimization stage are the optimized simulation models of each GOF, represented by uncertain attribute values, and the GOF that achieved\nTable 1\nGlobal objective functions.\nGOF\tDescription\tFormula\t\nSE\tSimple error\tm\tn SE \u2014 E E (|hji-Sji|) j\u20141 i\u20141\t(3)\nNE\tNormalized error\tn m E (\u00a1hJ\u00bb-sn|) NE \u2014 E 1\u2014-\t- J\u20141 E (|hi-bi|) i \u2014 1\t(4)\nWNE\tWeighted normalized error\tm\tE (\\hjl -SiD\t(5)\n\t\tj\u20141 E(|hji-bi|)\t\nDWNE\tDynamic weighted normalized error\tn m\tE (|hj i-sjiD DWNE \u2014 E wsDj -i \u2014 1 j\u20141\tE(|hji-bi|) i \u2014\t(6)\nSqE\tSquare error\tm\tn SqE \u2014 E E (hji-Sji)2 j\u20141 i\u20141\t(7)\nNSE\tNormalize square error\tn\to m E (hji-Sji) NSE \u2014 E '\t- J\u20141 E (hji-bji)2 i \u2014 1\t(8)\nWNSE\tWeighted normalized square error\tm\tE (hji-Sji) WNSE \u2014 E wj \u2014 1 j\u20141 E (hji-bji)2 i \u2014 1\t(9)\nDWNSE\tDynamic weighted normalized square error\tn\t\u201e m\tE (hji-Sjd DWNSE \u2014 E\t- j\u20141\tE (hi-bji)2 i \u2014 1\t(10)\nresponse for validation of the methodology. It is divided into five regions with different forms, area and volume, with different geological properties among them. The application is an upscale model from a refined reservoir. The historical data used in the POF calculations was obtained from the refined model. Although the application is a synthetic reservoir the real attribute values are unknown.\nThe corner point grid showed in Fig. 3 has 2550 cells distributed in 30(I) X 1 7(J) x5(K). The reservoir has five producer wells and five injector wells, a producer/injector pair for each region is located in the same reservoir position. The reservoir cells of the injector wells are Injector 1 (I4 J 1 -6K5); Injector2 (I 1 4 J 1 -9K5); Injector3 (I20-29J6K5); Injector4 (I3J8-17K5) and Injector5 (I10-28J14 K5) and for the producer the cells are Prod1 (I4J1-6 K1); Prod2 (I14J1-9 K1); Prod3 (I20-29J6 K1); Prod4 (I3J8-17 K1) and Prod5 (I10-28J14 K1).\nThe model presents four uncertain attributes per region. The attributes are horizontal permeability in the X direction (Kx), vertical permeability in the Z direction (Kz), coefficient of Corey's Eq. (11) for water relative permeability (ExW) and the maximum value of the water relative permeability in Corey's equation (Krw0). Corey's equation for water relative permeability shows the last two attributes. However, the simulation model has a total of 20 uncertain attributes.\n\u2014 krw0 \u25a0\n\nr (sw-swc) iExw k1~SWc~SOr )J\n(11)\nthe best reduction in the comparison function. Each application and history match stage will lead to a specific comparison function.\n4.\tApplication\nThe reservoir model used in the application of the methodology is shown in Figs. 2 and 3. The reservoir is synthetic, with known\nwhere, KrW is the water relative permeability, SW is the water saturation, SWC is the connate water saturation and, finally, Sor is the residual oil saturation.\nThe permeabilities Kx and Kz are modified in the simulation models through multiplier numbers. The limits are 0.5 and 2.0, which represent the half and the double of the absolute permeability Kx and Kz of the base model. The base model is the unitary reference of the absolute permeability multipliers. On the other hand, the attributes ExW present a variation range from 1 to 5 and the attributes krw0 from 0.15 to 0.90. Table 2 shows the reservoir model attributes used in each\nRegion3\nRegion 2\nRegionl\nRegions\nRegion4\n10.000\n10.000\n20.000\n30.000\n20 000\n0.00 0.50\n0 00 1.00\n30.000\n1.00 miles\n2.00 km\nFig. 2. Mapped reservoir regions.\nPorosity (a)\n0 10.000\nPorosity K layer: 1 (b)\n1 1 I 1 1 20.000\n0 I\n30.000 , , I \u25a0 ,\n20,000\n, \u25a0 I . ,\ni.................  1\t\u00b0\n0 10,000\nPorosity K layer: 5 (C)\n1 r 1\n20,000\n30,000\n<Zl \" CD -O._\nO -\nCM _\n0 10,000\nI................I\t\u25a0 \u25a0 \u25a0 \u25a0\nFig. 3. Porosity distribution (a); porosity layer 1 and producers (b); porosity layer 5 and injectors (c).\ninitial point set including the Set 1 which is the base simulation model.\nThe partial objective functions (POF) considered in this application were oil production (bbl/day), water production (bbl/day) and bottom-hole pressure (psi). The well production strategy used in the simulation had a surface liquid limit of 30,000 bbl/day and the bottom hole pressure limit of 3000 psi. The oil production target was informed in the simulator for each simulated date.\nThe sequential quadratic programming - SQP was the chosen optimization process. SQP is a method resulting from the application of the Newton method to the minimization of the Lagrange function of the problem and it is one of the most used methods in nonlinear\n1 1 I.............\n30,000\nTable 2\nReservoir model attributes for each initial set.\n\t\tReservoir attributes\tInitial values\t\t\t\t\n\t\t\tSet 1\tSet 2\tSet 3\tSet 4\tSet 5\nPermeability multipliers\tRegion 1\tKx1\t1.00\t2.00\t0.50\t0.50\t2.00\n\t\tKz1\t1.00\t2.00\t0.50\t2.00\t0.50\n\tRegion 2\tkx2\t1.00\t2.00\t0.50\t2.00\t0.50\n\t\tkz2\t1.00\t2.00\t0.50\t0.50\t2.00\n\tRegion 3\tkx3\t1.00\t2.00\t0.50\t0.50\t2.00\n\t\tkz3\t1.00\t2.00\t0.50\t2.00\t0.50\n\tRegion 4\tkx4\t1.00\t2.00\t0.50\t2.00\t0.50\n\t\tkz4\t1.00\t2.00\t0.50\t0.50\t2.00\n\tRegion 5\tkx5\t1.00\t2.00\t0.50\t0.50\t2.00\n\t\tkz5\t1.00\t2.00\t0.50\t2.00\t0.50\nCorey's equation\tRegion 1\tExw1\t2.20\t5.00\t1.00\t3.00\t1.00\nattributes\t\tKrW01\t0.60\t0.90\t0.15\t0.80\t0.20\n\tRegion 2\tExw2\t1.10\t5.00\t1.00\t4.00\t2.00\n\t\tKrW02\t0.80\t0.90\t0.15\t0.50\t0.80\n\tRegion 3\tExw3\t4.00\t5.00\t1.00\t2.00\t4.00\n\t\tKrW03\t0.50\t0.90\t0.15\t0.70\t0.30\n\tRegion 4\tExw4\t1.30\t5.00\t1.00\t5.00\t2.00\n\t\tKrW04\t0.70\t0.90\t0.15\t0.20\t0.70\n\tRegion 5\tExw5\t4.30\t5.00\t1.00\t3.50\t2.00\n\t\tKrW05\t0.80\t0.90\t0.15\t0.40\t0.90\noptimization problems (Venkataraman, 2001). The idea of this method is to approximate, in each iteration, the nonlinear problem for quadratic programming (QP) subproblems with linear restrictions. The subproblems are created using the Hessian matrix approximation of the Lagrange function through the Quasi-Newton method with BFGS (Broyden Fletcher Goldfarb Shanno) approach (Vanderplaats, 1984). The solution of these subproblems generates a specific search direction for the linear search method.\nTherefore, the SQP optimization consists of three-step iteration: to update the Hessian matrix of the Lagrange function, to solve the subproblems of quadratic programming and, finally, to accomplish the linear search and evaluate the value of the function. Matlab software presents the fmincon (Biran &amp; Breiner, 2002) function as a SQP optimization method.\nThe fmincon is a local optimization function that results in a small disturbance in the variables of a project space, in agreement with the restrictions. As a consequence, the fmincon convergence is related to the initial values. For the application in this paper, the maximum number of evaluations during the optimization process was set to 640 (this number was chosen after some previous tests to guarantee the minimized result for all GOF).\nIn order to generalize results, four other sets, shown in Table 2, were tested. The same five initial point sets were used for each GOF. The first set is the base model, the second and third sets are the upper and lower attributes limits.\nFor the study of the history matching process's performance behavior, eight global objective functions were used and are defined in the Table 1, all of them working with the POF data defined above.\nThe multiplier weights of four considered GOF were calculated by well and by POF. In this application, there are three POF (oil production, water production and bottom-hole pressure) and five production wells, totaling 15 multiplier weights. Eqs. (12) and (13) show the formula for simple and quadratic weight.\nWSPOF W \u2014\nNEPOF W Max (NEPOF )\n(12)\nnsepof w\nWqpOF W \u2014 Max (NSEpof)\t(13)\nwhere the index s represents simple weight, q, quadratic weight, POF, the partial objective function, and w, the well.\nThe largest normalized error between measured and simulated data (NE) for each POF represents the denominator of the equation. The division of the SE of the well over the denominator is used to obtain the weight for the considered POF (in a similar way as NSE). The weight values are in a range of zero for better-matched wells, and one for wells with the worst history matching.\nThe dynamic weight follows the same equation; however, it is calculated after each simulation of the optimization cycle shown in Fig. 1. The calculation of every cycle provides an adjustment of the weights according to the improvement or worsened performance of each well and POF. In the static case, the weight is calculated only once at the beginning of the optimization cycle.\nOne comparison function was chosen for this application; the simple error (SE) function. The outputs from the comparison function of each well and POF were gathered through the Euclidean norm of the SE vector. In this application, this vector has 15 fields (three POF with five production wells). The Euclidean norm is calculated through Eq. (14).\nIIXII =\t(Xi )2)/2\t(14)\nwhere, X is the comparison function component of the vector.\n5.\tResults comparison\nWith the objective of creating a quality matching indicator (4), Eq. (14) was divided by the Euclidean norm of the base model. The indicator 4 is calculated through Eq. (15).\n(E (Xi)2\n*/2\n' 15\t]/2\nE (XM)2\n(15)\n* =\nThe interpretation of 4 is direct: values greater than 1 represent a worsening in the history matching; equal to 1, the model is having the same performance of the base model; and smaller than 1, the model presents improvements in the history matching. Therefore, in the application, we have the quality matching indicator for simple error (4se).\nThe ideal would be to compare the quality of production prediction but that is not the objective of this work. Another possible alternative would be the comparison of all global objective functions but too many results would be presented with basically the same conclusions. So we are showing the influence of the objective functions in 4.\n6.\tResults\nThe 4se and the number of required simulation to reach the minimum 4SE of each optimized model are shown in Fig. 4. The upper plots display the result of each set for each GOF. In the lower plots the average and the standard deviation are presented. Looking at the 4SE values smaller than 1, it is clear that all GOF obtained improvements in the history matching (base model). The SE and SqE GOF were the best two performers. Further those GOF obtained a consistent number of simulations to reach the minimum 4SE in all initial point sets.\nWe can notice different behaviors along the optimization cycles in Fig. 5 for each set. The GOF dynamically weighted DWNE and DWNSE obtained reduced values of 4SE as shown in Table 3. However, they had a limited profile along the simulations for almost all sets. It can be noticed that there was not a gradual improvement of the history matching with the optimization process. The dynamic weight alters the GOF at every simulation, varying the forecast and the efficiency of the optimization method.\nThe reduction of 4SE obtained by WNE and WNSE GOF was expressive already in the first simulations. The optimization of the initial point set 1 and 5 show this profile and it can be visualized in Fig. 5. We can attribute these effects to the given initial weight of the GOF. At the beginning of the process, the optimization method prioritized POF and wells with the worst history matching.\nFig. 4. Number of simulation and 4Se result summary.\nFig. 5. Quality matching indicator (^SE) for GOFs listed in Table 1.\nFinally, the SE and SqE GOF presented a gradual decrease of AI'SE. Both obtained improvements in the history matching, arriving at 83% of reduction in AI'SE (Average SE GOF), according to the values shown\nin Table 3. The main difference was the speed of the decrease. Looking the Fig. 5, for all initial point sets the SqE GOF obtained a faster AI'SE reduction along the simulations compared with the SE GOF.\nTable 3\nMinimum ^SE values vs. number of simulations.\n\tGlobal objective function - GOF\t\t\t\t\t\t\t\n\tSE\tNE\tWNE\tDWNE\tSqE\tNSE\tWNSE\tDWNSE\n^se set 1 (base model)\t0.171\t0.352\t0.244\t0.345\t0.181\t0.324\t0.237\t0.299\n^se set 2\t0.150\t0.327\t0.236\t0.600\t0.249\t0.445\t0.284\t0.362\n^se set 3\t0.139\t0.417\t0.262\t0.456\t0.180\t0.251\t0.274\t0.378\n^sEset4\t0.190\t0.336\t0.197\t0.358\t0.277\t0.471\t0.335\t0.273\n^se set 5\t0.192\t0.267\t0.295\t0.413\t0.169\t0.347\t0.289\t0.421\nAverage\t0.168\t0.340\t0.247\t0.434\t0.211\t0.367\t0.284\t0.347\nStandard deviation\t0.023\t0.054\t0.036\t0.103\t0.048\t0.091\t0.035\t0.060\nNumber of simulations to reach the minimum (Set 1)\t252.00\t97.00\t443.00\t72.00\t139.00\t125.00\t73.00\t483.00\nNumber of simulations to reach the minimum (Set 2)\t247.00\t267.00\t160.00\t273.00\t115.00\t168.00\t223.00\t204.00\nNumber of simulations to reach the minimum (Set 3)\t229.00\t629.00\t240.00\t345.00\t219.00\t179.00\t361.00\t223.00\nNumber of simulations to reach the minimum (Set 4)\t282.00\t458.00\t538.00\t151.00\t195.00\t289.00\t320.00\t590.00\nNumber of simulations to reach the minimum (Set 5)\t186.00\t438.00\t612.00\t180.00\t219.00\t591.00\t470.00\t125.00\nAverage\t239.20\t377.80\t398.60\t204.20\t177.40\t270.40\t289.40\t325.00\nStandard deviation\t35.32\t202.66\t193.02\t106.60\t47.80\t189.15\t149.93\t200.15\nPRODI\n40.000 S\u201930.000 5 B O 20.000 w 2 re i 10,000 6 0\t\t\t\t\t\n\t\t: i i\t\t\t\n\t\ti :\t:\t\t\t\n\t\t\t\t\t\u2022 :\n1991199219931994199519961997199819992000\nTime (Date)\nPROD2\t\t\n5 30,000\t! ! H\t: i i : i\n\ti i IsiStK\t: : i ; ;\nB O 20,000&lt;0\t\t\n\t! ! !\tI\t!\t!\tI\n\t: : : ;\t\ni 10.000\t: ; ; :\t\n\t\t\no\t: ; i !\t: : : : :\n0\t\t: : :\n1991199219931994199519961997199819992000\nTime (Date)\nPROD3\n40,000\t\t::::::::\n\t\t::::::::\n\u00a15* to non\t\u25a0 :\t\u25a0\t1\t1\t1\tL\t*\tj\tj\n73\t\tj\t;\t;\tj\tj\t;\tj\ti\n\t\t\n\t\t\nJ3\t\t\n.O\t\t> 1 1 1 &lt;\u25a0 \u25a0 \u2022\n\t\t1 1 1 1 \u2022 \u25a0 \u2022 1\nnon nnn.\t\t\n\t\t\nCO\t\t\u2022 1 1 1 \u2022 \u2022 \u2022 \u2022\n\u2022\t\t\n**\t\t\nre\t\t\n\t\t\n\u2014 10.000\t\t\n\t\t\no\t\t\n0\t\t:\t: i :\t!\t:\n1991199219931994199519961997199819992000\nTime (Date)\nPROD4\n40,000'\t\t\ti\t\t\t\t\n5 30.000' w\t\tj\ti\t\t\t\t\n\t\tyw-\u2122-n,\t\t\t\t\t\nB e\t\tJ\tj\t\t\t\t\nQ 20.000- CO\t\t\t\t\t\t\t\n\t\t: : : :\t\t\t\u25a0\t\t\n\u00ab i - 10,000' o\t\t\t\t\t\t\t\n\t\t\u2022\tI\t\t\u25a0\t\t\nO'\t\t\u25a0\tj\t\t\t\t\nPROM\n40.000-]\t::::::::::\n\t! : i i : i ; : i i\n\t\n\t\n\t\n\t\n\t\n-a\t\u25a0\ti\ti\t\u25a0\u25a0\u25a0\u25a0\u25a0\u25a0\n\t\u25a0\t\u00ab\t\u2022\t\u2022\u25a0\u2022ii\no ?o non\t\nco\t\u2022\tt\t1\t\u25a0\t\u25a0'\t>\t1\t1\n\u00a9\t\nA\t\nre\t\nK\t\u2019 \u2019 ! ! : \u2022 \u25a0 \u2019 ! \u2022\n\t\n\t\nO\t::::::::::\n0\t\n\t1991199219931994199519961997199819992000\n\tTime (Date)\n1991199219931994199519961997199819992000\nTime (Date)\nO\tHistory\nBase\n\u25a0\u25a0\u25a0\u25a0\u25a0\u25a0\u25a0 NE\n..... NSE\n\u2014 WNSE\nDWNSE\nDWNE\nFig. 6. Oil production for each GOF (Set 1).\nPROD?\n25.000\n4V\n5\n<\u00bb 20.000\n\u2014\"15.000 o tn\n~ 10.000 Of\n1991199219931994199519961097199819902000\nTime (Date)\nPRODS\n20.000\n5\n5.000\n-S 15.000\no\nW 10.000\n0J~\u2014\n1901199219931904199510961997199819992000\nTime (Date)\nFig. 7. Water production for each GOF (Set 1).\nWNSE DWNSE DWNE\nFor this application, the SE global objective function obtained the best performance in the history matching process, considering the SE comparison function.\nThe history matching data of the POF, oil production, water production and bottom-hole pressure for each one of the GOF optimized models, were compared by well. Although the oil production on each simulated date had been informed in the simulator, the oil POF was considered in the objective function. Preliminary test showed the oil production matching decrement when oil POF was not considered in the OF.\nThe optimized simulation model for each GOF and for the initial point set 1 (base model) are displayed, using the oil POF, in the Fig. 6. The oil production did not show much variation. The opposite happened with water production and bottom-hole pressure POF. The water production shown in Fig. 7 presented great variations.\nTable 3 summarizes the values obtained by the GOF with the SE comparison function for all initial point sets.\nIn a similar way, the bottom-hole pressure POF had variations according to Fig. 8.\nAt the end of the methodology, SE, SqE, WNE and WNSE GOF obtained similar results according to Table 3. However, the behaviors along the simulations were different. In a general way, the quadratic functions showed an accentuated reduction at the beginning of the optimization process since it prioritizes points of larger difference among simulated and observed data. On the other hand, the simple functions obtained a deeper reduction of the indicator, however, with a large number of simulations. These results consequently reflected in the history matching of oil and water production, and in the bottom hole pressure.\nEven with similar Al'Sk results, some of the POF behaviors were not unique among the wells as showed in Figs. 6, 7 and 8. The application with 20 uncertain attributes presented multiple combinations and a complex solution such as real reservoir models.\nPRODI\nTime (Date)\nPR002\n7.580 \u25a0\t\t\n\t5\tj\tI\tI\t:\t:\t;\ti\t;\n\u2014 6.580\t'ML\t\n\tV ' \u201cLA'Cl*\u2014 '\t \u2019\t\u25a0\t...\t\nu>\t- \u2018i. \t\u2018\t.....\t\nQ.\t\u2014\u2014\u25a0 i\t'\"\u25a0-v * \u2014\t\u25a0\t*\t\u25a0\t.\tj\t\n\t\t\nQ.\t\t\n5.580 CD\t\t!\tL\t\t^*\"4.\t*\t1\t1\t\t\n\t\t\n\u2014\t\t\no 5 4,580\t\t\t\u25a0\t\u2022_\t\t\t\u25a0\t* . - -\n\tI\t. \u00bb \u2022 ,\u25a0 _ _ 4 >\t\u25a0\t\u2022\t\u2014k\t'\t\u2019\n\t\u2022\t\u2022 \u25a0 \u25a0 \u25a0 \u25a0 '\n\t\t\n\t19911992 19931994 19951996 1997 19981999 2000\t\nTime (Date)\nPRO05\nPROD3\n7.580\t\t\n\t:::::::::\t\n6,580 to 3;\t\t\n\t::::::\t\nI BHP co a o\t\t\t\t\n\t\u00a3 j \u00cd\t\n\t\t\n4.580 3.580\t\u25a0\t\u25a0\t\u2022 Y\t'\t*\ti\tr\t\n\t:\t:\t:\t: : :\t:\t:\t:\t:\t\n1991199219931994199519961997199819992000\nTime (Date)\nPROD4\n7.580 \u2014 6.580 CO a Q_ X 5.580 tn \"5 4 580\t\t\t\t\t\t\t\n\ts\tJ\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\u25a0\ti\t\tb- **\t>aJ\t\t\t\n\t\u25a0\t\t\u25a0\t\t\t\u2014\t\n\t19911992 1993199419951996199719981999 2000\t\t\t\t\t\t\nTime (Date)\nTime (Date)\nO\tHistory\nBase\n\u00bb\u25a0*\u00bb SE\n\u25a0\u25a0\u00ab\u25a0\u25a0\u25a0\u25a0 NE\nSqE\n----- NSE\nWNSE\nDWN5E\nDWNE\nFig. 8. Bottom-hole pressure for each GOF (Set 1).\n7.\tConclusions\nThe results presented in this work yield the following conclusions:\n(1)\tThis work showed that more attention must be given to the objective function used in the history matching process due to its influence on the performance of the optimization method. Although the quality of the matching does not guarantee a good model, assisted procedures frequently relies on a good performance of the optimization method so the choice of the objective function is important.\n(2)\tThis work show the study of just one model; nevertheless, the results showed different performances for the GOF, indicating the need for a previous study of the objective function for each application.\n(3)\tA smaller number of simulations was obtained with the square error global objective function (Eq. 7). Therefore, it is the most indicated function for this example\n(4)\tThe simple error global objective function (Eq. 3) presented good results but the convergence was slow.\n(5)\tNormalized and weighted functions did not present improvements over the square error for this example. Therefore, they must be further investigated in other cases.\nFor future works, the optimization process will be (1) studied with multiple objective functions (Yang et al., 2009), (2) divided into stages with different limit rules of optimization, being flexible for GOF changes when the established limit of the stage is reached.\nNomenclature\nOF\tobjective function\nGOF\tglobal objective function\nPOF\tpartial objective function\n\u00a5\tquality matching indicator\nKrW\twater relative permeability\nSet\tinitial reservoir attribute values\nSw\twater saturation\nSwc\tconnate water saturation\nSor\tresidual oil saturation\nExw\tcoefficient of Corey's equation for water relative permeability\nkrW0\tmaximum value of the water relative permeability in Corey's\nequation\nKx\tpermeability in X direction\nKy\tpermeability in Y direction\nws\tsimple weight\nwq\tquadratic weight\nwsD\tdynamic simple weight\nwqD\tdynamic quadratic weight\nSQP\tsequential quadratic programming\nQP\tquadratic programming\nBFGS\tBroyden Fletcher Goldfarb Shanno\nw\twell\nb\tbase\nh\thistorical\ns\tsimulated\nfmincon\tMatlab local optimization function\nCullick, A.S., Johnson, D., Shi, G., 2006. Improved and more rapid history matching with a nonlinear proxy and global optimization. SPE 101933 prepared for presentation at the 2006 SPE Annual Technical Conference and Exhibition, held in San Antonio, 24-27 September.\nDean, S.O., Albert, C.R., Ning, L., 2008. Inverse theory for petroleum reservoir characterization and history matching. Cambridge University Press.\nGomez, S., Gosselin, O., Barker, J.W., 1999. Gradient-based history matching with a global optimization method. SPE 71307, revised for publication from paper 56756, first presented at the 1999 SPE Annual Technical Conference and Exhibition, held in Houston, 3-6 October.\nMaschio, C., Schiozer, D.J., 2005. Development and application of methodology for assisted history matching. SPE 94882 presented at the SPE Latin-American and Caribbean Petroleum Engineering Conference, Rio de Janeiro, Brazil, 20-23 June.\nThomas, L.K., Hellums, L.J., Reheis, G.M., 1971.A nonlinear automatic history matching technique for reservoir simulation models. SPE 3475 presented at the SPE 46th Annual Fall Meeting, held in New Orleans, 3-6 October.\nVanderplaats, G.N., 1984. Numerical optimization techniques for engineering design: with applications. Mcgraw-Hill, New York.\nVenkataraman, P., 2001. Applied optimization with Matlab programming. Wiley-Interscience.\nWatson, A.T., Lee, W.J., 1986. A new algorithm for automatic history matching production data. sPe 15228 prepared for presentation at the Unconventional Gas Technology Symposium of the SPE, held in Louisville, 18-21 May.\nYang, C., Card, C., Nghiem, L., 2009. Economic optimization and uncertainty assessment of commercial SAGD operations. J. Canadian Petroleum Technol. 48 (9) September.\nReferences\nBiran, A., Breiner, M., 2002. Matlab for Engineers. Prentise Hall.\nChen, W.H., Gavalas, G.R., Seinfeld, J.H., Wasserman, M.L., 1973. A new algorithm for automatic history matching. SPE 4545 presented at the SPE-AIME 48 th Annual Fall Meeting, held in Las Vegas, 30 September.\n3.\tARTICLE 2: A Methodology to Evaluate and Reduce Reservoir\nUncertainties using Multivariate Distribution\nAndr\u00e9 Carlos Bertolini, C\u00e9lio Maschio and Denis Jos\u00e9 Schiozer\nJournal of Petroleum Science and Engineering, Volume 128, April 2015, Pages 1-14\n24\nContents lists available at ScienceDirect\nJournal of Petroleum Science and Engineering\njournal homepage: www.elsevier.com/locate/petrol\nA methodology to evaluate and reduce reservoir uncertainties using multivariate distribution\nAndre Carlos Bertolini*, Celio Maschio* 1, Denis Jose Schiozer2\nState University of Campinas - UNICAMP, Brazil\nARTICLE INFO\nABSTRACT\nArticle history:\nReceived 11 April 2013\nAccepted 2 February 2015\nAvailable online 20 February 2015\nKeywords:\nreservoir uncertainty multivariate sensitivity reservoir simulation history matching Latin hypercube interaction among reservoir properties\nHistory matching is a challenging and time-consuming task related to reservoir simulation. Probabilistic approaches using dynamic data are often used to reduce reservoir uncertainties and improve matching. This work presents a new process to evaluate and reduce reservoir uncertainties using multivariate analysis incorporating the interaction between reservoir properties.\nThe proposed uncertainty reduction workflow provides a multivariate approach without the use of proxy models, allowing understanding of the reservoir response through the R2 matrix as well as more reliable reservoir predictions. The methodology offers a quantitative analysis and a new tool to evaluate and reduce uncertainties. The process uses a Latin Hypercube (LHC) to sample the reservoir attribute range and a smoothed mismatch data set from the LHC selected objective functions. The attribute interval, which minimizes the mismatch, is identified through polynomial fitting. The main objective is to reduce uncertainties considering the reservoir attributes range and a multivariate sensitivity matrix.\nThe methodology was firstly applied to a simple synthetic reservoir simulation model with 20 uncertainty attributes and we drew the following conclusions: (1) R2 sensitivity matrix clearly showed the key physical features of the reservoir model; (2) all reservoir attributes ranges were reduced, providing a set of simulation models with improved history matching. We successfully applied to the UNISIM-I-H reservoir model based on Namorado field, Campos basin, Brazil.\n\u00a9 2015 Elsevier B.V. All rights reserved.\n1.\tIntroduction\nDifferent stages of reservoir life, from exploration to abandonment phases, require several types of methodologies and tools to improve confidence in production prediction. The proper use of these methods affects the reliability of the decisions in developing and managing reservoirs.\nAmong important tools, reservoir simulation plays a key role in integrating disciplines such as geophysics, geology, petrophysics and fluid mechanics. It predicts alternative scenarios to support management decisions. In addition, considering reservoir uncertainties allows reservoir simulation to make probabilistic predictions. Today, even with more complex reservoir models, the effect of many uncertain parameters can be investigated with the evolution of computer facilities.\nAs the number of uncertain attributes is very high, it is common practice to select the most critical through a sensitivity analysis. It is a simple and direct interpretation of the case as it shows the direct\n* Corresponding author. Tel.: + 55 21 32168119.\nE-mail addresses: andre@dep.fem.unicamp.br (A.C. Bertolini), celio@dep.fem.unicamp.br (C. Maschio), denis@dep.fem.unicamp.br (D.J. Schiozer).\n1\t+ 55 19 35211235.\n2\t+ 55 19 35213339.\nhttp://dx.doi.org/10.1016jj.petrol.2015.02.003\n0920-4105/\u00a9 2015 Elsevier B.V. All rights reserved.\nrelationship between reservoir properties and reservoir responses. However, while this method may provide satisfactory results, for instance, increasing the understanding of the relationships between input and output variables, for complex reservoirs models, these results are insufficient to solely inform decisions. The relationship between the attributes is not always determined using univariate analysis and this relationship can be important for several applications.\nAn alternative to overcome this is multivariate analysis. It corresponds to methods that try to explore interaction between factors to better understand the effects of uncertainties. More often, studies are conducted with statistical tools that include a global response to the problem.\nIn this paper, we present a novel process to evaluate and reduce reservoir uncertainties using multivariate analysis. Several approaches have been used to estimate and to reduce uncertainties successfully. Bissel (1997) and Bennett and Graf (2002) combined geostatis-tical modeling and gradient technique to generate many priori models for a better matching. It also compares using the gradzone method in which groups of grid cells in the model are modified using constraints, for instance, proximity to the wellbore, prior variograms and a selection of grid groups that allow property change within limits.\nKalman filters applied by Gu and Oliver (2004), also achieve satisfactory results, such as improvement in assisted history matching\n(HM) and an estimate of uncertainty in future reservoir performance, both with a significant reduction in computational costs.\nThe application used by Liu and McVay (2010) is a real-time reservoir modeling studying the Markov Chain Monte Carlo (MCMC) method. The authors showed that assimilating data, HM, and forecasting continuously over time can result in forecast-uncertainty ranges that narrow with time when compared with traditional methods. In addition, the continuous simulation process allows us to calibrate uncertainty estimates over time.\nManceau et al. (2001) presented a fully-integrated methodology using statistical methods to quantify the risk associated with deterministic uncertainties, for instance, petrophysics and well locations, and stochastic uncertainties, such as geostatistical realization and matched reservoir models. They used experimental design, surface response and joint modeling method to evaluate the risk with all \u201cdeterministic\u201d, \u201ccontrolled\u201d and \u201cstochastic\u201d uncertainties.\nRisso et al. (2011) compared different sampling techniques in which the Derivative Tree, Monte Carlo and Latin Hypercube methods were used in a synthetic reservoir with 4 uncertain attributes. Although all three methods present a satisfactory result, the Latin Hypercube has the best results considering precision and number of simulations. Similarly, Maschio et al. (2005) applied the Derivative Tree technique to quantify the impact of uncertainties on the HM process and in the production forecast. In addition to the proposed methodology, the application shows that management of uncertainties in the prediction phase is important and that it can be considered in the HM stage.\nFig. 1. Reservoir uncertainty reduction workflow.\nEmerick and Reynolds (2012) combined the Ensemble Kalman filter (EnKF) and Markov Chain Monte Carlo (MCMC) methodologies to obtain a relatively efficient algorithm for sampling the posterior probability density function (PDF) for reservoir-model parameter. They tested the method on a small 3D two-phase-flow reservoir, allowing a long Markov chain creation for comparison. EnkF-MCMC narrows the spread of reservoir predictions, resulting in histograms significantly closer to those obtained with the long MCMC case. In summary, the application of EnkF-MCMC improves the data matches from EnKF by generating samples of higher-probability regions of the posterior PDF.\nRecently Ferreira et al. (2014) studied the emulator methodology applied to uncertainty reduction quantification. It uses a stochastic representation of the computer model to quantify the reduction in the parameter input space from production data over different periods. Using a five-spot synthetic case the authors showed the importance of using emulators in the uncertainty reduction and HM process. At an early stage, identifying the hypothetical real field permeability and possible values for channel positioning reduced the uncertainties.\nReservoir uncertainty has been studied for many years with different techniques and objectives. This paper presents a modified workflow based on the procedure given by Maschio and Schiozer (2013), with the addition of a smoothing step to capture the reservoir response trend along the attribute range, and a sensitivity matrix step to aid the uncertainty analysis and local HM processes. The Latin Hypercube (LHC) sampling technique is applied in the first stage of the methodology to provide the variability of the reservoir uncertain attributes. In the second stage, the gap between history data and simulated data is linked to a combination of attribute variation. The process uses a smoothed mismatch data set from the selected OF and polynomial fitting to identify the attribute interval, minimizing the mismatch.\nThe proposed methodology aims primarily to evaluate and reduce reservoir uncertainties, while improving the global history matching (HM) and, secondly, to provide a sensitivity analysis of reservoir response and attributes aiding the uncertainty analysis process.\nFig. 2. Moving average outputs with different y terms for a set of 100 data points. By taking the arithmetic means of subsequences of y terms, red curve - 2 terms, yellow - 4, green - 6, and blue - 8 (from MathWorld - A Wolfram Web Resource). (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)\nTable 1\nThe R2 sensitivity matrix structure.\nReservoir attributes\tObjective functions\t\t\n\tOF1 misfit\tOF2 misfit\tOFm misfit\nA1\tRA1 OF1\tRA1 OF2\tRA1 OF1m\nA2\tRa2_OF1\tRa2_OF2\tRA2_OFm\n\t\t\tJ\nAn\tRAn_OF1\tRAn8/5_OF2\tRAn_OFm\nThe methodology is applied to a synthetic reservoir with twenty uncertain attributes and in the UNISIM-I-H model (based on the Namorado field, Campos Basin, Brazil), where the objective functions (OFs) are oil and water production rates and bottom-hole pressure. We examine the uncertainty reduction every cycle of the loop shown in Fig. 1 and the principal properties influencing the reservoir model through the sensitivity matrix.\n2.\tMethodology\nThe workflow in Fig. 1 shows the proposed methodology. The first step is reservoir characterization from defined attributes and\nFig. 3. Schematic example of two OF misfits (OF1 and OF2), the corresponding polynomial 1 and 2 (Poll and Pol2), the average polynomial and the distribution (modified from Maschio and Schiozer, 2013).\nuncertainty limits. In the next step, Latin Hypercube sampling generates a distribution of plausible sets of attribute values. The amount of desired models (samples) varies according to the number of reservoir attributes.\nLHC returns an a-by-b matrix, W, containing a Latin hypercube sample of a divisions on each of b variables. For each column of W, the a divisions are randomly distributed with one from each interval (0,1/a), (1/a,2/a),..., (1-1/a,1), and are randomly permuted. Given a and b, the matrix W can be compared with the maximum number of combination given by (a!)b-1.\nAfter that, objective functions must be selected. The models are run in the simulator and the misfit for all OF between dynamic (historical) and simulated data is obtained. Data reorganization follows to study the misfit profile along reservoir attribute variation.\nBefore any processing, a moving-average smoothing algorithm as described by Achelis (1995) is applied individually to each misfit function. The algorithm removes the outlier results while preserving underlying patterns. The moving average is a smoothing method that provides a time series, constructed by taking averages of several sequential values of another time series. So taking an average of the points near an observed point provides a reasonable estimate of the trend. Fig. 2 shows the moving average for a set of 100 data points, by taking the arithmetic means of subsequences terms. This process provides the next stage with the smooth misfit data collection to fit a polynomial for each attribute.\nThe polynomial correlates the normalized OF misfit with the attribute range. The normalization uses the maximum misfit range among all OF. We calculate the coefficient of determination R2 for each polynomial and, at the end, obtain an R2 sensitivity matrix between reservoir attributes and OF misfit. Therefore, at this stage\nPorosity (a)\nRegion2\nRegionl\nRegion5\nRegion4\n0.00 0.501.00 miles\n0.00 1.00 2.00 Km\n0.16 0.17 0.18 0.19 0.20 0.21 0.22 0.23 0.24 0.25\nPorosity K layer: 5(c)\nPorosity K layer: 1(b)\n0.00 0.501.00 miles\n0.00 0.501.00 miles\n0.00 1.00 2.00 Km\n0.00 1.00 2.00 Km\no - o _ o\nO -o__ o' _\nCM\nO -o -o__ o' _\nCM\no - - o _ _ o\nFig. 4. Case 1 reservoir model.\no\no - o _ o\no - o _ o\n_ NJ o\n\u2014\to\n-\to _ o\no -O -o _ o' _\nthe multivariate sensitivity study is completed and can be used for future applications. Table 1 shows the R2 sensitivity matrix structure.\nIn Table 1, each matrix element represents the quality of fit of a model. For instance, RAi_oFi element shows how well the polynomial fits the OF1 misfit using all LHC experiments the OF, n is the number of reservoir attributes and m is the number of OF.\nThen, we assess the final objective to further reduce uncertainty and prioritize each OF. For instance, the user may want to\nprioritize water breakthrough, so the user will attach high weights to calculate the water production OF. Otherwise, the process continues giving unitary weight to each OF.\nAt this point, we apply a filter to the R2 sensitivity matrix to select the high matrix values. Each selected polynomial is a function of a reservoir attribute and the OF misfit. The key difference from traditional methods is that reservoir attributes are modified together with all the uncertain attributes (LHC sampling). With this procedure,\nTable 2\nBase model reservoir attributes and their limits - case 1.\nReservoir attributes Multipliers\nLimits\tKxi\tKX2\tKx3\tKx4\tKX5\tKzi\tKz2\tKz3\tKz4\tKz5\nLower\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\nBase\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\nUpper\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\nCorey's equation\nLimits\tExpoW1\tKrw1 *\tExpoW2\tKrw2*\tExpoW3\tKrw3*\tExpoW4\tKrw4*\tExpoW5\tKrw5*\nLower\t1.00\t0.15\t1.00\t0.15\t1.00\t0.15\t1.00\t0.15\t1.00\t0.15\nBase\t2.20\t0.60\t1.10\t0.80\t4.00\t0.50\t1.30\t0.70\t4.30\t0.80\nUpper\t5.00\t0.90\t5.00\t0.90\t5.00\t0.90\t5.00\t0.90\t5.00\t0.90\nFig. 5. Reservoir attribute range versus normalized square error (blue), smoothed NSE (red) and polynomial (black) for water production at Prod3 well, cycle 1 - Study test 1. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)\neach polynomial not only represents the misfit trend along a unique attribute variation, but also shows the relationship between misfits and a combination of attribute variations.\nNext, all the filtered polynomials are combined to create a global misfit response per attribute. Fig. 3 shows a schematic example with two OF misfits, polynomials, average polynomial (global misfit) and the distribution. The average polynomial becomes the input data, which is used to fit a probability distribution (black curve in Fig. 3). The distribution prioritizes the range of attributes over the lower global misfit. Different distribution percentiles can be chosen to conservatively reduce the range, using low percentiles, for instance, P25 or more severe reduction with high percentiles (P90).\nAt this stage, the models are run with the reduced attribute ranges and evaluated using a match quality indicator. If the indicator does not improve the results, the process is restarted, using results from the previous cycle. Otherwise, the last step is to improve the local HM and consequently the attribute range. The workflow is completed if the quality criterion and the local HM are achieved. The process stays in the loop until a specific criterion is met.\nAiming to create a match quality indicator (\u00a5), we gathered, through the Euclidean norm, the outputs from the misfit function of each well and OF. A square error function shown in Eq. (1) was selected according to Bertolini and Schiozer (2011) to characterize the misfit.\ncl\nSqEm =\t(hi - sf)2\t(1)\ni = 1\nwhere the index s represents simulated data, h, historical data, d, total number of data, and m, number of OF. However, the match quality indicator (\u00a5) is obtained dividing the Euclidean norm by the Euclidean norm of the base model.\n, . fr- 1 \u21222f\t(2)\n[PL 1 (SqEw)2] =\nThe interpretation of is direct. Values greater than 1 represent a worsening in the HM; values equal to 1 represent that model has the same performance of the base model; and values smaller than 1 represent improvements in the HM.\nThis work focuses on uncertainty reduction and on multivariate sensitivity matrix based on history reservoir data. Neither the conventional HM, nor optimization under uncertainty, which identifies the best set of models to make predictions, is studied in this paper.\n2.1.\tCase 1 - synthetic reservoir model\nThe first case study uses an upscaled model from a refined reservoir. The porosity was upscaled through the arithmetic average using the method for permeability as described by Maschio and Schiozer (2003). It is a technique based on a heterogeneity coefficient (Dykstra-Parsons), and upper and lower permeability limits. The history data used in the OF calculations were obtained from the refined model, in which 30,600 cells are distributed in 90 x 34 x 10 blocks and of a single porosity type. Horizontal permeability varies from 10 to 1900 mD, with a median of 373 mD and standard deviation of 284 mD. The vertical permeability has the same heterogeneous distribution, with a median of 6.8 mD and standard deviation of 105 mD. The porosity distribution has a median of 0.19 and a standard deviation of 0.05. Although it is a synthetic upscaled reservoir, the true reservoir attribute values to match the history data are unknown. The upscaled base case model contains a similar heterogeneity to the refined model. It is divided into five regions, shown in the top right of Fig. 4 with different geometries, area and volume, and different geological properties. The model presents four uncertain attributes per region.\nThe attributes are horizontal permeability in the X direction (Kx), vertical permeability in the Z direction (Kz), coefficient of Corey (Eq. (3)) for water relative permeability (ExpoW) and the maximum value of the water relative permeability in Corey's equation (krwn). Corey's equation\nTable 3\nCycle 1 R2 sensitivity matrix - study test 1.\nCycle 1\t\tObjective functions\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nR2\tmatrix\tProdi\t\t\tProd2\t\t\tProd?\t\t\tProd4\t\t\tProdi\t\t\n\t\tOil\tWater\tBHP\tOil\tWater\tBHP\tOil\tWater\tBHP\tOil\tWater\tBHP\tOil\tWater\tBHP\n\t\tB92\t| 0.06\tB*\t| 0.13\t| 0.16\t|o.22\t0.02\t0.03 |o.29\t\t0.04\t|0.29\t|0.18\t|o.23\t|o.24\tB-39\n\tK.2\t| 0.12\t\u25a0>.33\t| 0.09\t\u25a088\tB-88\t\u25a0.85\t| 0.13\tb-23\t0.11\t|o.26\t|o.l6\t|o.25\t| 0.07\t| 0.07\t|o.21\n\tKx3\t|o.2O\t| 0.05\t|o.l7\t0.05\t| 0.05\t|).39\t\u25a090\t\u25a074\tI87\t|o.l9\t|d.39\t| 0.03\t\u00a10.14\t| 0.14\t|o.l7\n\tK\u00ab4\t|o,17\t| 0.05\t|p.48\t|0.27\t|o.24\t|o.2O\t| 0.12\t|0.18\tb33\t1.94\t|o.16\t\u25a095\t0.04\t| 0.04\t\n\tKx5\t|o.21\t| 0.07\t| 0.15\t|o.2O\t|o,15\t| 0.13\t0.02\t| 0.08\t|d.28\t|o.23\t|o,18\t|o,19\t\u25a090 B89 ^85\t\t\n\tK,i\t|o.2O\t|o.21\t|0.27\t|o.32\t[o.3O\t|o,18\t|C.33\tB.32\t\u00a10.20\t|o.24\t|o.2O\t|o.24\t0.00\t0.00\tB-27\n\t*z2\t|o.2O\t|o.22\t| 0.13\t\u25a072\tB-74\t|o.l5\t\u00a10.19\tB.31\t|o.2O\t|o.25\t|o.28\t|o,18\t\u00a10.31\t|0.30\t|o.17\n2\tKu\t| 0.08\t| 0.07\t| 0.05\t|o,16\t|o,28\t|o.21\t\u25a081\t\u25a080\t|).41\t\u00a10.17\t|o,19\t|o.2O\t|0.31\tb-32\tB-33\n3 -n\tK!a\t|o.21\t| 0.11\t|0.17\t| 0.11\t| 0.11\t| 0.11\t| 0.08\tI0-17\t0.02\t| 0.10\t| 0.05\t|0.30\t|o,16\t|o,17\t\u25a0\u25a044\nro\tK,s\t| 0.06\tJo. 22\t| 0.11\tB32\t|o.28\t|o.36\t| 0.12\t\u00a1011\t|o,19\t0.02\t|o,16\t|p.46\tB59\tB59\t| 0.14\no\tExpoWl\tB'3\tB*97\t|0.20\t|c.28\t|o.34\t|o.22\t|0.30\t|o.2O Id. 32\t\t0.06\t| 0.08\t| 0.07\tl<\t|o.3O\tBso\n>\tKjwl*\tB63\tB64\t|o.24\t|0.20\t|o,18\t\u25a0\u202254\t|o.32\tb-27\t|D.26\t\u00a10.17\t| 0.05\t|o.2O\t|o,19\t|o,19\tBso\n<u (\u00a3.\tEXpoW2\t\u25a0-44\t|o.21\t|0.28\tB>\t\u25a066\tB.67\t|o,19\tb23\t0.04\t10.31\t| 0.06\t\u00a10.16\t|0.31\tB.33\t| 0.14\n\tw\t| 0.14\t| 0.05\t| 0.02\tB-52\t\u25a0si\t|o.32\t0.01\t0.03\t0.07\t| 0.14\t|o.l9\t|o.21\t0.03\t| 0.03\t|o.25\n\t^xpoWS\t\u25a0\u202248\t| 0.10\t|o.39\t|o.23\t|o.26\t| 0.08\tB83\tB89\tB82\t[ 0.07\t| 0.12\t| 0.04\t0.04\t| 0.03\t| 0.03\n\tK\u21223\u2018\t|0.22\t|c.28\t|o.26\t| 0.11\t| 0.13\t|o.22\tB74\t\u25a091\t\u25a078\t| 0.07\t|o.21\t|0-33\t|o.29\t|0.28\tB52\n\t^xpoW4\t| 0.13\t\u25a0\u202249\t| 0.02\t| 0.07\t| 0.06\t\u00a10.42\t|o.23\tb-23\t|0.17\t\u25a0so\t\u25a0\u202293\t|o.l5\t|o.34\t|o.33\t|o.l9\n\t\tB67\t| 0.12\tB-42\t| 0.11\t| 0.11\t\u25a0_47\t| 0.08\t| 0.05\t|).36\t|o.34\t\u25a068\t|o.45\tf.45\tB.45\tB-79\n\t^xpoWS\t|o.3O\t|o.26\t|0.19\t|o.24\t|o.3O\t|P-46\t|0.33\t\u25a0 35\t|0.28\tB-42\t| 0.03\t\u25a0\u202257\tB82\t\u25a083\t\u25a066\n\tK\u2122s\u2019\t|o.28\t|d.28\t| 0.10\t| 0.07\t| 0.04\t| 0.07\t|o.l8\tb-29\t|o.22\t|0.29\t|p.30\t| 0.15\tB82\tB83\t\u25a0\u25a036\nfor water relative permeability shows the last two attributes. However, the simulation model has a total of 20 uncertain attributes.\nKrw\nkrw\nq ExpoW\nPw ~ Swir\n(3)\nn\nwhere Krw is the water relative permeability, Sw is the water saturation, Swr is the irreducible water saturation and, Sor is the residual oil saturation.\nThe permeabilities Kx and Kz are modified in the simulation models through multiplier numbers. The limits are 0.5 and 2.0, which represent half and double the absolute permeability Kx and Kz of the base model. The base model is the unitary reference of the absolute permeability multipliers, while the attributes of ExpoW present a variation range from 1 to 5 and the attributes of km* from 0.15 to 0.90. Table 2 presents a reservoir attribute summary.\nThe corner point grid shown in Fig. 4 has 2550 cells distributed in 30 x 17 x 5 blocks. The reservoir has five producer wells and five injector wells, the producer/injector pair for each region is located in the same reservoir position. The reservoir cells of the injector wells are Injectorl (4;1-6;5); Injector2 (14;1-9;5); Injector3 (20-29;6;5); Injector4 (3;8-17;5) and Injector5 (10-28;14;5) and for the producer the cells are Prod1 (4;1 -6;1); Prod2 (14;1-9;1); Prod3 (20-29;6;1); Prod4 (3;8-17;1) and Prod5 (10-28;14;1).\nThe objective functions (OF) considered in this case were oil production (m3/day), water production (m3/day) and bottom-hole pressure (KPa) for the five production wells. In total 15 functions were considered. The well production strategy used in the simulation had a surface liquid limit of 4770 m3/day and the bottom hole pressure limit of 20,684 KPa. The maximum liquid rate on each simulated date was input into the simulator. The simulations used the commercial IMEX software.\nThe constraints for the injector wells were the maximum surface water rate of 4770 (m3/day) and the maximum bottom hole pressure of 82,737 KPa.\nThree study tests were analyzed. From previous runs, 150 Latin Hypercube samples captured the mismatch trend versus reservoir\nparameter change. Study test 1 uses 150 samples from LHC and 20 uncertain parameters, which provides a 150 x 20 (W) matrix; moving average process with 10% of the number of samples. Study test 2 uses the same set of samples and parameters, but without the smoothing stage. Finally, Study test 3 uses only 50 Latin Hypercube samples (50 x 20 matrix) and a moving average of 10% to demonstrate the impact of a reduced number of samples on the proposed method. For all tests, we used the four cycles presented in Fig. 1 and the likelihood distribution P25 to select the new attribute range.\nWe normalized the mismatch between simulated and history data between the maximum and minimum simulated values for all three OF. Finally, we used the square error function, providing the normalized square error (NSE) data.\n2.2.\tResult 1 - synthetic reservoir model\n2.2.1. Study test 1: moving average technique applied to smooth data for 150 LHC experiments\nOn this particular test, the methodology outputs per step are presented according to the sequence presented in Fig. 1. Fig. 5 illustrates the smoothing and polynomial fitting stage in the first cycle. It shows the water production normalized square error (NSE) for Prod3 well; the smooth NSE and the polynomial of degree 3 for all experiments selected by LHC sampling technique. Note that for most of the attributes the NSE and even the smoothed NSE do not have a clear trend. We concluded that other attributes are affecting the water production for these cases, here called interaction effect among the attributes.\nTable 3 clearly shows the NSE versus reservoir attributes. The matrix R2 shows how well the OF is associated with the reservoir attribute, where oil represents oil production OF; Water, water production OF; and BHP, bottom hole pressure OF. Numbers closer to 0 indicate that the polynomial does not fit the data very well, while R2 closer to 1 indicates a good fit. The highlighted column in Table 3 shows the R2 for those polynomials presented in Fig. 5. Applying a R2 > 0.3 cutoff, only seven polynonials out of twenty were selected for water rate in Prod3 well.\nProdi\n2500\n2000\nOOO History \u25a0 Base model\nCycle 1\n^\u25a0i Cycle 2 Cycle 3 Cycle 4\n4000\n5000\n4000\n3000\n2000\n1000\nProd4\n1000\nProd5\n4000\n3000\n2000\n1500\n1000\n500\n50\t100\nProdi\n4000\n3000\n2000\n1000\nProd2\n50\t100\nProd2\n3000\n2000\n1000\nProd3\n50\nProd3\n100\n2500\n2000\n1500\n1000\n500\n50\t100\nProd4\n50\t100\nProd4\n4000\n3000\n2000\n1000\n50\t100\nProd5\n0\nr X104\nx10\n50\t100\nTime (month)\n50\t100\nTime (month)\nFig. 6. Objective function responses for all cycles - study test 1. (For interpretation of the references to color in this figure, the reader is referred to the web version of this article.)\nx10\n100\nTime (month)\nx10\n50\t100\nTime (month)\n0\n0\t50\t100\nX1Q4\tProd5\n50\t100\nTime (month)\nIn Fig. 6, all OF considered in this case are combined. The different colors are associated with the cycles. The black circle curves represent the history data and the dotted black lines, the base model. In cycle 1 the simulation model responses are scattered around the history data\ndue to the wide range of the reservoir attributes. On the other hand, the cycles 2, 3 and 4 show a thin belt closer to the desired response. Following the sequence presented in Fig. 1, the polynomials with R2 > 0.3 were combined to give a unique output for each attribute.\nNumber of experiments (HCL)\nNumber of experiments (HCL)\nFig. 7. Evolution of the match quality indicator - study test 1.\nCycle 1 ^AVERAGE = 16227\t*\n** >\t* * -\n\t* *\n** *\t* *** *\u25a0 ****** *\n\u2022 * +* * *\t\u2666* * * t *\t# . *\t> * * * *\t*\tu,* * V *\t** *\t/ ** \u25a0 iw ********* */\u2666\u00bb* \u2019\u00bb;4 \u2022\u2022 V.\nCycle 4\nWave rag f= 0.2311\nTable 4\nCycle 3 R2 sensitivity matrix - study test 1.\nCycle 3\t\tObjective functions\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nR2\tmatrix\tProdi\t\t\tProd2\t\t\tProd3\t\t\tProd4\t\t\tProdi\t\t\n\t\tOil\tWater\tBHP\tOil\tWater\tBHP\tOil\tWater\tBHP\tOil\tWater\tBHP\tOil\tWater\tBHP\n\tK\u00abi\t(.53\t|o.u\t(.99\t10.13\t| 0.14\t(.20\t| 0.07\t1 0.11\t1 0.10\t| 0.12\t(.21\t| 0.09\t(.23\t(.26\t| 0.07\n\t\u00abx2\t(.20\t(.35\t| 0.14\t(.90 (88 (93\t\t\t| 0.06\t(.16\t(.25\t(.16\t| 0.05\t| 0.09\t(.19\t(.20\t(.33\n\t*x3\t| 0.10\t| 0.03\t(.29\tJ.49\tJ.48\t(.37\tJ.95 J).89 J).87 |o.47\t\t\t\t| 0.07\t(.32\t(.16\t(.16\t(.13\n\t*x4\t0.04\t1 0.10\t| 0.10\t(.18\t(.20\t| 0.11\t| 0.14\t|0.23\t|0.17\tJ.80\t[0.I8\t|o.97\t0.05\t| 0.06\t(.34\n\t*xS\t1 0.11\t1 0.12\t(.33\t(.19\t(.19\t| 0.09\t| 0.09\t(.17\t(.16\t(.40\t(.20\t| 0.08\t(\u202271\t(.71\t(93\n\t\u00abzl\t(.16\t| 0.07\t(.32\t0.03\t| 0.03\t| 0.15\t(.41\t(.44\t(.31\t| 0.11\t(.18\tB-71\t| 0.09\t| 0.10\t(.48\n\t\u00abz2\t|0.25\t(.29\t(.25\t|0.27\t(.24\t(.21\t| 0.07\t| 0.06\t(.22\t(.47\t| 0.03\t(.44\t(.29\t(.28\t| 0.11\n\tKz3\t1 0.10\t| 0.06\t| 0.10\t1 0.10\t| 0.08\t(.20\t(.53\t(.61\t(.41\t(.25\t(.17\t(.13\t(.23\t(.24\t(.36\n\u25a1\tKz4\tI 0.06\t| 0.13\t| 0.09\t0.04\t| 0.05\t(.19\t| 0.06\t(.16\tI 0.01\t0.03\t| 0.09\t| 0.04\t0.03\t| 0.03\t(.54\n4-\u00bb ro\tKzS\t| 0.14\t(.17\t(.25\t0.04\t| 0.04\t(.32\t(.17\t(.19\t| 0.14\t10.13\t(.17\t(.40\t(.32\t(.33\t(.18\no\t\t(.93\t(.98\t| 0.03\t0.01\t1 0.01\t| 0.04\tIo.21\t10.15\t(.39\t[o.48\t| 0.02\t(.37\t(.32\tIo. 31\t| 0.10\n> cu\tKrwl*\tK-47\t(.49\t1 0.11\t(.53\t(59\t| 0.07\t(.35\t(.35\t| 0.08\t(.32\t| 0.06\t(.26\t(.36\t(.35\t| 0.07\n<D or\t^xpoW2\t(.20\t(.25\t(.40\t(66\t(.62\t(.83\t(.22\t(.17\t| 0.04\t| 0.10\tI 0.01\t| 0.10\t(.34\t(.34\t| 0.07\n\t\t| 0.09\t| 0.02\t| 0.06\t\u00a10.41\t(.38\t\t| 0.04\t| 0.03\t| 0.07\t(.34\t(.21\t| 0.04\t(.30\t(.29\t(.24\n\t^xpoW3\t| 0.09\tI 0.11\t(.26\t| 0.07\t| 0.08\t| 0.07\tK75\t|D.9C |p.86 | 0.16\t\t\t(.36\t| 0.16\t(.19\t(.19\t(.22\n\t\u00abiwS*\t(.42\t(.36\t(.29\t|0.32\t(.28\t(.21\t(.48\t(71\tft\u201945\t| 0.04\t(.24\t| 0.14\t(.26\t(.27\t(.16\n\t^xpoW4\tB-56\t(.25\t| 0.14\t(.43\t(.42\t(.20\t(.22\t(.24\t(.19\t(.53\t(.39\t(.19\t(.23\t(.22\t(.17\n\tKzw4*\t0.01\t| 0.10\t| 0.17\t(.28\t(.26\t(.19\t(.22\t(.17\t(.22\t(.52\t(60\t(.17\tB-59\t(.59\t(.16\n\t^xpoWS\t(.22\t(.23\t| 0.07\t(.35\t(.37\t\t(.27\t(.27\t(.26\t(.16\t(.3?\t(.27\t(.67\t(.66\t(81\n\tK\u2122s*\t(.47\t(.50\t0.01\t(.37\t(.39\t| 0.06\t| 0.11\t| 0.11\t| 0.13\t(.27\t(.25\t| 0.11\tB-57\t(56\t(.36\nFinally, a likelihood function was applied, providing a relationship between the attribute range and OF misfit. The final attribute ranges are presented in Fig. 8.\nFrom Fig. 6 and Table 3, note that it is important to analyze several reservoir behaviors when applying the proposed methodology.\n(I)\tObserve that even considering 20 uncertain attributes in the upscale model, it may not capable of representing the history data. Therefore, either other reservoir attributes that were not considered uncertain are contributing to a mismatch, or different range limits are needed on the current 20 uncertain attributes;\n(II)\tAll OF considered for this case showed an improvement along the cycles. The methodology combines all the OF responses and adjusts the best attribute interval to improve the global matching between observed and simulated data. Wells with comparatively lower rates, such as Prodi and Prod4 wells for water rate, showed a wider spread around the history data.\nWe know that objective functions combined in one general equation delivers globally improved matched models, but to achieve this sometimes they do not necessarily deliver the same for local functions with lower rates, and consequently lower SqE. Further, Bertolini and Schiozer (2011) showed that simple and squared error functions influence the HM optimization process, which may affect this method as well. However, the methodology prioritizes OFs with high accumulative difference between simulated and history data;\n(III)\tThe R2 sensitivity matrix shows how each attribute correlates with OFs. The optimization of the attribute ranges with higher R2 coefficients can lead to better local HM (last check of the proposed workflow - Fig. 1), for instance, Prodi well for water rate.\n(IV)\tThe number of simulation runs is the number of LHC samples multiplied by the number of cycles. For Study test 1, 150 simulation runs were used in each cycle (LHC 150 x 20) to support the uncertainty reduction.\nProdi - water rate\n|ooo Normalized square error (NSE)\tSmooth NSE ^\u2014Polynomial\nx10S\tx10S\n8 -------<------\u25a0------.------,----- 8 ---------\u25a0-------------\u2022--------\n1\t1.5\t2\t2.5\t3\t3.5 0.4\t0.5\t0.6\t0.7\t0.8\t0.9\nExpoWl\tKrwi*\nFig. 8. NSE, smoothed NSE and polynomial for water rate Prod1 well - study test 1.\nThe match quality indicator, F, described above was used to evaluate the HM improvement along the cycles. Fig. 7 shows F in all four cycles for every simulation model.\nThe R2 sensitivity matrix, cycle 3, in Table 4 shows that ExpoW1 and Krw1n have the first and third highest R2, respectively for water rate Prodi well.\nFig. 8 shows the NSE, smoothed NSE and the polynomial along the ExpoW1 and Krw1n range in cycle 3. The lower NSE for ExpoW1 were allocated between the attribute range (multiplier) 1.0, lower\nlimit (LL) and 2.0, upper limit (UL) and from 0.70 (LL) to 0.90 (UL) for the Krw1n attribute. These intervals are slightly different from the final ranges of cycle 4, which consider all three OFs and the five producer wells. In cycle 4, ExpoW1 varies from 1.05 (LL) to 3.30 (UL) and Krw1n from 0.454 (LL) to 0.8725 (UL). Fig. 9 shows the uncertainty reduction from the original attribute ranges (Table 2) to the cycle 4 ranges and the modified ExpoW1IKrw1 ranges.\nNote that interaction effect mentioned previously affects simulation results when ExpoW1 and Krw1* attributes interval are changed.\nTime (month)\nTime (month)\nTime (month)\nTime (month)\nFig. 10. Cycle 4 models (green) and cycle 4 modified models (magenta) responses - Study test 1. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)\nooo History\nTime (month)\nProd2\nProd3\n4000\nProdi\nProd3\nProdi\nProd2\nProd3\nTime (month)\nTime (month)\nTime (month)\n5000\n4000\n3000\n2500\nFig. 11. Objective function response for all cycles - study test 2.\nProdi\n\t5000 4000 3000 2000 1000\t\t5000 4000 3000 2000 1000\t\t\t\n\t0\t..\t0\t\t\t\n2000\n1000\nProd4\n5000\n\t50\t100\n\tProd2\t\n2000\n1500\n1000\n500\n50\t100\nProd4\n50\t100\nProd4\n3000\n4000\nProd5\n4000\n3000\n2000\n1000\n50\nProd5\n100\n2000\n1000\n100\nx 10\n50\nX10'\tProd5\n50\t100\nTime (month)\n50\t100\nTime (month)\nFrom Table 4 we can predict which OF will be most influenced. When the modified ranges stay in the lower OF NSE interval, there are insignificant variances in the results. On the other hand, the results change more when the ranges are modified to the upper OF NSE interval. This change occurred in Prod4 well for oil and water rates. The modified ExpoW1IKrw1* attribute ranges improved Prodi water rate results, but changed Prod4 oil rate and, consequently, the water rate. Fig. 10 shows the reservoir model results from cycle 4 and the results from ExpoW1IKrw1* modified attribute ranges. Note the R2 for Prod4 oil rate function is 0.48 for ExpoW1 and 0.32 for Krw1 *. Therefore,\nthe right attributes can be locally adjusted according to R2 sensitivity matrix.\n2.2.2.\tStudy test 2: raw data for 150 LHC experiments\nUnlike Study test 1, the moving average smoothing technique was not used in Study test 2. The OF curves presented in Fig. 11 are evenly spread for the last cycle.\nThe raw NSE in this test shows an unsatisfactory trend and consequently provides low R2 coefficients. Therefore, the polynomials\nNumber of experiments (HCL)\nFig. 12. Evolution of the match quality indicator - study test 2.\nCycle 1\t*\t\tCycle 2\nWaverage= 1-6227\t\t3.5\tWaverage= 1-0224\nCycle 3\t*\t\tCycle 4\nV'werage= 06642\t\t1.2\tV'average= \u00b0-4366\n* * * * * *\n**\n* * * ** *\n*\t*\tJ\n.1.\tJ, -*\u2022 **** * \u201e\nFig. 13. UNISIM-I-H model: porosity map and well locations.\ndo not identify the reservoir attributes range to reduce the OF error functions. The match quality indicator plotted in Fig. 12 reflects this issue.\nComparing the results of Study tests 1 and 2, we can see that the smooth technique helped filter the data and extract the principal trend.\n2.2.3.\tStudy test 3: moving average technique applied to smooth data for 50 LHC experiments\nConsidering only the match quality indicator, Study test 3 performed well compared with Study test 2, which used 150 LHC samples. The^AVE for Study test 3 was 0.2797 in cycle 4, compared with \u00a5AVE equal to 0.2311 for Study test 1 and \u00a5AVE equal to 0.4365 for Study test 2. Even with one third of models from Study test 2, Study test 3 presented better results. The applied smoothing technique extracted the principal trend even with fewer models.\n2.3.\tCase 2 - UNISIM-I-H reservoir model\nThe geological model has 3.5 million active cells and uses core and well logging data, 2D and 3D seismic data provided by Brazilian\nNational Petroleum Agency - ANP and also from Petrobras (released public data). It uses structural, facie and petrophysical models from Namorado field, located in the Campos Basin, Brazil. Avansi and Schiozer (2015) describe the details of the UNISIM-I-H model.\nThe dataset contains the well log information for 56 wells drilled through the upper Macae formation (Meneses and Adams, 1990). This field is one of the main reservoirs in the Campos Basin, largely comprised of sandstone of turbidite (Guardado et al., 1989a, 1989b, 2000). The 3D seismic volume and 2D seismic lines are available in the public dataset from ANP. These data are used to derive structural (reservoir boundary limit; top, bottom, sequences and faults) and sedimentological (zones and horizons) information for reservoir characterization.\nBased on the geological model in a high-resolution grid, an upscaling procedure to a medium reservoir scale was necessary to decrease the computational effort. A simulation grid cell resolution was defined with 100 x 100 x 8 m3 blocks to reflect reservoir behavior and heterogeneities. It was discretized into a corner point grid (81 x 58 x 20 cells, with 36,739 active total cells). Porosity was upscaled through an arithmetic volume weighted method to ensure that the hydrocarbon pore volume remained constant when upscaling (additive property characteristics). Permeability was upscaled\nFig. 14. UNISIM-I-H reservoir regions and Fault F1.\nTable 5\nOriginal (cycle 1) reservoir attribute range for UNISIM-I-H model.\nLimits\tReservoir attributes\n\tMpor1\tMpoR2\tMpor3\tMpor4\tMpor5\tMpor6\tMpor?\tMpor8\tMpor9\nLower\t0.70\t0.70\t0.70\t0.70\t0.70\t0.70\t0.70\t0.70\t0.70\nBase\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\nUpper\t1.30\t1.30\t1.30\t1.30\t1.30\t1.30\t1.30\t1.30\t1.30\nLimits\tMporw\tMporn\tMporn\tMKh\tMKV\tWOC (m)\tCoeffA\tCoeffB\tExpoW\nLower\t0.70\t0.70\t0.70\t0.50\t0.50\t3095.00\t0.085\t-0.150\t1.00\nBase\t1.00\t1.00\t1.00\t1.00\t1.00\t3095.00\t0.085\t0.000\t3.00\nUpper\t1.30\t1.30\t1.30\t3.00\t3.00\t3105.00\t0.095\t0.150\t5.00\nusing a flow-based upscaling technique described by (Deutsch, 1989). When an isotropic permeability is upscaled, the effective results become anisotropic; three effective permeabilities in all directions (i, j and k) are then obtained for the upscaled reservoir model. Fig. 13 shows the porosity map and the well locations.\nThe original volume of oil is 130 million m3, the oil density is 28\u00b0 API and the fluid model is the Black Oil. The production strategy was defined with 25 wells (4 vertical producers, 10 horizontal producers and 11 injectors). The vertical wells NA1D, NA2, NA3D and RJS19 were the pilot vertical wells for this field. They produced for 4 years and then were closed for one year. The production restarted in the sixth year with all 14 producers and 11 injection wells for six more years.\nIn this work the UNISIM model was divided into twelve regions, as shown in Fig. 14. The model presents 18 uncertain attributes. Table 5 presents the limits for each attribute. They are 12 porosity multipliers (Mpor), one horizontal permeability multiplier (Mkh), one vertical permeability multiplier (Mkv) for the entire reservoir, wateroil contact (WOC), coefficient A (CoeffA) and coefficient B (CoeffB) of Eq. (4) which correlates porosity (<ph) with horizontal permeability (Kh), and ExpoW of Eq. (3). The vertical permeability without any\nmultiplier was defined as 10% of the horizontal permeability.\nKh = 10[(^xCoeffA)~ CoeffB]\t(4)\nThe oil rate and the water injection rate on each simulated date was input into the simulator. The BHP was limited to 15,000 KPa as a minimum for producer wells and a maximum of 35,000 KPa for injector wells. The maximum liquid rate was set to 3000 m3/day for producer wells and 6000 m3/day for injector wells. A Study test was run using 100 samples from LHC (100 x 18 matrix); moving average process with 20% of the number of samples; the three cycles presented in Fig. 1 and the likelihood distribution P50. The same OFs were evaluated, oil production (m3/day), water production (m3/day) and bottom-hole pressure (KPa) for 14 production wells. In total 42 functions were considered.\n2.4.\tResult 2 - UNISIM-I-H reservoir model\nFig. 15 shows the oil and water rate functions, and BHP for all vertical wells. The different colors represent the cycles and the black circle curves, the history data. Cycle 1 (cyan curves) uses the\nFig. 15. Vertical wells objective function responses for all cycles - UNISIM-I-H model. (For interpretation of the references to color in this figure, the reader is referred to the web version of this article.)\nTable 6\nReduced (cycle 3) reservoir attribute range for UNISIM-I-H model.\nLimits\tReservoir attributes\n\tMpor-!\tMpoR2\tMpor3\tMpor4\tMpor5\tMpore\tMpor7\tMpors\tMpor9\nLower\t1.03\t1.01\t1.16\t0.85\t1.07\t0.96\t0.85\t0.80\t0.83\nBase\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\nUpper\t1.15\t1.13\t1.28\t0.93\t1.193\t1.08\t0.97\t0.92\t0.95\nLimits\tMporw\tMporn\tMporn\tMKh\tMKV\tWOC\tCoeffA\tCoeffB\tExpoW\nLower\t0.77\t0.96\t0.83\t1.86\t1.58\t3101.04\t0.094\t-0.019\t2.00\nBase\t1.00\t1.00\t1.00\t1.00\t1.00\t3095.00\t0.085\t0.000\t3.00\nUpper\t0.89\t1.07\t0.94\t2.36\t2.10\t3103.02\t0.098\t0.037\t2.75\nField oil rate (m3/D)\nx 10*\nOOO History Cycle 1 Cycle 2 Cycle 3\n120 Months\nField water rate (m3/D)\nx 104\nAverage BHP x 10\tproducer wells (KPa)\n0\t40\t80\t120 Months\n0\t40\t80\t120\n120 Months\nFig. 16. Field objective function responses for all cycles and the evolution of the match quality indicator - UNISIM-I-H model.\n2\tMatch quality indicator (y/J\n\tI ITeycM = \u00ab.9861\t= 0.8511 y._,rl,3 = 0.477 |\n1.5\t****** * ** * * *--\n\t\n1 0.5\t*\t** *J>\t* *\t*\t* \u2019%\u00a3**** ****vAlv*tW ******* *$ **M\u2019*A^*%^\n\t20\t40\t60\t80\t100\nNumber of experiments (HCL)\noriginal attribute range presented in Table 5. Over the three cycles the reservoir range of attributes was reduced using P50 for cycle 2 and P65 percentile for cycle 3. The simulation results moved closer to the history data. A similar behavior was achieved for the horizontal wells.\nFrom cycle 1 to cycle 2 (red curves) the method was applied without the need of local adjustment based on R2 sensitivity matrix. Since the model responses followed the history data trend, the reduced attribute ranges were used without local correction in the following cycle. From cycle 2 to cycle 3 (green curves) the water production in some wells did not improve as expected. We then used the R2 matrix and identified the ExpoW of Eq. (1) as the most influential attribute for water production. However, at cycle 3 the attribute ranges were reduced again and the ExpoW attribute was modified based on R2 sensitivity matrix. Table 6 shows the reduced reservoir attribute range at cycle 3.\nEven with the attribute ExpoW modified in cycle 3 for a better water production match, the simulated results of some wells showed asymmetrical results around the history data. For instance, the NA2 well had higher water rate results than the history data for most models. This happened because the method prioritized the global matching between observed and simulated data as described in item (II) from case 1.\nFig. 16 presents the field performance results and the match quality indicator through the cycles. The history BHP average was calculated from the start of production (84th month). The history BHP average was calculated from the 80th month for the injector wells.\nOver the cycles the three field functions results moved closer to the history data and the match quality indicator/ improved.\n3. Conclusions\n\u2022\tThe methodology presented in this work yields uncertainty reduction of reservoir properties using dynamic data. All the ranges of reservoir attributes dropped along the cycles, providing a set of simulation models with improved HM for both cases;\n\u2022\tThe proposed methodology provided an R2 sensitivity matrix showing the relationship between the expected reservoir behavior and the\nreservoirs uncertain attributes. We presented an example to show how the matrix helps understanding the interaction between objective functions and reservoir attributes, and how it should be used to locally adjust the simulation model (Study test 1 from case 1). This work did not perform the local HM using optimization algorithms because the objective was only the first step (uncertainty reduction) but this will be addressed in future works;\n\u2022\tThis methodology provided a set of improved simulation models without the use of proxy models, avoiding an additional complex step of similar techniques. The multivariate approach allows understanding of the reservoir response through the sensitivity matrix and also allows future analysis and reservoir predictions;\n\u2022\tThe methodology showed that even a reduced number of experiments (Study test 3 from case 1) achieved better results than Study test 2, which used 3 times more models;\n\u2022\tThe smoothing technique helped obtain the general trend between reservoir attributes and the OF misfit selected in both cases. Comparing the results of Study test 1 and 2 from case 1, and results from Study test 2 and 3, showed that this technique was fundamental to improve the overall matching;\n\u2022\tThe global HM indicator clearly showed the improvement in every cycle. In both cases, the normalized Euclidean norm from the selected OF was used. The evaluation method will vary according to the objective of each study;\n\u2022\tThe definition of uncertainties of reservoir attributes and their range showed to be critical for both cases. With few and/or wrong attributes, and narrow ranges the proposed method will perform under the optimal solutions.\nNomenclature\nLHC\tLatin hypercube\nHM\thistory matching\nBHP\tbottom-hole pressure\nWOC\twater-oil contact\nR2\tcoefficient of determination\nMCMC\tMarkov Chain Monte Carlo\nOF\tobjective function\nF\tmatch quality indicator\nKrw\twater relative permeability\nSw\twater saturation\nSwir\tirreducible water saturation\nSor\tresidual oil saturation\nExpow\tcoefficient of Corey's equation for water relative\npermeability\nkrw*\tmaximum value of the water relative permeability in\nCorey's equation\nKx\teffective permeability in X direction\ns\tsimulated data\nh\thistory data\nSqE\tsquare error\ny\tnumber of terms used\tin the moving average algorithm\na\tnumber of LHC divisions\nb\tnumber of variables\nW\tLHC matrix with a-by-b dimension\nporosity\nKh\thorizontal permeability\nm\tnumber of OF\nd\tnumber of data points\nReferences\nAchelis, Steven B., 1995. Technical Analysis From A to Z. Second Printing. McGraw-Hill, pp. 184-192.\nAvansi, G.D., Schiozer, D.J., A New Approach to History Matching Using Reservoir Characterization and Reservoir Simulation Integrated Studies, OTC, 4-5 Maio, Houston, Estados Unidos, 2015.\nBennett, F., Graf, T., 2002. Use of geostatistical modeling and automatic history matching to estimate production forecast uncertainty - a case study. In: Proceedings of SPE 74389, International Petroleum Conference and Exhibition, Mexico, 10-12 February.\nBertolini, A., Schiozer, D., 2011. Influence of the objective function in the history matching process. J. Pet. Sci. Eng. 78 (1), 32-41.\nBissel, R.C., 1997. Combining geostatistical modeling with gradient information for history matching: the Pilot Point Method. In: Proceedings of SPE 38730 Annual Technical Conference and Exhibition, San Antonio, Texas, USA, 5-8 October.\nDeutsch, C., 1989. Calculating effective absolute permeability in sandstone/shale sequences SPEForm. Eval. 4 (3), 343-348.\nEmerick, A.A., Reynolds, A.C., 2012. Combining the ensemble Kalman filter with Markov Chain Monte Carlo for improved history matching and uncertainty characterization. In: Proceedings of SPE 141336-PA, SPE Reservoir Simulation Symposium Held in The Woodlands, Texas, USA.\nFerreira, C., Vernon, I., Schiozer, D.J., Goldstein, M., 2014. Use of emulator methodology for uncertainty reduction quantification. In: Proceedings of SPE 169405-MS, Latin American and Caribbean Petroleum Engineering Conference Held in Maracaibo, Venezuela, 21-23 May.\nGu, Y., Oliver, D.S., 2004. History matching of the PUNQ-S3 reservoir model using the ensemble Kalman filter. In: Proceedings of SPE 89942, Annual Technical Conference and Exhibition, Houston, Texas, USA, 26-29 September.\nGuardado, L.R., Gamboa, L.A.P., Lucchesi, C.F., 1989b. Petroleum geology of the Campos Basin, Brazil, a model for a producing Atlantic Type Basin: Part 2. AAPG Spec. Vol. A13242\nGuardado, L.R., Spadini, A.R., Brandao, J.S.L., Mello, M.R., 2000. Petroleum system of the Campos Basin, Brazil. In: Proceedings of M.R.M.a Petroleum Systems if the South Atlantic Margins: AAPG Memoir 73, pp. 317-324.\nLiu, C., McVay, D.A., 2010. Continuous Reservoir-Simulation-Model Updating and Forecasting Improves Uncertainty Quantification. SPE 119197.\nGuardado, L.R., Gamboa, L.A.P., Lucchesi, C.F., 1989a. Petroleum geology of the Campos Basin, Brazil, a model for a producing Atlantic type Basin: Part 1. AAPG Spec. Vol. A132, 33.\nManceau, E., Mezghani, I., Zabalza-Mezghani, I., Roggero, F., 2001. Combination of experimental design and joint modeling methods for quantifying the risk associated with deterministic and stochastic uncertainties - an integrated test study. In: Proceedings of SPE 71620 Annual Technical Conference and Exhibition held in New Orleans, Louisiana, 30 September-3 October.\nMaschio, C., Schiozer, D., 2003. A new upscaling technique based on Dykstra-Parsons coefficient: evaluation with streamline reservoir simulation. J. Pet. Sci. Eng. 40, 27-36.\nMaschio, C., Schiozer, D., 2013. A new procedure to reduce uncertainties in reservoir models using statistical inference and observed data. J. Pet. Sci. Eng. 110, 7-21.\nMeneses, S.X.d., Adams, T., 1990. Ocorr\u00eancias de resistividades an\u00f4malas no Campo de Namorado, Bacia de Campos.. Rio de Janeiro, Brasil.\nMaschio, C., Schiozer, D., Moura Filho, M.A.B., 2005. Methodology to quantify the impact of uncertainties in the history matching process and in the production forecast. In: Proceedings of SPE 96613 Prepared for Presentation at the SPE Annual Technical Conference and Exhibition, Dallas, Texas, USA.\nRisso, F.V.A., Risso, V.F., Schiozer, D.J., 2011. Risk analysis of petroleum fields using Latin hypercube, Monte Carol and derivative tree techniques. J. Pet. Gas Explor. Res. 1 (1), 014-021.\n4.\tARTICLE 3: Principal Component Analysis for Reservoir Uncertainty Reduction\nAndr\u00e9 Carlos Bertolini and Denis Jos\u00e9 Schiozer\nJournal of the Brazilian Society of Mechanical Sciences and Engineering, p. 1-11, 2015.\n40\nCrossMark\nREVIEW PAPER\nPrincipal component analysis for reservoir uncertainty reduction\nAndr\u00e9 Carlos Bertolini* 1 \u2022 Denis Jos\u00e9 Schiozer1\nReceived: 25 February 2015 / Accepted: 27 May 2015\n\u00a9 The Brazilian Society of Mechanical Sciences and Engineering 2015\nAbstract Reservoir monitoring considering all measurements and simulator outcomes available nowadays can become a complex task. The data integration and mainly the proper use of the big datasets is a challenge, especially in full field studies. This scenario of increasing data availability is an ongoing process due to new measurement technologies, high computational power and the reservoir characterization complexity. We propose to identify reservoir measurements that best represent the overall reservoir behavior using the Principal Component Analysis mathematical procedure. In addition, this procedure allows a reduction of the dataset dimension for a faster and more efficient reservoir analysis. Latin Hypercube sampling is used to sample the reservoir attribute range and the principal component of the measurements are integrated to identify the attribute interval that minimizes the simulation mismatch. The methodology is applied to a reservoir simulation model with 20 uncertainty attributes. Three study tests were performed using different percentiles in the likelihood distribution, which can conservatively or severely reduce the attribute ranges. The method achieved a coverage of approximately 95 % of the problem variability using five out of fifteen original principal components. Reservoir uncertainties were reduced and most of the simulated measurements had a significant history matching improvement.\nTechnical Editor: Marcelo A. Trindade.\n** Andr\u00e9 Carlos Bertolini\nandre@dep.fem.unicamp.br\nDenis Jos\u00e9 Schiozer\ndenis@dep.fem.unicamp.br\n1\tUNICAMP, Campinas, Brazil\nKeywords Uncertainty reduction \u2022 History matching \u2022 Reservoir simulation \u2022 Principal components \u2022 Mismatch\nList of symbols\nm\tNumber of observations (models)\nn\tNumber of variables\nX\tOriginal data\nb\tPrincipal component\nY\tNew data (called\tScore)\nM\tRaw data matrix\nMADJ\tAdjusted matrix\nC\tCovariance matrix\nN\tNew matrix\nE\tMatrix containing the eigenvectors\nET\tTranspose of the E matrix containing the\neigenvectors\nw\tReservoir uncertainty attributes\nKrW\tWater relative permeability\nSW\tWater saturation\nSWir\tIrreducible water saturation\nSOR\tResidual oil saturation\nExpoW\tCoefficient of Corey's equation for water rela-\ntive permeability\nkrw*\tMaximum value of the water relative perme-\nability in Corey's equation\nKx\tEffective permeability in X direction\nKZ\tEffective permeability in Z direction\nV\tMatch quality indicator\nh\tHistory data\ny\tSimulated data\nd\tNumber of data points\nAbbreviations\nPCA\tPrincipal component analysis\nPC\tPrincipal component\nKPCA\tKernel principal component analysis\nDCT\tDiscrete cosine transform\nLSP\tLeast square projection\nLL\tLower limit\nProjClus\tProjection by Clustering\nSM\tSimulated measurement\nSqE\tSquare error\nSqER\tSquare error ratio\nUP\tUpper limit\nLHC\tLatin hypercube\n1\tIntroduction and objectives\nMore than ever, engineers are looking for different reservoir measurements to understand the complexity of reservoir behavior. Previously, bottom-hole pressure, oil, and water production rates were the most commonly analyzed outputs. Today, other simulator outcomes and reservoir measurements are used to properly characterize the reservoir, for instance, compositional and fine grid model simulations and in situ measures such as fluid density and viscosity. This issue becomes critical with a high number of wells and measurements available to evaluate reservoir performance. In addition, the availability of computational power and the reservoir characterization complexity allows the inclusion of a larger number of reservoir uncertain attributes on the reservoir studies.\nIn order to reduce a dataset dimension, a common practice is the selection of the critical measurements at a point in time, leaving other measurements out of the interpretation. This approach can lead to the consideration of unnecessary data or, worse, it can neglect important datasets that may be indispensable for future reservoir analysis. Based on this scenario, Principal component analysis (PCA) is an alternative to overcome dataset selection difficulties. It is a mathematical procedure, which, in summary, identifies the correlation among the datasets and combines them in a different coordinate system.\nPCA is a multivariate method that was proposed by Pearson in 1901 and was developed by Hotelling in 1933 [6]. The objective of PCA is to reduce the dimension of the datasets based on the correlation among them. The new variables, called principal components (PCs), are sorted from the highest variance to the lowest and are uncorrelated.\n2\tLiterature review\nSarma et al. [10] presented a new approach of automatic history matching (HM) using Kernel PCA. They used a new parameterization, called Kernel Principal Component Analysis, KPCA. It enables the preservation of arbitrarily high order statistics of random fields, which allows the\nrepresentation of complex geology. The gradient-based HM technique was combined with KPCA and the results demonstrated an accurate matching and, more important by the retention of the geological features.\nDadashpour et al. [4] used PCA to speed up porosity and permeability estimations. The gradient-based approach was used to minimize the misfit from production and offset timelapse seismic data, using the most sensitive PCs. The discrete cosine transform (DCT) on those PCs proved to be a fairly efficient technology to hasten the parameter estimation.\nDifferently from the previously described studies, [9] presented a history matching review, considering manual and automatic HM, gradient and non-gradient methods, and the reparameterization techniques, including PCA. In discussions, the authors suggested that no single method is the best. Rather, the best technique depends on the parameters of the problem and the data that need to be matched, and also computing power and time availability.\nAnother work involving PCA in HM, done by [5], showed a comparison among recent multidimensional schemes. The Least Square Projection (LSP), Projection by Clustering (ProjClus) and PCA were used to examine the relationship between exploration of search space and the uncertainty in predictions of reservoir production. It was concluded that a multidimensional approach should accompany assisted HM workflows in order to evaluate their performance, and that exploration of the search space is critical for uncertainty quantification. Furthermore, the authors concluded that the choice of convergence speed versus sampling coverage is affected by the targets of the project and the available computer resources.\nHistory matching, uncertainty reduction and PCA have been studied for many years and recently the multidimensional approach from PCA combined with reservoir studies has become a promising integrated process for HM. This paper presents a modified workflow based on the procedure given by [7] and [2], with the addition of a data smoothing step to capture the reservoir response trend along the attribute range, and the PCA tool, which reduces the interpretable dataset dimension saving time and computational power. It supports an assisted HM, identifying the reservoir measurements that best represent the overall reservoir behavior and provides uncertainty reduction using the highly sensitive components from PCA.\n3\tMethodology\nTaking m observations of n correlated variables, three criteria are used to describe the PCA; (1) there are exactly n PCs, each one being a linear combination of the observed variables as shown in Eq. 1; (2) the PCs are mutually orthogonal (i.e., perpendicular and uncorrelated); (3)\nFig. 1\nEigenvectors for each SM\u2014Principal Component 1 (a) and Eigenvalues\u2014Cumulative Variability (b)\nthe components are extracted in the order of decreasing variance.\nY = Bixi + B2X2 + \u2022 \u2022 \u2022 + bnXn\t(1)\nwhere Xt is the original data, bt is the principal component and Y is the new data, called Score.\nThe conventional PCA method is composed of three steps. The starting point is the conditioning of the data, which identifies the m observations and n variables, forming the raw data matrix M. The average of each variable is then calculated and subtracted from M. The final output from this step is the adjusted matrix MADJ.\nThe next step is the calculation of the covariance matrix, C, from the adjusted matrix MADJ. In the following step, eigenvectors and eigenvalues of matrix C are calculated. Finally, the last step is the data transformation set to the new basis. The new matrix N is obtained from Eq. 2.\nN -^eigenvectors '\t(2)\nwhere \u00a3jgenvectors are the transpose of the E matrix containing the eigenvectors.\nThe purposes of this study are: (1) identification of the reservoir measurements that best represent the overall reservoir behavior; (2) reduction of the dataset dimension for a fast and efficient reservoir analysis and (3) provision of a reservoir uncertain reduction method using the high variability components from PCA.\nThe PCA workflow for reservoir uncertainty reduction starts defining the base simulation model, the reservoir uncertainties and the attribute range for each uncertainty. The base model and the original attribute range are the reference for future comparison. Next, the w reservoir attribute ranges are explored through a probabilistic approach to create representative simulation models. The ensemble of models (m) is designed to cover most of the problem variability and, ideally, to represent all reservoir performance scenarios. The amount of desired models (samples) varies according to the number of reservoir attributes.\nThe m models are run on the simulator and the desired simulated measurements (SMb SM2, SM3,...,SMn) are obtained. The n number of SMs can vary from few measurements, for instance, in the case of a single well modeling, to several dozens of measurements in a full field model. The data matrix has m models (observations) and n simulated measurements (SMs). Instead of using the SM, a common practice in reservoir engineering is the use of a misfit, which is the difference between history measurements and SMs. A misfit is preferable as it directly shows the quality of the simulation model. Each SM misfit has a different trend along reservoir attribute variation. This trend might not be clear due to high dispersion of the misfit values. At this point, we apply individually a smoothing technique to each SM misfit. It creates w smoothed data matrices, one for each reservoir attribute. This technique removes the outlier results while preserving underlying patterns.\nSome SMs can be correlated. Instead of analyzing the full smoothed matrix, which can become impracticable when n assumes large numbers, the PCA is applied to reduce the dimension of the data matrix m x n. The b coefficient shown in Eq. 1 are the matrix eigenvectors. Coefficients close to zero indicate that the SM, which is multiplied by the coefficient, is not affecting the variability of the principal component (PC) to any extent and coefficient close to plus or minus one present a key SM that must be considered. Figure 1a shows the PC1 matrix eigenvectors illustration for SMn. On the other hand, the matrix eigenvalues, shown in Fig. 1b, are associated with the variability of each principal component and are in order of decreasing variance. Normally, the last PCs are left out of the new data matrix (called Score), due to low variability, reducing the dimension of the matrix. Furthermore, the relationships between PCs and reservoir attribute ranges are preserved.\nAfter the PCA application, w new matrices (Score matrices) are created with m lines and n columns (principal components). Removing the lower variability PCs, the Score matrix dimensions are reduced. Figure 2 illustrates the\nAttribute interval\tAttribute interval\tAttribute interval\nFig- 2 From the original data matrix to the high variability components and attribute range selection\ninput data, which is used to fit a probability distribution (black curve in Fig. 3).\n! 0\t\u25a1 PCI (66.7%) o PC2 (28.9%)\n\u2014 Poll\t---Pol2\n0.5\t2.5\t4.5\nAttribute interval\nFig. 3 Schematic example of two PC misfits (PC1 and PC2). The corresponding polynomial 1 and 2 (Poll and Pol2), the weighted average polynomial and the distribution (modified from [2])\n4 Case study\nprocess with the misfit data matrix (Fig. 2a) with four SMs, the 4 PCs and their cumulative variability are presented in Fig. 2b and the reduced Score matrix (PC1 and PC2) are presented in Fig. 2c. The cumulative variability from PC1 and PC2 are close to 95 % and PC3 and PC4 Score can be discarded.\nTaking Fig. 2 as an example and considering the variability of 66.7 % for PC1 and 28.9 % for PC2, the optimum attribute range is showed in the gray area on Fig. 2c, from the lower limit (LL) to the upper limit (UL).\nThe last step is the attribute interval selection. We use polynomial fitting to correlate the PCs with the attribute range. Each polynomial is a function of a reservoir attribute and the Score PC misfit. The polynomials are used to create a global misfit response per attribute. Figure 3 shows a schematic example with PC1 and PC2 misfits, with cumulative variability of 70 and 30 % respectively, polynomial, weighted average polynomial (global misfit) and the distribution. The weighted average polynomial becomes the\nThe methodology was applied to a synthetic case, where the simulation model is an upscaled model from a refined reference reservoir (described by [1]), which was used to extract the history data. It has 30,600 cells distributed in 90 x 34 x 10 blocks and a single porosity type. Horizontal permeability varies from 10 to 1900 mD, with a median of 373 mD and standard deviation of 284 mD. The vertical permeability has the same heterogeneous distribution, with a median of 6.8 mD and standard deviation of 105 mD. The porosity distribution has a median of 0.19 and a standard deviation of 0.05. Although it is a synthetic upscaled reservoir, the true reservoir attribute values to match the history data are unknown. The upscaled base case model contains a similar heterogeneity to the refined model. The reservoir has five producer and five injector wells, each producer/ injector pair is located in one of the five reservoir regions, which has different geological characteristics. The model presents four uncertain attributes per region: horizontal permeability in the X direction (Kx), vertical permeability in the Z direction (Kz), Corey\u2019s coefficient (Eq. 3) for water relative permeability (ExpoW), and the maximum value of the water relative permeability in Corey\u2019s equation (^rw*).\nKrw\n\u2014 Krw\n* .\n(Sw\tSwir)\n(1 - Swir - Sor)\nExpoW\n(3)\nwhere Krw is the water relative permeability, Sw is the water saturation, Swir is the irreducible water saturation and, finally, Sor is the residual oil saturation. Therefore, the simulation model has a total of 20 uncertain attributes.\nTable 1 Base model reservoir attributes and their limits\nLimits\tReservoir attributes\t\t\t\t\t\t\t\t\t\n\tMultipliers\t\t\t\t\t\t\t\t\t\n\tKx1\tKx2\tKx3\tKx4\tKx5\tKZ1\tKz2\tKz3\tKz4\tKz5\nLower\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\nBase\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\nUpper\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\nLimits\tReservoir attributes\t\t\t\t\t\t\t\t\t\n\tCorey\u2019s equation\t\t\t\t\t\t\t\t\t\n\tExpoW1\tK * Krw1\tExpoW2\tK * Krw2\tExpoW3\tK * Krw3\tExpoW4\tK * Krw4\tExpoW5\tKrw5*\nLower\t1.00\t0.15\t1.00\t0.15\t1.00\t0.15\t1.00\t0.15\t1.00\t0.15\nBase\t2.20\t0.60\t1.10\t0.80\t4.00\t0.50\t1.30\t0.70\t4.30\t0.80\nUpper\t5.00\t0.90\t5.00\t0.90\t5.00\t0.90\t5.00\t0.90\t5.00\t0.90\nThe permeabilities Kx and Kz are modified in the simulation models through multipliers. The limits are 0.5 and 2.0, which represent the half and the double of the absolute permeability Kx and Kz of the base model. The base model is the unitary reference of the absolute permeability multipliers, while the attributes ExpoW present a variation range from 1 to 5 and the attributes of krw from 0.15 to 0.90. Table 1 presents the reservoir attribute summary.\nThe corner point grid has 2550 cells distributed in 30 x 17 x 5. The reservoir has five producer wells and five injector wells; a producer/injector pair for each region is located in the same reservoir position. The reservoir cells of the injector wells are: Injector1 (4;1-6;5), Injector2 (14;1-9;5), Injector3 (20-29;6;5), Injector4 (3;8-17;5), and Injector5 (10-28;14;5). For the producer wells the cells are: Prod1 (4;1-6;1), Prod2 (14;1-9;1), Prod3 (20-29;6;1), Prod4 (3;8-17;1), and Prod5 (10-28;14;1).\nThe simulated measurements (SMs) considered in this case study were: oil production (m3/day), water production (m3/day), and bottom-hole pressure (KPa), for five production wells. In total, 15 SMs were considered. The well production strategy used in the simulation had a surface liquid limit of 4770 m3/day and a bottom-hole pressure (BHP) limit of 20.7E+3 kPa. The oil rate on each simulated data was input into the simulator. The constraints for the injector wells were the maximum surface water rate of 4770 (m3/day) and the maximum bottom hole pressure of 82.7E+3 kPa.\nWith the objective of creating a match quality indicator (V), the outputs from the normalized misfit function of each well and SMs were gathered through the Euclidean norm. The normalization uses the maximum misfit range among all SM. A square error function shown in Eq. 4 was selected according to [Bertolini and Schiozer [1]] to characterize the misfit.\n= \u2014\n(5)\nd\nSqE\u201e =\t(hi - si )2\t(4)\n1=1\nwhere the index s represents simulated data, h, historical data, d, total number of data, and n, number of SM. However, the match quality indicator (V) is obtained dividing the Euclidean norm by the Euclidean norm of the base model.\nn -> SqEt) 2\n1=1\n(t (SqEbi)2}\nThe interpretation of V is direct. Values greater than 1 represent a worsening in the HM; values equal to 1 represent that model has the same performance of the base model; and values smaller than 1 represent improvements in the HM.\nIn addition to the V global indicator, the square error ratio (SqER) was used for each SM and well. The ratio is between the simulated square error (SqE) and the maximum acceptable square error (SqEM) for each SM. The acceptance range may vary for each application. The environment in which the measurements are taken, sensor technology and resolution, the sampling acquisition interval and desired HM quality are some factors that might help in getting a representative range.\nIn order to provide the SqER signal, the error function divided by the absolute error function was used as a multiplier. A positive signal means that simulated results have lower values compared with the observed data, and a negative signal means the opposite. The SqER is calculated in Eq. 6.\nSqER\u201e =\nd\n(hi - Si)\n1=1\n~d\n(hi - si)\ni=1\nSqEn =\tSqEN\nSqEMn\tlE\u00abl SqEMrc\n(6)\nwhere the index s represents simulated data, h, historical data, d, total number of data, and n, number of SM. SqER interpretation is also direct: values between \u2014 1 and 1 indicate that the well is within the acceptance range of the HM.\nThe Latin Hypercube (LHC) sampling technique was applied to create the representative models. It is a statistical method for generating a distribution of plausible sets of attribute values. [8] compared different sampling techniques in which the Derivative Tree, Monte Carlo and Latin Hypercube methods were used in a synthetic reservoir with 4 uncertain attributes. Although all three methods present a satisfactory result, the Latin Hypercube has the best results considering precision and number of simulations. The amount of desired models (samples) will vary according to the number of reservoir attributes.\nThe moving average was used for the smoothing technique. It was described by [3] and is applied to remove noise from datasets while preserving underlying patterns. So, taking an average of the points near an observation will provide a reasonable estimate of the trend at that observation.\nPrevious simulation runs showed that 50 models were able to capture most of the reservoir responses. The following results are based on 50 models from the probabilistic approach LHC, and the moving average smoothing process with 15 % of the number of models. The acceptance range was \u00b1250 bbl/day for oil production, \u00b1500 bbl/day for water production, and \u00b14000 kPa for BHP. After the PCA calculation, three study tests were performed using different percentiles in the likelihood distribution.\n5 Results\nConsidering the 15 simulated measurements, which for this case study are misfits between history and simulated data, and 50 experiments, the original data matrix is formed by 50 (m) x 15 (n). For each uncertain attribute, the moving average was applied, providing 20 Score matrixes m x n. The proposed methodology was applied to those matrixes and the PCs with higher variability for each attribute are presented in Fig. 4 as blue bars. In general, only five PCs or less were required to cover more than 95 % of the variability. The solid blue line in Fig. 4 shows the cumulative variability.\nTaking only the cumulative PC1 and PC2 variability, the lowest value is approximately 70 % for the \u00a3xpoW1 attribute and most are above 80 % or even higher than 90 %. For\nFig. 4 Principal Components for all 20 uncertain attributes; cumulated variability from PC1 and PC2 achieved 70 % or higher percentages\nTable 2 PC1 and PC2 variability percentage\t\t\t\t\t\t\t\t\t\t\n\tVariability\t\t\t\t\t\t\t\t\t\n\tKx1 (%)\t(%)\tKx3 (%)\tKx4 (%)\tKx5 (%)\tKz1 (%)\tKz2 (%)\tKz3 (%)\tKz4 (%)\tKz5 (%)\nPC1\t75.6\t82.2\t94.8\t59.8\t55.0\t69.9\t83.6\t90.0\t54.7\t64.3\nPC2\t14.5\t11.6\t3.1\t29.1\t20.4\t19.1\t7.3\t5.3\t23.3\t16.9\nAccumulative\t90.0\t93.8\t98.0\t88.9\t75.4\t89.0\t90.9\t95.3\t78.0\t81.2\n\tVariability\t\t\t\t\t\t\t\t\t\n\tExpoW1 (%)\tKrw1 (%)*\tExpoW2 (%)\tKrw2* (%)\tExpoW3 (%)\tKIW3 (%)*\tExpoW4 (%)\tKrw4* (%)\tExpoW5 (%)\tKw5* (%)\nPC1\t45.2\t62.7\t80.8\t79.0\t65.9\t68.3\t71.4\t78.2\t63.0\t73.7\nPC2\t24.6\t20.7\t9.1\t8.7\t14.9\t10.6\t16.4\t13.7\t21.8\t11.9\nAccumulative\t69.8\t83.4\t90.0\t87.6\t80.8\t78.9\t87.9\t91.9\t84.8\t85.6\nFig. 5 PC1 and PC2 for all 20 uncertainty attributes showing the weights for each SM\nall study tests, PC1 and PC2 were the components used to achieve the results presented in this paper. Table 2 shows the PC1 and PC2 variability percentage for each attribute. The average PC1 and PC2 variability (20 attributes) are 70.9 and 15.2 % respectively.\nApart from the variability of the components, the methodology provides the matrix eigenvectors (weights) of the SMs. The SMs contributing more significantly to PC1 and PC2 are shown in Fig. 5. For each attribute, the eigenvectors are the weights for the SMs on the principal components. For instance, attribute ExpoW4 has Prodi well BHP, Prod2 well oil production and BHP, Prod3 well water production and BHP, Prod4 well oil production and BHP, and, finally, Prod5 well BHP with higher influence on PC1 (blue\nbars). On the other hand, Prod2 well oil production and BHP, Prod3 well BHP, Prod4 well oil production and BHP, and Prod5 well water production and BHP have the high weights on PC2 (red bars).\nAiming for a complete analysis of the principal components, it is also important to associate those weights with the variability of each PC. Considering ExpoW4 once again, the PC1 has approximately 71.4 % of the variability and PC2 only 16.4 %. Table 3 shows the SMs cumulative weights for the 20 attributes.\nUsing the PC1 and PC2 results, the attribute ranges were reduced between LL and UL according to Fig. 2c. Different percentiles were chosen, P50 for a conservatively range reduction, P75 and a more severe reduction with P90.\nTable 3 Cumulative weights for PC1 and PC2 components\nCumulative weights\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\tProd well 1\t\tProd well 1\t\t\tProd well 1\t\t\tProd well 1\t\t\tProd well 1\t\t\n\tOil\tWater BHP\tOil\tWater\tBHP\tOil\tWater\tBHP\tOil\tWater\tBHP\tOil\tWater\tBHP\nPC1\t0.4\t0.0 -2.0\t1.5\t-0.8\t-2.6\t0.0\t-3.1\t-2.8\t-0.1\t0.0\t-2.6\t0.1\t-0.3\t-2.0\nPC2\t0.1\t0.0 -1.2\t-0.3\t-0.3\t-1.4\t0.0\t0.4\t0.6\t-0.7\t0.1\t-1.1\t0.1\t-0.2\t-0.6\n5000\n2000\nProdi\nProd2\nProd3\nProd4\nProd5\nooo History ....Base model\nOriginal 50 models\n\u2014 PCAwith P75\n1000\n4000\n0\u00ae---------\u2014--------*---e\n0\t50\t100\t0\nTime (month)\nProdi\n3000\n50\t100\nTime (month)\nProd2\nTime (month) Prod2\nTime (month) Prod3\n100\nTime (month) X104 Prod4\n0\t50\t100\nTime (month) Prod5\n50\t100\nTime (month)\nProd5\n2\n0\t50\t100\nTime (month)\n50\t100\nTime (month)\n50\t100\nTime (month)\n0\t50\t100\t0\t50\t100\t0\nTime (month)\tTime (month)\nFig. 6 Original 50 models and 50 models after the proposed PCA methodology with P75\nTherefore, three study tests were performed using these percentiles.\nFigure 6 shows the original models from LHC and the red curves are the models generated after the proposed methodology with P75. The black circles are the history data and the dotted blue lines are the base model. The cyan curves are the original models from LHC and the red curves are the models generated after the proposed methodology. The reduction and positioning of the new attribute range presented in Fig. 7, resulted in an overall HM improvement. Note that Kz1, ExpoW1, and Krw1* ranges were not reduced because the misfit along the original range was almost constant.\nFig. 7 Original and PCA P75 reduced attribute ranges\nFig. 8 SqER distribution for oil and water production and BHP. Original dataset is shown in black, P50 in green, P75 in red and P90 in blue for Prod Wells 1-5\nProdi\tProd2\tProd3\tProd4\tProd5\n\u202220-j\t1\n\u25a025\nThe SqER for the four datasets are presented in Fig. 8. On each box, the central mark is the median, the edges of the box are the 25th and 75th percentiles, and the whiskers extend to the most extreme data points not considered outliers. Some comments regarding each SM class are relevant and described below.\nSqER: BHP values were similarly improved; all five producer wells present the square error in the same order of magnitude. It can also be noticed on Table 3 and Fig. 5 for the P75 dataset. The BHP weights are quite similar. The original dataset showed a spread SqER values, varying mainly from -23 to 3. For P50, P75 and P90, the distributions were narrowed. P75 and P90 datasets have included all producer wells within the acceptance range (gray band between \u20141 and 1).\nSqER: Oil Production values increased slightly for Prod2, Prod4 and Prod5 wells when comparing the original data with P90 dataset. As expected, the SqER\u2014Oil Production distribution varied from 0 to a positive number, which means that simulated oil production is always equal to or lower than the history data. For the P90 dataset, mainly for Prod4 and Prod5 wells, the SqER values were moved out of the acceptance range. Therefore, in order to validate the P90 dataset for reservoir forecast,\na model assessment and recharacterization must be performed to improve the HM in those wells.\nSqER: Water Production values gradually decreased with the increase of the percentile. Although all producer wells had improved the water production matching, the level of improvement was different among them. Due to the low water production rate, Prodi and Prod4 wells had a slight SqER change between the datasets. The other three wells, which have a high production rate, had a more consistent reduction. The weights presented in Table 3 for the P75 dataset show the same trend; small weights for Prodi and Prod4 wells and high weights for the other wells. The original dataset showed a spread SqER values, varying mainly from \u20142 to 18. For P50, P75 and P90 datasets, the SqERs values were moved to the acceptance range with the exception of Prod3 well. Although SqER values from the P90 dataset showed the best result for the Prod3 well, it crossed the SqER acceptance limit for Prod4 well. In general, all three datasets reduced the water production SqER values, but similarly to oil production, a model assessment and recharacterization must be performed to improve the HM in those wells.\nThe global match quality indicator V from original models, P50, P75, and P90 datasets are shown in Fig. 9a. As the\nNumber of experiments from HCL\tDatasets\nFig- 9 Global match quality indicator and its distribution for original, P50, P75, and P90 datasets\npercentile increased, all three study tests showed a significant improvement in the global indicator and a narrowed distribution between the 50 models, which are presented in Fig. 9b.\n6 Conclusions\nWe presented a reservoir uncertainty reduction workflow based on the procedure given by [7]. Smoothing technique and PCA were integrated into the workflow to capture the misfit trend along each reservoir interval and reduce the interpretable dataset dimension respectively. The method identified the more influent reservoir measurement and provided an HM improved set of models. From this workflow, the following conclusions were drawn:\n\u2022\tIn this application, the interpretable dataset dimension was reduced by one third of the original size. Five principal components covered approximately 95 % of the problem variability (from 15 original SMs). In reservoir with a larger number of wells and SMs, the use of the reduced dimension dataset represents a faster uncertainty analysis and reservoir forecast.\n\u2022\tThe application of the proposed method might work as an alternative to reduce the time and computation power required to process full field studies.\n\u2022\tReservoir uncertainties were reduced (Fig. 7) and the global history matching improved (Figs. 8, 9). The results from higher percentile study provided the highest global HM improvement and the worst local HM, mainly for oil production function. The compromise with this range is the balance between reservoir uncertainty reduction and the quality of reservoir forecast. In\nthis work, the P90 dataset must be reassessed to honor the acceptance interval.\n\u2022\tDifferently from other methodologies that normally require a large number of simulations to evaluate the reservoir, the proposed method used 50 models, which were sufficient to provide the principal components for this application.\n\u2022\tThe combined interpretation of eigenvector's matrix and eigenvalue's vector provided the interaction between different reservoir behaviors and uncertain attributes, which can be useful for local HM.\n\u2022\tThe results showed that a combined interpretation between global and local HM indicators is the preferable approach. Considering only global indicators may lead to a very poor match in some of the wells.\n\u2022\tEstimation of the acceptance ranges is a key stage for a proper history matching evaluation. Whenever we do not know the measurement errors and/or a reasonable tolerance margin for the reservoir model, a sensitivity analysis with different estimated values is recommended to build a set of quality measurement scenarios.\nFurther studies, particularly in model reparametrization requirements, to mitigate the scenario where the simulated results are totally out of the acceptance range, will be addressed in a future work.\nReferences\n1.\tBertolini A, Schiozer D (2011) Influence of the objective function in the history matching process. J Pet Sci Eng 78(1):32-41\n2.\tBertolini AC, Maschio C, Schiozer DJ (2015) A methodology to evaluate and reduce reservoir uncertainties using multivariate distribution. J Pet Sci Eng 128:1-14 (Abril)\n3.\tBiran A, Breiner M (1995) MATLAB for engineers. Addison-Wesley, Reading\n4.\tDadashpour M, Rwechungura R (2011) Fast Reservoir Parameter Estimation by Using Effect of Principal Components Sensitivities and Discrete Cosine Transform, SPE 141913 was selected for presentation at the 2011 SPE Reservoir Simulation Symposium held in The Woodlands. Texas, USA\n5.\tHajizadeh Y, Amorin EP, Sousa MC (2012) Building Trust in History Matching: The Role of Multidimensional Projection, SPE 152754 was selected for presentation at the EAGE Annual Conference &amp; Exhibition incorporating SPE Europec held in Copenhagen, Denmark\n6.\tJolliffe IT (2002) Principal component analysis, 2nd edn. Springer, New York\n7.\tMaschio C, Schiozer D (2013) A new procedure to reduce uncertainties in reservoir models using statistical inference and observed data. J Pet Sci Eng 110:7-21\n8.\tRisso FVA, Risso VF, Schiozer DJ (2011) Risk analysis of petroleum fields using Latin hypercube, Monte carlo and derivative tree. J Pet Gas Explor Res 1(1):014-021\n9.\tRwechungura R, Dadashpour M, Kleppe J (2011) Advanced history matching technique reviewed, SPE 142497 was selected for presentation at the SPE Middle East Oil and Gas Show and Conference held in Manama, Bahrain\n10.\tSarma P, Durlofsky LJ, Aziz K, Chen WH (2007) A new approach to automatic history matching using kernel PCA, SPE 106176 was selected for presentation at the 2007 SPE Reservoir Simulation Symposium held in Houston. Texas, USA\n52\n5.\tARTICLE 4: Use of a Probabilistic Approach to Perform History\nMatching Tracking over Simulation Time\nAndr\u00e9 Carlos Bertolini and Denis Jos\u00e9 Schiozer\nSubmitted to Journal of Petroleum Science and Engineering, January 2015\n54\nUse of a Probabilistic Approach to Perform History Matching Tracking over Simulation Time\nAuthors:\tAndre Carlos Bertolini (andre@dep.fem.unicamp.br)\nDenis Jose Schiozer (denis@dep.fem.unicamp.br)\nAbstract\nNumerical reservoir simulation is widely used in the industry for reservoir management, allowing full data integration. A challenging and consuming task related to reservoir simulation is the history matching process. No closed-form solutions exist for this complex inverse problem, and any solutions that are determined may not be unique. The history data that are used as the observed response of the reservoir to some stimulus are subject to noise and error, which also contribute to the lack of any exact, unique solution.\nThe history matching process is recently treated using probabilistic approaches, where dynamic data reduces uncertainty of reservoir attributes to quantify risk, allowing more robust decision analysis based on uncertain production forecast. In this probabilistic context, we propose a sequence of steps to evaluate the model performance regularly over time. This new method is composed by nine steps and works with an acceptance range applied to the history dataset. It included an uncertainty reduction tool and is associated with match quality indicators, which allows a practical and efficient way to give support for reservoir decisions. The acceptance range formulation considers a relative and fixed measurement error. These errors are based on (1) the quality of the measurement, which may vary according to sensor specifications, flow conditions in the well, and measurement conditions, and (2) the desired quality of the solution for each objective-function specified in the problem that represents the deviation from history data.\nWe used a synthetic reservoir to validate the method and the UNISIM-I-H reservoir model, which is based on the Namorado field, Campos basin, Brazil. The reservoir models were evaluated annually against the acceptance range. The method managed to maintain a set of calibrated models for the simulation period and the reservoir uncertainties were reduced. A multivariate analysis method was applied to both reservoir models to reduce the reservoir uncertainty. The results show the importance of a continuous evaluation tool, which guarantees calibrated models for reservoir management decisions, and the need for continuous reservoir model updating over the simulation time.\n1.\tIntroduction\nPetroleum reservoir management has been discussed and defined by many authors in the literature. Reservoir management practice relies on use of financial, technological, and human resources, while minimizing capital\ninvestment and operating expense to maximize economic recovery of oil and gas from a reservoir (Thakur, 1996). It is based on a series of decisions that enables oil and gas companies to meet their technical and business objectives. Management, economics, legal and environmental disciplines are some of the topics included in reservoir management. The process requires models of the reservoir system and the ability to predict the consequences of implementing possible and alternative strategies. The reliability of reservoir predictions is closely related to the amount of reservoir information and the understanding its behavior. Reservoir characterization, a vital part of the model creation process, involves generating an editable and mathematical subsurface model. However, the details and type of mathematical reservoir modeling depends on data gathering and management. Reservoir characterization is a continuous process that must be updated as new information is gathered. It starts with the acquisition and interpretation of data from different disciplines. Secondly, data integration is used to build the initial model and finally, the most challenging and time consuming task of the reservoir characterization, which is the history matching (HM) process. This step is an inverse problem, which adjusts reservoir attributes by history matching production data. The solutions are not unique, nor exact solutions exist for these cases (Oliver et al., 2008). The history data used as the observed reservoir response to stimuli are subject to noise and error, which may also prohibit a close-form, exact solution.\nHM keeps evolving as new reservoir measurements become available and computer power availability increases. Manual and assisted HM tools have been published over the years, using different mathematical tools and focusing on different reservoir applications. In this paper, we propose a new HM workflow with three objectives:\n1)\tTo include measurement error and a tolerance margin for all history data before the history matching evaluation;\n2)\tTo synchronize the history data sampling frequency with the history matching workflow, capturing the reservoir trends along the production period in the model.\n3)\tTo provide a quality indicator and an efficient graphical way to evaluate the reservoir model performance over time.\nNew observed dynamic data provide additional reservoir information and help reducing reservoir uncertainties. All new data must be assimilated and incorporated while history matching. Furthermore, reservoir management is performed by evaluating several data and quality indicators, so the HM method must allow reservoir management decisions in a practical and efficient way.\n2.\tLiterature review\nSeveral approaches have been used to estimate and reduce uncertainties successfully. The procedure by Maschio and Schiozer (2013) show a methodology to reduce uncertainties of reservoir attributes using statistical inference based on observed data. This method offers two main advantages. The first is robustness, since it can be applied to complex cases with a high number of uncertain attributes. The second advantage is modifiability, which allows selecting the number of iterations and the number of simulations for each iteration, to meet a desired quality of results.\nSlotte and Smprgrav (2008) present the combination of experimental designs and history matching tools to generate a probabilistic production forecast. Schaaf et al. (2008) used similar combination with a Bayesian framework, a posterior distribution of the most sensitive parameters were derived from the a priori distribution and a non-linear proxy model of the likelihood function. Several history matched models together with a posterior parameter distribution were used to obtain probabilistic production profiles.\nLiu et al. (2010) use real time reservoir modeling to study the Markov-Chain Monte-Carlo (MCMC) method. The continuous simulation process provides a mechanism for calibrating uncertainty estimates over time. From assimilating data, history matching, and continuously forecasting over time, the authors showed that the resulting forecast uncertainty ranges are narrowed with time when compared with traditional methods.\nEmerick and Reynolds (2012) combined the Ensemble Kalman filter (EnKF) and Markoc Chain Monte Carlo (MCMC) methodologies to obtain a relatively efficient algorithm for sampling the posterior probability density function (PDF) for reservoir-model parameter. They tested the method on a small 3D two-phase-flow reservoir, allowing a long Markov chain creation for comparison. EnkF-MCMC narrows the spread of reservoir predictions, resulting in histograms significantly closer to those obtained with the long MCMC case. In summary, the application of EnkF-MCMC improves the data matches from EnKF by generating samples of higher-probability regions of the posterior PDF.\nMaschio et al. (2005, 2009) proposed a method to integrate history matching and uncertainty analysis using discrete levels of uncertainty (discrete probability density functions - pdf) combined through the derivative tree technique. The method was successfully applied in cases with a small number of attributes.\nKalman filters applied by Gu et al. (2005), also achieve satisfactory results, such as improvement in assisted history matching (HM) and an estimate of uncertainty in future reservoir performance, both with a significant reduction in computational costs.\nRwechungura et al. (2011) reviews HM methods and its advancement to date. The paper covers manual and automatic HM, minimization algorithms including gradient methods such as conjugate, steepest descent, Gauss-Newton and QuasiNewton and non-gradient methods, such as evolutionary strategies, genetic algorithm and Kalman filter. All methods were evaluated using a data set based on data from the Norne Field in the Norwegian Sea provided by Statoil and its partners. The authors suggest a computer cluster availability assessment to support the HM method selection. The performance of derivative-free methods, in terms of absolute computing times, could be similar to that of adjoint-based optimizers. Furthermore, they concluded that no single method is the best; rather the best method for HM depends on the parameters of the problem and the data that need to be matched.\n3.\tThe Theory\nHistory matching concepts have been applied for many years as part of the dynamic reservoir characterization. The HM process is an inverse problem, it identifies unknown reservoir parameter values, providing a best fit between observed and simulated data. Figure 1 shows the conventional HM sequence.\nFigure 1 - Conventional history matching workflow\nThe conventional workflow starts with the first reservoir simulation model (A), which comes from a multidisciplinary team normally composed by geologists, geophysics and engineers. Using the results from the initial model, the next step is a comparison between observed and simulated results (B). If the initial model is able to reproduce the observed dynamic data within the geological constrains (C), the model is calibrated (D) and can be used for reservoir prediction (E). On the other hand, if the initial model does not match the observed data, which is normal, the simulation model is modified (F). The modifications should respect and vary inside the geological, geophysical and engineering ranges defined previously during the reservoir evaluation by the multidisciplinary team. After, the modified model is run (G) and the results are compared again with the observed data (B).\n4.\tThe Problem\nNumerical reservoir models carries challenging features that remain over the reservoir life. For instance, the addition of new reservoir information into the model and local mismatch between observed and simulated data. Another challenge is the process to maintain calibrated models over the production period. It requires a continuous effort from the field asset team, which is not always achieved along the production period of the reservoir. Furthermore, HM is commonly performed in the initial field development phase. After the initial HM, the calibrated models are used over the coming years to offer reservoir forecasts. Even with new observed data available, the first calibrated models are normally used to make production forecasts without considering recent observed data. The three main difficulties while updating a reservoir model over time are: required try and error time to achieve satisfactory HM results, cost of man-hour and human expertise.\nAn inefficient HM evaluation criteria can also contribute to poor reservoir forecasts over time. Often, a rigorous method does not exist to regularly validate the HM. For instance, when the calibrated model cannot capture the water breakthrough or the bottom-hole pressure (BHP) trend, a reservoir evaluation tool must identify such model deficiencies early on. If the model deficiencies is not identified by the model evaluation, the initial calibrated models will continue providing production forecasts over the years without any update, probably leading to erroneous forecasts. Faced with this risk, the desired approach is a rigorous model evaluation, combined with model assessment and updating as needed.\nApart from the HM challenges, the quality of the observed data and the reservoir characterization must be considered in every reservoir simulation study. Tolerance margins and measurement errors from the observed data leads to the concept of an acceptance range (AR). The range varies according to (1) the quality of the measurements, which is related to sensor specifications, flow conditions in the well and measurement conditions, and (2) the field characterization quality and the desired HM quality. Bertolini et al. (2013) studied a reservoir parameter inversion method, for interference well testing interpretation, which considered the pressure measurement errors. They proposed a similar formulation of the objective function using a constant and relative errors to change the weights of the individual pressure measurements.\nThe method described in this paper allows rapid HM tracking over the simulation time. In the next section, the method is presented in detail, broken down into several phases. In summary, an acceptance range (AR) for the observed data is defined, this AR is then used to identify the mismatch between the simulation model and the observed measurements.\n5.\tThe Proposed Method\nReservoir simulation models provide a set of simulated data for each well and for each function. The square-error function (equation 1) was chosen based on the results presented by Bertolini and Schiozer (2011) to represent the mismatch between history and simulated data. The authors showed the influence of different error functions on reservoir simulation optimization performance and the advantages of a square-error function.\nd\nSE = \u00a3(h, -i, )2\t(1)\ni=1\nwhere 1 represents the simulated data, h the history data (measured data of the past), d, total number of data, and m, number of simulated measurement (SM). SqE is calculated for SM and every well.\nThe AR functions (Far) were calculated using a tolerance margin (Tm) and a history data percentage, obtained through relative measurement error (Mre), as shown in equation 2.\nFAR, = DOBS, \u00b1 DOBS, \u25a0 M RE \u00b1 TM\t(2)\nwhere Dobs represents the observed data, and d, total number of data.\nTm and Mre estimation for a real reservoir model requires an investigation regarding measurement conditions, such as downhole or surface measurements, individual or combined production rates, sensor resolution and the quantity and quality of information available to build the reservoir model. Oil rate measurements are more precise (expected lower Tm and Mre values) due to the petroleum regulatory agency requirements. A tighter error associated to oil rate measurements is needed since taxes are based on them. Brazilian National Petroleum Agency - ANP uses oil rates to calculate, for instance, royalties, special participation, landowners fees and research &amp; development (R&amp;D) investments. In the literature, measurement errors are also commonly assumed to be Gaussian with zero mean, and have a standard deviation value (g) for each function (Emerick and Reynolds, 2011 and Tavassoli et al., 2004). Emerick and Reynolds estimate measurement error g by smoothing the observed data using a moving average and subtracting the observations from the smoothed data. Then, they compute the relative error by diving each data difference by the value corresponding to the smoothed data.\nThe simulated square error SqE over the maximal acceptable square error SqEAR for each simulated value gives the square error ratio (SqER). In order to provide the SqER signal, the simple error function divided by the absolute error\nfunction was used as a multiplier. A positive outcome to the equation means that simulated results have lower values\ncompared with the observed data, and a negative outcome means the opposite.\nSqERm=\nt (hi - st)\ni=1____________\nt h - st)\ni=l\nSVEm\nSqEmAR\n(3)\nThe AR may vary for each application. The environment, in which the measurements are taken, the sensor technology and its resolution, and finally field characterization quality, are some factors that might help to determine a representative range.\nSqER interpretation is direct: values between -1 and 1 indicate that the well is within the AR of the history matching.\nThe method works with a set of x models, which present the possible scenarios based on the reservoir uncertainties. These are created using a statistical sampling technique, which may use methods such as Latin Hypercube or Monte Carlo. The SqER values are used to create the HM tracker graphic (Figure 2A). Each function F is assigned to a targeted reservoir or well response, such as water rate, oil rate and bottom-hole pressure. The hatch rectangle limited by the SqER values +1 and -1 defines the acceptance range for the observed data. Figure 2A shows six different SqER distribution positions that may occur while studying a reservoir. Each cross represents the result of a reservoir model. The following features are valid for each distribution position.\nAl. The SqER values are within the AR. This agreement means that the current models are matching the history data range for F1 (Figure 2A). The models are ready to make predictions.\nAll. The SqER values are above, below and inside the AR. To allow proper predictions, an uncertainty reduction method should be applied to move most of the models within the AR.\nAIII. All SqER values are higher than +1. In practice, the simulated measurements are below the observed data. Either other reservoir attributes that were held constant are contributing to a mismatch or different limit ranges are needed. A model reassessment is required because the x models no longer honor the history data.\nAIV. All SqER values are lower than -1. In practice, the simulated measurements are above the observed data. Either other reservoir attributes that were held constant are contributing to a mismatch or different limit ranges are needed. However, a model reassessment is required because the x models no longer honor the history data.\nAV. The SqER values are below and inside the AR. Some models were able to honor while others are above the history data range. It is probably an indicator that the reservoir attributes have a wider or different uncertainty range. An appropriate uncertainty reduction method may help to move the models result inside the AR. Otherwise, a model reassessment is required to guarantee that most of the models are within the AR.\nAVI. The SqER values are above and below the AR. The simulated measurements are below and above the observed data. None of the models were able to honor the history data range. Future prediction cannot be performed using these models; instead, the model must be reassessed.\nFigure 2 - History matching tracker graphic\nApart from the different SqER positions in Figure 2A, the HM tracker graph can accommodate several functions from different wells. Finally, each function is associated with a time period. The matching function evolution can also be tracked over the simulation time. Figure 2B shows different scenarios that may evolve during the HM process. For instance, five years of simulation time, from T1 to T5 and the HM evaluation time every year are presented in Figure 2B for function Fl. Three main behaviors may occur, considering that all the models in the first time step are inside the AR and that five years of observed data are known.\nBI. The SqER values may vary within the AR over the five years. This is ideal and there is no need to update the model. The models honor the new Dobs every year;\nBII. If the SqER values move towards the upper boundary over time, the simulated results are below the observed data. If the models move out of AR over simulation time, for instance, at T4, additional uncertainty analysis is needed. The need to update the model occurs when most of the models are outside the AR;\nBill. If the SqER values are crossing the lower boundary, the simulated results are above the observed data. The same approach as case II must then be taken.\nThe HM tracker graph facilitates the decision to continue with or to update the current simulation model, which is ultimately used for reservoir management.\nThe probabilistic history matching workflow starts with the initial simulation model and the uncertainties of the reservoir. The uncertainties and their range are commonly related to the data and reservoir characterization quality and availability. So, even with advanced reservoir characterization techniques available, the development and management of reservoirs still carry uncertainty. The second stage in Figure 3 is the simulation run of representative scenarios. At this point, a sampling technique helps select a set of models to cover most of the possible reservoir responses. The number of models (samples) to cover the search space varies with the number of reservoir attributes. Risso et al. (2011) compared different sampling techniques in which the Derivative Tree, Monte Carlo and Latin Hypercube methods were used in a synthetic reservoir with 4 uncertain attributes. Although all three methods present a satisfactory result, the Latin Hypercube provides the best results considering precision and number of simulations.\nFigure 3 - Probabilistic history matching workflow\nAfter the reservoir characterization and running the representative models, the Dobs are incorporated into the models in Stage 3. Here the simulated results are compared to real data. Stage 4 is the first evaluation process, checking if the representative models can reproduce simulated results within the AR. The HM SqER indicators and the HM tracker graph are used at this stage; the SqER values are the quality indicators for each well and each function considered in the HM process. If the SqER value is outside the AR (Figure 2A - III, IV and VI), the next stage is model reparametrization (Stage 9). At this point, we know if the current models and their uncertainty attribute range could not be reconciled with simulated and observed data within the proposed AR. Ideally, the multidisciplinary team responsible for the model construction will reanalyze the model. Some options to mitigate the problem are the inclusion of new reservoir uncertainties, the variation range of the attributes, or even a complete geological recharacterization. The next step after\nthe model reparametrization is returning to Stage 2. The workflow stays in the loop until the simulated results agree with the observations within the AR.\nIf the HM tracker graph shows the SqER values within (Figure 2A - I) or crossing the AR (Figure 2A - II and IV), the process continues moving to the next stage: the uncertainty reduction in Stage 5. In Stage 5, we know if some or all representative models honor the observed data within the proposed AR. Some functions may have a wider distribution (Figure 2A - II), indicating that some models are within, while some models are outside of the AR. Other functions show a narrow response (Figure 2A - I), meaning that all representative models are already within the AR. Any method may be applied at this stage to reduce the uncertainty range of the reservoir attributes.\nThe second evaluation process is Stage 6. Before any reservoir prediction, this evaluation stage guarantees that all simulation results are inside the AR. After Stage 5, some functions narrow down the result distribution, reducing SqER distribution into the AR. For example, the distribution from Figure 2A - II may become similar to distribution from Figure 2A - I after Stage 5. The opposite can also occur: even after the uncertainty analysis stage, the models may still provide results out of the AR. In this case, the next step is the model reparametrization (Stage 9). Even the functions that had the values within the AR at Stage 4 must be checked again. The uncertainty reduction method may worsen the results of specific functions while improving others.\nStage 7 is the prediction under uncertainty. A simple filter is applied to the original set of models discarding the outlier models, which are outside the AR and easily recognized in the HM tracker graph. The representative models are then used to predict the selected functions and well performances. These predictions guide the reservoir management decision.\nThe final stage is a check for new observation data Dobs. Stage 8 should be synchronized with the Dobs acquisition frequency. If no new Dobs is available, the workflow ends, and the representative models used to make the prediction in stage 7 are the calibrated models. If new Dobs are available, the process moves to Stage 3 again. The process loop from Stage 3 to Stage 8 is expected to continue during the entire production life of a reservoir. Each selected reservoir function is monitored using the HM tracker graph shown in Figure 2B. For each new set of Dobs a new SqER distribution is created in this graph. In summary, the proposed workflow is evaluating and controlling the SqER distribution inside the AR.\nThe common HM approaches deal with history data as discrete observed values. Measurement errors and the addition of tolerance margins are rarely included in history data in the literature. The proposed method facilitates the conventional HM analysis described in Figure 1. It allows a consistent HM evaluation over the reservoir production period combining the history data with an acceptance range. This method may initially require an additional set-up effort if compared with the convention HM. On the other hand, the workflow from Figure 3 establishes a rigorous quality tracking process and a multivariate uncertainty reduction method proposed by Bertolini et al. (2015). The method was positively applied to the same reservoir models presented in the work (case study 1 and 2), at a static production period. Furthermore, although the method still requires a manual HM approach in some stages of the workflow, it tends to save computational power and human resources along the production time period.\n6. Case Study 1: Synthetic Reservoir Model\nThe selected reservoir model is divided into five regions (Figure 4A) with different geometries, areas, volumes and properties (Figure 4A and 4B). It is an upscaled model from a refined reservoir. The porosity was upscaled through the arithmetic average using the permeability methodology described by Maschio and Schiozer (2003). The history data serving as true reference were obtained from the refined model.\nAlthough case study 1 is a synthetic upscaled reservoir, with known response for validation of the methodology, the true reservoir attribute values that shall match the history data are unknown. The porosity distribution for the bottom reservoir layer is presented in Figure 4C. Figure 4D shows the top layer. The upscaled base-case model maintained the heterogeneities from the refined model.\nRegion3\nRegion2\nRegion5\nRegion4\nPorosity (a)\n0.00 0.501.00 miles\n0.00 1.00 2.00 Km\n0.16 0.17 0.18 0.19 0.20 0.21 0.22 0.23 0.24 0.25\nPorosity K layer: 5(c)\nPorosity K layer: 1(b)\n_o\n0.00 0.501.00 miles\n0.00 0.501.00 miles\n0.00 1.00 2.00 Km\n0.00 1.00 2.00 Km\no -O -o_ o' _\nO -O -o _ o' _\nO \" o -o__ o' _\nCXI\nO -O -o _ o' _\nO \u25a0 o -o__ o' _ CXI\n_o o - o _ o\n_ N) _o o\n- o _ o\n_o o - o _ o\n_o o - o _ o\n_ N)\n__O\n\u2014\tO\n-\to _ o\nFigure 4 - Case study 1 reservoir model\nThe reservoir uncertainties are horizontal permeability in the X direction (Kx), vertical permeability in the Z direction (Kz), Corey coefficient (Equation 4) for water relative permeability (Expow), and the maximal water relative permeability in Corey\u2019s equation\tCorey\u2019s equation for water relative permeability provides the last two attributes. However,\nthe simulation model presents four uncertain attributes per region.\nK = k *.\nrw\trw\n(v - V )\nw wir\n- ExpoW\n(i - v - v )\nwir or\n(4)\nwhere, Km is the water relative permeability, Sw is the water saturation, Swir is the irreducible water saturation and, finally, Sor is the residual oil saturation.\nThe absolute permeabilities Kx and Kz are modified in the simulation models through multiplier numbers. The limits are\n0.5 and 2.0, which represent half and double the absolute permeability Kx and Kz of the base model. The base model uses\nthe unitary multiplier for K and K. Alternatively, the attributes Expow present a variation range from 1 to 5 and the\nattributes K,w* from 0.15 to 0.90. Table 1 summarizes the reservoir attributes.\nTable 1 - Base model reservoir attributes and their limits for case study 1\n\tReservoir attributes\t\t\t\t\t\t\t\t\t\n\tMultipliers\t\t\t\t\t\t\t\t\t\nLimits\tKxi\tKx2\tKx3\tKx\u00ab\tKxs\tKzi\tK:2\tK23\tK24\tKzS\nLower\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\nBase\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\nUpper\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\n\tCorey's equation\t\t\t\t\t\t\t\t\t\nLimits\tExpoW1\tKm*\tExpoW2\tKm*\tExpoW3\tKm*\tExpoW4\tKm*\tExpo W5\tKm*\nLower\t1.00\t0.15\t1.00\t0.15\t1.00\t0.15\t1.00\t0.15\t1.00\t0.15\nBase\t2.20\t0.60\t1.10\t0.80\t4.00\t0.50\t1.30\t0.70\t4.30\t0.80\nUpper\t5.00\t0.90\t5.00\t0.90\t5.00\t0.90\t5.00\t0.90\t5.00\t0.90\nThe reservoir has five horizontal producer wells (Pl, P2, P3, P4 and P5) and five horizontal injector wells (Il, 12, 13, 14 and 15), each producer / injector pair for each region is located in the same reservoir position. The corner point grid shown in Fig. 4 has 2550 cells distributed in 30x17x5 blocks. The reservoir cells of the injector wells are Inj 1 (4;1-6;5); Inj2 (14;1-9;5); Inj3 (20-29;6;5); Inj4 (3;8-17;5) and Inj5 (10-28;14;5) and for the producer the cells are Prodi (4;1-6;1); Prod2 (14;1-9;1); Prod3 (20-29;6;1); Prod4 (3;8-17;1) and Prod5 (10-28;14;1). The well production strategy used in the simulation had a surface liquid limit of 4770 (m3/day); the BHP limit of 20684 KPa for the producer wells and the minimal BHP of 82737 KPa for the injector wells.\nThe multiwell history dataset for this case study has oil production measurements (m3/day) with Tm = 50 m3/day and Mre = 10%, water production measurements (m3/day) with Tm = 350 m3/day and Mre = 10% and BHP measurements (KPa) with Tm = 1000 KPa and Mre = 10%. These values were selected using previous simulation tests with this synthetic reservoir model.\nAlthough the oil rate target on each simulated date is informed into the simulator, the oil production mismatch was one of the analyzed functions in the proposed method. Preliminary tests showed the oil rate mismatching increase when oil function was not included in the uncertainty reduction process. The simulator uses the oil targets to honor the oil rate history data.\n7. Case Study 1: Results and Discussion\nUsing the 20 uncertainty attributes and their upper and lower limits (Table 1), a total of 50 models were generated to represent the search space (Stage 2 from the proposed workflow). From preliminary runs, a set of 50 models could represent the reservoir trend for this case study. The statistical sampling tool selected was Latin Hypercube (LHC). LHC returns an axb matrix, W, containing a Latin hypercube sample of a divisions on each of b variables. For each column of W, the a divisions are randomly distributed with one value from each interval (0,1/a), (1/a,2/a),..., (1-1/ a,1); these values are randomly permuted. The dimensions of the matrix W were 50x20 (number of models and number of attributes). Before the reservoir prediction step, we increased the number of reservoir models to 400 using the reduced reservoir attribute ranges (Stage 5) and the same statistical sampling tool (LHC) with a 400x20 matrix W. The need for a larger set of models for reservoir prediction is discussed in the next sections.\nWe used the multivariate analysis method, described by Bertolini et al. (2015) to evaluate and reduce the reservoir uncertainties in Stage 5 of the workflow. The methodology offers a quantitative analysis and a new tool to evaluate and reduce uncertainties. The process uses a Latin Hypercube (LHC) to sample the reservoir attribute range and a smoothed mismatch data set from the LHC selected objective functions. The attribute interval, which minimizes the mismatch, is identified through polynomial fitting. After, the models are run with the reduced attribute providing an improved history matching for most of the simulated measurements. This method is applied every time that a new observed data (Dobs) is assimilated into the proposed HM workflow. Dobs provides new reservoir information, which might change the performance of the reservoir models. When the set of models are still valid (Stage 4), the application of the uncertainty reduction method keeps searching for the optimum attributes ranges, using the previous ranges. Otherwise, when the models are reparameterized, the application of the uncertainty reduction method started with new attribute ranges.\nThe total simulation period was limited to ten years and the first years of the simulation were used to validate the method. The acquisition of Dobs was set annually. From year one to four, the workflow presented in Figure 3 was applied step by step. Figure 5 shows the reservoir response for the five producer wells using the original attribute range from Table 1 in solid cyan lines (50 models), the AR in dotted red lines, base model in solid red line, and the observed data in black. The top graphs are oil rate in m3/day, middle graphs are water rate in m3/day, and bottom graphs are the BHP in KPa.\n6000\nProdi\nProd2\nProd3\nProd4\nProd5\n\u25a0Q\ng 4000\n2000\nOriginal models \u25a0\u2022\u25a0\u25a0\u25a0AR\n...Base model\nccoofloBS\no\n\u00a3\n6\nO' 5000\nS 4000 E\n\u25a0o 3000 p\nt 2000\n5 1000\nO'\n6\n^0123466789 10\nTime (years)\n0123456789 10\nTime (years)\n0123456789 10 0123456789 10 0123456789 10 Time {years)\tTime (years)\tTime (years)\nFigure 5 - Reservoir response from the 50 models (cyan curves) with the original attribute range; acceptance range\n(red dotted lines); base model (red curves) and observed data (black circles) - Full simulation period (Casel)\nThe HM tracker graph for the tenth year is presented in Figure 6 showing the SqER quality indicator for each well and SM. The oil rate function (SqER - Oil rate) has no problems, the simulator results are inside the AR. Conversely, the SqER for water rate and BHP both exceed the -1 to 1 interval (AR). In the following subsections, the workflow from Figure 3 was applied to evaluate the performance of the simulation models.\n-1\n-2\nSqER - Oil rate\n15\n10\nPl\nP5\nP2 P3 P4\nProducer Wells\n(at 10th year)\nSqER - Water rate\n5\n0\nPl\nP5\nP2 P3 P4\nProducer Wells\n(at 10th year)\n5\n0\n-5\n-10\n-15\n-20\n+\t\t+ +\t\t\t\t\n\t\t\t\t\t\t\u00b1 -\n\t\t\t\t\t\t\n\t\t\t\t\t\t= n\n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t: \u00a5\n\t\t\t\t\t\t\u2019 i \u25a0\n\t\t\t\t\t\t5\tzl\n\t\t\t\t\t\t\nProducer Wells\n(at 10th year)\n5\n4\n3\n2\n1\n0\nFigure 6- HM tracker graph for SqER oil and water rate, and SqER BHP functions at 10th year (Casel)\n7.1\tThe first year\nFor the annual acquisition frequency, the initial set of observed data is at the end of the first production year. At this time the reservoir uncertainties and the representative models are ready, and the Dobs from the first year were added into the models. The next step is the model evaluation against the new Dobs (Stage 4 in Figure 3). With only a year of simulation time, most of the 50 models have a similar response. Figure 7 shows the HM tracker graphic at the first year.\nFor oil and water rates and for the five producer wells, the 50 simulation results are the same. However, the HM tracker graphic shows a flat line for those functions and wells between the -1 to 1 interval, except P3 well for SqER water rate. Although the SqER BHP results present different responses, they are mostly within the AR.\nProducer Wells\n(at lsxyear)\n\t\t- - - =\t-\ni\ti i nun hi II I II IIIIIIIIBII\t\tIll\n\t\t\t\nFigure 7- HM tracker graph for SqER oil and water rate, and SqER BHP functions at 1st year (original models -Casel)\nNo model from the original set represented the P3 well water rate history data. Even with a year of observed data, the models failed to honor the observed data with the inclusion of the AR. The output for the Stage 4 is negative, so models must be reparameterized. The reservoir model was analyzed in greater depth, looking for the parameters that most strongly affect the water production at the P3 well (Bertolini et al., 2015). The models were improved after three manual attempts, passing from Stage 1 to 4 of the workflow. The two main changes were the porosity distribution in region 3 and the Expow3 range reduction from 1 - 5 to 1 - 2. Figure 9 shows the HM tracker graph for the updated models for the first year.\nFigure 8- HM tracker graph for SqER oil and water rate, and SqER BHP functions at 1st year (reparameterized\n\t\n\u25a0 + + =\t= + + \u25a0\n\t\n\ts\t\u25a0\n\u25a0 + + 1\t1 + + \u25a0\n\t\nmodels - Casel)\nCompared with Figure 7 (original models), the results presented in Figure 8 had very similar responses for oil rate and\nBHP functions. The main change occurred in the P3 well for the SqER water rate. It presents a wide range of results, with the median inside the AR. Therefore, this set of models is ready for the next stage in the workflow.\nThe multivariate uncertainty reduction method described by Bertolini et al. (2015) reduced the new ranges (Table 2).\nTen of the twenty parameter ranges were narrowed after the application of the method, including the Expow3 range of 1 - 2. The HM graphic is shown in Figure 9.\nTable 2 - Original and reduced reservoir attributes after uncertainty reduction method at 1St year (Case 1)\n\tReservoir attributes - original range (white) and reduced range (gray)\t\t\t\t\t\t\t\t\t\n\tMultipliers\t\t\t\t\t\t\t\t\t\nLimits\tKX1\tKx2\tKx3\tKx4\tKx5\tKzi\tKz2\tKz3\tKz4\tKzS\nLower\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\t0.50\nLower\t0.92\t0.55\t0.92\t0.50\t0.50\t0.81\t0.50\t1.07\t0.50\t0.73\nUpper\t1.65\t1.29\t1.66\t2.00\t2.00\t1.57\t2.00\t1.80\t1.22\t1.46\nUpper\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\t2.00\n\tCorey's equation\t\t\t\t\t\t\t\t\t\nLimits\tExpxPOl\tKm*\tExpoW2\tKrw2*\tExpoW3\tKrw3*\tExpxP04\tKm*\tExpo W5\tKm*\nLower\t1.00\t0.15\t1.00\t0.15\t1.00\t0.15\t1.00\t0.15\t1.00\t0.15\nLower\t1.00\t0.15\t1.00\t0.15\t1.00\t0.42\t1.00\t0.15\t1.00\t0.49\nUpper\t5.00\t0.90\t5.00\t0.90\t2.00\t0.79\t5.00\t0.90\t5.00\t0.86\nUpper\t5.00\t0.90\t5.00\t0.90\t5.00\t0.90\t5.00\t0.90\t5.00\t0.90\nFigure 9- HM tracker graph for SqER oil and water rate, and SqER BHP functions at 1st year (reparameterized\nmodels and uncertainty reduction method applied - Casel)\n+\t\n\u25a0 + + =\t^ + + \u25a0\n\t\nProducer Wells (at lSIyear)\n\t\t+ +\t\t\u25a0\t\t\n- +\t+\t\t\t+\t+\t-\n\t\t+\t\t\t\t\nProducer Wells\n(at 1st year)\n+\t\nmi inn II \u25a0\u25a0III I \u25a0Hill I\ti mu I Hill in i iii mm\n\t\nProducer Wells\n(at l5tyear)\nTwo main changes occurred after Stage 5 (Figure 9). The P3 well for SqER oil rate results spread slightly within the AR while the P3 well for SqER water rate function moved into the AR, away from the upper outliers. With the SqER distributions presented in Figure 9, Stage 6 receives a positive output, and the process moves to Stage 7 for the reservoir predictions. From the 400 models generated using the attribute ranges from Table 2 and the 400x20 LHC matrix, 103 were discarded using the filter (models with any SqER out of AR). The original 50 models, Dobs, base model and the 297 representative reparameterized models are presented in Figure 10. The vertical dashed line represents the present, on the left, the past and on the right, the future reservoir behavior.\nProdi\tProd2\tProd3\tProd4\tProd5\n01 23456789 10 01 23456789 10 01 23456789 10 01 23456789 10 01 23456789 10\nTime (years)\tTime (years)\tTime (years)\tTime (years)\tTime (years)\nFigure 10 - Case 1 reservoir response from the 50 original models with 1 year of history data; Dobs; base model and\n297 reparameterized models. On the left of vertical dashed line is past reservoir behavior and on the right is future.\nStage 8 is the last check in the proposed workflow, guaranteeing the use of recent Dobs. In case of new Dobs, the process starts again at Stage 3. The following sections present the results from the 2nd, 3rd and 4th years.\n7.2\tThe second year\nAt the end of the second production year, new Dobs are available; their use brings a better reservoir understanding. Using the reparameterized 50 models from the previous year, the HM tracker graph is presented in Figure 11 for the first and second year.\nFigure 11- HM tracker graph for SqER oil and water rate, and SqER BHP functions at 1st and 2nd year (Case 1)\nMost of SqER distributions maintain the same positions from the first year. The most representative change was the P3 well for oil rate function, which expanded the result distribution within the AR. However, the reservoir prediction can still be obtained from 281 (filtered at 2nd year) reparameterized models from the first year.\n7.3\tThe third year\nAfter three years of production, the HM graph shows an intensified increase in SqER trends from the 2nd year such as the Oil and Water rate for well P3, shown in Figure 12. The SqER BHP distributions and the P3 well SqER oil rate expand with time, although they are all within the AR. The SqER water rate for the P2 and P5 wells shows a small increase; as does the SqER water rate for the P3 well. This well was out of range and therefore forced a model reparametrization in the first year; now it varies within the AR, indicating consistency and validating the model\nmodification. At the 3rd year, 260 representative models from the first year still honor the observed data within the acceptance range.\nProducer Wells\tProducer Wells\tProducer Wells\n(at 1st, 2nd and 3rd year)\t(at 1st, 2nd and 3rd year)\t(at 1st, 2nd and 3rd year)\nFigure 12- HM tracker graph for SqER oil and water rate, and SqER BHP functions at 1st, 2nd and 3rd year (Case 1)\n7.4\tThe fourth year\nSimilar trends occurred after the inclusion of the observed data from the fourth year. Now, some trends that appeared in the third year have intensified; the SqER water rate values for the P2 and P5 wells are moving out of the AR. This evolution means that the observed data from the fourth year were included in the representative models at Stage 3; but at Stage 4, 84% of the models were no longer able to match the new Dobs. After filtering (Stage 7), only 65 representative models from the first year honored the observed data within the AR. Figure 13 shows the SqER distribution trends from 1st to 4th year.\nProducer Wells\tProducer Wells\tProducer Wells\n(From 1st to 4th year)\t(From 1st to 4xh year)\t(From 1st to 4xh year)\nFigure 13- HM tracker graph for SqER oil and water rate, and SqER BHP functions from 1st to 4th year (Case 1)\nSince most of SqER water rate values for P2 and P5 wells are out of the AR, a new model reparametrization is now required (Stage 9). However, at this time the reservoir model was reassessed again, Expow2 and Expows attribute ranges were also reduced to 1 - 2, and Kw*and Kw* from 0.5 to 0.9.\nApplying these changes, we ran 50 reparameterized models in the simulator. Figure 14 shows the HM tracker graph from 1st to 4th year. The SqER values are either within the AR for most of the functions or at least more symmetrically distributed around the zero, except for some functions that have outliers larger than 1 or -1. These results allow progression to the next stage.\nProducer Wells\tProducer Wells\tProducer Wells\n(From 1\" to 4'\" year)\t(From 1st to 4'' year)\t(From 1st to 4\u2019\" year)\nFigure 14- HM tracker graph for SqER oil and water rate, and SqER BHP functions from 1st to 4th year\n(reparameterized models - Casel)\nWith the same multivariate uncertainty reduction method in the 4th year, the attribute range was reduced. SqER oil rate for P2 and P3 wells and SqER water rate for P2, P3 and P5 wells closer to or moved into the AR. The opposite occurred to SqER BHP for Pl well where few SqER values are higher than the AR. Figure 15 presents the SqER values after applying the uncertainty reduction method.\n(From 1st to 4th year)\t(From 1st to 4th year)\t(From l5tto 4th year)\nFigure 15- HM tracker graph for SqER oil and water rate, and SqER BHP functions from 1st to 4th year\n(reparameterized and uncertainty reduction method applied - Casel)\nFrom the 400 models generated using the 400x20 LHC matrix and the new attribute range from 4th year, 74 were discarded using the filter. The original 50 models, Dobs, base model and the 326 representative reparameterized models are presented in Figure 16.\n01 23456789 10 0123456789 10 0123456789 10 0123456789 10 01 23456789 10 Time (years)\tTime (years)\tTime (years)\tTime (years)\tTime (years)\nFigure 16- Case 1 reservoir response from the 50 original models; Dobs; base model and 326 reparameterized models\n(in the 1st to 4th years and uncertainty reduction method applied in the 1st and 4th year). On the left of vertical dashed\nline is past reservoir behavior and on the right is future behavior\n7.5\tGeneral process for n years\nThe loop continues during the reservoir production period. According to the Dobs acquisition frequency, the representative models used to make prediction are checked against the observed data with AR at Stage 8. The HM tracker graphic is also updated every time there is a new Dobs. It is a quick evaluation tool for the user managing the reservoir. Apart from the visual graphic tool, the implementation of an assisted workflow based on Figure 3, and different levels of reservoir response alerts can be set up using conventional computer codes. The number of simulation models inside all ARs for each set of models are showed in Figure 17. At the 1st year, the original set of models (white bars in Fig.17) and the set of reparameterized and optimized models at 1st year (gray bars in Fig.17) were history matched using the proposed workflow. In the following years, these sets are making reservoir forecasts. The set of reparameterized and optimized at 4th year (black bars in Fig. 17) was history matched at 4th year and the following year are reservoir forecasts.\nYEARS\nFigure 17- Number of simulation models inside all ARs - Casel\n8. Case Study 2: UNISIM-I-H Reservoir Model\nThe full description of UNISIM-I-H model is presented by Avansi and Schiozer (2014). It uses structural, facies and petrophysical models from Namorado field, located in Campos Basin, Brazil. The geological model has 3.5 million active cells and it uses core and well logging data, 2D and 3D seismic data provided by Brazilian National Petroleum Agency - ANP and also from Petrobras (released public data).\nBased on the geological model in a high-resolution grid, an upscaling procedure to a medium reservoir scale was necessary to decrease the computational effort. A simulation grid cell resolution was defined with 100 x 100 x 8 m blocks to reflect reservoir behavior properly and heterogeneities. It was discretized into a corner point grid (81 x 58\nx 20 cells, with 36,739 active total cells). Porosity was upscaled through an arithmetic volume weighted method to ensure that the hydrocarbon pore volume remained constant when upscaling (additive property characteristics). Permeability was upscaled using a flow-based upscaling technique described by Deutsch (1989). When an isotropic permeability is upscaled, the effective results become anisotropic; three effective permeabilities in all directions (i, j and k) are then obtained for the upscaled reservoir model. In this work, 12 reservoir regions were defined using well location and their influences to the total reservoir production. The fluid model is Black Oil, oil density is 28\u00b0 API and the original volume of oil of the model is 130 million m3. The production strategy was defined with 25 wells (4 vertical producers, 10 horizontal producers and 11 injectors). Figure 18 shows the porosity map and the well locations.\nFig. 18 - UNISIM-I-H porosity map and well locations\nThe vertical wells NA1D, NA2, NA3D and RJS19 were the pilot vertical wells for this field. They produced the field for 4 years and then were closed for one year. Production resumed in the sixth year with all 14 producers and 11 injectors for six more years. The model presents 18 uncertain attributes. Table 3 indicates the limits for each attribute. They are 12 porosity multipliers (Mpor), one horizontal permeability multiplier (Mkh), one vertical permeability multiplier (Mkv) for the entire reservoir, water-oil contact (WOC), coefficient A (CoeffA) and coefficient B (CoeffB) of Eq.5, which correlates porosity ($,) with horizontal permeability (Kh), and\tof Eq.4.\nThe vertical permeability without any multiplier was defined as 10% of the horizontal permeability.\nTable 3 - Base model reservoir attributes and their limits for case study 2\n\tReservoir attributes\t\t\t\t\t\t\t\t\nLimits\tMpori\tMpor2\tMpor3\tMpor4\tMpors\tMpors\tMpor7\tMpors\tMpors\nLower\t0.70\t0.70\t0.70\t0.70\t0.70\t0.70\t0.70\t0.70\t0.70\nBase\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\nUpper\t1.30\t1.30\t1.30\t1.30\t1.30\t1.30\t1.30\t1.30\t1.30\n\t\t\t\t\t\t\t\t\t\nLimits\tMporio\tMporu\tMpori2\tMKh\tMKV\tWOC (m)\tCoeffA\tCoeffB\tExpoW\nLower\t0.70\t0.70\t0.70\t0.50\t0.50\t3095.00\t0.040\t1.00\t2.00\nBase\t1.00\t1.00\t1.00\t1.00\t1.00\t3095.00\t0.045\t1.15\t3.00\nUpper\t1.30\t1.30\t1.30\t3.00\t3.00\t3105.00\t0.050\t1.30\t5.00\nThe oil rate and the water injection rate on each simulated date was input into the simulator. The BHP was limited at 15000 KPa as a minimum for producer wells and at a maximum of 35000 KPa for injector wells. The maximum liquid rate was set to 3000 m3/day for producer wells and 6000 m3/day for injector wells. The same SMs were evaluated, oil production with Tm = 25 m3/day and Mre = 7.5%, water production with Tm = 125 m3/day and Mre = 15% and BHP for producer wells with Tm = 250 KPa and Mre = 15%, for 14 producer. In total, 42 functions were considered.\n9. Case Study 2: Results and Discussion\nOnly vertical wells (NA1D, NA2, NA3D and RJS19 well) produce during the first four years. At the 1st year the SqER oil rate presents the biggest values and most of the models are out of the AR. Water rate is insignificant with one year of production, so SqER water rates are within the AR. SqER BHP are spread within and out of the AR. Figure 19 (upper plots) shows SqER for the 100 original simulation models (Set1) generated through LHC. Table 4 presents the number of models within each function and the number of models within all acceptance ranges (ARs). After the filter, Set1 has 32 models within all ARs. An uncertainty reduction tool optimized reservoir attribute ranges for Set1. An overall improvement for SqER was achieved, from 32 models (Set1) to 60 (Table 4) models (Set2) inside all ARs. Fig. 19 (lower plots) shows the SqER for the new set of models (Set2).\nAt the 4th year, the last year before the full field production with all 25 wells, a new reservoir attribute assessment was performed through the uncertainty reduction tool using 4 years of history data. Set3 represents the 100 optimized models at the 4th year. Fig. 20 shows the SqER until the 4th year for Set3.\nWe evaluated the reservoir models again after one year of full field production. At this time (7th year), 14 producer wells and 11 injector wells were active. Fig. 21 (upper plots) shows the Setl SqER for each well and function. Similarly to Setl, Set2 and Set3 models also result in unmatched BHP for Prod5 and Prod14 wells (Table 4). None of the models from Setl, Set2 or Set3 were within all 42 ARs (3 functions and 14 wells). However, at the time the reservoir model was reparameterized. The reservoir model was analyzed in greater depth, with changes in the porosity distribution around Prod5 and Prod14 wells and the water relative permeability. New models were created (Set4) using the original attribute ranged from Table 3 and LHC W (100 x 18). The uncertainty reduction tool then optimized the models (Set5). Fig. 21 (lower plots) shows the Set5 SqER for each well and function.\nFigure 19- HM tracker graph for SqER oil and water rate, and SqER BHP at 1st year (upper plot - original models\nSetl and lower plot - optimized models Set2) - Case2\n1234123412341234\nYears\nNA1A\tNA2\tNA3D\tRJS19\nVertical producer wells (From 1st to 4th year)\nvertical producer wells (From 1st to 4th year)\nSqER - BHP (Set 3)\n\nFigure 20- HM tracker graph for SqER oil and water rate, and SqER BHP from 1st to 4th year (optimized models Set3 - Case2)\n\t\nth1\t\n11 =\t= --\n= = :\t+ +\ni: *\t+ \u25a0\nSqER - BHP (Set 1)\nFigure 21- HM tracker graph for SqER oil and water rate, and SqER BHP functions at 7th year (upper plot - original\nmodels Setl and lower plot - optimized models Set5) - Case2\nFigures 22, 23 and 24 present the results for Dobs, Setl, Set4 and Set5. The vertical dashed line represents present reservoir behavior, with the past on the left, and future on the right. The number of models within all ARs for Set4 and Set5 at the 7th year, are 10 and 21 respectively (Table 4). Field oil and water production, and average BHP are shown in Fig. 25. Table 4 shows the numbers of models within the ARs for each set of models and functions.\nFigure 22 - Oil rate from 100 original models (Setl); 100 reparameterized models (Set4) and 100 optimized models\n(Set5). On the left of vertical dashed line is past reservoir behavior and on the right is future behavior (Case 2)\n2000\n1500\n1000\n500\n0\n2000\n1500\n1000\n500 0\n2000\n1500\n1000\n500 0\nNA1A\nRJS19\n1 23456789 10 11 Time (years)\nNA2\nWater rate (m3/D)\nNA3D\nPROD005\n1 23456789 10 11 Time (years)\n1 23456789 10 11 Time (years)\n1 23456789 10 11 Time (years)\n1 23456789 10 11 Time (years)\nPRQD008\nPRQD009\nPRQD010\nPRQD012\nPRODQ14\nPRODQ24A\nPRQD021\nPRODQ23A\nPRODQ25A\nooDobs \u2014Setl \u2014 Set 4 \u2014Set 5 \u2014AR\nFigure 23 - Water rate from 100 original models (Setl); 100 reparameterized models (Set4) and 100 optimized\nmodels (Set5). On the left of vertical dashed line is past reservoir behavior and on the right is future behavior (Case 2)\nBHP (KPa)\nx10 NA1A  NA2  NA3D\nX104 PROD008\tPROD009\tPROD010\n----------------'--------- ----------------1--------- ----------------r\"\n\t\t1\t\t\t\t\tPT\nx104 PROD021\tPROD023A\tPROD024A\n\t\t\t\t\t\t\u25a0 I\t\n\t\t\tjwtr mvJlk'vl'U irAWV'8l\tIw.\t\u25a0\t\t\t\n1 23456789 10 11 1 23456789 10 11 1 23456789 10 11\nTime (years)\tTime (years)\tTime (years)\nRJS19  PRQD005\nPROD025A\n23456789 10 11 Time (years)\n1 23456789 10 11 Time (years)\nooDobs \u2014Setl \u2014Set 4 \u2014Set 5 \u2014AR I\nFigure 24 - BHP from 100 original models (Setl); 100 reparameterized models (Set4) and 100 oplimiz.ed models\n(Set5). On the left of vertical dashed line is past reservoir behavior and on the right is future behavior (Case 2)\n16000\n14000\n12000\n10000\n8000\n6000\n4000\n2000\nField oil production (m3/d)\nTime (years)\n14000\n12000\n10000\n8000\n6000\n4000\n2000\n0\nField water production (m3/d)\nx10'\nAverage BHP (KPa)\n4\nTime (years)\noo Dobs \u2014Setl \u2014Set 4 \u2014Set 5 \u2014AR\nTime (years)\nFigure 25 - Field reservoir response from 100 original models (Setl); 100 reparameterized models (Set4) and 100 optimized models (Set5). On the left of vertical dashed line is past reservoir behavior and on the right is future behavior (Case 2)\nTable 4 and Figure 26 show the numbers of models within the ARs for each set of Case 2 models and functions. At the 1st year, the original set of models (Setl) and the set of optimized models at 1st year (Set2) were history matched using the proposed workflow. In the following years, these sets are making reservoir forecasts. The set of optimized at 4th year (Set3) was history matched at 4th year and the following year they are making reservoir forecasts. Finally, the set of reparameterized models at 7th year (Set4) and the set of reparameterized and optimized models at 7th year (Set5) were history matched at 7th and from 7th to 11th year the sets are making reservoir forecasts.\nTable 4 - Numbers of models inside the ARs for each set of models and functions - Case Study 2\n\tNumber of models inside the AR - Oil Rate\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\tSet 1 - Year\t\t\tSet 2 - Year\t\t\tSet 3 - Year\t\t\tSet 4 - Year\t\t\tSet 5 - Year\t\t\nWells\t1st\t4th\t7th\t1st\t4th\t7th\t1st\t4th\t7th\t1st\t4th\t7th\t1st\t4th\t7th\nNA1A\t97\t90\t81\t100\t100\t100\t100\t100\t100\t100\t98\t93\t100\t100\t99\nNA2\t100\t72\t55\t100\t99\t92\t100\t99\t99\t100\t98\t88\t100\t99\t99\nNA3D\t70\t57\t40\t99\t98\t79\t99\t99\t96\t97\t93\t91\t100\t100\t100\nRJS19\t77\t81\t83\t100\t100\t100\t100\t100\t100\t99\t99\t100\t100\t100\t100\nPROD5\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t79\t100\t100\t93\nPROD8\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\nPROD9\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\nPROD10\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\nPROD12\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t99\t100\t100\t100\nPROD14\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t100\t85\t100\t100\t99\nPROD21\t100\t100\t89\t100\t100\t99\t100\t100\t99\t100\t100\t100\t100\t100\t100\nPROD23A\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\nPROD24A\t1OO\t1OO\t57\t1OO\t1OO\t74\t1OO\t1OO\t91\t1OO\t1OO\t98\t1OO\t1OO\t1OO\nPROD25A\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\n\t\t\t\t\tNumber of models inside the AR\t\t\t\t\t- Water Rate\t\t\t\t\t\n\tSet 1 - Year\t\t\tSet 2 - Year\t\t\tSet 3 - Year\t\t\tSet 4 - Year\t\t\tSet 5 - Year\t\t\nWells\t1st\t4th\t7th\t1st\t4th\t7th\t1st\t4th\t7th\t1st\t4th\t7th\t1st\t4th\t7th\nNA1A\t1OO\t99\t99\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t99\t99\t1OO\t99\t99\nNA2\t1OO\t44\t23\t1OO\t68\t33\t1OO\t73\t6O\t1OO\t64\t83\t1OO\t32\t7O\nNA3D\t1OO\t47\t3O\t1OO\t65\t3O\t1OO\t91\t47\t1OO\t1OO\t99\t1OO\t1OO\t99\nRJS19\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\nPROD5\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t92\t1OO\t1OO\t98\nPROD8\t1OO\t1OO\t96\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\nPROD9\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\nPROD1O\t1OO\t1OO\t88\t1OO\t1OO\t99\t1OO\t1OO\t99\t1OO\t1OO\t99\t1OO\t1OO\t99\nPROD12\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t99\t1OO\t1OO\t99\nPROD14\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\nPROD21\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\nPROD23A\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\nPROD24A\t1OO\t1OO\t89\t1OO\t1OO\t99\t1OO\t1OO\t99\t1OO\t1OO\t99\t1OO\t1OO\t99\nPROD25A\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\n\t\t\t\t\tNumber of models inside the AR -\t\t\t\t\t\tBHP\t\t\t\t\n\tSet 1 - Year\t\t\tSet 2 - Year\t\t\tSet 3 - Year\t\t\tSet 4 - Year\t\t\tSet 5 - Year\t\t\nWells\t1st\t4th\t7th\t1st\t4th\t7th\t1st\t4th\t7th\t1st\t4th\t7th\t1st\t4th\t7th\nNA1A\t79\t85\t91\t92\t1OO\t1OO\t1OO\t1OO\t1OO\t96\t99\t99\t1OO\t1OO\t1OO\nNA2\t1OO\t76\t84\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t99\t1OO\t1OO\t99\t1OO\nNA3D\t1OO\t1OO\t99\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\nRJS19\t76\t97\t99\t62\t99\t1OO\t48\t99\t1OO\t62\t98\t99\t63\t1OO\t1OO\nPROD5\t1OO\t1OO\t1\t1OO\t1OO\t1\t1OO\t1OO\tO\t1OO\t1OO\t83\t1OO\t1OO\t73\nPROD8\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\nPROD9\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\nPROD1O\t1OO\t1OO\t98\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\nPROD12\t1OO\t1OO\t96\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t85\t1OO\t1OO\t99\nPROD14\t1OO\t1OO\t3\t1OO\t1OO\tO\t1OO\t1OO\tO\t1OO\t1OO\t99\t1OO\t1OO\t1OO\nPROD21\t1OO\t1OO\t67\t1OO\t1OO\t99\t1OO\t1OO\t99\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\nPROD23A\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t98\t1OO\t1OO\t99\nPROD24A\t1OO\t1OO\t46\t1OO\t1OO\t93\t1OO\t1OO\t87\t1OO\t1OO\t43\t1OO\t1OO\t66\nPROD25A\t1OO\t1OO\t96\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t1OO\t9O\t1OO\t1OO\t83\n\tNumber of models inside all ARs (oil, water rates and BHP)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\tSet 1 - Year\t\t\tSet 2 - Year\t\t\tSet 3 - Year\t\t\tSet 4 - Year\t\t\tSet 5 - Year\t\t\n\t1st\t4th\t7th\t1st\t4th\t7th\t1st\t4th\t7th\t1st\t4th\t7th\t1st\t4th\t7th\n\t32\t16\tO\t6O\t52\tO\t47\t65\tO\t53\t52\t1O\t63\t32\t21\n1\t2\t345\t6789\t10\t11\nYEARS\nFigure 26- Number of simulation models inside all ARs - Case 2\nHaving the observed data available for the next years, we noted from Figure 26 that the models history matched at\n7th year are no longer valid (inside all ARs) in the following year. It reinforces the advantages of using a continuous\nHM workflow, allowing a faster model reassessment as needed and ultimately, providing reliable reservoir forecasts.\n10. Conclusions\nWe propose a sequence of steps to continually evaluate the model performance over the simulation period. This method works with an acceptance range (AR) applied to the multiwell history dataset. The method is composed by nine-step workflow, which incorporates an uncertainty reduction tool and a HM indicator graph over time. The graph provides a practical and efficient way to support reservoir decisions. The acceptance range formulation considers relative measurement errors and tolerance margins from field characterization quality.\nIn this application, the reservoir models were annually evaluated against the acceptance range. The method maintained a set of calibrated models for the simulation period. The multivariate analysis method reduced reservoir uncertainties. This uncertainty reduction tool narrowed reservoir attribute ranges, minimizing the mismatch. The workflow was applied and described in detail from the first to the ninth step. We reparameterized the models twice, in the first and fourth years for Case 1, and once (seventh year) for Case 2 to honor the new observed data included in the HM.\nThe results presented annually showed the importance of continuous evaluation, and reservoir model updating to guarantee calibrated reservoir models over time. Furthermore, this application and its results lead to the following observations:\n\u2022\tMeasurement errors and tolerance margins were incorporated in the observed data, providing an acceptance history range, which was used to evaluate the reservoir model while performing HM.\n\u2022\tEstimation of the relative measurement errors and the tolerance margin is a key stage for a proper history matching procedure and prediction. Whenever we do not know the measurement errors and/or a reasonable tolerance margin for the reservoir model, a sensitivity analysis with different estimated values is recommended to build a set of acceptance range scenarios.\n\u2022\tA rigorous measurement error determination and tolerance margins associated with reservoir characterization improves the evaluation of the simulation models. Minimizing the effect of measurement conditions, for instance, individual well rate measurement and precise depths of pressure gauges, and a refined reservoir characterization, allow tighter evaluation criteria applied during HM.\n\u2022\tFor full field model reservoir, the method facilitates the model performance evaluation through the squared-error values of functions and wells, in a unique HM tracker graphs. This graph tracks the set of the reservoir models throughout the simulation period, which ideally should be synchronized with history data sampling frequency.\n\u2022\tThe method allows an easily assisted HM implementation based on the proposed tracker plot (Figure 2). The main loop from Stage 3 until Stage 8 in Figure 3 can be automated using computer codes.\n\u2022\tThe uncertainty analysis was performed using a multivariate analysis method proposed by Bertolini et al. (2015). Different tools and uncertainty reduction methods can be selected according to the number and type of the reservoir uncertainties. The production period can also determine reservoir management priorities, which may affect the reservoir uncertainty evaluation.\nNomenclature\nHM - History matching\nLHC - Latin Hypercube\nAR - Acceptance range\nKrw - Water relative permeability\nSw - Water saturation\nSwir - Connate water saturation\nSor - Residual oil saturation\nExpow - Coefficient of Corey\u2019s equation for water relative permeability\nKrw* - Maximum value of the water relative permeability in Corey\u2019s equation\nKx - Effective permeability in X direction\nKy - Effective permeability in Y direction\nSM - simulated measurement\ns - Simulated data\nh - History data\nd - Number of data points\nm - Number of simulated measurement\nDobs - Observed data\nSqE - Square error\nSqER - Square error ratio\na - Number of LHC divisions\nb - Number of variables\nW - LHC matrix with a-by-b dimension\nx - Number of simulation models\nFar - Acceptance range function\nTm - Tolerance margin\nMre - Relative measurement error\nBHP - Bottom hole pressure\ng - Standard deviation\nReferences\n\u2022\tBertolini A., Schiozer D., 2011. Influence of the objective function in the history matching process. Journal of\nPetroleum Science and Engineering, May, Volume 78, Issue 1, July 2011, Pages 32-41.\n\u2022\tEmerick, A. A. and Reynolds, A. C., 2011. History Matching a Field Case Using the Ensemble Kalman Filter With\nCovariance Lacalization. SPE 141216-PA, SPE Reservoir Simulation Symposium held in The Woodlands, Texas, USA.\n\u2022\tEmerick, A. A. and Reynolds, A. C., 2012. Combining the Ensemble Kalman Filter With Markov Chain Monte Carlo for Improved History Matching and Uncertainty Characterization. SPE 141336-PA, SPE Reservoir Simulation Symposium held in The Woodlands, Texas, USA.\n\u2022\tMaschio, C., Schiozer, D., 2013. A new procedure to reduce uncertainties in reservoir models using statistical inference and observed data. Journal of Petroleum Science and Engineering, Volume 110, October 2013, Pages 721.\n\u2022\tOliver, D. S., Reynolds A. C., Liu N., 2008. Inverse Theory for Petroleum Reservoir Characterization and History Matching. Cambridge University Press.\n\u2022\tZhou, W., Gupta, S., Banerjee, R., Poe, B., Spath, J., and Thambynayagam, M., 2013. Production Forecasting and Analysis for Unconventional Resources. Paper IPTC 17178-MS presented at the International Petroleum Technology Conference, Beijing, China, 26-28 March.\n\u2022\tRisso, F. V. A., Risso, V. F., Schiozer, D. J., 2011. Risk Analysis of Petroleum Fields using Latin Hypercube, Monte Carol and Derivative Tree Techniques. Journal of Petroleum and Gas Exploration Research Vol. 1(1) pp. 014-021, September.\n\u2022\tSlotte, P.A., Sm0rgrav, E., 2008. Response surface methodology approach for history matching and uncertainty assessment of reservoir simulation models. In: Proceedings of the Europec/EAGE Annual Conference and Exhibition, 9-12 June. SPE113390. Rome, Italy.\n\u2022\tSchaaf, T., Coureaud, B., Labat, N., 2008. Using experimental designs, assisted history matching tools and Bayesian framework to get Probabilistic production forecasts. In: Proceedings of the SPE Europec/EAGE Annual Conference and Exhibition, 9-12June. SPE113498. Rome, Italy.\n\u2022\tLiu, C., McVay, D. A., 2010. Continuous Reservoir-Simulation-Model Updating and Forecasting Improves Uncertainty Quantification. SPE 119197.\n\u2022\tMaschio, C., Schiozer, D.J., Moura Filho, M.A.B., 2005. A methodology to quantify the impact of uncertainties in the history matching process and in the production forecast. In: Proceedings of the Annual Technical Conference and Exhibition, 9-12 October. SPE96613. Dallas, Texas.\n\u2022\tMaschio, C., Schiozer, D.J., Moura Filho, M.A.B., Becerra, G.G., 2009. A methodology to reduce uncertainty constrained to observed data. SPE Reserv. Eval. Eng. (SPE 111030) 12(1), 167-180.\n\u2022\tMaschio, C., Schiozer, D., 2003. A new upscaling technique based on Dykstra-Parsons coefficient: evaluation with streamline reservoir simulation. Journal of Petroleum Science and Engineering 40, 27- 36.\n\u2022\tTavassoli, Z., Carter, J. N., King, P. R., 2004. Errors in History Matching. SPE 86883-PA\n\u2022\tThakur, G.C., 1996. What is Reservoir Management? Journal of Petroleum Technology, Volume 48, Number 6, June. SPE 26289-MS.\n\u2022\tBertolini, A. C., Booth, R. J., Morton, K. L., Fitzpatrick, A. J., 2013. Design of Objective Function for Interference Well Testing. OTC-24513MS. Paper was presented at the Offshore Technology Conference Brasil held in Rio de Janeiro, Brazil, 29-31.\n\u2022\tBertolini, A. C.; Maschio, C.; Schiozer, D. J., 2015. A Methodology to Evaluate and Reduce Reservoir Uncertainties Using Multivariate Distribution, Journal of Petroleum Science and Engineering, v. 128, pp. 1-14, Abril.\n\u2022\tGu, Y. and Oliver, D.S., 2004. History Matching of the PUNQ-S3 Reservoir Model Using the Ensemble Kalman Filter.SPE 89942, Annual Technical Conference and Exhibition, Houston, Texas, U.S.A., 26-29 September.\n\u2022\tDeutsch, C., 1989. Calculating Effective Absolute Permeability in Sandstone/Shale Sequences SPE Formation Evaluation, 4(3): 343 -348.\n\u2022\tAvansi, G.D., Schiozer, D.J., 2015. A New Approach to History Matching Using Reservoir Characterization and Reservoir Simulation Integrated Studies, OTC, 4-5 May, Houston, USA.\n92\n6.\tCONCLUSIONS\nWe proposed a methodology to calibrate reservoir simulation models considering four main steps: (1) a comparison scheme to identify appropriate objective functions for HM processes, (2) an uncertainty reduction method that uses multivariate analysis, incorporating the interaction between reservoir properties, (3) an uncertainty evaluation method capable of reducing the dimension of the problem through principal component analysis (PCA) and (4) a real-time history matching method that rigorously evaluates the HM quality and identifies the model updating and model reassessment need over time. Furthermore, there are some important results specific to each of the four articles, which should be highlighted.\nFrom article 1, the following conclusions are drawn:\n\u2022\tHM results are influenced by objective function formulation. Although the quality of the matching does not guarantee a good model, assisted procedures frequently relies on a good performance of the optimization method. However, the optimization functions should be carefully chosen.\n\u2022\tSimple error function computed using history minus simulated data achieved the highest HM improvement. On the other hand, the optimization convergence was gradual and slow, requiring a large number of simulations.\n\u2022\tThe quadratic error function presented significant HM improvements at the beginning of the optimization process, even with a reduced number of simulations. It prioritizes points of larger difference, which accelerates the optimization solution.\n\u2022\tThe quadratic error function was selected and used in the next articles. Before, the function was further improved through the addition of sign, indicating an overestimation or a underestimation of the simulation results, and normalized for the use in multiobjective evaluation.\nThe methodology presented in article 2 is innovative and integrates mathematical tools to reduce reservoir uncertainties using dynamic data. Some of the results to be highlighted are as following:\n\u2022\tThe smoothing technique helped obtaining the general trend between reservoir attributes and the objective function misfit selected in both reservoir models. The examples showed that even using a large number of models (from the Latin Hypercube), the HM improvements are not significant when the smooth misfit is not used.\n\u2022\tA lower number of simulations and consequently less computation power are required while using the smoothing technique applied to misfit functions. In addition, this methodology provided a set of improved simulation models without the use of proxy models, avoiding an additional complex step of similar techniques.\n\u2022\tThe methodology allows checking the relationship between the expected reservoir behavior and the reservoirs uncertain attributes through a sensitivity matrix. The matrix is a relevant tool to support HM and it was used to identify the critical attributes that influence the reservoir responses. The optimization of these attributes using the higher R2 coefficients is powerful to achieve better local HM.\nArticle 3 results are an extension of the methodology developed in the previous article. The additional conclusions are the following:\n\u2022\tThe size of the interpretable dataset is a critical factor for a reservoir evaluation. The time required and solution space coverage are the elements often associated with an efficient big dataset interpretation. The PCA method presented in article 3 efficiently reduced the size of the dataset, and consequently the computation time required to narrow the reservoir uncertainty.\n\u2022\tSolution space coverage is controlled by the number of principal components. All principal components will fully cover the variability of the problem. The selection of a reduced number of principal components is a compromise between computational power (time to run models and number of simulations) and quality of the solution.\n\u2022\tInterpretation between global and local match indicators was being the preferable HM approach. Considering only global match indicators may lead to a very poor match in some of the wells.\nSome points to highlight concerning the real time HM method (article 4) are listed below:\n\u2022\tMeasurement errors and tolerance margins were included in the history matching process. It compares the simulation results against the history data and an acceptance range. The method allows a flexible model selection, avoiding restricted model selection based only on a fixed dataset.\n\u2022\tThe proposed workflow synchronizes the HM model evaluation with the history data acquisition, allowing model update and reparametrization as needed.\n\u2022\tA proper estimation of relative measurement errors and tolerance margin provides the quality of the expected solution. The high quality and amount of reservoir data are usually proportional to the quality of the solution.\n\u2022\tA new HM evaluation criteria was implemented and tested for both reservoir models. It is inside the probabilistic real time workflow, and works integrated with the reservoir uncertainty and model reparametrization stages. The evaluation provides a quality indicators and a HM tracker graph for each function and well, which establishes a rigorous quality tracking process over time.\n96\n7.\tFUTURE WORK\nThe following points are the subjects to extend the proposed methods described in this thesis.\n\u2022\tApplication of PCA uncertainty reduction method in a more complex reservoir with a large number of wells and objective functions.\n\u2022\tFor reservoir models where reservoir property distributions created through geostatistics techniques are used as uncertainty attributes, for instance, porosity or permeability, are used to represent geological uncertainty, a new algorithm might be required to include them as uncertain reservoir attributes.\n\u2022\tFor some reservoirs, different HM priorities might be targeted, such as water breakthrough, gas-oil ratio or BHP match. The use of different curve fitting and smoothing techniques allow different weights for each function and an improved attribute range selection focuses on HM priorities.\n\u2022\tPerform an integration between the proposed real-time workflow and optimization techniques. Optimization algorithm would search for the best attribute combinations using the reduced reservoir attributes from the real-time HM method.\n\u2022\tApply the real-time HM method for a real case and on an ongoing history matching process.\n98\nREFERENCE\nAchelis, Steven B., 1995. Technical Analysis from A to Z. Second printing, McGraw-Hill, pp. 184-192.\nAvansi, G. D.; Schiozer, D. J., \"A New Approach to History Matching Using Reservoir Characterization and Reservoir Simulation Integrated Studies\", OTC, 4-5 May, Houston, United States, 2015.\nAvansi, G.D., Schiozer, D.J., \u201cReference and Simulation Model UNISIM-I: Geological Modeling under Uncertainties and Reservoir Development Application\u201d accepted for publication to the International Journal of Modeling and Simulation for the Petroleum Industry, April 2014, Brazil.\nBennett, F. and Graf, T., 2002. Use of Geostatistical Modeling and Automatic History Matching to Estimate Production Forecast Uncertainty - A Case Study. SPE 74389, International Petroleum Conference and Exhibition, Mexico, 10-12 February.\nBertolini A., Schiozer D., 2011. Influence of the objective function in the history matching process. Journal of Petroleum Science and Engineering, May, Volume 78, Issue 1, July 2011, Pages 32-41.\nBertolini, A. C., Booth, R. J., Morton, K. L., Fitzpatrick, A. J., 2013. Design of Objective Function for Interference Well Testing. OTC-24513MS. Paper was presented at the Offshore Technology Conference Brasil held in Rio de Janeiro, Brazil, 29-31.\nBertolini A., Schiozer D., Maschio, C., 2015. A methodology to evaluate and reduce reservoir uncertainties using multivariate distribution. Journal of Petroleum Science and Engineering, Volume 128, April 2015, Pages 1-14.\nBertolini, A. C., Schiozer, D. J., 2015. Principal component analysis for reservoir uncertainty reduction. Journal of the Brazilian Society of Mechanical Sciences and Engineering, 1-11.\nBiran, A. and Breiner M., 2002. Matlab for Engineers. Prentise Hall.\nBissel, R. C., 1997. Combining Geostatistical Modeling with Gradient Information for History Matching: The Pilot Point Method. SPE 38730 Annual Technical Conference and Exhibition, San Antonio, Texas, U.S.A., 5-8 October.\nChen, W.H., Gavalas, G.R., Seinfeld, J.H., Wasserman, M.L., 1973. A new algorithm for automatic history matching. SPE 4545 presented at the SPE-AIME 48th Annual Fall Meeting, held in Las Vegas, 30 September.\nCraig, EE, et al., 1977. Optimized Recovery Through Continuing Interdisciplinary Cooperation,\" JPT (July 1977) 755.\nCullick, A.S., Johnson, D., Shi, G., 2006. Improved and more rapid history matching with a nonlinear proxy and global optimization. SPE 101933 prepared for presentation at the 2006 SPE Annual Technical Conference and Exhibition, held in San Antonio, 24-27 September.\nDadashpour, M., Rwechungura, R., 2011. Fast Reservoir Parameter Estimation by Using Effect of Principal Components Sensitivities and Discrete Cosine Transform, SPE 141913 was selected for presentation at the 2011 SPE Reservoir Simulation Symposium held in The Woodlands, Texas, USA.\nDean, S.O., Albert, C.R., Ning, L., 2008. Inverse theory for petroleum reservoir characterization and history matching. Cambridge University Press.\nDeutsch, C., 1989. Calculating Effective Absolute Permeability in Sandstone/Shale Sequences SPE Formation Evaluation, 4(3): 343 -348.\nEmerick, A. A. and Reynolds, A. C., 2012. Combining the Ensemble Kalman Filter With Markov Chain Monte Carlo for Improved History Matching and Uncertainty Characterization. SPE 141336-PA, SPE Reservoir Simulation Symposium held in The Woodlands, Texas, USA.\nEmerick, A. A. and Reynolds, A. C., 2012. Combining the Ensemble Kalman Filter With Markov Chain Monte Carlo for Improved History Matching and Uncertainty Characterization. SPE 141336-PA, SPE Reservoir Simulation Symposium held in The Woodlands, Texas, USA.\nFerreira, C., Vernon, I., Schiozer, D.J. and Goldstein, M., 2014. Use of Emulator Methodology for Uncertainty Reduction Quantification. SPE 169405-MS, Latin American and Caribbean Petroleum Engineering Conference held in Maracaibo, Venezuela, 21-23 May.\nGomez, S., Gosselin, O., Barker, J.W., 1999. Gradient-based history matching with a global optimization method. SPE 71307, revised for publication from paper 56756, first presented at the 1999 SPE Annual Technical Conference and Exhibition, held in Houston, 3-6 October.\nGuardado, L.R., Gamboa, L.A.P. and Lucchesi, C.F., 1989a. Petroleum Geology of the Campos Basin, Brazil, a Model for a Producing Atlantic Type Basin: PART 1. AAPG Special Volumes, A132: 33.\nGuardado, L.R., Gamboa, L.A.P. and Lucchesi, C.F., 1989b. Petroleum Geology of the Campos Basin, Brazil, a Model for a Producing Atlantic Type Basin: PART 2. AAPG Special Volumes, A132: 42.\nGuardado, L.R., Spadini, A.R., Brandao, J.S.L. and Mello, M.R., 2000. Petroleum System of the Campos Basin, Brazil. In: M.R.M.a Petroleum Systems if the South Atlantic Margins: AAPG Memoir 73, pp. 317-324.\nGu, Y. and Oliver, D.S., 2004. History Matching of the PUNQ-S3 Reservoir Model Using the Ensemble Kalman Filter.SPE 89942, Annual Technical Conference and Exhibition, Houston, Texas, U.S.A., 26-29 September.\nHajizadeh, Y., Amorin, E. P, Sousa, M. C., 2012. Building Trust in History Matching: The Role of Multidimensional Projection, SPE 152754 was selected for presentation at the EAGE Annual Conference &amp; Exhibition incorporating SPE Europec held in Copenhagen, Denmark.\nJolliffe, I., 1986, Principal Component Analysis: Springer-Verlag Inc.\nLiu, C., McVay, D. A., 2010. Continuous Reservoir-Simulation-Model Updating and Forecasting Improves Uncertainty Quantification. SPE 119197.\nManceau, E., Mezghani, I., Zabalza-Mezghani, I., Roggero, F., 2001. Combination of Experimental Design and Joint Modeling Methods for Quantifying the Risk Associated with\nMaschio, C., Schiozer, D., 2003. A new upscaling technique based on Dykstra-Parsons coefficient: evaluation with streamline reservoir simulation. Journal of Petroleum Science and Engineering 40, 27- 36.\nMaschio, C., Schiozer, D.J., 2005. Development and application of methodology for assisted history matching. SPE 94882 presented at the SPE Latin-American and Caribbean Petroleum Engineering Conference, Rio de Janeiro, Brazil, 20-23 June.\nMaschio, C., Schiozer, D., Moura Filho, M.A.B., 2005. Methodology to Quantify the Impact of Uncertainties in the History Matching Process and in the Production Forecast. SPE 96613 prepared for presentation at the SPE Annual Technical Conference and Exhibition, Dallas, Texas, U.S.A.\nMaschio, C.; Schiozer, D.J, \"A New Methodology for Assisted History Matching Using Independent Objective Functions\", Petroleum Science and Technology, pp. 1047-1062, v. 26, 2008.\nMaschio, C., Schiozer, D. J., de Moura Filho, M. A. B., &amp; Becerra, G. G. (2009, February 1). A Methodology To Reduce Uncertainty Constrained to Observed Data. Society of Petroleum Engineers. doi:10.2118/111030-PA\nMaschio, C., Schiozer, D., 2013. A new procedure to reduce uncertainties in reservoir models using statistical inference and observed data. Journal of Petroleum Science and Engineering, Volume 110, October 2013, Pages 7-21.\nMeneses, S.X.d. and Adams, T., 1990. Ocorr\u00eancias de resistividades an\u00f4malas no Campo de Namorado, Bacia de Campos., Rio de Janeiro, Brasil.\nOliver, D. S., Reynolds A. C., Liu N., 2008. Inverse Theory for Petroleum Reservoir Characterization and History Matching. Cambridge University Press.\nRisso, F. V. A., Risso, V. F., Schiozer, D. J., 2011. Risk Analysis of Petroleum Fields using Latin Hypercube, Monte Carol and Derivative Tree Techniques. Journal of Petroleum and Gas Exploration Research Vol. 1(1) pp. 014-021, September.\nRwechungura, R., Dadashpour, M., Kleppe, J., 2011. Advanced History Matching Technique Reviewed, SPE 142497 was selected for presentation at the SPE Middle East Oil and Gas Show and Conference held in Manama, Bahrain.\nSarma, P., Durlofsky, L. J., Aziz, K., Chen, W. H., 2007. A New Approach to Automatic History Matching Using Kernel PCA, SPE 106176 was selected for presentation at the 2007 SPE Reservoir Simulation Symposium held in Houston, Texas, U.S.A.\nSchaaf, T., Coureaud, B., Labat, N., 2008. Using experimental designs, assisted history matching tools and Bayesian frame work to get Probabilistic production forecasts. In: Proceedings of the SPE Europec/EAGE Annual Conference and Exhibition, 9-12June. SPE113498. Rome, Italy.\nSlotte, P.A., Sm0rgrav, E., 2008. Response surface methodology approach for history matching and uncertainty assessment of reservoir simulation models. In: Proceedings of the Europec/EAGE Annual Conference and Exhibition, 9-12 June. SPE113390. Rome, Italy.\nThakur, G.C., 1996. What is Reservoir Management? Journal of Petroleum Technology, Volume 48, Number 6, June. SPE 26289-MS.\nThomas, L.K., Hellums, L.J., Reheis, G.M., 1971. A nonlinear automatic history matching technique for reservoir simulation models. SPE 3475 presented at the SPE 46th Annual Fall Meeting, held in New Orleans, 3-6 October.\nVanderplaats, G.N., 1984. Numerical optimization techniques for engineering design: with applications. Mcgraw-Hill, New York.\nVenkataraman, P., 2001. Applied optimization with Matlab programming. Wiley-Interscience.\nWatson, A.T., Lee, W.J., 1986. A new algorithm for automatic history matching production data. SPE 15228 prepared for presentation at the Unconventional Gas Technology Symposium of the SPE, held in Louisville, 18-21 May.\nZhou, W., Gupta, S., Banerjee, R., Poe, B., Spath, J., and Thambynayagam, M., 2013. Production Forecasting and Analysis for Unconventional Resources. Paper IPTC 17178-MS presented at the International Petroleum Technology Conference, Beijing, China, 26-28 March.\nTavassoli, Z., Carter, J. N., King, P. R., 2004. Errors in History Matching. SPE 86883-PA"}]}}}