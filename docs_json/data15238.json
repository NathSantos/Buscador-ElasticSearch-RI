{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.19226"}, {"@name": "filename", "#text": "26355_2014_AnaCarolinaCardosodeSousa.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "DISSERTATION\n\nSensors in Modular Robotics for Pipeline Inspection:\nDesign and Test of Erekobot-? Module\n\nAna Carolina Cardoso de Sousa\n\nBras\u00edlia\nNovember, 2014\n\nUNIVERSIDADE DE BRAS\u00cdLIA\n\nFACULDADE DE TECNOLOGIA\n\n\n\nUNIVERSIDADE DE BRASILIA\nFaculdade de Tecnologia\n\nDISSERTATION\n\nSensors in Modular Robotics for Pipeline Inspection:\nDesign and Test of Erekobot-? Module\n\nAna Carolina Cardoso de Sousa\n\nReport submitted to the Department of Mechanical\n\nEngineering as a partial requirement for obtaining\n\nthe title of Master in Mechatronic Systems\n\nExamination board\n\nCarla Maria Chagas e Cavalcante Koike, CIC/UnB\nAdvisor\n\nCarlos Humberto Llanos Quintero, ENM/UnB\nChair member\n\nRenato Alves Borges , ENE/UnB\nChair member\n\n\n\nTo\n\nMy family.\n\nAna Carolina Cardoso de Sousa\n\n\n\nAcknowledgments\n\nHere, I am using the opportunity to express my gratitude to everyone who supported me\nthroughout these years. I am thankful for their aspiring guidance, constructive criticism\nand friendly advices during my project, not only in the academic sense, but also in a\npersonal sense. I am sincerely grateful to them for sharing their truthful and illuminating\nviews on a number of issues related to the project.\nI express my warm thanks to my academic advisors Dr. Carla Koike and Dr. Dianne\nMagalh\u00e3es for their expertise, understanding, and patience in the Ereko Group, they\nprovided me with the required facilities and conductive condictions for my dissertation\nproject. I appreciate their vast knowledge and skill in many areas (e.g., robotics, computer\nscience, electronics, mechanics, interaction with participants and contributors), and their\nassistance in writing reports (i.e., proceedings articles and this dissertation). I also want\nto express my gratitude to all participants of the Ereko Group, especially Ricardo, whose\nvolunteer work was fundamental for this project. I would also like to thank the other\nmembers of the chair, Dr. Carlos Humberto Llanos Quintero and Dr. Renato Alves\nBorges for the careful evaluation of my project.\nI must also acknowledge the Brazilian institutions: Ag\u00eancia Nacional do Petr\u00f3leo, G\u00e1s\nNatural e Biocombust\u00edveis (ANP), Financiadora de Estudos e Projetos (FINEP), Min-\nist\u00e9rio da Ci\u00eancia e Tecnologia (MCT), and Petr\u00f3leo Brasileiro S.A. (Petrobras) for\nfinancial support in the program PRH-PB 223, especially in the present study. I would\nalso like to thank the coordinator of the program Dr. Eug\u00eanio Liborio Feitosa Fortaleza\nfor providing me support and knowledge. I also express my eternal gratitude to the Uni-\nversity of Brasilia (UnB) and the Department of Mechanical Engineer (ENM); I will\nalways consider these places home.\nFinally, I would also like to thank my parents for the support they provided me though my\nentire life, specially my time in UnB. Their constant love and support were fundamental\nin order to finish this dissertation, I love you guys. I must acknowledge my best friend\nand love, Patricia, without whose love, encouragement and editing assistance (mainly\nspoken words, not only written), I would not have finished this dissertation. Trust me,\nyou have made me a better person. I would also like to thank Ethel, Aline, Thais, Natalia,\nErich, Camila, Carlos, Danusa, Murilo, Dan, Higor, Lores and Ju (do not hate me if I\nam forgetting someone, please!). For you guys that are always there, I yell \u201dthank you\u201d!\n\nAna Carolina Cardoso de Sousa\n\n\n\nABSTRACT\n\nPipelines still are the most efficient, safe, ecological and economical environmental to transport\ncrude oil over long distances. However, the transported oil and the environment in which the\npipeline is located may corrode the metal to the point of failure, affecting not only production but\nalso the environment. In addition, activities such as inspection and maintenance are more complex\ndue to difficult access \u2013 exposure to toxins, a wide variety of terrains and the special cloths are\njust some of the challenges. Therefore, pipelines require processes recurrent and autonomous,\nwhich motivates the development of new technologies: the machinery of inspection should be\ncheap, robust and versatile for maintenance, cleaning, removal of fluids, product separation and\ninspection. The reconfigurable modular robots are autonomous machines with variable morphology\nand, with the reorganization of the connectivity of parts (called modules), this architecture offers a\ngreater degree of flexibility and fault tolerance at a lower cost. Because of its low cost, robustness\nand versatility reconfigurable modular robots can perform inspection tasks and reduce production\ncosts in the Oil and Oil Industry. The objective of this work is to design, build and test a module\nof a reconfigurable modular robot with sensors for inspection in pipelines, called ErekoBot. Each\nmodule must have the ability to estimate its own pose, detect an obstacle and align yourself with\na plan (simulating a pipe). In this work, the most suitable sensors for ErekoBot were chosen: four\ninfrared sensors and an inertial measurement unit. After the definition of the sensors, the complete\nmodule was designed and its prototype was built, considering shape, size, weight, electronic circuit,\nposition of components and material. Tests with the prototype has shown that the module is\ncapable of (1) to estimate its own orientation, (2) detecting the presence of obstacles and (3) align\nwith a plane. These abilities are sufficient to allow a situation where the robot must move moved\nthrough a pipeline, avoid obstacles and stop at a specific position to perform an inspection inside\nthe tube.\n\nRESUMO\n\nOleodutos ainda s\u00e3o os meios mais eficientes, seguros, ecol\u00f3gicos e econ\u00f4micos para transportar\npetr\u00f3leo bruto a longas dist\u00e2ncias. Por\u00e9m, o petr\u00f3leo transportado e o meio em que o oleoduto se\nencontra podem corroer o metal a ponto de surgir falhas, afetando n\u00e3o s\u00f3 a produ\u00e7\u00e3o, mas tamb\u00e9m\no meio ambiente. Al\u00e9m disso, atividades como inspe\u00e7\u00e3o e manuten\u00e7\u00e3o s\u00e3o dificultadas devido ao\ndif\u00edcil acesso para operadores \u2013 exposi\u00e7\u00f5es a toxinas, uma grande variedade de terrenos e a uti-\nliza\u00e7\u00e3o de roupas espec\u00edficas s\u00e3o apenas alguns dos desafios. Portanto, oleodutos requerem ainda\nmais processos recorrentes e aut\u00f4nomos, o que motiva o desenvolvimento de novas tecnologias: o\nmaquin\u00e1rio de inspe\u00e7\u00e3o deve ser barato, robusto e vers\u00e1til para tarefas de manuten\u00e7\u00e3o, limpeza,\nremo\u00e7\u00e3o de l\u00edquidos, separa\u00e7\u00e3o de produtos e inspe\u00e7\u00e3o. Os rob\u00f4s modulares reconfigur\u00e1veis s\u00e3o\n\n\n\nm\u00e1quinas aut\u00f4nomas com morfologia vari\u00e1vel e, com a reorganiza\u00e7\u00e3o das conectividades de suas\npartes (chamados m\u00f3dulos), essa arquitetura oferece um maior grau de flexibilidade e toler\u00e2ncia a\nfalhas por um custo menor. Por serem baratos, robustos e vers\u00e1teis, os rob\u00f4s modulares reconfig-\nur\u00e1veis podem realizar tarefas de inspe\u00e7\u00e3o e reduzir custos de produ\u00e7\u00e3o na Ind\u00fastria do Petr\u00f3leo\ne \u00d3leo. O objetivo deste trabalho \u00e9 projetar, construir e testar um m\u00f3dulo de um rob\u00f4 modular\nreconfigur\u00e1vel com sensores para inspe\u00e7\u00e3o em tubula\u00e7\u00f5es, chamado ErekoBot. Cada m\u00f3dulo deve\nter a capacidade de estimar sua pr\u00f3pria pose, detectar um obst\u00e1culo e alinhar-se com um plano\n(simulando uma tubula\u00e7\u00e3o). Neste trabalho foram escolhidos os sensores mais adequados para o\nErekoBot: quatro sensores infravermelhos e uma unidade de medi\u00e7\u00e3o inercial. Depois da defini\u00e7\u00e3o\ndos sensores, o m\u00f3dulo completo foi projetado e seu prot\u00f3tipo constru\u00eddo, considerando forma,\ntamanho, peso, circuito eletr\u00f4nico, posi\u00e7\u00e3o dos componentes e material. Os testes com o prot\u00f3tipo\nmostraram que esse m\u00f3dulo \u00e9 capaz de (1) estimar sua pr\u00f3pria orienta\u00e7\u00e3o, (2) detectar a presen\u00e7a\nde obst\u00e1culos e (3) alinhar-se com um plano. Essas habilidades s\u00e3o suficientes para simular uma\nsitua\u00e7\u00e3o em que o rob\u00f4 deve se locomover por uma tubula\u00e7\u00e3o, desviar de obst\u00e1culos e parar em\numa posi\u00e7\u00e3o espec\u00edfica para realizar uma inspe\u00e7\u00e3o no interior do tubo.\n\n\n\nTable of Contents\n\nSensores em Rob\u00f3tica Modular para Inspe\u00e7\u00e3o em Tubula\u00e7\u00f5es: Projeto\ne Testes do M\u00f3dulo Erekobot ? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiv\n\n1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1 Presentation ............................................................................ 1\n1.2 Aims ........................................................................................ 2\n1.3 Structure of the Document....................................................... 3\n\n2 Brief Review of Pipeline Inspection, SRM Robots and Instrumenta-\ntion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2.1 Pipeline Inspection.................................................................... 4\n2.1.1 Classification of Pipeline Robots ............................................... 5\n2.2 Self-Reconfigurable Modular Robots......................................... 6\n2.2.1 Taxonomy ................................................................................ 7\n2.2.2 Brief History of SRM Robotics .................................................. 8\n2.2.3 Recent SRM Robots .................................................................. 8\n2.2.4 ErekoBot ................................................................................ 13\n2.3 General Measurement System in SRM Systems ............................. 13\n2.3.1 Systematic Characteristics........................................................ 14\n2.3.2 Rotation Motion sensors ........................................................... 15\n2.3.3 Translational Displacement Sensors ........................................... 20\n2.3.4 Filters..................................................................................... 20\n2.4 Orientation: Euler Angles......................................................... 24\n2.4.1 Euler angles ............................................................................ 24\n2.5 Summary .................................................................................. 25\n\n3 Conceptual Design and Modelling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n3.1 Introduction ............................................................................ 27\n3.2 Conceptual Design of ErekoBot ? ................................................ 27\n3.3 Instrumentation Model.............................................................. 29\n3.3.1 Attitude Estimation .................................................................. 30\n3.3.2 Distance Estimation .................................................................. 34\n3.4 Alignment Algorithm ................................................................ 35\n\niii\n\n\n\n3.5 Conclusions ............................................................................. 35\n\n4 Module Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n4.1 Introduction ............................................................................ 37\n4.2 Sensors Selection ..................................................................... 37\n4.3 Eletronic Design ...................................................................... 39\n4.3.1 Microcontroller ...................................................................... 39\n4.3.2 Communication ......................................................................... 40\n4.3.3 Electronic Devices ................................................................... 40\n4.3.4 Power Supply ........................................................................... 41\n4.4 Mechanical Design .................................................................... 41\n4.4.1 Intermodular Connection .......................................................... 41\n4.4.2 Servo Motor ............................................................................ 42\n4.4.3 Geometric Description and Materials ......................................... 42\n4.4.4 Weight Analysis ....................................................................... 43\n4.5 Module Analysis ....................................................................... 44\n4.5.1 Actual and estimated weights .................................................... 44\n4.5.2 Comparison between ErekoBot ? and other modular robots ............. 45\n4.6 Conclusions ............................................................................. 48\n\n5 Experiments and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n5.1 Orientation Experiment ............................................................. 49\n5.1.1 Experimental Method................................................................ 50\n5.1.2 Results .................................................................................... 51\n5.2 Distance Experiment ................................................................. 53\n5.2.1 Experimental Method................................................................ 53\n5.2.2 Results .................................................................................... 54\n5.3 Alignment Experiment............................................................... 56\n5.3.1 Experimental Method................................................................ 56\n5.3.2 Alignment Results .................................................................... 56\n5.4 Conclusions ............................................................................. 60\n\n6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n6.1 Main Contributions................................................................... 63\n6.2 Future Lines of Investigation .................................................... 64\n6.3 Publications ............................................................................. 65\n\nBibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n\nAppendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n\nI Demonstrations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\nI.1 Six possible rotation matrix ....................................................... 72\n\n\n\nII Libraries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\nII.1 Codes ...................................................................................... 74\nII.1.1 servo.h .................................................................................... 75\nII.1.2 leds.h ...................................................................................... 75\nII.1.3 USART.h .................................................................................. 76\nII.1.4 adc.h ....................................................................................... 79\nII.1.5 SHARP-0A41SKF36.h.................................................................. 80\nII.1.6 i2c.h ........................................................................................ 81\nII.1.7 ADXL-345.h .............................................................................. 84\nII.1.8 ITG-3200.h................................................................................ 87\n\nIII Electronic Circuit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91\n\nIV ErekoBot ? plans. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n\nV Overview of the Attached Disk . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\nV.1 ATMega8 Files ......................................................................... 105\nV.2 Eagle Files .............................................................................. 105\nV.3 Matlab Files ............................................................................ 105\nV.4 Media ...................................................................................... 105\nV.5 Report Files............................................................................. 105\nV.6 SolidWorks Files ...................................................................... 106\n\n\n\nList of Figures\n\n2.1 Classification of pipeline robots (Figures from (ARCHILA; BECKER, 2013)): (a)\nPIG. (b) Wheel. (c) Caterpillar. (d) Wall-press. (e) Walking. (f) Inchworm. (g)\nScrew. (h) Snake. (i) Variable Velocity PIG...................................................... 5\n\n2.2 Examples of Pipeline Robots. ........................................................................ 6\n2.3 Types of SRM robots (Figure from (MURATA; KUROKAWA, 2007)).................... 7\n2.4 Examples of Pipeline Robots. ........................................................................ 9\n2.5 SMORES (DAVEY; KWOK; YIM, 2012). ........................................................ 9\n2.6 UBot (CUI et al., 2012; WANG; ZHU; ZHAO, 2013; ZHU et al., 2013)................... 10\n2.7 UBot target (ZHU et al., 2013). ..................................................................... 10\n2.8 CoSMO (LIEDKE et al., 2013). ..................................................................... 11\n2.9 Roombots (MOECKEL et al., 2013; BONARDI et al., 2013; VESPIGNANI et al.,\n\n2013; SPR\u00f6WITZ et al., 2014). ...................................................................... 12\n2.10 Transmote (QIAO et al., 2012b; QIAO et al., 2012a). ......................................... 13\n2.11 ErekoBot ?v.2 . .......................................................................................... 13\n2.12 Accelerometer mass-spring-damper model......................................................... 16\n2.13 Gyroscope (Figure from (JENSEN, 2011)). n is a normal force acting upwards at\n\nthe pivot O; mg is a downward gravitational force that produces a torque ? related\nto the angular momentum M......................................................................... 18\n\n2.14 Vector diagram for a gyroscope. ..................................................................... 18\n2.15 Mechanical Gyroscope. ................................................................................. 19\n2.16 Optical Gyroscope (Figures from (MORRIS, 2001))............................................ 20\n2.17 Range Sensors (Figures from (MORRIS, 2001)). ................................................ 21\n2.18 Outputs from filters (Figures from (MORRIS, 2001)).......................................... 22\n2.19 Signals from a complementary filter (Figure from (GLASSER, )). ......................... 23\n2.20 A basic complementary filter (Figure from (HIGGINS, 1975)). ............................. 23\n2.21 Alternative complementary filter block diagram (Figure from (HIGGINS, 1975))...... 23\n2.22 Complementary filter estimating vertical velocity (Figure from (HIGGINS, 1975)). ... 24\n2.23 Rotation in 2D (Figure from (USTA, 1999)). .................................................... 24\n\n3.1 Wired model of the module. .......................................................................... 28\n3.2 ErekoBot ? example of application.................................................................. 28\n3.3 ErekoBot ? requirements............................................................................... 29\n3.4 ErekoBot ? 3D model................................................................................... 29\n3.5 Frames with positive axes and torques. ............................................................ 30\n\nvi\n\n\n\n3.6 Block diagram of the attitude estimator (Figure adapted from (MAGNUSSEN;\nOTTESTAD; HOVLAND, 2013)). .................................................................. 34\n\n3.7 Sensor output depending on object attitude (Figure adapted from (YE et al., 2013)). 35\n\n4.1 Flow chart for the ErekoBot ? design (Blue: Electronic Design; Green: Mechanical\nDesign.). ................................................................................................... 38\n\n4.2 ErekoBot ? sensors. ..................................................................................... 39\n4.3 Control and communication devices. ............................................................... 40\n4.4 Xbee configuration. ..................................................................................... 41\n4.5 Hitec HS-85BB. .......................................................................................... 42\n4.6 ErekoBot ? mechanic pieces........................................................................... 42\n4.7 Possible connections between two modules........................................................ 43\n4.8 Free Body Diagram...................................................................................... 44\n4.9 Estimated ErekoBot ? (drawn in SolidWorks R\u00a9 ). ............................................... 45\n4.10 Actual ErekoBot ? ...................................................................................... 46\n\n5.1 Different types of connections in modular robots a) Pitch-pitch. b) Yaw-yaw. c)\nPitch-yaw. ................................................................................................. 50\n\n5.2 Positions of ErekoBot ? for the orientation experiment........................................ 50\n5.3 Pitch angle estimations of position 0? without a filter. ........................................ 51\n5.4 Pitch angle estimations of position 0? filtered with Perr = 0.9, Perr = 0.7, Perr = 0.5,\n\nPerr = 0.3 and Perr = 0.1. ............................................................................. 52\n5.5 Pitch angle estimations of positions ?45? to 45? without a filter. .......................... 52\n5.6 Pitch angle estimations of positions ?45? to 45? filtered with Perr = 0.9, Perr = 0.7,\n\nPerr = 0.5, Perr = 0.3 and Perr = 0.1. .............................................................. 53\n5.7 Preparation for the distance experiment. The IR Sensor measures the voltage in\n\ndifferent distances for calibration. ................................................................... 54\n5.8 IR sensor voltage outputs points (blue markers) and curve formed from the average\n\nvalues (red line). ......................................................................................... 55\n5.9 IR sensor voltage outputs and power fit from Equation (5.2.2) curves..................... 55\n5.10 Alignment results for position 15?................................................................... 57\n5.11 Alignment results for position ?25?. ............................................................... 58\n5.12 Alignment results for position ?40?. ............................................................... 59\n5.13 Alignment results with a white sheet of paper plane (white)................................. 60\n5.14 Alignment results with a card paper plane (gray)............................................... 61\n5.15 Alignment results with a black sheet of paper plane (black). ................................ 61\n\nII.1 Libraries architecture. .................................................................................. 74\n\nIII.1 Base Circuit Schematic................................................................................. 91\nIII.2 Lateral Circuit Schematic.............................................................................. 92\nIII.3 Colored Base Circuit Board. .......................................................................... 93\nIII.4 Black and White Base Circuit Board. .............................................................. 94\n\n\n\nIII.5 Colored Lateral Circuit Board........................................................................ 95\nIII.6 Black and White Lateral Circuit Board............................................................ 96\n\nIV.1 Base Plan. ................................................................................................. 98\nIV.2 Motor Holder Plan. ..................................................................................... 99\nIV.3 Rod Plan...................................................................................................100\nIV.4 Cover Plan.................................................................................................101\nIV.5 Base Blends. ..............................................................................................102\nIV.6 Motor Holder Blends....................................................................................103\nIV.7 Rod Blends. ...............................................................................................104\n\n\n\nList of Tables\n\n3.1 Basic requirements for ErekoBot ? design......................................................... 29\n\n4.1 Estimated and measured weights. ................................................................... 44\n4.2 Comparison between ErekoBot ? and other SRM modules. .................................. 47\n\nix\n\n\n\nList of Symbols\n\nNomenclature\n\nO A signal output,\n\nI A signal input,\n\nOMIN, OMAX Minimum and maximum values of O,\n\nIMIN, IMAX Minimum and maximum values of I,\n\nOM Environmental output,\n\nIM Environmental input,\n\nm Mass,\n\nk Constant stiffness of a spring,\n\nb Damping factor,\n\nFexternal External force,\n\nFinertial Inertial force,\n\nFdamping Damping force,\n\nFspring Spring force,\n\nt Time,\n\na(t) Acceleration at time t,\n\nx(t) Distance at time t,\n\n?r Resonant frequency,\n\n? Damping ratio,\n\nn Normal force,\n\n? Torque,\n\nx\n\n\n\ng Gravitational force,\n\nh Distance,\n\nM Angular momentum,\n\nMi,Mf Initial and final angular momentum,\n\n? Angle,\n\n?p Procession motion velocity,\n\nH(s),G(s),X(s),A(s) Transfer functions,\n\nf Frequency,\n\nI Identity matrix,\n\nz? Estimated value of z,\n\nn1,n2 Noise,\n\nRx(?) Rotation matrix of x axis by angle ?,\n\nRy(?) Rotation matrix of x axis by angle ?,\n\nRz(?) Rotation matrix of z axis by angle ?,\n\nH Hamilton domain,\n\nR3 Three-dimensional vector space,\n\nq Quaternion,\n\ni,j,k Imaginary units,\n\nq? Conjugation of q,\n\nqv Vector part of q,\n\nqr Real part of q,\n\nu Unit quaternion,\n\nv Vector in R3,\n\n? Angular velocity,\n\nL Length,\n\n? Bending angle,\n\nqg,qa Quaternions from the gyroscope and the accelerometer,\n\nTs Sample rate time,\n\n\n\nPerr Scaling factor,\n\not Orientation vector from accelerometer and gyroscope at time t,\n\ndt Distance vector from IR sensors at time t,\n\n\u00b5s Coefficient of friction,\n\nV Output voltage,\n\nAbreviations\n\n2D Two dimensional,\n\n3D Three dimensional,\n\nAC Alternating Current,\n\nADC Analog-to-digital converter,\n\nCPU Central Processing Unit,\n\nDAC Digital-to-analog converter,\n\nDC Direct Current,\n\nDoF Degrees of Freedom,\n\nFPU Foating-point unit,\n\nI2C Inter-Integrated Circuit,\n\nI/O Input and Output,\n\nIMU Inertial Measurement Unit,\n\nIR Infrared,\n\nLED Light Emissor Diode,\n\nLiPo Lithium Polymer,\n\nLSB Least Significant Bit,\n\nMEMS Micro Eletromechanical Systems technology,\n\nPCB Printed Circuit Board,\n\nPID Proportional Integral Derivative controller,\n\nPIG Pipeline Inspection Gauge,\n\nPWM Pulse Width Modulation,\n\n\n\nRF Radio Frequency,\n\nSMD Surface-mount device,\n\nSRM Self Reconfigurable Modular,\n\nUSART Universal Synchronous Asynchronous Receiver Transmitter\n\n\n\nSensores em Rob\u00f3tica Modular para\nInspe\u00e7\u00e3o em Tubula\u00e7\u00f5es: Projeto e\nTestes do M\u00f3dulo ErekoBot ?\n\nCap\u00edtulo 1: Introdu\u00e7\u00e3o\n\nApresenta\u00e7\u00e3o\n\nEste trabalho trata de rob\u00f4s modulares reconfigur\u00e1veis com foco espec\u00edfico no estudo da in-\nstrumenta\u00e7\u00e3o para simples tarefas em inspe\u00e7\u00e3o em tubula\u00e7\u00f5es. O principal problema enfrentado \u00e9\ncomo projetar e construir um m\u00f3dulo de um rob\u00f4 modular reconfigur\u00e1vel capaz de se alinhar com\nas paredes internas de uma tubula\u00e7\u00e3o.\n\nH\u00e1 desafios nas decis\u00f5es para o projeto de rob\u00f4s, incluindo qual tipo de sensor utilizar. A\nInstrumenta\u00e7\u00e3o \u00e9 a ci\u00eancia das medi\u00e7\u00f5es e do controle de vari\u00e1veis de processo; suas t\u00e9cnicas s\u00e3o\nessenciais em todos os ramos da tecnologia e ci\u00eancia nos dias de hoje (BENTLEY, 2005). Como\nt\u00e9cnicas de produ\u00e7\u00e3o modernas determinam limites cada vez menores de precis\u00e3o com menores\ncustos, h\u00e1 um crescimento nos esfor\u00e7os de pesquisa e desenvolvimento de instrumentos para medir,\nregistrar e controlar as vari\u00e1veis do processo.\n\nAl\u00e9m da instrumenta\u00e7\u00e3o, outro importante desafio em desenvolvimento de rob\u00f4s reside em\nfornecer versatilidade: capacidade de um rob\u00f4 em executar uma variedade de tarefas em diferentes\nterrenos. Esse tema \u00e9 de especial relev\u00e2ncia quando o ambiente \u00e9 desconhecido \u2013 como em ex-\nplora\u00e7\u00f5es, opera\u00e7\u00f5es de resgate e inspe\u00e7\u00e3o em ambientes de risco. O ambiente das tubula\u00e7\u00f5es na\nInd\u00fastria do Petr\u00f3leo e o G\u00e1s se encaixa nessa situa\u00e7\u00e3o: \u00e9 um ambiente industrial perigoso com\numa variedade de tarefas em diferentes terrenos. A inspe\u00e7\u00e3o em tubula\u00e7\u00f5es necessita de sistemas e\nprocessos aut\u00f4nomos recorrentes, motivando novas tecnologias, assim como a de rob\u00f4s modulares\nreconfigur\u00e1veis.\n\nA abordagem tradicional de rob\u00f4s \u00e9 primeiro estudar as caracter\u00edsticas do terreno e, em seguida,\ncriar a estrutura mais adequada do rob\u00f4 para essa situa\u00e7\u00e3o espec\u00edfica. Nessa abordagem, uma\nescolha de projeto ruim ou a desvaloriza\u00e7\u00e3o de algumas vari\u00e1veis do ambiente resultam em refor-\nmula\u00e7\u00f5es do rob\u00f4.\n\nxiv\n\n\n\nEm 1994, Mark Yim, em sua tese de doutorado (YIM, 1994), prop\u00f4s empregar m\u00f3dulos simples\nconectados um ao outro para criar diferentes configura\u00e7\u00f5es no mesmo rob\u00f4. Assim, os rob\u00f4s\npoderiam mudar sua forma, o que lhes permitiria se locomover em diferentes terrenos. Nessa nova\nproposta, \u00e9 poss\u00edvel criar diferentes configura\u00e7\u00f5es com m\u00f3dulos b\u00e1sicos.\n\nEmbora essa abordagem possa parecer motivadora, \u00e9 importante ressaltar que um rob\u00f4 con-\nvencionalmente projetado para uma determinada tarefa ser\u00e1 sempre a realizar\u00e1 melhor do que\num sistema modular reconfigur\u00e1vel. Rob\u00f4s modulares reconfigur\u00e1veis s\u00e3o uma alternativa para\nsistemas em que os rob\u00f4s convencionais n\u00e3o atendem aos requisitos do ambiente. A robustez e\nversatilidade dos rob\u00f4s modulares os tornam sistemas redundantes, o que pode cruzar a linha entre\nconvencional e modular. As complexidades mec\u00e2nicos e computacionais aumentam substancial-\nmente com a modularidade do sistema, como seria de se esperar.\n\nNo entanto, um rob\u00f4 modular reconfigur\u00e1vel com sensores \u00e9 capaz de interagir com o mundo,\nadaptarem \u00e0s altera\u00e7\u00f5es do ambiente. Este tipo de rob\u00f4 pode: (1) diminuir o custo de fabrica\u00e7\u00e3o e\nde manuten\u00e7\u00e3o, (2) aumentar o n\u00famero de aplica\u00e7\u00f5es em compara\u00e7\u00e3o com os rob\u00f4s convencionais\ne (3) aumentar a robustez do sistema.\n\nObjetivos\n\nO principal objetivo deste trabalho \u00e9 projetar, construir e testar um rob\u00f4 modular reconfigur\u00e1vel\ncom sensores. \u00c9 desej\u00e1vel que este rob\u00f4 reagir a altera\u00e7\u00f5es ambientais a partir de sensores de\nresposta.\n\nA miss\u00e3o do rob\u00f4 \u00e9 inspecionar Gathering Lines de tubula\u00e7\u00f5es que geralmente t\u00eam as seguintes\ncaracter\u00edsticas:\n\n\u2022 Eles s\u00e3o usados para o transporte de petr\u00f3leo bruto ou de g\u00e1s natural da cabe\u00e7a do po\u00e7o\npara um ponto de coleta central;\n\n\u2022 Eles t\u00eam tamanho pequeno di\u00e2metro: entre 101, 6 mm to 304, 8 mm;\n\n\u2022 Eles trabalham em baixa press\u00e3o e fluxo.\n\nH\u00e1 muitas maneiras de construir este m\u00f3dulo dependendo do or\u00e7amento, materiais, tamanho,\npeso e forma. O m\u00f3dulo aqui projetado \u00e9 baseado em rob\u00f4s anteriores desenvolvidos na Universi-\ndade de Bras\u00edlia. Os objetivos concretos est\u00e3o listados abaixo, cada um ligado a uma pergunta:\n\n1. Descobrir os tipos de sensores comumente empregado em rob\u00f3tica m\u00f3dulos de rob\u00f4s modu-\nlares recentes (Que tipo de sensores s\u00e3o mais comuns em m\u00f3dulos recentes?).\n\n2. Determinar as tarefas b\u00e1sicas que o m\u00f3dulo proposto deve executar (Que tipo de requisitos\no m\u00f3dulo possui?)\n\n3. Analisar que tipo de sensores est\u00e3o dispon\u00edveis no mercado (Que tipo de sensores v\u00e3o ser\nusados neste m\u00f3dulo?)\n\n\n\n4. Depois da escolha dos sensores, ainda \u00e9 necess\u00e1rio projetar o m\u00f3dulo completo (Qual a forma,\ntamanho, peso, circuitos e materiais do m\u00f3dulo?)\n\n5. Fabrica\u00e7\u00e3o todo o m\u00f3dulo e testar se os sensores atendem aos requisitos (Os sensores escol-\nhidos s\u00e3o suficientes para as nossas necessidades?)\n\nAlguns aspectos relevantes de rob\u00f4s modulares reconfigur\u00e1veis n\u00e3o fazem parte deste trabalho:\n\n1. Locomo\u00e7\u00e3o do m\u00f3dulo, porque para analisar a instrumenta\u00e7\u00e3o n\u00e3o \u00e9 necess\u00e1rio analisar a\nlocomo\u00e7\u00e3o dos m\u00f3dulos.\n\n2. Conex\u00f5es entre os m\u00f3dulos, uma simples conex\u00e3o \u00e9 empregada apenas para garantir que os\nm\u00f3dulos sejam manualmente reconfigur\u00e1vel.\n\n3. Programa\u00e7\u00e3o distribu\u00edda de alto, uma vez que estes m\u00f3dulos n\u00e3o est\u00e3o nesse n\u00edvel de pro-\ngrama\u00e7\u00e3o ainda.\n\nEstrutura do Documento\n\nO primeiro cap\u00edtulo contextualizou a disserta\u00e7\u00e3o e os objetivos do trabalho. No segundo cap\u00ed-\ntulo, o embasamento te\u00f3rico necess\u00e1rio para a plena compreens\u00e3o do trabalho desenvolvido \u00e9\ndescrito. O terceiro cap\u00edtulo apresenta os modelos e conceitos para o m\u00f3dulo e a instrumenta\u00e7\u00e3o.\n\nO Cap\u00edtulo 4 combina o conhecimento apresentado nos cap\u00edtulos anteriores para apresentar\no projeto do rob\u00f4 proposto. No quinto cap\u00edtulo, as experi\u00eancias mais relevantes s\u00e3o descritas e,\nfinalmente, o sexto cap\u00edtulo apresenta algumas futuras linhas de investiga\u00e7\u00e3o.\n\nCap\u00edtulo 2: Breve Revis\u00e3o de Inspe\u00e7\u00e3o em Tubula\u00e7\u00f5es, Rob\u00f4s Mod-\nulares Auto-reconfigur\u00e1veis e Instrumenta\u00e7\u00e3o\n\nEsse cap\u00edtulo familiariza o leitor com o backgroud do trabalho. Devido ao fato do trabalho se\nestende em mais de um campo, s\u00e3o apresentadas as principais quest\u00f5es subjacentes a este projeto:\n(1) principais descobertas sobre os temas de pesquisa, por quem e quando, (2) os principais pontos\nde vista em torno dos assuntos investigados e (3) algumas conclus\u00f5es gerais sobre o estado da arte,\nincluindo as lacunas que permanecem nas \u00e1reas.\n\nA Se\u00e7\u00e3o 2.1 resume Inspe\u00e7\u00f5es em Tubula\u00e7\u00f5es na Ind\u00fastria do Petr\u00f3leo e G\u00e1s, com suas carac-\nter\u00edsticas e problemas. Al\u00e9m disso, a Se\u00e7\u00e3o 2.2 introduz os Rob\u00f4s Modulares Auto-reconfigur\u00e1veis\n(rob\u00f4s SRM) com defini\u00e7\u00e3o, taxonomia, aplica\u00e7\u00e3o e exemplos. Com isso em mente, s\u00e3o mostrados\nna Se\u00e7\u00e3o 2.3 alguns sensores e filtros normalmente aplicada na instrumenta\u00e7\u00e3o de um Rob\u00f4 Mod-\nular Auto-recofigur\u00e1vel para inspe\u00e7\u00e3o de dutos. Finalmente, a Se\u00e7\u00e3o 2.4 mostra como representar\nrota\u00e7\u00f5es espaciais em tr\u00eas dimens\u00f5es utilizando \u00e2ngulos de Euler.\n\n\n\nCap\u00edtulo 3: Projeto Conceitual e Modelamento\n\nIntrodu\u00e7\u00e3o\n\nEste cap\u00edtulo apresenta os conceitos e modelos empregados no estudo de sensoriamento em\nrob\u00f3tica modular auto-reconfigur\u00e1vel. Apresenta-se os conceitos do ErekoBot ? , em seguida\ndemonstra-se os modelos dos sistema de instrumenta\u00e7\u00e3o: atitude, dist\u00e2ncia e filtragem. Com\nisso, prop\u00f5em-se o Algoritmo de alinhamento utilizando a resposta dos sensores IR e da IMU.\n\nModelo Conceitual do ErekoBot ?\n\nA simplicidade e robustez caracteriza o conceito do ErekoBot ? , que evita altos custos com\nmateriais e processamento. Um m\u00f3dulo \u00e9 representando como segmentos de linha e essas linhas\ns\u00e3o conectadas a um eixo de coordenadas 3D que representa o rob\u00f4 modular completo.\n\nA se\u00e7\u00e3o apresenta os par\u00e2metros m\u00ednimos de projeto, uma poss\u00edvel aplica\u00e7\u00e3o e os objetivos do\nErekoBot ? : (1) detectar um objeto, (2) se alinhar com um plano (simulando uma tubula\u00e7\u00e3o) e\n(3) estimar sua pr\u00f3pria atitute.\n\nAlguns par\u00e2metros b\u00e1sicos (como dimens\u00f5es, tipo de microcontrlador e n\u00famero de graus de\nliberdade) foram definidos para come\u00e7ar a projetar o rob\u00f4.\n\nModelo de Instrumenta\u00e7\u00e3o\n\nQuando estimando a pose do rob\u00f4, \u00e9 proposto um modelo de atitiude utilizando \u00e2ngulos de\nEuler a patir dos resultados do girosc\u00f3pio e aceler\u00f4metro. O modelo do girosc\u00f3pio \u00e9 baseado na\nintegra\u00e7\u00e3o num\u00e9rica dos resultados e do aceler\u00f5metro, na orienta\u00e7\u00e3o do corpo relativa a gravidade\nno eixo de coordenadas de navega\u00e7\u00e3o.\n\nComo o girosc\u00f3pio e o aceler\u00f4metro possuem vantagens e desvantagens complementares, um\nfiltro complementar \u00e9 proposto para combinar esses dados para uma melhor resposta. A estima\u00e7\u00e3o\nda dist\u00e2ncia ajusta as dire\u00e7\u00f5es normais da face do ErekoBot ? com rela\u00e7\u00e3o a superf\u00edcie do objeto\ndetectando o erro de atitute utilizando sensores IR.\n\nAlgoritmo de Alinhamento\n\nEnt\u00e3o, o algoritmo de alinhamento \u00e9 proposto para mudar a posi\u00e7\u00e3o do ErekoBot ? enquanto\nos sensores IR est\u00e3o desalinhados com o plano.\n\nCap\u00edtulo 4: Projeto do M\u00f3dulo\n\nEste cap\u00edtulo apresenta todos os passos para a constru\u00e7\u00e3o do ErekoBot ? . O projeto come\u00e7a\npela sele\u00e7\u00e3o dos sensores, verificando quais sensores costumam ser utilizados em rob\u00f3tica modular\n\n\n\nauto-reconfigur\u00e1vel.\n\nEm seguida, apresenta-se o projeto eletr\u00f4nico (microcontrolador, comunica\u00e7\u00e3o, dispositivos\neletr\u00f4nicos e alimenta\u00e7\u00e3o externa) e o projeto mec\u00e2nico (conex\u00e3o intermodular, servo motor, ma-\nteriais, descri\u00e7\u00e3o geom\u00e9trica e an\u00e1lise de peso). Com o m\u00f3dulo construido, fizemos uma an\u00e1lise do\nm\u00f3dulo, comparando-o com outros m\u00f3dulos de rob\u00f4s modulares auto-reconfigur\u00e1veis.\n\nCap\u00edtulo 5: Experimentos e Resultados\n\nEste cap\u00edtulo descreve as plataformas e configura\u00e7\u00f5es desenvolvidas para realizar os experimen-\ntos. E, ent\u00e3o, os resultados s\u00e3o apresentados.\n\nOs experimentos descritos nesse cap\u00edtulos objetivam verificar a qualidade da informa\u00e7\u00e3o obtida\ncom os dados dos sensores. Tr\u00eas tipos de experimentos foram realizados: de orienta\u00e7\u00e3o (dados\nda IMU), de dist\u00e2ncia (dados dos sensores IR) e de alinhamento (para posicionamento do m\u00f3dulo\nparalelo a um obst\u00e1culo).\n\nExperimento de Orienta\u00e7\u00e3o\n\nO principal objetivo desses experimentos foi estimar a posi\u00e7\u00e3o do ErekoBot ? utilizando o\naceler\u00f4metro e o girosc\u00f3pio. Nesses experimentos, o microcontrolador l\u00ea os dados da IMU e os\nenvia pelo o Digi R\u00a9 XBee R\u00a9 1mW PCB radio module para o host, que filtra o sinal usando o Filtro\ncomplementar.\n\nAs leituras da IMU foram testadas em duas diferentes situa\u00e7\u00f5es: quando o m\u00f3dulo est\u00e1 na\nposi\u00e7\u00e3o de repouso e quando o m\u00f3dulo est\u00e1 em movimento. Os experimentos s\u00e3o considerados\nbem sucedidos quando \u00e9 poss\u00edvel estimar os \u00e2ngulos pitch sem o desvio do girosc\u00f3pio.\n\nOs m\u00f3dulos t\u00eam apenas um grau de liberdade, que pode ser disposto de forma a realizar os\n\u00e2ngulos de pitch e yaw (ver Figura 5.1). Como n\u00e3o \u00e9 poss\u00edvel fazer o m\u00f3dulo de executar um\nmovimento de rolagem, esse \u00e2ngulo n\u00e3o ser\u00e1 analisado aqui.\n\nAl\u00e9m disso, por causa do Gimbal Lock (Se\u00e7\u00e3o 2.4.1.1), n\u00e3o \u00e9 poss\u00edvel estimar a posi\u00e7\u00e3o yaw\ncom o filtro complementar combinando as informa\u00e7\u00f5es do aceler\u00f4metro e girosc\u00f3pio. Portanto, o\n\u00fanico \u00e2ngulo a ser analisado \u00e9 o \u00e2ngulo pitch.\n\nO filtro complementar \u00e9 ajustado no host e em seguida, o resultado encontrado de Perr \u00e9\nutilizado em cada m\u00f3dulo.\n\nM\u00e9todo Experimental\n\nA figura 5.2a mostra a posi\u00e7\u00e3o e a configura\u00e7\u00e3o para o primeiro experimento. O m\u00f3dulo repousa\nna posi\u00e7\u00e3o 0? e as medidas da IMU s\u00e3o lidas por 80 segundos, com um tempo de amostra de 200 ms.\nPortanto, o m\u00f3dulo envir 400 medi\u00e7\u00f5es para o host, que calcula off-line os sinais filtrados com o\nalgoritmo do filtro Complementar.\n\n\n\nA figura 5.2b mostra como o m\u00f3dulo se movimenta da posi\u00e7\u00e3o ?45? a 45?. O algoritmo utilizado\npelo m\u00f3dulo \u00e9 constitu\u00eddo pelos seguintes passos:\n\n1. Ler a IMU 10 vezes;\n\n2. Enviar as medi\u00e7\u00f5es para o host;\n\n3. Esperar 200 ms;\n\n4. Avan\u00e7ar 5?;\n\n5. Se a posi\u00e7\u00e3o for inferior a 45?, voltar para o passo 1.\n\nResultados\n\nUsando as equa\u00e7\u00f5es (3.2), (3.12), (3.13), o host calcula o \u00e2ngulo pitch a partir das medi\u00e7\u00f5es da\nIMU, enquanto o m\u00f3dulo permanece na posi\u00e7\u00e3o de repouso (0?), conforme indicado na Figura 5.3.\n\u00c9 poss\u00edvel observar que os os resultados baseados no aceler\u00f4metro forneceram valores de \u00e2ngulos\nexatos: mesmo que o valor m\u00e9dio varie no tempo, a m\u00e9dia \u00e9 ?3.30? com um desvio padr\u00e3o de\n12.74?. Esses valores n\u00e3o s\u00e3o precisos, porque h\u00e1 uma grande varia\u00e7\u00e3o em cada medi\u00e7\u00e3o. Em\ncontraste, os \u00e2ngulos baseados girosc\u00f3pio foram precisos, mas inexatos devido ao desvio que ocorre\nao longo do tempo.\n\nOs resultados sugerem que os dados do aceler\u00f4metro e girosc\u00f3pio s\u00e3o complementares, reafir-\nmando a possibilidade do uso do Filtro Complementar. Os resultados da estimativa de \u00e2ngulo\nusando o filtro Complementar s\u00e3o apresentados na Figura 5.4. Como mencionado na Se\u00e7\u00e3o 3.3.1.3,\nquando Perr \u00e9 pr\u00f3ximo de 0, o Filtro Complementar elimina as leituras do aceler\u00f4metro (linhas\nmais escuras) e quando Perr est\u00e1 perto de 1, o Filtro Complementar n\u00e3o leva em conta as medidas\ndo girosc\u00f3pio.\n\nO \u00e2ngulo pitch tamb\u00e9m foi calculado pelo host a partir das medi\u00e7\u00f5es da IMU quando o motor\nest\u00e1 se movimentando de ?45? a 45?, e as leituras s\u00e3o mostrados no gr\u00e1fico da Figura 5.5. Esses\nresultados s\u00e3o semelhantes aos do gr\u00e1fico da Figura 5.3: o aceler\u00f4metro fornece \u00e2ngulos exatos, mas\nimprecisas, enquanto os \u00e2ngulos do girosc\u00f3pio s\u00e3o precisos, mas inexatos. A figura 5.6 apresenta\no gr\u00e1fico com a estimativa obtida usando o filtro Complementar, quando Perr \u00e9 0.9, 0.7, 0.5, 0.3 e\n0.1.\n\nOs resultados das Figuras 5.4 e 5.6 fornecem dados suficientes para empregar o Filtro Comple-\nmentar para estimativas futuras, com with Perr = 0.5, porque \u00e9 o resultado que mais se aproxima\nda linha reta entre ?45? a 45?.\n\nExperimento de Dist\u00e2ncia\n\nO principal objetivo desses experimentos \u00e9 detectar a presen\u00e7a de um obst\u00e1culo e estimar sua\ndist\u00e2ncia da face do ErekoBot ? onde os sensores IR s\u00e3o fixados. A depend\u00eancia entre a sa\u00edda,\ntens\u00e3o, e a dist\u00e2ncia estimada para os sensores IR n\u00e3o \u00e9 linear, o que sugere a necessidade de\n\n\n\ncalibrar e linearizar o Sensor IR SHARP GP2Y0A41SK0F (Se\u00e7\u00e3o 2.3.1). Ap\u00f3s a calibra\u00e7\u00e3o, uma\nlookup table \u00e9 gerado e \u00e9 inserida no microcontrolador para ser utilizado enquando se estima a\ndist\u00e2ncia entre a face do m\u00f3dulo e um obst\u00e1culo no meio.\n\nO experimento \u00e9 bem sucedido quando o ErekoBot ? \u00e9 capaz de detectar um obst\u00e1culo e estimar\nsua dist\u00e2ncia usando a tabela de refer\u00eancia.\n\nM\u00e9todo Experimental\n\nO sensor IR SHARP GP2Y0A41SK0F detecta obst\u00e1culos e mede as medidas dentro de uma\nfaixa entre 40 a 300 mm. Com o objetivo de garantir a detec\u00e7\u00e3o e medi\u00e7\u00e3o corretas, o Sensor IR\nfoi calibrado atrav\u00e9s da an\u00e1lise da curva de tens\u00e3o n\u00e3o-linear detectar um obst\u00e1culo cinza entre 10\nto 350 mm com uma resolu\u00e7\u00e3o de 10 mm. A Figura 5.7 mostra a disposi\u00e7\u00e3o experimento.\n\nA fim de considerar a poss\u00edveis mudan\u00e7as por causa da histerese e das condi\u00e7\u00f5es do meio, as\nmedidas foram realizadas em ambas as dire\u00e7\u00f5es. Inicialmente, o sensor est\u00e1 localizado na posi\u00e7\u00e3o\n10 mm, e ent\u00e3o o sensor IR se move lentamente para outras medidas at\u00e9 atingir 350 mm. Nesse\nponto, o sensor \u00e9 movido para tr\u00e1s e as medi\u00e7\u00f5es s\u00e3o feitas novamente. Para certificar-se os\nresultados s\u00e3o redundantes, as medi\u00e7\u00f5es s\u00e3o repetidos quatro vezes para cada posi\u00e7\u00e3o.\n\nUma curva com base nas leituras dos sensores \u00e9 tra\u00e7ada, e a faixa aceit\u00e1vel \u00e9 determinada.\nA melhor equa\u00e7\u00e3o exponencial \u00e9 escolhida com a ajuda do aplicativo Curve Fitting Toolbox R\u00a9 do\nMATLAB R\u00a9.\n\nResultados\n\nA Figura 5.8 mostra a curva obtida pelos valores m\u00e9dios. A depend\u00eancia entre a sa\u00edda de\ntens\u00e3o e dist\u00e2ncia de proximidade para sensores de IR \u00e9 n\u00e3o-linear e bastante semelhante \u00e0 curva\ndo datasheet (SHARP, 2002). A partir desta curva, \u00e9 poss\u00edvel especificar um intervalo de trabalho\nentre 5 e 28 cm .\n\nCom o Curve Fitting Toolbox R\u00a9 do MATLAB R\u00a9, a melhor equa\u00e7\u00e3o foi encontrada.\n\nA fim de construir a tabela de refer\u00eancia, necess\u00e1ria para calcular a dist\u00e2ncia baseado na\nmedi\u00e7\u00e3o de tens\u00e3o, a Equa\u00e7\u00e3o (5.2.2) \u00e9 invertida.\n\nExperimento de Alinhamento\n\nO objetivo principal desse experimento \u00e9 detectar a presen\u00e7a de um obst\u00e1culo, estimar sua\ndist\u00e2ncia da face do ErekoBot ? e alinhar a superf\u00edcie do m\u00f3dulo com a superf\u00edcie do obst\u00e1culo.\nA fim de verificar o algoritmo de alinhamento da Se\u00e7\u00e3o 3.4, o algoritmo foi testado com diferentes\nplanos em diferentes dist\u00e2ncias.\n\n\n\nM\u00e9todo Experimental\n\nCombinando os resultados das Se\u00e7\u00f5es 5.1.2 e 5.2.2, o seguinte algoritmo de alinhamento foi\naplicado:\n\n1. O ErekoBot ? l\u00ea a orienta\u00e7\u00e3o da haste no tempo t (orientt(6)) e calcula o \u00e2ngulo pitch atrav\u00e9s\nde um filtro complementar com Perr = 0.5;\n\n2. O ErekoBot ? l\u00ea a dist\u00e2ncia de objetos em tempo de t (proximt(4)), utilizando a tabela de\nrefer\u00eancia a partir da Equa\u00e7\u00e3o (5.1);\n\n3. Atrav\u00e9s do Digi R\u00a9 XBee R\u00a9 1mW PCB radio module , o m\u00f3dulo envia orientt(6), proximt(4)\ne t para o host;\n\n4. Se as dist\u00e2ncias s\u00e3o diferentes, o servo motor gira para um \u00e2ngulo ? proporcionalmente a\ndiferen\u00e7a medida pelos sensores IR, a fim de alinhar com o plano;\n\n5. Ap\u00f3s a adicionar 1 a t e esperar por 300 ms, o ErekoBot ? retorna ao passo 1.\n\nO alinhamento foi testado com tr\u00eas superf\u00edcies diferentes: uma folha de papel branco, um\npapel cart\u00e3o cinza e uma folha de papel preta em diferentes posi\u00e7\u00f5es. O objetivo \u00e9 testar se o\nalinhamento trabalha com diferentes cores (branco, cinza e preto) e estimar quanto tempo leva\npara o ErekoBot ? para alinhar com os planos.\n\nResultados\n\nFiguras 5.13, 5.14 e 5.15 apresentaram os experimentos de alinhamento. Os resultados foram\nsemelhantes com as tr\u00eas superf\u00edcies diferentes testados: o ErekoBot ? se alinha com o plano. Su-\nperf\u00edcies brancas refletem melhor do que superf\u00edcies pretas, e, como sensores IR funciona com luz\ninfravermelha refletida (Se\u00e7\u00e3o 2.3.3), o plano branco funciona mais rapidamente que os planos\ncinza e preto.\n\nConsiderando resultados quantitativos, os tr\u00eas ensaios s\u00e3o apresentados. O ErekoBot ? executa\no algoritmo de alinhamento em uma superf\u00edcie cinza, e as diferen\u00e7as entre as dist\u00e2ncias medidas\ndos sensores IR e as posi\u00e7\u00f5es de orienta\u00e7\u00e3o da IMU (ap\u00f3s a execu\u00e7\u00e3o de um filtro complementar)\ns\u00e3o enviados para o host. Os testes foram realizados dez vezes em cada posi\u00e7\u00e3o.\n\nNo primeiro teste, o ErekoBot ? -se alinhou-se com o plano na posi\u00e7\u00e3o 15? em menos de 1\nsegundo, como mostrado nas Figuras 5.10a e 5.10b. O servo motor gira no sentido dos \u00e2ngulos\npositivos at\u00e9 a haste do m\u00f3dulo se alinhar ao \u00e2ngulo de 16?.\n\nO mesmo acontece no segundo teste, o ErekoBot ? alinha-se com o plano na posi\u00e7\u00e3o ?25? em\nmenos de 1 segundo, como mostrado nas Figuras 5.11a e 5.11b. O servo motor gira no sentido dos\n\u00e2ngulos negativos at\u00e9 o \u00e2ngulo da haste convergir para 27?.\n\n\n\nNo terceiro e \u00faltimo teste, o ErekoBot ? alcan\u00e7a o alinhamento com o plano na posi\u00e7\u00e3o ?40?\n\nem menos de 1.2 segundos, como mostrado nas Figuras 5.12a e 5.12a. O servo motor gira no\nsentido dos \u00e2ngulos negativos at\u00e9 que o valor ?43? seja atingido.\n\nOs testes apontaram algumas limita\u00e7\u00f5es:\n\n\u2022 Luz: quando h\u00e1 uma luz apontada diretamente para um sensor IR, as respostas de medi\u00e7\u00e3o\ns\u00e3o afetadas. O sensor IR considera que existe um objeto e o alinhamento n\u00e3o funciona\ncorretamente.\n\n\u2022 Dist\u00e2ncias superior a 280 mm: como esperado, o sensor IR n\u00e3o mede adequadamente dist\u00e2n-\ncias maiores do que o m\u00e1ximo da faixa. O alvo \u00e9 considerado a uma dist\u00e2ncia de 280 mm\npara qualquer dist\u00e2ncia maior.\n\n\u2022 Dist\u00e2ncias menores que 50 mm: como esperado, o sensor IR n\u00e3o mede adequadamente dist\u00e2n-\ncias menores do que o m\u00ednimo do intervalo. Observando o gr\u00e1fico da Figura 5.8, \u00e9 poss\u00edvel que\no ErekoBot ? considere o objeto a uma posi\u00e7\u00e3o dentro da faixa aceit\u00e1vel de valores 50 mm\na 280 mm. Para trabalhos futuros, um algoritmo que considere estat\u00edsticas baseadas em\ndist\u00e2ncias anteriores podem ser desenvolvidos para trabalhar nesses casos.\n\n\u2022 Posi\u00e7\u00f5es do servo motor maiores que 35? e menores que 145?: a fim de evitar a colis\u00e3o das\npe\u00e7as internas m\u00f3dulo, foram determinadas posi\u00e7\u00f5es m\u00e1ximas e m\u00ednimas ao servo motor.\n\n\u2022 A calibra\u00e7\u00e3o do sensor IR: a Figura 5.9 funciona apenas para obst\u00e1culos cinzas, cores difer-\nentes podem produzir diferentes lookup tables. No entanto, como o ErekoBot ? se alinha\ncom base nas diferen\u00e7as entre essas dist\u00e2ncias, se o alinhamento ocorre em uma superf\u00edcie\nhomog\u00eanea, (mesma cor e textura), os resultados n\u00e3o s\u00e3o afetados.\n\nConsiderando estas limita\u00e7\u00f5es n\u00e3o \u00e9 poss\u00edvel utilizar esse rob\u00f4 em tubula\u00e7\u00f5es ainda.\n\nConclus\u00f5es\n\nUm m\u00f3dulo SRM foi projetado e fabricado respeitando o desenho conceptual proposto no\nCap\u00edtulo 4, o que nos permitiu testar os modelos do Cap\u00edtulo 3. Os sensores incorporados s\u00e3o\nusados para:\n\n1. Estimando a orienta\u00e7\u00e3o do ErekoBot ? usando o Filtro Complementar.\n\n2. Calibrar os sensores IR para medi\u00e7\u00f5es de dist\u00e2ncia.\n\n3. Alinhar a face do ErekoBot ? com um plano.\n\nCom os resultados dos testes de IMU (Figura 5.3 e Figura 5.5), \u00e9 poss\u00edvel verificar que as\nmedi\u00e7\u00f5es para estimar a orienta\u00e7\u00e3o m\u00f3dulo s\u00e3o ruidosas ou desviam ao longo do tempo. Para\nsuperar este problema, um filtro complementar foi empregado, o que diminui o ru\u00eddo e o desvio,\n\n\n\nestimando rapidamente e n\u00e3o sobrecarregando o processador do m\u00f3dulo. Portanto, para efeitos de\nestabiliza\u00e7\u00e3o mais r\u00e1pida e mais precisa do ErekoBot ? , o filtro complementar \u00e9 escolhido como\npadr\u00e3o utilizado para esse tipo de processos com a IMU.\n\nA calibra\u00e7\u00e3o do sensor IR forneceu uma curva semelhante \u00e0 que aparece no datasheet (SHARP,\n2002), e os resultados da equa\u00e7\u00e3o (5.1) foram convertidos em uma lookup table programado no\nAtmel R\u00a9 AVR R\u00a9 ATmega8 .\n\nCom estes resultados, foi poss\u00edvel realizar o alinhamento, e demonstrar a viabilidade do algo-\nritmo descrito na Se\u00e7\u00e3o 3.4. Mas n\u00e3o \u00e9 poss\u00edvel confirmar que o rob\u00f4 n\u00e3o pode ser utilizado para\naplica\u00e7\u00f5es de inspec\u00e7\u00e3o oleoduto ainda.\n\nCap\u00edtulo 6: Conclus\u00f5es\n\nEste cap\u00edtulo apresenta as principais contribui\u00e7\u00f5es desta disserta\u00e7\u00e3o com uma breve discuss\u00e3o\nsobre as suas implica\u00e7\u00f5es. E, em seguida, indica algumas das poss\u00edveis futuras linhas de investiga\u00e7\u00e3o\npara este trabalho.\n\nPrincipais contribui\u00e7\u00f5es\n\nO ErekoBot ? \u00e9 um m\u00f3dulo reconfigur\u00e1vel simples com sensores capaz de reagir ao ambiente.\nNeste trabalho, o m\u00f3dulo foi projetado, fabricado e testado, o que nos permitiu responder \u00e0s\nquest\u00f5es apresentadas na Se\u00e7\u00e3o 1.2:\n\n1. Que tipo de sensores s\u00e3o mais comuns em m\u00f3dulos recentes? A Tabela 4.2 retoma as princi-\npais caracter\u00edsticas dos cinco dos m\u00f3dulos mais recentes. Os sistemas Roombots e SMORES\nn\u00e3o tem sensores internos; O Transmote s\u00f3 usa sensores de proximidade; j\u00e1 o Cosmo e UBot\nt\u00eam uma sele\u00e7\u00e3o mais completa de sensores de orienta\u00e7\u00e3o e de proximidade.\n\n2. Que tipo de requisitos o m\u00f3dulo possui? A se\u00e7\u00e3o 3.2 apresenta os tr\u00eas principais requisitos\npara o ErekoBot ? : as habilidades para (1) detectar um obst\u00e1culo (Figura 3.3a), (2) se\nalinhar com um plano simulando uma tubula\u00e7\u00e3o (Figura 3.3b) e (3) estimar a sua pr\u00f3pria\nposi\u00e7\u00e3o (Figura 3.3c).\n\n3. Que tipo de sensores v\u00e3o ser usados neste m\u00f3dulo? O ErekoBot ? possui quatro sensores\ninfravermelhos (GP2Y0A41SK0F) para detec\u00e7\u00e3o de obst\u00e1culos e o algoritmo de alinhamento.\nAl\u00e9m disso, ErekoBot ? possui uma IMU (com ADXL345 e ITG-3200) para medi\u00e7\u00f5es de\nmovimento de rota\u00e7\u00e3o.\n\n4. Qual a forma, tamanho, peso, circuitos e materiais do m\u00f3dulo? O Cap\u00edtulo 4 foca no projeto\ndo m\u00f3dulo, e as figuras 4.6, 4.9, 4.10 e a Tabela 4.2 ilustram e retomam a forma, tamanho,\npeso, circuitos e materiais do m\u00f3dulo completo.\n\n5. Os sensores escolhidos s\u00e3o suficientes para as nossas necessidades? O Cap\u00edtulo 5 apresenta\nos resultados dos experimentos. O ErekoBot ? \u00e9 capaz de: (1) detectar um obst\u00e1culo entre\n\n\n\n5 e 28 cm (Figura 5.9), (2) se alinhar com um plano que simula uma tubula\u00e7\u00e3o (Figuras 5.13,\n5.14 e 5.15), e (3) estimar a sua pr\u00f3pria pose com um Filtro Complementar do girosc\u00f3pio e\naceler\u00f4metro medi\u00e7\u00f5es (Figuras 5.4 e 5.6).\n\nO m\u00f3dulo mostra evid\u00eancias para a sua aplica\u00e7\u00e3o nas inspec\u00e7\u00f5es de oleodutos, por\u00e9m as solu\u00e7\u00f5es\npropostas t\u00eam suas limita\u00e7\u00f5es e que ainda n\u00e3o s\u00e3o vi\u00e1veis para aplica\u00e7\u00e3o em campo.\n\nTrabalhos Futuros\n\nAlgumas linhas de investiga\u00e7\u00e3o s\u00e3o apresentados para dar continuidade a esta disserta\u00e7\u00e3o (a\nordem que aparece \u00e9 uma sugest\u00e3o da autora de import\u00e2ncia):\n\n\u2022 M\u00f3dulo mais leve Ainda poss\u00edvel diminuir o peso do m\u00f3dulo, a alterando o acr\u00edlico por um\nmaterial mais leve (tais como resinas, fibras de carbono) e mudando a placa de circuito\nimpresso (PCB) para um dispositivo de montagem superficial (SMD).\n\n\u2022 Cabo/Energia Diminuir o peso do m\u00f3dulo permite a utiliza\u00e7\u00e3o de uma fonte de energia\nautonoma, eliminando a necessidade do cabo.\n\n\u2022 Magnet\u00f4metro Para projetos futuros, o magnet\u00f4metro pode ser usado para determinar o yaw.\n\n\u2022 Alinhamento e algoritmos de desvio de obst\u00e1culos Este trabalho apresenta c\u00f3digos e algorit-\nmos para a leitura dos valores de sensores e convert\u00ea-los para o sistema mais familiar aos\nusu\u00e1rios (dist\u00e2ncia em mil\u00edmetros, orienta\u00e7\u00e3o em vetores). No entanto, as leis de controle\nn\u00e3o foram adicionados a encontrar a melhor resposta para os m\u00f3dulos. \u00c9 poss\u00edvel fazer um\ncontrole de malha fechada do sistema.\n\n\u2022 Conex\u00e3o Outra linha de investiga\u00e7\u00e3o diz respeito a conex\u00e3o entre os m\u00f3dulos, \u00e9 fundamental\npara substituir o VelcroTM por um sistema macho-f\u00eamea com motores de corrente cont\u00ednua\nem cada face do m\u00f3dulo.\n\n\u2022 M\u00e9todos de Vis\u00e3o Computacional A homogeneidade de ErekoBot ? possui a vantagem para\nsua produ\u00e7\u00e3o em s\u00e9rie. No entanto, um dos m\u00f3dulos pode ser diferente e transportar uma\nc\u00e2mera para permitir a utiliza\u00e7\u00e3o de m\u00e9todos de vis\u00e3o computacional para a detec\u00e7\u00e3o e\nalinhamentos obst\u00e1culos.\n\n\u2022 Sistemas de Rob\u00f3tica Distribuida Depois de resolver o sistema de alinhamento, \u00e9 poss\u00edvel\ntrabalhar com sistemas rob\u00f3ticos distribu\u00eddos, analisando quando se conectar, como ligar e\nque tipo de colabora\u00e7\u00f5es entre o rob\u00f4 e os m\u00f3dulos seram estabelecidas.\n\nEmbora existam v\u00e1rias limita\u00e7\u00f5es neste sistema, o projeto e testes contribuem para a rob\u00f3tica\nmodular reconfigur\u00e1vel a fim de construir um sistema vers\u00e1til que pode alterar a automa\u00e7\u00e3o dos\nprocessos de manuten\u00e7\u00e3o e de detec\u00e7\u00e3o de vazamentos no futuro.\n\n\n\nChapter 1\n\nIntroduction\n\n1.1 Presentation\n\nThis work deals with reconfigurable modular robots with specific focus on the study of instru-\nmentation for simple tasks in pipelines inspection. The main problem faced here is how to design\nand manufacture a reconfigurable modular robot able to align with the internal walls of a pipeline.\n\nThere are challenges in the decisions for robots design, including what type of sensors to use.\nInstrumentation is the science of measurements and control of process variables; its techniques\nare essential in every branch of technology and science nowadays (BENTLEY, 2005). As modern\nproduction techniques dictates tighter accuracy limits with lower production costs, there is a\ngrowth in the research and development efforts of instruments to measure, record and control\nprocess variables.\n\nBesides instrumentation, other important challenge in developing a robot resides in providing\nversatility: the ability for a robot to perform a variety of tasks in different terrains. This is of a\nspecial relevance when the environment is unknown - such as outdoors exploration, rescue opera-\ntions and inspection in hazard environments. The pipeline environment in Oil and Gas industry\nfits: it is a hazardous industrial environment with a variety of tasks in different terrains. Pipeline\ninspection needs recurrent autonomous processes and systems, motivating new technologies, such\nas reconfigurable modular robots.\n\nThe traditional approach in robots is to first study the characteristics of the terrain and then\ndesign the most adequate structure of the robot for that specific situation. In this approach, a bad\ndesign choice or a misevaluation of some environment variable results in the need to redesign the\nrobot.\n\nIn 1994, Mark Yim, in his doctoral thesis (YIM, 1994), proposed to employ simple modules\njoined one to another to make up different configurations in a robot. Thus, the robots can change\ntheir form, enabling them to move thought unknown terrains. In this new idea, it is possible to\ncreate different configurations with basic modules.\n\nAlthough this approach may seem motivating, it is important to emphasize that a robot con-\n\n1\n\n\n\nventionally designed for a particular task will always perform better than a modular system.\nReconfigurable Modular Robots are an alternative for systems where the conventional robots do\nnot meet the environment requirements. The robustness and versatility of modular robots make\nthem redundant systems, which may cross the line between conventional and modular. Mechanical\nand computational complexities substantially increase with the system modularity, as should be\nexpected.\n\nNevertheless, a reconfigurable modular robot with sensors is able to interact with the world,\nadapting to changes in the environment. This type of robot may: (1) decrease manufacturing and\nmaintenance cost, (2) increase the number of applications compared to conventional robots and\n(3) increase robustness.\n\n1.2 Aims\n\nThe main aim of this work is to design, manufacture and test a reconfigurable modular robot\nwith sensors. It is desired that this robot react to environmental changes based on sensors response.\n\nThe mission of the robot is to inspect Gathering Lines of pipelines that usually have these\ncharacteristics:\n\n\u2022 They are used to transport crude oil or natural gas from the wellhead to a central collection\npoint;\n\n\u2022 They have small diameter size: between 101.6 mm to 304.8 mm;\n\n\u2022 They work on low pressure and flow.\n\nThere are many ways to construct this module depending on budget, materials, size, weight and\nshape. The module here designed is based on previous robots developed at University of Bras\u00edlia.\nThe concrete aims are listed below, each one linked to a question:\n\n1. Discover types of sensors commonly employed in recent SRM robotics (What kind of sensors\nare more common in recent SRM robotics?).\n\n2. Determine the basic tasks that the proposed module must perform (What kind of requirements\ndoes the robot have?)\n\n3. Analyze what kind of sensors are available to measure variables for the module requirements\n(What kind of sensors are going to be used in this module?)\n\n4. After choosing the sensors, it is still necessary to design the complete module (What is the\nshape, size, weight, circuits and materials of the module?)\n\n5. Manufacture the entire module and test if the sensors meets the requirements (Does the\nchosen sensors are sufficient for our needs?)\n\n2\n\n\n\nSome relevant aspects of SRM are not part of this work:\n\n1. Locomotion of the module,because to verify the instrumentation it is not necessary to analyze\nthe locomotion of the modules.\n\n2. Connections between modules, a simple connection is employed just to make sure the modules\nare manually reconfigurable.\n\n3. High level distributive programming, as these modules are not at this level of programming\nyet.\n\n1.3 Structure of the Document\n\nThis first chapter introduced the context of the dissertation and the aims of the work. In\nthe second chapter, the theoretical background necessary for the full understanding of the work\ndeveloped is described. The third chapter presents the models and concepts for the module and\ninstrumentation.\n\nChapter 4 combines the knowledge showed in previous chapters to presents the design of the\nproposed robot. In the fifth chapter, the most relevant experiments are described and, finally, the\nsixth chapter lists some future lines of investigation.\n\n3\n\n\n\nChapter 2\n\nBrief Review of Pipeline Inspection,\nSRM Robots and Instrumentation\n\nThis Chapter familiarizes the reader with this work background. Due to the fact that our\nwork spans more than one field, we will present the key issues underlying this project: (1) major\nfindings on the research topics, by whom and when, (2) main points of view surrounding the\nissues investigated and (3) some general conclusions about the state of the art, including gaps that\nremains in the area.\n\nSection 2.1 resumes Pipeline Inspections in Oil and Gas Industry, with its characteristics and\nproblems. In addition, Section 2.2 introduces Self-Reconfigurable Modular Robots (SRM robots)\nwith its definition, taxonomy, application and examples. With that in mind, we will show in\nSection 2.3 some sensors and filters usually applied for instrumentation in a Self-Reconfigurable\nModular Robot for pipeline inspection. Finally, Section 2.4 shows how to represent spatial rotation\nin three dimensions using Euler angles.\n\n2.1 Pipeline Inspection\n\nOil and gas pipelines play a critical role in the transportation process, the World Factbook\nfrom the Central Intelligence Agency (Central Intelligence Agency, 2013) estimates 2, 225, 032\nkilometers of pipelines in the United States, 259, 913 in Russia and 100, 000 in Canada. The\nlengths for transporting products in Brazil is 251 km for condensate/gas; 17, 312 km for gas; 352\nkm for liquid petroleum gas; 4, 831 km for oil and 4, 722 km for refined products, totalizing 27, 477\nkm of pipelines.\n\nIn addition to a substantial cost advantage, pipelines also result in fewer leak incidents and per-\nsonal injuries than other types of transportation (GREEN; FURCHTGOTT-ROTH, 2013), making\nthem the most ecological friendly and economically viable form for transportation of crude oil over\nlong distances. However, there is still a potential leak: the transported oil and the environment\nmay still corrode the pipelines metal to the point of failure, affecting not only production but also\n\n4\n\n\n\nthe environment (GREEN; FURCHTGOTT-ROTH, 2013).\n\nMoreover, these hazardous industrial environments are difficult and dangerous places for per-\nsonnel: exposure to toxins, explosive gases, and bulky personal protective equipment are just a\nfew of the challenges of working in these facilities. Therefore, pipes increasingly require recur-\nrent autonomous processes and systems, which motivates the development of new technologies\n(ARCHILA; BECKER, 2013). In this scenario, pipeline inspection machines, often robots, must\nbe low-cost, robust and versatile to perform tasks, such as maintenance, cleaning, removal of\nliquids, separation of products and inspection.\n\n2.1.1 Classification of Pipeline Robots\n\nIn the context of pipeline robots, there is a wide variety of tasks \u2013 like inspection, maintenance\nand construction. In 1999, Hirose et al (HIROSE et al., 1999) presented a classification based\non locomotion mechanisms and, in 2007, Choi et al (CHOI; RYEW, 2002) improved adding two\ndifferent types of locomotion, as shown in Figure 2.1.\n\n(a) (b) (c)\n\n(d) (e) (f)\n\n(g) (h) (i)\n\nFigure 2.1: Classification of pipeline robots (Figures from (ARCHILA; BECKER, 2013)): (a) PIG.\n(b) Wheel. (c) Caterpillar. (d) Wall-press. (e) Walking. (f) Inchworm. (g) Screw. (h) Snake. (i)\nVariable Velocity PIG.\n\nFigure 2.1 presents the classification proposed in (CHOI; RYEW, 2002): (a) The pipeline\ninspection gauge (PIG), formed by large pieces of machinery pulled together with powerful technol-\nogy, where the flow-line service generates locomotion for pipelines with large diameters (OKAMOTO\net al., 1999); (b) The wheel type, similar to plain mobile robots (HIROSE et al., 1999); (c) The\n\n5\n\n\n\ncaterpillar or crawler type, such as the robot Versatrax (INUKTUM, ), that uses caterpillars in-\nstead of wheels; (d) The wall-press type, that puts pressure on the wall of the duct, and thus\ngenerate the necessary traction (CHOI; RYEW, 2002); (e) The walking type, that possess legs\nproducing highly sophisticated motions (PFEIFFER; ROSSMANN; LOFFLER, 2000); (f) The\ninchworm type, used in small diameters pipelines (BAUER, 2011); (g) The screw or helical type,\ndisplaying motion of a screw when it advances in the pipelines (HORODINCA et al., 2002); (h) The\nsnake type, similar to a snake or a annelid animal in nature, like MAKRO (STREICH; ADRIA,\n2004) and Slim Slim Robot (OHNO; HIROSE, 2001); (i) And, finally, the variable velocity PIG\n(Torres Jr; MANZAK; MILLER, 2002), where we can control the PIG speed introducing a bypass\nthrough the PIG body.\n\nIn this work, we will focus on robots similar to the snake MAKRO (Figure 2.2a) and Slim Slim\nRobot (Figure 2.2b), and classified as the snake type.\n\n(a) MAKRO (STREICH; ADRIA, 2004). (b) Slim Slime Robot (OHNO; HIROSE, 2001).\n\nFigure 2.2: Examples of Pipeline Robots.\n\n2.2 Self-Reconfigurable Modular Robots\n\nIn order to adapt for different terrains and tasks, Mark Yim developed in 1994 (YIM, 1994) the\nconcept of a robot system with variable morphology, nowadays called Self-Reconfigurable Modular\nRobots (SRM Robots). Besides presenting other robots characteristics (like actuators, sensors and\ncontrol systems), SRM Robots are also capable of changing its own shape and reorganizing its\nparts, often called modules. Modules are devices with processors, batteries, actuators and special\nmechanisms like hooks and cameras; they may transmit force, momentum, energy and data for the\nrest of the robot.\n\nIn manufacturing, modularity refers to the use of exchangeable parts or options in the fabri-\ncation of an object based on standardized units or dimensions, that easies assembly and repair\n(NORBERG, 2001). Reconfigurability is the ability to repeatedly change and rearrange the com-\nponents of a system in a cost-effective way (SETCHI; LAGOS, 2004). Both these characteristics in\nSRM robots give them the potential to excel conventional robots in multi-functionality, flexibility,\n\n6\n\n\n\nand robustness, with possibility of morphogenesis (Self-Assembly), self-repair, self-reproduction,\nscalability and motion generation (MURATA; KUROKAWA, 2007).\n\n2.2.1 Taxonomy\n\nGenerally, we classify SRM Robotic Systems according to their geometric arrangement (MU-\nRATA; KUROKAWA, 2007):\n\nLattice Architecture modules dock into interfaces at points into virtual cells of some regular\ngrid (Figure 2.3a). Usually, few modules are sufficient to accomplish a reconfiguration step\nwith a simpler mechanical design and a simpler computational representation. It is also\neasier to scale the reconfiguration planning to complex systems.\n\nChain Architecture modules may reach any point in space and therefore, the robot is more\nversatile (Figure 2.3b). However, the robot may need more modules to reach a point, making\nit usually more difficult to accomplish a reconfiguration step. They are more computationally\ndifficult to represent and analyze.\n\nHybrid Architecture it is a hybrid between the previous architectures: the control and mecha-\nnisms are designed in lattice, and the robot is constructed to reach any point in space.\n\n(a) Lattice type. (b) Chain type.\n\nFigure 2.3: Types of SRM robots (Figure from (MURATA; KUROKAWA, 2007)).\n\nWe can also classify the SRM robots depending on the way by which units are reconfigured\n(MURATA; KUROKAWA, 2007):\n\nDeterministic Reconfiguration the location of each module is regulated at all times during\nreconfiguration with sophisticated feedback control. Therefore, it is possible to guarantee\nreconfiguration time, even if precise feedback manipulation is necessary.\n\nStochastic Reconfiguration statistical processes are responsible for modules moving around.\nThe exact location of each module is unknown, except when they are connected to the main\nstructure.\n\n7\n\n\n\nFurthermore, we can classify the modules according to their design (MURATA; KUROKAWA,\n2007):\n\nHomogeneous when SRM robot modules have the same design forming a structure suitable to\nperform the required task. It is simpler to scale it in size, but the functionality is more\nlimited, as more modules are necessary to achieve a given function.\n\nHeterogeneous when SRM robot modules are different, with specialized functions. This type of\nrobot is more compact, and it is easier to add units, but it is also more complex to design,\nmanufacture and simulate.\n\n2.2.2 Brief History of SRM Robotics\n\nThe idea of building systems by assembling homogeneous components is not new. It dates\nback to von Neumann\u2019s \u201cTheory of self-reproducing cellular automata\u201d (BANKS, 1970), which\nassumed complete homogeneity of initial modules. This is an analogy to biological systems, in\nwhich cell division from a single cell creates all the differentiated cells. However, biological systems\nneed a vast number of cells to form their bodies and artificial systems need to admit heterogeneity\namong components or use complex modules with more functions within themselves (MURATA;\nKUROKAWA, 2007).\n\nCEBOT (FUKUDA; KAWAUCHI, 1990) was the first SRM robot designed based on hetero-\ngeneous modules, such as transportation, rotation joint, telescopic arm, and grasping modules.\nThese combinations made it possible for a CEBOT to perform a variety of tasks.\n\nPolybot (Figure 2.4a) is a system used to highlight methods and issues in the docking require-\nments of self-reconfiguration (Figure 2.4a). An IR ranging system permits a docking controlled by\na closed loop control system: when the modules are close enough, the IR sensors response give a\nempirically centralized feedback for the docking control (Figure 2.4b). This method proved to be\nmore robust than a computed offset method (YIM et al., 2002).\n\nSeveral SRM robots with homogeneous modules followed the CEBOT project (MURATA et\nal., 2002; JORGENSEN; OSTERGAARD; LUND, 2004; YIM et al., 2002). In the homogeneous\nsystem, a set of common rules must sufficiently describe the differentiation and behavior of each\nmodule when it is part of a specific robot configuration. Therefore, we can replace any module\nwith another one, which simplifies self-repair and self-reproduction schemes.\n\n2.2.3 Recent SRM Robots\n\nThis Section shows some of the most recent work on SMR, developed by different research\ncenters around the world, like the Karlsruhe Institute of Technology (KIT - Germany), the \u00c9cole\nPolytechnique F\u00e9d\u00e9rale de Lausanne (EPFL - Swiss), the Southeast University (SEU - China), the\nHarbin Institute of Technology (HIT - China) and the University of Pennsylvania (Penn - EUA).\n\n8\n\n\n\n(a) CAD rendering of a PolyBot G2 module\n(Figure from (YIM et al., 2002)).\n\n(b) IR sensing device on a PolyBot faceplate\n(Figure from (YIM et al., 2002)).\n\nFigure 2.4: Examples of Pipeline Robots.\n\n2.2.3.1 SMORES\n\nThe SMORES (Self- assembling Modular Robot for Extreme Shape-shifting, shown in Figure\n2.5) (DAVEY; KWOK; YIM, 2012) is a 100 \u00d7 100 \u00d7 90 mm module designed by the School of\nEngineering and Applied Science at University of Pennsylvania (U.S.A.). The SMORES module\nweights 0.52 kg and contains five identical motors to achieve a module with four Degrees of Freedom\n(DoF)1. Power, microcontroller and communications are embedded on the module, but there are\nno environmental sensing devices on-board yet.\n\nFigure 2.5: SMORES (DAVEY; KWOK; YIM, 2012).\n\nFuture revisions expect vision capabilities, local communication between the docking ports of\nneighboring modules and several environmental sensing abilities, such as torque feedback (current\nsensing), tactile sensing and orientation sensing to perform self-balance on its two outside wheels.\n\n1The number of independent parameters that defines its configuration.\n\n9\n\n\n\n2.2.3.2 UBot\n\nThe State Key Laboratory of Robotics and Systems at the Harbin Institute of Technology\n(China) designed the UBot (CUI et al., 2012; WANG; ZHU; ZHAO, 2013; ZHU et al., 2013)\n(shown in Figure 2.6), with two 80 mm cube shape. Each module has two independent rotational\nDoF and weights 280 g; they are also classified as passive or active module, depending on their\nconnecting mechanisms. The universal joints of UBot makes it more flexible for locomotion and\nreconfiguration (CUI et al., 2012).\n\nFigure 2.6: UBot (CUI et al., 2012; WANG; ZHU; ZHAO, 2013; ZHU et al., 2013).\n\nThe system also have a sensory module with the same cubic structure and dimensions including\nfour types of sensors: wireless vision sensor, accelerometer, infrared range finder, and linear Hall\nSensor. A chain module group with a sensory module as the head of the robot docks with a target\nactive module. Figure 2.7 shows the four symmetrically distributed yellow round tags for visual\nrecognition in the target (ZHU et al., 2013).\n\nFigure 2.7: UBot target (ZHU et al., 2013).\n\nThe docking approach consists of two phases: pre-positioning preparation and precise position-\ning (ZHU et al., 2013). In the phase of pre-positioning preparation, the sensory module obtains\nvisual information, extracts the features and generates the motion adjustment parameters through\ncomputation in the host PC. Then, the motion module group repeats the process of parameters\n\n10\n\n\n\nadjustment to achieve pre-positioning.\n\nAfter pre-positioning, the linear Hall sensors capture range information and the host calculates\nthe motion ajustment parameters for the docking algorithm.\n\n2.2.3.3 CoSMO\n\nCoSMO (Collective Self-reconfigurable Modular Organism, shown in Figure 2.8) (LIEDKE et\nal., 2013) consists of several uniform building blocks, the CoSMO modules, and was designed by\nthe Institute for Process Control and Robotics, Karlsruhe Institute of Technology (Germany). The\nmodule boundary box is an exact cube with dimensions 105 \u00d7 105 \u00d7 105 mm, weight 1.25 kg and\none DoF. Embedded in the module, there is a battery pack and a PCB with a Micro Controller\nUnit, which scans and preprocesses sensor data.\n\nFigure 2.8: CoSMO (LIEDKE et al., 2013).\n\nThe system also supports proprioceptive sensors (such as Hall sensor, gyroscope, accelerometer\nand motor current sensor) and exteroceptive sensors (such as camera, infrared sensor and micro-\nphone). For docking, one DC gear motor actuates on the hooks for grasping four bolts of other\nrobots docking units. Based on the infrared sensors readings, the docking approach algorithms\nmove the robot exactly as required by the mechanics of the docking unit. In the future, force sen-\nsitive resistors based sensors will aid docking units to measure forces and torques between docked\nrobots.\n\n2.2.3.4 Roombots\n\nThe Roombots system (MOECKEL et al., 2013; BONARDI et al., 2013; VESPIGNANI et\nal., 2013; SPR\u00f6WITZ et al., 2014) (shown in Figure 2.9), designed by the Biorobotics Laboratory\nat \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (Switzerland), focus on building blocks for adaptive\npieces of furniture able to move, self-assemble and self-reconfigure. Two half-spheres linked together\nwith revolute joints forms a 110 mm diameter module weighting 1.4 kg. Each Roombot has three\n\n11\n\n\n\nDoF and is a fully autonomous robot with a 4-cell LiPo battery with autonomy for about 1 hour.\n\nThe user control and configure Roombot modules from a PC using a wireless Bluetooth com-\nmunication module. In addition, slip rings allow the transmission of communication and power\nwithin the modules. In open-loop experiments, there is a PID to controle the position of RB\nmodules through relative position sensors at each joint. However, there are no additional sensors\nfor sensing the alignment of a module with the grid.\n\nFigure 2.9: Roombots (MOECKEL et al., 2013; BONARDI et al., 2013; VESPIGNANI et al.,\n2013; SPR\u00f6WITZ et al., 2014).\n\nEach Roombot module can autonomously connect and disconnect from another module or\ndock to a passive connector embedded in the environment (BONARDI et al., 2013), but there\nare no external sensors for position and orientation in world-coordinates. Therefore, a human\noperator is needed to remotely control the joint movements through relative positions between\njoints (SPR\u00f6WITZ et al., 2014). In the future, absolute encoders are planned to be employed to\ndetect joint backlash, and infrared sensors are devised to be included to give the estimation of\ndistance and alignment of Roombots.\n\n2.2.3.5 Transmote\n\nTransmote (QIAO et al., 2012b; QIAO et al., 2012a) (shown in Figure 2.10) has an aluminum\nbody shell and a hybrid lattice and chain architecture with three DoF. Each module has a dock-\ning mechanism with a male or female connector and can implement an inchworm-like crawling\nlocomotion gait by coordinating the two end joints.\n\nA set of two IR Sensors helps adjusting the robot position to align the male connector to the\nfemale connector, measuring the distance between docking interfaces. According to the character-\nization curves of the IR sensors, the threshold distance for docking is set to 9cm in misalignment\nin pitch and roll is not consider to simplify analysis.\n\n12\n\n\n\nFigure 2.10: Transmote (QIAO et al., 2012b; QIAO et al., 2012a).\n\n2.2.4 ErekoBot\n\nEreko Group is a research group of University of Brasilia with researchers from Mechanical and\nComputer Science departments. The group focus on the development of homogeneous modules\nwith manual reconfiguration for inspection since 2009. The latest published prototype was the\nacrylic-shell ErekoBot ?v.2 module (SOUSA; VIANA; KOIKE, 2013a) with dimensions 50 mm\u00d7\n50 mm\u00d750 mm and weight 100 g (shown in Figure 2.11). For connection, each ErekoBot ?v.2 has\nVelcroTM straps glued to the acrylic structure. This project aimed a small, light and cheap manually\nreconfigurable modular robot.\n\nFigure 2.11: ErekoBot ?v.2 .\n\nIn the embedded electronic circuit, there are two LiPo batteries to power the microcontroller\nand the servo motor. A PWM signal controls the servo motor position through a wired communi-\ncation via USART.\n\n2.3 General Measurement System in SRM Systems\n\nWe define a process as a system that generates information (BENTLEY, 2005), such as tem-\nperature, pressure, velocity, and displacement. The purpose of a measurement system is to link\nthe observer (person who needs the information) to the process. We call the information variable,\n\n13\n\n\n\nwhere the input to the measurement system is the true value; and the output is the measured value\nof the variable. In an ideal measurement system, the measured value is equal to the true value,\nand the accuracy quantifies how close the measured value is to the true value.\n\nIn a given system, there are some types of element may be missing or may occur more than\nonce (BENTLEY, 2005):\n\nSensing element This element gives an output that depends in some way on the measured vari-\nable.\n\nSignal-conditioning element This element takes the output of the sensing element and coverts\nit into a form more suitable for further processing (DC voltage, DC current, frequency signal,\nfor example).\n\nSignal-processing element This element takes the output of the signal conditioning element\nand converts it into a form more suitable for presentation (for instance ADC, DAC).\n\nData representation element This element presents the measured value in a form recognizable\nfor the observer.\n\nAs described in Section 2.2, SRM systems require on-board sensing elements to perform au-\ntonomous exploration of the environment. Therefore, we need to design each module measurement\nstructure. In Section 2.3.1, we discuss characteristics that typical elements possess and their effect\non the overall performance of the system. In addition, we describe some sensing elements tipically\nused in SRM robots for orientation ( Section 2.3.2) and proximity (Section 2.3.3).\n\n2.3.1 Systematic Characteristics\n\nMathematical or graphical tools can be extremely helpful to quantify the relationships which\nmay occur between the output O and input I of an element when I is either at constant value or\nchanging slowly(BENTLEY, 2005). Some characteristics are described as:\n\nRange This characteristic is the minimum and maximum values of I and O (IMIN,IMAX,OMIN\nand OMAX).\n\nSpan This characteristic is the maximum variation in input or output (IMAX?IMIN and OMAX?\nOMIN).\n\nIdeal straight line An element is linear if the corresponding values of I and O lie on a straight\nline. The ideal straight line connects the minimum point A(IMIN,OMIN ) to the maximum\npoint B(IMAX,OMAX ). In common usage, linearity refers to a mathematical relationship\nor function that can be graphically represented as a straight line, as in two quantities that\nare directly proportional to each other, such as voltage and current in a simple DC circuit,\nor the mass and weight of an object. When the relationship differs from that, the system is\nsaid to be non-linear.\n\n14\n\n\n\nSensitivity This is the change ?O in output O for unit change ?I in input I, i.e. it is the ratio\n?O\n?I\n\n.\n\nEnvironmental effects In general, the output also depends on environmental inputs, such as\ntemperature, pressure, humidity, supply voltage. There are two main types of environmental\ninputs: a modifying input and an interfering input. A modifying input causes the linear\nsensitivity of an element to change and an interfering input causes the straight line intercept\nor zero bias to change.\n\nHysteresis The output may change depending on whether the input is increasing or decreasing.\nHysteresis is the dependence of the output of a system not only on its current input, but also\non its history of past inputs. The dependence arises because the history affects the value of\nan internal state.\n\nResolution Some elements are characterized by the output increasing in a series of discrete steps\nin response to a continuous increase in the input. Resolution is the largest change in the\ninput that can occur without any corresponding change in the output.\n\nCalibration An element is calibrated by measuring and comparing values of the input I, the\noutput O, the environmental input IM and the environmental output OM, when I is either\nat a constant value or changing slowly (BENTLEY, 2005). The accuracy of a measurement\nof a variable is the closeness of the measurement to the true value of the variable. We can\nquantify it by terms of measurement error (the difference between the measured value and\nthe true value).\n\nAccuracy and Precision Accuracy is a measure of how close to the actual value a measurement\nis. Precision is a measure of how close each measurement is to each other.\n\nLookup table A lookup table (LUT) is an array that replaces runtime computation with a simpler\narray indexing operation.\n\n2.3.2 Rotation Motion sensors\n\nRotation sensors measure angular motion of a body about some rotation axis, providing atti-\ntude and orientation information commonly used in military, aerospace, industrial, medical and\nconsumer areas (MORRIS, 2001). The main factors for choosing a sensing element for a specific\napplication includes the analysis of sensibility, size, cost and resolution.\n\nThere are various devices available for measuring rotation, but the most used in SRM robots\nare accelerometers (Section 2.3.2.1) and gyroscopes (Section 2.3.2.2).\n\n2.3.2.1 Accelerometer\n\nAcceleration is an inert physical characteristic of any system, and control systems often use\nthese measurements (in m/s2) to correct dynamic conditions. An accelerometer is a device able\nto measure linear acceleration, local gravitational field, tilt and shocks as well as vibration.\n\n15\n\n\n\nGenerally, an accelerometer consists of a proof mass suspended by compliant beams anchored\nto a fixed frame. The proof mass has a mass of m, the suspension beams have an effective spring\nconstant stiffness k and there is a damping factor b affecting the dynamic movement of the mass\ngenerated by the air-structure interaction.\n\nA second-order Mass-Damper-Spring system, as shown in Figure 2.12, models the accelerome-\nter: an external acceleration displaces the support frame, which in turn changes the internal stress\nin the suspension spring. When an external force Fexternal acts at the accelerometer, the proof\nmass develops a force given by D\u2019Alembert inertial force Finertial = ma(t) (MORRIS, 2001), where\nm is the mass of the system and a(t) the acceleration. This force also displays the spring by a\ndistance x(t), generating a damping Fdamping and a spring force Fspring. Hence the total force\nexternally balance is the sum of internal forces:\n\nFexternal = Finertial + Fdamping + Fspring.\n\nFigure 2.12: Accelerometer mass-spring-damper model.\n\nThe following second-order differential equation gives the dynamic equation of the vibration\nsystem (MORRIS, 2001):\n\nma(t) = m\nd2\n\ndt2\nx(t) + b\n\nd\n\ndt\nx(t) + kx(t).\n\nUsing Newton\u2019s second law and the accelerometer model, we obtain the mechanical transfer\nfunction\n\nH(s) =\nX(s)\n\nA(s)\n=\n\nm\n\nms2 + bs + k\n=\n\n1\n\ns2 + 2??rs + ?2r\n, (2.1)\n\nwhere ?r =\n?\n\nk\nm\n\nis the natural frequency and ? = b\n2\n?\nkm\n\nis the damping ratio.\n\nAlthough Equation (2.1) rules its operation, there are still various types of accelerometers,\nbased on materials and principles of operation, as shown below.\n\nCapacitive There are two plates in the capacitor with sense electrodes, only one of them is fixed.\nWhen acceleration acts, it moves the non-moving plate and consequently causes a change in\nthe capacitance between them and the sensor measures acceleration differences accordingly.\nCapacitive sensors have important advantages compared to other types of inertial sensors.\nThey have simple structure and hence low fabrication cost. In addition, they provide low\npower consumption, high sensitivity, and high reliability as well as low nonlinearity, low\n\n16\n\n\n\ntemperature dependency, low noise, and low drift (ER??M??, 2004).\n\nHall Effect Changes in the magnetic field result in voltage variations, causing the Hall Effect\n(MORRIS, 2001). With a proof mass integrated at a semiconductor material, it is possible\nto measure the output of the hall element, which varies according to the applied force because\nof the consequent variation in the sensed magnetic field.\n\nPiezoelectric The Piezoelectric Effect is the increase of electricity (or electric) polarity by apply-\ning a mechanical stress to certain crystals, because their asymmetrical lattice of molecules\ndistorts when a force is applied (MORRIS, 2001). With a proof mass attached to a crystal,\nit is possible to measure the output voltage differences due to the acceleration.\n\nPiezoresistive When strained, some metals changes its own electrical resistivity, which is called\nthe Piezoresistive Effect (MORRIS, 2001). With a proof mass attached to this type of\nmaterial, it is possible to measure the resistance difference generated due to the acceleration.\n\nIn 1989, Prof. R. Howe from Stanford University described a special type of technology, the Mi-\ncro Eletromechanical Systems technology (MEMS), which consists of devices with features smaller\nthan 100 \u00b5m. The most notable elements from this technology were the micro sensors, which not\nonly were small, but also demonstrated performances exceeding the macro scale counterparts.\n\nThe most common MEMS accelerometers are capacitive because of its high sensitivity and\nresistance through temperature (LEE et al., 2005). As the micro scale type, they contain a movable\nproof mass with plates (capacitors) attached through a mechanical suspension system to a reference\nframe. With the changes at the capacitance, it is possible to know the deflection and acceleration\nof the proof mass.\n\n2.3.2.2 Gyroscope\n\nGyroscopes measure both absolute angular displacement and absolute angular velocity, based\non the principle of conservation of angular momentum. As can be seen in Figure 2.13, a gyroscope\nis essentially a spinning disk that rotates about the x, y and z axes (MORRIS, 2001), and, once\nthe device spins, it tends to resist changes to its orientation due to the angular momentum of the\nwheel.\n\nThe unsupported end of the rotating gyroscope does not fall, but it starts to move in circular\npath about the vertical axis. There are two forces in this system, a normal force n, acting upwards\nat the pivot, and a downward gravitational force mg (JENSEN, 2011). The gravitational force\nproduces a torque ? = mgh, which relates, by definition, to the angular momentum M as\n\n? =\ndM\n\ndt\n. (2.2)\n\nEquation (2.2) states that the torque produces a change in angular momentum dM, which are\nin the same direction as ? and perpendicular to M. In summary, the gyroscope spins about one\n\n17\n\n\n\naxis, the gravitational force creates a torque about a second axis, and, as a result, the gyroscope\nrotates about a third axis. We call this motion the Precession Motion, and its effect the Gyroscope\nEffect.\n\nFigure 2.13: Gyroscope (Figure from (JENSEN, 2011)). n is a normal force acting upwards at\nthe pivot O; mg is a downward gravitational force that produces a torque ? related to the angular\nmomentum M.\n\nIn a time interval dt, the axis rotates an angle d, as the magnitude of Mi ? Mf ? M remains\nthe same, angular velocity can be calculated from the vector diagram shown in Figure 2.14\n\nsin (d?) ? d? =\ndM\n\nM\n=\n?dt\n\nM\n=\n\n(mgh)dt\n\nM\n.\n\nFigure 2.14: Vector diagram for a gyroscope.\n\nAssuming small rotations sin (d?) ? d? and dividing by dt ? 0, we describe the relation\nbetween torque ? = mgh, angular momentum M and procession motion velocity ?p as\n\n?p =\nd?\n\ndM\n=\nmgh\n\nM\n. (2.3)\n\nEquation (2.3) is useful to analyze the structural systems affected by gyroscope effects.\n\nThere are mainly two kinds of gyroscope: mechanical, depicted in Figure 2.15 and optical,\nillustrated in Figure 2.16.\n\n18\n\n\n\nMechanical It consists essentially of a rotor driven wheel whose angular momentum is high\nenough to maintain the axis of rotation fixed in space, thus acting as a reference point (inner\nring) (MORRIS, 2001). The inner ring is attached to the body whose motion it is desired to\nmeasure (frame). The output is the angle between the frame and the outer ring.\n\nOptical It works with light beams instead of wheels, which results in high performance although\nit is rather difficult to fabricate. The major advantages of optical gyroscopes are that they\nare immune to electromagnetic interference and they can operate at high temperatures (ER-\n??M??, 2004). There are many types of optical gyroscopes, such as the ring laser, shown\nin Figure 2.16a, and the fibre-optic, presented in Figure 2.16b, both of them measuring the\ntime and position of the beams of light and tubes. The ring laser gyroscope consists of laser\ngain tubes, mirror glasses and anode/cathodes that generate the laser beams. Any rotation\nof the systems changes the coherence of the beams, raising one and lowering the other. In\nthe fibre-optic (Figure 2.16b), there are incident light from a source separated by a beam\nsplitter into a pair of beams a and b. These beams travel in opposite directions around an\noptic-fibre coil and emerge from the coil marked as a? and b?: any motion of the coil causes\na phase shift between a? and b? detected by the interferometer (ER??M??, 2004).\n\nFigure 2.15: Mechanical Gyroscope.\n\nIn the last decade, industry opted for the MEMS gyroscopes, which are extremely small and\naccurate for applications of orientation and tilting. This technology, with vertically driven vibrating\nmasses, produces a functionally complete, low-cost motion sensor.\n\n19\n\n\n\n(a) Ring Laser Gyroscope. (b) Fibre-Optic Gyroscope.\n\nFigure 2.16: Optical Gyroscope (Figures from (MORRIS, 2001)).\n\n2.3.3 Translational Displacement Sensors\n\nTranslational displacement sensors detect the motion of a body in a straight line between two\npoints using electromagnetic fields, light, and/or sound without any physical contact (MORRIS,\n2001). Usually, a translational displacement sensor emits an electromagnetic field or a beam of\nelectromagnetic radiation and search for changes in the field or in the returned signal.\n\nAs in the case of orientation sensors, it is necessary to analyze sensibility, size, cost and resolu-\ntion when choosing a translational displacement sensor for specific applications and environments.\n\nSome techniques for measuring large translational displacements exist and measure motions of\na body with respect to some fixed initial point. Range sensors provide a well-used technique of\nmeasuring the translational displacement of a body with respect to some fixed boundary. Figure\n2.17 illustrates how range sensors work.\n\nRange sensing systems consists of an energy source, an energy detector and electronic means of\ntiming the time of flight of the energy between the source and detector. The form of energy used\nis either ultrasound or light. In some systems, both energy source and detector are fixed on the\nmoving body and operation depends on the energy being reflected back from the fixed boundary\nas in Figure 2.17a. In other systems, the energy source is attached to the moving body and the\nenergy detector within the fixed boundary, as shown in Figure 2.17b.\n\n2.3.4 Filters\n\nSignal filtering consists of processing a signal to remove a certain band of frequencies within\nit (MORRIS, 2001). The band removed can be either at the low-frequency band (low-pass filter,\nFigure 2.18a) or at the high-frequency band (high-pass filter, Figure 2.18b), at both bands (band-\npass filters, Figure 2.18c), or in the middle (band-stop filters, Figure 2.18d). Either analogue or\n\n20\n\n\n\n(a) Energy source and detector fixed on the moving body.\n\n(b) Energy source attached to the moving body and detector to the fixed\nboundary.\n\nFigure 2.17: Range Sensors (Figures from (MORRIS, 2001)).\n\n21\n\n\n\ndigital methods can filter signals.\n\n(a) Low-pass filter. (b) High-pass filter.\n\n(c) Band-pass filter. (d) Band-stop filter.\n\nFigure 2.18: Outputs from filters (Figures from (MORRIS, 2001)).\n\nAn analogue filter is an electrical network, consisting usually of resistors, capacitors and op-\nerational amplifiers, which conditions continuous signals; and a digital filter is usually a digital\ncomputer programmed to process sampled values of a signal (BENTLEY, 2005).\n\nSince single results of sensors lack of accuracy, there are filters that combines the outputs of\ngyroscope and accelerometer. The Complementary Filter is an estimation technique widely used\nin robotics to combine measurements (Section 2.3.4.1). This filter is actually a Kalman Filter\nat steady state (Wiener filter) (KOVVALI; BANAVAR; SPANIAS, 2013) for a class of filtering\nproblems (HIGGINS, 1975). Users of the Complementary Filter disregard statistical descriptions\nof the noise and obtain its filter by a simple analysis in the frequency domain. On the other\nhand, users of the Kalman Filter work in the time domain and disregard the transfer function or\nfrequency domain approach to the filtering problem.\n\n2.3.4.1 Complementary Filter\n\nUsually, we call Complementary Filter any digital algorithm used to blend or merge similar or\nredundant data from different sensors to achieve a robust estimate of a single state variable. In\naddition, while filters usually act on the signal, the complementary filter acts only on the different\nkinds of noise associated with different kinds of measurements of the same signal.\n\nAssume a typical system with two inputs, where one input gives information with a high\nfrequency noise, and then goes through a low frequency filter. In addition, a second input gives\n\n22\n\n\n\ninformation with a low frequency noise, and then goes through a high frequency filter. If the\nfilters are mathematically complementary, the filter output is a complete reconstruction from the\nmeasurement variable without the noise (GLASSER, ). Figure 2.19 illustrates this process with a\nperfect low pass filter and a perfect high pass filter.\n\nFigure 2.19: Signals from a complementary filter (Figure from (GLASSER, )).\n\nAs the Complementary Filter is a filter in the frequency domain, it uses two or more transfer\nfunctions that are mathematically complementary to one another. Then, if G(s) is associated to\na sensor, and I ?G(s) is associated to another sensor, then the sum of the transfer functions is I\n(the identity matrix).\n\nIt can be seen in Figure 2.20 a basic complementary filter, where x and y are measurements\nfrom z with noise, and z? is the estimate value from z.\n\nFigure 2.20: A basic complementary filter (Figure from (HIGGINS, 1975)).\n\nConsidering that n1 is the noise that acts on signal x and n2 on y, the filter can also be set\nas shown in Figure 2.21. In this case, the input for G(s) is y ?x = n2 ?n1, therefore, G(s) only\noperates at the noise or error from x and y.\n\nFigure 2.21: Alternative complementary filter block diagram (Figure from (HIGGINS, 1975)).\n\nA typical example of application is the fusion between vertical acceleration and barometric\nvertical velocity measurements to obtain an estimate of vertical velocity. The acceleration mea-\nsurement h?a is integrated producing a signal h?a, and this integration attenuates the high-frequency\n\n23\n\n\n\nnoise, whereas the noise in h?b remains the same. Figure 2.22 illustrates the process of filtering h?b\nwith the low-pass filter\n\nG(s) =\n1\n\n?s + 1\n\nand h?a with the high-pass filter\n\n1 ?G(s) = 1 ?\n1\n\n?s + 1\n=\n\n?s\n\n?s + 1\n.\n\nFigure 2.22: Complementary filter estimating vertical velocity (Figure from (HIGGINS, 1975)).\n\n2.4 Orientation: Euler Angles\n\n2.4.1 Euler angles\n\nEuler angles describe rotation as a sequence of rotations about three mutually orthogonal\ncoordinate axes fixed in space. These axes may be world or local coordinates, where rotations act\non points in the space (USTA, 1999). The coordinate axes remain fixed, and subsequent rotations\nhave the effect of rotating the axes about the preceding rotations. There are six possible ways to\norder three sequential rotations on different axes, different rotations lead to different orientations.\n\nEuler angles method defines the rotation on three body fixed orthogonal axes by extending 2D\nrotations to 3D for each axis. Figure 2.23 shows Euler angles rotations and Equations (2.4), (2.5)\nand (2.6) represent individual rotation matrices.\n\nFigure 2.23: Rotation in 2D (Figure from (USTA, 1999)).\n\n24\n\n\n\nRx(?) =\n\n?\n?? 1 0 00 cos ? ?sin ?\n\n0 sin ? cos ?\n\n?\n?? (2.4)\n\nRy(?) =\n\n?\n?? cos ? 0 sin ?0 1 0\n?sin ? 0 cos ?\n\n?\n?? (2.5)\n\nRz(?) =\n\n?\n?? cos ? ?sin ? 0sin ? cos ? 0\n\n0 0 1\n\n?\n?? (2.6)\n\nMatrix multiplication of these matrices produces rotation matrices for multiple rotations. It is\nimportant to notice that different sequences result in different rotation matrices.\n\n2.4.1.1 Gimbal Lock\n\nGimbal lock is the loss of one degree of freedom in a three-dimensional, three-gimbal mechanism\nthat occurs when the axes of two of the three gimbals are driven into a parallel configuration, locking\nthe system into rotation in a degenerate two-dimensional space. There are two common situations\nof Gimbal lock:\n\n\u2022 When is not possible to represent the orientation of the sensor using Euler Angles. The exact\norientation at which gimbal lock occurs depends on the order of rotations used (Equations\n(2.4), (2.5) and (2.6) ). It may occur that, after some operations, two axes may stay align,\nlocking the system into rotation in a degenerate two-dimensional space, losing one degree of\nfreedom. One way to avoid the Gimbal Lock is to use quaternions for representing rotations\nin 3D space.\n\n\u2022 In gyroscopes, gimbal lock may occur when vehicle rotation causes two of the three gimbal\nrings to align with their pivot axes in a single plane. When this occurs, it is no longer possible\nto maintain the sensing platform\u2019s orientation.\n\n2.5 Summary\n\nThis chapter has described pipeline inspection and the latest pipeline robots. Also, it was\npresented the problem of flexibility and, in contrast to the classical solutions using rigid structures,\nthe idea has arisen of using SRM robots, which are capable, at any moment, of changing their shape\nto be able to move in the most efficient way.\n\nTo sum up, the chapter mentioned important definitions and concepts of general measure-\nment system, using systematic characteristics to describe some rotation motion and translational\n\n25\n\n\n\ndisplacement sensors. The specific sensors in which this work is interested are accelerometer, gyro-\nscope and IR sensors. These sensors need filters for processing their information in order to allow\nsome robot tasks. In order to calculate the orientation pose of the modular robot, definitions and\nconcepts of the orientation technique using Euler angles were also presented.\n\nAlthough other investigators have constructed prototypes of SRM robots, up to now there are\nfew works with the construction of a low-cost module with cheap sensors and simple algorithms\nfor alignment with an external plane.\n\n26\n\n\n\nChapter 3\n\nConceptual Design and Modelling\n\n3.1 Introduction\n\nAfter the research background presented in Chapter 2, this chapter deals with concepts and\nmodels employed for the study of sensing in SRM robotics. Section 3.2 presents the concept of the\nErekoBot ? introduced and, then, Section 3.3 demonstrates the fundamental measurement system\nmodels: attitude, distance and filtering. Section 3.4 proposes the Alignment Algorithm using the\nresponse from IR sensors and IMU. Finally, the conclusion will establish the relationship between\nall of these and propose a solution to the sensory problem in SRM robotics.\n\n3.2 Conceptual Design of ErekoBot ?\n\nThe conception, design and manufacturing of a robotic platform specific for a task consumes\na lot of time and resources, and the resulting robot is obviously very expensive. Therefore, there\nis a comprehensible concern about its integrity: it is usual to make it robust to support hazard\nenvironments, which makes them even more expensive. In order to reduce the impact of these\nconcerns, the ErekoBot ? was conceived to be a simple and robust Reconfigurable Modular Robot\nwith embedded sensors suitable for pipeline inspection. The important contribution of this work\nregarding SRM robotics is the addition of an inexpensive but efficient measurement system, making\nit less expensive than the robots presented in Sections 2.1 and 2.2. This work focus on sensing\nimprovements of the ErekoBot ?v.2 , and therefore, the robot is still manually reconfigurable (for\ntotal self-reconfigurability the type of connection, locomotion and algorithms of reconfigurability\nneed to be upgraded).\n\nFor simplicity, the module is represented as shown in Figure 3.1: two segments (or linkages)\nwith total length L and mass m. A joint links both segments, determining a bending angle (?),\nwhich is restricted in the interval [?90, 90] degrees (typical of commercial servos).\n\nConsider a snake robot, composed of modules manually configured by a user, and inspecting a\npipeline, as shown in Figure 3.2. When ErekoBot ? system finds a possible point of failure, with\n\n27\n\n\n\nFigure 3.1: Wired model of the module.\n\na camera for example, the robot needs to align itself with the pipeline internal walls and make a\ncomplete inspection of the area.\n\nFigure 3.2: ErekoBot ? example of application.\n\nEach ErekoBot ? must have the ability to (1) detect an obstacle (Figure 3.3a), (2) align with\na plane simulating a pipeline (Figure 3.3b) and (3) estimate its own pose (Figure 3.3c).\n\nThe basic parameters whose requirements were necessary for the module design are shown in\nTable 3.1. These requirements are in accordance with ErekoBot ?v.2 described in Section 2.2.4\n\nThe 3D-model was designed by Ricardo Diniz Caldas, including microcontroller, servomotor\n\n28\n\n\n\n(a) (b) (c)\n\nFigure 3.3: ErekoBot ? requirements.\n\nParameter Requirement\nDimensions bigger than 50 mm \u00d7 50 mm \u00d7 50 mm\n\nMicrocontroller AVR ATMega series\nNumber of DoF 1 (rotational 180?)\n\nMotor Servo motor\n\nTable 3.1: Basic requirements for ErekoBot ? design.\n\nand sensors (Figure 3.4).\n\nFigure 3.4: ErekoBot ? 3D model.\n\n3.3 Instrumentation Model\n\nSection 3.3.1 presents a method to calculate the attitude of a body with few calculations, and it\nis proposed here that these calculations be based on gyroscope and accelerometer response from an\nInertial Measurement Unit (IMU). In addition, a filter is proposed to combine the angles resulting\n\n29\n\n\n\nfrom the gyroscope and accelerometer (Section 3.3.1.3). Finally, Section 3.3.2, proposes a fusion\nprocessing technique of data measured through the IR sensors within a limited range.\n\n3.3.1 Attitude Estimation\n\nThe Euler angles are calculated from the gyroscope and accelerometer readings based on equa-\ntions of the Rotation Matrices, presented at Section 2.4.1. The attitude estimator is a filter that\ncombines the different angles (from the gyroscope and accelerometer) into one filtered angle (Sec-\ntion 3.3.1.3), and is estimating the roll and pitch angles.\n\nThe ErekoBot ? reference frame is the body frame denoted with a subscript b. The navigation\nframe is a fixed frame denoted with a subscript n, as showed in Figure 3.5.\n\nFigure 3.5: Frames with positive axes and torques.\n\nA rigid body can be placed in an arbitrary orientation by first rotating it about its z-axis by an\nangle ? (azimuth or yaw rotation), then about its y-axis by an angle ? (elevation or pitch rotation),\nand finally about its x-axis by angle ? (bank or roll rotation).\n\n3.3.1.1 Gyroscope Model\n\nThe ideal gyroscope gives the raw measurements values ~gb = [gx,gy,gz]T in LSB (Least Sig-\nnificant Bit unit), this data (Gyroscale) is scaled to convert to angular velocities in rad/s (MAG-\nNUSSEN; OTTESTAD; HOVLAND, 2013):\n\n~?b =\n\n?\n?? ?x?y\n?z\n\n?\n?? =\n\n?\n?? gxgy\ngz\n\n?\n??Gyroscale.\n\nMaking a numerical integration of the gyroscope measurements results in\n\n30\n\n\n\n?gyrot = ?gyrot?1 + ?x?t, (3.1)\n\n?gyrot = ?gyrot?1 + ?y?t (3.2)\n\nand\n\n?gyrot = ?gyrot?1 + ?z?t, (3.3)\n\nwhere ?gyrot, ?gyrot and ?gyrot are angles in the iteration t; ?gyrot?1, ?gyrot?1 and ?gyrot?1 are angle\nin the iteration t ? 1; ?x, ?y and ?z are angular velocities measurements in x, y and z by the\ngyroscope; and ?t is the sample time between each iteration.\n\nThe initial values ?gyro0, ?gyro0 and ?gyro0 have to be set to arbitrary normalized angles, i.e.\n[0? 0? 0?]T , or to initial angles values from the accelerometer - which results in more correct initial\nvalues.\n\n3.3.1.2 Accelerometer Model\n\nThe accelerometer values describes the body orientation vector relative to the gravity in the\nnavigation frame, given a steady state of the movement. Sudden movements may affect the ac-\ncelerometer with other forces and give a false reading of the gravity vector.\n\nThe measured acceleration vector in the body coordinate system is\n\n~a =\n\n?\n?? axay\naz\n\n?\n?? .\n\nA three-axis accelerometer mounted in a body oriented in the earth gravitational field will have\noutput Gp given by\n\n~Gp =\n\n?\n?? GpxGpy\nGpz\n\n?\n?? = ~R(~g ?~a) = ~R~g = ~R\n\n?\n?? 00\n\n1\n\n?\n?? , (3.4)\n\nwhere ~R is the rotation matrix describing the orientation of the module relative to the earth\ncoordinate frame and ~g the gravitational field. It is assumed that the module has no linear\nacceleration (or it is small enough to be approximated to zero) and that its initial orientation is\naligned with the z axis of the gravitational field, therefore ~a = [000]T . To define the roll, pitch and\nyaw rotations from an initial position, the matrices defined in Equations (2.4), (2.5) and (2.6) in\nSection 2.4.1 are employed. We also consider ~g = [001]T , using units of g.\n\nTherefore, there are six possible rotations (as demonstrated in Appendix I.1). A direct con-\n\n31\n\n\n\nsequence for these differences is that roll, pitch and yaw rotation angles are meaningless without\nfirst defining the order in which we applied the rotations (PEDLEY, 2013).\n\nFour sequences can be immediately rejected: the system has only two degrees of freedom since\nthe vector magnitude must always equal 1 in the absence of a linear acceleration. It is not possible\nto solve for three unique values of roll, pitch and yaw angles.\n\nAll accelerometers are completely insensitive to rotations about the gravitational field vector,\nand it cannot be used to determine the yaw rotation. Therefore, it is conventional to select either\nthe rotation sequence Rxyz (Equation (3.5)) or Ryxz (Equation (3.6)) to eliminate the yaw rotation\n(PEDLEY, 2013).\n\n~Rxyz\n\n?\n?? 00\n\n1\n\n?\n?? = ~Rx(?) ~Ry(?) ~Rz(?)\n\n?\n?? 00\n\n1\n\n?\n?? =\n\n?\n?? ?sin ?cos ? sin ?\n\ncos ? cos ?\n\n?\n?? (3.5)\n\n~Ryxz\n\n?\n?? 00\n\n1\n\n?\n?? = ~Ry(?) ~Rx(?) ~Rz(?)\n\n?\n?? 00\n\n1\n\n?\n?? =\n\n?\n?? ?sin ? cos ?sin ?\n\ncos ? cos ?\n\n?\n?? (3.6)\n\nThe Equation (3.5) can be rewritten in the form\n\n~Gp\n||Gp||\n\n=\n\n?\n?? ?sin ?cos ? sin ?\n\ncos ? cos ?\n\n?\n?? ? 1?\n\nG2px + G\n2\npy + G\n\n2\npz\n\n?\n?? GpxGpy\nGpz\n\n?\n?? =\n\n?\n?? ?sin ?cos ? sin ?\n\ncos ? cos ?\n\n?\n?? , (3.7)\n\nrelating the roll ? and pitch ? angles to the normalized accelerometer reading Gp. Solving for roll\nand pitch angles, it is obtained\n\ntan (?xyz) =\nGpy\nGpz\n\n(3.8)\n\ntan (?xyz) =\n?Gpx\n\nGpy sin ? + Gpz cos ?\n=\n\n?Gpx?\nG2py + G\n\n2\npz\n\n(3.9)\n\nThe Equation (3.6) can be rewritten in the form\n\n~Gp\n||Gp||\n\n=\n\n?\n?? ?sin ? cos ?sin ?\n\ncos ? cos ?\n\n?\n?? ? 1?\n\nG2px + G\n2\npy + G\n\n2\npz\n\n?\n?? GpxGpy\nGpz\n\n?\n?? =\n\n?\n?? ?sin ? cos ?sin ?\n\ncos ? cos ?\n\n?\n?? , (3.10)\n\nrelating the roll ? and pitch ? angles to the normalized accelerometer reading Gp. Solving for roll\nand pitch angles, it results\n\n32\n\n\n\ntan (?yxz) =\nGpy?\n\nG2px + G2pz\n, (3.11)\n\ntan (?yxz) =\n?Gpx\nGpz\n\n. (3.12)\n\nThe subscripts xyz and yxz denote the specific rotation employed to compute the angles.\n\nEquations (3.8) to (3.12) have an infinite number of solutions at multiples of 360?. The range\nof the roll angle will be restricted to ?180? to 180? and the pitch angle to ?90? to 90? for the Rxyz\nrotation.\n\nFor convenience, the accelerometer outputs are normalized to unit vectors: ~?a denote the nor-\nmalized vector of the acceleration measurements,\n\n~?a =\n~a\n\n|a|\n=\n\n?\n?? a?xa?y\na?z\n\n?\n?? ,\n\nwhere |a| is the norm of the acceleration vector ~a.\n\n3.3.1.3 Filter Model\n\nA complementary filter is proposed to combine two different angles, resulting from the gyroscope\nand accelerometer (angleg and anglea), into one filtered result to estimate roll and pitch angles\n(MAGNUSSEN; OTTESTAD; HOVLAND, 2013).\n\nThe gyroscope provides an angle with fast and smooth updates. The result calculated is a\nrotation from its initial position based on angular velocities; therefore, it is independent from the\nfixed reference frame. However, angleg drifts over time if not compensated.\n\nThe accelerometer always has a fixed reference frame: the navigation frame. However, the\naccelerometer is sensitive to noise and airframe vibrations and is not able to estimate the attitude\nas smooth and fast as the gyroscope.\n\nThe proposed filter combines angleg with anglea and compensate for both drifting and noise.\nAs angleg starts to drift, it will be significant different from anglea. We have to rotate angleg back\ntowards anglea, however, since anglea has a lot of noise, angleg should only be rotated enough\nto compensate for the drifting. A simple way of doing it is to compare angleg and anglea by\ncalculating the difference anglee:\n\nanglee = anglea ?angleg,\n\nwhere anglee is the correction needed to be added to angleg in order to become anglea. The\namount to rotate depends on a scaling factor Perr, so that at each cycle the estimated angle\nbecomes:\n\n33\n\n\n\nangle = angleg + Perr angle\ne\n\nangle = angleg + Perr (angle\na ?angleg)\n\nangle = angleg \u00b7 (1 ?Perr) + anglea \u00b7Perr (3.13)\n\nwhere it is necessary to set Perr ? [0, 1] as low as possible to reduce the noise from the accelerom-\neter, but high enough to correct the drifting of the gyroscope. Setting Perr = 0 eliminates the\naccelerometer and Perr = 1 eliminates the gyroscope.\n\nThe value of Perr depends on factors such as gyroscope bias, cycle time of the system, ac-\ncelerometer noise, etc. It is possible to find the initial value of Perr by monitoring the estimated\nangles with no movement: Perr is reduced until the estimated angle starts to drift. Figure 3.6\nshows the block diagram of the filter.\n\nFigure 3.6: Block diagram of the attitude estimator (Figure adapted from (MAGNUSSEN;\nOTTESTAD; HOVLAND, 2013)).\n\nThe block acc2euler converts the accelerometer values from the accelerometer using Equations\n(3.8) and (3.9).\n\n3.3.2 Distance Estimation\n\nIn order to position one face of the module parallel to a surface, this work proposes a method\nthat adjusts the normal directions of the ErekoBot ? with respect to the surface of the object by\ndetecting the error in the object attitude, using just IR sensors.\n\nConsider the case where the surface of the object is larger than the surface of the ErekoBot ? ,\nas shown in Figure 3.7. When the surface of the object is sufficiently larger than the surface of the\nsensor, and this relationship holds even if the sensor surface has a constant curvature, the attitude\noutput is equivalent to position output, and it is feasible ou reasonable to correct to attitude error.\n\n34\n\n\n\nFigure 3.7: Sensor output depending on object attitude (Figure adapted from (YE et al., 2013)).\n\n3.4 Alignment Algorithm\n\nAt each loop, the ErekoBot ? repeats the sequence:\n\n1. Read the orientation of the rod at time t;\n\n2. Read the objects distance at time t;\n\n3. Send the orientation, distance and t to the host;\n\n4. If the distance is different, move the servo motor to align, reducing the distance difference;\n\n5. Add 1 to t and returns to step 1.\n\nAbove, the orientation is six degrees orientation readings from the gyroscope and accelerometer,\nthe distance is the distances readings from the four IR sensors and t is the current time.\n\nThe host converts the IMU readings into angles and applies the complementary filter from\nSection 3.3.1.3. With the orientation angles and IR response, we can visualize at the screen the\nprocess of alignment.\n\n3.5 Conclusions\n\nSimplicity and robustness characterize the ErekoBot ? conceptual design, which avoids high\ncosts, both in materials and processing. A module is represented as two segments lines, and these\n\n35\n\n\n\nlines connected in a 3D coordinate frame represent the complete reconfigurable modular robot.\n\nSome basic parameters (such as dimensions, type of microcontroller and motor and number\nof degrees of freedom) were defined in order to start manufacturing a robot that follows its three\nmain requirements.\n\nWhen estimating the robot pose, it is proposed an attitude model using Euler angles with one\ngyroscope and one accelerometer. As gyroscopes and accelerometers have different and comple-\nmentary advantages and disadvantages, a complementary filter is applied to combine these data\nfor better response. For alignment, a method is proposed to change the ErekoBot ? position while\nthe IR sensors are unaligned with the plane.\n\nFrom these conceptual design and models, the ErekoBot ? was designed and, then, algorithms\nfor alignment were implemented and tested (Chapter 4).\n\n36\n\n\n\nChapter 4\n\nModule Design\n\n4.1 Introduction\n\nAs described in Chapter 1, the aim of this work is to develop a reconfigurable modular robot\nwith sensors for pipeline inspections. This chapter shows the efforts made to construct the concep-\ntual design of ErekoBot ? presented in Section 3.The selection of the sensor is described in depth in\nSection 4.2, as the electronic design is discussed in Section 4.3 and the mechanical design detailled\nin Section 4.4.\n\nFigure 4.1 illustrates in detail the flowchart used in the phases of designing and manufacturing\nof ErekoBot ? : the choice of the sensors , the microcontroller and communication hardware, the\nintermodular connection, the electronic devices, the servo motor, the materials and the power\nsupply are made with the help of a careful analysis if the final weight was acceptable. All the\npieces of the module interfere at the final weight, but only the pieces with higher influence were\nanalyzed. Finally, the pieces were manufactured and the parts assembled.\n\n4.2 Sensors Selection\n\nWhen choosing the sensors, the ErekoBot ? requirements, described in Section 3.2, were ana-\nlyzed: (1) detect an obstacle (Figure 3.3a), (2) align with a plane (Figure 3.3b) and (3) estimate\nits own pose (Figure 3.3c).\n\nConsidering that the ErekoBot ? needs to detect obstacles at its front and its back, at least two\ntranslational displacement sensors are necessary, one at each side. However, the second requirement\ninvolves at least one more translational displacement sensor at each side for the distance estimator\nmodel described in Section 3.3.2. Finally, for the third requirement, ErekoBot ? needs rotation\nmotion sensors attached to its mobile piece.\n\nTherefore, 4 Infrared Sensors (IR Sensors) SHARP GP2Y0A41SK0F were choosen (Figure\n4.2a). One of the strong points of these sensors is that the environmental temperature and operating\nduration do not influence this sensor unit. The voltage output is proportional to the detection\n\n37\n\n\n\nFigure 4.1: Flow chart for the ErekoBot ? design (Blue: Electronic Design; Green: Mechanical\nDesign.).\n\n38\n\n\n\ndistance (SHARP, 2002).\n\nIn addition, an inertial measurement unit (IMU) was selected, with one accelerometer ADXL345\n(Analog Devices Inc, 2009) and one gyroscope ITG-3200 (INVENSENSE, 2010). This unit (Figure\n4.2b is tiny, with two mounting holes and it communicates though Inter-Integrated Circuit (I2C)\ninterface1.\n\nThese sensors were elected mainly because of their repeatability, temperature stability, design\nflexibility, low cost, low power usage and, most of all, because of their small size.\n\n(a) SHARP GP2Y0A41SK0F. (b) ADXL345 and ITG-3200.\n\nFigure 4.2: ErekoBot ? sensors.\n\n4.3 Eletronic Design\n\nThe electronic design consists in selecting the microcontroller and the communication architec-\nture, as well as the possible types of power supply for each ErekoBot ? .\n\n4.3.1 Microcontroller\n\nInside each module, the microcontroller controls communications, servomotor positions and\nsensors response. The criteria employed to decide upon a microcontroller are: number of pins, size\nof program memory, low-power consumption, low price and availability purchase in our country.\n\nThe ErekoBot ?v.2 uses an Atmel R\u00a9 AVR R\u00a9 ATmega8 , however the size of the program memory\n(8 Kbytes) was found to be insufficient for the sensors response, mainly because of the floating\npoint number library. Therefore, another microcontroller from the same family was adopted, the\nAtmel R\u00a9 AVR R\u00a9 ATmega32 (8-bit RISC CPU, 32KB, 16MHz, USART communication and I2C\ninterface), as illustrated in Figure 4.3a. The number and positions of pins are the same for both\n\n1I2C is a serial protocol for two-wire interface to connect low-speed devices like microcontrollers, EEPROMs,\nA/D and D/A converters, I/O interfaces and other similar peripherals in embedded systems.\n\n39\n\n\n\nmicrocontrollers, which simplifies the changes in the electronic design (ATMEL, 2011).\n\nThe Atmel R\u00a9 AVR R\u00a9 ATmega32 does not contain a floating-point unit (FPU), so additional\nlibraries are required to compute it. However, these libraries occupy a relatively large space in\ncode size and can compromise the execution speed. Nevertheless, the Atmel R\u00a9 AVR R\u00a9 ATmega32\nworked in our tests due to its simplicity, low-power consumption, low-price and availability.\n\n4.3.2 Communication\n\nFor a reliable and simple RF communication between the modules and the operator outside\nthe pipeline, one Digi R\u00a9 XBee R\u00a9 1mW PCB radio module , as shown in Figure 4.3b, is employed\nat each ErekoBot ? , as it provides two serial modes of communication: a simple transmit/receive\nmethod and a framed mode that offers advanced features (Digi International Inc, 2009). Even with\nthe small PCB antenna, this XBee has an outdoor range up to 90 m and an indoor range up to\n30 m. One XBee is connected at each module and another one at the host, allowing transmission\nbetween all parts of the system through a serial port (Figure 4.4).\n\n(a) Atmel R\u00a9 AVR R\u00a9 ATmega32 .\n(b) Digi R\u00a9 XBee R\u00a9 1mW PCB radio\nmodule .\n\nFigure 4.3: Control and communication devices.\n\n4.3.3 Electronic Devices\n\nTwo electronic boards are embedded in the ErekoBot ? . The base board contains voltage\nregulators to provide 3.3 V , 5 V and 6 V for the devices in the circuit. A capacitor based filter\nthe signals, resulting in a clean DC signal for the logic inputs. In addition, there are three LEDs\nto help debugging. The lateral board allows the connection between the electronic board and the\nsensors. The complete circuit schematics and circuit board drawings are shown in Appendix III.\n\n40\n\n\n\nFigure 4.4: Xbee configuration.\n\n4.3.4 Power Supply\n\nThere are two options for power supply in modular robotics: ErekoBot ? has an external\n12 V DC power supply while internal Lithium Polymer batteries are used in ErekoBot ?v.2 . The\nchoice for the external power supply in ErekoBot ? was done so the module maximum weight\nwould not be exceeded (see Section 4.4.4 for more information).\n\n4.4 Mechanical Design\n\nThe main idea of ErekoBot ? was that they should not only be easy to build, but at a low\ncost. Therefore, a simple intermodular connection is adopted (Section 4.4.1) and simple structural\npieces are employed (Section 4.4.3). Finally, the maximum weight that the servomotor supports is\nexamined (Section 4.4.4).\n\n4.4.1 Intermodular Connection\n\nThe ErekoBot ? has a VelcroTM connection for simplicity, which makes the self-reconfigurability\nimpossible, but the manual reconfigurability easy for experimental tests. In the future, with self-\nreconfigurability it is possible to change the shape of the module inside the pipeline and not only\noutside by the operator.\n\n41\n\n\n\n4.4.2 Servo Motor\n\nIt is decided to use the 3 pole servomotor Hitec HS-85BB (Figure 4.5) with a 3.5 kg\ncm\n\n(when\npowered at 6.0 V ). It is a small (29 \u00d7 13 \u00d7 30 in mm) and light (19 g) servomotor with a high\ntorque and strong resin gear train. The power consumption depends on the characteristics of the\nrobot, such as weight, form of connection and number of modules lifted.\n\nFigure 4.5: Hitec HS-85BB.\n\nThe Pulse Width Modulation (PWM) sent to the motor determines position of the shaft, and,\nbased on the duration of the pulse sent via the control wire, the rotor will turn to the desired\nposition.\n\n4.4.3 Geometric Description and Materials\n\nErekoBot ? is a cube with 70 mm edge, formed by an acrylic 2 mm cut by laser. This material\nproved to be light and resistant to impacts. There are three pieces: the Base, the Motor Holder\nand the Rod-Cover set (Figure 4.6). The Base holds two IR sensors and the electronic board\n(manually and soldered manually); the Rod holds the IMU; and the Cover holds the other two IR\nsensors.\n\n(a) Base. (b) Motor Holder. (c) Rod-cover.\n\nFigure 4.6: ErekoBot ? mechanic pieces.\n\nThe Rod-cover set is screwed into the servo motor, which is screwed into the Motor Holder,\nwhich, finally, is screwed into the Base (Appendix IV presents the plans for the pieces). The only\ndegree of freedom is given by the servo motor that moves the Rod-cover set.\n\n42\n\n\n\n4.4.4 Weight Analysis\n\nFor this analysis, lets consider the servomotor and the mass center positioned at the module\ncenter. In addition, all modules connections are in the same plane. There are two types of\nconnection that provide two types of movements: in the vertical plane pitch (Figure 4.7a) and in\nthe horizontal plane yaw (Figure 4.7b).\n\n(a) Pitch. (b) Yaw.\n\nFigure 4.7: Possible connections between two modules.\n\nThe torque intensity ? necessary for the module A lift the module B in pitch is\n\n?pitch = mgL sin ?,\n\nwhere m is the module mass, g is the gravitational force, L is the length of the module (defined in\nSection 3.2) and ? is the pitch angle of the segment related to the vertical axis.\n\nIn addition, the torque ? necessary in yaw is\n\n?yaw = mgL sin \u00b5s,\n\nwhere \u00b5s is the coefficient of friction in the horizontal plane.\n\nThe maximum torque ?max occurs when ? = ?/2 or \u00b5 = 1, which corresponds in both cases to\n\n?max = mg L + mg (2L) = 3 mg L,\n\nas can be seen in the free body diagram in Figure 4.8.\n\nThe Hitec HS-85BB has a torque ?a = 3.5 kg/cm or ?a = 0.3437 Nm. The gravitational force\nis g = 9.82 m/s2 and the module length is 70 mm = 0.070 m, therefore, the maximum weight of\nErekoBot ? can be calculated as:\n\n43\n\n\n\nFigure 4.8: Free Body Diagram.\n\n0.3437 = 3 ? 9.82 ? 0.07m\n\nm = 0.167 kg\n\nConsidering a security factor of 25%, the maximum weight of each module is\n\nmmax = 0.75 m = 0.12525 kg = 125 g. (4.1)\n\n4.5 Module Analysis\n\nAfter manufacturing one ErekoBot ? (Figures 4.9 and 4.10), the differences between the ac-\ntual and the estimated weights are measured (Section 4.5.1). Then, its main characteristics are\ncompared with other SRM modules (Section 4.5.2).\n\n4.5.1 Actual and estimated weights\n\nEach piece of the ErekoBot ? was weighted and, then, compared to their estimated values by\nthe data sheets or by SolidWorks R\u00a9 in Table 4.1. Although each estimated and measured values\nvaries (18.9%,?20.0%), the total weight of the module is closer to the estimated value: only 0.2%\nlighter.\n\nPiece Estimated (g) Measured (g) Difference\nBase 22.72 28 18.9%\n\nMotor Holder 3.94 3.4 ?15.9%\nRod-Cover set 12.46 14.8 15.8%\n\nElectronic Circuit 30 25 ?20.0%\nServo Motor 19 19 0.0%\nIR Sensors 4 ? 3.5 4 ? 3.2 ?9.4%\n\nIMU 0.5 0.4 ?25%\nXBee 10 9.4 ?6.4%\nOther 5 4.6 ?8.7%\nTotal 117.62 117.4 ?0.2%\n\nTable 4.1: Estimated and measured weights.\n\n44\n\n\n\nFigure 4.9: Estimated ErekoBot ? (drawn in SolidWorks R\u00a9 ).\n\n4.5.2 Comparison between ErekoBot ? and other modular robots\n\nTable 4.2 resumes the comparison between ErekoBot ? and the most recent SRM modules\npresented in Section 2.2.3. All of them use wireless communication in order to decrease dependences\nwith wires in reconfiguration. In addition, most modules also are homogeneous, which eases\ndesign, manufacture and simple tests. Except for CoSMO and Roombots, most modules, including\nErekoBot ? , uses servomotors to enable position control for more complex movements.\n\nIn comparison with other modules, ErekoBot ? is smaller and lighter, mainly because it has\nonly one degree of freedom and no motor for connection. This selection was made considering the\nErekoBot ? goals (sensors with simplicity and low cost).\n\nOnly Roombots and SMORES do not have internal sensors. In the case of Roombot, users\nget information about the modules using computer vision with external cameras. The research on\nSMORES focus on a blind connection using magnets.\n\nThe Transmote module just uses IR sensors for a similar alignment of the ErekoBot ? , but\nthere is no feedback of internal positions.\n\nCoSMO and UBot have a more complete selection of sensors (orientation and proximity) but\nCosMO sensors have not been tested yet and UBot design used heterogeneous modules, and just\nthe head of the robot has these sensors.\n\n45\n\n\n\nFigure 4.10: Actual ErekoBot ? .\n\n46\n\n\n\nN\nam\n\ne\nE\nre\n\nko\nB\no\nt\n?\n\nS\nM\nO\nR\nE\nS\n\nU\nB\no\nt\n\nC\no\nS\nM\nO\n\nR\no\no\nm\nb\no\nts\n\nT\nra\nn\nsm\n\no\nte\n\nT\ny\np\ne\n\nH\nom\n\nog\nen\n\neo\nus\n\nH\nom\n\nog\nen\n\neo\nus\n\nH\net\ner\nog\n\nen\neo\nus\n\nH\nom\n\nog\nen\n\neo\nus\n\nH\nom\n\nog\nen\n\neo\nus\n\nH\nom\n\nog\nen\n\neo\nus\n\nD\nim\n\nen\nsi\no\nn\ns\n(m\n\nm\n)\n\n7\n0\n\u00d7\n\n7\n0\n\u00d7\n\n7\n0\n\n1\n0\n0\n\u00d7\n\n1\n0\n0\n\u00d7\n\n9\n0\n\n8\n0\n\u00d7\n\n8\n0\n\u00d7\n\n8\n0\n\n7\n0\n\u00d7\n\n7\n0\n\u00d7\n\n7\n0\n\n1\n0\n0\n\u00d7\n\n1\n0\n0\n\u00d7\n\n9\n0\n\n8\n0\n\u00d7\n\n8\n0\n\u00d7\n\n8\n0\n\nW\nei\ng\nh\nt\n(g\n)\n\n1\n1\n8\n\n5\n2\n0\n\n2\n8\n0\n\n1\n2\n5\n0\n\n1\n4\n0\n0\n\nN\not\n\nin\nfo\nrm\n\ned\n\nC\nP\nU\n\nA\nT\nM\neg\na3\n\n2\nM\nB\nE\nD\n\nN\not\n\nin\nfo\nrm\n\ned\nD\nua\n\nl\nC\nor\ne\nB\nla\nck\nfin\n\n,\nM\nSP\n\n43\n0\nan\n\nd\nC\nor\nte\nxM\n\n3\nM\nIP\n\nS\nds\nP\nIC\n\n33\nR\nIS\nC\n\nco\nre\n\nM\no\nto\nrs\n\nSe\nrv\no\n\nSe\nrv\no\n\nSe\nrv\no\n\nD\nC\n\nD\nC\n\nSe\nrv\no\n\nD\no\nF\n\n1\n4\n\n2\n1\n\n3\n3\n\nC\no\nn\nn\nec\nto\nrs\n\nM\nan\n\nua\nl\n\nby\nve\nlc\nro\n\nA\nct\niv\ne\nan\n\nd\npa\n\nss\niv\ne\npi\nns\n\nA\nct\niv\ne\nan\n\nd\npa\n\nss\niv\ne\npi\nns\n\nA\nct\niv\ne\nan\n\nd\npa\n\nss\niv\ne\npi\nns\n\nA\nct\niv\ne\nan\n\nd\npa\n\nss\niv\ne\npi\nns\n\nA\nct\niv\ne\nan\n\nd\npa\n\nss\niv\ne\npi\nns\n\nC\no\nm\nm\nu\nn\nic\nat\nio\nn\n\nW\nir\nel\nes\ns\n\nW\nir\nel\nes\ns\n\nW\nir\nel\nes\ns\n\nW\nir\nel\nes\ns\n\nW\nir\nel\nes\ns\n\nW\nir\nel\nes\ns\n\nS\nen\n\nso\nrs\n\nIM\nU\n\nan\nd\n\nIR\nse\nns\nor\ns\n\nN\no\nse\nns\nor\ns\n\nW\nir\nel\nes\ns\nvi\nsi\non\n\nse\nns\nor\n,\n\nac\nce\nle\nro\nm\net\ner\n,\nIR\n\nra\nng\n\ne\nfin\n\nde\nr\n\nan\nd\nlin\n\nea\nr\nH\nal\nl\nSe\n\nns\nor\n\nH\nal\nl\nse\nns\nor\n,\nIM\n\nU\n,\n\ncu\nrr\nen\nt\nse\nns\nor\n,\nca\nm\ner\na\n\nan\nd\nIR\n\nse\nns\nor\ns\n\nN\no\nse\nns\nor\ns\n\nIR\nse\nns\nor\ns\n\nT\nab\n\nle\n4.\n2:\n\nC\nom\n\npa\nri\nso\nn\nb\net\nw\nee\nn\nE\nre\nko\nB\not\n?\nan\n\nd\not\nhe\n\nr\nSR\n\nM\nm\nod\n\nul\nes\n.\n\n47\n\n\n\n4.6 Conclusions\n\nIn this chapter, all the devices and architectures of ErekoBot ? were defined in order to meet\nits desired requirements. In Section 5, the manufactured module is used in experiments that are\ndescribed and analysed.\n\n48\n\n\n\nChapter 5\n\nExperiments and Results\n\nThis chapter describes the platform and setup developed to carry out the experiments (Sections\n5.1.1, 5.2.1 and 5.3.1). Then, the results are presented in sections 5.1.2, 5.2.2 and 5.3.2.\n\nThe experiments described in this chapter aim to verify the quality of the information obtained\nwith the data acquired from the sensors. Three types of experiments are performed: orientation\nexperiment, which employs the IMU acquired data; distance experiment, that applies the data\ncoming from the IR sensors; and the alignment experiment, for positioning the module face parallel\nto a detected obstacle.\n\n5.1 Orientation Experiment\n\nThe main goal of these experiments is to estimate the ErekoBot ? position using the accelerom-\neter or the gyroscope from the IMU. In these experiments, the microcontroller reads the IMU data\nand sends them thought the Digi R\u00a9 XBee R\u00a9 1mW PCB radio module to the host computer, which\nfilters the signal using the Complementary Filter described in Section 2.3.4.1.\n\nThe IMU readings were tested in two situations: when the module is at rest position and when\nthe module is in movement. The experiments are considered successful if it is possible to estimate\nthe pitch angle of the module without deviation.\n\nThe modules have only one degree of freedom, that can be arranged to perform yaw or pitch\nangles (see Figure 5.1). As it is not possible to make the module perform a roll movement, the roll\nangle will not be analyzed here.\n\nIn addition, because of the Gimbal Lock (Section 2.4.1.1), it is not possible to estimate the\nyaw position with the Complementary Filter combining information from the accelerometer and\ngyroscope sensors. Therefore, the only angle to be analyzed is the pitch angle.\n\nThe complementary filter is adjusted in the host and then, the result of Perr is used in each\nmodule.\n\n49\n\n\n\nFigure 5.1: Different types of connections in modular robots a) Pitch-pitch. b) Yaw-yaw. c)\nPitch-yaw.\n\n5.1.1 Experimental Method\n\nFigure 5.2a shows the position and setup for the first experiment. The module rests at position\n0? and the IMU measurements are read for 80 seconds with a sample time of 200 ms. Therefore,\nthe module send 400 measurements for the host, that calculates offline the filtered signals with the\nComplementary Filter algorithm.\n\nFigure 5.2b shows how the module moves from position ?45? to 45?. The algorithm employed\nby the module consists of the following steps:\n\n1. Read the IMU 10 times;\n\n2. Send the measurements to the host;\n\n3. Wait 200 ms;\n\n4. Advance 5?.\n\n5. If position is less than 45?, go back to 1\n\n(a) Rest position. (b) Moving position.\n\nFigure 5.2: Positions of ErekoBot ? for the orientation experiment.\n\n50\n\n\n\n5.1.2 Results\n\nUsing the Equations (3.2), (3.12), (3.13), the host computed the pitch angle from the IMU\nmeasurements, while the module was holding at rest (0?), as pictured in Figure 5.3. It can be\nseen that the results based on the accelerometer provided exact angle values: even if the mean\nvalue varies in time, it remains close to ?3.30? with a standard deviation of 12.74?. However,\nthese values are inaccurate because there is a great variation at each measurement. In contrast,\nthe gyroscope based angles were more accurate, but inexact due to the deviation that occurs over\ntime.\n\nFigure 5.3: Pitch angle estimations of position 0? without a filter.\n\nThe findings above imply that accelerometer and gyroscope data are complementary which\nasserts that the Complementary Filter can be used for combining their measurements and achieving\na better estimation of the module pitch angle. The results of pitch angle estimation using the\nComplementary Filter are presented in Figure 5.4. As mentioned in Section 3.3.1.3, when Perr is\nclose to zero, the Complementary Filter eliminates the accelerometer readings (shown as darker\nlines) and when Perr is close to one, the Complementary Filter does not take into account the\ngyroscope measurements.\n\nThe pitch angle was also calculated by the host computer from the IMU measurements when the\nmotor is moving from ?45? to 45?, and the readings are shown in the graph of Figure 5.5. These\nresults are similar to the graph of Figure 5.3: the accelerometer provided exact but inaccurate\nangles while the gyroscope supplies accurate but inexact angles. Figure 5.6 presents the graph\nwith the estimation obtained using the Complementary Filter, when Perr is 0.9, 0.7, 0.5, 0.3 and\n0.1.\n\nThe results from Figures 5.4 and 5.6 provide enough evidence towards employing the comple-\nmentary filter for future estimations with Perr = 0.5 because it is the outcome that best approxi-\nmates the straight line ?45? to 45?.\n\n51\n\n\n\nFigure 5.4: Pitch angle estimations of position 0? filtered with Perr = 0.9, Perr = 0.7, Perr = 0.5,\nPerr = 0.3 and Perr = 0.1.\n\nFigure 5.5: Pitch angle estimations of positions ?45? to 45? without a filter.\n\n52\n\n\n\nFigure 5.6: Pitch angle estimations of positions ?45? to 45? filtered with Perr = 0.9, Perr = 0.7,\nPerr = 0.5, Perr = 0.3 and Perr = 0.1.\n\n5.2 Distance Experiment\n\nThe main goal of this part of the experiments is to detect the presence of an obstacle and\nestimate its distance from the ErekoBot ? face where the IR sensors are fixed. The dependence\nbetween voltage output and estimated distance for the IR Sensors is not linear which suggests\nthe need to calibrate the IR SHARP GP2Y0A41SK0F (Section 2.3.1). After calibration, a lookup\ntable is generated and it is inserted in the microcontroller to be used when estimating the distance\nbetween the module face and an obstacle in the environment.\n\nThe experiment succeeds when the ErekoBot ? is capable of detecting an obstacle and estimat-\ning its distance using the lookup table.\n\n5.2.1 Experimental Method\n\nThe IR SHARP GP2Y0A41SK0F sensor detects obstacles and measures distances within a\nrange from 40 to 300 mm. In order to assure the correct detection and measurement, the IR\nSensor was calibrated by analyzing the non-linear voltage curve detecting a gray obstacle between\n10 to 350 mm with a resolution of 10 mm. Figure 5.7 shows the experiment arrangement.\n\nIn order to consider possible hysteresis and environmental changes, the measurements were\nmade in both directions. Initially, the sensor is located at 10 mm, then the IR sensor moves slowly\nfor others measures until it reaches 350 mm. At that point, the sensor is moved backwards and\nthe measurements are made again. To make sure the results are redundant, the measurements are\n\n53\n\n\n\nFigure 5.7: Preparation for the distance experiment. The IR Sensor measures the voltage in\ndifferent distances for calibration.\n\nrepeated four times for each position.\n\nA curve based on the sensor readings is built, and the acceptable range is determined. The\nbest power equation is chosen with the help of the computational engine Curve Fitting Toolbox R\u00a9\n\nfrom MATLAB R\u00a9.\n\n5.2.2 Results\n\nFigure 5.8 shows the curve obtained by the measurement average values. The dependence\nbetween voltage output and proximity distance for IR Sensors is nonlinear, and rather similar to\nthe curve in the IR sensor data sheet (SHARP, 2002). From this curve, it is possible to specify a\nworking range between 5 and 28 cm .\n\nWith the Curve Fitting Toolbox R\u00a9 from MATLAB R\u00a9, the best power equation fit was found\n\nVIR = 112.3 d\n?0.9915,\n\nwhere VIR is the output voltage in Volts and d is the distance, in millimeters, between the IR\nsensor and the obstacle.\n\nIn order to build the lookup table, it is necessary to compute the distance based on the voltage\nmeasurement, the Equation (5.2.2) is inverted, which results in\n\nd =\n\n(\n112.3\n\nVIR\n\n)1.0086\n. (5.1)\n\n54\n\n\n\nFigure 5.8: IR sensor voltage outputs points (blue markers) and curve formed from the average\nvalues (red line).\n\nFigure 5.9: IR sensor voltage outputs and power fit from Equation (5.2.2) curves.\n\n55\n\n\n\n5.3 Alignment Experiment\n\nThe main goal of this experiment is to detect the presence of an obstacle, estimate its distance\nfrom the ErekoBot ? face, and align the module sensor surface with the obstacle. In order to\nverify the Alignment Algorithm from Section 3.4, the algorithm was tested with different planes\nat different distances.\n\n5.3.1 Experimental Method\n\nCombining the results from Sections 5.1.2 and 5.2.2, the following Alignment Algorithm was\napplied:\n\n1. The ErekoBot ? reads the orientation of the rod at time t (orientt(6)) and calculates the\npitch angle using a complementary filter with Perr = 0.5;\n\n2. The ErekoBot ? reads the objects distance at time t (proximt(4)) using a lookup table from\nEquation (5.1);\n\n3. Through Digi R\u00a9 XBee R\u00a9 1mW PCB radio module , it sends orientt(6), proximt(4) and t to\nthe host computer;\n\n4. If the measured distances are different, the servo motor rotates to an angle ? proportional\ndo the difference measured from IR sensors, in order to align with the plane;\n\n5. After adding 1 to t and waiting for 300 ms, the ErekoBot ? returns to step 1.\n\nThe alignment was tested with three different surfaces: a white sheet of paper, a card paper\nplane and a black sheet of paper in different positions. The purpose is to test if the alignment\nworks with different surface colors (white, gray and black) and to estimate how long it takes for\nthe ErekoBot ? to align with the plane.\n\n5.3.2 Alignment Results\n\nFigures 5.13, 5.14 and 5.15 present the alignment experiments. The results were similar with\nthe three different surfaces tested: the ErekoBot ? aligned with the plane. White surfaces reflect\nbetter than black surfaces, and, as IR sensors works with infrared reflected light (see Section 2.3.3),\nthe white plane works faster than gray or black planes.\n\nConcerning quantitative results, three tests are shown below. The ErekoBot ? executed the\nalignment algorithm in front of a gray surface, and the differences between the measured distances\nfrom the IR sensors and the orientation positions from the IMU (after execution of a complementary\nfilter) are sent to the host. The tests were performed ten times at each position.\n\nIn the first test, the ErekoBot ? aligned itself with the plane at position 15? in less than 1.0\nsecond, as shown in Figures 5.10a and 5.10b. The servomotor rotates towards positive angles until\nthe module rod gets close to the pitch angle 16?.\n\n56\n\n\n\n(a) Differences in measured distances during alignment algorithm (Position 15?).\n\n(b) Orientation pitch positions during alignment algorithm (Position 15?).\n\nFigure 5.10: Alignment results for position 15?.\n\n57\n\n\n\nAs in the second test, the ErekoBot ? could align with the plane at position ?25? in less than\n1.0 second, as shown in Figures 5.11a and 5.11b. The servomotor rotates towards negative angles\nuntil the module rod angle converge towards 27?.\n\n(a) Differences in measured distances during alignment algorithm (Position ?25?).\n\n(b) Orientation pitch positions during alignment algorithm (Position ?25?).\n\nFigure 5.11: Alignment results for position ?25?.\n\nIn the third and last test, the ErekoBot ? achieved alignment with the plane at position ?40?\n\nin less than 1.2 second, as shown in Figures 5.12a and 5.12a. The servomotor rotates towards\nnegative angles until the pitch angle value of ?43? is attained.\n\nThe tests above pointed some limitations:\n\n\u2022 Light: occasionally, when there is a direct light pointing to an IR sensor, the measurement\n\n58\n\n\n\n(a) Differences in measured distances during alignment algorithm (Position ?40?).\n\n(b) Orientation pitch positions during alignment algorithm (Position ?40?).\n\nFigure 5.12: Alignment results for position ?40?.\n\n59\n\n\n\nresponses are affected. The IR sensor considers that an object exists at its front and the\nalignment does not work properly.\n\n\u2022 Distances higher than 280 mm: as expected, the IR sensor does not properly measure dis-\ntances higher than the maximum of the range, 280 mm. The target is considered to be at a\ndistance 280 mm for the alignment algorithm.\n\n\u2022 Distances smaller than 50 mm: as expected, the IR sensor does not properly measure dis-\ntances smaller than the minimum of the range, 50 mm. Observing the graph of Figure 5.8, it\nis possible that the ErekoBot ? consider the object in a position inside the range 50 mm to\n280 mm. For future work, an algorithm that consider statistics based on previous distances\ncan be developed to work in such cases.\n\n\u2022 Servomotor position higher than 35? and smaller than 145?: in order to avoid the collision\nof the module internal parts, a maximum and minimum servomotor positions, from 35? to\n145?, were determined.\n\n\u2022 The calibration for the IR sensor in Figure 5.9 works just for a gray obstacle, and different\ncolors may produce different lookup tables. However, as the ErekoBot ? aligns based on\ndifferences between these distances, the alignment still works with an homogeneous plane\n(same color and texture).\n\n(a) 0 second. (b) 0.2 second. (c) 0.4 second. (d) 0.6 second.\n\nFigure 5.13: Alignment results with a white sheet of paper plane (white).\n\nConsidering these limitations it is not possible to confirm that the robot can be used in pipelines\nyet.\n\n5.4 Conclusions\n\nA SRM module was designed and manufactured respecting the conceptual design proposed in\nChapter 4, which allowed us to test the models from Chapter 3. The embedded sensors are used\nfor:\n\n60\n\n\n\n(a) 0 second. (b) 0.2 second. (c) 0.4 second. (d) 0.6 second.\n\nFigure 5.14: Alignment results with a card paper plane (gray).\n\n(a) 0 second. (b) 0.2 second. (c) 0.4 second. (d) 0.6 second.\n\nFigure 5.15: Alignment results with a black sheet of paper plane (black).\n\n61\n\n\n\n1. Estimating the orientation pose of ErekoBot ? using the Complementary Filter.\n\n2. Calibrating the IR sensors for distance measurements.\n\n3. Aligning the ErekoBot ? face with a detected plane.\n\nWith the results of the IMU tests (Figure 5.3 and Figure 5.5), it is possible to verify that the\nsensors readings to estimate the module orientation are either noisy or present drift over time.\nTo overcome this problem, a complementary filter was employed, which decreases noise and drift,\nestimating faster and not overloading the module processor. Therefore, for faster and more accurate\nstabilization of the ErekoBot ? , the complementary filter is chosen as the default filter used for\nfuture processes using the IMU.\n\nThe IR sensor calibration provided a similar curve to the one that appears in the data sheet\n(SHARP, 2002), and the results from Equation (5.1) were converted in a LUT programmed in the\nAtmel R\u00a9 AVR R\u00a9 ATmega8 .\n\nWith these results, it was possible to perform the alignment, and demonstrate the viability of\nthe algorithm described in Section 3.4. With the alignment experiment results, it is possible to\nconfirm that the robot may not be used for pipeline inspection applications yet.\n\n62\n\n\n\nChapter 6\n\nConclusions\n\nThis Chapter first presents the principal contributions of this dissertation with a brief discussion\nof its implications and, then, indicates some of possible future lines of investigation to this work.\n\n6.1 Main Contributions\n\nThe ErekoBot ? is a simple reconfigurable module with sensors able to react to the environment\nbased on sensors response. In this work, the module was designed, manufactured and tested, which\nallowed us to answer the questions presented in Section 1.2:\n\n1. What kind of sensors are more common in recent SRM robotics? Table 4.2 resumes the main\ncharacteristics of five of the most recent modules. Roombots and SMORES do not have\ninternal sensors; Transmote just uses proximity sensors; and CoSMO and UBot have a more\ncomplete selection of orientation and proximity sensors.\n\n2. What kind of requirements does the robot have? Section 3.2 presents three main requirements\nfor the ErekoBot ? : the abilities to (1) detect an obstacle (Figure 3.3a), (2) align with a\nplane simulating a pipeline (Figure 3.3b) and (3) estimate its own pose (Figure 3.3c).\n\n3. What kind of sensors are going to be used in this module? Section 4.2 presents the sensors\nselection. The ErekoBot ? has four Infrared Sensors (GP2Y0A41SK0F) for obstacles detec-\ntion and the alignment algorithm. In addition, ErekoBot ? has an IMU (with ADXL345 and\nITG-3200) for rotation motion measurements.\n\n4. What is the shape, size, weight, circuits and materials of the module? Chapter 4 focus on\nthe module design, and Figures 4.6, 4.9, 4.10 and Table 4.2 illustrates and resumes shape,\nsize, weight, circuits and materials of the complete module.\n\n5. Does the chosen sensors are sufficient for our needs? Chapter 5 presents the results of\nthe experiments. The ErekoBot ? is able to: (1) detect an obstacle between 5 and 28 cm\n(Figure 5.9), (2) align with a plane simulating a pipeline (Figures 5.13, 5.14 and 5.15), and\n\n63\n\n\n\n(3) estimate its own pose with a Complementary Filter from gyroscope and accelerometer\nmeasurements (Figures 5.4 and 5.6).\n\nAfter answering these initial questions, the ErekoBot ? presented limitations:\n\n1. Yaw angle With just accelerometer and gyroscope is not possible yet to measure the yaw\nangle.\n\n2. VelcroTM The VelcroTM limits the reconfigurability of the module.\n\n3. Cable The power cable limits the locomotion of the robot.\n\n4. Alignment limitations Light, distances, servomotors positions and calibration of the IR sen-\nsors are described in Section 5.3.2.\n\nThe designed module shows evidence towards its application in pipeline inspections, however\nthe proposed solutions have its limitations and are not yet viable for field application.\n\n6.2 Future Lines of Investigation\n\nSome lines of investigation are presented to give continuity to this dissertation (the order that\nappears is an author suggestion of importance):\n\n\u2022 Thinning the module It is still possible to thin the module, changing the acrylic for a lighter\nmaterial (such as resin, carbon fiber) and changing the printed circuit board (PCB) for a\nsurface-mount device (SMD).\n\n\u2022 Cable/Energy Thinning the module allows the use of an autonomous energy source, elimi-\nnating the cable requirement of the system.\n\n\u2022 Magnetometer For future designs, the magnetometer can be used to determine the yaw\nrotation.\n\n\u2022 Alignment and obstacle deviation algorithms This work presents codes and algorithms for\nreading the sensors values and converting them to system more familiar to users (distance\nin millimeters, orientation in vectors). Nevertheless, control laws were not added to find the\nbest response for the modules. It is possible to make a close control loop.\n\n\u2022 Connection Another line of investigation regards connection between modules, it is funda-\nmental to substitute the VelcroTM for a male-female system with DC motors in each face of\nthe module.\n\n\u2022 Computational vision method The homogeneity of ErekoBot ? gives advantage for a modules\nseries production. However, one of the modules may carry a camera to allow the use of\ncomputational vision methods for obstacles detection and alignments.\n\n64\n\n\n\n\u2022 Distributed Robotic systems After solving the alignment system, it is possible to work with\ndistributed robotic systems, analyzing when to connect, how to connect and what kind of\ncollaborations between the fleet will be established.\n\nAlthough there are several limitations in this system, this module design and tests contribute\nto the modular robotics in order to build a versatile system to change automation of maintenance\nand leaks detection processes in the future.\n\n6.3 Publications\n\nThe work in this manuscript allowed the development, directly or indirectly, of the following\npapers accepted for presentation at conferences:\n\n\u2022 Kinematics of a Hexapod Modular Robot (GONCALVES et al., 2013).\n\n\u2022 Data Communication and Protocols in self-reconfigurable modular robots (SOUSA; VIANA;\nKOIKE, 2013a).\n\n\u2022 Programando a movimenta\u00e7\u00e3o em rob\u00f4s modulares autorreconfigur\u00e1veis \u00e1podes para in-\nspe\u00e7\u00e3o em tubula\u00e7\u00f5es (SOUSA; VIANA; KOIKE, 2013b).\n\n\u2022 Sensors in Reconfigurable Modular Robot for Pipeline Inspection : Design and Tests of a\nPrototype (SOUSA; VIANA; KOIKE, 2014).\n\n\u2022 ErekoBot Sigma: Prot\u00f3tipo de um rob\u00f4 modular reconfigur\u00e1vel com sensores (SOUSA et al.,\n2014).\n\n65\n\n\n\nBibliography\n\nAnalog Devices Inc. Digital Accelerometer ADXL345 Datasheet. [S.l.], 2009. Cited on page 39.\n\nARCHILA, J. F.; BECKER, M. Study of Robots to Pipelines, Mathematical Models and\nSimulation. In: 2013 Latin American Robotics Symposium and Competition. IEEE, 2013. p.\n18\u201323. ISBN 978-0-7695-5139-5. Dispon\u00edvel em:&lt;http://ieeexplore.ieee.org/xpls/abs\\_all.jsp?\narnumber=6693264http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6693264>.\nCited 2 times on pages vi e 5.\n\nATMEL. ATmel AVR Atmega32 Datasheet. [S.l.], 2011. Cited on page 40.\n\nBANKS, E. R. Universality in cellular automata. In: BURKS, A. W. (Ed.). 11th Annual\nSymposium on Switching and Automata Theory (swat 1970). IEEE, 1970. p. 194\u2013215. Dispon\u00edvel\nem:&lt;http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4569649>. Cited on\npage 8.\n\nBAUER, J. Milling Robot for processing the internal walls of inaccessible pipelines. 2011.\nDispon\u00edvel em:&lt;http://www.google.com/patents/US8573889>. Cited on page 6.\n\nBENTLEY, J. P. Principles of Measurement Systems. 4th. ed. Harlow: Pearson Education, 2005.\nISBN 9780130430281. Cited 6 times on pages xiv, 1, 13, 14, 15 e 22.\n\nBONARDI, S. et al. Collaborative manipulation and transport of passive pieces using the\nself-reconfigurable modular robots roombots. In: 2013 IEEE/RSJ International Conference on\nIntelligent Robots and Systems. IEEE, 2013. p. 2406\u20132412. ISBN 978-1-4673-6358-7. Dispon\u00edvel\nem:&lt;http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6696694>. Cited 3\ntimes on pages vi, 11 e 12.\n\nCentral Intelligence Agency. The World Factbook 2013-4. Washington, DC, 2013. Dispon\u00edvel em:\n<https://www.cia.gov/library/publications/the-world-factbook/fields/2117.html>. Cited on\npage 4.\n\nCHOI, H.; RYEW, S. Robotic system with active steering capability for internal inspection of\nurban gas pipelines. Mechatronics, v. 12, n. 5, p. 713\u2013736, jun. 2002. ISSN 09574158. Dispon\u00edvel\nem:&lt;http://linkinghub.elsevier.com/retrieve/pii/S0957415801000228>. Cited 2 times on pages\n5 e 6.\n\nCUI, X. et al. A homogenous CPG-network for multimode locomotion control of modular\nself-reconfigurable robot. In: 2012 IEEE International Conference on Mechatronics\nand Automation. IEEE, 2012. p. 2526\u20132530. ISBN 978-1-4673-1278-3. Dispon\u00edvel em:\n<http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6285744>. Cited 2 times on\npages vi e 10.\n\n66\n\nhttp://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=6693264 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6693264\nhttp://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=6693264 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6693264\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4569649\nhttp://www.google.com/patents/US8573889\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6696694\nhttps://www.cia.gov/library/publications/the-world-factbook/fields/2117.html\nhttp://linkinghub.elsevier.com/retrieve/pii/S0957415801000228\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6285744\n\n\nDAVEY, J.; KWOK, N.; YIM, M. Emulating self-reconfigurable robots - design of\nthe SMORES system. In: 2012 IEEE/RSJ International Conference on Intelligent\nRobots and Systems. IEEE, 2012. p. 4464\u20134469. ISBN 978-1-4673-1736-8. Dispon\u00edvel em:\n<http://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=6385845http://ieeexplore.ieee.org/\nlpdocs/epic03/wrapper.htm?arnumber=6385845>. Cited 2 times on pages vi e 9.\n\nDigi International Inc. XBee /XBee-PRO RF Modules Datasheet. [S.l.], 2009. Cited on page 40.\n\nER??M??, M. A. MEMS Accelerometers and Gyroscopes for Inertial Measurements Units. Tese\n(PhD) \u2014 Middle East Techincal University, 2004. Cited 2 times on pages 17 e 19.\n\nFUKUDA, T.; KAWAUCHI, Y. Cellular robotic system (CEBOT) as one of the realization of\nself-organizing intelligent universal manipulator. In: Proceedings., IEEE International Conference\non Robotics and Automation. Cincinnati, OH: IEEE Comput. Soc. Press, 1990. p. 662\u2013667.\nISBN 0-8186-9061-5. Dispon\u00edvel em:&lt;http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?\narnumber=126059>. Cited on page 8.\n\nGLASSER, P. C. An Introduction to the Use of Complementary Filters for Fusion of Sensor Data.\nDispon\u00edvel em:&lt;http://glassercommunications.com/paul/samples/filters\\_for\\_fusion.pdf>.\nCited 2 times on pages vi e 23.\n\nGONCALVES, L. L. C. et al. Kinematics of a Hexapod Modular Robot. In: 22nd International\nCongress of Mechanical Engineering (COBEM 2013). Ribeir\u00e3o Preto, SP, Brazil: ABCM, 2013.\nCited on page 65.\n\nGREEN, K.; FURCHTGOTT-ROTH, D. Intermodal Safety in the Transport of Oil.\nStudies in Energy Transportation, n. October, p. 32, 2013. Dispon\u00edvel em:&lt;http:\n//ssrn.com/abstract=2345409>. Cited 2 times on pages 4 e 5.\n\nHIGGINS, W. A Comparison of Complementary and Kalman Filtering. IEEE Transactions\non Aerospace and Electronic Systems, AES-11, n. 3, p. 321\u2013325, maio 1975. ISSN 0018-9251.\nDispon\u00edvel em:&lt;http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4101411>.\nCited 4 times on pages vi, 22, 23 e 24.\n\nHIROSE, S. et al. Design of in-pipe inspection vehicles for ?25, ?50, ?150 pipes. In: Proceedings\n1999 IEEE International Conference on Robotics and Automation (Cat. No.99CH36288C).\nIEEE, 1999. v. 3, p. 2309\u20132314. ISBN 0-7803-5180-0. ISSN 1050-4729. Dispon\u00edvel em:\n<http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=770450>. Cited on page 5.\n\nHORODINCA, M. et al. A simple architecture for in-pipe inspection robots. In: International\nColloquium on Mobile and Autonomous Systems. Magdeburg, Germany: [s.n.], 2002. p. 061\u2013064.\nCited on page 6.\n\nINUKTUM. Crawler Vehicles. Dispon\u00edvel em:&lt;http://www.inuktun.com/crawler-vehicles/>.\nCited on page 6.\n\nINVENSENSE. ITG-3200 Product Specification Datasheet. [S.l.], 2010. v. 1, n. 408, 1\u201339 p. Cited\non page 39.\n\nJENSEN, C. Numerical Simulation of Gyroscope Effects in Ansys. 1\u201378 p. Tese (PhD Thesis) \u2014\nAalborg University, 2011. Cited 3 times on pages vi, 17 e 18.\n\nJORGENSEN, M.; OSTERGAARD, E.; LUND, H. Modular ATRON: modules for a self-\nreconfigurable robot. In: 2004 IEEE/RSJ International Conference on Intelligent Robots and\n\n67\n\nhttp://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=6385845 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6385845\nhttp://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=6385845 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6385845\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=126059\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=126059\nhttp://glassercommunications.com/paul/samples/filters\\_for\\_fusion.pdf\nhttp://ssrn.com/abstract=2345409\nhttp://ssrn.com/abstract=2345409\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4101411\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=770450\nhttp://www.inuktun.com/crawler-vehicles/\n\n\nSystems (IROS) (IEEE Cat. No.04CH37566). IEEE, 2004. v. 2, p. 2068\u20132073. ISBN 0-7803-\n8463-6. Dispon\u00edvel em:&lt;http://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=1389702http:\n//ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1389702>. Cited on page 8.\n\nKOVVALI, N.; BANAVAR, M.; SPANIAS, A. An Introduction to Kalman Filtering with\nMATLAB Examples. Synthesis Lectures on Signal Processing, v. 6, n. 2, p. 1\u201381, set.\n2013. ISSN 1932-1236. Dispon\u00edvel em:&lt;http://www.morganclaypool.com/doi/abs/10.2200/\nS00534ED1V01Y201309SPR012>. Cited on page 22.\n\nLEE, I. et al. Development and analysis of the vertical capacitive accelerometer. Sensors\nand Actuators A: Physical, v. 119, n. 1, p. 8\u201318, mar. 2005. ISSN 09244247. Dispon\u00edvel em:\n<http://linkinghub.elsevier.com/retrieve/pii/S0924424704004716>. Cited on page 17.\n\nLIEDKE, J. et al. The Collective Self-reconfigurable Modular Organism (CoSMO). In: 2013\nIEEE/ASME International Conference on Advanced Intelligent Mechatronics. IEEE, 2013. p. 1\u20136.\nISBN 978-1-4673-5320-5. Dispon\u00edvel em:&lt;http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.\nhtm?arnumber=6584059>. Cited 2 times on pages vi e 11.\n\nMAGNUSSEN, O.; OTTESTAD, M.; HOVLAND, G. Experimental validation of a quaternion-\nbased attitude estimation with direct input to a quadcopter control system. In: 2013\nInternational Conference on Unmanned Aircraft Systems (ICUAS). IEEE, 2013. p. 480\u2013485.\nISBN 978-1-4799-0817-2. Dispon\u00edvel em:&lt;http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.\nhtm?arnumber=6564723>. Cited 4 times on pages vii, 30, 33 e 34.\n\nMOECKEL, R. et al. Gait optimization for roombots modular robots \u2014 Matching\nsimulation and reality. In: 2013 IEEE/RSJ International Conference on Intelligent\nRobots and Systems. IEEE, 2013. p. 3265\u20133272. ISBN 978-1-4673-6358-7. Dispon\u00edvel em:\n<http://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=6696820http://ieeexplore.ieee.org/\nlpdocs/epic03/wrapper.htm?arnumber=6696820>. Cited 3 times on pages vi, 11 e 12.\n\nMORRIS, A. S. Measurement and Instrumentation Principles. 3rd editio. ed. Oxford:\nButterworth, 2001. ISSN 0957-0233. Cited 8 times on pages vi, 15, 16, 17, 19, 20, 21 e 22.\n\nMURATA, S.; KUROKAWA, H. Self-reconfigurable robots. IEEE Robotics &amp; Automation\nMagazine, v. 14, n. 1, p. 71\u201378, mar. 2007. ISSN 1070-9932. Dispon\u00edvel em:&lt;http:\n//ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=4141035http://ieeexplore.ieee.org/lpdocs/\nepic03/wrapper.htm?arnumber=4141035>. Cited 3 times on pages vi, 7 e 8.\n\nMURATA, S. et al. M-TRAN: self-reconfigurable modular robotic system. IEEE/ASME\nTransactions on Mechatronics, v. 7, n. 4, p. 431\u2013441, dez. 2002. ISSN 1083-4435. Dispon\u00edvel em:\n<http://staff.aist.go.jp/e.yoshida/papers/dars2002.pdfhttp://ieeexplore.ieee.org/lpdocs/epic03/\nwrapper.htm?arnumber=1159221>. Cited on page 8.\n\nNORBERG, A. Design Rules, Volume 1: The Power of Modularity [Book Review]. IEEE Annals\nof the History of Computing, MIT Press, Cambridge, MA, v. 23, n. 1, p. 65\u201366, jan. 2001. ISSN\n1058-6180. Dispon\u00edvel em:&lt;http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=\n4496938>. Cited on page 6.\n\nOHNO, H.; HIROSE, S. Design of slim slime robot and its gait of locomotion. Proceedings 2001\nIEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal\nRole of Robotics in the the Next Millennium (Cat. No.01CH37180), v. 2, 2001. Cited on page 6.\n\nOKAMOTO, J. et al. Autonomous system for oil pipelines inspection. Mechatronics, v. 9, n. 7,\np. 731\u2013743, out. 1999. ISSN 09574158. Dispon\u00edvel em:&lt;http://www.sciencedirect.com/science/\n\n68\n\nhttp://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=1389702 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1389702\nhttp://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=1389702 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1389702\nhttp://www.morganclaypool.com/doi/abs/10.2200/S00534ED1V01Y201309SPR012\nhttp://www.morganclaypool.com/doi/abs/10.2200/S00534ED1V01Y201309SPR012\nhttp://linkinghub.elsevier.com/retrieve/pii/S0924424704004716\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6584059\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6584059\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6564723\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6564723\nhttp://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=6696820 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6696820\nhttp://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=6696820 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6696820\nhttp://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=4141035 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4141035\nhttp://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=4141035 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4141035\nhttp://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=4141035 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4141035\nhttp://staff.aist.go.jp/e.yoshida/papers/dars2002.pdf http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1159221\nhttp://staff.aist.go.jp/e.yoshida/papers/dars2002.pdf http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1159221\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4496938\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4496938\nhttp://www.sciencedirect.com/science/article/pii/S0957415899000318 http://linkinghub.elsevier.com/retrieve/pii/S0957415899000318\nhttp://www.sciencedirect.com/science/article/pii/S0957415899000318 http://linkinghub.elsevier.com/retrieve/pii/S0957415899000318\nhttp://www.sciencedirect.com/science/article/pii/S0957415899000318 http://linkinghub.elsevier.com/retrieve/pii/S0957415899000318\n\n\narticle/pii/S0957415899000318http://linkinghub.elsevier.com/retrieve/pii/S0957415899000318>.\nCited on page 5.\n\nPEDLEY, M. Tilt Sensing Using a Three-Axis Accelerometer. Freescale Semiconductor\nApplication Note, p. 2012\u20132013, 2013. Cited on page 32.\n\nPFEIFFER, F.; ROSSMANN, T.; LOFFLER, K. Control of a tube crawling machine.\nIn: 2000 2nd International Conference. Control of Oscillations and Chaos. Proceedings\n(Cat. No.00TH8521). IEEE, 2000. v. 3, p. 586\u2013591. ISBN 0-7803-6434-1. Dispon\u00edvel em:\n<http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=874339>. Cited on page 6.\n\nQIAO, G. et al. Design of a self-reconfigurable wireless network system for modular\nself-reconfigurable robots. In: 2012 IEEE International Conference on Robotics and\nBiomimetics (ROBIO). IEEE, 2012. p. 1337\u20131342. ISBN 978-1-4673-2127-3. Dispon\u00edvel em:\n<http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6491154>. Cited 3 times on\npages vi, 12 e 13.\n\nQIAO, G. et al. Design of transmote: A modular self-reconfigurable robot with versatile\ntransformation capabilities. In: 2012 IEEE International Conference on Robotics and\nBiomimetics (ROBIO). IEEE, 2012. p. 1331\u20131336. ISBN 978-1-4673-2127-3. Dispon\u00edvel em:\n<http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6491153>. Cited 3 times on\npages vi, 12 e 13.\n\nSETCHI, R.; LAGOS, N. Reconfigurability and reconfigurable manufacturing systems\nstate-of-the-art review. In: 2nd IEEE International Conference on Industrial Informatics,\n2004. INDIN \u201904. 2004. IEEE, 2004. p. 529\u2013535. ISBN 0-7803-8513-6. Dispon\u00edvel em:\n<http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1417401>. Cited on page 6.\n\nSHARP. GP2Y0A41SK0F Datasheet. [S.l.], 2002. 1\u20139 p. Cited 5 times on pages xx, xxiii, 39, 54\ne 62.\n\nSOUSA, A. C. C. de et al. ErekoBot Sigma: Prot\u00f3tipo de um rob\u00f4 modular reconfigur\u00e1vel com\nsensores. In: VIII Congresso Nacional de Engenharia Mec\u00e2nica. Uberl\u00e2ndia, MG, Brazil: [s.n.],\n2014. Cited on page 65.\n\nSOUSA, A. C. C. de; VIANA, D. M. a.; KOIKE, C. M. C. e. C. Data Communication and\nProtocols in self-reconfigurable modular robots. In: 22nd International Congress of Mechanical\nEngineering (COBEM 2013). Ribeir\u00e3o Preto, SP, Brazil: ABCM, 2013. Cited 2 times on pages\n13 e 65.\n\nSOUSA, A. C. C. de; VIANA, D. M. a.; KOIKE, C. M. C. e. C. Programando a movimenta\u00e7\u00e3o\nem rob\u00f4s modulares autorreconfigur\u00e1veis \u00e1podes para inspe\u00e7\u00e3o em tubula\u00e7\u00f5es. In: 7o PDPetro\nCongresso Brasileiro de P&amp;D em Petr\u00f3leo e G\u00e1s. Aracaju, SE, Brazil: [s.n.], 2013. Cited on page\n65.\n\nSOUSA, A. C. C. de; VIANA, D. M. a.; KOIKE, C. M. C. e. C. Sensors in Reconfigurable\nModular Robot for Pipeline Inspection : Design and Tests of a Prototype. In: Joint Conference\non Robotics and Intelligent Systems 2014. S\u00e3o Carlos, SP, Brazil: [s.n.], 2014. Cited on page 65.\n\nSPR\u00f6WITZ, a. et al. Roombots: A hardware perspective on 3D self-reconfiguration\nand locomotion with a homogeneous modular robot. Robotics and Autonomous Systems,\nElsevier B.V., v. 62, n. 7, p. 1016\u20131033, jul. 2014. ISSN 09218890. Dispon\u00edvel em:\n<http://linkinghub.elsevier.com/retrieve/pii/S0921889013001632>. Cited 3 times on pages vi,\n11 e 12.\n\n69\n\nhttp://www.sciencedirect.com/science/article/pii/S0957415899000318 http://linkinghub.elsevier.com/retrieve/pii/S0957415899000318\nhttp://www.sciencedirect.com/science/article/pii/S0957415899000318 http://linkinghub.elsevier.com/retrieve/pii/S0957415899000318\nhttp://www.sciencedirect.com/science/article/pii/S0957415899000318 http://linkinghub.elsevier.com/retrieve/pii/S0957415899000318\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=874339\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6491154\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6491153\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1417401\nhttp://linkinghub.elsevier.com/retrieve/pii/S0921889013001632\n\n\nSTREICH, H.; ADRIA, O. Software approach for the autonomous inspection robot MAKRO.\nIn: IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA \u201904.\n2004. IEEE, 2004. v. 4, p. 3411\u20133416 Vol.4. ISBN 0-7803-8232-3. ISSN 1050-4729. Dispon\u00edvel em:\n<http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1308781>. Cited on page 6.\n\nTorres Jr, C. R.; MANZAK, P. T.; MILLER, J. E. Variable speed PIG for pipeline applications.\n2002. Cited on page 6.\n\nUSTA, U. Y. Comparison of quaternion and Euler angle methods for joint angle animation of\nhuman figure models. Tese (Master of Science in Computer Science) \u2014 Naval Postgraduate\nSchool, 1999. Cited 2 times on pages vi e 24.\n\nVESPIGNANI, M. et al. An experimental study on the role of compliant elements on the\nlocomotion of the self-reconfigurable modular robots Roombots. In: 2013 IEEE/RSJ International\nConference on Intelligent Robots and Systems. IEEE, 2013. p. 4308\u20134313. ISBN 978-1-4673-6358-7.\nDispon\u00edvel em:&lt;http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6696974>.\nCited 3 times on pages vi, 11 e 12.\n\nWANG, X.; ZHU, Y.; ZHAO, J. A dynamic simulation and virtual evolution platform for\nmodular self-reconfigurable robots. In: 2013 IEEE International Conference on Information\nand Automation (ICIA). IEEE, 2013. p. 457\u2013462. ISBN 978-1-4799-1334-3. Dispon\u00edvel em:\n<http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6720342>. Cited 2 times on\npages vi e 10.\n\nYE, S. et al. Robust robotic grasping using IR Net-Structure Proximity Sensor to handle\nobjects with unknown position and attitude. In: 2013 IEEE International Conference on\nRobotics and Automation. IEEE, 2013. p. 3271\u20133278. ISBN 978-1-4673-5643-5. Dispon\u00edvel\nem:&lt;http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6631033http:\n//ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6564723>. Cited 2 times on pages\nvii e 35.\n\nYIM, M. Polypod: Locomotion With a Unit Modular Reconfigurable Robot. Tese (PhD) \u2014 Stanford\nUniversity, 1994. Cited 3 times on pages xv, 1 e 6.\n\nYIM, M. et al. Connecting and disconnecting for chain self-reconfiguration with PolyBot.\nIEEE/ASME Transactions on Mechatronics, v. 7, n. 4, p. 442\u2013451, dez. 2002. ISSN 1083-4435.\nDispon\u00edvel em:&lt;http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1159222>.\nCited 2 times on pages 8 e 9.\n\nZHU, Y. et al. Design and implementation of UBot: A modular Self-Reconfigurable Robot. In:\n2013 IEEE International Conference on Mechatronics and Automation. IEEE, 2013. p. 1217\u20131222.\nISBN 978-1-4673-5560-5. Dispon\u00edvel em:&lt;http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.\nhtm?arnumber=6618087>. Cited 2 times on pages vi e 10.\n\n70\n\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1308781\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6696974\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6720342\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6631033 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6564723\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6631033 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6564723\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1159222\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6618087\nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6618087\n\n\nAppendix\n\n71\n\n\n\nI. DEMONSTRATIONS\n\nI.1 Six possible rotation matrix\n\n~Rxyz\n\n?\n?? 00\n\n1\n\n?\n?? = ~Rx(?) ~Ry(?) ~Rz(?)\n\n?\n?? 00\n\n1\n\n?\n??\n\n=\n\n?\n?? cos ? cos ? cos ? sin ? ?sin ?cos ? sin ? sin ?? cos ? sin ? cos ? cos ? + sin ? sin ? sin ? cos ? sin ?\n\ncos ? cos ? sin ? + sin ? sin ? cos ? sin ? sin ? ? cos ? sin ? cos ? cos ?\n\n?\n??\n?\n?? 00\n\n1\n\n?\n??\n\n=\n\n?\n?? ?sin ?cos ? sin ?\n\ncos ? cos ?\n\n?\n?? (I.1)\n\n~Ryxz\n\n?\n?? 00\n\n1\n\n?\n?? = ~Ry(?) ~Rx(?) ~Rz(?)\n\n?\n?? 00\n\n1\n\n?\n??\n\n=\n\n?\n?? cos ? cos ? ? sin ? sin ? sin ? sin ? cos ? + sin ? sin ? cos ? ?sin ? cos ??cos ? sin ? cos ? cos ? sin ?\n\ncos ? sin ? cos ? + sin ? cos ? ?cos ? cos ? sin ? + sin ? sin ? cos ? cos ?\n\n?\n??\n?\n?? 00\n\n1\n\n?\n??\n\n=\n\n?\n?? ?sin ? cos ?sin ?\n\ncos ? cos ?\n\n?\n?? (I.2)\n\n~Rxzy\n\n?\n?? 00\n\n1\n\n?\n?? = ~Rx(?) ~Rz(?) ~Ry(?)\n\n?\n?? 00\n\n1\n\n?\n??\n\n=\n\n?\n?? cos ? cos ? sin ? ?cos ? sin ??cos ? cos ? sin ? + sin ? sin ? cos ? cos ? cos ? sin ? + cos ? sin ? sin ?\n\ncos ? sin ? sin ? + cos ? sin ? ?cos ? sin ? cos ? cos ?? sin ? sin ? sin ?\n\n?\n??\n?\n?? 00\n\n1\n\n?\n??\n\n=\n\n?\n?? ?cos ? sin ?cos ? sin ? + cos ? sin ? sin ?\n\ncos ? cos ? ? sin ? sin ? sin ?\n\n?\n?? (I.3)\n\n72\n\n\n\n~Ryzx\n\n?\n?? 00\n\n1\n\n?\n?? = ~Ry(?) ~Rz(?) ~Rx(?)\n\n?\n?? 00\n\n1\n\n?\n??\n\n=\n\n?\n?? cos ? cos ? cos ? cos ? sin ? + sin ? sin ? cos ? sin ? sin ? ? sin ? cos ??sin ? cos ? cos ? cos ? sin ?\n\ncos ? sin ? ?cos ? sin ? + cos ? sin ? sin ? cos ? cos ? + sin ? sin ? sin ?\n\n?\n??\n?\n?? 00\n\n1\n\n?\n??\n\n=\n\n?\n?? cos ? sin ? sin ? ? cos ? sin ?cos ? sin ?\n\ncos ? cos ? + sin ? sin ? sin ?\n\n?\n?? (I.4)\n\n~Rzxy\n\n?\n?? 00\n\n1\n\n?\n?? = ~Rz(?) ~Rx(?) ~Ry(?)\n\n?\n?? 00\n\n1\n\n?\n??\n\n=\n\n?\n?? cos ? cos ? + sin ? sin ? sin ? cos ? sin ? cos ? sin ? sin ? ? sin ? cos ??cos ? sin ? + cos ? sin ? sin ? cos ? cos ? cos ? cos ? sin ? + sin ? sin ?\n\ncos ? sin ? ?sin ? cos ? cos ?\n\n?\n??\n?\n?? 00\n\n1\n\n?\n??\n\n=\n\n?\n?? cos ? sin ? sin ? ? cos ? sin ?cos ? cos ? sin ? + sin ? sin ?\n\ncos ? cos ?\n\n?\n?? (I.5)\n\n~Rzyx\n\n?\n?? 00\n\n1\n\n?\n?? = ~Rz(?) ~Ry(?) ~Rx(?)\n\n?\n?? 00\n\n1\n\n?\n??\n\n=\n\n?\n?? cos ? cos ? cos ? sin ? + cos ? sin ? sin ? sin ? sin ? ? cos ? cos ? sin ??cos ? sin ? cos ? cos ? + sin ? sin ? sin ? cos ? sin ? + cos ? sin ? sin ?\n\nsin ? ?cos ? sin ? cos ? cos ?\n\n?\n??\n?\n?? 00\n\n1\n\n?\n??\n\n=\n\n?\n?? sin ? sin ? ? cos ? cos ? sin ?cos ? sin ? + cos ? sin ? sin ?\n\ncos ? cos ?\n\n?\n?? (I.6)\n\n73\n\n\n\nII. LIBRARIES\n\nWe programed some libraries in C Language for the ErekoBot ? , and the architecture of the\nsoftware works as follows (Figure II.1):\n\n\u2022 The main.c controls the servo motor thought PWM signal using servo.h library.\n\n\u2022 The main.c controls the LEDs connected to I/O pins using leds.h library.\n\n\u2022 The main.c sends and receives messages through USART using USART.h library.\n\n\u2022 The main.c receives data from the IR Sensors connected to AD ports using adc.h library.\n\n\u2013 The SHARP-0A41SKF36.h library converts the binary data to a volts metric system.\n\n\u2022 The main.c receives data from the IMU connected to the I2C pins using i2c.h library.\n\n\u2013 The ADXL345.h holds the accelerometer address and saves the binary data to more\nreadable variables.\n\n\u2013 The ITG-3200.h holds the gyroscope address and saves the binary data to more readable\nvariables.\n\nFigure II.1: Libraries architecture.\n\nThe main.c program depends of the routine of the experiments showed in Section 5.\n\nII.1 Codes\n\nWe programed all codes n C Language and compiled them with avr-gcc in Ubuntu 12.04 LTS.\n\n74\n\n\n\nII.1.1 servo.h\n\n1 #i f n d e f servo_HEADER_GUARD\n#d e f i n e servo_HEADER_GUARD\n\n3\n\ne x t e r n v o i d s e r v o I n i t ( v o i d ) ;\n5 e x t e r n v o i d s e r v o A n g l e ( uint16_t a n g l e ) ;\n\n7 #e n d i f\n\nAppendix\u2013B/codes/servo.h\n\nII.1.1.1 servo.c\n\n/?\n2 Setup s e r v o motor .\n\n4 @author Ana C a r o l i n a Cardoso de Sousa\n@ v e r s i o n 1 . 0\n\n6\n\n?/\n8\n\n#i n c l u d e&lt;avr / i o . h>\n10 #i n c l u d e \" s e r v o . h\"\n\n12 v o i d s e r v o I n i t ( v o i d ) {\n\n14 TCCR1A |= (1<<COM1A1) | (1<<WGM11) ; // non?i n v e r t i n g mode f o r OC1A\nTCCR1B |= (1<<WGM13) | (1<<WGM12) | (1<<CS11 ) ; // Mode 1 4 , P r e s c a l e r 8\n\n16 ICR1 = 4 0 0 0 0 ; // 320000 / 8 = 40000\nDDRB |= (1<<PB1) ; // OC1A s e t t o output\n\n18\n\ns e r v o A n g l e ( 3 0 0 0 ) ;\n20 }\n\n22 v o i d s e r v o A n g l e ( uint16_t a n g l e ) {\n\n24 OCR1A = a n g l e ;\n\n26 }\n\nAppendix\u2013B/codes/servo.c\n\nII.1.2 leds.h\n\n1 #i f n d e f leds_HEADER_GUARD\n#d e f i n e leds_HEADER_GUARD\n\n3\n\n#d e f i n e RED 0\n5 #d e f i n e GREEN 1\n\n7 e x t e r n v o i d l e d s I n i t ( v o i d ) ;\ne x t e r n v o i d ledON ( u n s i g n e d c h a r c o r ) ;\n\n9 e x t e r n v o i d ledOFF ( u n s i g n e d c h a r c o r ) ;\n\n75\n\n\n\n11 #e n d i f\n\nAppendix\u2013B/codes/leds.h\n\nII.1.2.1 leds.c\n\n/?\n2 Setup l e d s .\n\n4 @author Ana C a r o l i n a Cardoso de Sousa\n@ v e r s i o n 1 . 0\n\n6\n\n?/\n8\n\n#i n c l u d e&lt;avr / i o . h>\n10 #i n c l u d e \" l e d s . h\"\n\n12 v o i d l e d s I n i t ( v o i d ) {\n\n14 DDRB = _BV(PB0) ; // Green Pin\nDDRD = _BV(PD7) ; //Red Pin\n\n16 }\n\n18 v o i d ledON ( u n s i g n e d c h a r c o r ) {\n\n20 /?Switch f o r : r e c e p t o r , t r a n s m i s s o r , r e c e p t o r and t r a n s m i s s o r?/\ns w i t c h ( c o r ) {\n\n22 c a s e GREEN:\nPORTB |= _BV(PB0) ; break ;\n\n24 c a s e RED:\nPORTD |= _BV(PD7) ; break ;\n\n26 d e f a u l t :\nbreak ;\n\n28 }\n}\n\n30\n\nv o i d ledOFF ( u n s i g n e d c h a r c o r ) {\n32\n\n/?Switch f o r : r e c e p t o r , t r a n s m i s s o r , r e c e p t o r and t r a n s m i s s o r?/\n34 s w i t c h ( c o r ) {\n\nc a s e GREEN:\n36 PORTB &amp;= ~_BV(PB0) ; break ;\n\nc a s e RED:\n38 PORTD &amp;= ~_BV(PD7) ; break ;\n\nd e f a u l t :\n40 break ;\n\n}\n42 }\n\nAppendix\u2013B/codes/leds.c\n\nII.1.3 USART.h\n\n#i f n d e f USART_HEADER_GUARD\n2 #d e f i n e USART_HEADER_GUARD\n\n76\n\n\n\n4 #d e f i n e SYNC 0 x44\n#d e f i n e RADDR 0 x00\n\n6 #d e f i n e RECEPTOR 0\n#d e f i n e TRANSMISSOR 1\n\n8 #d e f i n e RECEPTOR_E_TRANSMISSOR 2\n\n10 e x t e r n v o i d USART_Init ( u n s i g n e d i n t ubrr , u n s i g n e d c h a r t i p o ) ;\ne x t e r n v o i d USART_TransmitByte ( uint8_t data ) ;\n\n12 e x t e r n v o i d USART_TransmitPackage ( uint8_t sync , uint8_t addr , u n s i g n e d i n t cmd) ;\ne x t e r n v o i d USART_SensorPackage ( uint8_t sync , uint8_t addr , u n s i g n e d i n t cmd) ;\n\n14 e x t e r n v o i d USART_TransmitSensorPackage ( uint8_t sync , uint8_t addr , s i g n e d s h o r t i n t ?gyro ,\ns i g n e d s h o r t i n t ?acc , uint16_t d1 , uint16_t d2 ) ;\n\n16 #e n d i f\n\nAppendix\u2013B/codes/USART.h\n\nII.1.3.1 USART.c\n\n1 /? Setup USART.\n\n3 @author Ana C a r o l i n a Cardoso de Sousa\n@ v e r s i o n 2 . 0?/\n\n5\n\n#i n c l u d e&lt;avr / i o . h>\n7 #i n c l u d e \"USART. h\"\n\n9 /?Setup frame : 8?b i t , 2 s t o p b i t s . Setup b o u d r a t e : u b r r .\n\n11 @param u b r r b o u d r a t e\n@param t i p o type o f communication , r e c e p t o r , t r a n s m i s s o r , r e c e p t o r and t r a n s m i s s o r . ?/\n\n13\n\nv o i d USART_Init ( u n s i g n e d i n t ubrr , u n s i g n e d c h a r t i p o ) {\n15\n\nUBRR0H = ( u n s i g n e d c h a r ) ( u b r r >> 8 ) ; /?b a u d r a t e h i g h?/\n17 UBRR0L = ( u n s i g n e d c h a r ) u b r r ; /?b a u d r a t e low?/\n\n19 /?Frame : asynchronous , no p a r i t y , 8?b i t , 1 s t o p b i t ?/\nUCSR0C |= (1<<UMSEL01) | (0<<UMSEL00) | (0<<UPM01) | (0<<UPM00) | (0<<USBS0) | (1<<UCSZ01\n\n) | (1<<UCSZ00 ) | (0<<UCPOL0) ;\n21\n\n/?Switch f o r : r e c e p t o r , t r a n s m i s s o r , r e c e p t o r and t r a n s m i s s o r?/\n23 s w i t c h ( t i p o ) {\n\nc a s e RECEPTOR:\n25 UCSR0B = ( 1&lt;&lt;RXEN0) | ( 1&lt;&lt;RXCIE0) ; break ;\n\nc a s e TRANSMISSOR:\n27 UCSR0B = ( 1&lt;&lt;TXEN0) ; break ;\n\nd e f a u l t :\n29 UCSR0B = ( 1&lt;&lt;RXEN0) | ( 1&lt;&lt;RXCIE0) | ( 1&lt;&lt;TXEN0) ; break ;\n\n}\n31\n\n}\n33\n\n/?Write i n t h e b u f f e r .\n35\n\n@param data Byte t r a n s m i t e d . ?/\n37\n\n77\n\n\n\nv o i d USART_TransmitByte ( u n s i g n e d c h a r data ) {\n39\n\nw h i l e ( (UCSR0A&amp;(1<<UDRE0) ) == 0 ) ; /?Wait t h e t r a n s m i s s i o n b u f f e r c l e a r ?/\n41\n\nUDR0 = data ; /?Put i t a t t h e b u f f e r ( send byte )?/\n43 }\n\n45 /?Write data t h e b u f f e r .\n\n47 @param addr SYNC Byte\n@param addr Receptor a d d r e s s\n\n49 @param cmd Data?/\n\n51 v o i d USART_TransmitPackage ( uint8_t sync , uint8_t addr , u n s i g n e d i n t cmd) {\n\n53 uint8_t chk ;\nchk = addr+cmd ;\n\n55\n\n/?Send Package?/\n57 USART_TransmitByte ( sync ) ; // sync byte\n\nUSART_TransmitByte ( addr ) ; // r e c e p t o r a d d r e s s byte\n59 USART_TransmitByte ( ( u n s i g n e d c h a r ) (cmd >> 8 ) ) ; // data h i g h 8 b i t s\n\nUSART_TransmitByte ( ( u n s i g n e d c h a r )cmd) ; // data low 8 b i t s\n61 USART_TransmitByte ( chk ) ; // checksum\n\n}\n63\n\n/?Transmit s e n s o r package\n65\n\n@param addr Sync Byte\n67 @param addr Receptor a d d r e s s\n\n@param gyro Gyro Data\n69 @param a c c Acc Data\n\n71 ?/\n\n73 v o i d USART_TransmitSensorPackage ( uint8_t sync , uint8_t addr , s i g n e d s h o r t i n t ?gyro , s i g n e d\ns h o r t i n t ?acc , uint16_t d1 , uint16_t d2 ) {\n\n75 uint8_t chk ;\ns i g n e d s h o r t i n t gx , gy , gz ;\n\n77 s i g n e d s h o r t i n t ax , ay , az ;\nchk = addr+sync ;\n\n79\n\n// Get gyro\n81 gx = gyro [ 0 ] ;\n\ngy = gyro [ 1 ] ;\n83 gz = gyro [ 2 ] ;\n\n85 // Get a c c\nax = a c c [ 0 ] ;\n\n87 ay = a c c [ 1 ] ;\naz = a c c [ 2 ] ;\n\n89\n\n/?Send Package?/\n91 USART_TransmitByte ( sync ) ; // sync byte\n\nUSART_TransmitByte ( addr ) ; // r e c e p t o r a d d r e s s byte\n93\n\nUSART_TransmitByte ( ( u n s i g n e d c h a r ) ( gyro [ 0 ] >> 8 ) ) ; // data h i g h 8 b i t s gyro\n95 USART_TransmitByte ( ( u n s i g n e d c h a r ) gyro [ 0 ] ) ; // data low 8 b i t s gyro\n\nUSART_TransmitByte ( ( u n s i g n e d c h a r ) ( gyro [ 1 ] >> 8 ) ) ; // data h i g h 8 b i t s gyro\n\n78\n\n\n\n97 USART_TransmitByte ( ( u n s i g n e d c h a r ) gyro [ 1 ] ) ; // data low 8 b i t s gyro\nUSART_TransmitByte ( ( u n s i g n e d c h a r ) ( gyro [ 2 ] >> 8 ) ) ; // data h i g h 8 b i t s gyro\n\n99 USART_TransmitByte ( ( u n s i g n e d c h a r ) gyro [ 2 ] ) ; // data low 8 b i t s gyro\n\n101 USART_TransmitByte ( ( u n s i g n e d c h a r ) ( a c c [ 0 ] >> 8 ) ) ; // data h i g h 8 b i t s a c c\nUSART_TransmitByte ( ( u n s i g n e d c h a r ) a c c [ 0 ] ) ; // data low 8 b i t s a c c\n\n103 USART_TransmitByte ( ( u n s i g n e d c h a r ) ( a c c [ 1 ] >> 8 ) ) ; // data h i g h 8 b i t s a c c\nUSART_TransmitByte ( ( u n s i g n e d c h a r ) a c c [ 1 ] ) ; // data low 8 b i t s a c c\n\n105 USART_TransmitByte ( ( u n s i g n e d c h a r ) ( a c c [ 2 ] >> 8 ) ) ; // data h i g h 8 b i t s a c c\nUSART_TransmitByte ( ( u n s i g n e d c h a r ) a c c [ 2 ] ) ; // data low 8 b i t s a c c\n\n107\n\nUSART_TransmitByte ( ( u n s i g n e d c h a r ) ( d1 >> 8 ) ) ; // data h i g h 8 b i t s IR1\n109 USART_TransmitByte ( ( u n s i g n e d c h a r ) d1 ) ; // data low 8 b i t s IR1\n\nUSART_TransmitByte ( ( u n s i g n e d c h a r ) ( d2 >> 8 ) ) ; // data h i g h 8 b i t s IR2\n111 USART_TransmitByte ( ( u n s i g n e d c h a r ) d2 ) ; // data low 8 b i t s IR2\n\n113 USART_TransmitByte ( chk ) ; // checksum\n}\n\nAppendix\u2013B/codes/USART.c\n\nII.1.4 adc.h\n\n1 #i f n d e f adc_HEADER_GUARD\n#d e f i n e adc_HEADER_GUARD\n\n3\n\ne x t e r n v o i d a d c I n i t ( v o i d ) ;\n5 e x t e r n i n t 1 6 _ t adcRead ( c h a r ch ) ;\n\ne x t e r n i n t 1 6 _ t adcReadMean ( c h a r ch ) ;\n7\n\n#e n d i f\n\nAppendix\u2013B/codes/adc.h\n\nII.1.4.1 adc.c\n\n/?\n2 ADC f u n c t i o n s .\n\n4 @author Ana C a r o l i n a Cardoso de Sousa\n@date 2014/05/12\n\n6 @ v e r s i o n 1 . 0\n?/\n\n8\n\n#i n c l u d e&lt;avr / i o . h>\n10 #i n c l u d e&lt;s t d i n t . h>\n\n#i n c l u d e \" adc . h\"\n12\n\n/? I n i t i a l i z e s t h e ADC. ?/\n14 v o i d a d c I n i t ( v o i d ) {\n\n16 //AREF = AVcc , ADC l e f t a d j u s t r e s u l t\nADMUX = (0<<REFS1) |(1<<REFS0) |(1<<ADLAR) ;\n\n18 //ADC Enable , P r e s c a l e r o f 128 ( 1 6M/128 = 125 k )\nADCSRA = (1<<ADEN) |(1<<ADPS2) |(1<<ADPS1) |(1<<ADPS0) ;\n\n79\n\n\n\n20 }\n\n22 /? Reads t h e v a l u e o f t h e ADC. ?/\ni n t 1 6 _ t adcRead ( c h a r ch ) {\n\n24\n\n// S e l e c t t h e c o r r e s p o n d i n g c h a n n e l 0~7\n26 ch &amp;= 0 b00000111 ; // always keep t h e v a l u e o f ch between 0 and 7\n\nADMUX = (ADMUX &amp; 0xF8 ) | ch ; // c l e a r s t h e bottom 3 b i t s b e f o r e ORing\n28\n\n// S t a r t s i n g l e c o n v e r t i o n\n30 ADCSRA |= (1<<ADSC) ;\n\n32 // Wait f o r c o n v e r s i o n t o c o m p l e t e\nw h i l e (ADCSRA &amp; (1<<ADSC) ) ;\n\n34\n\nr e t u r n (ADC) ;\n36 }\n\n38 /? Reads many v a l u e s o f ADC. ?/\ni n t 1 6 _ t adcReadMean ( c h a r ch ) {\n\n40\n\ni n t 3 2 _ t temp = 0 ;\n42 i n t 1 6 _ t adc = 0 ;\n\ni n t 8 _ t i = 0 ;\n44\n\nf o r ( i =0; i&lt;5; i ++){\n46 temp += adcRead ( ch ) ;\n\n}\n48\n\nadc = temp / 5 ;\n50\n\nr e t u r n ( adc ) ;\n52 }\n\nAppendix\u2013B/codes/adc.c\n\nII.1.5 SHARP-0A41SKF36.h\n\n#i f n d e f SHARP0A41SKF36_HEADER_GUARD\n2 #d e f i n e SHARP0A41SKF36_HEADER_GUARD\n\n4 #d e f i n e T1 00\n#d e f i n e T2 01\n\n6 #d e f i n e F1 02\n#d e f i n e F2 03\n\n8\n\ne x t e r n i n t 1 6 _ t s h i f t 6 ( i n t 1 6 _ t adc ) ;\n10 e x t e r n i n t 1 6 _ t a d c 2 v o l t s ( i n t 3 2 _ t adc ) ;\n\ne x t e r n i n t 1 6 _ t ?r e a d F r o n t ( v o i d ) ;\n12 e x t e r n i n t 1 6 _ t ?readBack ( v o i d ) ;\n\n14 #e n d i f\n\nAppendix\u2013B/codes/SHARP\u20130A41SKF36.h\n\nII.1.5.1 SHARP-0A41SKF36.c\n\n80\n\n\n\n/?\n2 SHARP?0A41SKF36 f u n c t i o n s .\n\n4 @author Ana C a r o l i n a Cardoso de Sousa\n@date 2014/05/30\n\n6 @ v e r s i o n 1 . 0\n?/\n\n8\n\n#i n c l u d e&lt;s t d i n t . h>\n10 #i n c l u d e \"SHARP?0A41SKF36 . h\"\n\n#i n c l u d e \" adc . h\"\n12\n\n/? S h i f t adc v a l u e?/\n14 i n t 1 6 _ t s h i f t 6 ( i n t 1 6 _ t adc ) {\n\nr e t u r n adc = adc >> 6 ;\n16 }\n\n18 /?Converts adc t o v o l t s ?/\ni n t 1 6 _ t a d c 2 v o l t s ( i n t 3 2 _ t adc ) {\n\n20 i n t 6 4 _ t x ;\n\n22 x = s h i f t 6 ( adc ) ;\nx = ( 5 0 0 0?x ) ; // 5?1000?x\n\n24 x = ( x>>10) ; // r e s u l t = x /1024\n\n26 r e t u r n ( i n t 1 6 _ t ) x ;\n\n28 }\n\n30 /? Reads t h e IR S e n s o r s \u2019 Front \u2019 v a l u e s ?/\ni n t 1 6 _ t ?r e a d F r o n t ( v o i d ) {\n\n32\n\ns t a t i c i n t 1 6 _ t adc [ 2 ] ;\n34\n\nadc [ 0 ] = adcRead ( F1 ) ; // r e a d adc v a l u e a t F1\n36 adc [ 1 ] = adcRead ( F2 ) ; // r e a d adc v a l u e a t F2\n\n38 r e t u r n adc ;\n}\n\n40\n\n/? Reads t h e IR S e n s o r s \u2019 Back \u2019 v a l u e s ?/\n42 i n t 1 6 _ t ?readBack ( v o i d ) {\n\n44 s t a t i c i n t 1 6 _ t adc [ 2 ] ;\n\n46 adc [ 0 ] = adcRead (T1) ; // r e a d adc v a l u e a t T1\nadc [ 1 ] = adcRead (T2) ; // r e a d adc v a l u e a t T2\n\n48\n\nr e t u r n adc ;\n50 }\n\nAppendix\u2013B/codes/SHARP\u20130A41SKF36.c\n\nII.1.6 i2c.h\n\n#i f n d e f i2c_HEADER_GUARD\n2 #d e f i n e i2c_HEADER_GUARD\n\n81\n\n\n\n4 #i n c l u d e&lt;avr / i o . h>\n#i n c l u d e&lt;avr / i n t e r r u p t . h>\n\n6 #i n c l u d e &lt;u t i l / d e l a y . h>\n#i n c l u d e \" t y p e s . h\"\n\n8 #i n c l u d e \" d e f s . h\"\n\n10 #d e f i n e TW_START 0 x08\n#d e f i n e TW_REP_START 0 x10\n\n12 #d e f i n e TW_MT_SLA_ACK 0 x18\n#d e f i n e TW_MT_SLA_NACK 0 x20\n\n14 #d e f i n e TW_MT_DATA_ACK 0 x28\n#d e f i n e TW_MT_DATA_NACK 0 x30\n\n16 #d e f i n e TW_MT_ARB_LOST 0 x38\n#d e f i n e TW_MR_ARB_LOST 0 x38\n\n18 #d e f i n e TW_MR_SLA_ACK 0 x40\n#d e f i n e TW_MR_SLA_NACK 0 x48\n\n20 #d e f i n e TW_MR_DATA_ACK 0 x50\n#d e f i n e TW_MR_DATA_NACK 0 x58\n\n22 #d e f i n e TW_ST_SLA_ACK 0xA8\n#d e f i n e TW_ST_ARB_LOST_SLA_ACK 0xB0\n\n24 #d e f i n e TW_ST_DATA_ACK 0xB8\n#d e f i n e TW_ST_DATA_NACK 0xC0\n\n26 #d e f i n e TW_ST_LAST_DATA 0xC8\n#d e f i n e TW_SR_SLA_ACK 0 x60\n\n28 #d e f i n e TW_SR_ARB_LOST_SLA_ACK 0 x68\n#d e f i n e TW_SR_GCALL_ACK 0 x70\n\n30 #d e f i n e TW_SR_ARB_LOST_GCALL_ACK 0 x78\n#d e f i n e TW_SR_DATA_ACK 0 x80\n\n32 #d e f i n e TW_SR_DATA_NACK 0 x88\n#d e f i n e TW_SR_GCALL_DATA_ACK 0 x90\n\n34 #d e f i n e TW_SR_GCALL_DATA_NACK 0 x98\n#d e f i n e TW_SR_STOP 0xA0\n\n36 #d e f i n e TW_NO_INFO 0xF8\n#d e f i n e TW_BUS_ERROR 0 x00\n\n38 #d e f i n e TWCR_CMD_MASK 0x0F\n#d e f i n e TWSR_STATUS_MASK 0xF8\n\n40 #d e f i n e I2C_OK 0 x00\n#d e f i n e I2C_ERROR_NODEV 0 x01\n\n42\n\n#d e f i n e s b i ( var , mask ) ( ( var ) |= ( uint8_t ) ( 1&lt;&lt;mask ) )\n44 #d e f i n e c b i ( var , mask ) ( ( var ) &amp;= ( uint8_t ) ~(1&lt;&lt;mask ) )\n\n46 #d e f i n e WRITE_sda ( ) DDRC = DDRC | 0 b00010000 //SDA must be output when w r i t i n g\n#d e f i n e READ_sda ( ) DDRC = DDRC &amp; 0 b11101111 //SDA must be i n p u t when r e a d i n g ? don \u2019 t\n\nf o r g e t t h e r e s i s t o r on SDA ! !\n48\n\n// f u n c t i o n s\n50 v o i d i 2 c I n i t ( v o i d ) ;\n\nv o i d i 2 c S e n d S t a r t ( v o i d ) ;\n52 v o i d i 2 c S e n d S t o p ( v o i d ) ;\n\nv o i d i2cWaitForComplete ( v o i d ) ;\n54 v o i d i2cS endByte ( u n s i g n e d c h a r data ) ;\n\nv o i d i 2 c R e c e i v e B y t e ( u n s i g n e d c h a r ackFlag ) ;\n56 u n s i g n e d c h a r i 2 c G e t R e c e i v e d B y t e ( v o i d ) ;\n\nu n s i g n e d c h a r i 2 c G e t S t a t u s ( v o i d ) ;\n58\n\n#e n d i f\n\nAppendix\u2013B/codes/i2c.h\n\n82\n\n\n\nII.1.6.1 SHARP-0A41SKF36.c\n\n1 /?\nI2C f u n c t i o n s\n\n3\n\n@author Ana C a r o l i n a Cardoso de Sousa\n5 @date 2014/04/23\n\n@ v e r s i o n 1 . 0\n7 ?/\n\n9 #i n c l u d e \" i 2 c . h\"\n\n11 // I n i t i a l i z e I2C (TWI) i n t e r f a c e\nv o i d i 2 c I n i t ( v o i d ) {\n\n13 c b i (TWSR, TWPS0) ;\nc b i (TWSR, TWPS1) ;\n\n15\n\noutb (TWBR, 1 2 ) ; // That j u s t work f o r 16MHz, l o o k a t :\n17 // ATMega8 DataSheet t a b l e (CPU and SCL I2C f r e q u e n c y )\n\ns b i (TWCR, TWEN) ; // Enable TWI\n19 _delay_ms ( 2 0 0 ) ;\n\n}\n21\n\n// Low?l e v e l I2C t r a n s a c t i o n commands\n23 // Send an I2C s t a r t c o n d i t i o n i n Master mode\n\nv o i d i 2 c S e n d S t a r t ( v o i d ) {\n25 WRITE_sda ( ) ;\n\n// send s t a r t c o n d i t i o n\n27 TWCR = (1<<TWINT) |(1<<TWSTA) |(1<<TWEN) ;\n\n}\n29\n\n// Send an I2C s t o p c o n d i t i o n i n Master mode\n31 v o i d i 2 c S e n d S t o p ( v o i d ) {\n\n// t r a n s m i t s t o p c o n d i t i o n\n33 TWCR = (1<<TWINT) |(1<<TWEN) |(1<<TWSTO) ;\n\n}\n35\n\n// Wait f o r c u r r e n t I2C o p e r a t i o n t o c o m p l e t e\n37 v o i d i2cWaitForComplete ( v o i d ) {\n\ni n t i = 0 ; // time out v a r i a b l e\n39\n\n// w a i t f o r i 2 c i n t e r f a c e t o c o m p l e t e o p e r a t i o n\n41 w h i l e ( ( ! (TWCR &amp; (1<<TWINT) ) ) &amp;&amp; ( i &lt;9 0 ) )\n\ni ++;\n43 }\n\n45 // Send an ( a d d r e s s |R/W) c o m b i n a t i o n o r a data byte o v e r I2C\nv o i d i2cS endByte ( u n s i g n e d c h a r data ) {\n\n47 _delay_ms ( 1 ) ;\n// p r i n t f ( \" s e n d i n g 0x%x\\n \" , data ) ;\n\n49 WRITE_sda ( ) ;\n// s a v e data t o t h e TWDR\n\n51 TWDR = data ;\n// b e g i n send\n\n53 TWCR = (1<<TWINT) |(1<<TWEN) ;\n}\n\n55\n\n// ! R e c e i v e a data byte o v e r I2C\n57 // ackFlag = TRUE i f r e c e v i e d data s h o u l d be ACK \u2019 ed\n\n// ackFlag = FALSE i f r e c e v i e d data s h o u l d be NACK\u2019 ed\n\n83\n\n\n\n59 v o i d i 2 c R e c e i v e B y t e ( u n s i g n e d c h a r ackFlag ) {\n// b e g i n r e c e i v e o v e r i 2 c\n\n61 i f ( ackFlag ) {\n// ackFlag = TRUE: ACK t h e r e c e v i e d data\n\n63 outb (TWCR, ( i n b (TWCR)&amp;TWCR_CMD_MASK) |BV(TWINT) |BV(TWEA) ) ;\n}\n\n65 e l s e {\n// ackFlag = FALSE : NACK t h e r e c e v i e d data\n\n67 outb (TWCR, ( i n b (TWCR)&amp;TWCR_CMD_MASK) |BV(TWINT) ) ;\n}\n\n69 }\n\n71 // Pick up t h e data t h a t was r e c e i v e d with i 2 c R e c e i v e B y t e ( )\nu n s i g n e d c h a r i 2 c G e t R e c e i v e d B y t e ( v o i d ) {\n\n73 // r e t i e v e r e c e i v e d data byte from i 2 c TWDR\nr e t u r n ( i n b (TWDR) ) ;\n\n75 }\n\n77 // Get c u r r e n t I 2 c bus s t a t u s from TWSR\nu n s i g n e d c h a r i 2 c G e t S t a t u s ( v o i d ) {\n\n79 // r e t i e v e c u r r e n t i 2 c s t a t u s from i 2 c TWSR\nr e t u r n ( i n b (TWSR) ) ;\n\n81 }\n\nAppendix\u2013B/codes/i2c.c\n\nII.1.7 ADXL-345.h\n\n1 #i f n d e f ADXL345_HEADER_GUARD\n#d e f i n e ADXL345_HEADER_GUARD\n\n3\n\n// ADXL?345 a d d r e s s e s\n5 #d e f i n e ADXL345_R 0xA7 // ADD p i n i s p u l l e d h i g h\n\n#d e f i n e ADXL345_W 0xA6 // So a d d r e s s i s 0 x53\n7\n\n// ADXL?345 r e g i s t e r s\n9 #d e f i n e WHO 0 x00\n\n#d e f i n e BW_Rate 0x2C\n11 #d e f i n e PWR_CTL 0x2D\n\n#d e f i n e INT_SRC 0 x30\n13 #d e f i n e DATA_FORMAT 0 x31\n\n#d e f i n e AX_L 0 x32\n15 #d e f i n e AX_H 0 x33\n\n#d e f i n e AY_L 0 x34\n17 #d e f i n e AY_H 0 x35\n\n#d e f i n e AZ_L 0 x36\n19 #d e f i n e AZ_H 0 x37\n\n#d e f i n e FIFO_CTL 0 x38\n21 #d e f i n e FIFO_STATUS 0 x39\n\n23 // Macros\n#i f n d e f sbimacro_HEADER_GUARD\n\n25 #d e f i n e sbimacro_HEADER_GUARD\n#d e f i n e s b i ( var , mask ) ( ( var ) |= ( uint8_t ) ( 1&lt;&lt;mask ) )\n\n27 #d e f i n e c b i ( var , mask ) ( ( var ) &amp;= ( uint8_t ) ~(1&lt;&lt;mask ) )\n#e n d i f\n\n29\n\n// ADXL?345 d e f i n i t i o n s\n\n84\n\n\n\n31 #d e f i n e AX 1\n#d e f i n e AY 2\n\n33 #d e f i n e AZ 3\n\n35 e x t e r n v o i d ADXL345Init ( ) ;\ne x t e r n c h a r ADXL345Read ( u n s i g n e d c h a r a d d r e s s ) ;\n\n37 e x t e r n v o i d ADXL345Write ( u n s i g n e d c h a r a d d r e s s , u n s i g n e d c h a r data ) ;\ne x t e r n s i g n e d s h o r t i n t ? ADXL345get_a ( ) ;\n\n39\n\n#e n d i f\n\nAppendix\u2013B/codes/ADXL\u2013345.h\n\nII.1.7.1 SHARP-0A41SKF36.c\n\n1 /?\nADXL?345 f u n c t i o n s .\n\n3\n\n@author Ana C a r o l i n a Cardoso de Sousa\n5 @date 2014/04/29\n\n@ v e r s i o n 1 . 0\n7 ?/\n\n#i n c l u d e&lt;avr / i o . h>\n9 #i n c l u d e &lt;u t i l / d e l a y . h>\n\n#i n c l u d e \"ADXL?345.h\"\n11 #i n c l u d e \" t y p e s . h\"\n\n#i n c l u d e \" i 2 c . h\"\n13\n\nv o i d ADXL345Init ( ) {\n15 ADXL345Write (PWR_CTL, 0 x00 ) ; // Go i n t o standby mode t o c o n f i g u r e t h e d e v i c e .\n\nADXL345Write (DATA_FORMAT, 0x0B ) ; // 0x0B : F u l l r e s o l u t i o n , +/?16g , 4mg/LSB .\n17 ADXL345Write (BW_Rate, 0x0D ) ; // 800Hz data r a t e .\n\nADXL345Write (PWR_CTL, 0 x08 ) ; // 0 x08 : Measurement mode .\n19 _delay_ms ( 2 2 ) ;\n\n}\n21\n\nc h a r ADXL345Read ( u n s i g n e d c h a r a d d r e s s ) {\n23 c h a r data ;\n\n25 c b i (TWCR, TWEN) ; // D i s a b l e TWI\ns b i (TWCR, TWEN) ; // Enable TWI\n\n27\n\ni 2 c S e n d S t a r t ( ) ;\n29 i2cWaitForComplete ( ) ;\n\n31 i2cSendByte (ADXL345_W) ; // w r i t e 0xA6\ni2cWaitForComplete ( ) ;\n\n33\n\ni2cSendByte ( a d d r e s s ) ; // w r i t e r e g i s t e r a d d r e s s\n35 i2cWaitForComplete ( ) ;\n\n37 i 2 c S e n d S t a r t ( ) ;\n\n39 i2cSendByte (ADXL345_R) ; // w r i t e 0xA7\ni2cWaitForComplete ( ) ;\n\n41 i 2 c R e c e i v e B y t e (FALSE) ;\ni2cWaitForComplete ( ) ;\n\n43\n\n85\n\n\n\ndata = i 2 c G e t R e c e i v e d B y t e ( ) ; // Get MSB r e s u l t\n45 i2cWaitForComplete ( ) ;\n\ni 2 c S e n d S t o p ( ) ;\n47\n\nc b i (TWCR, TWEN) ; // D i s a b l e TWI\n49 s b i (TWCR, TWEN) ; // Enable TWI\n\n51 r e t u r n data ;\n}\n\n53\n\nv o i d ADXL345Write ( u n s i g n e d c h a r a d d r e s s , u n s i g n e d c h a r data ) {\n55 i 2 c S e n d S t a r t ( ) ;\n\ni2cWaitForComplete ( ) ;\n57\n\ni2cSendByte (ADXL345_W) ;\n59 i2cWaitForComplete ( ) ;\n\n61 i2cSendByte ( a d d r e s s ) ; // w r i t e r e g i s t e r a d d r e s s\ni2cWaitForComplete ( ) ;\n\n63\n\ni2cSendByte ( data ) ;\n65 i2cWaitForComplete ( ) ;\n\n67 i 2 c S e n d S t o p ( ) ;\n}\n\n69\n\ns i g n e d s h o r t i n t ? ADXL345get_a ( ) {\n71\n\ns i g n e d s h o r t i n t ax , ay , az ;\n73 s t a t i c s i g n e d s h o r t i n t a _ r e s u l t [ 3 ] ;\n\nc h a r temp ;\n75\n\ns i g n e d i n t accx =0, accy =0, a c c z =0;\n77\n\n// Get a c c e l e r a t i o n s :\n79 w h i l e ( ! ( ADXL345Read (INT_SRC) &amp; 0 x01 ) ) ;\n\ntemp = 0 ;\n81 temp = ADXL345Read (AX_H) ; // h i g h b i t s ax\n\nax = temp&lt;&lt;8 ;\n83 ax = ADXL345Read (AX_L) ; // low b i t s ax\n\n85 w h i l e ( ! ( ADXL345Read (INT_SRC) &amp; 0 x01 ) ) ;\ntemp = 0 ;\n\n87 temp = ADXL345Read (AY_H) ; // h i g h b i t s ay\nay = temp&lt;&lt;8 ;\n\n89 ay |= ADXL345Read (AY_L) ; // low b i t s ay\n\n91 w h i l e ( ! ( ADXL345Read (INT_SRC) &amp; 0 x01 ) ) ;\ntemp = 0 ;\n\n93 temp = ADXL345Read (AZ_H) ; // h i g h b i t s az\naz = temp&lt;&lt;8 ;\n\n95 az |= ADXL345Read (AZ_L) ; // low b i t s az\n\n97 a _ r e s u l t [ 0 ] = ax ;\na _ r e s u l t [ 1 ] = ay ;\n\n99 a _ r e s u l t [ 2 ] = az ;\n\n101 r e t u r n a _ r e s u l t ;\n}\n\n86\n\n\n\nAppendix\u2013B/codes/ADXL\u2013345.c\n\nII.1.8 ITG-3200.h\n\n1 #i f n d e f ITG3200_HEADER_GUARD\n#d e f i n e ITG3200_HEADER_GUARD\n\n3\n\n// ITG?3200 a d d r e s s e s\n5 #d e f i n e ITG3200_R 0xD1 // ADD p i n i s p u l l e d h i g h\n\n#d e f i n e ITG3200_W 0xD0 // So a d d r e s s i s 0 x68\n7\n\n// ITG?3200 r e g i s t e r s\n9 #d e f i n e WHO 0 x00\n\n#d e f i n e SMPL 0 x15\n11 #d e f i n e DLPF 0 x16\n\n#d e f i n e INT_C 0 x17\n13 #d e f i n e INT_S 0x1A\n\n#d e f i n e TMP_H 0x1B\n15 #d e f i n e TMP_L 0x1C\n\n#d e f i n e GX_H 0x1D\n17 #d e f i n e GX_L 0x1E\n\n#d e f i n e GY_H 0x1F\n19 #d e f i n e GY_L 0 x20\n\n#d e f i n e GZ_H 0 x21\n21 #d e f i n e GZ_L 0 x22\n\n#d e f i n e PWR_M 0x3E\n23\n\n// Macros\n25 #i f n d e f sbimacro_HEADER_GUARD\n\n#d e f i n e sbimacro_HEADER_GUARD\n27 #d e f i n e s b i ( var , mask ) ( ( var ) |= ( uint8_t ) ( 1&lt;&lt;mask ) )\n\n#d e f i n e c b i ( var , mask ) ( ( var ) &amp;= ( uint8_t ) ~(1&lt;&lt;mask ) )\n29 #e n d i f\n\n31 // ITG?3200 d e f i n i t i o n s\n#d e f i n e GYRO_SCALE 1 4 . 3 7 5\n\n33 #d e f i n e GX 1\n#d e f i n e GY 2\n\n35 #d e f i n e GZ 3\n\n37 e x t e r n v o i d ITG3200Init ( v o i d ) ;\ne x t e r n c h a r ITG3200Read ( u n s i g n e d c h a r a d d r e s s ) ;\n\n39 e x t e r n v o i d ITG3200Write ( u n s i g n e d c h a r a d d r e s s , u n s i g n e d c h a r data ) ;\ne x t e r n i n t I T G 3 2 0 0 c h e c k I n t e r r u p t ( v o i d ) ;\n\n41 e x t e r n s i g n e d s h o r t i n t ? I T G 3 2 0 0 c a l i b r a t i o n ( ) ;\ne x t e r n s i g n e d s h o r t i n t ?ITG3200get_w ( s i g n e d s h o r t i n t ?g y r o _ o f f s e t ) ;\n\n43 // e x t e r n s i g n e d s h o r t i n t ?ITG3200get_w_average ( s i g n e d s h o r t i n t ?g y r o _ o f f s e t ) ;\n\n45 #e n d i f\n\nAppendix\u2013B/codes/ITG\u20133200.h\n\nII.1.8.1 SHARP-0A41SKF36.c\n\n87\n\n\n\n1 /?\nITG?3200 f u n c t i o n s .\n\n3\n\n@author Ana C a r o l i n a Cardoso de Sousa\n5 @date 2014/04/28\n\n@ v e r s i o n 1 . 0\n7 ?/\n\n#i n c l u d e&lt;avr / i o . h>\n9 #i n c l u d e &lt;u t i l / d e l a y . h>\n\n#i n c l u d e \"ITG?3200. h\"\n11 #i n c l u d e \" t y p e s . h\"\n\n#i n c l u d e \" i 2 c . h\"\n13\n\nv o i d ITG3200Init ( v o i d ) {\n15 ITG3200Write (PWR_M, 0 x80 ) ; // Reset t o d e f a u l t s\n\nITG3200Write (SMPL, 0 x00 ) ; // SMLPRT_DIV = 0\n17 ITG3200Write (DLPF, 0 x18 ) ; // DLPF_CFG = 0 , FS_SEL = 3\n\nITG3200Write (INT_C, 0 x05 ) ; // Generate i n t e r r u p t when d e v i c e i s ready o r raw data ready\n19 ITG3200Write (PWR_M, 0 x00 ) ;\n\n_delay_ms ( 5 0 ) ;\n21 }\n\n23 c h a r ITG3200Read ( u n s i g n e d c h a r a d d r e s s ) {\nc h a r data ;\n\n25\n\nc b i (TWCR, TWEN) ; // D i s a b l e TWI\n27 s b i (TWCR, TWEN) ; // Enable TWI\n\n29 i 2 c S e n d S t a r t ( ) ;\ni2cWaitForComplete ( ) ;\n\n31\n\ni2cSendByte (ITG3200_W) ; // w r i t e 0xD1\n33 i2cWaitForComplete ( ) ;\n\n35 i2cSendByte ( a d d r e s s ) ; // w r i t e r e g i s t e r a d d r e s s\ni2cWaitForComplete ( ) ;\n\n37\n\ni 2 c S e n d S t a r t ( ) ;\n39\n\ni2cSendByte ( ITG3200_R ) ; // w r i t e 0xD3\n41 i2cWaitForComplete ( ) ;\n\ni 2 c R e c e i v e B y t e (FALSE) ;\n43 i2cWaitForComplete ( ) ;\n\n45 data = i 2 c G e t R e c e i v e d B y t e ( ) ; // Get MSB r e s u l t\ni2cWaitForComplete ( ) ;\n\n47 i 2 c S e n d S t o p ( ) ;\n\n49 c b i (TWCR, TWEN) ; // D i s a b l e TWI\ns b i (TWCR, TWEN) ; // Enable TWI\n\n51\n\nr e t u r n data ;\n53 }\n\n55 v o i d ITG3200Write ( u n s i g n e d c h a r a d d r e s s , u n s i g n e d c h a r data ) {\ni 2 c S e n d S t a r t ( ) ;\n\n57 i2cWaitForComplete ( ) ;\n\n59 i2cSendByte (ITG3200_W) ; // w r i t e 0xB4\n\n88\n\n\n\ni2cWaitForComplete ( ) ;\n61\n\ni2cSendByte ( a d d r e s s ) ; // w r i t e r e g i s t e r a d d r e s s\n63 i2cWaitForComplete ( ) ;\n\n65 i2cSendByte ( data ) ;\ni2cWaitForComplete ( ) ;\n\n67\n\ni 2 c S e n d S t o p ( ) ;\n69 }\n\n71 /?Get o f f s e t f o r c a l i b r a t i o n ?/\ns i g n e d s h o r t i n t ? I T G 3 2 0 0 c a l i b r a t i o n ( ) {\n\n73 c h a r temp ;\ns i g n e d i n t gx [ 1 0 ] , gy [ 1 0 ] , gz [ 1 0 ] ;\n\n75 s i g n e d i n t gyrox =0, gyroy =0, g y r o z =0;\nu n s i g n e d i n t i ;\n\n77\n\ns t a t i c s h o r t i n t gyro [ 3 ] ;\n79\n\n81 f o r ( i = 0 ; i&lt;10; i ++){\nw h i l e ( ! ( ITG3200Read (INT_S) &amp; 0 x01 ) )\n\n83 ;\ntemp = 0 ;\n\n85 temp = ITG3200Read (GX_H) ;\ngx [ i ] = temp&lt;&lt;8 ;\n\n87 gx [ i ] |= ITG3200Read (GX_L) ;\n\n89 gyrox += gx [ i ] ;\n}\n\n91\n\nf o r ( i = 0 ; i&lt;10; i ++){\n93 w h i l e ( ! ( ITG3200Read (INT_S) &amp; 0 x01 ) )\n\n;\n95 temp = 0 ;\n\ntemp = ITG3200Read (GY_H) ;\n97 gy [ i ] = temp&lt;&lt;8 ;\n\ngy [ i ] |= ITG3200Read (GY_L) ;\n99\n\ngyroy += gy [ i ] ;\n101 }\n\n103 f o r ( i = 0 ; i&lt;10; i ++){\nw h i l e ( ! ( ITG3200Read (INT_S) &amp; 0 x01 ) )\n\n105 ;\ntemp = 0 ;\n\n107 temp = ITG3200Read (GZ_H) ;\ngz [ i ] = temp&lt;&lt;8 ;\n\n109 gz [ i ] |= ITG3200Read (GZ_L) ;\n\n111 g y r o z += gz [ i ] ;\n}\n\n113\n\ngyrox = gyrox / 1 0 ;\n115 gyroy = gyroy / 1 0 ;\n\ng y r o z = g y r o z / 1 0 ;\n117\n\ngyrox = gyrox /GYRO_SCALE;\n119 gyroy = gyroy /GYRO_SCALE;\n\n89\n\n\n\ng y r o z = g y r o z /GYRO_SCALE;\n121\n\ngyro [ 0 ] = gyrox ;\n123 gyro [ 1 ] = gyroy ;\n\ngyro [ 2 ] = g y r o z ;\n125\n\nr e t u r n gyro ;\n127 }\n\n129 /?Get a n g u l a r v e l o c i t i e s w=[wx , wy , wz ] ?/\ns i g n e d s h o r t i n t ?ITG3200get_w ( s i g n e d s h o r t i n t ?g y r o _ o f f s e t ) {\n\n131\n\ns i g n e d s h o r t i n t gx , gy , gz ;\n133 s i g n e d s h o r t i n t gx_off , gy_off , g z _ o f f ;\n\ns t a t i c s i g n e d s h o r t i n t w_result [ 3 ] ;\n135 c h a r temp ;\n\n137 // Get o f f s e t\ngx_off = g y r o _ o f f s e t [ 0 ] ;\n\n139 gy_off = g y r o _ o f f s e t [ 1 ] ;\ng z _ o f f = g y r o _ o f f s e t [ 2 ] ;\n\n141\n\n// Get a n g u l a r v e l o c i t i e s :\n143 w h i l e ( ! ( ITG3200Read (INT_S) &amp; 0 x01 ) ) ;\n\ntemp = 0 ;\n145 temp = ITG3200Read (GX_H) ;\n\ngx = temp&lt;&lt;8 ; // h i g h wx\n147 gx |= ITG3200Read (GX_L) ; // h i g h and low wx\n\n149 w h i l e ( ! ( ITG3200Read (INT_S) &amp; 0 x01 ) ) ;\ntemp = 0 ;\n\n151 temp = ITG3200Read (GY_H) ;\ngy = temp&lt;&lt;8 ; // h i g h wy\n\n153 gy |= ITG3200Read (GY_L) ; // h i g h and low wy\n\n155 w h i l e ( ! ( ITG3200Read (INT_S) &amp; 0 x01 ) ) ;\ntemp = 0 ;\n\n157 temp = ITG3200Read (GZ_H) ;\ngz = temp&lt;&lt;8 ; // h i g h wz\n\n159 gz |= ITG3200Read (GZ_L) ; // h i g h and low wz\n\n161 // Angular V e l o c i t y s c a l e d w i t h o u t o f f s e t\ngx = gx /GYRO_SCALE;\n\n163 gy = gy /GYRO_SCALE;\ngz = gz /GYRO_SCALE;\n\n165\n\ngx = ( gx ? gx_off ) ;\n167 gy = ( gy ? gy_off ) ;\n\ngz = ( gz ? g z _ o f f ) ;\n169\n\nw_result [ 0 ] = gx ;\n171 w_result [ 1 ] = gy ;\n\nw_result [ 2 ] = gz ;\n173\n\nr e t u r n w_result ;\n175 }\n\nAppendix\u2013B/codes/ITG\u20133200.c\n\n90\n\n\n\nIII. ELECTRONIC CIRCUIT\n\nWe draw the both circuit schematics in CadSoft EAGLE PCB Design Software v6.5.0 (Figures\nIII.1 and III.2). From these schemes, we generated the boards (Figures III.3, III.4, III.5 and\nfig:lateral-boardBW), printed and manually soldered the PCB components.\n\nFigure III.1: Base Circuit Schematic.\n\n91\n\n\n\nFigure III.2: Lateral Circuit Schematic.\n\n92\n\n\n\nFigure III.3: Colored Base Circuit Board.\n\n93\n\n\n\nFigure III.4: Black and White Base Circuit Board.\n\n94\n\n\n\nFigure III.5: Colored Lateral Circuit Board.\n\n95\n\n\n\nFigure III.6: Black and White Lateral Circuit Board.\n\n96\n\n\n\nIV. ErekoBot ? PLANS\n\nWe draw the all pieces in the CAD Software SolidWorks 2013, as we can see in Figures IV.1,\nIV.2, IV.3 and IV.4.\n\nFigures IV.5, IV.6 and IV.7 show where to blend the pieces.\n\n97\n\n\n\nFigure IV.1: Base Plan.\n\n98\n\n\n\nFigure IV.2: Motor Holder Plan.\n\n99\n\n\n\nFigure IV.3: Rod Plan.\n\n100\n\n\n\nFigure IV.4: Cover Plan.\n\n101\n\n\n\nFigure IV.5: Base Blends.\n\n102\n\n\n\nFigure IV.6: Motor Holder Blends.\n\n103\n\n\n\nFigure IV.7: Rod Blends.\n\n104\n\n\n\nV. OVERVIEW OF THE ATTACHED DISK\n\nV.1 ATMega8 Files\n\nCodes in C language compiled by avr-gcc in Ubuntu 12.04.\n\natmega8-libraries.zip Basic libraries for the features of ErekoBot ? described in Appendix II.\n\nV.2 Eagle Files\n\nFiles designed in CadSoft EAGLE PCB Design Software v6.5.0.\n\nFigures from the board Figures for the electronic circuit of the module described in Appendix\nIII.\n\neagle-schemes.zip Basic schematic for the electronic circuit of the module described in Appendix\nIII.\n\nV.3 Matlab Files\n\nRoutines and functions written in Matlab R2013a.\n\nmatlab-experiments.zip Basic routines and functions for the features of the module described\nin Section 5.\n\nV.4 Media\n\nErekoBot ? figures and videos.\n\nfigures.zip Figures.\n\nvideos.zip Videos.\n\nV.5 Report Files\n\nLatex files compiled by pdfLatex.\n\ndissertation.zip Latex files for compiling this report.\n\n105\n\n\n\ndissertation.pdf PDF file of this dissertation.\n\nfigs.zip Figures used in this report and in other articles.\n\nV.6 SolidWorks Files\n\nFiles designed in CAD Software SolidWorks 2013.\n\nsolid-design.zip Basic design for the complete module described in Appendix IV.\n\n106\n\n\n\tSensores em Rob\u00f3tica Modular para Inspe\u00e7\u00e3o em Tubula\u00e7\u00f5es: Projeto e Testes do M\u00f3dulo Erekobot \n\tIntroduction\n\t99993em.5Presentation\n\tAims\n\tStructure of the Document\n\n\tBrief Review of Pipeline Inspection, SRM Robots and Instrumentation\n\tPipeline Inspection\n\tClassification of Pipeline Robots\n\n\tSelf-Reconfigurable Modular Robots\n\tTaxonomy\n\tBrief History of SRM Robotics\n\tRecent SRM Robots\n\tErekoBot\n\n\tGeneral Measurement System in SRM Systems\n\tSystematic Characteristics\n\tRotation Motion sensors\n\tTranslational Displacement Sensors\n\tFilters\n\n\tOrientation: Euler Angles\n\tEuler angles\n\n\tSummary\n\n\tConceptual Design and Modelling\n\tIntroduction\n\tConceptual Design of ErekoBot\n\tInstrumentation Model\n\tAttitude Estimation\n\tDistance Estimation\n\n\tAlignment Algorithm\n\tConclusions\n\n\tModule Design\n\tIntroduction\n\tSensors Selection\n\tEletronic Design\n\tMicrocontroller\n\tCommunication\n\tElectronic Devices\n\tPower Supply\n\n\tMechanical Design\n\tIntermodular Connection\n\tServo Motor\n\tGeometric Description and Materials\n\tWeight Analysis\n\n\tModule Analysis\n\tActual and estimated weights\n\tComparison between ErekoBotand other modular robots\n\n\tConclusions\n\n\tExperiments and Results\n\tOrientation Experiment\n\tExperimental Method\n\tResults\n\n\tDistance Experiment\n\tExperimental Method\n\tResults\n\n\tAlignment Experiment\n\tExperimental Method\n\tAlignment Results\n\n\tConclusions\n\n\tConclusions\n\tMain Contributions\n\tFuture Lines of Investigation\n\tPublications\n\n\tBibliography\n\tAppendix\n\tDemonstrations\n\tSix possible rotation matrix\n\n\tLibraries\n\tCodes\n\tservo.h\n\tleds.h\n\tUSART.h\n\tadc.h\n\tSHARP-0A41SKF36.h\n\ti2c.h\n\tADXL-345.h\n\tITG-3200.h\n\n\n\tElectronic Circuit\n\tErekoBotplans\n\tOverview of the Attached Disk\n\tATMega8 Files\n\tEagle Files\n\tMatlab Files\n\tMedia\n\tReport Files\n\tSolidWorks Files"}]}}}