{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.11901"}, {"@name": "filename", "#text": "17339_ulfc124321_tm_Patr%c3%adcia_Jorge.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNIVERSIDADE DE LISBOA\n\nFACULDADE DE CIE?NCIAS\n\nDEPARTAMENTO DE ESTATI?STICA E INVESTIGAC?A?O OPERACIONAL\n\nApplying Generalized Linear Models to\nEstimate Group Size and Improve Blainville\u2019s\n\nBeaked Whale Abundance Estimation\n\nPatr??cia Alexandra de Almeida Jorge\n\nMestrado em Bioestat??stica\n\nTrabalho de projeto orientado por:\nDoutor Tiago Marques\n\nDoutora Helena Mourin?o\n\n2017\n\n\n\n\n\nFairy tales are more than true: not because they tel l us that dragons exist, but because they tell\nus that dragons can be beaten.\n\n- Neil Gaiman\n\n\n\n\n\nAcknowledgements\n\nThis work was conducted over data collected under the project GROUPAM, funded by\nthe Office of Naval Research of the United States of America. I thank Jessica Ward, Karin\nDolan, David Moretti, and Len Thomas, as well as the remaining large NUWC team, which\nwere responsible for processing the raw acoustic data into a format that I could use, and for\nanswering some of the questions that arose while implementing the analysis. An additional\nthank you to Karin Dolan for having gone through the hoops and loops of getting the data\nthrough the public release process.\n\nI would also like to thank Helena Mourin?o, for her formidable knowledge, support and\npatience.\n\nMy sincere gratitude to Tiago Marques, who made all this possible. I could not have had\nsomeone better to guide me through this journey.\n\ni\n\n\n\nii\n\n\n\nTable of Contents\n\nList of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . v\n\nList of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vi\n\nResumo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi\n\nAbstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiv\n\n1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1 The Idea Behind this Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.2 Blainville\u2019s Beaked Whale . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n1.3 The Case Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n\n1.3.1 The AUTEC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.4 Main Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n\n2 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.1 The Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n\n2.1.1 Modelling Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.1.2 Density Estimation Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n\n2.1.2.1 Raw data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.1.2.2 Data Cleaning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n\n2.2 Some Insights on Exploratory Data Analysis . . . . . . . . . . . . . . . . . . . . . 14\n2.2.1 Correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n\n2.2.1.1 Pearson Product-Moment Correlation Coefficient . . . . . . . . . 14\n2.2.1.2 Spearman\u2019s Rank Correlation Coefficient . . . . . . . . . . . . . 15\n2.2.1.3 Point-Biserial Correlation Coefficient . . . . . . . . . . . . . . . 15\n2.2.1.4 Phi Coefficient . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n\n2.2.2 Pearson\u2019s ?2 Tests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n2.2.2.1 Pearson\u2019s ?2 Independence Test . . . . . . . . . . . . . . . . . . 17\n2.2.2.2 Pearson\u2019s ?2 Goodness-of-Fit-Test . . . . . . . . . . . . . . . . . 18\n\n2.2.3 Interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.2.4 Shapiro-Wilk Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.2.5 Multicollinearity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n\n2.3 Modelling Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n2.3.1 Linear Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n2.3.2 Generalized Linear Models . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.3.3 Generalized Additive Models . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.3.4 Zero-Truncated Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.3.5 Modelling with GLM &amp; GAM . . . . . . . . . . . . . . . . . . . . . . . . . 28\n\niii\n\n\n\n2.4 Modelling Strategy: Variable Selection . . . . . . . . . . . . . . . . . . . . . . . . 29\n2.4.1 Stepwise Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n2.4.2 Criteria for Evaluating Subset Regression Models . . . . . . . . . . . . . . 29\n\n2.4.2.1 Likelihood Ratio Test . . . . . . . . . . . . . . . . . . . . . . . . 30\n2.4.2.2 Akaike\u2019s Information Criterion . . . . . . . . . . . . . . . . . . . 30\n\n2.5 Residual Analysis and Influential Observations . . . . . . . . . . . . . . . . . . . 31\n2.5.1 Residuals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n2.5.2 Influential Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n\n2.6 Group Size and Density Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n2.6.1 Bootstrap . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n\n2.6.1.1 Parametric Bootstrap . . . . . . . . . . . . . . . . . . . . . . . . 37\n\n3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3.1 The Modelling Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n\n3.1.1 Exploratory Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3.1.1.1 Univariate Analysis . . . . . . . . . . . . . . . . . . . . . . . . . 43\n\n3.1.2 Correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n3.1.3 Model Building . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n\n3.1.3.1 Non-Truncated GLM &amp; GAM . . . . . . . . . . . . . . . . . . . 48\n3.1.3.2 Zero-truncated GLM &amp; GAM . . . . . . . . . . . . . . . . . . . 49\n\n3.1.4 Analysing the model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n3.1.4.1 Residuals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n3.1.4.2 Hat values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n\n3.2 Density Estimation Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n3.2.1 Exploratory Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n3.2.2 Group Size Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n3.2.3 Density Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n3.2.4 Bootstrapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n\n3.3 Comparison with Previous Results . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n\n4 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n4.1 Underlying Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n4.2 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n4.3 Acquired Competencies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\n4.4 Final Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n\niv\n\n\n\nList of Figures\n\n1.1 Representation of Blainville\u2019s beaked whales. Female (bottom) and male (top).\nThe later exhibits body scarring, more prominent teeth and darker body\ncolouration. Source: \u00a9 Wurtz \u2013 www.artescienza.org. . . . . . . . . . . . . . . . . 2\n\n1.2 Illustration of an individual\u2019s diving profile depth: data from a 22.6h deployment\non a tagged Blainville\u2019s beaked whale divided into two days: A (12.6 hours) and\nB (10 hours). Adapted from Baird et al., 2006. . . . . . . . . . . . . . . . . . . . 3\n\n1.3 Dive profile illustration of a Blainville\u2019s beaked whale foraging dive showing vocal\nevents, featuring regular and buzz clicks. Retrieved from Johnson et al., 2006. . . 4\n\n1.4 Hydrophone camp with the 93 hydrophones (numbered), featuring the \u201cconvex\nhull\u201d area (yellow), the Edge hydrophones (black line), non-Edge hydrophones\n(red line and inside red line), Whiskey hydrophones (circled green), and\nBidirectional hydrophones (squared grey). Adapted from Moretti et al., 2010. . . 5\n\n2.1 A: Poisson distribution, \u00b5 = 3. B: Zero-truncated Poisson, \u00b5 = 3, with adjusted\nprobabilities according to Equation 2.40. The vertical lines are slightly higher due\nto each probability being divided by 1 ?P(Y = 0). The sum of all probabilities\nin both A and B is therefore equal to 1, representing a valid distribution. . . . . 28\n\n3.1 Click counts for all 93 hydrophones. Uni and Bi hydrophones are distinguished\nwith different colours (salmon and blue, respectively). . . . . . . . . . . . . . . . 40\n\n3.2 Total number of clicks detected for each one of the 51 groups. . . . . . . . . . . . 41\n\n3.3 Group size count distribution for the modelling dataset, ranging from 1 to 6\nindividuals per group, with a total of 51 groups. . . . . . . . . . . . . . . . . . . 42\n\n3.4 Univariate analysis for each continuous explanatory variable (x-axis) against\nthe response variable, cluster size (y-axis). Each black dot corresponds to an\nobservation and the blue line matches the regression line, where the grey area is\nthe 95% confidence level interval for the predictions. A: click mean count, B:\nnumber of hydrophones, C: click duration, D: number of clicks, E: click rate. . . 44\n\n3.5 Univariate analysis for each binary explanatory variable (x-axis) against the\nresponse variable, cluster size (y-axis). Each violin plot considers an orange\narea where its width is proportional to the number of observations, and a black\ndot that corresponds to the observations\u2019 median. F: whiskey/non-whiskey, G:\nuni-directional/bi-directional. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n\n3.6 Behaviour of each non-binary variable against each other (mean count, number\nof hydrophones, click duration, number of clicks, and click rate, respectively). . . 46\n\n3.7 Correlation plot featuring Pearson\u2019s ? value for each non-binary variable duo\n(mean count, number of hydrophones, click duration, number of clicks, and click\nrate). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n\nv\n\n\n\n3.8 Correlation plot featuring Spearman\u2019s rs value for each non-binary variable duo\n(mean count, number of hydrophones, click duration, number of clicks, and click\nrate). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n\n3.9 Correlation plot featuring the Point biserial correlation coefficient between the\nnon-binary (mean count, number of hydrophones, click duration, number of clicks,\nand click rate) and the binary (direction and whiskey) variables. . . . . . . . . . 47\n\n3.10 Fitted values and corresponding residuals, with a scatter plot smoother (grey area). 50\n3.11 Model residuals and corresponding hat values . . . . . . . . . . . . . . . . . . . . 51\n3.12 Click counts for each hydrophone (raw data). . . . . . . . . . . . . . . . . . . . . 53\n3.13 Group size estimations for each day (orange area), considering the first period (61\n\ndays). The orange area width is proportional to the number of estimated values\nfor the group size. Each black dot inside every violin plot represents the median\nfor the respective day. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n\n3.14 Group size estimations for each day (orange area), considering the second period\n(18 days). The orange area width is proportional to the number of estimated\nvalues for the group size. Each black dot inside every violin plot represents the\nmedian for the respective day. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n\n3.15 Group size estimations for each day (orange area), considering the third period\n(30 days). The orange area width is proportional to the number of estimated\nvalues for the group size. Each black dot inside every violin plot represents the\nmedian for the respective day. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n\n3.16 Density estimation for each day (whales/1000 km2), considering the first period\n(61 days). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n\n3.17 Density estimation for each day (whales/1000 km2), considering the second period\n(18 days). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n\n3.18 Density estimation for each day (whales/1000 km2), considering the third period\n(30 days). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n\n3.19 The observed group sizes and corresponding click rate (black dots), along with\nthe model\u2019s maximum likelihood fit line (red line), and the model\u2019s bootstrap\n95% percentile interval (grey area). . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n\n3.20 999 group size bootstraps for the chosen model, for each click rate value. Although\nbarely distinguishable, each colour represents a group size bootstrap for the\ncorresponding click rate value. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n\n3.21 999 model density bootstraps for each day, considering the three time periods.\nAlthough barely distinguishable, each colour represents a single bootstrap. . . . . 61\n\nvi\n\n\n\nList of Tables\n\n2.1 The data available for each group. For illustration purposes only the data for the\nfirst 5 groups are shown. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n\n2.2 Time periods summary table, discarding the \u201chalf-days\u201d and only considering 109\ndays. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n\n2.3 The data available from the second dataset. For illustration purposes only the\ndata for the first 10 lines are shown. . . . . . . . . . . . . . . . . . . . . . . . . . 10\n\n2.4 The data for group size estimation. For illustration purposes only the data for\nthe first 10 lines are shown. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n\n2.5 2x2 contingency table for two random binary variables, X and Y. . . . . . . . . . 16\n\n2.6 Contingency table for two categorical variables, A and B, with r and c categories,\nrespectively. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n\n2.7 The data available for each group, after adding the cs0 column. For illustration\npurposes only the data for the first 5 groups are shown. . . . . . . . . . . . . . . 29\n\n2.8 The first ten lines from data regarding each day, featuring the estimated\nabundance and density. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\n3.1 The best three candidate Poisson models (GLM and GAM) that explain the\nresponse variable \u201cgroup size\u201d, along with the explanatory variables\u2019 coefficients\n(from GLM), and smooth significance level (from GAM), and the model\u2019s AIC\nvalue. The models were built considering all the 51 observations. . . . . . . . . . 48\n\n3.2 The best three candidate Poisson models (GLM and GAM) that explain the\nresponse variable \u201cgroup size\u201d, along with the explanatory variables\u2019 coefficients\n(from GLM), and smooth significance level (from GAM), and the model\u2019s AIC\nvalue. The models were built only considering the 43 groups with a confidence\nlevel of 1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n\n3.3 The best three candidate Poisson models (zero-truncated GLM) that explain the\nresponse variable \u201cgroup size\u201d, along with the explanatory variables\u2019 coefficients\nand the model\u2019s AIC value. The models were built considering all the 51\nobservations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n\n3.4 The best three candidate Poisson models (zero-truncated GLM) that explain the\nresponse variable \u201cgroup size\u201d, along with the explanatory variables\u2019 coefficients\nand the model\u2019s AIC value. The models were built only considering the 43 groups\nwith a confidence level of 1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n\n3.5 The best three candidate Poisson models (zero-truncated GLM) that explain the\nresponse variable \u201cgroup size\u201d, along with the explanatory variables\u2019 coefficients\nand the model\u2019s AIC value. The models were built considering all the 49\nobservations without extreme hat values. . . . . . . . . . . . . . . . . . . . . . . . 52\n\nvii\n\n\n\n3.6 The best three candidate Poisson models (zero-truncated GLM) that explain the\nresponse variable \u201dgroup size\u201d, along with the explanatory variables\u2019 coefficients\nand the model\u2019s AIC value. The models were built only considering the 41\nobservations without extreme hat values and with a confidence level of 1. . . . . 52\n\n3.7 Group size estimation summary statistics for each of the three time periods\nconsidered. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n\n3.8 Values regarding the density estimation for the three time periods. . . . . . . . . 59\n3.9 Estimated abundance and density based on dive counting, with corresponding\n\ncoefficient of variation (CV). Values in brackets after the estimates are 95% limits.\nAdapted from tables 1 and 3 in Moretti et al., 2010. . . . . . . . . . . . . . . . . 62\n\nviii\n\n\n\nResumo\n\nEm ecologia, me?todos precisos e eficientes sa?o fundamentais no que toca a? estimac?a?o\nda abunda?ncia das populac?o?es naturais, sendo necessa?rios para uma gesta?o e conservac?a?o\nsustenta?veis e eficazes. Consequentemente, e? importante optimizar os modelos existentes de\nmaneira a garantir a efica?cia das suas previso?es. Assim, me?todos que garantam a monitorizac?a?o\ncom a m??nima intervenc?a?o humana te?m vindo a ganhar popularidade no estudo das populac?o?es\nnaturais.\n\nA Baleia de bico de Blainville (Mesoplodon densirostris, Md) e? a espe?cie do ge?nero\nMesoplodon com a mais abrangente a?rea de distribuic?a?o, estando presente em a?guas temperadas\ne tropicais de todos os oceanos. Sa?o facilmente identificadas pelo seu corpo largo e robusto,\nbem como pelo bico bem definido que esta? na origem do seu nome: \u201ddensirostris\u201d vem do Latim\nque significa \u201ddo bico denso\u201d. Apesar da sua ampla distribuic?a?o, raramente e? avistada devido a\npassar a maior parte do tempo em a?guas a grandes profundidades. Apenas por breves per??odos\nse desloca a? superf??cie, o que resulta numa baixa probabilidade de avistamento. Esta espe?cie e?\ntambe?m conhecida por se associar em grupos e exibir um comportamento metrono?mico aquando\no mergulho, apresentando tende?ncia para vocalizar apenas durante os mergulhos profundos que\nefectua para a alimentac?a?o. Para tal, recorre a sinais de ecolocalizac?a?o ultraso?nica de banda\nlarga, conhecidos como \u201dcliques\u201d, com um comprimento de onda de 26 a 51 kHz. Estes cliques\nocorrem predominantemente em locais onde as baleias procuram e encontram presas, e sa?o\ndivididos em duas categorias: search clicks e buzz clicks. Os primeiros sa?o produzidos durante\ntodo o mergulho profundo, enquanto que os u?ltimos sa?o emitidos durante curtos per??odos no\nesta?dio final da captura de presa. Devido a? continuidade dos search clicks ao longo do mergulho,\ne? neste primeiro tipo de cliques que o presente trabalho se baseia.\n\nO AUTEC (Atlantic Undersea Test and Evaluation Center) e? um centro naval de treino\npertencente aos E.U.A localizado na Tongue of the Ocean (TOTO), nas Bahamas. E? um\nlocal onde frequentemente ocorrem testes com sonares, e onde a espe?cie da baleia em estudo\ne? rotinamente detetada. O centro possui um vasto campo de 93 hidrofones ligados a? base, aos\nquais se pode recorrer para detetar os cliques de ecolocalizac?a?o produzidos por Md. Dadas\nas caracter??sticas dos hidrofones, a densa grelha que estes apresentam e a a?rea que ocupam,\ncombinando com caracter??sticas intr??nsecas a? espe?cie, os mergulhos efetuados dentro do campo\nconsiderado sera?o certamente detetados.\n\nRecorrendo a dados recolhidos pelo AUTEC, e? apresentado um me?todo para estimar a\nabunda?ncia de Md. Visto os indiv??duos desta espe?cie despenderem muito pouco tempo a?\nsuperf??cie, os tradicionais me?todos de estimac?a?o de abunda?ncia, como a amostragem por\ndista?ncias por transetos lineares, podem conduzir a resultados inconclusivos. Com o aux??lio\nde me?todos acu?sticos que detetam e classificam os cliques de ecolocalizac?a?o de Md, e? poss??vel\nneste trabalho atribuir estes cliques detetados a cada grupo que efectue um mergulho.\n\nA abordagem proposta propo?e desenvolver me?todos previamente apresentados por DiMarzio\net al. (2008) e Moretti et al. (2010). De acordo com estes autores, a densidade de animais e?\nestimada como o produto entre uma estimativa da densidade de grupos e do nu?mero me?dio de\nanimais por grupo. Ao inve?s de se considerar um tamanho me?dio de grupo baseado na literatura,\n\nix\n\n\n\no nu?mero de animais em cada grupo sera? estimado com base na sua pegada acu?stica (acoustical\nfootprint) atrave?s de um modelo linear generalizado.\n\nPara este estudo, sa?o considerados dois conjuntos de dados:\n(1) o conjunto de dados da modelac?a?o. Utilizado para construir o modelo do tamanho de\n\ngrupo como func?a?o da pegada acu?stica dos grupos;\n(2) o conjunto de dados da estimac?a?o da densidade. Utilizado para estimar a densidade dado\n\no modelo de tamanho de grupos obtido com o primeiro conjunto de dados.\nO conjunto de dados da modelac?a?o consiste em 51 mergulhos profundos identificados entre\n\n2005 e 2008, para os quais o tamanho de grupos se confirmou visualmente ou mediante\numa ana?lise dos dados acu?sticos complexa e que como tal na?o pode ser automatizada ou\nrotineiramente utilizada. As potenciais varia?veis explicativas incluem, para cada mergulho\ndetetado, o nu?mero de hidrofones envolvidos na detec?a?o dos cliques, o nu?mero de cliques\ndetectados em cada hidrofone, o in??cio e o fim do per??odo da ecolocalizac?a?o, o tempo entre cliques\nsucessivos detectados num mesmo hidrophone, e varia?veis bina?rias: uma que indica se algum dos\nhidrofones em que o grupo foi detectado se encontra na periferia da rede de hidrofones, e outras\nduas que indicam se algum dos hidrofones pertencem a uma categoria diferente dos restantes\n(hidrofones \u201cWhiskey ou \u201cDirection\u201d). Posteriormente, constru??ram-se varia?veis adicionais tendo\npor base estas u?ltimas: a durac?a?o dos cliques e a taxa a que os cliques ocorrem. O tamanho de\ngrupo para estes dados varia entre 1 e 6 baleias.\n\nO conjunto de dados da estimac?a?o da densidade e? uma se?rie temporal que cobre cerca de 4\nmeses do ano de 2011: (1) de 28 de April a 27 de Junho (61 dias), (2) de 20 de Outubro a 6\nde Novembro (18 dias), e (3) de 2 a 31 de Dezembro (30 dias). Estes dados foram processados\nutilizando o mesmo procedimento que gerou os dados para a modelac?a?o do tamanho de grupo,\nsendo que este sera? estimado para todos os mergulhos profundos detetados. Este me?todo permite\nquantificar os cliques que ocorreram no campo de hidrofones do AUTEC durante o per??odo\nconsiderado, permitindo tambe?m estimar o nu?mero total de animais envolvidos. Por sua vez, tal\nprocedimento permitira? a estimac?a?o de densidade ao longo do tempo recorrendo a um me?todo\nmelhorado de contagem de mergulhos proposto por Moretti et al (2010).\n\nNum total de 15493 potenciais mergulhos apenas 8271 foram considerados apo?s implementar\num pre?-processamento dos dados baseado em caracter??sticas biolo?gicas de Md e dos hidrofones.\nEste pre?-processamento consiste em excluir poss??veis falsos positivos tendo em conta:\n\n(1) detec?o?es que ocorrem somente num u?nico hidrofone;\n(2) um m??nimo de 400 cliques detetados por grupo;\n(3) grupos apenas detetados por hidrofones localizados na periferia.\nAs 8271 detec?o?es consideradas como verdadeiros mergulhos das baleias aparentam dividir-se\n\nde forma uniforme ao longo dos 3 per??odos considerados: 4562 para o primeiro, com uma me?dia\nde 75 mergulhos detetados por dia; 1439 para o segundo, com cerca de 80 mergulhos por dia;\ne 2270 mergulhos para o terceiro per??odo, com uma me?dia de 76 mergulhos por dia. A ana?lise\nindica que o tamanho de grupo podera? ser previsto pela pegada acu?stica do grupo com base nas\ncovaria?veis consideradas. A varia?vel mais importante para a modelac?a?o do tamanho do grupo\naparenta ser a taxa de cliques. No entanto, sera? necessa?ria uma maior recolha de dados de\nmodelac?a?o para sustentar esta hipo?tese.\n\nAquando da estimac?a?o, verifica-se que existe uma certa flutuac?a?o da densidade ao longo\ndo tempo. De maneira a propagar a varia?ncia do modelo selecionado pelas estimativas de\n\nx\n\n\n\nvaria?ncia da densidade por dia, implementou-se um bootstrap. Tal conduziu a novas estimativas\ndos para?metros, o que por sua vez faculta diferentes estimac?o?es para cada tamanho de grupo.\nEste procedimento permite visualizar poss??veis variac?o?es na estimac?a?o dos para?metros e a sua\ninflue?ncia na estimac?a?o do tamanho de grupo e da densidade para cada dia.\n\nDe futuro, pretende-se relacionar esta flutuac?a?o com a ocorre?ncia de fatores externos,\nnomeadamente fatores antropoge?nicos. Os resultados deste trabalho, conjugando com\ntrabalhos anteriores e futuros, sera?o utilizados para prever os comportamentos desta espe?cie de\nmaneira a monitorizar padro?es inerentes a? sua mobilidade. Com isto, espera-se contribuir para\no reposito?rio de informac?a?o de Md e preencher lacunas na compreensa?o dos ha?bitos desta espe?cie.\n\nPalavras-Chave: Baleia de bico de Blainville, Ecolocalizac?a?o, Contagem de mergulhos,\nEstimac?a?o de densidade, Tamanho de grupo, Acu?stica passiva.\n\nxi\n\n\n\nxii\n\n\n\nAbstract\n\nBlainville\u2019s beaked whales (Mesoplodon densirostris, Md) are known to associate in groups,\nexhibiting metronomic dive behaviour. They tend to vocalize via echolocations only during deep\nforaging dives using broadband clicks.\n\nUsing Md click data collected on AUTEC (Atlantic Undersea Test and Evaluation Center)\nhydrophones, a method for estimating Md abundance is presented. The Md click data accounts\nfor the echolocations for each corresponding Md group foraging dive, where the start of a foraging\ndive is assumed to be the time of the first detected echolocation click.\n\nThe proposed approach extends previous methods developed by Moretti et al. (2010) and\nDiMarzio et al. (2008). Instead of considering an estimated average group size value based\non literature, the size of each group will be estimated considering variables derived from the\nacoustic data, via a generalized linear model.\n\nWe consider two different data sets: one to build the model of group size as a function of the\ngroups acoustic footprint, and another to estimate density, leveraging on the group\u2019s size model.\n\nThe modelling dataset consists of 51 deep dives identified between 2005 and 2008, for which\nthe group size was visually confirmed. Potential explanatory variables include, for each detected\ndive, the number of the hydrophones which detected the echolocation clicks, the number of clicks\ndetected in each hydrophone, the corresponding start and end of the echolocation period, and\nbinary variables which indicate whether or not the particular group had its clicks detected by at\nleast one hydrophone located on the edge, or if at least one hydrophone belongs to the particular\ntypes of Whiskey or Bi-directional hydrophones. Further, a number of derived variables were\nconstructed from the dataset. The group size in this modelling data ranged between 1 and 6\nwhales.\n\nThe density estimation dataset is a time series of AUTEC data from which density will be\nestimated. It includes 3 separate periods of time in 2011: (1) 61 days from the 28th of April to\nthe 27th of June, (2) 18 days from the 20th of October to the 6th of November, and (3) 30 days\nfrom the 2nd to the 31st of December. These data were processed using the same procedure that\ngenerated the data for the group size model, and the group size will be estimated for all deep\ndives detected. This method allows to quantify how many dives occurred on the AUTEC range\nduring that period, and to estimate the total number of animals involved. This in turn allows\nthe estimation of density over time using this improved version of the dive counting method\nproposed by Moretti et al. (2010).\n\nIn total 15493 potential deep dives were detected in the second dataset. A preprocessing\nof the data to exclude false positives was implemented, based on a set of biologically infeasible\ncharacteristics:\n\n(1) detections occurring on a single hydrophone;\n(2) a minimum threshold of 400 clicks detected. This resulted in a much more biologically\n\nplausible distribution of observed vocal lengths, matching what would be expected given\ndescribed values in the literature;\n\n(3) groups detected only on edge hydrophones, considering these would correspond to groups\noutside the area of inference.\n\nxiii\n\n\n\nThis led to 8271 detections considered to correspond to relevant beaked whale deep dives.\nThe first period of time recorded 4562 dives, with an average of 75 dives per day; the second\nperiod showed 1439 dives with an average of 80 dives per day; and the third one registered 2270\ndives with an average of 76 dives per day.\n\nAfter adjusting generalized linear models, there is an indication that the group size can be\npredicted from acoustic footprint of the group via available covariates. The most important\nvariable to explain group size appears to be the click rate. When looking at the estimation\u2019s\nresults, a certain fluctuation over time is noticeable. Hereafter, this fluctuation is intended to be\nrelated with external factors, namely anthropogenic factors. A bootstrap was then applied to\npropagate the variance in the model of group size thorough the estimates of variance of density\nper day.\n\nThe results from this study, conjugating with previous and future studies, will allow a better\nunderstanding of this species behaviour in order to monitor mobility patterns.\n\nKeywords: Blainville\u2019s beaked whales, Echolocation, Dive counting, Density Estimation,\nGroup size, Passive acoustic.\n\nxiv\n\n\n\nChapter 1\n\nIntroduction\n\n1.1 The Idea Behind this Study\n\nEfficient and precise methods for estimating the abundance of natural populations are\nrequired for their effective management and conservation. Consequently, it is important to\noptimize existing models. Methods allowing in situ monitoring with a minimum amount\nof human intervention are becoming more popular to study natural populations. As the\nindividuals belonging to the Mesoplodon densirostris species spend little time on the surface,\nother traditional abundance estimation methods, like line transect distance sampling, may lead\nto inconclusive results. The fact that these whales produce distinctive echolocation clicks at\na relatively steady rate while searching for prey, makes them a suitable candidate for Passive\nAcoustic Monitoring (PAM) (Tyack et al., 2006).\n\nGroup size is an important factor to account for when dealing with animal density estimation.\nDescribing the group size distribution over time and space might bring further knowledge about\nthe effect of AUTEC sonar usage on the considered species (Marques et al., 2013); and it was\nin fact shown by DiMarzio et al. (2008) that, for a reduced number of groups with known size,\nthe acoustical footprint of a group is dependent on its group size.\n\nThe present case study focuses on PAM to detect and classify these whales\u2019 echolocation\nclicks. It starts by using a first dataset to model group size as a function of the acoustical\nfootprint of the groups on the surrounding hydrophones on the Atlantic Undersea Test\nand Evaluation Center. A model is created relating acoustic footprint statistics (e.g., click\ndetection counts, number of hydrophones involved) on hydrophones to group size, estimating the\nparameters using surface visual observations. The statistical model will enable the development\nof a real-time algorithm to estimate and display group size information for support of routine\ndensity estimation (e.g., Marques et al., 2009 and Moretti et al., 2010) and to assist in live range\noperations.\n\nA previously published approach to estimate this species density in the area uses an estimated\naverage group size value based on literature (Moretti et al, 2010). As visually confirming each\ngroup\u2019s size for time-series data is an impossible task, an automated way to estimate group size is\nneeded. This work will extend the previous approach by first modelling the group size resorting\nto a dataset of 51 Md groups detected at the hydrophones on the Atlantic Undersea Test and\nEvaluation Center whose size was visually and acoustically confirmed, relating the group size to\nthe acoustic footprint variables.\n\nResorting to the previous developed model, group size is estimated for more than 8000\nMesoplodon Densirostris groups, whose group size was not visually confirmed, from a dataset\nwhere density will be estimated: a time series of acoustic data also collected by the same\nhydrophones, which considers the same acoustic footprint variables from the modelling dataset.\nAfter estimating group size for each detected group, density and associated precision measures\n\n1\n\n\n\nwill be estimated by day over the time period for which recordings are available.\nIn the next subsections, a brief description of Mesoplodon Densirostris will take place, as\n\nwell as the hydrophone range camp, followed by a summary of the main goals.\n\n1.2 Blainville\u2019s Beaked Whale\n\nDescription\n\nBlainville\u2019s beaked whale, Mesoplodon densirostris (Md), is the widest ranging species\nbelonging to the genus Mesoplodon, occurring in low to mid-latitudes in all oceans. Maximum\nrecorded length is around 4.7 meters, with the individuals weighing about 1000 kilograms\n(Jefferson et al., 2008). They are most easily identified by their large and robust body, small\nforehead and long, dense, well-defined beak, which inspired this species\u2019 name. The most\ndistinctive feature is the dense upper jawbone, along with the posterior half of the lower jaw\nhighly arched with two massive horn-like teeth, typically more prominent in males. Males also\ntend to show dorsal body scarring, whose patterns seem to match the tooth structure and\nposition of conspecifics, which suggests these same markings occur due to intraspecific combat\n(MacLeod, 1998). Body colouration is lighter on female individuals, varying from blue-grey to\nblack, with a whiter tone on the ventral side and several spots along the body. (Leatherwood\n&amp; Reeves, 1983; McCann, 1963; Mead, 1989; Pastene et al., 1990). Figure 1.1 illustrates these\nMd\u2019s physical features.\n\nFigure 1.1: Representation of Blainville\u2019s beaked whales. Female (bottom) and male (top). The later exhibits\nbody scarring, more prominent teeth and darker body colouration. Source: \u00a9 Wurtz \u2013 www.artescienza.org.\n\nBehaviour and Habits\n\nAlthough it is perhaps one of the most well documented beaked whale species, these whales\nexhibit a shy and discreet behaviour, being rarely seen due to spending most of their time\nforaging at depth. Only a short period of time is spent at the surface, resulting in a low\nprobability of visual detection (Barlow, 1999; Tyack et al., 2006). These whales typically occur\n\n2\n\n\n\nin small groups of up to about 11 individuals (Dimarzio et al, 2008), and engage in prolonged\ndives several times a day to feed mainly on squid; although they also prey on small deep-sea fish\nand crustaceans (Baird et al, 2008; Johnson et al, 2006). When foraging, the group is known to\nperform synchronized dives to great depths, time at which Md produces distinctive ultrasonic\necholocation signals, known as \u2018clicks\u2019, with a bandwidth from 26 to 51 kHz (Johnson et al,\n2006). Figure 1.2 provides an insight of Md\u2019s diving profile, where the tagged individual forages\nto depths up to 1400 meters.\n\nFigure 1.2: Illustration of an individual\u2019s diving profile depth: data from a 22.6h deployment on a tagged\nBlainville\u2019s beaked whale divided into two days: A (12.6 hours) and B (10 hours). Adapted from Baird et al.,\n\n2006.\n\nAccording to Johnson et al. (2006), there are two types of click sounds: search clicks (also\nknown as \u2018regular clicks\u2019) and buzz clicks, as illustrated in figure 1.3. The first one is produced\nduring the whole foraging dive, whereas the later is emitted in short bursts during the final stage\nof prey capture.\n\n3\n\n\n\nFigure 1.3: Dive profile illustration of a Blainville\u2019s beaked whale foraging dive showing vocal events,\nfeaturing regular and buzz clicks. Retrieved from Johnson et al., 2006.\n\nTyack et al. (2006) suggests that Md hunt by echolocation in deep waters between 250 and\n1900 meters, attempting to capture about 30 prey per dive. The food source is so deep that the\naverage foraging dives are deeper (835 m) and longer (47 min) than reported in the literature\nfor any other marine mammal species.\n\nIt is known that Md groups produce a minimum amount of clicks when diving (Moretti et\nal., 2010, Shaffer et al., 2013). According to Shaffer et al. (2013), the mean number of foraging\nclicks emitted by each animal is around 3000 clicks per dive (with a range of 939 \u2013 6663 clicks).\n\nBaird et al. (2008) reported that deep foraging dives (>800 m) occur at similar rates during\nboth the day and night, despite whales spending more time in shallow depths (<100 m) during\nthe night. Dives to mid-water depths (100-600 m) occurred significantly more often during the\nday. This suggests that the whales may spend less time in surface waters during the day to\navoid near-surface, visually oriented predators such as large sharks or killer whales.\n\n1.3 The Case Study\n\n1.3.1 The AUTEC\n\nThe Atlantic Undersea Test and Evaluation Center (AUTEC) is a U.S.A. Navy testing and\ntraining range located in the Tongue of the Ocean (TOTO) in the Bahamas. It is a site of\nrepeated sonar use, and Md are routinely detected year-round on the AUTEC range. It includes\na large network of hydrophones cabled to shore that can be used to detect Md echolocation\nclicks. Given the hydrophone spacing and sensitivity, combined with the animals\u2019 clicks source\nlevel, all the dives occurring on the AUTEC range can be assumed to be detected with certainty\n(Moretti et al., 2010).\n\nAs represented in figure 1.4, the training range consists of two separate hydrophones\nsystems: the two older Whiskey arrays (hydrophones 1-14, a total of 14) which were the\nfirst devices installed, and the newer Advanced Hydrophone Replacement Program (AHRP)\narray (hydrophones 15-93, a total of 79) which hold a more recent technology. The AHRP\n\n4\n\n\n\narray is itself composed by two different types of hydrophones: 16 bi-directional (transmit and\nreceive) and 63 uni-directional (receive only) hydrophones. The Whiskey and AHRP arrays have\ndifferent hydrophone features and shore processing hardware resulting in distinct Md detection\ncharacteristics, while the uni-directional and bi-directional hydrophones have different receiver\nbeam patterns. The bi-directional hydrophones have more electronic noise adding to a greater\nchance of false positive detections. The AHRP bi-directional hydrophones include numbers 15,\n20, 30, 41, 42, 45, 56, 58, 61, 69, 72, 75, 78, 88, 91, and 93 (Shaffer, J., personal communication).\n\nThe range area is defined as a \u201cconvex hull\u201d with a 6.5 km buffer around the non-edge\nhydrophones. This area for dive counting is defined based on the assumption that groups\noccurring within it would have at least some clicks detected on non-edge phones, and groups\noccurring outside that area would not have any clicks detected on non-edge phones. This provides\na straightforward operational rule to include/exclude dives from our dive counting procedure,\nas will be explained forward.\n\nFigure 1.4: Hydrophone camp with the 93 hydrophones (numbered), featuring the \u201cconvex hull\u201d area\n(yellow), the Edge hydrophones (black line), non-Edge hydrophones (red line and inside red line), Whiskey\n\nhydrophones (circled green), and Bidirectional hydrophones (squared grey). Adapted from Moretti et al., 2010.\n\nIt is also important to highlight it is taken into account in this study whether or not a\nhydrophone is located on the edge. Since these type of hydrophones have a higher chance\n\n5\n\n\n\nof capturing echolocations out of the considered area of 1291km2, it is more likely that they\nincorporate false positive detections. Edge hydrophones include numbers 1, 2, 3, 15, 16, 17, 20,\n24, 25, 30, 34, 35, 41, 42, 46, 53, 56, 61, 64, 69, 72, 77, 78, 80, 85, 88, 91, 92 and 93.\n\n1.4 Main Objectives\n\nThe specific key objectives of this study are:\n\n1. To model group size as a function of the acoustic footprint of a group as detected\nautomatically by an existing algorithm, using a dataset of acoustical footprints for groups\nwith verified group size;\n\n2. By using the model previously built, predict the group size for groups with no verified\ngroup size;\n\n3. To estimate Md density per day for a 4 month period, adapting the previous method\nproposed by Moretti et al. (2010);\n\n4. Obtain precision measures for the model predictions and density estimates using a\nnon-parametric bootstrap.\n\nBesides the four items above, two other \u201cextra\u201d objectives were incorporated in this project:\n\n5. Since both datasets will probably be used in future studies, a more profound exploratory\ndata analysis was performed, looking in particular at click detection differences between\nthe hydrophone types.\n\n6. Inspired in the author\u2019s own previous experience, this work\u2019s writing style is aimed at\necologists whose statistical knowledge might be scarse. Therefore, an extra effort was made\nto provide a theoretical explanation which may help the reader to actually understand what\nis behind the employed statistical methods.\n\nIn the next section, the methodology required to implement the methods will be described.\nAfterwards, the project\u2019s results are presented. We conclude with a discussion about our\nresults, possible ways forward, and the summary of the acquired competencies during the MSc\nprogramme.\n\n6\n\n\n\nChapter 2\n\nMethodology\n\nIn this section we begin by describing the data, followed by all the transformations necessary\nto implement the analysis. All the data were analysed resorting to the R software.\n\n2.1 The Data\n\nFor this study two different datasets are considered: (1) the modelling dataset consists of Md\ngroups acoustic data whose size was visually confirmed. It was used to build the model of the\ngroup size as function of the group\u2019s acoustic footprint; and (2) the density estimation dataset\nwhich was employed after building the model, which consists on a time series of data from the\nAUTEC hydrophones for which the Md group size and density were estimated.\n\nBoth datasets were generated at AUTEC resorting to Autogrouper, which is a MATLAB\n(Mathworks) script, an automatic process that identifies whale dives by quickly identifying start\nand end times of the echolocations. It works by combining clicks within hydrophones into\nsequences of clicks, named click trains. Then it groups click trains close in space and time, i.e.,\ndetected simultaneously in adjacent hydrophones, into vocal groups. Each vocal group detected\ncorresponds to a Md foraging dive. Associated with each detected dive there is a set of available\nstatistics that define the acoustic footprint of the group, such as the amount of detected clicks\nand the quantity of hydrophones involved on each detection (Madsen et al., 2013).\n\nAs buzz clicks are produced in short bursts with no FM structure and may be difficult to\ncollect (Johnson et al., 2006), the data only includes search clicks. Since these clicks are produced\nduring the whole foraging dive, and not only during the final stage of prey capture (like buzz\nclicks), search clicks offer a thorough insight of Md acoustic footprint.\n\n2.1.1 Modelling Dataset\n\nThe modelling dataset includes the Autogrouper routine output for 51 deep dives, between\n2005 and 2008, that were confirmed either visually or resorting to a very detailed acoustical\nanalysis which is far more time consuming than it would be possible to process data on an\neveryday basis. It includes several potential covariates to model group size:\n\n\u2022 The number of hydrophones at which group i was detected, Ki;\n\n\u2022 The number of clicks from group i detected at hydrophone k, ci,k . It is then possible\nto obtain the total number of clicks detected for group i (Ni) by summing over the Ki\nhydrophones it was detected on:\n\n7\n\n\n\nNi =\nKi?\nk=1\n\nci,k ; (2.1)\n\n\u2022 The mean number of clicks, mi, detected per hydrophone for group i, where:\n\nmi =\nNi\nKi\n\n; (2.2)\n\n\u2022 Each hydrophone\u2019s click period, in microseconds, from which it is possible to obtain the\ntotal clicking duration, d i ;\n\n\u2022 The maximum click count per hydrophone detected for group i, maxi(ci,1, ci,2,..., ci,Ki );\n\n\u2022 A pooled detected click rate, ri, for each group i, where:\n\nri =\nNi\ndi\n. (2.3)\n\nTable 2.1: The data available for each group. For illustration purposes only the data for the first 5 groups are\nshown.\n\ngID cs conf maxi mi Ki di (in \u00b5s) Ni ri wisk direc\n1 2 2 740 335.5 6 24.20 2013 83.2 1 0\n2 2 1 575 239.7 6 13.67 1438 105.2 1 0\n3 3 1 5263 924.0 11 39.40 10164 257.9 1 0\n4 2 1 3214 491.0 10 41.95 4916 117.2 0 1\n5 5 1 3852 1140.1 9 31.97 10261 320.9 0 1\n\nSince the Whiskey hydrophones are more densely distributed, dives occurring around these\nmay result in groups which are detected by a higher number of hydrophones. This may\nintroduce confounding, hence an indicator (wisk) to account the variable \u201cWhiskey\u201d was defined.\nAdditionally, because hydrophones with different directionality may have dissimilar detectability,\na binary indicator variable (direc) was defined to further investigate that possibility.\n\nTable 2.1 columns represent the potential covariates stated above plus the dependent variable\ngroup size (cs), as well as a few indicator variables:\n\n\u2022 gID - the group identification (ID);\n\n\u2022 cs - the cluster (group) size, the dependent or response variable;\n\n\u2022 conf - the confidence level associated with the visual confirmation of group size. This\nindicator takes the values conf = 1,2,3, where 1 = more certain, 2 = more or less certain,\nand 3 = less certain;\n\n\u2022 wisk - if there is at least one Whiskey hydrophone involved (wisk = 1) or not (wisk = 0);\n\n8\n\n\n\n\u2022 direc - if there is at least one Bidirectional hydrophone involved (direc = 1) or not (direc\n= 0).\n\nThe majority of the groups involved, 43 out of 51, have a confidence level of 1 (conf = 1 ),\nwhile 7 groups have a confidence of 2 (conf = 2 ), and only one group has confidence level 3\n(conf = 3 ). To evaluate the influence of certainty in group size assignment in the model, another\nanalysis with only groups with a confidence level of 1 will be considered. If the models are not\nsignificantly different, and for the sake of using the maximum available data to parametrize a\nmodel for predicting group size, all the groups will be used to create the final model.\n\n2.1.2 Density Estimation Dataset\n\nA second dataset (with unknown group sizes) will be used to estimate group sizes based\non the model that related group size to acoustic footprint, which will then allow the density\nestimation over time. It contemplates three different time periods from 2011, covering a total of\n113 days. However, 4 out of 113 these days were only partially sampled. Given our objective of\nproducing density estimates per day, it is simpler to consider only the 109 days for which there\nare 24 hours of recording, and hence these incomplete days were discarded from further analysis.\n\nThe considered time periods are: (1) from the 28th of April to the 27th of June; (2) from\nthe 20th of October to the 6th of November; and (3) from the 2nd to the 31st of December, as\nrepresented in table 2.2.\n\nTable 2.2: Time periods summary table, discarding the \u201chalf-days\u201d and only considering 109 days.\n\nPeriod Start date End data Total days\n1 28/04/2011 27/06/2011 61\n2 20/10/2011 06/11/2011 18\n3 02/12/2011 31/12/2011 30\n\n2.1.2.1 Raw data\n\nThis dataset has a total of 70865 observations, where each line refers to the detections for a\ngiven group on a single hydrophone. Hence, each group includes as many rows as hydrophones\nit was detected on. The same automated procedure that originated the dataset for modelling\nwas also used to obtain this dataset for predictions.\n\n9\n\n\n\nTable 2.3: The data available from the second dataset. For illustration purposes only the data for the first 10\nlines are shown.\n\ngID edge hyd clickcnt start (in days) end (in days) ici (in secs)\n1 1 93 2058 15091.859392 15091.866419 0.2844\n1 1 92 263 15091.859441 15091.866395 0.3416\n1 0 90 152 15091.859450 15091.866078 0.2546\n1 0 89 85 15091.859635 15091.866173 0.3291\n2 1 42 963 15091.867232 15091.887353 0.3575\n2 0 43 239 15091.867716 15091.887377 0.3386\n3 0 36 2499 15091.867396 15091.895267 0.3767\n3 0 37 1500 15091.869670 15091.894790 0.3829\n3 1 35 11 15091.872627 15091.873743 0.2540\n3 1 35 508 15091.876053 15091.894321 0.3396\n\nTable 2.3 contains the first ten lines from the dataset, where each column corresponds to:\n\n\u2022 gID - the number of the group detected;\n\n\u2022 edge - whether or not the hydrophone that detected the clicks is located at the edge;\n\n\u2022 clickcnt - the number of clicks counted by the corresponding hydrophone;\n\n\u2022 start - time at which the corresponding hydrophone first detected the clicks, in days,\nwhere 0 days would correspond to midnight on the 1st of January, 1970 (00h00 UTC,\n01/01/1970);\n\n\u2022 end - time at which the corresponding hydrophone ceased detecting clicks, in days, with\nan identical format as the start column;\n\n\u2022 ici - a mean value for the inter-click interval at the corresponding hydrophone.\n\n2.1.2.2 Data Cleaning\n\nThe dataset reported above (section 2.1.2.1) was first processed to construct a database with\na similar format as that used for modelling, obtaining all the relevant variables required (e.g., the\nKi is the number of rows a click was recorded on, the Ni the sum of the click count across those\nsame rows, and so on). Additionally, several procedures to eliminate false positive detections\nwere employed. The following steps were taken sequentially:\n\n1) Hydrophone Duplicates\n\nFirst, it was necessary to remove multiple records of clicks detected for the same group and\nsame hydrophone, which were created when there were large time gaps between successive click\ntrains in a given hydrophone. To do so, a unique identifier for each row was created, consisting\nin the group and the hydrophone separated by a dot (e.g. \u201d1.89\u201d corresponds to clicks from\nthe first group detected on hydrophone 89). Records with the same indicator would correspond\n\n10\n\n\n\nto records for the same group and hydrophone, and hence were merged. The values kept were\nthe earliest start and end time, the summation of the click counts, and the minimum inter-click\ninterval. The remaining hydrophone related variables were kept unchanged, since corresponding\nto records from the same hydrophone, they would have the same value.\n\n2) Click Duration\n\nThe next step was to incorporate a new column that refers to the click duration. It is\nachieved simply by subtracting the end and start columns.\n\n3) Whiskey Hydrophones\n\nIt is also relevant to distinguish between Whiskey and non-Whiskey hydrophones, for which a\nbinary column (0=non-Whiskey, 1=Whiskey) was added. An analysis comparing the potential\ndetection differences between these two types of hydrophones was implemented (see details\nbelow).\n\n4) Uni/Bi-Directional Hydrophones\n\nSince the type of beam direction may influence click detection, it makes sense that Uni\nand Bi-directional hydrophones should be distinguished. A binary column was added (0=Uni,\n1=Bi).\n\n5) Data per Group\n\nSince this study addresses the size and density estimation for each Md group, there was the\nneed to restructure the data set, such that each record correspond to a single group. To achieve\nit, the data for each group, comprising as many rows as hydrophones it had been detected on,\nwas condensed into a single row per group with variables at the group level. These included:\n\n\u2022 A new column (nhyd) was created, with the number of hydrophones (Ki) involved on each\ngroup clicks detection;\n\n\u2022 A new indicator for the edge column was created. If all hydrophones for a group were\nedge, then the indicator variable edge becomes 1, else it becomes 0. If there is at least a\nnon-Edge hydrophone, it suggests that the corresponding group is most certainly inside\nthe area over which density will be estimated. If edge = 1 we assume the record most\nlikely corresponds to a false positive;\n\n\u2022 The variable (shyd) was also created. If the group was only detected on a single\nhydrophone, the variable shyd was recorded as 1, and 0 otherwise. The former are\nconsidered background noise and were removed since it is highly unlikely, if not impossible,\nfor a Md individual to pass through the AUTEC range with only a hydrophone detecting\nthe corresponding echolocations. Note therefore a 1 suggests a false positive;\n\n\u2022 Since there is the possibility of background noise being detected, hence resulting in false\npositives, a minimum number of detected clicks per group threshold was set (thres).\nA threshold of 400 clicks was previously tested to be a reasonable amount to consider\n(Moretti, D., personal communication). Variable thres was set to 1 if the total number of\n\n11\n\n\n\nclicks detected for the group was less to 400, and 1 otherwise. Note therefore a 1 suggests\na false positive.\n\n6) Additional information\n\nSome additional information was added for each group, such as which period each group\nbelongs to, and the corresponding time and date.\n\n7) Removing False Positives\n\nLastly, a final column (est) was created, which will take the value 1 if the group is to be\nconsidered for estimation of density, and 0 otherwise. The variable takes the value 1, meaning\nthe row corresponds to a valid group size and not a false positive, only if none of the 3 false\npositive indicator variables were true, and 0 otherwise.\n\nTable 2.4 illustrates the first lines of the filtered and transformed data, where each column\nrepresents for each group:\n\n\u2022 gID - the number of the group detected;\n\n\u2022 nhyd - the total number of hydrophones the group was detected on;\n\n\u2022 nclicks - the total number of clicks detected by the group;\n\n\u2022 start - time of the first click detected;\n\n\u2022 end - time of the last detected click;\n\n\u2022 mici - the minimum inter-click interval;\n\n\u2022 edge - indicator for whether the group was only detected on edge hydrophones;\n\n\u2022 shyd - indicator for groups detected on a single hydrophone;\n\n\u2022 thres - indicator of whether a minimum number of clicks (400) was detected;\n\n\u2022 est - indicator of whether the group is to be used for density estimation;\n\n\u2022 period - the period (1, 2 or 3) the corresponding group was detected on.\n\n\u2022 cdur - the total duration, in minutes, the hydrophones detected the corresponding group\u2019s\nclicks;\n\n\u2022 crate - a pooled detection click rate for the corresponding group;\n\n\u2022 date - the date each group was first detected, format day/month/year;\n\n\u2022 jday - the julian day of year for the first click detected;\n\n12\n\n\n\nTable 2.4: The data for group size estimation. For illustration purposes only the data for the first 10 lines are shown.\n\ngID nhyd nclicks start end mici edge shyd thres est period cdur crate date jday\n1 4 2558 15091.86 15091.87 0.25 0 0 0 TRUE 1 10.12 252.7948 27/04/2011 117\n2 2 1202 15091.87 15091.89 0.34 0 0 0 TRUE 1 29.01 41.4357 27/04/2011 117\n3 12 14462 15091.87 15091.90 0.25 0 0 0 TRUE 1 40.13 360.3407 27/04/2011 117\n5 5 11250 15091.87 15091.91 0.28 0 0 0 TRUE 1 48.64 231.2828 27/04/2011 117\n8 8 5430 15091.89 15091.92 0.26 0 0 0 TRUE 1 51.56 105.3188 27/04/2011 117\n11 8 6342 15091.92 15091.95 0.23 0 0 0 TRUE 1 39.67 159.8783 27/04/2011 117\n14 7 10117 15091.95 15091.97 0.34 0 0 0 TRUE 1 31.09 325.4444 27/04/2011 117\n16 12 13149 15091.95 15091.99 0.24 0 0 0 TRUE 1 56.29 233.5776 27/04/2011 117\n19 7 6654 15091.97 15092.00 0.29 0 0 0 TRUE 1 37.99 175.1377 27/04/2011 117\n20 5 9401 15091.98 15092.00 0.33 0 0 0 TRUE 1 36.80 255.4375 27/04/2011 117\n\n13\n\n\n\n2.2 Some Insights on Exploratory Data Analysis\n\nBefore implementing any models, it is useful to thoroughly understand the data. Considering\nthe modelling dataset, an univariate analysis for each explanatory variable was implemented,\nfollowed by studying the correlation between them. Some techniques to evaluate correlation\nbetween variables are presented next.\n\nAdditionally, the data may hold potential differences between the echolocations collected\nfrom the several types on hydrophones. Therefore, graphics and histograms were useful to\nprovide additional insights about the data. Each covariate was also studied individually.\n\n2.2.1 Correlation\n\nExamining possible relations within the pool of independent variables is a first step to\nunderstand how the variables interact with each other. Analysing the respective graphics may\nbe an important tool to visualize such patterns. Although correlation may take several forms,\nsuch as a quadratic pattern, the most common and perceptible correlations happen when a\nvariable increases or decreases linearly or monotonically along with another one. If a variable\nincreases when another ones does, then these two variables are said to be positively correlated.\nOn the other hand, when a variable increases and another decreases, then they are said to be\nnegatively correlated. In the case of a low or no correlation, no discernible linear pattern is\npresent between the two variables.\n\nThere are different ways to measure the correlation between variables, even if they differ in\nnature. Bellow are presented methods, based on correlation coefficients, that take into account\nthe two types of variables the two datasets hold: continuous and dichotomous. All the methods\npresented are accompanied with significance tests for the correlation coefficients, based on the\nsample correlation coefficient, considering a level of significance (?) of 0.05, where the null\nhypothesis refers to no correlation (correlation coefficient = 0).\n\n2.2.1.1 Pearson Product-Moment Correlation Coefficient\n\nAccording to Cramer (1998), the Pearson product-moment correlation coefficient, or\nPearson\u2019s ?, arguably the most widely correlation statistic used, measures the strength of linear\ndependence between two continuous variables. This coefficient\u2019s estimator, R, varies between -1\nand 1, where:\n\n\u2022 R = 1 means a perfect positive correlation between the two variables (they both increase\nor decrease together);\n\n\u2022 R = ?1 means a perfect negative correlation between the two variables (one increases as\nthe other decreases);\n\n\u2022 R = 0 means the two variables do not hold a linear dependency.\n\nThe closer R is to ?1 or 1, the stronger the association. Pearson\u2019s ? is estimated by the\nformula:\n\n14\n\n\n\nR(X,Y) =\n\nn?\ni=1\n\n(Xi ? X?)(Yi ? Y? )?\nn?\ni=1\n\n(Xi ? X?)2.\n?\n\nn?\ni=1\n\n(Yi ? Y? )2\n=\nS(X,Y )?\nS2XS\n\n2\nY\n\n, (2.4)\n\nwhere X and Y represent two different random variables; and both X 1, X 2, ...,X n and Y 1,\nY 2, ...,Y n correspond to the sampled populations from X and Y, respectively. Also, X? and Y?\ncorrespond to the sample means of X and Y, respectively:\n\nX? =\n1\nn\n\nn?\ni=1\n\nXi , Y? =\n1\nn\n\nn?\ni=1\n\nYi , (2.5)\n\nwhere S(X,Y) is the sample covariance between X and Y ; and S2X and S\n2\nY are respectively the\n\nsample variances of X and Y.\nTo be able to use this coefficient, both variables have to be measured on either an interval\n\nor ratio scale. It is not needed for them to be both measured on the same scale. Nonetheless,\noutliers may have a great influence on Pearson\u2019s correlations, which is why it is useful to compare\nthis coefficient\u2019s result with other methods.\n\n2.2.1.2 Spearman\u2019s Rank Correlation Coefficient\n\nAccording to Conover (1999), the Spearman\u2019s rank correlation coefficient, or Spearman\u2019s rs,\nalso varies between ?1 and 1, and applies to ranks by measuring not a linear, but a monotonic\nrelationship between two continuous or discrete random variables. A monotonic function may\nbe defined as one that is either entirely increasing (for all x and y such as x ? y, one has f(x) ?\nf(y)), or decreasing (for all x and y such as x ? y, one has f(x) ? f(y)).\n\nSpearman\u2019s rs is defined as the Pearson correlation coefficient between ranked data and its\nestimator, Rs, may be obtained through the following formula:\n\nRs =\n\nn?\ni=1\n\nR(Xi)R(Yi) ?n\n(\nn+1\n\n2\n\n)2\n?\n\nn?\ni=1\n\nR(Xi)2 ?n\n(\nn+1\n\n2\n\n)2\n\u00b7\n\n?\nn?\ni=1\n\nR(Yi)2 ?n\n(\nn+1\n\n2\n\n)2 , (2.6)\n\nwhere R(Xi) is the rank as compared with the other X values, i = 1, 2, 3, ...,n; and R(Yi) is the\nrank as compared with the other Y values, i = 1, 2, ...,n.\n\nIn case of ties, assign to each tied value the average of the ranks that would have been\nassigned if there had been no ties.\n\nSpearman\u2019s rank correlation coefficient is merely what one obtains by replacing the\nobservations by their ranks and then computing Pearson\u2019s correlation coefficient on the ranks.\nAdditionally, contrarily to Pearson\u2019s ?, Spearman\u2019s rs is used with ordinal data and is robust to\noutliers (Altman, 1991).\n\n2.2.1.3 Point-Biserial Correlation Coefficient\n\nAccording to Sheskin (2011), the Point-biserial correlation coefficient, rpb, is a method to\nstudy the correlation between a continuous and a dichotomous variable. It is mathematically\n\n15\n\n\n\nequivalent to the Pearson product-moment correlation, also varying between ?1 and 1, and can\nbe obtained using the following formula:\n\nrpb =\nX?1 ? X?0\n\nSn-1\n\n?\nn1 \u00b7 n0\nn(n? 1)\n\n, (2.7)\n\nwhere X?1 and X?0 denote the sample means on the continuous variable X for the data points\nwhere the dichotomous variable Y is either Y =1 (group 1) or Y =0 (group 2), respectively; n0\nrepresents the number of observations for group 2; n1 is the number of observations for group\n1. Finally, Sn-1 corresponds to the sample standard deviation, based on X1,X2, ...,Xn, i.e.:\n\nSn?1 =\n\n???? 1\nn? 1\n\nn?\ni=1\n\n(Xi ? X?)2 . (2.8)\n\n2.2.1.4 Phi Coefficient\n\nCramer (1946) defines the Phi coefficient, also known as ?, as a measure of association\nbetween two binary variables and varies between ?1 and 1. It is similar to the Pearson\nproduct-moment correlation coefficient in its interpretation. This coefficient is calculated\nconsidering the marginal and joint distributions from a 2x2 contingency table, as seen in table\n2.5.\n\nContingency tables are a type of table in a matrix format that presents the frequency\ndistribution of the variables. They hold data assorted simultaneously according to several\ncharacteristics.\n\nTable 2.5: 2x2 contingency table for two random binary variables, X and Y.\n\nY = 1 Y = 0 total\nX = 1 n11 n10 n1.\nX = 0 n01 n00 n0.\ntotal n.1 n.1 n\n\nIn table 2.5, a 2x2 contigency table is presented. The entries in the cells of the table are the\nfrequency counts, denoted by n11, n10, n01 and n00, that sum up to n. The marginal totals are\nrepresented by n1., n0., n.1 and n.0.\n\nTwo binary variables are considered positively associated if most of the data falls along the\nmain diagonal. On the contrary, they are considered negatively associated if the majority of the\ndata falls off the main diagonal.\n\nThe ? is defined as:\n\n? =\nn11n00 ? n10n01?\n\nn1.n0.n.0n.1\n. (2.9)\n\n2.2.2 Pearson\u2019s ?2 Tests\n\nPearson\u2019s ?2 tests are commonly used for goodness-of-fit, independence, and homogeneity\ntesting, depending on the type of data one has available and on the sampling design.\n\n16\n\n\n\nBellow are presented two types of Pearson\u2019s ?2 Tests: one for independence and another for\ngoodness-of-fit.\n\n2.2.2.1 Pearson\u2019s ?2 Independence Test\n\nGreenwood and Nikulin (1996) define Pearson\u2019s ?2 independence test as a method to evaluate\nif there is a relationship between two categorical variables by evaluating how likely the differences\nor similarities between them happen by chance. The test is performed under the null hypothesis\nthat the joint distribution of the cell counts in a contingency table is the product of the row and\ncolumn marginals or, put in other way:\n\nH 0: Column classification is independent of row classification\nvs.\n\nH 1: Column classification is not independent of row classification\n\nLet A and B be two categorical variables with respectively r (rows) and c (columns)\ncategories. When observed over n individuals, a contigency table as illustrated in Table 2.6\ncan be built.\n\nTable 2.6: Contingency table for two categorical variables, A and B, with r and c categories, respectively.\n\nB1 B2 ... Bc\nA1 n11 n12 ... n1. n1.\nA2 n21 n22 ... n2. n2.\n... ... ... ... ... ...\nAr nr1 nr2 ... nrc nr.\n\nn.1 n.2 ... n.c n\n\nwhere nij is the observed value in cell (i,j), with i = 1, ...,r and j = 1, ...,c.\nThe expected frequency, Eij, corresponds to the expected value in cell (i,j). Given the H 0\n\nhypothesis of independence, Eij is calculated as:\n\nEij = n pi. p.j , (2.10)\n\nwhere:\n\npi. =\nni.\nn\n\n=\nc?\nj=1\n\nnij\nn\n, i = 1, ...,r ; p.j =\n\nn.j\nn\n\n=\nr?\ni=1\n\nnij\nn\n, j = 1, ...,c, (2.11)\n\nwith ni. referring to the observed frequencies from group i; p.j denotes the column totals of type\nj observations ignoring the row attribute; and n.j refers to the observed frequencies from group\nj. ni. and n.j are also known as the marginal totals.\n\nThe statistical test considers the difference between expected and observed values, being\ndefined as the following:\n\n?2 =\nr?\ni=1\n\nc?\nj=1\n\n(Nij - eij)2\neij\n\n? ?2(r?1)(c?1) . (2.12)\n\n17\n\n\n\nReject H 0 if ?2obs ? ?\n2\n1??;(r?1)(c?1), where ?\n\n2\n1??;(r?1)(c?1) represents the quantile with\n\nprobability 1?? from the ?2 distribution with (r?1)(c?1) degrees of freedom. The closer ?2obs\nis to zero, the less significant is the independence between the variables. Note, the convergence\nto a ?2 is dependent on the fact that no more than 20% of the expected counts are less than 5\nand all individual expected counts are 1 or greater (Yates et al, 1999).\n\n2.2.2.2 Pearson\u2019s ?2 Goodness-of-Fit-Test\n\nAccording to Wayne and Cross (2013), a goodness-of-fit test is suitable to analyse if an\nobserved distribution of frequencies is incompatible with some preconceived or hypothesized\ndistribution. It tests if there is evidence to reject H0, that is, to reject the belief that the\ndata follows a certain distribution. The test takes into account whether or not a sample of\nobserved values of some random variable is compatible with the hypothesis that it is drawn\nfrom a population of values which follows a certain probability distribution. Such procedure\nconsists of placing the values into mutually exclusive categories or class intervals and noting the\nfrequency of occurrence of values in each category.\n\nIt considers:\n\nH 0: The data were drawn/do not deviate from a specified distribution\nvs.\n\nH 1: The data were not drawn/deviate from a specified distribution\n\nSimilarly to Pearson\u2019s ?2 independence test, the goodness of fit ?2 test, is given by:\n\n?2 =\nn?\ni=1\n\n(Oi - Ei)2\nEi\n\n? ?2(k?1?r) , (2.13)\n\nwhere n corresponds to the total number of observations (or the number of cells in the considered\ntable); Oi is the observed frequency for the ith observation; and Ei is the expected frequency\nfor the ith observation.\n\nReject H0 if ?2obs > ?\n2\n1??;(k?1?r), where k is the number of classes of the variable considered,\n\nand r is the number of estimated parameters. ?21??;(k?1?r) represents the quantile with\nprobability 1 ?? from a ?2 distribution with (k ? 1 ?r) degrees of freedom.\n\n2.2.3 Interaction\n\nIt is also important to evaluate the interaction between variables. It occurs when the effect\nof one explanatory variable on the response variable may not be the same at all levels of another\nexplanatory variable. That is, the effect of a explanatory variable on another one is not constant\nas the effect is not equal for different values the variable takes.\n\nIn order to test for interaction, it is common to build a model which considers the\ncorresponding variables and their interaction, and then verifying if the interaction is statistically\nrelevant.\n\n18\n\n\n\n2.2.4 Shapiro-Wilk Test\n\nShapiro and Wilk (1965) describe the Shapiro-Wilk test as a method to determine whether\na sample deviates from a Gaussian distribution. Several statistical tests have a normality\nassumption, and the Shapiro-Wilk test can be used under that context to evaluate if the\nassumption is reasonable. Considering a random sample X1, X2,..., Xn of size n, with some\nunknown distribution function, F(.), the following hypothesis are tested:\n\nH 0: F(.) is a Gaussian distribution function with unspecified mean and variance\nvs.\n\nH 1: F(.) is not a Gaussian distribution function\n\nThe test statistic, W , is calculated as follows:\n\nW =\n\n(\n[n/2]?\ni=1\n?ai(X(n+1?i) ?X(i))\n\n)2\nn?\ni=1\n\n(Xi ? X?)2\n, (2.14)\n\nwhere [x] is the largest integer ? x; X(i) is the ith order statistic (where X(1) is the smallest value\nand X(n) is the largest); X? corresponds to the sample mean; and ai are constants generated\nfrom the means, variances and covariances of independent and identically distributed random\nvariables of size n sample from the standard normal distribution, and are tabulated in Sarhan\nand Greenberg (1956). Also, in the numerator, the minus sign in front of ai makes no difference\nbecause of the squaring, but is given because ai for 2i ? n are negative (Shapiro &amp; Wilk, 1965).\n\nReject H0, at the level of significance ?, if W<W?, where W? is the respective critical value.\nIf W is close to 1, the sample behaves like a Normal drawn from a Gaussian distribution.\n\n2.2.5 Multicollinearity\n\nMulticollinearity is a common problem in regression models, happening when two or more\nindependent variables are correlated. Although multicollinearity occurs in most data sets, it\nbecomes an issue when there is a high correlation between the variables, and should therefore be\ninvestigated. A high level of correlation means that one variable is linearly related to the others\nwith a considerable accuracy, which may lead to imprecise estimates of the model parameters.\n\nOne method to examine whether the independent variables may be correlated is by the\nVariance Inflation Factor (VIF) calculation. A VIF for n explanatory variable is obtained using\nthe R-squared value of the regression (a value which indicates how close the data are to the\nfitted values) of that variable against all other explanatory variables.\n\nConsidering k explanatory variables X, the VIF calculation starts by running an OLS which\nconsiders each explanatory variable as a function of all the other predictors. Then, the VIF\nfactor is calculated for each explanatory variable Xi, with i = 1, ...,k:\n\nV IFi =\n1\n\n1 ?R2i\n, (2.15)\n\nwhere R2i represents the regression R-squared value for the corresponding explanatory variable\nXi against all the other predictor variables.\n\n19\n\n\n\nPractical experience points out that if any of the VIF values is higher than 10, then\nmulticollinearity can lead to serious problems (Kutner et al, 2004). VIFs can help to identify\nwhich regressors are involved in the multicollinearity. Their removal from the analysis should\nbe considered.\n\n2.3 Modelling Approach\n\nChoosing the correct modelling approach for a dataset is a challenge. In this case, the data\nconsists of group size counts, and because counts are always non-negative integers, the Poisson\ndistribution is usually the default option. However, in the presence of overdispersion, i.e., when\nthe observed variance is (considerably) larger than the mean, the Negative Binomial distribution\nmay represent a reasonable alternative (Zuur et al., 2009).\n\n2.3.1 Linear Models\n\nLinear Models (LM) attempt to describe a continuous or categorical dependent variable as\na function of one (simple linear model) or more (multiple linear model) continuous or discrete\nindependent variables.\n\nAccording to Rencher and Schaalje (2008), a linear model has the following form, which hold\nthe systematic and random components:\n\nY = ?0 + ?1x1 + ?2x2 + ... + ?kxk? ?? ?\nsystematic\n\n+ ?????\nrandom\n\n, (2.16)\n\nwhere Y is the response variable; the regressor variables (also known as predictors) are\nx1,x2, ...,xk; ?0 is a constant which represents the intercept; ?j, j = 1, 2, . . . ,k, is the regression\ncoefficient and it corresponds to the rate of change in y for one unit change in the respective jth\n\nregressor, assuming the remaining k?1 regressors are hold fixed; and ? is the error term, which\nincludes everything the model does not take into account by considering the deviations that the\nobserved values y have from the fitted model.\n\nIn practice, the betas are not known, and hence must be estimated based on the data. The\nsame happens for the error term, which is estimated via the residual term, denoted by e, as\nexplained further.\n\nLM consist of three components:\n\n1. Systematic component - characterized by the k covariates (and the intercept ?0). The\nlinear predictor, ?, is given by:\n\n? = ?0 + ?1x1 + ?2x2 + ... + ?kxk ; (2.17)\n\n2. Random component - corresponds to the error term which is assumed to follow a normal\ndistribution, with mean zero and a constant variance ?2:\n\n? _ N(0,?2) .\n\n20\n\n\n\nAs a consequence, the response variable Y (conditional on the regressor variables) follows\na normal distribution, with mean \u00b5 and constant variance ?2:\n\nY |x1,x2, . . . ,xk _ N(\u00b5,?2) ,\n\nwith the mean value, \u00b5 ? E(Y |x1,x2, ...,xk), depending on the values of the k predictors\nxj, j = 1, 2, . . . ,k, as one would expect:\n\n\u00b5 = ?0 + ?1x1 + ?2x2 + ... + ?kxk ; (2.18)\n\n3. Link function - characterizes the relationship between the random and the systematic\ncomponents, and is specified via a link function, g(\u00b5), with:\n\ng(\u00b5) = ? ,\n\nwhose objective is to provide a connection between \u00b5 and ?. Comparing both equations\n2.17 and 2.18, it is noticeable that ? = \u00b5. Thus, in LM the link function is the \u201cidentity\nfunction\u201d because the mean is modelled directly, as seen bellow:\n\n? = E(Y |x1,x2, . . . ,xk) = \u00b5 .\n\nWhile this might seem a rather convoluted explanation, it is general and sets the scene for\nother models, where other functions besides the identity function can be considered.\n\nThe estimation of the parameters of the model, ?0,?1, ...,?k, can be done by minimizing the\nsum of the square of the distances, measured vertically, between the observed values and the\nmodel. That is, by the ordinary least squares (OLS) method.\n\nLet each of the k predictor variables, x1, x2, . . . , xk, have n observations. Assuming\ni = 1, 2, . . . ,n, xji represents the ith observation of the jth predictor variable. The observations,\ny1, y2, . . . , yn, constitute realizations of the random sample of size n, Y1, Y2, . . . , Yn, from a\npopulation Y . Thus, the model 2.16 takes the form of:\n\ni = ?0 + ?1x1i + . . . + ?kxki + ?i , i = 1, 2, . . . ,n. (2.19)\n\nEmploying matrix notation simplifies all the math underlying the OLS method; so the model\n2.19 can be written in matrix notation such as:\n\nYYY = X??? + ???, (2.20)\n\nwith\n\nYYY =\n\n?\n??????\nY1\n\nY2\n...\nYn\n\n?\n?????? , X =\n\n?\n??????\n\n1 x11 x21 . . . xk1\n1 x12 x22 . . . xk2\n...\n\n...\n...\n\n...\n1 x1n x2n . . . xkn\n\n?\n?????? , ??? =\n\n?\n??????\n?0\n\n?1\n...\n?k\n\n?\n?????? , and ??? =\n\n?\n??????\n?1\n\n?2\n...\n?n\n\n?\n?????? ,\n\n21\n\n\n\nwhere YYY is a n\u00d71 vector of random variables; XXX is a n\u00d7(k+1) matrix containing the information\nregarding the observations of the k predictor variables; ??? is the (k + 1) \u00d7 1 vector of regression\ncoefficients; and ??? is a n-dimensional vector of the errors.\n\nThe least square estimates for the coefficients are given by:\n\n???? = (XXX?XXX)?1XXX?yyy, (2.21)\n\nwhere ? represents the transpose of the corresponding matrix. ???? will result in a column matrix\nwith k + 1 entries, where the first entry is the estimate of ?0 and the remaining k are the other\nslope parameters. Detailed information on this topic can be found, for instance, in Montgomery\nand Peck (1992).\n\nAfter obtaining the estimates of the model parameters, the fitted values from the linear\nregression are computed as follows:\n\ny?yy = XXX???? , (2.22)\n\nwhere y??y?y is the n-dimensional vector of the fitted values.\nThe error estimate (that is, the residual) for each observation, ei, is then calculated as follows:\n\nei = yi ? y?i , i = 1, 2, ...,n, (2.23)\n\nor, in matrix form:\n\neee = yyy ? y??y?y , (2.24)\n\nwhere eee is a n-dimensional vector of the residuals.\nAlso, it is important to refer the projection n\u00d7n matrix, H, or hat matrix, as it is crucial\n\nwhen measuring each observation\u2019s influence on the regression model (as seen further in section\n2.5.2). This matrix also describes the influence each response value has on each fitted value and\nis defined as:\n\nH = X(X?X)?1X? . (2.25)\n\nThus:\n\ny?yy = XXX???? = HHHyyy , eee = (III ?HHH)yyy , (2.26)\n\nwhere III is the identity matrix of order n.\n\n22\n\n\n\nThe hat matrix and its properties play a central role in regression analysis. It is symmetric,\nidempotent, and rank (HHH) = k + 1, with k being the number of covariates.\n\nThus far, the assumption of the errors\u2019 normality has not been used. This assumption is\ncrucial when constructing statistics for testing hypothesis on the model parameters. Other\nassumptions for inferential purposes have to be made:\n\n1. Homoscedasticity: var[?i] = ?2, ?i=1,...,n;\n\n2. Independence: cov[?i,?j] = 0, i 6= j.\n\nUnder these assumptions, it can be proved that the least squares estimator of ??? coincided\nwith the maximum likelihood estimator. Detailed information on hypothesis testing on ??? can\nbe found, for instance, in Montgomery and Peck (1992).\n\nAs a final remark, while the model may help predict values for the dependent variable Y ,\none should not use a regression model to make a prediction for a point that is outside the range\nof the collected data covariates (i.e. the independent variables). That is called extrapolation\nand one of statistics\u2019 \u201cmortal sins\u201d: there is no way to know whether the predicted relationship\nwill hold outside the range of predictor values studied.\n\n2.3.2 Generalized Linear Models\n\nAccording to McCullagh and Nelder (1989), the term generalized linear models (GLM) refers\nto a large class of models for a continuous/discrete response variable given continuous and/or\ncategorical predictors. Similar to linear models, the data is still expected to be independently\ndistributed, though they differ on several aspects:\n\n\u2022 Errors do not need to be normally distributed, though they still need to be independent;\n\n\u2022 GLM allow skewed distributions. Although these models accept a non-normally distributed\ndependent variable Y , they assume it follows a distribution from the exponential family;\n\n\u2022 GLM do not assume a linear relationship between the dependent and independent\nvariables, though they do assume linear relationship between the transformed response\nin terms of the link function and the explanatory variables;\n\n\u2022 The homogeneity of variances, i.e., the residuals follow a common distribution with mean\n0 and constant variance ?2;\n\n\u2022 GLM typically use maximum likelihood estimation (MLE) instead of OLS to estimate the\nparameters; hence relying on large samples properties to obtain precise estimators of the\nmodel parameters.\n\nGLM also consist of the same three components of LM:\n\n1. Systematic component - this component is characterized the same way as linear models,\nwhere the k covariates combine to create the linear predictor, ?:\n\n23\n\n\n\n? = xxx??? ; (2.27)\n\nwhere xxx is the 1 \u00d7 (k + 1) vector of the covariates.\n\n2. Random component - similar to linear models, it specifies the distribution of the dependent\nvariable Y . GLM assume a distribution from the exponential family, i.e., Y should have a\nprobability density function (PDF) or a probability mass function (PMF) of the following\nform:\n\nf(y|?,?) = exp\n(\ny? ? b(?)\na(?)\n\n+ c(y,?)\n)\n, (2.28)\n\nwhere ? and ? are parameters, and a(\u00b7), b(\u00b7), c(\u00b7, \u00b7) are real known functions. Any density\nfollowing the form above is an exponential family density, where ? is called the natural\nparameter, and ? is the dispersion parameter. It is worth to mention that the mean \u00b5 of\nthe distribution is related to the natural parameter ? by \u00b5 = E(Y ) = b?(?).\n\nFor the normal distribution (the LM case), ? = \u00b5 and ? = ?.\n\nWhen considering the Poisson PMF with mean \u00b5:\n\nf(y|\u00b5) = exp\n{\ny log(\u00b5) ?\u00b5? log(y!)\n\n}\n. (2.29)\n\nwhich means that, according to equation 2.28: a(?) = 1, ? = log(\u00b5), b(?) = \u00b5 = e?, ? = 1,\nand c(y,?) = ?log(y!).\n\n3. Link function - Contrarily to the LM, the mean is not modelled directly, but through\na differentiable transformation resorting to the link function g(\u00b5), which is now chosen\naccording to the distribution under consideration.\n\nConsidering the Poisson distribution, and according to the equation 2.29, the log link\nfunction (canonical link) is used:\n\n? = log(\u00b5) ? ? ,\n\nwhich implies the expected value, \u00b5, is represented as:\n\nlog(\u00b5) = ?0 + ?1x1 + . . . + ?kxk , (2.30)\n\nand since log(\u00b5) of the response variable is a linear function of the explanatory variables,\n\u00b5 takes the form:\n\n\u00b5 = e?0+?1x1+ ... +?kxk = e?0 \u00d7e?1x1 \u00d7 . . .\u00d7e?kxk . (2.31)\n\n24\n\n\n\nOne advantage of suitable chosen link functions is that we can force the predictions to be\nwithin a given plausible range, i.e. to model counts as positive numbers or proportions in the\n(0,1) interval (Hardin &amp; Hilbe, 2007).\n\nAs referred before, GLM typically uses the MLE to estimate the unknown parameters. An\noverview of the MLE method in the GLM framework will be given.\n\nLet each of the k predictor variables, x1, x2, . . . , xk, have n observations; with the 1\u00d7(k+ 1)\nvector xixixi = [1 x1i x2i . . . xki], representing the values of the k + 1 regressor variables for the\nith observation, i = 1, 2, . . . ,n. The observations, y1, y2, . . . , yn, constitute realizations of the\nrandom sample of size n, Y1, Y2, . . . , Yn, from a population Y .\n\nMLE is grounded on the likelihood function, L(?,?; y1,y2, . . . ,yn), of the sampled data. It\ngives the likelihood that the random variables assume a particular value y1,y2, . . . ,yn. One\nwants to know from which density (what values of the unknown parameters) this particular set\nof values most likely have come from. The likelihood function is, therefore, a function of the\nunknown model parameters, whose values that maximize the likelihood of the observed sample\nare the maximum likelihood estimators.\n\nAccording to the probability distribution of the dependent variable Y (equation 2.28), the\nlikelihood function of the n random variables Y1, Y2, . . . , Yn, as a function of ???, is given by:\n\nL(???) =\nn?\ni=1\n\nf(yi; ?i,?) =\nn?\ni=1\n\nexp\n\n(\nyi?i ? b(?i)\n\na(?)\n+ c(yi,?)\n\n)\n. (2.32)\n\nThe common mathematical technique to solve the equation 2.32 involves applying a\nlogarithmic transformation to L(???), which becomes the log-likelihood, L(???):\n\nL(???) =\nn?\ni=1\n\n(\nyi?i ? b(?i)\n\na(?)\n+ c(yi,?)\n\n)\n=\n\nn?\ni=1\n\n`i(???), (2.33)\n\nwhere:\n\n`i(???) =\nyi?i ? b(?i)\n\na(?)\n+ c(yi,?), (2.34)\n\nis the contribution of the observed value yi to the likelihood, i = 1, 2, . . . ,n.\nUnder certain regularity conditions, the maximum likelihood estimators for ??? are given by\n\nthe following system of equations:\n\n?L(???)\n??j\n\n=\nn?\ni=1\n\n?`i(???)\n??j\n\n= 0 , j = 0, 1, . . . ,k. (2.35)\n\nThese k + 1 equations are non-linear in the k + 1 unknown ??? parameters and, thus, there\nis no analytical solution for obtaining the maximum likelihood estimators ????. Therefore, the\nparameter estimates are obtained by numerical maximization of the log-likelihood.\n\nThere are a number of optimization routines that maximize the likelihood as a function of\nthe parameters, as e.g. Newton-Raphson (N-R). Detailed information on this topic can be found\nin Hardin and Hilbe (2007).\n\n25\n\n\n\nIn the case of GLM bespoke code to maximize the underlying likelihood exist based on the\nN-R method, via the glm function in R. The R function optim, implementing the N-R method, is\nresponsible for the implementation of the glm function, and can be accessed directly for bespoke\nproblems, but several other options exist (e.g. nlm in the nlme package).\n\nAfter maximizing equation 2.32 and obtaining the estimates for the parameters, it is then\npossible to proceed with hypotheses testing on the parameters, model evaluation, such as residual\nanalysis, goodness-of-fit, etc. More detailed information can be found of Hardin and Hilbe\n(2007).\n\nGLM were the primary model framework used for this study. Nonetheless, we also\ninvestigated the use of Generalized Additive Models for comparison, as described in the following\nsection.\n\n2.3.3 Generalized Additive Models\n\nGeneralized additive models (GAM) are an extension of the GLM. GAM can be seen as\n\u201cnon-parametric GLM\u201d because the linear (or some other parametric) form which describes the\nrelation between each covariates and the dependent variable can be replaced by a functional\nform defined by smoothing techniques.\n\nAccording to equation 2.27, the linear predictor ? specifies that the covariates act in a linear\nfashion, that is, ? = ?0 + ?1x1 + ?2x2 + ... + ?kxk.\n\nHastie and Tibshirani (1986) introduced a more general form of the linear predictor:\n\n? = s0 +\nk?\nj=1\n\nsj(xj), (2.36)\n\nwhere sj(\u00b7), with j = 1, 2, ...,k, are the unspecified (non-parametric) smooth functions. As seen\nin the GLM case, the dependent variable Y belongs to the exponential family, which means the\npredictor ? is connected to the dependent variable via a link function.\n\nInstead of estimating single parameters, GAM find a general unspecified function that relates\nthe predicted y values to the predictor values. These unspecified functions are estimated\nusing a scatterplot smoother, in an iterative procedure called local scoring algorithm. Detailed\ninformation about this procedure may be found in Hastie &amp; Tibshirani (1990).\n\nUsing a GAM may be a good way to evaluate whether GLM is accurate enough to describe\nthe relationship between a set of covariates and a response variable. It was with that in mind\nthat GAM were considered in this study.\n\n2.3.4 Zero-Truncated Models\n\nAccording to Zuur et al. (2009), if zero counts are not a possibility for the data being\nmodelled, then the underlying PDF may need to be adapted to adjust for the excluded zero\ncounts. Zero-Truncated Models (ZTM) are built for that exact purpose, to model data for\nwhich the zero value cannot occur.\n\nZTM should not to be confounded with Zero-Inflated Models (ZIM), which are more\ncommonly applied in ecological research. According to Zuur &amp; Ieno (2016), ZIM are used\nwhen the response variable contains more zeros than expected, a common issue in ecology. ZIM\n\n26\n\n\n\ntheory suggests that the excess zeros are generated by a separate process from the count values,\nallowing the excess zeros to be modelled independently; while ZTM implies the absence of the\nzero counts and changes the probability of the remaining frequencies.\n\nThe objective of zero-truncated models is to model the data excluding the possibility of the\nresponse variable to be zero. An example allows a better understanding of what is involved: let\nY be the number of Md individuals counted in a group. Assuming that Y could be assumed to\nhave a Poisson distribution with mean \u00b5, its probability mass function would be:\n\nP(Y = y) =\n\u00b5y \u00d7 e?\u00b5\n\ny!\n, y ? N. (2.37)\n\nP(Y = 0), the probability of observing a zero, is given by:\n\nP(Y = 0) =\n\u00b50 \u00d7 e?\u00b5\n\n0!\n= e?\u00b5 . (2.38)\n\nTherefore:\n\nP(Y = 0) = e?\u00b5\n\n1 ?P(Y = 0) = 1 ?e?\u00b5\n\nConsidering a concrete example, suppose \u00b5 = 3, one gets:\n\nP(Y = 0) = e?3 ? 0.05 and 1 ?P(Y = 0) ? 0.95\n\nThis means the probability of observing a positive count would be approximately 0.95, while\nthere is approximately a 0.05 probability of observing a zero. In other words, for every 100\ngroups 5 would expected to have size zero. As one might suspect, there is no such thing as a\ngroup of size zero. The problem aggravates for smaller mean values, where the density condenses\nmore around zero, which would imply a higher amount of zero counts. The solution is attained\nby modifying the distribution and excluding the possibility of a zero observation.\n\nThere is, thus, the need to change the probability mass function in such a way that the\nprobability of y = 0 is equal to zero. However, in a trivial context, that would mean that the\nremaining probabilities would sum up to 0.95. By resorting to ZTM, to obtain a valid PDF, the\nprobability of each outcome larger than 0 is divided by 1 ?P(Y = 0).\n\nTherefore, there is a need to define the conditional probability of Y as being a Poisson, but\nstrictly positive:\n\nP(Y = y|Y > 0) =\nP(Y = y,Y > 0)\n\nP(Y > 0)\n=\n\nP(Y = y)\n1 ? (P(Y = 0))\n\n=\n\u00b5y\u00d7e?\u00b5\n\ny!\n1 ?e?\u00b5\n\n=\n\u00b5y \u00d7 e?\u00b5\n\ny!(1 ?e?\u00b5)\n, y ? N.\n\n(2.39)\n\nConsidering \u00b5 = 3, the new probability function is then set as:\n\nP(Y = y|Y > 0) =\n1\n\n0.95\n\n(\ne?2\n\n3y\ny!\n\n)\n, y ? N . (2.40)\n\n27\n\n\n\nFigure 2.1 below illustrates the differences between the probability mass functions (PMF)\nfrom a Poisson and a zero-truncated Poisson, both with a mean value of 3.\n\nFigure 2.1: A: Poisson distribution, \u00b5 = 3. B: Zero-truncated Poisson, \u00b5 = 3, with adjusted probabilities\naccording to Equation 2.40. The vertical lines are slightly higher due to each probability being divided by\n1 ? P(Y = 0). The sum of all probabilities in both A and B is therefore equal to 1, representing a valid\n\ndistribution.\n\nSumming up, the PMF of the truncated Poisson regression model with k covariates is given\nby:\n\nP(Y = yi|Y > 0) =\n\u00b5\nyi\ni e\n?\u00b5i\n\nyi!(1 ?e?\u00b5i )\n, yi ? N, i = 1, 2, . . . ,n, (2.41)\n\nwhere yi is the ith observed value of the random variable Y ; xji represents the ith observation\nfrom the jth covariate; and:\n\nlog(\u00b5i) = ?0 + ?1x1i + ?2x2i + . . . + ?kxki.\n\nNote that, while zero truncated models are by far the most common case of truncated models,\none could easily extend the framework to deal with any kind of truncated model (e.g., counts\nmust be larger than K1, or lower than K2, etc). For the current study, the zero-truncated\nfeature was applied resorting to the VGAM package for R (Yee, 2015), which incorporates\nzero-truncation in models for both GLM and GAM, with the commands vglm and vgam,\nrespectively.\n\nWhen investigating the best model for further inference, one may consider several model\nselection criteria. On the next section it will be described how such selection might be\nimplemented, as well as how the best model is chosen.\n\n2.3.5 Modelling with GLM &amp; GAM\n\nStandard GLM and GAM account for zero truncation. However, to compare results, and for\nthe sake of academic curiosity, an ad hoc solution which allows the use of non-truncated GLM\nand GAM was applied: to consider modelling Y = X -1, where X is the actual group size. This\nimplies that a new variable (cs0 ) with the transformed response needs to be created, as seen in\nthe table 2.7 below.\n\n28\n\n\n\nTable 2.7: The data available for each group, after adding the cs0 column. For illustration purposes only the\ndata for the first 5 groups are shown.\n\ngID cs conf maxi mi Ki di (in \u00b5s) Ni ri wisk direc cs0\n1 2 2 740 335.5 6 24.20 2013 83.2 1 0 1\n2 2 1 575 239.7 6 13.67 1438 105.2 1 0 1\n3 3 1 5263 924.0 11 39.40 10164 257.9 1 0 2\n4 2 1 3214 491.0 10 41.95 4916 117.2 0 1 1\n5 5 1 3852 1140.1 9 31.97 10261 320.9 0 1 4\n\nThis means that, while using non-truncated GLM and GAM, the response variable is the\ncs0 column instead of cs.\n\n2.4 Modelling Strategy: Variable Selection\n\nOn any modelling exercise, choosing a suitable model is fundamental. It is desirable for a\nmodel to follow the principle of parsimony, i.e., to incorporate the minimum possible number\nof parameters which reasonably explain the response variable. While it is actually debatable\nwhich method should be employed to build the most appropriate model, the literature suggests\ndifferent approaches. Hence, there is still no consensus on the optimal methodology to address\nthis issue. The researcher must always use knowledge of the underlying problem and common\nsense when evaluating candidate regressors.\n\nBelow are presented some of the most commonly used model selection criteria.\n\n2.4.1 Stepwise Regression\n\nIn most practical problems, the researcher has a set a candidate regressors which should\ninclude all the factors that influence the dependent variable. However, the actual subset of\nregressors that must be used in the model needs to be determined. Fitting models with different\ncombinations of the regressor variables is usually considered to find the optimal subset(s) of\nvariables. One of the most popular techniques to attain this goal is the stepwise regression\nmethods (see, for instance, Draper &amp; Smith, 1981). Such method examines regression variables\nsubsets by either adding or deleting regressors one at a time. These procedures can be\nbroadly classified into three categories: forward selection; backwards elimination; and stepwise\nregression, which is a combination of the forward and backward methods. A detailed description\nof the stepwise regression methods is given in Montgomery and Peck (1992).\n\n2.4.2 Criteria for Evaluating Subset Regression Models\n\nAfter selecting several subsets of regressor variables, which constitute the different candidate\nmodels, it is crucial to decide which subset is the best one. Two criteria for evaluating and\ncomparing subset regression models will be provided.\n\n29\n\n\n\n2.4.2.1 Likelihood Ratio Test\n\nThe likelihood ratio test, LRT, is often used to test the parsimony of two models, as long\nas one of them is a special case of the other (i.e., nested within the other). It is commonly\nemployed when adding or removing variables one by one from a model.\n\nLRT evaluates if a more complex model is required. A broad explanation of LRT is given next.\nConsider two models: the first contains q regressor coefficients (reduced or restricted model),\nand the second contains an additional k+1?q regression coefficients (full or unrestricted model).\nLet the (k + 1)-dimensional vector of the regression parameters ??? be partitioned as follows:\n\n??? =\n[\n\n???q\n\n???k+1?q\n\n]\n, (2.42)\n\nwhere ???q is a q-dimensional vector, and ???k+1?q is a (k + 1 ? q)-dimensional vector. The LRT\ntests the contribution of the k+1?q subset of the regression variables to the model (i.e., ???q 6= 000).\nThus:\n\nH 0: ???k+1?q = 000 vs H 1: ???k+1?q 6= 000\n\nLet ??????q and ?????? represent the maximum likelihood estimators for the two models; and Lq,\nL denote the values of the likelihood functions for the two models evaluated at ??????q and ??????,\nrespectively.\n\nUnder the null hypothesis, the LRT statistic, denoted by D, is given by:\n\nD = ?2ln\n(\nLq\nL\n\n)\n? ?2(k+1?q) . (2.43)\n\nReject H0 when D > ?2(1??)(k+1?q), which represents the quantile with probability (1 ??)\nfrom a ?2 distribution with (k + 1 ?q) degrees of freedom, where ? is the significance level.\n\nWhen the null hypothesis is not rejected, that means the extra regression variables do not\nincrease the fit enough to justify their inclusion in the model. Adhering to the parsimony\nprinciple, the model considering less variables, the reduced model, is a better representation of\nthe data.\n\n2.4.2.2 Akaike\u2019s Information Criterion\n\nThe Akaike\u2019s information criterion, AIC is a model selection criterion and attempts to choose\nfrom a group of models the one which appears to be the most accurate model to describe the\nresponse variable. The AIC is calculated as:\n\nAIC = ?2log L(??????) + 2k ; (2.44)\n\nwhere ??? is the vector of the regression parameters; L(??????) represents the likelihood function\nevaluated at the maximum likelihood estimate of ???; and k is the number of regression variables.\n\nThe more parsimonious candidate model is the one with the lowest AIC. Since this function\nis multiplied by ?2, the model with the lowest AIC is the one with the highest likelihood\n\n30\n\n\n\nfunction value. An adjustment is made to the AIC equation by adding the number of estimated\nparameters (2k) to this measure. The model is penalized by the number of parameters added:\nmore parameters add to a higher AIC value (Fabozzi et al., 2014).\n\nHowever, there may be times the AIC values from different models are extremely similar,\nonly differing by a single unit, or even less. How should one proceed when confronted with such\nissue? According to Burnham and Anderson (2002), models within 1 or 2 units of the best model\n(the one with the lowest AIC value) have substantial support from the data. However, there is\ncurrently some controversy about these specific values (Burnham &amp; Anderson, 2002; Fabozzi et\nal., 2014).\n\nFor this current study, these perspectives were taken into consideration to decide between\nmodels, also including an analysis to each model\u2019s quality, as described on the next section.\n\n2.5 Residual Analysis and Influential Observations\n\nWhen conducting statistical analysis it is important to evaluate how well the model fits\nthe data and if the data meet the assumptions of the model; to detect outliers; and to detect\ninfluential observations (i.e., observations with a high influence on the fitted model). In section\n2.5.1, a summary on residual analysis is presented. Section 2.5.2 provides a few measures on\ninfluential observations.\n\n2.5.1 Residuals\n\nIt is an usual practice to analyse the residuals from the candidate models, as this provides\na measure of goodness-of-fit, how adequate the model actually is for the data at hand. In the\nLM context, each residual, ei, corresponds to the discrepancy between the observed value, yi,\nand the fitted value, y?i, with i = 1, ...,n, as seen before in equation 2.23. Residuals should be\n\u201cwell-behaved\u201d, by showing no distinguishable pattern and a constant variance.\n\nAlthough, when considering a GLM framework the residuals definition is not unique and,\nthus, their interpretation is less clear and graphical patterns may vary quite differently for\ndifferent models. Several residuals definitions have been proposed for the GLM models, and in\nparticular for the Poisson regression. In this section some of those definitions will be presented.\nHowever, it is important to emphasise there appears to be no one single residual definition that\nbe used in all contexts. For Poisson regression models, there is no one residual that has zero\nmean, constant variance, and symmetric distribution. This leads to several different residuals\naccording to which of these properties is felt to be the most desirable (Cameron &amp; Trivedi,\n1998).\n\nFor academic purposes, a residual analysis still took place, along with other model quality\nmeasures as described next.\n\nRaw residuals\nFrom the LM context, the raw residuals are the \u201cnatural residuals\u201d:\n\nei = yi ? \u00b5?i , i = 1, 2, . . . ,n, (2.45)\n\n31\n\n\n\nwhere the fitted mean \u00b5?i is the conditional mean \u00b5i = E(Yi|xxxi) evaluated at ??? = ????.\nFor count regression models, Cameron and Trivedi (1998) showed that the raw residuals are\n\nheteroskedastic and asymmetric.\n\nPearson Residuals\nAccording to Cameron and Trivedi (1998), the obvious correction for heteroskedasticity is\n\nresorting to the Pearson Residuals:\n\npi =\nyi ? \u00b5?i?\n\n??i\n, i = 1, 2, . . . ,n, (2.46)\n\nwhere ??i is the estimated variance ?i of yi.\nFor large samples, these residuals have zero mean, and are homoskedastic (with unit\n\nvariance), but are asymmetrically distributed.\nFor the Poisson regression, one gets:\n\npi =\nyi ? \u00b5?i?\n\n\u00b5?i\n, i = 1, 2, . . . ,n. (2.47)\n\nOnce the residuals are obtained, one should use them to extract fruitful information. For\ninstance, residuals should be plotted against the predicted values of the dependent variable; and\nagainst the regressors under study, to see whether regressors should enter through a different\nfunctional form than that specified (Cameron and Trivedi, 1998).\n\n2.5.2 Influential Observations\n\nWhen looking at the residuals, one often finds observations that may influence the model\nin several ways. For instance, if an observation has a response value which holds a large\ndifference from the predicted value, then that observation may be described as an outlier, i.e.,\nthe observation has an extreme or a notably different y value than the rest. Regression outliers\nusually have large residuals but do not necessarily affect the regression slope coefficient.\n\nOn the other hand, if an observation stands out from one or more predictor values, then it\nis said to have a high leverage. In other words, leverage measures how unusual that point is\nwhen comparing with all the other observations. High leverage does not necessarily mean the\nobservation will influence the regression coefficients, i.e., it may have an extreme value when\ncompared to the other points, but following at the same time the prediction tendency (Chatterjee\nand Hadi, 1986).\n\nIn LM, the matrix HHH is one of the most common measures of leverage. According to equation\n2.26, \u00b5??\u00b5?\u00b5 = y??y?y = HyHyHy. Consider hii the ith diagonal element of the projection matrix H, i =\n1, 2, . . . ,n. If hii is large, then the matrix XXX, which determines HHH, is such that yi has a large\ninfluence on its own prediction (Cameron and Trivedi, 1998).\n\nIn the GLM case, Hardin and Hilbe (2007) proved that the HHH matrix is given by:\n\nHHH = WWW 1/2XXX(XXX?WXWXWX)?1XXX?WWW 1/2 , (2.48)\n\n32\n\n\n\nwhere WWW = diag\n{ 1\nV (\u00b5)a(?)\n\n(\n?\u00b5\n\n??\n\n)2}\n, with V (\u00b5) =\n\n?\u00b5\n\n??\n. As in LM, the n \u00d7 n matrix HHH is\n\nidempotent with trace equal to its rank k + 1, the number of regressor variables. Therefore, the\naverage value of hii is (k+1)n , and the values of hii in excess of\n\n2(k+1)\nn\n\nare viewed as having high\nleverage (Cameron &amp; Trivedi, 1998; Hoaglin &amp; Welsch, 1978). This will be the criterion used\nfor the present work.\n\nStudentized Pearson Residuals\nAccording to Hardin and Hilbe (2007), the studentized Pearson residuals, p?i , are then given\n\nby:\np?i =\n\npi?\n1 ?hii\n\n, i = 1, 2, . . . ,n. (2.49)\n\nHat values are the most common measure of leverage. They are calculated based on the\nfitted values from the regression and are defined as:\n\nhii = [H]ii ,\n\nwhere hii is the ith observation leverage score, which is found in the ith diagonal element of the\nprojection matrix H. Hat values describe the influence each response value has on the fitted\nvalue for that same observation.\n\nAlthough literature considers different cut-off criteria, Hoaglin &amp; Welsch (1978) suggest hii\nis a high leverage point when hii > 2pn , where p is the summation of the hat values, and n is\nthe sample size. This will be the criterion used for the present work. In simple regression, hat\nvalues measure the distance of each points from the expected value. In multiple regression, the\ndistance from the centroid point.\n\nCook\u2019s Distance\nAnother way of measuring an observation\u2019s influence is by calculating its Cook\u2019s distance, Di,\n\nwhich measures how much the regression estimated coefficients change when the ith observation\nis removed from the estimation procedure. In the GLM context, Hardin and Hilbe (2007)\napproximate Cook\u2019s distance with:\n\nDi =\n(\n?????(i) ? ????\n\n)?\nI\n(\n?????(i) ? ????\n\n)\n, (2.50)\n\nwhere I is the Fisher information matrix; ?????(i) is the one-step approximation to the\njackknife-estimated coefficient vector.\n\nThese measures can be used to detect observations with undue influence. An observation i\nis considered to have high influence when Di >\n\n4\nn?k\n\n(Hair et al, 1998; Hardin &amp; Hilbe, 2007).\nObservations with measures greater than 4/n should be investigated (Hardin &amp; Hilbe, 2007).\n\nEven if no observations exceed these thresholds, additional attention should be dictated if a\nsmall set of observations has substantially higher values than the remaining observations (Hair\net al, 1998).\n\nThis study contemplated these issues, so to mitigate any extra weight from the influential\npoints, different models were built taking into account a new dataset were these observations\nwere removed. The different models were then compared, and if they held no major difference\nthen no observations were removed when modelling.\n\n33\n\n\n\n2.6 Group Size and Density Estimation\n\nBefore proceeding with the estimation, an exploratory analysis was performed on the second\ndataset. Building on the best model chosen using the tools and methods described above, the\ngroup size for each dive observation in the density estimation dataset was then predicted.\n\nAfter estimating the group sizes we can finally estimate Md density. Following Moretti et\nal. (2010), the estimator of animal density is given by:\n\nD? =\nn s?\nr? TA\n\n; (2.51)\n\nwhere:\n\n\u2022 n - total number of dives/groups;\n\n\u2022 s? - estimated average group size (common to all groups);\n\n\u2022 r? - estimated average number of dives per hour (a value of 0.36 measured by Moretti et\nal, 2010);\n\n\u2022 T - considered amount of time;\n\n\u2022 A - considered area (1291 km2 in the current study).\n\nIf the area (A) is removed from the equation, the estimator of abundance (N?) is obtained.\n\nN? =\nn s?\nr?T\n\n; (2.52)\n\nThe abundance corresponds to the total amount of animals detected for the time period\nconsidered, whereas the density is simply the abundance taking into account a certain area.\n\nWhile Moretti et al. (2010) use an average estimated value (s?) common to all groups, this\nwork focuses on the previously obtained model to estimate the number of individuals for each\ndetected group. Instead of resorting to the total number of dives and multiplying that value for\nan estimated average group size based on literature, this study suggests a more precise approach\nfor Md density estimation. Therefore, and estimator of density (D?) is now obtained using a\ndifferent equation:\n\nD? =\n\nn?\ni=1\n\ns?i\n\nr?TA\n; (2.53)\n\nwhere s?i corresponds to the estimated group size for group i, and n represents the number of\ngroups for the considered time period. For this study, the density was estimated for each day,\nconsidering the amount of Md individuals in 1000 km2. In fact, to make the analogy with\nequation 2.52 , we can represent the density per day (D?d) as a function of the mean group size\nper day:\n\n34\n\n\n\nD?d =\n\nnd?\ni=1\n\ns?i\n\nr? TA\n=\nnd \u02c6?si\nr? TA\n\n; (2.54)\n\nwhere nd represents the number of groups on day d; s?i is the estimated mean group size on day\nd; and \u02c6?si is the estimated group size mean.\n\nA new table was created pooling information for each day (table 2.8), including:\n\n\u2022 groups - the number of groups detected on that day;\n\n\u2022 mcs - a mean cluster (group) size value for the corresponding day;\n\n\u2022 stime - time (in hours) when the first group was detected for the corresponding day;\n\n\u2022 etime - time (in hours) when the last group ceased being detected for the corresponding\nday;\n\n\u2022 ttime - the time frame (in hours) per day the click detection occurred, i.e., the time period\nover which the measurement was made;\n\n\u2022 abundance - the abundance of individuals detected per hour on the corresponding day;\n\n\u2022 density - the density of individuals detected per hour on the corresponding day, per 1000\nkm2 of the total considered area.\n\n35\n\n\n\nTable 2.8: The first ten lines from data regarding each day, featuring the estimated abundance and density.\n\nday groups nhyd nclicks ici period crate mcs stime etime ttime abundance density\n117 10 70 80565 0.2315 1 214.0648 3.3889 20.6167 23.4000 2.7833 33.8218 26.1981\n118 58 339 383357 0.2300 1 165.2208 3.1689 1.0000 23.4833 22.4833 22.7083 17.5897\n119 28 136 128323 0.2310 1 106.4493 2.8435 0.9833 23.3167 22.3333 9.9028 7.6707\n120 58 325 322389 0.2313 1 148.3170 3.0232 0.9833 23.2167 22.2333 21.9073 16.9693\n121 67 379 352552 0.2301 1 147.9339 2.9175 0.8667 23.4000 22.5333 24.0969 18.6653\n122 57 322 292268 0.2303 1 144.8485 2.7951 1.01667 22.8500 21.8333 20.2697 15.7008\n123 74 413 376923 0.2300 1 129.2886 2.8160 1.1167 23.9500 22.8333 25.3509 19.6366\n124 92 492 496524 0.2318 1 120.0953 2.8769 0.2333 23.6833 23.4500 31.3529 24.2858\n125 82 502 476841 0.2307 1 132.0471 2.8462 1.0333 23.4333 22.4000 28.9419 22.4182\n126 42 197 207308 0.2307 1 117.4795 3.0406 1.3000 23.0667 21.7667 16.2972 12.6237\n\n36\n\n\n\n2.6.1 Bootstrap\n\nOne main goal of inferential statistics is to determine the value of a population parameter.\nAccording to Manly (2006), bootstrap is a form of random statistical sampling which evaluates\nthe precision of the sample estimates by estimating properties of those same estimators. When\ncomputing a statistic from a single dataset only that one statistic is known. There is no\ninformation about the variability of that statistic. That is why bootstrap is helpful, since it\ncreates a large number of possible datasets, and computes the statistic on each of these datasets;\nthus providing a distribution of the statistic. That is the strategy of bootstrap: to create data\nthat \u201dmight have been seen\u201d (Chernick &amp; LaBudde, 2011).\n\nThe basic idea behind this method starts with a sample with size n, which only allows one\nestimate of the parameters say, the mean, or the variance. Then, this same sample is randomly\nre-sampled with replacement to build a new sample, also with size n. Here is the trick: since the\nre-sample occurs randomly and with replacement, several elements will most likely be repeated\nin the new sample while some will be missed altogether and, as n increases, the probability that\nthe new sample will look exactly like the original one will tend to zero. This process is then\nrepeated a great number of times, and for each of these new samples the parameter in study\nwill be computed. The variance over these bootstrap pseudo values for the statistic of interest\n(say, the mean) will be an approximation of the variance of the estimator for that mean.\n\nConsidering the present study, the final task is to propagate the variance in the model of\ngroup size thorough the estimates of variance of density per day. This is straightforward to do\nwithin a bootstrap context. Therefore, the modelling dataset will be re-sampled 999 times. For\neach re-sample, the model selected for inference will be refit. This will therefore lead to new\nparameter estimates, and hence, corresponding different predictions for each of the groups sizes\none needs to predict. At each iteration the density per day will be calculated. Therefore, in\nthe end, there will be K estimates for each day\u2019s density, and getting variance or confidence\nintervals using the percentile method (Manly, 2006, p. 46-51) from these allows one to obtain\nprecision measures which incorporate the model uncertainty in the final inferences.\n\n2.6.1.1 Parametric Bootstrap\n\nThe bootstrap technique mentioned before used the empirical bootstrap, which draws\nbootstrap samples by resampling the data, making no assumptions about the underlying\ndistribution. The difference between the empirical and the parametric bootstraps is the source of\nthe bootstrap sample. The parametric type produces the bootstrap sample from a parametrized\ndistribution by fitting a parametric model to the data, often by MLE, and samples of random\nnumbers are drawn from this fitted model. Confidence intervals for the parameter may then be\nbuilt.\n\nThe bounds for a 100(1 ? 2?)% approximate standard normal confidence interval are given\nby:\n\n??L = ?? ?z? \u00b7 s?e(??) , ??U = ?? + z? \u00b7 s?e(??) ; (2.55)\n\nwhere ?? is the estimation of the parameter of interest ?; ??L and ??U are respectively the lower\nand upper bounds of the confidence interval of ?; and z? = ??1(1 ??) is the (1 ??)th quantile\nof the standard normal distribution.\n\n37\n\n\n\nHowever, the standard normal confidence interval has the drawback of always being\nsymmetric around the estimated parameter.\n\nEfron and Tibshirani (1993) then suggest replacing the confidence interval with the percentile\ninterval. It is based on the empirical percentiles of the bootstrap replicates. Given B bootstrap\nsamples, the replicates, ???, are ordered from the smallest to the largest, where the bounds for\nthe confidence interval are chosen from the B?th and the B(??1)th replicates. I.e., the bounds\nfor a 100(1 ? 2?)% percentile interval are given by:\n\n??L = ???(B?) , ??U = ??\n?\n(B(1??)) . (2.56)\n\nA parametric bootstrap was employed in the present study, since Moretti et al (2010)\ncalculated a weighted mean dive rate (r?) of 0.36 dives/hour, with a weighted standard error\nof 0.04. In order to include the dive rate variance in each bootstrap, a vector with 999 values\nwas created (one for every single bootstrap), from a normal distribution with a mean of 0.36\nand a standard error of 0.04.\n\n38\n\n\n\nChapter 3\n\nResults\n\nThe code required to reproduce the results is provided in Appendix A.\n\n3.1 The Modelling Dataset\n\n3.1.1 Exploratory Analysis\n\nAn exploratory analysis for the modelling dataset took place before beginning the model\nselection.\n\nFigure 3.1 reveals the total number of clicks detected for each hydrophone. The salmon and\nblue bars represent uni and bi directional hydrophones, respectively. It is also important to\nhighlight that the hydrophones numbered 1-14 are Whiskey.\n\nFigure 3.2 illustrates the number of clicks detected for each group. One may see that the\ngroups 13 and 47 stand out from the rest.\n\n39\n\n\n\nFigure 3.1: Click counts for all 93 hydrophones. Uni and Bi hydrophones are distinguished with different colours (salmon and blue, respectively).\n\n40\n\n\n\nFigure 3.2: Total number of clicks detected for each one of the 51 groups.\n\n41\n\n\n\nIn any regression framework it is recommended to understand the distribution of the response\nvariable prior to implementation of plausible candidate models. In our setting, that corresponds\nto investigate the distribution of observed group sizes for the groups for which group size is\nassumed to be known.\n\nFigure 3.1 illustrates the counts from the response variable.\n\nFigure 3.3: Group size count distribution for the modelling dataset, ranging from 1 to 6 individuals per\ngroup, with a total of 51 groups.\n\nIgnoring the lack of zeros, the group size distribution appears to resemble a Poisson\ndistribution. Although, before testing that hypothesis, it is important to check for\noverdispersion. The sample\u2019s group size mean is approximately 2.57, while the sample\u2019s group\nsize variance is about 0.97. Since 0.97 &lt;2.57, it looks like there is no overdispersion, but\nprobably underdispersion instead. Underdispersion occurs when the variance is smaller than\nthe mean, and it is actually a rare case. In many cases it does not constitute an issue, a Poisson\nmay continue to reasonably fit the response variable distribution (Frome, 1982).\n\nTo verify the validity of a Poisson distribution, a Pearson\u2019s ?2 goodness of fit test was\nemployed by comparing the group size distribution with a Poisson distribution with a mean\nvalue equal to the sample\u2019s group size mean. However, since the standard Poisson considers the\nvalue zero, an adjustment for this test was made to incorporate the zero in the data group size\nby removing a single unit to each y value, i.e., by considering the response variable to be cs0\ninstead of cs, similarly as what was described on the previous chapter.\n\n42\n\n\n\nThe hypothesis to consider are:\n\nH 0: The sample\u2019s group size follows a Poisson distribution\nvs.\n\nH 1: The sample\u2019s group size does not follow a Poisson distribution\n\nThe following results were then obtained:\n\nX-squared = 9.3333\np-value = 0.1557\n\nHowever, a warning message appeared: \u201cChi-squared approximation may be incorrect\u201d. A\nquick fix relies in simulating the p-value based on replicates for the sample size with n = 51 (in\nthis case 10000 replicates). The results were:\n\nX-squared = 9.3333\np-value = 0.1540\n\nThe null hypothesis, H 0, is not rejected for the usualy considered significance values (0.01,\n0.05 and 0.1). This means the analysis may proceed considering the Poisson distribution, since\nit appears to fit well to the data.\n\n3.1.1.1 Univariate Analysis\n\nIn this section each explanatory variable\u2019s relation with the response variable will be analysed.\nThe plots corresponding to this relation may be seen on figures 3.4 and 3.5:\n\n43\n\n\n\nFigure 3.4: Univariate analysis for each continuous explanatory variable (x-axis) against the response\nvariable, cluster size (y-axis). Each black dot corresponds to an observation and the blue line matches the\n\nregression line, where the grey area is the 95% confidence level interval for the predictions. A: click mean count,\nB: number of hydrophones, C: click duration, D: number of clicks, E: click rate.\n\nThe group size appears to increment as each continuous explanatory variable increases.\nHowever, only the variables \u201cclick mean count\u201d, \u201cnumber of clicks\u201d, and \u201cclick rate\u201d appear to\nbe statistically significant with a p-value &lt;0.05, when building univariate regression models.\n\n44\n\n\n\nFigure 3.5: Univariate analysis for each binary explanatory variable (x-axis) against the response variable,\ncluster size (y-axis). Each violin plot considers an orange area where its width is proportional to the number of\n\nobservations, and a black dot that corresponds to the observations\u2019 median. F: whiskey/non-whiskey, G:\nuni-directional/bi-directional.\n\nLooking at the binary variables, it appears that group size decreases with Whiskey\nhydrophones. It seems to indicate that smaller group sizes were more commonly detected on the\nthese hydrophones. On the contrary, groups size shows the opposite behaviour with the variable\n\u201cdirection\u201d. Both variables are not statistically significant on their univariate analysis (p-value\n> 0.05).\n\n3.1.2 Correlation\n\nCorrelation, whether causal or not, may indicate a predictive relationship that can be\nbeneficial, since it may be possible to predict a variable from another one.\n\nFigure 3.6 illustrates each non-binary variable (meancount, nhyd, cdur, nclicks, crate)\nbehaviour against each other.\n\nFigures 3.7 and 3.8 illustrate the correlation between the non-binary variables via Pearson\u2019s\n? and Spearman\u2019s rs, respectively.\n\n45\n\n\n\nFigure 3.6: Behaviour of each non-binary variable against each other (mean count, number of hydrophones,\nclick duration, number of clicks, and click rate, respectively).\n\nFigure 3.7: Correlation plot featuring Pearson\u2019s ? value for each non-binary variable duo (mean count,\nnumber of hydrophones, click duration, number of clicks, and click rate).\n\n46\n\n\n\nFigure 3.8: Correlation plot featuring Spearman\u2019s rs value for each non-binary variable duo (mean count,\nnumber of hydrophones, click duration, number of clicks, and click rate).\n\nFigure 3.9 exhibits the Point-Biserial coefficients between the non-binary and binary\n(direction, wisk) variables.\n\nFigure 3.9: Correlation plot featuring the Point biserial correlation coefficient between the non-binary (mean\ncount, number of hydrophones, click duration, number of clicks, and click rate) and the binary (direction and\n\nwhiskey) variables.\n\nFinally, when using the Phi coefficient measure between both binary variables, one gets\n? = ?0.68.\n\n47\n\n\n\n3.1.3 Model Building\n\nAfter getting an insight into the modelling dataset, it is time to build candidate models that\nwould explain the group size. Standard Poisson GLM and GAM were the first models employed,\nfollowed by the zero-truncated approach.\n\n3.1.3.1 Non-Truncated GLM &amp; GAM\n\nThe non-truncated GLM and GAM modelling results are shown below on tables 3.1 and\n3.2. The first table considers models fit to all 51 observations, whereas the second one only\nretains the 43 observations with the highest confidence level (confidence=1). Note that GAM\nis composed by smooth functions which have several coefficients. Therefore, there is no single\nparameter value associated with each smooth, and only the significance level of each smooth\nmay be displayed.\n\nTable 3.1: The best three candidate Poisson models (GLM and GAM) that explain the response variable\n\u201cgroup size\u201d, along with the explanatory variables\u2019 coefficients (from GLM), and smooth significance level (from\n\nGAM), and the model\u2019s AIC value. The models were built considering all the 51 observations.\n\nModel\nname\n\nModel explanatory\nvariables\n\nGLM\ncoeff.\n\nGAM smooth\np-value\n\nGLM\np-value\n\nAIC value\n\nA1\nclick duration\n\nnumber of hydrophones\nclick rate\n\n0.0125\n?0.1122\n\n0.0045\n\n0.1013\n0.0461?\n\n0.0049??\n\n0.1013\n0.0461?\n\n0.0049??\n142.2435\n\nA2\nnumber of hydrophones\n\nclick rate\n?0.0695\n\n0.0039\n0.1499\n0.0101?\n\n0.1499\n0.0101?\n\n142.9390\n\nA3 click rate 0.0022 0.0160? 0.0160? 143.1803\n\nSignificance codes: 0.01 \u2018**\u2019, 0.05, \u2018*\u2019\n\nTable 3.2: The best three candidate Poisson models (GLM and GAM) that explain the response variable\n\u201cgroup size\u201d, along with the explanatory variables\u2019 coefficients (from GLM), and smooth significance level (from\n\nGAM), and the model\u2019s AIC value. The models were built only considering the 43 groups with a confidence\nlevel of 1.\n\nModel\nname\n\nModel explanatory\nvariables\n\nGLM\ncoeff.\n\nGAM smooth\np-value\n\nGLM\np-value\n\nAIC value\n\nB1\nclick duration\n\nwhiskey hydrophones\nclick rate\n\n0.0045\n?0.4718\n\n0.0029\n\n0.5341\n0.0657\n0.0055??\n\n0.5341\n0.0657\n0.0055??\n\n122.0444\n\nB2\nwhiskey hydrophones\n\nclick rate\n?0.4905\n\n0.0032\n0.0546\n0.0024??\n\n0.0546\n0.0024??\n\n120.4265\n\nB3 click rate 0.0025 0.0095?? 0.0095?? 122.1139\n\nSignificance codes: 0.01 \u2018**\u2019, 0.05, \u2018*\u2019\n\nBoth GLM and GAM methods hold the same variable choices, significance levels, and AIC\nresults.\n\n48\n\n\n\nWhen merely considering the groups with a confidence level of 1, the importance of the\nvariable \u201cnumber of hydrophones\u201d diminishes, being replaced by \u201cwhiskey hydrophones\u201d. The\none model common in both tables is composed solely by the variable \u201cclick rate\u201d.\n\nFurthermore, when attempting to fit a Negative Binomial GLM or GAM, a warning message\nwould appear indicating a large ? parameter (the scale parameter of the Negative Binomial)\nthat would not converge. For very large ? values the coefficient estimates are close to a Poisson\ndistribution. (Klugman et al., 2004), which is not surprising for our under dispersed data set.\n\n3.1.3.2 Zero-truncated GLM &amp; GAM\n\nFor the zero-truncated approach the analysis encountered an issue: when modelling with\nGAM, R would evoke a likelihood convergence error. This often occurs due to the sample\nsize, which may not be large enough. Family functions from the VGAM package use the type\nof algorithm described in McCullagh (1980), where it is demonstrated that for sufficient large\nsamples an unique maximum of the likelihood is guaranteed, whereas while modelling with\nsmaller samples one may be confronted with convergence obstacles. This led us to continue the\nzero-truncated analysis solely with GLM. The results are presented in tables 3.3 and 3.4.\n\nTable 3.3: The best three candidate Poisson models (zero-truncated GLM) that explain the response variable\n\u201cgroup size\u201d, along with the explanatory variables\u2019 coefficients and the model\u2019s AIC value. The models were\n\nbuilt considering all the 51 observations.\n\nModel\nname\n\nModel explanatory\nvariables\n\nGLM\ncoeff.\n\nGLM\np-value\n\nAIC value\n\nC1\nclick duration\n\nnumber of hydrophones\nclick rate\n\n0.0103\n?0.0926\n\n0.0037\n\n0.1374\n0.0713\n0.0113?\n\n150.4935\n\nC2\nnumber of hydrophones\n\nclick rate\n?0.0573\n\n0.0033\n0.1931\n0.0205?\n\n150.7108\n\nC3 click rate 0.0018 0.0298? 150.5499\n\nSignificance codes: 0.01 \u2018**\u2019, 0.05, \u2018*\u2019\n\nTable 3.4: The best three candidate Poisson models (zero-truncated GLM) that explain the response variable\n\u201cgroup size\u201d, along with the explanatory variables\u2019 coefficients and the model\u2019s AIC value. The models were\n\nbuilt only considering the 43 groups with a confidence level of 1.\n\nModel\nname\n\nModel explanatory\nvariables\n\nGLM\ncoeff.\n\nGLM\np-value\n\nAIC value\n\nD1\nclick duration\n\nwhiskey hydrophones\nclick rate\n\n0.0037\n?0.3873\n\n0.0024\n\n0.5740\n0.0960\n0.0124?\n\n129.1026\n\nD2\nwhiskey hydrophones\n\nclick rate\n?0.4027\n\n0.002\n0.0821\n0.0062??\n\n127.4147\n\nD3 click rate 0.0021 0.0196? 128.4403\n\nSignificance codes: 0.01 \u2018**\u2019, 0.05, \u2018*\u2019\n\n49\n\n\n\nThe models built under untruncated and zero-truncated analysis hold the same variables.\nConsidering models with similar AIC and according to the rule of parsimony, the simpler\n\nmodel should be picked. Also, the simpler model is the only one featured when modelling both\nwith 51 or 43 observations. Therefore, in order to use the maximum amount of information\npossible, all the 51 observations will be considered. Such will prompt the study to continue with\nthe model C3 , as seen on table 3.3.\n\n3.1.4 Analysing the model\n\nAs mentioned before, it is important to analyse the model chosen for further inference,\nspecially in terms of residuals and influential values.\n\n3.1.4.1 Residuals\n\nA Shapiro-Wilk test was applied to test the normality of the residuals. The results are as\nfollowed:\n\nH 0: The model\u2019s residuals are normally distributed\nvs.\n\nH 1: The model\u2019s residuals are not normally distributed\n\nW = 0.97532\np-value = 0.3626\n\nThe null hypothesis is not rejected for any reasonable ? level considered.\nFigure 3.10 illustrates the residuals\u2019 behaviour against the fitted values, with a 95%\n\nconfidence interval.\n\nFigure 3.10: Fitted values and corresponding residuals, with a scatter plot smoother (grey area).\n\nAdditionally, a Pearson\u2019s product-moment correlation test between the fitted group size\nvalues and the residuals was employed:\n\n50\n\n\n\nH 0: The correlation between the fitted values and their residuals is equal to zero.\nvs.\n\nH 1: The correlation between the fitted values and their residuals is not equal to zero.\n\nR = ?0.01525496\np-value = 0.9154\n\nThe null hypothesis is not rejected, which indicates there is not a significant correlation\nbetween the model\u2019s fitted values and their residuals.\n\n3.1.4.2 Hat values\n\nThe model may include some extreme hat values. Figure 3.11 provides a better visual insight.\n\nFigure 3.11: Model residuals and corresponding hat values\n\nThe extreme hat values correspond to observations 13 and 47. The later were removed in\norder to pinpoint their influence. The model was then rebuilt. Table 3.5 holds the results.\n\n51\n\n\n\nTable 3.5: The best three candidate Poisson models (zero-truncated GLM) that explain the response variable\n\u201cgroup size\u201d, along with the explanatory variables\u2019 coefficients and the model\u2019s AIC value. The models were\n\nbuilt considering all the 49 observations without extreme hat values.\n\nModel name\nModel explanatory\n\nvariables\nGLM\ncoeff.\n\nGLM\np-value\n\nAIC value\n\nE1\nclick duration\n\nnumber of hydrophones\nclick rate\n\n0.0106\n?0.0974\n\n0.0038\n\n0.1831\n0.0842\n0.0386?\n\n142.7658\n\nE2\nnumber of hydrophones\n\nclick rate\n?0.0594\n\n0.0031\n0.1993\n0.0728\n\n142.9766\n\nE3 click rate 0.0014 0.2130 142.9038\n\nSignificance codes: 0.01 \u2018**\u2019, 0.05, \u2018*\u2019\n\nThe same variables were selected as before, although it is noticeable the decrease in value\nregarding the \u201cnumber of hydrophones\u201d variable coefficient. Also, although the same variables\nwere chosen, their significance level (p?value) decreased. This may be an indication that more\ndata need to be collected to sustain a model.\n\nAdditionally, the observations without a confidence level of 1 were also removed and the\nmodel rebuilt. Table 3.6 holds the results.\n\nTable 3.6: The best three candidate Poisson models (zero-truncated GLM) that explain the response variable\n\u201dgroup size\u201d, along with the explanatory variables\u2019 coefficients and the model\u2019s AIC value. The models were\n\nbuilt only considering the 41 observations without extreme hat values and with a confidence level of 1.\n\nModel name\nModel explanatory\n\nvariables\nGLM\ncoeff.\n\nGLM\np-value\n\nAIC value\n\nF1\nmean count\nclick rate\n\nwhiskey hydrophones\n\n0.0003\n0.0018\n?0.2829\n\n0.4020\n0.2470\n0.2990\n\n129.1026\n\nF2\nclick rate\n\nwhiskey hydrophones\n0.0023\n?0.4038\n\n0.0841\n0.0834\n\n127.4147\n\nF3 whiskey hydrophones ?0.3312 0.1480 128.4403\n\nSignificance codes: 0.01 \u2018**\u2019, 0.05, \u2018*\u2019\n\nIt is noticeable that removing more observations in an already small dataset leads to a\ndifferent selection of variables and a decrease on the variables\u2019 significance level.\n\nComparing all the modelling approaches, the model with the single explanatory variable\n\u201cclick rate\u201d appears to be the best one. Once more, in furtherance of preserving the maximum\namount of information available, the analysis proceeds with the model where all observations\nwere considered (model C3).\n\n52\n\n\n\n3.2 Density Estimation Dataset\n\nSimilarly to the modelling dataset, the density estimation dataset was first subjected to a\nthorough exploratory data analysis.\n\n3.2.1 Exploratory Analysis\n\nTo visualize possible click detection problems among the hydrophones, the variable \u201cclick\ncount\u201d was plotted against the 93 hydrophones. Figure 3.12 illustrates the click counts each\nhydrophone detected on the raw data.\n\nFigure 3.12: Click counts for each hydrophone (raw data).\n\nOne may notice that two of the hydrophones (86 and 87) have no detections at all, meaning\nthere was probably an issue with them. The AUTEC was promptly notified of the situation.\n\n3.2.2 Group Size Estimation\n\nGroup size was then estimated for every group. A mean group size value of 2.35 individuals\nper group was estimated for the three time periods. The figures bellow illustrate the mean group\nsize per day, for the corresponding 3 periods: (1) figure 3.13, (2) figure 3.14, and (3) figure 3.15,\nwith a group size mean value of approximately 2.36, 2.30, and 2.33, respectively.\n\nTable 3.7 summarizes the group size values obtained for each time period.\n\n53\n\n\n\nFigure 3.13: Group size estimations for each day (orange area), considering the first period (61 days). The orange area width is proportional to the number of estimated\nvalues for the group size. Each black dot inside every violin plot represents the median for the respective day.\n\n54\n\n\n\nFigure 3.14: Group size estimations for each day (orange area), considering the second period (18 days). The\norange area width is proportional to the number of estimated values for the group size. Each black dot inside\n\nevery violin plot represents the median for the respective day.\n\nFigure 3.15: Group size estimations for each day (orange area), considering the third period (30 days). The\norange area width is proportional to the number of estimated values for the group size. Each black dot inside\n\nevery violin plot represents the median for the respective day.\n\n55\n\n\n\nTable 3.7: Group size estimation summary statistics for each of the three time periods considered.\n\nPeriod 1 Period 2 Period 3\nMean 2.3557 2.2976 2.3310\nStandard Deviation 0.3144 0.2706 0.3117\nMinimum 1.9898 1.9952 1.9914\nMaximum 6.7230 4.6200 5.4425\n\n3.2.3 Density Estimation\n\nFinally, the density estimation (whales/1000 km2) for each day was obtained. The overall\nmean density value estimation for all three periods is 15.91 whales/1000 km2, with a mean value\nof 75.88 dives per day. The figures bellow illustrate the density estimation for the corresponding\n3 time periods: (1) figure 3.16, (2) figure 3.17, and figure (3) 3.18, with respectively a density\nmean value of approximately 15.80, 16.45, and 15.81 whales/1000 km2, and an average number\nof dives per day of 74.79, 79.94, and 75.67. The average number of dives per day for the three\ntime periods is approximately 76.8.\n\nTable 3.8 summarizes the density values obtained for each time period.\n\n56\n\n\n\nFigure 3.16: Density estimation for each day (whales/1000 km2), considering the first period (61 days).\n\n57\n\n\n\nFigure 3.17: Density estimation for each day (whales/1000 km2), considering the second period (18 days).\n\nFigure 3.18: Density estimation for each day (whales/1000 km2), considering the third period (30 days).\n\n58\n\n\n\nTable 3.8: Values regarding the density estimation for the three time periods.\n\nPeriod 1 Period 2 Period 3\nMean 15.7944 16.4674 15.8129\nStandard Deviation 4.8373 2.6441 3.3323\nMinimum 5.6368 11.1746 9.2678\nMaximum 30.2686 20.4704 22.4915\nAverage # of groups/day 74.7869 79.9444 75.6667\n\n3.2.4 Bootstrapping\n\nTo estimate the variance associated with the model for predicting group size, a bootstrap\nwas implemented. The results are illustrated bellow.\n\nFigure 3.19 illustrates the observed group size for each Md group, as well as the model\u2019s\nmaximum likelihood fit line with a percentile interval of 95%.\n\nFigure 3.19: The observed group sizes and corresponding click rate (black dots), along with the model\u2019s\nmaximum likelihood fit line (red line), and the model\u2019s bootstrap 95% percentile interval (grey area).\n\nIt was then necessary to propagate the variability of the model to the density estimation\nprocedure, where a bootstrap exercise was also implemented. Figure 3.20 represents the 999\nbootstraps (one for each colour), where the x-axis corresponds to the click rate variable and the\ny-axis to the group size.\n\n59\n\n\n\nFigure 3.20: 999 group size bootstraps for the chosen model, for each click rate value. Although barely\ndistinguishable, each colour represents a group size bootstrap for the corresponding click rate value.\n\nFigure 3.21 is representing the estimated density per day for each bootstrap.\n\n60\n\n\n\nFigure 3.21: 999 model density bootstraps for each day, considering the three time periods. Although barely distinguishable, each colour represents a single bootstrap.\n\n61\n\n\n\n3.3 Comparison with Previous Results\n\nOne of the main goals of the present study is to compare the results with previous ones.\nMoretti et al (2010) compared estimated densities between time periods before, during and\nafter sonar usage. Table 3.9 reproduces their results.\n\nTable 3.9: Estimated abundance and density based on dive counting, with corresponding coefficient of variation\n(CV). Values in brackets after the estimates are 95% limits. Adapted from tables 1 and 3 in Moretti et al., 2010.\n\nTime period Abundance\nDensity\n\n(whales/1000 km2)\nTotal #\n\nof groups\nCV (%)\n\nBefore sonar (65h prior\nto initial transmission)\n\n22 (17-28) 16.99 (13.47 - 21.43) 194 11.89\n\nDuring sonar (68.12h of\ntransmission)\n\n6 (4-8) 4.76 (3.78 - 6.01) 57 11.89\n\nAfter sonar (65h after\nlast transmission)\n\n11 (8-14) 8.67 (6.87 - 10.94) 99 11.89\n\n65h after sonar\n(43.23h)\n\n32 (25-40) 24.76 (19.63 - 31.23) 188 11.89\n\nMoretti et al (2010) used a single mean group size (s) of 2.62 animals/group, based on\nexisting literature. Comparatively, Baird et al (2006) measured a Md group size value of 3.6\nanimals/group on the Big Island in Hawaii; while Claridge (2004) reported an average group of\nsize of 4.1 animals/group on the Northern Bahamas.\n\nAccording to table 3.9, the total number of groups detected per 24 hours would be\napproximately 71.63, 20.08, 36.55, and 104.37, respectively, for the four measurement periods.\n\n62\n\n\n\nChapter 4\n\nDiscussion\n\nNews regarding catastrophic wildlife declines are common. In fact, these reports are\nbecoming more prominent as we are dealing first-hand with real environmental consequences.\nWhen digesting that information, a question we often guiltily ask ourselves is \u201cwhat can I\ndo to help?\u201d. That feeling of culpability often vanishes after a while. Fortunately, in other\noccasions, such spark will not vanish, ending up being the foundation of something meaningful.\nScientists are often the ones keeping their spark alive, presenting and innovating methods aiming\nbetter conservancy policies. An example lies with Passive Acoustic Monitoring, a field with a\ngreat potential when it comes to study wild marine populations. PAM presents us the chance\nof accurately estimating wild animal population size and density. Since it relies on acoustic\nfootprints, its performance is not compromised by dark environments. Also, each species produce\ndistinctive sounds, and because acoustic signs are often detectable at greater distances, it often\nmakes them a more reliable source of information than visual cues. Due to its distinctive and\ninnovative characteristics, PAM may become an important tool for the future of Ecology and\nConservation.\n\nSince Md is a species known to produce echolocation sounds, but hard to detect visually, PAM\nmay be an efficient solution to collect data about it. Presently, Md does not have an established\nconservation status due to lack of information (iucnredlist.org), which may be adjusted in a near\nfuture as we obtain additional information on the species. The present work aims to pave that\nchange by contributing with this analysis of Md data.\n\nThe density estimation formula (2.53) has two random components associated with it, the\ngroup size and the dive rate. The proposed method improves on the previous approach of Moretti\net al (2010) by (1) allowing the estimation of a group size for each group, and hence (2) allowing\nthe estimation of a mean group size for each period of interest, and therefore (3) allowing to\nrelax the implicit assumption that group size is constant over time and space. However, the same\nproblem still applies to the dive rate, which is taken from the literature, based on a small sample\nof tagged animals (Moretti et al, 2010), and assumed constant over time. It is possible that\ndifferences of dive rates are larger over time and space than differences in group sizes, meaning\nthat while a useful step in obtaining more reliable estimates, dealing with variation in group size\nmight fall short from being enough to get reliable density estimates from dive counting methods.\nThis means that additional studies looking at dive rates from beaked whales, investigating how\nthese might change in time (e.g., seasonally) and in space (e.g., being or not depth dependent),\nare fundamental to understand the reliability of dive counting methods.\n\n4.1 Underlying Assumptions\n\nIn this work we assumed no false positives and no missed detections, nonetheless there is some\nevidence that a small number of these might occur (D. Moretti 2016, personal communication).\n\n63\n\n\n\nIt seems important to refer that a study looking at these two assumptions would be much\nwelcome. Depending on the magnitude of each of these phenomena the density estimates\nunder these assumptions might be underestimating or over estimating density. Given that\nthese phenomena occur at a small scale and the induced biases will have different signs, with\nfalse positives overestimating abundance, but missed detections underestimating abundance.\nTherefore, despite perhaps more elegant and thorough analysis might be conducted while\naccounting for them, we do not anticipate major changes once these factors are actually\nincorporated.\n\n4.2 Conclusions\n\nWe conclude that, based on the acoustic footprint of groups detected on AUTEC\nhydrophones, the variable \u201cclick rate\u201d appears to be the best descriptor of group size. However,\nwhen it comes to modelling, it is noticeable that more observations may be needed, as a small\ndata set will never allow a complex model to be a parsimonious choice. Therefore, it is possible\nthat with additional data more complex models might prove useful to describe group size from\nthe group\u2019s acoustical footprint. Although the model composed solely by the \u201cclick rate\u201d variable\nwas always among the models\u2019 top 3, the variable \u201cnumber of hydrophones\u201d was replaced by\n\u201cwhiskey hydrophones\u201d on the remaining two models when only considering the groups with a\nconfidence level of 1, which may indicate difficulties when choosing between variables.\n\nMoreover, the variable \u201cnumber of hydrophones\u201d held a negative coefficient, which is not\nlogically or physically plausible since a bigger group would trigger more hydrophones, and not the\nother way around. This could be due to several groups being detected over Whiskey hydrophones:\nit would be possible for a smaller group to trigger a higher number of hydrophones if it happened\nto dive near Whiskey hydrophones. That is enough to introduce confounding and the consequent\ndifficulty in getting a reliable model. Therefore, a different way of incorporating the information\nfrom these hydrophones in the analysis might be preferable, which should be investigated in the\ncontinuation of this study.\n\nIn terms of the estimated group sizes and densities, the results presented here are well in\nline with those from previous studies (e.g., Moretti et al., 2010). Nonetheless, the present work\nobtained a smaller mean group size estimate than the one from literature (2.35 vs 2.62). The\ndifference is higher when considering the values reported in Claridge (2004) and Baird et al\n(2006), (4.1 and 3.6 respectively). The present work estimates a mean density of 15.91 across\nall time periods. It is presumed that no major sonar activity took place during the echolocation\nclicks detection, although small activities can not be ruled out, both during this study, before\nor after. Although interpreting the results might be easier knowing times of sonar emission,\ninformation about sonar activity at the AUTEC range is extremely sensitive and therefore\nunlikely to be available to us.\n\nIt is important to acknowledge that the density values reported by Moretti et al. (2010) are\n16.99, 4.76, 8.67 and 24.76 were calculated considering much smaller time periods (65h, 68.13h,\n65h and 43.23h respectively), for which the impact from the sonar activity may have become\nmore perceptible. Therefore, localized sonar activity occurring for the present three time periods\n(1464h, 432h and 720h, respectively) would probably not gravely reflect on the total estimated\ndensities, although it would on the daily estimates. This may indicate that reactions are fast,\n\n64\n\n\n\nand considering a larger scale the effect of the sonar activity on Md density is barely perceptible.\nIt is clear that some density fluctuation occurs over time. This fluctuation is also apparent when\nvisualizing the density bootstrap figure (figure 3.21). This indicates that the estimation of the\ngroup size is an important factor when estimating density.\n\nAdditionally, the number of groups detected per day appears to be consistent among the three\ntime periods (74.8, 79.9 and 75.7, respectively), with a global mean of 75.9 groups/24h. Moretti\net al. (2010) results for before, during and after sonar activities seem to exhibit larger differences\n(97.1, 32.8 and 24.0 groups/24h, respectively). That is not surprising due to shorter time (65h,\n68h and 365h, respectively), and the fact that sonar activities were occurring, presumably driving\noff Md individuals from the AUTEC range.\n\nOne advantage of the proposed method is to be able to provide a mean group size estimate\nfor any time period that one might consider. These differences would be averaged out when\nmaking comparisons across time points having to share the same mean estimate obtained from\nthe literature. This kind of data could be used in itself to derive spatio-temporal models of\ngroup size at AUTEC.\n\nThese type of studies aim conservation purposes. It is important to acknowledge their\nimportance and their necessity to be constantly updated. Describing the group size over time\nmay contribute to better understand Md species habits, which leads to better conservation\nmethods, since a species\u2019 density fluctuation over time may be due to several external factors,\nwhich may also include human disturbance. Those are important to target, in order to minimize\nhuman-made impact. At the current pace that species are being affected by habitat deterioration,\nmodel improvements are vital when it comes to study natural populations, as they provide more\naccurate information which will help to provide decisions based on evidence leading to an effective\nmanagement of ecosystems.\n\nFuture work on this area are will include gathering more group size data for visually\nconfirmed groups; a different approach for the inclusion of the differential detection capabilities\nof Whiskey hydrophones, and to extend the density estimation by incorporating false positives\nand non-detected groups.\n\n4.3 Acquired Competencies\n\nThe work presented here was a partial requirement for obtaining an MSc in Biostatitsics.\nIt is worth to list explicitly the set of tools and statistical competences that it allowed me to\ndevelop and become familiar with:\n\n1. Manipulate large datasets;\n\n2. Perform a thorough exploratory data analysis;\n\n3. Resort to different correlation measures between different types of variables;\n\n4. Recognize when variables interact or correlate, and be able to deal with that issue;\n\n5. Properly apply and distinguish different statistical tests;\n\n6. Being able to implement LM, GLM, GAM, and zero-truncated models;\n\n7. Deal with data from different distributions, especially Poisson and Negative Binomial;\n\n65\n\n\n\n8. Build and chose between models resorting to different approaches;\n\n9. Employ different goodness-of-fit tools;\n\n10. Implement both non-parametric and parametric bootstraps to estimate variances when\nanalytical expressions are not available;\n\n11. Able to work and compile large documents in LaTeX;\n\n12. Able to work with several R packages (to name a few: ggplot2, cowplot, vioplot, VGAM,\nmcgv, leaps, boot);\n\n13. Develop coding and programming capabilities;\n\n14. Adhere to the ideas of reproducible research using dynamic reports (Appendix A).\n\n4.4 Final Remarks\n\nStatistical procedures can be used to obtain practical answers to biological questions. In this\nwork we have estimated beaked whale density at AUTEC during a 4 month period. Additionally,\nwe have obtained the associated precision measures without which density estimates would be\nmeaningless. While doing so we have identified a number of follow up research questions and\ngained a number of statistical competencies. By providing the data and the code used via\na dynamic report, we make the research process completely transparent, allowing readers to\nimplement themselves the analysis presented, adhering to the uprising paradigm of reproducible\nresearch (Peng, 2011).\n\n66\n\n\n\nReferences\n\n? Altman, D. G. (1991). Practical Statistics for Medical Research. London: Chapman and\nHall.\n\n? Baird, R.W., Webster D.L., McSweeney D.J., Ligon A.D., Schorr G.S., &amp;\nJ. Barlow (2006). Diving behaviour of Cuvier\u2019s (Ziphius cavirostris) and Blainville\u2019s\n(Mesoplodon densirostris) beaked whales in Hawai\u2019i. Canadian Journal of Zoology, 84,\n1120-1128.\n\n? Baird, R.W., Webster D.L.,Schorr G.S., McSweeney D.J., &amp; Barlow J. 2008. Diel\nvariation in beaked whale diving behavior. Marine Mammal Science 24, 630-642.\n\n? Barlow, J. (1999). Trackline detection probability for long-diving whales. In G. W. Garner,\nS. C. Amstrup, J. L. Laake, B. J. F. Manley, L. L. McDonald &amp; D. G. Robertson (Eds.)\nMarine Mammal Survey and Assessment Methods (pp. 209-221). Netherlands: A.A. Balkema\nPublishers.\n\n? Burnham, K. P., Anderson, D. R. (2002). Model Selection and Multimodel Inference A\nPractical Information-Theoretic Approach. New York: Springer-Verlag.\n\n? Cameron, A. C., Trivedi, P. K. (1998). Regression Analysis of Count Data. Cambridge:\nCambridge University Press.\n\n? Chatterjee, S. &amp; Hadi, A. (1986). Influential observations. Statistical Science, 1, 379-392.\n\n? Chernick, M. R., &amp; LaBudde, R. A. (2011). An Introduction to Bootstrap Methods with\nApplications to R. New Jersey: Wiley.\n\n? Claridge, D. E. (2004). Fine-scale distribution and habitat selection of beaked whales (MSc\nthesis). University of Aberdeen, Scotland.\n\n? Conover, W. J. (1999). Practical Nonparametric Statistics. New York: Wiley.\n\n? Cramer, H. (1946). Mathematical Methods of Statistics. New Jersey: Princeton University\nPress.\n\n? Cramer, D. (1998). Fundamental Statistics for Social Research. London: Routledge.\n\n? DiMarzio, N., Moretti, D., Ward ,D., Morrissey, R., Jarvis, S., Izzi, A., Johnson,\nM., Tyack,P., &amp; Hansen, A. (2008). Passive acoustic measurement of dive vocal behavior\nand group size of Blainville\u2019s beaked whale (Mesoplodon densirostris) in the tongue of the\nocean (TOTO). Canadian Acoustics, 36, 166-173.\n\n? Draper, N., &amp; Smith, H. (1981). Applied Regression Analysis. New York: Wiley.\n\n? Efron, B. &amp; Tibshirani, R. (1993). An Introduction to the Bootstrap. New York: Chapman\nand Hall.\n\n67\n\n\n\n? Fabozzi, F. J., Focardi, S. M., Rachevand, S. T., &amp; Arshanapalli, B. G. (2014).\nThe Basics of Financial Econometrics: Tools, Concepts, and Asset Management Applications.\nNew Jersey: Wiley.\n\n? Frome, E. L. (1982). Algorithm AS 171: Fisher\u2019s Exact Variance Test for the Poisson\nDistribution. Journal of the Royal Statistical Society. Series C (Applied Statistics), 31, 67-71.\n\n? Greenwood, P. E., &amp; Nikulin, M. S. (1996). A Guide to Chi-Squared Testing. New Jersey:\nWiley.\n\n? Hair, J.F. Jr., Anderson, R.E., Tatham, R.L., &amp; Black, W.C. (1998). Multivariate\nData Analysis. New Jersey: Prentice Hall.\n\n? Hardin, J. W., Hilbe, J. M. (2007). Generalized Linear Models and Extensions. Texas:\nStata Corp.\n\n? Hastie, T. J., &amp; Tibshirani R. J. (1986). Generalized additive models. Statistical Science,\n1, 295\u2013318.\n\n? Hastie, T. J., &amp; Tibshirani, R. J. (1990). Generalized Additive Models. New York:\nChapman and Hall.\n\n? Jefferson, T. A., Webber, M. A., &amp; Pitman, R. L. (2008). Marine Mammals of the\nWorld, A Comprehensive Guide to their Identification. Amsterdam: Elsevier.\n\n? Johnson, M., Madsen, P. T., Zimmer, W. M. X., Aguilar de Soto, N., &amp; Tyack,\nP. L. (2006). Foraging Blainville\u2019s beaked whales (Mesoplodon densirostris) produce distinct\nclick types matched to different phases of echolocation. The Journal of Experimental Biology,\n209, 5038-5050.\n\n? Klugman, S.A., Panjer, H. H., &amp; Wilmot, G. E. (2004). Loss Models, From Data to\nDecisions. New York: Wiley\n\n? Kutner, M. H., Nachtsheim, C. J., &amp; Neter, J. (2004). Applied Linear Regression\nModels. Illinois: McGraw-Hill Irwin.\n\n? Leatherwood, S., &amp; Reeves, R.R. (1983). The Sierra Club Handbook of Whales and\nDolphins. San Francisco: Sierra Club Books.\n\n? MacLeod, C. D. (1998). Intraspecific scarring in odontocete cetaceans: an indicator of male\n\u2019quality\u2019 in aggressive social interactions? Journal of Zoology, 244, 71 \u2013 77.\n\n? Manly B. F. J. (2006) Randomization, Bootstrap and Monte Carlo Methods in Biology,\nBoca Raton, FL: Chapman and Hall/CRC.\n\n? Marques, T. A., Thomas, L., Ward, J., DiMarzio, N., &amp;Tyack, P. L. (2009).\nEstimating cetacean population density using fixed passive acoustic sensors: an example with\nBlainville\u2019s beaked whales. The Journal of the Acoustical Society of America, 125, 1982-1994.\n\n? Marques T., Shaffer J., &amp; Thomas L. (2013). Modelling group size as a function of\nautogrouper outputs. University of St Andrews, Scotland.\n\n68\n\n\n\n? Marques, T. A., Thomas, L., Martin, S. W., Mellinger, D. K., Ward, J. A.,\nMoretti, D. J., Harris, D., &amp; Tyack, P. L. (2013). Estimating animal population density\nusing passive acoustics. Biological Reviews, 88, 287-309.\n\n? McCann, C. (1963). Occurrence of Blainville\u2019s beaked-whale Mesoplodon densirostris\n(Blainville) in the Indian ocean. Journal of the Bombay Natural History Society, 60, 727-731.\n\n? McCullagh, P. (1980). Regression models for ordinal data. Journal of the Royal Statistical\nSociety. Series B (Methodological), 42, 109\u2013142.\n\n? McCullagh, P. &amp; Nelder, J.A. (1989) Generalized Linear Models. Washington, DC:\nChapman and Hall/CRC.\n\n? Mead, J.G. (1989). Handbook of Marine Mammals. London: Academic Press.\n\n? Montgomery, D. C., &amp; Peck, E. A. (1992). Introduction to Linear Regression. New York:\nJohn Wiley.\n\n? Moretti, D., Marques, T., Thomas, L., DiMarzio, N., Dilley, A., Morrissey, R.,\nMcCarthy, E., Ward, J., &amp; Jarvis, S. (2010). A dive counting density estimation method\nfor Blainville\u2019s beaked whale (Mesoplodon densirostris) using a bottom-mounted hydrophone\nfield as applied to a Mid-Frequency Active (MFA) sonar operation. Applied Acoustics, 71,\n1036-1042.\n\n? Pastene, L. A., K. Numachi, M. Jofre, M. Acevedo, &amp; G. Joyce. (1990). First\nrecord of the Blainville\u2019s beaked whale, Mesoplodon densirostris Blainville, 1817 (Cetacea,\nZiphiidae) in the eastern South Pacific. Marine Mammal Science, 6, 82-84.\n\n? Peng, R. D.. (2011). Reproducible Research in Computational Science, Science 334,\n1226-1227.\n\n? R Core Team. (2017). R: A language and environment for statistical computing. R\nFoundation for Statistical Computing. Vienna, Austria. URL https://www.R-project.org/.\n\n? Rencher, A. C., &amp; Schaalje, G.B. (2008). Linear Models in Statistics. New Jersey: Wiley.\n\n? Sarhan, A. E. &amp; Greenberg,B. G. (1956). Estimation of location and scale parameters by\norder statistics from singly and double censored samples. Part I. The Annals of Mathematical\nStatistics, 27, 427-51.\n\n? Shaffer, J., Moretti, D., Jarvis, S., Tyack, &amp; P., Johnson, M. (2013). Effective beam\npattern of the Blainville\u2019s beaked whale (Mesoplodon densirostris) and implications for passive\nacoustic monitoring. The Journal of the Acoustical Society of America, 133, 1770\u20131784.\n\n? Shaffer, J., &amp; Baggenstoss, P. Beaked Whale Group Deep\nDive Behavior from Passive Acoustic Monitoring. Retrieved from:\nhttps://www.onr.navy.mil/reports/FY15/mbshaffe.pdf\n\n? Shapiro, S. S., &amp; Wilk, M. B. (1965). An analysis of variance test for normality (complete\nsamples). Biometrika, 52, 591\u2013611.\n\n69\n\n\n\n? Sheskin, D. (2011). Handbook of Parametric and Non Parametric Statistical Procedure.\nBoca Raton, FL: CRC Press.\n\n? Yee, T. W., Stoklosa, J., &amp; Huggins, R. M. (2015). The VGAM Package for\nCapture-Recapture Data Using the Conditional Likelihood. Journal of Statistical Software,\n65, 1-33. URL http://www.jstatsoft.org/v65/i05/.\n\n? Tyack, P. L., Johnson M., Soto, N. A., Sturlese, A., Madsen P. T. (2006). Extreme\ndiving of beaked whales. The Journal of Experimental Biology, 209, 4238-4253.\n\n? Wayne, D. W., &amp; Cross, C. L. (2013). Biostatistics: A Foundation for Analysis in the\nHealth Sciences. Toronto, ON: Wiley.\n\n? Wickham, H. (2009). ggplot2: Elegant Graphics for Data Analysis. New York:\nSpringer-Verlag.\n\n? Wood, S.N. (2006). Generalized Additive Models: An Introduction with R. Boca Raton, FL:\nChapman and Hall/CRC.\n\n? Yates, D., Moore, Moore, D., &amp; McCabe, G. (1999). The Practice of Statistics. New\nYork: W.H. Freeman.\n\n? Yee, T. (2015). Vector Generalized Linear and Additive Models: With an Implementation\nin R. New York: Springer.\n\n? Zuur, A. F., Ieno, E. N., Walker, N. J., Saveliev, A. A., &amp; Smith, G. M. (2009).\nMixed Effects Models and Extensions in Ecology with R. New York: Springer.\n\n? Zuur, A. F., &amp; Ieno, E. N. (2016). Beginner\u2019s Guide to Zero-Inflated Models with R.\nNewburgh, NY: Highland Statistics Ltd.\n\n70\n\n\n\nAppendix A\n\n1 Introduction\n\nThis document serves the purpose of aiding the visualization and interpretation of the dissertation\u2019s content\nby including the code itself.\n\nThe main goal is to estimate the density of Mesoplodon densirostris as described in Moretti et al (2010). In\norder to do so, the group size needs to be estimated via acoustic footprint variables, such as the number of\nclicks, the click duration, the click rate, among others. These clicks are echolocations the species produces to\ncommunicate and capture prey, and are collected by a field of hydrophones located at the AUTEC.\n\nThe analysis starts with a modelling where the group size was confirmed for 51 groups, with which the\nmodelling process takes place; followed by the density estimation dataset where the chosen model is employed.\nThe density estimation datset was collected by the AUTEC hydrophones over a course of 4 months, where\nthe group size was not confirmed for any group. With this work we hope to contribute to the creation of an\nautomatized method to estimate Md density over time.\n\nThe analysis will resort to a zero-truncated GLM approach, since a group with zero elements is not a group\nat all. Also, in order to compare results, non-truncated GLM will also be employed. But in this later case\nthe response variable needs to be transformed so no zero values are predicted. GAM were also applied, but\nwon\u2019t be considered in this report, since zero-truncated GAM did not converge for this particular dataset.\n\nAfterwards, in order to incorporate the variability from the first dataset and from the dive rate value (Moretti\net al, 2010) into the model, a bootstrap was applied.\n\nNote that some of the figures previously included in this work won\u2019t show up in this document as they occupy\na large amount space.\n\n2 The Modelling Dataset\n\nThe modelling dataset is composed by two separate tables which are then merged. The first table acknowledges\nthe detailed information for each group. It considers the number of times the groups were detected, how\nmany hydrophones were involved, the number of echolocation clicks, and the time period. The second table\nholds the number of whales confirmed in each group, as well as its confidence level (it goes from 1 to 3, where\n1 corresponds to \u201cmore certain\u201d, and 3 to \u201cless certain\u201d).\n\n2.1 Reading and preparing the data\n\nBoth tables refer to 51 whale groups with a confirmed group size, whose echolocations were detected by the\nhydrophones.\n#Reading the first table\ndados.mod&lt;- read.table(\"dadosi2.txt\", header=T)\nnomes&lt;- names(dados.mod)&lt;- c(\"gID\",\"month\",\"day\",\"year\",\"hyd\",\n\n\"count\",\"shou\",\"smin\",\"ssec\",\"ehou\",\"emin\",\"esec\")\n\n#Reading the second table\ndados.mod2&lt;- read.table(\"dadosi.txt\",header=F)\nnames(dados.mod2)&lt;- c(\"gID\",\"date\",\"cs\",\"conf\")\n\n#Merging the tables' information\n\n1\n\n\n\ngdatac&lt;- dados.mod[1,]\nn&lt;- nrow(dados.mod)\ncr = 2\nfor (i in 2:n) {\n\n#if it is the same hydrophone, same group\nif (dados.mod$gID[i] == dados.mod$gID[i-1] &amp; dados.mod$hyd[i] == dados.mod$hyd[i-1]) {\n\n#adding the click count to the previous row\ngdatac[cr-1,6] = gdatac[cr-1,6]+dados.mod[i,6]\n#get the end of the recorded vocal group in that phone\ngdatac[cr-1,10:12] = dados.mod[i,10:12]\n\n} else {\ngdatac[cr,] = dados.mod[i,]\ncr = cr+1\n\n}\n}\n\nAdditional information was then included, such as the time duration at each hydrophone, and whether or not\nthe hydrophone was Whiskey or Bi/Uni-directional.\n#Getting the duration at each hyd\ngdatac$date&lt;- with(gdatac,paste(month,day,year,sep=\"-\"))\ngdatac$stime&lt;- with(gdatac,paste(shou,smin,ssec,sep=\":\"))\ngdatac$etime&lt;- with(gdatac,paste(ehou,emin,esec,sep=\":\"))\ngdatac$stime&lt;- with(gdatac,strptime(paste(date,stime),format=\"%m-%d-%Y %H:%M:%S\"))\ngdatac$etime&lt;- with(gdatac,strptime(paste(date,etime),format=\"%m-%d-%Y %H:%M:%S\"))\ngdatac$hyddur&lt;- with(gdatac,difftime(time1=etime,time2=stime,units=c(\"mins\")))\n\n#Recoding Whiskey and Bi/Uni hydrophones\ngdatac$whiskey&lt;- gdatac$hyd\ngdatac$direction&lt;- gdatac$hyd\ngdatac$whiskey&lt;- car::recode(gdatac$whiskey, \"1:14=TRUE\")\ngdatac$whiskey&lt;- car::recode(gdatac$whiskey, \"15:93=FALSE\")\ngdatac$direction&lt;- car::recode(gdatac$direction,\n\"1=0;15=1;20=1;30=1;41=1;42=1;45=1;56=1;58=1;61=1;69=1;72=1;75=1;78=1;88=1;91=1;93=1\")\ngdatac$direction&lt;- car::recode(gdatac$direction, \"2:93=0\")\n\nSome other information was added: the maximum count and the number of clicks detected by each hydrophone,\nthe mean count of clicks for each hydrophone, and the number of hydrophones involved with each group.\n#Maximum count at a hydrophone\nmaxcount&lt;- with(gdatac,tapply(X = count, INDEX = gID, FUN = max))\n#Total count at all hydrophones\nnclicks&lt;- with(gdatac,tapply(X = count, INDEX = gID, FUN = sum))\n#Mean count at all hydrophones\nmeancount&lt;- with(gdatac,tapply(X = count, INDEX = gID, FUN = mean))\n#Number of hydrophones involved\nnhyd&lt;- with(gdatac,tapply(X = hyd, INDEX = gID, FUN = length))\n\nFurthermore, two different functions were built in order to differentiate the groups which were detected by at\nleast a Whiskey or a by Bi-directional hydrophone.\n#Whiskey hydrophone\nhas.wisk&lt;- function(dados){\n\nx = 0\nif (sum(dados%in%1:14)>0) x = 1\nreturn(x)\n\n2\n\n\n\n}\nwisk&lt;- with(gdatac,tapply(X = hyd, INDEX = gID, FUN = has.wisk))\n\n#Bi-directional hydrophone\ndirec&lt;- unique(gdatac$gID)\ni = 1\nfor (i in direc){\n\nx = 0\ng0&lt;- gdatac[gdatac$gID==i,]\nif (sum((g0$hyd%in%15|g0$hyd%in%20|g0$hyd%in%30|g0$hyd%in%41|\n\ng0$hyd%in%42|g0$hyd%in%45|g0$hyd%in%56|g0$hyd%in%58|\ng0$hyd%in%61|g0$hyd%in%69|g0$hyd%in%72|g0$hyd%in%75|\ng0$hyd%in%78|g0$hyd%in%88|g0$hyd%in%91|g0$hyd%in%93))>=1)\n\nx = 1\ndirec[i] = x\n\n}\n\nA further variable was added: the vocal click duration for each group.\n#Getting each group vocal period duration\ncdur&lt;- numeric(max(gdatac$gID))\nfor (i in 1:max(gdatac$gID)) {\n\ntemp1&lt;- gdatac$etime[gdatac$gID==i]\nge&lt;- max(temp1)\ntemp2&lt;- gdatac$stime[gdatac$gID==i]\ngs&lt;- min(temp2)\ncdur[i]&lt;- difftime(time1 = ge,time2 = gs,units = c(\"mins\"))\n\n}\n\nAlthough some of the previous information is not accounted as acoustic footprint, and will therefore not be\nincluded in the modelling process, it is always relevant to visualize and compare differences among the groups.\n\nFinally, the data is bundled up in a single data frame.\n#Modelling data frame\nd4reg&lt;- data.frame(gID = dados.mod2$gID, cs = dados.mod2$cs, conf = dados.mod2$conf,\n\nmaxcount = as.numeric(maxcount), meancount = as.numeric(meancount),\nnhyd = as.numeric(nhyd), cdur = as.numeric(cdur),\nnclicks = as.numeric(nclicks), crate = as.numeric(nclicks/cdur),\nwisk = as.numeric(wisk), direction = as.numeric(direc))\n\nA new variable, click rate (crate), was included in the data frame. Click rate is obtained simply by dividing\nthe corresponding group number of clicks by the click duration.\n\nSince the modelling process will resort not only to a zero-truncated approach GLM, a transformation of the\nresponse variable is needed so no zero values are predicted.\nd4reg$cs0&lt;- d4reg$cs-1\n\nAlso, it is important to factorize the Whiskey and Direction variables.\nd4reg$wisk&lt;- factor(d4reg$wisk)\nd4reg$direction&lt;- factor(d4reg$direction)\n\n3\n\n\n\n2.2 Exploratory analysis\n\nThe figure bellow reveals the number of clicks each hydrophone counted. It\u2019s important to have in account\nthe hydrophones numbered 1-14 are Whiskey, and the blue ones are Bi-directional.\n#Histogram, counts per hyd\nggplot(gdatac, aes(x = hyd, y = count,colour,fill = factor(direction,\n\nlabels = c(\"Uni\",\"Bi\")))) + geom_bar(stat=\"identity\") +\nscale_x_discrete(limits=c(1:93)) + ggtitle (\"Hydrophone click count\") +\nxlab(\"hydrophone\") + ylab(\"Click count\") +\ntheme(axis.text.x=element_text(size=5),axis.title=element_text(size=9,face=\"bold\")) +\nlabs(fill='Direction') + theme(plot.title=element_text(hjust = 0.5))\n\n0\n\n10000\n\n20000\n\n30000\n\n 1  2  3  4  5  6  7  8  9 101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293\n\nhydrophone\n\nC\nli\nc\nk\n\n c\no\n\nu\nn\n\nt\n\nDirection\nUni\nBi\n\nHydrophone click count\n\n#Percentage of clicks detected by Whiskey hydrophones\npwh&lt;- round(sum(gdatac$count[gdatac$whiskey==1])/sum(gdatac$count),2)*100\n\n#Percentage of clicks detected by non-Whiskey hydrophones\npnwh&lt;- round(sum(gdatac$count[gdatac$whiskey==0])/sum(gdatac$count),2)*100\n\nSimply by looking at the picture above it is noticeable the 14 Whiskey hydrophones (out of 93 total\nhydrophones) account for a considerable amount of clicks, which happens to be approximately 34%, while\nnon-Whiskey hydrophones account for 66%.\n\nBellow there is the number of clicks detected for each group.\nggplot(gdatac, aes(x = gID, y = count,colour)) +\n\ngeom_bar(stat=\"identity\") + scale_x_discrete(limits=c(1:51)) + labs(fill='Whiskey hyd') +\nggtitle (\"Click count per group\") + xlab(\"Groups\") + ylab (\"Click count\") +\ntheme(axis.text.x=element_text(size=5), axis.title=element_text(size=9,face=\"bold\")) +\ntheme(plot.title = element_text(hjust = 0.5)) + theme(aspect.ratio=3/5)\n\n4\n\n\n\n0\n\n10000\n\n20000\n\n30000\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51\n\nGroups\n\nC\nli\n\nc\nk\n\n c\no\n\nu\nn\n\nt\n\nClick count per group\n\ngn&lt;- with(gdatac,tapply(X = count, INDEX = gID, FUN = sum))\ngndata&lt;- order(gn, decreasing = TRUE)\n\nThe three groups with the most click counts are the numbers 13, 47, 43.\n\nThe figure bellow illustrates the response variable (Group/Cluster size) count.\nggplot(d4reg, aes(x = cs), geom = \"Count\") + stat_count() +\n\nscale_x_discrete(name =\"Cluster size\", limits=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\")) +\nylab (\"Count\")\n\n0\n\n5\n\n10\n\n15\n\n20\n\n1 2 3 4 5 6\nCluster size\n\nC\no\n\nu\nn\n\nt\n\nIt is also important to highlight it is taken into account in this study whether or not a hydrophone is located\non the edge. Since these type of hydrophones have a higher chance of capturing echolocations out of the\nconsidered area of 1291km2, it is more likely that they incorporate false positive detections. Edge hydrophones\ninclude numbers 1, 2, 3, 15, 16, 17, 20, 24, 25, 30, 34, 35, 41, 42, 46, 53, 56, 61, 64, 69, 72, 77, 78, 80, 85, 88,\n91, 92 and 93.\n\nThe response variable resembles a Poisson response. Although, if there are any signs of over dispersion it\nmeans a Negative Binomial approach may be useful. The mean count for the response variable is 2.57, while\nthe variance is 0.97. Since the variance is smaller than the mean, there appears to be no over dispersion,\nbut under dispersion instead. Additionally, the Negative Binomial approach raised warning messages as its\n\n5\n\n\n\nparameter was not able to converge and, therefore, will not be considered in the analysis. With this in mind,\nthe Poisson distribution appears to reasonably fit the response variable.\n\nFor the sake of academic curiosity, and since the standard R functions (in particular the Chi-square test)\ndo not support zero-truncated methods, we used an ad hoc approach to test if the Poisson response fits the\nmodified response variable (cs0), which was used for non-truncated GLM.\n#Defining sample size and the count for each response (using cs0)\nnd&lt;- length(d4reg$cs0)\na&lt;- length(which(d4reg$cs0==0))\nb&lt;- length(which(d4reg$cs0==1))\nc&lt;- length(which(d4reg$cs0==2))\nd&lt;- length(which(d4reg$cs0==3))\ne&lt;- length(which(d4reg$cs0==4))\nf&lt;- length(which(d4reg$cs0==5))\n\n#Creating a vector with the observed responses\nx&lt;- rep(0:5, times=c(a, b, c, d, e, f))\n\n#Empirical Poisson response with the observed responses mean value\nprobs&lt;- dpois(0:5, lambda=mean(x))\nprobp&lt;- as.integer(probs*nd)\nprobp&lt;- as.data.frame(probp)\n\n#Creating another vector with the empirical responses\nx1&lt;- c(rep(0,probp[1,]),rep(1,probp[2,]),rep(2,probp[3,]),\n\nrep(3,probp[4,]),rep(4,probp[5,]),rep(5,probp[6,]))\nprobp=as.data.frame(x1)\n\n#Contabilizing the remaining probabilities in order to include them in the test\ncomp&lt;- 1-sum(probs)\n\n#Chi-square test with 10000 p-value iterations (the zero includes \"comp\")\nchisq.test(x = c(a,b,c,d,e,f,0), p = c(probs, comp), simulate.p.value = TRUE, B = 10000)\n\n##\n## Chi-squared test for given probabilities with simulated p-value\n## (based on 10000 replicates)\n##\n## data: c(a, b, c, d, e, f, 0)\n## X-squared = 9.3333, df = NA, p-value = 0.154\n\nIt appears that the Poisson distribution fits well to the data.\n\n2.3 Univariate analysis\n\nBefore engaging in the modelling process it may be important to visualize how each explanatory variable\nbehaves.\n#Binary variables\nuni1&lt;- ggplot(d4reg,aes(x = wisk, y = cs)) + geom_violin(fill = \"orange\") +\n\nstat_summary(fun.y=median, geom=\"point\", size=2, color=\"black\") + xlab(\"Whiskey\") +\nylab (\"Cluster size\") + scale_x_discrete(labels=c(\"Non-whiskey\",\"Whiskey\")) +\ntheme_gray() + theme(plot.title = element_text(hjust = 0.5)) + ggtitle(\"Whiskey\")\n\n6\n\n\n\nuni2&lt;- ggplot(d4reg,aes(x = direction, y = cs)) + geom_violin(fill = \"orange\") +\nstat_summary(fun.y=median, geom=\"point\", size=2, color=\"black\") + xlab(\"Direction\") +\nylab (\"Cluster size\") + scale_x_discrete(labels=c(\"Uni\",\"Bi\")) + theme_gray() +\ntheme(plot.title = element_text(hjust = 0.5)) + ggtitle(\"Direction\")\n\n#Non-binary variables\nuni3&lt;- ggplot(d4reg, aes(y = cs, x = meancount)) + geom_point(size=1) +\n\nggtitle (\"Click mean count\") + scale_colour_manual(values=c(\"red\", \"blue\")) +\nxlab (\"Click meancount\") + theme(plot.title = element_text(hjust = 0.5)) +\n\ntheme_gray() + stat_smooth(method=\"glm\",size=1) + ylab(\"Cluster size\")\n\nuni4&lt;- ggplot(d4reg, aes(y = cs, x = nhyd)) + geom_point(size=1) +\nggtitle (\"Click mean count\") + scale_colour_manual(values=c(\"red\", \"blue\")) +\nxlab (\"Click meancount\") + theme(plot.title = element_text(hjust = 0.5)) +\n\ntheme_gray() + stat_smooth(method=\"glm\",size=1) + ylab(\"Cluster size\")\n\nuni5&lt;- ggplot(d4reg, aes(y = cs, x = cdur)) + geom_point(size=1) +\nggtitle (\"Click mean count\") + scale_colour_manual(values=c(\"red\", \"blue\")) +\nxlab (\"Click meancount\") + theme(plot.title = element_text(hjust = 0.5)) +\n\ntheme_gray() + stat_smooth(method=\"glm\",size=1) + ylab(\"Cluster size\")\n\nuni6&lt;- ggplot(d4reg, aes(y = cs, x = nclicks)) + geom_point(size=1) +\nggtitle (\"Click mean count\") + scale_colour_manual(values=c(\"red\", \"blue\")) +\nxlab (\"Click meancount\") + theme(plot.title = element_text(hjust = 0.5)) +\n\ntheme_gray() + stat_smooth(method=\"glm\",size=1) + ylab(\"Cluster size\")\n\nuni7&lt;- ggplot(d4reg, aes(y = cs, x = crate)) + geom_point(size=1) +\nggtitle (\"Click mean count\") + scale_colour_manual(values=c(\"red\", \"blue\")) +\nxlab (\"Click meancount\") + theme(plot.title = element_text(hjust = 0.5)) +\n\ntheme_gray() + stat_smooth(method=\"glm\",size=1) + ylab(\"Cluster size\")\n\nThe plots bellow illustrate each explanatory variable behaviour against the response variable.\nplot_grid(uni1, uni2, labels = c(\"A\", \"B\"))\n\n2\n\n4\n\n6\n\nNon?whiskey Whiskey\n\nWhiskey\n\nC\nlu\n\nst\ne\n\nr \nsi\n\nze\n\nWhiskeyA\n\n2\n\n4\n\n6\n\nUni Bi\n\nDirection\n\nC\nlu\n\nst\ne\n\nr \nsi\n\nze\n\nDirectionB\n\nIt is noticeable that while the group size decreases from non-Whiskey to Whiskey hydrophones, it increases\n\n7\n\n\n\nfrom Uni to Bi-directional hydrophones. It may be important to highlight that all the Whiskey hydrophones\nare Uni-directional.\nplot_grid(uni3, uni4, uni5, uni6,uni7, labels = c(\"C\", \"D\", \"E\", \"F\", \"G\"),\n\nncol = 2, nrow = 3)\n\n2\n\n4\n\n6\n\n0 500 1000 1500 2000\n\nClick meancount\n\nC\nlu\n\nst\ne\n\nr \nsi\n\nze\n\nClick mean countC\n\n2\n\n4\n\n6\n\n5 10 15 20\n\nClick meancount\n\nC\nlu\n\nst\ne\n\nr \nsi\n\nze\n\nClick mean countD\n\n2\n\n4\n\n6\n\n20 40 60 80\n\nClick meancount\n\nC\nlu\n\nst\ne\n\nr \nsi\n\nze\n\nClick mean countE\n\n2\n\n4\n\n6\n\n0 10000 20000 30000\n\nClick meancount\n\nC\nlu\n\nst\ne\n\nr \nsi\n\nze\n\nClick mean countF\n\n2\n\n4\n\n6\n\n0 200 400\n\nClick meancount\n\nC\nlu\n\nst\ne\n\nr \nsi\n\nze\n\nClick mean countG\n\nAll the other variables appear to increase along with the group size, specially click mean count, number\nof clicks, and click rate.\n\n2.4 Interaction\n\nIt is important to analyse the relationship between the explanatory variables and the response variable.\nInteraction occurs when the effect of a explanatory variable on another one is not constant as the effect is\nnot equal for different values the variable takes. This means a variable depends on the relationship between\n\n8\n\n\n\nthe interacting variables and not the variables themselves; which may have significant implications for the\ninterpretation of statistical models.\n#Between nhyd and wisk\nsummary(lm(d4reg$cs ~ d4reg$nhyd * d4reg$wisk)) #not significant\n\n#Between nhyd and direction\nsummary(lm(d4reg$cs ~ d4reg$nhyd * d4reg$direction)) #not significant\n\n#Between nhyd and crate\nsummary(lm(d4reg$cs ~ d4reg$nhyd * d4reg$crate)) #not significant\n\n#Between nhyd and cdur\nsummary(lm(d4reg$cs ~ d4reg$nhyd * d4reg$cdur)) #not significant\n\n#Between nhyd and meancount\nsummary(lm(d4reg$cs ~ d4reg$nhyd * d4reg$meancount)) #possibly not significant (0.089)\n\n#Between nhyd and nclicks\nsummary(lm(d4reg$cs ~ d4reg$nhyd * d4reg$nclicks)) #not significant\n\n#--\n\n#Between crate and wisk\nsummary(lm(d4reg$cs ~ d4reg$wisk * d4reg$crate)) #not significant\n\n#Between crate and direction\nsummary(lm(d4reg$cs ~ d4reg$crate * d4reg$direction)) #not significant\n\n#Between crate and cdur\nsummary(lm(d4reg$cs ~ d4reg$crate * d4reg$cdur)) #not significant\n\n#Between crate and meancount\nsummary(lm(d4reg$cs ~ d4reg$crate * d4reg$meancount)) #not significant\n\n#Between crate and nclicks\nsummary(lm(d4reg$cs ~ d4reg$crate * d4reg$nclicks)) #not significant\n\n#--\n\n#Between cdur and wisk\nsummary(lm(d4reg$cs ~ d4reg$wisk * d4reg$crate)) #not significant\n\n#Between cdur and direction\nsummary(lm(d4reg$cs ~ d4reg$crate * d4reg$direction)) #not significant\n\n#Between cdur and meancount\nsummary(lm(d4reg$cs ~ d4reg$cdur * d4reg$meancount)) #not significant\n\n#Between cdur and nclicks\nsummary(lm(d4reg$cs ~ d4reg$cdur * d4reg$nclicks)) #not significant\n\n#--\n\n9\n\n\n\n#Between meancount and wisk\nsummary(lm(d4reg$cs ~ d4reg$meancount * d4reg$wisk)) #not significant\n\n#Between meancount and direction\nsummary(lm(d4reg$cs ~ d4reg$meancount * d4reg$direction)) #not significant\n\n#Between meancount and nclicks\nsummary(lm(d4reg$cs ~ d4reg$meancount * d4reg$nclicks)) #not significant\n\n#--\n\n#Between direction and wisk\nsummary(lm(cs ~ direction+ wisk+ direction * wisk, data=d4reg)) #not significant\n\nAll the interactions are not significant for alpha=0.05. The only single significant interaction for alpha=0.01\nis between number of hydrophones and click mean count.\n\n2.5 Correlation\n\nCorrelation, whether causal or not, may indicate a predictive relationship that can be beneficial, since it may\nbe possible to predict a variable from another one.\n\nThe figure below starts with illustrating each non-binary variable behaviour against the other.\nplot(d4reg[5:9])\n\nmeancount\n\n5 15 0 20000\n\n5\n0\n\n0\n2\n\n0\n0\n\n0\n\n5\n1\n\n5\n\nnhyd\n\ncdur\n\n2\n0\n\n6\n0\n\n0\n2\n\n5\n0\n\n0\n0\n\nnclicks\n\n500 1500 20 60 0 200 500\n\n0\n3\n\n0\n0\n\ncrate\n\nThe two plots bellow also regard the non-binary variables: the first one holds the estimated Pearson\u2019s\ncoefficient values, and the second plot holds estimated Spearman\u2019s coefficient values.\n\n10\n\n\n\nxcorpearson&lt;- cor(d4reg[5:9], method = \"pearson\")\ncorrplot.mixed(xcorpearson)\n\n?1\n\n?0.8\n\n?0.6\n\n?0.4\n\n?0.2\n\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\nmeancount\n\nnhyd\n\ncdur\n\nnclicks\n\ncrate\n\n0.36\n\n0.69\n\n0.82\n\n0.63\n\n0.54\n\n0.73\n\n0.75\n\n0.71\n\n0.32 0.83\n\n#Estimated Pearson's coefficients\nround(xcorpearson,2)\n\n## meancount nhyd cdur nclicks crate\n## meancount 1.00 0.36 0.69 0.82 0.63\n## nhyd 0.36 1.00 0.54 0.73 0.75\n## cdur 0.69 0.54 1.00 0.71 0.32\n## nclicks 0.82 0.73 0.71 1.00 0.83\n## crate 0.63 0.75 0.32 0.83 1.00\nxcorspear&lt;- cor(d4reg[5:9], method = \"spearman\")\ncorrplot.mixed(xcorspear)\n\n?1\n\n?0.8\n\n?0.6\n\n?0.4\n\n?0.2\n\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\nmeancount\n\nnhyd\n\ncdur\n\nnclicks\n\ncrate\n\n0.31\n\n0.74\n\n0.78\n\n0.57\n\n0.52\n\n0.78\n\n0.75\n\n0.83\n\n0.34 0.78\n\n11\n\n\n\n#Estimated Spearman's coefficients\nround(xcorspear,2)\n\n## meancount nhyd cdur nclicks crate\n## meancount 1.00 0.31 0.74 0.78 0.57\n## nhyd 0.31 1.00 0.52 0.78 0.75\n## cdur 0.74 0.52 1.00 0.83 0.34\n## nclicks 0.78 0.78 0.83 1.00 0.78\n## crate 0.57 0.75 0.34 0.78 1.00\n\nBellow there are the Point-Biserial coefficients between the binary and non-binary variables.\n#nclicks &amp; direction/wisk\nct1&lt;- biserial.cor(d4reg$nclicks,d4reg$direction,level=2)\nct2&lt;- biserial.cor(d4reg$nclicks,d4reg$wisk,level=2)\n\n#cdur &amp; direction/wisk\nct3&lt;- biserial.cor(d4reg$cdur,d4reg$direction,level=2)\nct4&lt;- biserial.cor(d4reg$cdur,d4reg$wisk,level=2)\n\n#crate &amp; direction/wisk\nct5&lt;- biserial.cor(d4reg$crate,d4reg$direction,level=2)\nct6&lt;- biserial.cor(d4reg$crate,d4reg$wisk,level=2)\n\n#nhyd &amp; direction/wisk\nct7&lt;- biserial.cor(d4reg$nhyd,d4reg$direction,level=2)\nct8&lt;- biserial.cor(d4reg$nhyd,d4reg$wisk,level=2)\n\n#meancount &amp; direction/wisk\nct9&lt;- biserial.cor(d4reg$meancount,d4reg$direction,level=2)\nct10&lt;- biserial.cor(d4reg$meancount,d4reg$wisk,level=2)\n\ncttable&lt;- round(matrix(c(ct1,ct2,ct3,ct4,ct5,ct6,ct7,ct8,ct9,ct10),ncol=2,byrow=TRUE),2)\ncolnames(cttable)&lt;- c(\"direction\",\"wisk\")\nrownames(cttable)&lt;- c(\"nclicks\",\"cdur\",\"crate\",\"nhyd\",\"meancount\")\ncttable\n\n## direction wisk\n## nclicks -0.16 0.20\n## cdur -0.04 0.05\n## crate -0.18 0.31\n## nhyd -0.36 0.48\n## meancount 0.11 -0.08\n\nAnd there is also the Phi coefficient between both binary variables.\n#Phi coefficient\nbitab&lt;- with(d4reg, table(direction, wisk))\nbvar&lt;- matrix(c(phi(bitab)))\ncolnames(bvar)&lt;- c(\"direction\")\nrownames(bvar)&lt;- c(\"wisk\")\nbvar\n\n## direction\n## wisk -0.68\n\nAll the non-binary variables appear to be positively correlated. The two duos whose coefficients are closer to\n\n12\n\n\n\nzero are meancount &amp; nhyd, and cdur &amp; crate.\n\nAdditionally, some non-binary variables appear to correlate with direction and wisk, specially nhyd (positive\ncorrelation with wisk, and negative correlation with direction).\n\nFinally, both binary variables wisk and direction appear to be negatively correlated.\n\nDespite the correlation between variables, let us proceed with the modelling to see which of them appear to\nbe statistically significant.\n\n2.6 Modelling\n\nIn order to evaluate potential differences between the groups with different confidence levels, a new dataset\nonly containing the 43 groups with a confidence level of 1 was created.\n\nFurthermore, when attempting to fit a Negative Binomial response, a warning message prompts stating\nconvergence was not obtained for the theta value. According to literature, for very large theta values the\ncoefficient estimates are close to a Poisson distribution. (Klugman et al, 2004).\n#Creating a dataset with only the groups with conf=1\nd4regnew&lt;- d4reg[- c(which(d4reg$conf!=1)),]\n\n2.6.1 Non-truncated approach\n\nWe start with the non-truncated GLM method.\n\nConsidering all the 51 observations:\nmodel1&lt;- glm(cs0~meancount+cdur+nhyd+nclicks+crate+factor(wisk)\n\n+factor(direction), family=poisson, data=d4reg)\ndrop1(model1,test=\"F\") #remove direction\n\nmodel2&lt;- glm(cs0~meancount+cdur+nhyd+nclicks+crate+factor(wisk), family=poisson,\ndata=d4reg)\n\ndrop1(model2,test=\"F\") #remove nclicks\n\nmodel3&lt;- glm(cs0~meancount+cdur+nhyd+crate+factor(wisk), family=poisson, data=d4reg)\ndrop1(model3,test=\"F\") #remove meancount\n\nmodel4&lt;- glm(cs0~cdur+nhyd+crate+factor(wisk),family=poisson, data=d4reg)\ndrop1(model4,test=\"F\") #remove wisk\n\nmodel5&lt;- glm(cs0~nhyd+crate+cdur,family=poisson,data=d4reg)\ndrop1(model5,test=\"F\") #remove cdur\n\nmodel6&lt;- glm(cs0~crate+nhyd,family=poisson,data=d4reg)\ndrop1(model6,test=\"F\") #remove nhyd\n\nmodel7&lt;- glm(cs0~crate,family=poisson,data=d4reg)\n\n\u2022 model1: mean count + click duration + number of hydrophones + number of clicks + click rate +\nwhiskey + direction.\n\n\u2022 model2: mean count + click duration + number of hydrophones + number of clicks + click rate +\nwhiskey.\n\n\u2022 model3: mean count + click duration + number of hydrophones + click rate + whiskey.\n\n13\n\n\n\n\u2022 model4: click duration + number of hydrophones + click rate + whiskey.\n\n\u2022 model5: click duration + number of hydrophones + click rate.\n\n\u2022 model6: number of hydrophones + click rate.\n\n\u2022 model7: click rate.\naicglm1&lt;- c(AIC(model1), AIC(model2), AIC(model3), AIC(model4), AIC(model5),\n\nAIC(model6), AIC(model7))\nglm1&lt;- c(\"model1\",\"model2\",\"model3\",\"model4\",\"model5\",\"model6\",\"model7\")\nglmAIC1&lt;- matrix(aicglm1,ncol=1,byrow=TRUE)\nrownames(glmAIC1)&lt;- glm1\ncolnames(glmAIC1)&lt;- c(\"AIC\")\nkable(glmAIC1, caption = \"AIC values for the non-truncated GLM, n=51\")\n\nNow, non-truncated GLM with only the 43 groups with conf=1:\nmnew1&lt;- glm(cs0~meancount+cdur+nhyd+nclicks+crate+factor(wisk)\n\n+factor(direction), family=poisson, data=d4regnew)\ndrop1(mnew1,test=\"F\") #remove meancount\n\nmnew2&lt;- glm(cs0~cdur+nhyd+nclicks+crate+factor(wisk)+factor(direction), family=poisson,\ndata=d4regnew)\n\ndrop1(mnew2,test=\"F\") #remove direction\n\nmnew3&lt;- glm(cs0~cdur+nhyd+nclicks+crate+factor(wisk), family=poisson, data=d4regnew)\ndrop1(mnew3,test=\"F\") #remove nclicks\n\nmnew4&lt;- glm(cs0~cdur+nhyd+crate+factor(wisk),family=poisson, data=d4regnew)\ndrop1(mnew4,test=\"F\") #remove nhyd\n\nmnew5&lt;- glm(cs0~cdur+crate+factor(wisk),family=poisson,data=d4regnew)\ndrop1(mnew5,test=\"F\") #remove cdur\n\nmnew6&lt;- glm(cs0~crate+factor(wisk),family=poisson,data=d4regnew)\ndrop1(mnew6,test=\"F\") #remove wisk\n\nmnew7&lt;- glm(cs0~crate,family=poisson,data=d4regnew)\n\n\u2022 mnew1: mean count + click duration + number of hydrophones + number of clicks + click rate +\nwhiskey + direction.\n\n\u2022 mnew2: click duration + number of hydrophones + number of clicks + click rate + whiskey + direction.\n\n\u2022 mnew3: click duration + number of hydrophones + number of clicks + click rate + whiskey.\n\n\u2022 mnew4: click duration + number of hydrophones + click rate + whiskey.\n\n\u2022 mnew5: click duration + click rate + whiskey.\n\n\u2022 mnew6: click rate + whiskey.\n\n\u2022 mnew7: click rate.\naicglm2&lt;- c(AIC(mnew1), AIC(mnew2), AIC(mnew3), AIC(mnew4), AIC(mnew5),\n\nAIC(mnew6), AIC(mnew7))\nglm2&lt;- c(\"mnew1\",\"mnew2\",\"mnew3\",\"mnew4\",\"mnew5\",\"mnew6\",\"mnew7\")\nglmAIC2&lt;- matrix(aicglm2,ncol=1,byrow=TRUE)\nrownames(glmAIC2)&lt;- glm2\n\n14\n\n\n\ncolnames(glmAIC2)&lt;- c(\"AIC\")\nkable(glmAIC2, caption = \"AIC values for the non-truncated GLM, n=43\")\n\nTable 1: AIC values for the non-truncated GLM, n=43\n\nAIC\nmnew1 128.9031\nmnew2 126.9032\nmnew3 124.9752\nmnew4 123.1531\nmnew5 122.0444\nmnew6 120.4265\nmnew7 122.1139\n\nWhen considering all the 51 groups, the 3 best models include cdur, crate, and/or nhyd. Meanwhile, when\nusing the dataset with only 43 groups the variable nhyd is replaced by wisk. Although, they both share a\nmodel only containing the variable crate.\n\n2.6.2 Zero-truncated approach\n\nIn this section, zero-truncated GLM will be employed.\n\nBellow there are the results considering all the 51 observations:\nmp1&lt;- vglm(cs ~ meancount + cdur + nhyd + nclicks + crate + factor(wisk)\n\n+ factor(direction), family = pospoisson, data = d4reg)\nsummary(mp1)\n\nmp2&lt;- update(mp1, . ~ . - factor(direction))\nsummary(mp2)\n\nmp3&lt;- update(mp2, . ~ . - nclicks)\nsummary(mp3)\n\nmp4&lt;- update(mp3, . ~ . - meancount)\nsummary(mp4)\n\nmp5&lt;- update(mp4, . ~ . - factor(wisk))\nsummary(mp5)\n\nmp6&lt;- update(mp5, . ~ . - cdur)\nsummary(mp6)\n\nmp7&lt;- update(mp6, . ~ . - nhyd)\nsummary(mp7)\n\n\u2022 mp1: mean count + click duration + number of hydrophones + number of clicks + click rate + whiskey\n+ direction.\n\n\u2022 mp2: mean count + click duration + number of hydrophones + number of clicks + click rate + whiskey.\n\n\u2022 mp3: mean count + click duration + number of hydrophones + click rate + whiskey.\n\n\u2022 mp4: click duration + number of hydrophones + click rate + whiskey.\n\n15\n\n\n\n\u2022 mp5: click duration + number of hydrophones + click rate.\n\n\u2022 mp6: number of hydrophones + click rate.\n\n\u2022 mp7: click rate.\naict1&lt;- c(AIC(mp1), AIC(mp2), AIC(mp3), AIC(mp4), AIC(mp5), AIC(mp6), AIC(mp7))\ntglm1&lt;- c(\"mp1\",\"mp2\",\"mp3\",\"mp4\",\"mp5\",\"mp6\",\"mp7\")\nmtAIC1&lt;- matrix(aict1,ncol=1,byrow=TRUE)\nrownames(mtAIC1)&lt;- tglm1\ncolnames(mtAIC1)&lt;- c(\"AIC\")\n\nkable(mtAIC1, caption = \"AIC values for the zero-truncated GLM, n=51\")\n\nTable 2: AIC values for the zero-truncated GLM, n=51\n\nAIC\nmp1 157.5694\nmp2 155.5757\nmp3 153.5909\nmp4 151.6625\nmp5 150.4935\nmp6 150.7108\nmp7 150.5499\n\nAnd now, only with the 43 groups:\nmpn1&lt;- vglm(cs ~ meancount + cdur + nhyd + nclicks + crate + factor(wisk)\n\n+ factor(direction), family = pospoisson, data = d4regnew)\nsummary(mpn1)\n\nmpn2&lt;- update(mpn1, . ~ . - meancount)\nsummary(mpn2)\n\nmpn3&lt;- update(mpn2, . ~ . - factor(direction))\nsummary(mpn3)\n\nmpn4&lt;- update(mpn3, . ~ . - nclicks)\nsummary(mpn4)\n\nmpn5&lt;- update(mpn4, . ~ . - nhyd)\nsummary(mpn5)\n\nmpn6&lt;- update(mpn5, . ~ . - cdur)\nsummary(mpn6)\n\nmpn7&lt;- update(mpn6, . ~ . - factor(wisk))\nsummary(mpn7)\n\n\u2022 mpn1: mean count + click duration + number of hydrophones + number of clicks + click rate +\nwhiskey + direction.\n\n\u2022 mpn2: click duration + number of hydrophones + number of clicks + click rate + whiskey + direction.\n\n\u2022 mpn3: click duration + number of hydrophones + number of clicks + click rate + whiskey.\n\n16\n\n\n\n\u2022 mpn4: click duration + number of hydrophones + click rate + whiskey.\n\n\u2022 mpn5: click duration + click rate + whiskey.\n\n\u2022 mpn6: click rate + whiskey.\n\n\u2022 mpn7: click rate.\naict2&lt;- c(AIC(mp1), AIC(mp2), AIC(mp3), AIC(mp4), AIC(mp5), AIC(mp6), AIC(mp7))\ntglm2&lt;- c(\"mp1\",\"mp2\",\"mp3\",\"mp4\",\"mp5\",\"mp6\",\"mp7\")\nmtAIC2&lt;- matrix(aict2,ncol=1,byrow=TRUE)\nrownames(mtAIC2)&lt;- tglm2\ncolnames(mtAIC2)&lt;- c(\"AIC\")\n\nkable(mtAIC2, caption = \"AIC values for the zero-truncated GLM, n=43\")\n\nTable 3: AIC values for the zero-truncated GLM, n=43\n\nAIC\nmp1 157.5694\nmp2 155.5757\nmp3 153.5909\nmp4 151.6625\nmp5 150.4935\nmp6 150.7108\nmp7 150.5499\n\nNote that both non-truncated and zero-truncated GLM select the same variables when considering the same\nnumber of observations.\n\nThe model with the single variable crate appears to be the best one to describe the response variable.\n\n2.6.2.1 Analysing the model\n\n2.6.2.1.1 Residuals\n\nFirst, we test for the normality of the residuals.\nmp7&lt;- vglm(cs ~ crate, family = pospoisson, data = d4reg)\nshapiro.test(residuals(mp7,type=\"pearson\"))\n\n##\n## Shapiro-Wilk normality test\n##\n## data: residuals(mp7, type = \"pearson\")\n## W = 0.97532, p-value = 0.3626\n\nNormality is not rejected.\n\nThe figure bellow illustrates the residuals vs fitted values behaviour, with a scatter plot smoother in grey:\ntheme_set(theme_grey())\noutput&lt;- data.frame(resid = resid(mp7), fitted = fitted(mp7))\nggplot(output, aes(fitted, resid)) +\n\ngeom_jitter(size=1)+ stat_smooth(method=\"loess\")\n\n17\n\n\n\n?0.5\n\n0.0\n\n0.5\n\n1.0\n\n2.0 2.5 3.0 3.5 4.0\n\nfitted\n\nre\nsi\n\nd\n\nChecking if the residuals and the fitted values are correlated:\ncor.test(fitted(mp7), resid(mp7))\n\n##\n## Pearson's product-moment correlation\n##\n## data: fitted(mp7) and resid(mp7)\n## t = -0.1068, df = 49, p-value = 0.9154\n## alternative hypothesis: true correlation is not equal to 0\n## 95 percent confidence interval:\n## -0.2896211 0.2614278\n## sample estimates:\n## cor\n## -0.01525496\n\nThey appear to not be correlated.\n\n2.6.2.1.2 Hat Values\noutput2&lt;- data.frame(resid = resid(mp7, \"pearson\"), hatv = hatvalues(mp7))\nnames(output2)[2]&lt;-\"hatv\"\nggplot(output2, aes(resid, hatv)) + geom_point() + ylab(\"Hat values\") + xlab (\"Residuals\")\n\n18\n\n\n\n0.1\n\n0.2\n\n0.3\n\n?1.0 ?0.5 0.0 0.5 1.0\n\nResiduals\n\nH\na\n\nt \nva\n\nlu\ne\n\ns\n\n#Obtaining the highest hat values\nnlength&lt;- length(d4reg$gID)\nhvthres&lt;- (2*sum(hatvalues(mp7)))/nlength\nhv&lt;- which(output2$hatv>hvthres)\n\nThe observations with the highest hat values are 13, 47.\n\nIn order to see how much influence these points have, let us rebuild the model without them.\n#Building a new dataset without the influential values\nd4regnewh1=d4reg[- c(hv),]\n\nmpnh1&lt;- vglm(cs ~ meancount + cdur + nhyd + nclicks + crate + factor(wisk)\n+ factor(direction), family = pospoisson, data = d4regnewh1)\n\nsummary(mpnh1)\n\nmpnh2&lt;- update(mpnh1, . ~ . - factor(direction))\nsummary(mpnh2)\n\nmpnh3&lt;- update(mpnh2, . ~ . - nclicks)\nsummary(mpnh3)\n\nmpnh4&lt;- update(mpnh3, . ~ . - meancount)\nsummary(mpnh4)\n\nmpnh5&lt;- update(mpnh4, . ~ . - factor(wisk))\nsummary(mpnh5)\n\nmpnh6&lt;- update(mpnh5, . ~ . - cdur)\nsummary(mpnh6)\n\nmpnh7&lt;- update(mpnh6, . ~ . - nhyd)\nsummary(mpnh7)\n\n\u2022 mpnh1: mean count + click duration + number of hydrophones + number of clicks + click rate +\nwhiskey + direction.\n\n19\n\n\n\n\u2022 mpnh2: mean count + click duration + number of hydrophones + number of clicks + click rate +\nwhiskey.\n\n\u2022 mpnh3: mean count + click duration + number of hydrophones + click rate + whiskey.\n\n\u2022 mpnh4: click duration + number of hydrophones + click rate + whiskey.\n\n\u2022 mpnh5: click duration + number of hydrophones + click rate.\n\n\u2022 mpnh6: number of hydrophones + click rate.\n\n\u2022 mpnh7: click rate.\naich1&lt;- c(AIC(mpnh1), AIC(mpnh2), AIC(mpnh3), AIC(mpnh4), AIC(mpnh5), AIC(mpnh6),\n\nAIC(mpnh7))\nmhat1&lt;- c(\"mpnh1\",\"mpnh2\",\"mpnh3\",\"mpnh4\",\"mpnh5\",\"mpnh6\",\"mpnh7\")\nmhAIC1&lt;- matrix(aich1,ncol=1,byrow=TRUE)\nrownames(mhAIC1)&lt;- mhat1\ncolnames(mhAIC1)&lt;- c(\"AIC\")\n\nkable(mhAIC1, caption = \"AIC values for zero-truncated GLM, n=49\")\n\nTable 4: AIC values for zero-truncated GLM, n=49\n\nAIC\nmpnh1 149.9548\nmpnh2 147.9566\nmpnh3 145.9748\nmpnh4 144.0410\nmpnh5 142.7658\nmpnh6 142.9766\nmpnh7 142.9038\n\nNow, modelling without the hat values and only with the observations with conf=1:\nhv2&lt;- which(d4reg$conf!=1 | hatvalues(mp7)>(2*sum(hatvalues(mp7))/51))\nd4regnewh2=d4reg[- hv2,]\n\nmpnhc1&lt;- vglm(cs ~ meancount + cdur + nhyd + nclicks + crate + factor(wisk) +\nfactor(direction), family =pospoisson, data = d4regnewh2)\n\nsummary(mpnhc1)\n\nmpnhc2&lt;- update(mpnhc1, . ~ . - factor(direction))\nsummary(mpnhc2)\n\nmpnhc3&lt;- update(mpnhc2, . ~ . - nhyd)\nsummary(mpnhc3)\n\nmpnhc4&lt;- update(mpnhc3, . ~ . - cdur)\nsummary(mpnhc4)\n\nmpnhc5&lt;- update(mpnhc4, . ~ . - nclicks)\nsummary(mpnhc5)\n\nmpnhc6&lt;- update(mpnhc5, . ~ . - meancount)\nsummary(mpnhc6)\n\n20\n\n\n\nmpnhc7&lt;- update(mpnhc6, . ~ . - crate)\nsummary(mpnhc7)\n\nmpnhc8&lt;- update(mpnhc7, . ~ . - factor(wisk))\nsummary(mpnhc8)\n\n\u2022 mpnhc1: mean count + click duration + number of hydrophones + number of clicks + click rate +\nwhiskey + direction.\n\n\u2022 mpnhc2: mean count + click duration + number of hydrophones + number of clicks + click rate +\nwhiskey.\n\n\u2022 mpnhc3: mean count + click duration + number of clicks + click rate + whiskey.\n\n\u2022 mpnhc4: mean count + number of clicks + click rate + whiskey.\n\n\u2022 mpnhc5: mean count + click rate + whiskey.\n\n\u2022 mpnhc6: click rate + whiskey.\n\n\u2022 mpnhc7: click rate.\naich2&lt;- c(AIC(mpnhc1), AIC(mpnhc2), AIC(mpnhc3), AIC(mpnhc4),\n\nAIC(mpnhc5), AIC(mpnhc6), AIC(mpnhc7))\nmhat2&lt;- c(\"mpnhc1\",\"mpnhc2\",\"mpnhc3\",\"mpnhc4\",\"mpnhc5\",\"mpnhc6\",\"mpnhc7\")\nmhAIC2&lt;- matrix(aich2,ncol=1,byrow=TRUE)\nrownames(mhAIC2)&lt;- mhat2\ncolnames(mhAIC2)&lt;- c(\"AIC\")\n\nkable(mhAIC2, caption = \"AIC values for zero-truncated GLM, n=43\")\n\nTable 5: AIC values for zero-truncated GLM, n=43\n\nAIC\nmpnhc1 128.3319\nmpnhc2 126.3888\nmpnhc3 124.4536\nmpnhc4 123.0695\nmpnhc5 121.2859\nmpnhc6 119.9851\nmpnhc7 120.9000\n\nWe may see that removing more variables on an already small dataset leads to new variables to be chosen,\nand smaller coefficients of significance. Therefore, in order to include all the information, no observations\nwere removed and the analysis proceeded with the model mp7.\n\n3 The Density Estimation Dataset.\n\nA second dataset (with unknown group sizes) will be used to estimate group sizes based on the model\nthat related group size to acoustic footprint, which will then allow the density estimation over time. It\ncontemplates three different time periods from 2011, covering a total of 113 days. However, 4 out of 113 these\ndays were only partially sampled. Given our objective of producing density estimates per day, it is simpler to\nconsider only the 109 days for which we have 24 hours of recording, and hence these incomplete days were\ndiscarded from further analysis.\n\n21\n\n\n\nThe considered time periods are: (1) from the 28th of April to the 27th of June; (2) from the 20th of October\nto the 6th of November; and (3) from the 2nd to the 31st of December.\n\nThe code bellow describes how it was built:\ndados&lt;- read.table(\"dadostodos.txt\", header=T)\ndados.ghyd&lt;- dados\n\n#Sort the data by group number, then by hydrophone\ndados.ghyd&lt;- dados.ghyd[order(dados.ghyd$GroupNum,dados.ghyd$hyd),]\n#-------------------------------------------------------\n#Some hydrophones are included in multiple rows in the same group\n#Put all in the same row. Creating an unique indicator\ndados.ghyd$ghyd&lt;- with(dados.ghyd,paste(GroupNum,hyd,sep=\".\"))\n\n#Now get the GroupNum\ngroupnum&lt;- with(dados.ghyd,tapply(X=GroupNum, INDEX=ghyd, FUN = mean))\n\n#Now get the hyd\nhyd&lt;- with(dados.ghyd,tapply(X=hyd, INDEX=ghyd, FUN = mean))\n\n#Now get the total click count\nclickcnt&lt;- with(dados.ghyd,tapply(X=clickcnt, INDEX=ghyd, FUN = sum))\n\n#Now get the start - i.e. the minimum\nstart&lt;- with(dados.ghyd,tapply(X=start, INDEX=ghyd, FUN = min))\n\n#Now get the end - i.e. the maximum\nend&lt;- with(dados.ghyd,tapply(X=end, INDEX=ghyd, FUN = max))\n\n#Now get the minimum ici (this might be the best group size predictor)\nmici&lt;- with(dados.ghyd,tapply(X=ici, INDEX=ghyd, FUN = min))\n\n#Now get how many times that hyd was repeated\nhydreps&lt;- with(dados.ghyd,tapply(X=hyd, INDEX=ghyd, FUN = length))\n\n#Finally, bundle in the same data frame\ndados.nrhyds&lt;- data.frame(GroupNum=groupnum, hyd=hyd, clickcnt=clickcnt, start=start,\n\nend=end,mici=mici)\n\n#Lets create a new column, with the time duration of the click detection\ndados.nrhyds[\"clickdur\"]&lt;- NA\ndados.nrhyds$clickdur&lt;- dados.nrhyds$end-dados.nrhyds$start\n\n#And sort again as the tapply function messes up with sorting\ndados.nrhyds&lt;- dados.nrhyds[order(dados.nrhyds$GroupNum,dados.nrhyds$hyd),]\n\n#Now add whether phones are edge phone or not\nedgehyds&lt;- c(1,2,3,15,16,17,20,24,25,30,34,35,41,42,46,53,56,61,64,69,\n\n72,77,78,80,85,88,91,92,93)\ndados.nrhyds$edge&lt;- dados.nrhyds$hyd %in% edgehyds\n\n#Adding a whiskey/non-whiskey column\ndados.nrhyds[\"whiskey\"]&lt;- dados.nrhyds$hyd\ndados.nrhyds$whiskey&lt;- car::recode(dados.nrhyds$whiskey, \"1:14=TRUE\")\n\n22\n\n\n\ndados.nrhyds$whiskey&lt;- car::recode(dados.nrhyds$whiskey, \"15:93=FALSE\")\nwhiskey01&lt;- c(1)\ndados.nrhyds$whiskey&lt;- dados.nrhyds$whiskey %in% whiskey01\n\n#Adding a bi/uni directional column\ndados.nrhyds[\"direction\"]&lt;- dados.nrhyds$hyd\ndados.nrhyds$direction&lt;- car::recode(dados.nrhyds$direction, \"1=0 ; 15=1; 20=1; 30=1;\n41=1; 42=1; 45=1; 56=1; 58=1; 61=1; 69=1; 72=1; 75=1;\n78=1; 88=1; 91=1; 93=1\")\ndados.nrhyds$direction&lt;- car::recode(dados.nrhyds$direction, \"2:93=0\")\ndirection01&lt;- c(1)\ndados.nrhyds$direction&lt;- dados.nrhyds$direction %in% direction01\n\n#Obtaining some relevant variables by group\n\n#Getting the group's ID\ngroupnum2&lt;- with(dados.nrhyds,tapply(X=GroupNum, INDEX=GroupNum, FUN = mean))\n\n#Number of hyds it was detected at\nnhyd&lt;- with(dados.nrhyds,tapply(X=hyd, INDEX=GroupNum, FUN = length))\n\n#Total clicks\nnclick&lt;- with(dados.nrhyds,tapply(X=clickcnt, INDEX=GroupNum, FUN = sum))\n\n#Get the start - i.e. the minimum\nstart&lt;- with(dados.nrhyds,tapply(X=start, INDEX=GroupNum, FUN = min))\n\n#Get the end - i.e. the maximum\nend&lt;- with(dados.nrhyds,tapply(X=end, INDEX=GroupNum, FUN = max))\n\n#Now get the minimum ici\nici&lt;- with(dados.nrhyds,tapply(X=mici, INDEX=GroupNum, FUN = min))\n\n#And finally, define whether all hydrophones were edge phones\n#which happens to be the case if the minimum value on the\n#edge variable is 0 (if there's at least a non edge phone it becomes 0)\nedge&lt;- with(dados.nrhyds,tapply(X=edge, INDEX=GroupNum, FUN = min))\n\n#Create an object to hold the data by groups\ndados.groups&lt;- data.frame(GroupNum=groupnum2,nhyd=nhyd,clickcnt=nclick,start=start,\n\nend=end,ici=ici,edge=edge)\n\n#Select groups which were detected on a single hydrophone only\n#these are likely false positives\ndados.groups$unihyd&lt;- ifelse(dados.groups$nhyd==1,1,0)\n\n#Select groups for whick less than tresh clicks were detected\ntresh&lt;- 400\ndados.groups$tresh&lt;- ifelse(dados.groups$clickcnt<tresh,1,0)\n\n#The following variable can be used to select\n#only those thought to be true positives\ndados.groups$tps&lt;- with(dados.groups,edge+unihyd+tresh==0)\n\n23\n\n\n\n#Selecting that as a separate data frame\ndados.filtered&lt;- dados.groups[dados.groups$tps==1,]\n\n#Time periods\ndados.filtered[\"period\"]&lt;- dados.filtered$start\ndados.filtered$period&lt;- car::recode(dados.filtered$period, \"1:15200=1\")\ndados.filtered$period&lt;- car::recode(dados.filtered$period, \"15201:15300=2\")\ndados.filtered$period&lt;- car::recode(dados.filtered$period, \"15301:15400=3\")\n\n#Click duration\ndados.filtered[\"clickdur\"]&lt;- NA\ndados.filtered$clickdur&lt;- dados.filtered$end-dados.filtered$start\n#It is in days, lets put it in minutes\ndados.filtered$clickdur&lt;- (dados.filtered$clickdur)*24 #it is now in hours\ndados.filtered$clickdur&lt;- (dados.filtered$clickdur)*60 #it is now in minutes\n\n#Click rate\ndados.filtered[\"crate\"]&lt;- NA\ndados.filtered$crate&lt;- (dados.filtered$clickcnt)/(dados.filtered$clickdur)\n\n#Cluster size\ndados.filtered[\"cs\"]&lt;- NA\n\n#Date\ndados.filtered[\"date\"]&lt;- NA\ndados.filtered[\"date\"]&lt;- as.Date(dados.filtered$start, origin = \"1970-01-01\")\n\n#Julian date\ndados.filtered[\"day\"]&lt;- NA\ntmp&lt;- as.POSIXlt(dados.filtered$date, format = \"%y%d%b\")\ntmp&lt;- format(tmp, \"%j\")\ndados.filtered$day&lt;- tmp\n\n#Date with hours\nstartd&lt;- dados.filtered$start\ntmd&lt;- as.POSIXlt(startd*60*60*24, origin=\"1970-01-01\", tz = \"UTC\")\ndados.filtered$time&lt;- tmd\ndados.filtered$time[1]\n\n#Removing days without 24 hours, we already know their numbers\nddf&lt;- c(which(dados.filtered$day==117 | dados.filtered$day==292\n\n| dados.filtered$day==311 | dados.filtered$day==335))\n\ndados.filtered&lt;- dados.filtered[-c(ddf),]\n\nperiod1&lt;- dados.filtered[dados.filtered$period==1,]\nperiod2&lt;- dados.filtered[dados.filtered$period==2,]\nperiod3&lt;- dados.filtered[dados.filtered$period==3,]\n\nNow, using the previous model to predict the group size:\ndados.filtered[\"cs\"]&lt;- predict(mp7, dados.filtered, type=\"response\")\n\nAnd creating a new dataset regarding the information per day:\n\n24\n\n\n\n#Cluster size mean for each day\nmeancs&lt;- with(dados.filtered,tapply(X=cs, INDEX=day, FUN = mean))\n\ndados.filtered$time&lt;- as.POSIXct(dados.filtered$time,format = \"%d%m%Y %H:%M:%S\",tz=\"UTC\")\ndados.filtered$time&lt;- ymd_hms(dados.filtered$time)\n\nas.numeric(difftime(dados.filtered$time[2], dados.filtered$time[1], tz=\"UTC\",\nunits = c(\"hours\")))\n\nt.str&lt;- strptime(dados.filtered$time, \"%Y-%m-%d %H:%M:%S\", tz=\"UTC\")\nt.lub&lt;- ymd_hms(dados.filtered$time)\n\n#Extract decimal hours\nh.str&lt;- as.numeric(format(t.str, \"%H\")) +\n\nas.numeric(format(t.str, \"%M\"))/60\n\n#Adding a collumn for decimal hours\ndados.filtered$hours&lt;- h.str\n\n#The amount of hours per day the click detection occurred\n#(just for curiosity, wont be used)\nmaxhours&lt;- with(dados.filtered,tapply(X=hours, INDEX=day, FUN = max))\nminhours&lt;- with(dados.filtered,tapply(X=hours, INDEX=day, FUN = min))\ninthours&lt;- maxhours-minhours\n\n#The number of groups detected per day\nngday&lt;- as.numeric(with(dados.filtered,tapply(X=GroupNum, INDEX=day, FUN = length)))\n\n#Creating new data frame uniquely for days\nudngroup&lt;- with(dados.filtered,tapply(X=GroupNum, INDEX=day, FUN = length))\n\n#Number of groups for each day\nudhyd&lt;- with(dados.filtered,tapply(X=nhyd, INDEX=day, FUN = sum))\nudnclick&lt;- with(dados.filtered,tapply(X=clickcnt, INDEX=day, FUN = sum))\nudici&lt;- with(dados.filtered,tapply(X=ici, INDEX=day, FUN = min))\nudperiod&lt;- with(dados.filtered,tapply(X=period, INDEX=day, FUN = mean))\nudcrate&lt;- with(dados.filtered,tapply(X=crate, INDEX=day, FUN = mean))\nudcs&lt;- with(dados.filtered,tapply(X=cs, INDEX=day, FUN = mean))\nuday&lt;- unique(dados.filtered$day)\n\nrd=0.36\narea=1291\nintdays&lt;- inthours/24\nNh&lt;- (ngday*meancs)/(rd*inthours) #abundance per hour\nNd&lt;- (ngday*meancs)/(rd*intdays) #abundance per day\n\n#Assembling the new dataset\ndados.eachday&lt;- data.frame(groups=as.numeric(udngroup), nhyd=as.numeric(udhyd),\n\nnclick=as.numeric(udnclick), ici=as.numeric(udici),\nperiod=as.numeric(udperiod), crate=as.numeric(udcrate),\nmcs=as.numeric(udcs), day=as.numeric(uday),\ntime=as.numeric(minhours), etime=as.numeric(maxhours),\nttime=as.numeric(inthours))\n\n25\n\n\n\ndados.eachday$abundancy&lt;- ((dados.eachday$groups)*(dados.eachday$mcs))/(rd*24)\ndados.eachday$density&lt;- dados.eachday$abundancy/area*1000\n\nNow, the plots for each time period illustrating the estimated density:\nplot.ed1&lt;- ggplot(data=dados.eachday[dados.eachday$period==1,],aes(x= day, y = density))\nplot.ed1 + geom_point(size=1) + scale_y_continuous(limits = c(0, 40)) +\n\nggtitle(\"Estimated Density (whales/1000km2) for Period 1\")\n\n0\n\n10\n\n20\n\n30\n\n40\n\n120 140 160 180\n\nday\n\nd\ne\n\nn\nsi\n\nty\n\nEstimated Density (whales/1000km2) for Period 1\n\nplot.ed2&lt;- ggplot(data=dados.eachday[dados.eachday$period==2,],aes(x= day, y = density))\nplot.ed2 + geom_point(size=1) + scale_y_continuous(limits = c(0, 40)) +\n\nggtitle(\"Estimated Density (whales/1000km2) for Period 2\")\n\n0\n\n10\n\n20\n\n30\n\n40\n\n295 300 305 310\n\nday\n\nd\ne\n\nn\nsi\n\nty\n\nEstimated Density (whales/1000km2) for Period 2\n\nplot.ed3&lt;- ggplot(data=dados.eachday[dados.eachday$period==3,],aes(x= day, y = density))\nplot.ed3 + geom_point(size=1) + scale_y_continuous(limits = c(0, 40)) +\n\nggtitle(\"Estimated Density (whales/1000km2) for Period 3\")\n\n26\n\n\n\n0\n\n10\n\n20\n\n30\n\n40\n\n340 350 360\n\nday\n\nd\ne\n\nn\nsi\n\nty\n\nEstimated Density (whales/1000km2) for Period 3\n\n4 Bootstrap\n\nThe final task is to propagate the variance in the model of group size thorough the estimates of variance\nof density per day. Therefore, the modelling dataset will be re-sampled 999 times. For each re-sample, the\nmodel selected for inference will be refit. This will therefore lead to new parameter estimates, and hence,\ncorresponding different predictions for each of the groups sizes one needs to predict.\nset.seed(12397)\nB&lt;- 999\nres&lt;- numeric(B)\ngrupospredboot&lt;- matrix(NA,nrow=nrow(dados.filtered),ncol=999)\n\ntableboot&lt;- dados.filtered\ntab99&lt;- matrix(nrow=8271,ncol=999)\ntableboot&lt;- cbind(tableboot, tab99)\n\nfor(i in 1:B){\nindex = sample(1:51,51,replace=TRUE)\ndados4boot = d4reg[index,]\nmp7boot = vglm(formula = cs ~ crate, family = pospoisson, data = dados4boot)\npreds = predict(mp7boot,dados.filtered, type=\"response\")\ntableboot[,i+19] = preds\n\n}\n\n#Obtaining the cs mean for each day (mean within boostraps)\ntablebootday&lt;- matrix(nrow=109,ncol=999)\nB&lt;- 999\nfor (i in 20:(20+B-1)){\n#Cluster size mean for each day\ntablebootday[,i-19] = tapply(X=tableboot[,i],INDEX=tableboot$day,FUN=mean)\n}\n\n#Density bootstrap\nrdboot&lt;- rnorm(999,0.36,0.04)\n\n27\n\n\n\ntableboottot&lt;- matrix(nrow=109,ncol=999)\ntablebootfix&lt;- as.data.frame(tablebootday)\nttime&lt;- dados.eachday$ttime\nngroups&lt;- dados.eachday$groups\ntablebootday&lt;- rbind(tablebootday,rdboot)\n\n#Function which calculates density for each cell\nfdens&lt;- function(x,y) #x=column, y=line\n{ (((ngroups[y])*tablebootday[y,][x])/((tablebootday[110,][x])*ttime[y]))/1291*1000\n}\nfor (i in 1:999){\n\nfor (j in 1:109){\ntableboottot[j,][i] = fdens(i,j) }\n\n}\n\ntableboottot = as.data.frame(tableboottot,header=F)\n\nBoostrap plots:\n#Click rate\nfcrate&lt;- dados.eachday$crate\ntablebootdens&lt;- tableboottot\ntablebootdens&lt;- cbind(tablebootdens,fcrate)\ntablebootcs&lt;- tablebootfix\ntablebootcs&lt;- cbind(tablebootcs,fcrate)\n\nmeltcs&lt;- melt(tablebootcs,id=\"fcrate\")\nggplot(meltcs,aes(x=fcrate,y=value,colour=variable,group=variable))+\n\ngeom_point(size=0.5) + theme(legend.position=\"none\") +\nggtitle(\"Bootstrap Results Considering Each Click Rate value\")\n\n1.8\n\n2.2\n\n2.6\n\n3.0\n\n120 160 200 240\n\nfcrate\n\nva\nlu\n\ne\n\nBootstrap Results Considering Each Click Rate value\n\n28\n\n\n\n#Density\njdays109&lt;- as.numeric(unique(dados.filtered$day))\n\ndaydens&lt;-tablebootdens[-1000]\ndaydens&lt;- cbind(daydens,jdays109)\nmeltdaydens&lt;- melt(daydens,id=\"jdays109\")\n\nggplot(meltdaydens,aes(x = jdays109,y = value,colour = variable,group = variable)) +\ngeom_point(size=0.8) + theme(legend.position=\"none\") +\nxlab(\"Day\") + ylab (\"Density\") +\nscale_x_continuous(breaks=c(120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230,\n\n240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340,\n350, 360))+ggtitle(\"Bootstrap Results Considering Each Day\")\n\n20\n\n40\n\n60\n\n120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360\n\nDay\n\nD\ne\n\nn\nsi\n\nty\n\nBootstrap Results Considering Each Day\n\n5 Conclusions\n\nIt may be concluded, based on the acoustic footprint of groups detected on AUTEC hydrophones, that the\nvariable click rate appears to be the best descriptor of group size. However, when it comes to modelling, it\nis noticeable that more observations may be needed, as a small data set will never allow a complex model to\nbe a parsimonious choice. Therefore, it is possible that with additional data more complex models might\nprove useful to describe group size from the group\u2019s acoustical footprint. Although the model composed solely\nby the click rate variable was always among the models\u2019 top 3, the variable number of hydrophones was\nreplaced by whiskey hydrophones on the remaining two models when only considering the groups with a\nconfidence level of 1. This may indicate difficulties when choosing between variables. Nevertheless, the model\nmp7 appears to reasonably describe the response variable. In the future, more data shall be added to the\nmodelling dataset.\n\n29\n\n\n\tIntroduction\n\tThe Modelling Dataset\n\tReading and preparing the data\n\tExploratory analysis\n\tUnivariate analysis\n\tInteraction\n\tCorrelation\n\tModelling\n\tNon-truncated approach\n\tZero-truncated approach\n\n\n\tThe Density Estimation Dataset.\n\tBootstrap\n\tConclusions"}]}}}