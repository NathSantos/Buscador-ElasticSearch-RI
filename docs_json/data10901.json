{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.14577"}, {"@name": "filename", "#text": "20935_108860.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNIVERSIDADE FEDERAL DE SANTA CATARINA \nPROGRAMA DE P\u00d3S-GRADUA\u00c7\u00c3O EM ENGENHARIA\n\nDE PRODU\u00c7\u00c3O\n\nUM PROCEDIMENTO PARA AVALIA\u00c7\u00c3O DA \nSA\u00daDE FINACEIRA DE PEQUENAS EMPRESAS: \n\nESTUDO DE UM CASO USANDO REDES \nNEURONAIS ARTIFICIAIS\n\nGERTRUDES APARECIDA DANDOLINI\n\nDisserta\u00e7\u00e3o submetida ao Programa de P\u00f3s-Gradua\u00e7\u00e3o em \nEngenharia de produ\u00e7\u00e3o da Universidade Federal de Santa Catarina para \nobten\u00e7\u00e3o do Graus de Mestre em Engenharia, com especialidade em \nEngenharia de Produ\u00e7\u00e3o.\n\nBU\nFlorian\u00f3polis\n\nNovembro/1997\n\n\n\nn\n\nGERTRUDES APARECIDA DANDOLINI\n\nUM PROCEDIMENTO PARA AVALIA\u00c7\u00c3O DA SA\u00daDE \nFINACEIRA DE PEQUENAS EMPRESAS: ESTUDO DE UM \n\nCASO USANDO REDES NEURONASI ARTIFICIAIS\n\nEsta disserta\u00e7\u00e3o foi julgada para obten\u00e7\u00e3o do T\u00edtulo de Mestre, Especialidade \nem Engenharia de Produ\u00e7\u00e3o e aprovada em sua forma final pelo Programa de P\u00f3s- \nGradua\u00e7\u00e3o em Engenharia de Produ\u00e7\u00e3o da Universidade Federal de Santa Catarina.\n\nRicardo MifancIaBarcia, Ph.D.\nCoordenador\n\n\n\nJo\u00e3o Artur e Heitor\n\n\n\nI\nIV\n\nAGRADECIMENTOS\n\nAgradecer a todos que contribu\u00edram para realiza\u00e7\u00e3o deste trabalho \nreceb i^ 1' 86 nUma baStante dif\u00edci1\u2019 Pois foram in\u00fameras as contribui\u00e7\u00f5es que\n\nManifestarei aqui meus agradecimentos a algumas pessoas e institui\u00e7\u00f5es sem \nos quais nao teria realizado este trabalho.\n\nA CAPES pelo apoio financeiro.\n\n\u00c0 Universidade Federal de Pelotas, pela libera\u00e7\u00e3o de minha atividades \nacad\u00e9micas para realiza\u00e7\u00e3o deste Mestrado, principalmente aos companheiros de \ntrabalho que me apoiaram nesta libera\u00e7\u00e3o.\n\n\u00c0 Universidade Federal de Santa Catarina, em especial ao Programa de P\u00f3s- \nGradua\u00e7\u00e3o em Engenharia de Produ\u00e7\u00e3o em nome do Prof. Ricardo Miranda Barcia \npor ter me recebido de bra\u00e7os abertos. 5\n\nA S\u00e9rgio Farraco (Presidente Regional de Contabilidade) pelo fornecimento \n\nobjetivosS USad0S n6Sta dlSSerta\u00c7\u00e30\u2019 Sem os quais 0 trabalho \u00abao cumpriria com os\n\nAos Profs. Roberto Pacheco e Jos\u00e9 Leomar Todesco pelo incentivo e \norienta\u00e7\u00e3o durante o est\u00e1gio inicial deste aprendizado.\n\nAo professor e Orientador Alejandro Martins Rogriguez, pelo\nacompanhamento, orienta\u00e7\u00e3o e apoio desde os passos iniciais at\u00e9 a conclus\u00e3o deste \ntrabalho.\n\namizade^ \u00b0 S ^  6SpeC\u00cdal ao Roberto Raittz> pela colabora\u00e7\u00e3o, apoio e\n\nAos meus pais, Romeu e Adulce, dos quais nunca faltaram muito amor e \nincentivo, durante todo o meu desenvolvimento pessoal e profissional.\n\nE um agradecimento todo especial as duas pessoas que acompanharam cada\npasso desta longa trajet\u00f3ria. Por aquele rostinho sorridente que chegava de mansinho\nMamae. voce quer um chazinho?\u201d nas horas de concentra\u00e7\u00e3o (N\u00e3o dava para\n\nrecusar...) ou pelo \u201cVoc\u00ea quer uma ajuda?\u201d Ou Apenas um abra\u00e7o, nas horas do \ndesanim o...\n\n\n\nV\n\nSUM\u00c1RIO\n1. INTRODU\u00c7\u00c3O............................................................................................................... ...\n\n1.1 T em a  e C o n te x to ......................................................................................................  I\n\n1 . 2  J u stifica tiv a s............................................................................................................  2\n\n1.3 P r o p o sta  d e tr a b a lh o ................................................................................................  3\n\n1.4 O b jetiv o s d o tr a b a lh o ......................................................................................... .?........ 3\n\n1.5 M e to d o lo g ia ..................... ............................................................................................. 4\n\n1.6 E stru tu ra  d o  tr a b a lh o ................................... ..................................................................... 4\n\n2. AN\u00c1LISE D E  \u00cdNDICES FINANCEIROS....................................................................\n2.1 In tr o d u \u00e7 \u00e3 o ..........................................................................................................................  g\n\n2 .2  D e m o n stra \u00e7\u00f5 e s F in a n c e ir a s ..................................................................................................... 5\n2 .2 .1 Introdu\u00e7\u00e3o......................................................................................... 6\n2 .2.2 Principais Declara\u00e7\u00f5es Financeiras.............................................................  7\n\n2 .3 A n \u00e1 lise  d as D e m o n stra \u00e7\u00f5 e s F in a n c e ir a s ................................................................................  1 3\n\n2 .4  A n \u00e1 lise d e \u00edn d ic e s F in a n ceiro s....................... .............................................................................. ..\n2.4.1 Introdu\u00e7\u00e3o................................................................................................. 25\n2.4.2 Hist\u00f3rico sobre o uso dos \u00edndices Financeiros......................................................................  16\n2.4.3 Aspectos a Serem Considerados.................................................................. 20\n2.4.4 Principais \u00edndices Financeiros.................................................................................  26\n2.4.5 Outros Aspectos....................................................................................  28\n\n2 .5  A p lica \u00e7\u00f5 es d os \u00edn d ic e s F in a n c e ir o s ............................................................................................ 3 3\n\n2 .6  C o n c lu s \u00e3 o .....................................................................................................................  3 5\n\n3. T\u00c9CNICAS D E  INTELIG\u00caNCIA ARTIFICIAL.................................................... 3 7\n3.1 In tr o d u \u00e7 \u00e3 o ................................................................................................................................... 3-7\n\n3 .2  T \u00e9cn icas de In telig\u00ean cia A r tific ia l.................................................................................................\n3.2.1 Introdu\u00e7\u00e3o............................................................................................ ........................................3 g\n3.2.2 Sistemas especialistas................................................................................. ................................. 40\n3.2.3 Redes Neuronais Artificiais........................................................................... .............................44\n3.2.4 Sistemas Difusos.......................................................................................................................... 50\n3.2.5 Algoritmos Gen\u00e9ticos.................................................................................. ................................ gj\n3.2.6 Racioc\u00ednio Baseado em Casos..................................................................... ............................... 66\n\n3 .3  S istem a s H \u00edb r id o s ...............................................................................................................  7 2\n\n3 .4  C o n clu s\u00f5 es....................................................................................................................  7 ^\n\n4. REDES NEURONAIS ARTIFICIAIS........................................................................ ..\n4.1 In tr o d u \u00e7 \u00e3 o ...............................................................................................................................  j g\n\n4.2 A lg u m a s C aracter\u00edsticas d a s R N A s............................................................................................ ..\n4.2.1 Introdu\u00e7\u00e3o................................................................................................  \"  7 &amp;\n4.2.2 Hist\u00f3rico sobre as pesquisas sobre as R N A s............................................................ 79\n4.2.3 Arquiteturas.................................................................................................  34\n4.2.4 Aprendizagem.............................................................................................  g5\n4.2.5 Aplica\u00e7\u00f5es e Principais \u00c1reas de Atua\u00e7\u00e3o............................................................................  gg\n4.2.6 Taxinomia das Redes Neuronais........................................................................  90\n\n\n\nVI\n\n4 .4  U m  m \u00e9 to d o  h \u00edb rid o: F A N  ( F re e A sso cia tiv e N e u r o n s)............................................... 120\n1.4.1 Introdu\u00e7\u00e3o................. ..........................................\n\n4.4.2 FAN......................  ............................................................................................... \u201c 7\n....................................................................................................................121\n\n4.3 Caracteriza\u00e7\u00e3o das Principais Redes Neuronais........................................  9 2\n4.3.1 Introdu\u00e7\u00e3o.......................................................  ..............................................\n4.3.2 Rede de Kohonen........................................................ .................................. \u00c72\n\n4.3.3 Rede LVQ (Leaming Vector Quantization)................................................. 97\n4.3.4 Rede ART (Adaptative Resonance Theory).....................................\n4.3.5 Rede de Hopfield.............................................................  .................................. ^\n4.3.6 Perceptron Multicamadas.....................................................  ......................................... j 1Q\n4.3.7 Fun\u00e7\u00e3o de Base Radial (Radial Base Function - RBF).......................  .................. \\ 16\n\nI Um m\u00e9todo h\u00edl\n4.4.1 Introdu\u00e7\u00e3o\n4.4.2 FAN.,..\n\n4.5 Conclus\u00f5es..................................................................................  ^ 3\n\n5. APLICA\u00c7\u00c3O: CLASSIFICA\u00c7\u00c3O DA SA\u00daDE FINANCEIRA DE \nPEQUENAS EMPRESAS CATARINENSES........................................... 725\n\n5.1 Introdu\u00e7\u00e3o................................................................................................  ^ 5\n\n5.2 Aplica\u00e7\u00e3o.................................................................................................... ^ 5\n\n5.3 Diagn\u00f3stico atrav\u00e9s de R N ............................................................................ 1 3 Q\n5.3.1 MLP com Backpropagation. \u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\n5.3.2 RBF..............................  ................................................................................... ! \u00cd |\n\n5.3.3 L V Q ............................ ................................................................. ..\n\n53A f a n .......................................................\n5.4 Compara\u00e7\u00e3o dos Resultados...................................................................  1 3 7\n\n5.5 Conclus\u00e3o....................................................................................\n\n6. CONCLUS\u00d5ES E  RECOMENDA\u00c7\u00d5ES....................... .................... 140\n6 .1  Conclus\u00f5es........................................................................................................................................ 140\n6 .2  Recomenda\u00e7\u00f5es.................................................................................  j ^ 2\n\nREFERENCIAS BIBLIOGR\u00c1FICAS................................................... ..\nAP\u00caNDICE A: DADOS DE TREINAMENTO E  TESTE............................. ..\nAP\u00caNDICE B: HISTOGRAMA DO \u00cdNDICES FINANCEIROS.....................167\nAP\u00caNDICE C: RESULTADOS DA BACKPROPAGATION......................... 7 70\nAP\u00caNDICE D: RESULTADOS DA RBF.............................................. ..\nAP\u00caNDICE E: RESULTADOS DA L VQ........................................ jg j\nAP\u00caNDICE F: RESULTADOS DO FAN................................................\n\n\n\nVII\n\nLISTA DE FIGURAS\nFigura 2.1 Estrutura do Balan\u00e7o Patrim onial................................\nFigura 2.2: Estrutura da Demonstra\u00e7\u00e3o do R esultado............. ................................................................  rn\nFigura 2.3: Estrutura da Demonstra\u00e7\u00e3o das Origens e Aplica\u00e7\u00f5es de Recursos i i\nFigura 2.4: Estrutura da Demonstra\u00e7\u00e3o do Fluxo de Caixa..................... . ..........................\n^F oster 1986l? SS\u00cd? Ca\u00e7\u00e3\u00b0  ^  F oster ?  T\u00e9cnicas de An\u00e1lise de D eclara\u00e7\u00f5es Financeiras\n\nFigura 2.6: Tri\u00e2ngulo Du Pont [M atarazo, 1887J ......................................................................................... 24\n\nX  2  7' CUrVa ** rela\u00e7\u00e3\u00b0 &lt;luantidade de informa\u00e7\u00e3o versus quantidade de \u00edndices [M atarazzo,.........\n\nFigura 3.1: \u00c1 reas de A plica\u00e7\u00e3o de Sistema Inteligentes [ G o o n a tila te &amp; T r e ie a v e n ,1 9 9 5 a ] Z Z Z ~ . 39\n\n.8\n\n12\n\n14\n\nFigura 3.2 Estrutura gen\u00e9rica de um Sistema E specialista.................................. j \u00bb\nFigura 3.3: M odelo de um neur\u00f4nio artificia l.........................................  ...........................^\nFigura 3.4: Perceptron de m \u00faltiplas camadas com uma camada escondida e um neur\u00f4nio de sa\u00edda........ 45\nFigura 3.5: Processo de aprendizagem de uma RNA................................................  48\nFigura 3.6: Interpreta\u00e7\u00e3o para barato e caro na L\u00f3gica tradicional............................................... .............. 51\nFigura 3.7: Interpreta\u00e7\u00e3o p a ra  barato e caro na L\u00f3gica D ifu sa.............................................  51\n\n&amp; f u n m 5 J er\u00cdVa\u00e7\u00e3odey\" bapartirdex=aey=f(x)\u2019 onde a e b  s\u00e3o pontos e f(x ) \u00e9 uma cu w afJan g\n\nF igu ra3 .9 :D eriva\u00e7\u00e3o de y = b  a  p a rtir de x = a e y = f(x ), onde a  e b s ^ ^ i o s e M \u00e9 ^ f i ^ \u00e3 o\nintervalar [Jan g&amp;  Sun, 1995]........................................................................  J *\nFigura 3 .1 0 : Extens\u00e3o cil\u00edndrica A........................................................  ............................\nFigura 3.11: Rela\u00e7\u00e3o difusa F  sobre x e y . .........................................  .......................\nFigura 3.12: Opera\u00e7\u00e3o m in ........................................................... ................................\nFigura 3.13: Proje\u00e7\u00e3o sobre o eixo y . ...................................................  ...................... ^\nFigura 3.14: (A) Crossover entre dois cromossomos. (B) M uta\u00e7\u00e3o no alelo ......63\nFigura 4 .1: Eventos significantes no desenvolvimento de Redes Neuronais [Patterson, 19951.......84\nFigura 4 2: Uma taxinomia de arquiteturas de redes feed-forw ard e recorrentes/feedback...................  85\ntig u r a  4.3 : Arquitetura da rede Kohonen, caso de duas dimens\u00f5es [Pandya &amp; Macy, 19951 ........... 93\nFigura 4.4: Topologia quadrada [Pandya &amp; M acy, 1995]............................................. \u2019 .................... 9 4\nF1995] 4 5 Feedbaak lateral em uma camada de Kohonen de duas dimens\u00f5es [Pandya &amp; Macy,\n\nFigura 4.6  Classifica\u00e7\u00e3o de padr\u00f5es em dois est\u00e1gios....................................... ................\nFigura 4.7 Arquitetura da LVQ [Pandya &amp; Macy, 1995].................................................................................os\nFi&amp;tra 4.8 Treinamento da LVQ [Pandya&amp; M acy, 1 9 9 5 ]................................... . ................................ gg\nFigura 4.9: Estrutura b\u00e1sica da ART1 [Fauset, 1994]................................... ................................................ //i?\nFigura 4.10 :Rede de H opfieldD iscreta [Fauset, 1 9 9 4 ].........................................Z!.... ........................... J07\nFigura 4 .1 1 : A tratores de pon tos fix o s e bacias de atra\u00e7\u00e3o [Patterson, 1995]............  jq \u00a7\nFigura 4.12 Apresenta\u00e7\u00e3o esquem\u00e1tica da corre\u00e7\u00e3o dos pesos p o r backpropagation................................117\nFigura 4.13: Estrutura das redes M LP eR B F  [Pandya &amp; M acy 19951 .............  , , Q\nFigura 4.14: Arquitetura do FAN.................................................. \u2019 _ ..................................................  \u2122\nFigura 5 . 1 :  (a) Converg\u00eancia da Backpropagation usando 8  neur\u00f4nios, taxa da aprendizagem 0  08.....\nmomentum 0.8 e 1000 \u00e9pocas. Com esta arquitetura obtem os 81.25%  de acerto nos dados de teste; (b) \n,\u00b0 \u2122 ergencm? ?  Backpropagation usando 8  neur\u00f4nios, taxa da aprendizagem 0.08, momentum 0 .8  e \n2 0 0 0  epocas. Com esta arquitetura obtem os 6 8 .75%  de acerto nos dados de teste J33\nFigura 5.2: (a) Converg\u00eancia da rede RBFcom  15 centros, 1.3 de raio e 14 \u00e9pocas Com esta .............\narquitetura rede acertou 77.5% no treinamento e 81.25%  teste; (b) Converg\u00eancia da rede RBFcom  15 \nteste m i\u00b0  6 3 4  \u00e9pOCaS' C\u00b0 m esta ar<l uitetura rede acertou 100% no treinamento e 37.50%\n\nFigura 5.3: (a) Converg\u00eancia d a rede LVQ, trabalhando com os dados normalizados no intercalo [- 135 \n1, 1]  com taxa de aprendizagem 0 .2 decrescendo n\u00e3o linearmente e 4 5  \u00e9pocas. Com esta arquitetura \nrede acertou 72.5% no treinamento e 62.25%  no teste; (b) Converg\u00eancia d a rede LVQ, trabalhando \ncom os dados normalizados no intervalo [ - 1, 1]  com taxa de aprendizagem 0 .2  decrescendo 1> nao\n\n\n\nvm\n\nlinearmente e 200 \u00e9pocas. Com esta arquitetura rede acertou 70.00% no treinamento e 62 25%  no \n^ s te .............................................................................................................................................................. ..\nFigura 6. 1 . Arquitetura h\u00edbrida p a ra  an\u00e1lise da situa\u00e7\u00e3o fin an ceira...................................  j  43\n\n\n\nIX\n\nLISTA DE TABELAS\nTabela 2.1 Classifica\u00e7\u00e3o dos \u00edndices Financeiros segundo alguns pesquisadores...........  26\nT ibela 3.1 : Fun\u00e7\u00f5es de pertin\u00eancias m ais comuns.....................................................  ...................................5 2\nTabela 3 1 :  Compara\u00e7\u00e3o das T\u00e9cnicas Inteligentes [Goonatilake e Treleaven, 1995a -m odificado]......... 72\nla b e la  3.2: M odelos p a ra  integrar sistem as inteligentes [M edsker &amp; Bailey, 1992]. 74\nTabela 3.3: Tr\u00eas classes h\u00edbridas proposta [Goonatilake &amp; Khebbal, 1995b].........1.....\"...\".\"................. 75\nTabela 4.1. Algoritm os de Aprendizagem mais conhecidos................................... \u00e7 j\nTabela 5.1: Import\u00e2ncia de cada \u00edndice fin an ceiro............................................  .................................. 12g\n7b\u00f4e/a 5.2 : \u00edndices Financeiros de duas em presas e a  categoria o qual eles pertencem...........................129\nTabela 5 .1 : Fun\u00e7\u00f5es principais p a ra  a  rede backpropagation doM ATLAB...................................  7 3 /\n7abela 5.2 : Resultados da MLP com backpropagation usando os dados normalizados no intervalo\n* * ...................................................................................................................  j  $2\nTabela 5 . 1 :  Fun\u00e7\u00f5es principais para a  rede RBF doM ATLAB.............................134\nTabela 5. 2.  Resultados da RBF trabalhado com os dados normalizados no intervalo [-1,1]. 135\nTabela 5 .1 : Resultado da LVQ com dados normalizados no intervalo [1 ,1 ],.................................... 73 5\nTabela 5 . 1 :  Resultado do FAN (Porcentagem de acerto).........................................  j 3 7\nTabela 5 . 1 :  Compara\u00e7\u00e3o dos resultados................................................................. ........................................138\nTabela 6. 1 : Percentual de acerto de cada m odelo.......................................... \"............................................. 742\nTabela A - l : D ados de treinamento................................................................  ...............\nTabela A-2 : D ados de Teste............................................................  .........\nTabela C-l : Resultado da Backpropagation usando jun\u00e7\u00e3o de ativa\u00e7\u00e3o sigm oide na camada\nescondida e linear na \u00faltima camada.................................................................... I 7 2\nTabela C-2 : Resultado da Backpropagation usando Jun\u00e7\u00e3o de ativa\u00e7\u00e3o tangente hiperb\u00f3lica na \ncamada escondida e linear na ultima camada......................................................  j\nTabela C-3 : Resultado da Backpropagation usando Jun\u00e7\u00e3o de ativa\u00e7\u00e3o sigm oidal na camada \nescondida e linear na \u00faltima camada.................................................................  j  74\nTabela C - 4 : Resultado da Backpropagation usando fun\u00e7\u00e3o de ativa\u00e7\u00e3o n\u00e3o linear (sigmoidal\ne tangente hiperb\u00f3lica) na camada escondida e na camada de sa \u00edd a .......................... JJ4\nTabela D - l : Resultados do desempenho da rede RBF usando os dados nermalizados no intervalo\n\u00ed //*................'.......................................................................................  j\nTabela D -2 :Resultados do desempenho da rede RBF usando os dados normalizados no intervalo\nl   JgQ\nTabela E - l : Resultados da rede LVQ usando os dados n\u00e3o normalizados e a  taxa de aprendizagem \ndecresce linearmente em fun\u00e7\u00e3o do n\u00famero de \u00e9pocas..................................... j g j\nTabela E-2V Resultados da rede LVQ usando os dados n\u00e3o normalizados e a taxa de aprendizagem\ndecresce n\u00e3o linearmente em fun\u00e7\u00e3o do n\u00famero de \u00e9pocas..................................... jg 2\nTabela E-3 : Resultados da rede LVQ usando os dados normalizados entre [ - 1,1 ] e a tara de\naprendizagem decresce linearmente em Jun\u00e7\u00e3o do n\u00famero de \u00e9pocas..............................  i g j\nTabela E -4 : Resultados da rede LVQ usando os dados normalizados entre [-1 ,1 ] e a  taxa de\naprendizagem decresce n\u00e3o linearmente em fun\u00e7\u00e3o do n\u00famero de \u00e9pocas......................  7 $ 4\nTabela F - l :  R esultados da FAN com H =1 (grau de combina\u00e7\u00e3o das vari\u00e1reis)........................................ 185\n\n\n\nLISTA DE QUADROS\n\nQuadro 2.1: Quadro Resumo dos \u00edndices Financeiros.............\n\n\n\nXI\n\nRESUMO\n\nTendo em vista a import\u00e2ncia das pequenas empresas na economia nacional, \n\nesta disserta\u00e7\u00e3o tem como principal objetivo o aux\u00edlio das pequenas empresas na \n\ndetermina\u00e7\u00e3o de sua sa\u00fade financeira (diagn\u00f3stico) atrav\u00e9s de modelos \n\ncomputacionais que usam t\u00e9cnicas de Intelig\u00eancia Artificial. Estes modelos visam \n\nfornecer um \u201cespecialista\u201d \u00e0s pequenas empresas com menor custo.\n\nFaz-se, inicialmente, uma revis\u00e3o sobre an\u00e1lise de \u00edndices financeiros, uma \n\ndas principais ferramentas para diagn\u00f3stico de empresas. Em seguida, revisa-se \n\nalgumas t\u00e9cnicas de Intelig\u00eancia Artificial que s\u00e3o usadas freq\u00fcentemente na solu\u00e7\u00e3o \n\nde problemas da \u00e1rea financeira.\n\nObjetivando um diagn\u00f3stico mais apurado, analisou-se diferentes arquiteturas \n\nde redes neuronais (Backpropagation, RBF e LVQ) e uma rede h\u00edbrida (FAN) \n\nconsiderando alguns requisitos, aprendizagem dos dados, poder de generaliza\u00e7\u00e3o, \n\nrapidez, necess\u00e1rios para uma melhor classifica\u00e7\u00e3o (diagn\u00f3stico).\n\nOs dados trabalhados foram \u00edndices calculados de demonstrativos financeiros \n\n(Balan\u00e7o Patrimonial e Demonstrativos de Resultados) de 56 Micro Empresas \n\nCatarinenses do setor de com\u00e9cio.\n\nOs modelos usados apresentaram um bom desempenho apesar da pequena \n\nquantidade de dados, mostrando o poder de aprendizado e classifica\u00e7\u00e3o (diagn\u00f3stico) \n\nque as redes neuronais possuem.\n\nDeve-se enfatizar que a utiliza\u00e7\u00e3o correta e a difus\u00e3o do uso de tal diagn\u00f3stico \n\npoder\u00e1 auxiliar a pequena empresa no seu gerenciamento, representando uma \n\neconomia de recursos para o pa\u00eds.\n\n\n\nxn\n\nABSTRACT\n\nThe motivation o f this work was based on the necessity o f developing \n\nintelligent systems to give support to the Brazilian small and medium firms; these \n\nfirms are essential to the Brazilian economy.\n\nThe main objective o f this work is to aid small and medium firms to \n\ndetermine their financial health through the use o f computational models. The \n\nreferred models use artificial intelligence techniques; they have the potential to \n\nprovide a virtual \u201cspecialist\u201d to the firms at a lower cost than traditional financial \n\nhealth diagnosis techniques.\n\nA review o f financial ratio analysis is presented at the beginning o f the work It \n\nfollows a revision o f Artificial Intelligence techniques that are frequently used in \n\nproblem solving in the financial area.\n\nIn order to reach a precise diagnosis o f firms\u2019 financial health, different neural \n\nnetworks architectures (Backpropagation, RBF and LVQ) and a hybrid net (FAN) \n\nwere analyzed. The experiments have taken into account specific requirements o f the \n\nreal world data; they are: learning capacity, generalization power and speed.\n\nThe data used consisted in financial ratios that were evaluated from the m ain  \n\nfinancial reports (e.g., Balance Sheet and Income Statement), corresponding to fifty \n\nsix (56) small firms from the retail sector o f the Santa Catarina State.\n\nThe models presented a satisfactory performance in spite o f the small amount \n\no f data; this fact demonstrated the learning and classification power o f artificial \n\nneural networks models.\n\nFinally, it is worthy to emphasize that the use and diffusion o f such diagnosis \n\ncould boost the financial management o f the small and medium Brazilian firms, \n\nrepresenting an important economy to the country.\n\n\n\n1. INTRODU\u00c7\u00c3O\n\n1.1 Tema e Contexto\n\nA habilidade de uma empresa em usar as informa\u00e7\u00f5es e conhecimentos\n\nespecialistas tem se tomado um aspecto vital que pode determinar o sucesso ou a\n\nfal\u00eancia de uma organiza\u00e7\u00e3o. Isto \u00e9 particularmente verdade para as chamadas\n\npequenas empresas\u201d devido a seu tamanho e expans\u00e3o crescente, principalmente no \nBrasil.\n\nNeste contexto, muito dos pequenos neg\u00f3cios tem passado por dificuldades \n\nem seu gerenciamento devido a falta de conhecimento especialista em algumas das \n\nprincipais \u00e1reas de gerenciamento. De acordo com os dados do SEBRAE1 [Souza, \n\n1995], as micro empresas representam cerca de 98,3% de todas as empresas \n\nregistradas, e as suas atividades s\u00e3o respons\u00e1vel por 20,40% do Produto Interno Bruto \n\n(PIB) e por 54,40% da m\u00e3o de obra ocupada no pa\u00eds. Em particular na regi\u00e3o de Santa \n\nCatarina, uma pesquisa feita pelo Departamento de Engenharia de Produ\u00e7\u00e3o [Batalha \n\n&amp; Demon, 1990], relatou que o gerenciamento financeiro \u00e9 considerado uma das \n\n\u00e1reas mais problem\u00e1ticas para as pequenas ind\u00fastrias. A conseq\u00fc\u00eancia direta de tais \n\ndificuldades \u00e9 transformado em problemas de liquidez, baixo capital de giro, alto \n\nrisco devido \u00e0 posi\u00e7\u00e3o dos d\u00e9bitos e crescimento desestruturado entre outros casos. \n\nEstes aspectos posteriormente afetam os custos e rendas operacionais da empresa, e \n\ncausam, dependendo do tempo de uma corre\u00e7\u00e3o, a fal\u00eancia da empresa.\n\nA performance de uma firma depende do equil\u00edbrio entre liquidez e \n\nlucratividade. O monitoramento de problemas financeiros deve ser uma tarefa \n\ncont\u00ednua. Mesmo uma empresa muito rent\u00e1vel pode ocultar fatores que determinem\n\nSEBRAE: Servi\u00e7o de Apoio a Micro e Pequenas Empresas.\n\n\n\nCap\u00edtulo 1 - Introdu\u00e7\u00e3o\n2\n\nsua fal\u00eancia. A tarefa de monitoramento identifica fatores que podem ser ajustados \n\npara evitar a fal\u00eancia.\n\nUma t\u00e9cnica central para endere\u00e7ar situa\u00e7\u00f5es financeiras problem\u00e1ticas \u00e9 a \n\nAnalise de Declara\u00e7\u00f5es Financeiras, um processo no qual os especialistas \n\nreorganizam as informa\u00e7\u00f5es da firma e outras origens, criam vari\u00e1veis auxiliares \n\n(como os \u00edndices financeiros), e fazem uma compara\u00e7\u00e3o com padr\u00f5es a fim de \n\nidentificar e entender os desvios. Com o objetivo de encontrar um a conclus\u00e3o sem \n\nperdas em tal processo complexo, o especialista procura por sintomas financeiros \n\nbaseados em sua experi\u00eancia. Este processo \u00e9 essencialmente desestruturado. Em uma \n\nanalise mais detalhada, o especialista focaliza um aspecto particular a fim de verificar \n\nsuas causas principais, entender os desvios e finalmente conseguir uma conclus\u00e3o. \n\nEste processo \u00e9 muito mais estruturado que o primeiro, pois neste ponto o especialista \n\ntem mais sintomas espec\u00edficos para analisar.\n\nExistem tamb\u00e9m na literatura t\u00e9cnicas de Intelig\u00eancia Artificial (IA) \n\ndedicadas \u00e0 an\u00e1lise da sa\u00fade financeira: previs\u00e3o de fal\u00eancia [Wilson &amp; Hoff, 1994; \n\nOdom &amp; Shardo, 1990; Lacher et al, 1991], an\u00e1lise de cr\u00e9dito [Klymasauskas, 1991; \n\nBarker, 1990], auditoria [Blocher, 1990; [Mui et al., 1990], diagn\u00f3stico e solu\u00e7\u00e3o \n\n[Martins, 1996; Pacheco, 1996],\n\n1.2 Justificativas\n\nA An\u00e1lise de Demonstrativos Financeiros tradicional inclui v\u00e1rias t\u00e9cnicas \n\ntais como cross sectional (an\u00e1lise de \u00edndices financeiros e declara\u00e7\u00f5es de tamanho \n\ncomum), series de tempo e a combina\u00e7\u00e3o de informa\u00e7\u00f5es de declara\u00e7\u00f5es financeiras \n\ncom outros tipos de dados. O processo geral de extra\u00e7\u00e3o de informa\u00e7\u00f5es importantes \n\npara suportar uma decis\u00e3o n\u00e3o \u00e9 simples. Ele depende do setor econ\u00f4mico, do \n\ntamanho da empresa, do padr\u00e3o de compara\u00e7\u00e3o e al\u00e9m disto \u00e9 din\u00e2mico. Portanto, a \n\nAn\u00e1lise de Declara\u00e7\u00f5es Financeiras \u00e9 um processo que requer um especialista com \n\ngrande experi\u00eancia em an\u00e1lise financeira.\n\nUsualmente uma empresa tem duas alternativas quanto \u00e0s atividades de \n\nmonitoramento e resolu\u00e7\u00e3o de problemas: a pr\u00f3pria empresa fazer ou contratar um \n\nconsultor financeiro. Enquanto a primeira escolha requer recursos humanos, a\n\n\n\nCap\u00edtulo 1 - Introdu\u00e7\u00e3o\n3\n\nsegunda s\u00f3 pode ser uma solu\u00e7\u00e3o se a empresa dispor de recursos financeiros para a \n\ncontrata\u00e7\u00e3o de um especialista. Geralmente as pequenas empresas n\u00e3o podem contar \n\ncom nenhuma destas solu\u00e7\u00f5es, pois n\u00e3o tem nenhum especialista que trabalhe na \n\nempresa e tamb\u00e9m n\u00e3o disp\u00f5em de recursos financeiros para a contrata\u00e7\u00e3o do mesmo. \n\nAl\u00e9m disto, quando uma destas alternativas \u00e9 poss\u00edvel, a solu\u00e7\u00e3o pode chegar ap\u00f3s \n\num processo de interpreta\u00e7\u00e3o muito lento e portanto n\u00e3o ser mais \u00fatil.\n\nO monitoramento da sa\u00fade financeira das empresas \u00e9 um fator cr\u00edtico para seu \n\nsucesso. Uma das solu\u00e7\u00f5es para este problema \u00e9 o desenvolvimento de sistemas \n\ninteligentes que n\u00e3o somente analisam os problemas mas tamb\u00e9m sugerem solu\u00e7\u00f5es. \n\nA agrega\u00e7\u00e3o de ambas as tarefas envolve racioc\u00ednio dedutivo e indutivo, o que \n\njustifica mais de uma t\u00e9cnica de Intelig\u00eancia Artificial (IA).\n\nSistemas baseados em t\u00e9cnicas de IA podem tomar o conhecimento de um \n\nespecialista financeiro acess\u00edvel a um grande n\u00famero de empresas. Se corretamente \n\nimplementado, tais sistemas podem salvar milh\u00f5es de d\u00f3lares para um pa\u00eds devido o \n\nuso mais eficiente de todos os instrumentos financeiros e decis\u00f5es internas.\n\n1.3 Proposta de trabalho\n\nNeste trabalho pretende-se fazer uma an\u00e1lise dos diferentes modelos de redes \n\nexistentes na literatura, buscando os que mais se adaptam ao problema de diagn\u00f3stico \n\nde empresas. Feita esta an\u00e1lise, usar-se-\u00e1 as redes selecionadas para fazer o \n\ndiagn\u00f3stico das pequenas empresas catarinenses.\n\n1.4 Objetivos do trabalho\n\nO objetivo geral deste trabalho \u00e9 auxiliar as pequenas empresas na \n\ndetermina\u00e7\u00e3o da sa\u00fade financeira, possibilitando acesso aos especialistas com menor \ncusto.\n\nOs objetivos espec\u00edficos s\u00e3o:\n\n1. Apreciar a capacidade do sistema inteligente como elemento de avalia\u00e7\u00e3o \n\nde sa\u00fade financeira das empresas;\n\n\n\nCapitulo 1 - Introdu\u00e7\u00e3o 4\n\n2. Analisar o uso de diferentes algoritmos de Redes Neuronais e o sistema \n\nh\u00edbrido FAN (Free Associative Neuror\u00ed) quando aplicado em um dom\u00ednio.\n\nA fim de satisfazer os objetivos espec\u00edficos, os sistemas implementados neste \n\ntrabalho seguir\u00e3o os seguintes requisitos:\n\n\u2022  trabalhar com dados de empresas comerciais;\n\n\u2022  usar o menor volume de dados m\u00ednimo em rela\u00e7\u00e3o ao algoritmo;\n\n\u2022  facilidade de adaptar aos novos dados;\n\n\u2022  flexibilidade a fim de ser adaptado para diferentes setores econ\u00f4micos;\n\n\u2022  apresentar algumas ferramentas que auxiliam o gerenciamento financeiro \n\ndas pequenas empresas;\n\n1.5 Metodologia\n\nA primeira parte do trabalho, consiste em um levantamento bibliogr\u00e1fico \n\n(atrav\u00e9s de livros, artigos, internet), acerca de conceitos, desenvolvimentos, e \n\naplica\u00e7\u00f5es sobre An\u00e1lise de Declara\u00e7\u00f5es Financeiras e sobre algumas t\u00e9cnicas de IA.\n\nA segunda parte utiliza dados (Demonstrativos Financeiros) de pequenas \n\nempresas catarinenses. Analisa-se estes dados e determina-se quais os \u00edndices \n\nfinanceiros que ser\u00e3o utilizados como entrada para os sistemas inteligentes.\n\nA terceira parte do trabalho refere-se \u00e0 implementa\u00e7\u00e3o dos Sistemas \n\nInteligentes. Obt\u00e9m-se nesta fase o diagn\u00f3stico do(s) problema(s) financeiros Hac \n\nempresas analisadas.\n\nFinalmente na \u00faltima etapa do trabalho tem-se as conclus\u00f5es e poss\u00edveis \n\nsugest\u00f5es para outros trabalhos.\n\n1.6 Estrutura do trabalho\n\nA fim de melhor apresentar este trabalho, o mesmo divide-se em seis \n\ncap\u00edtulos, como seguem:\n\n\n\nCap\u00edtulo 1 - Introdu\u00e7\u00e3o 5\n\nNo Cap\u00edtulo 2 - \u201cAn\u00e1lise de \u00edndices Financeiros\u201d- discute-se o uso das \n\ninforma\u00e7\u00f5es das declara\u00e7\u00f5es financeiras, com \u00eanfase aos \u00edndices financeiros, como \n\nindicadores financeiros para um diagn\u00f3stico. Tamb\u00e9m apresenta-se neste cap\u00edtulo os \n\nconceitos das categorias de \u00edndices de liquidez, lucratividade, capital de giro,\n\nNo Cap\u00edtulo 3 - \u201cT\u00e9cnicas de Intelig\u00eancia A rtificial\u201d - descreve-se os \n\nfundamentos de algumas t\u00e9cnicas de IA (Sistema Especialistas, Conjuntos Difusos, \n\nRedes Neuronais Artificiais, Algoritmos Gen\u00e9ticos e Racioc\u00ednio Baseado em Casos). \n\nTamb\u00e9m faz-se uma an\u00e1lise das principais vantagens e desvantagens destas t\u00e9cnicas, \n\ne discute-se a necessidade de combina\u00e7\u00e3o das referidas t\u00e9cnicas (hibridiza\u00e7\u00e3o) a fim \n\nde se alcan\u00e7ar um melhor desempenho.\n\nNo Cap\u00edtulo 4 - \u201cRedes N euronais A rtificiais\u201d - analisa-se diversos modelos \n\nde redes neuronais artificiais, inclusive a rede h\u00edbrida FAN, buscando identificar as \n\nmais adequadas para o problema de diagn\u00f3stico.\n\nNo Cap\u00edtulo 5 - \u201cAplica\u00e7\u00e3o: Sa\u00fade F inanceira de Pequenas E m presas\u201d - \n\ndiscuti-se a defini\u00e7\u00e3o e relev\u00e2ncia do problema na \u00e1rea de finan\u00e7as. Explica-se a base \n\nda escolha das vari\u00e1veis financeiras dos dados reais envolvidos no problema. A \n\ndiscuss\u00e3o \u00e9 baseada nas descobertas de Martins sobre as ferramentas mais adequadas \n\nem Finan\u00e7as para diagn\u00f3stico e indica\u00e7\u00e3o de solu\u00e7\u00f5es para os problemas financeiros \n\n[Martins, 1996], Ap\u00f3s a an\u00e1lise do problema sobre o ponto de vista financeiro, \n\ndiscuti-se os resultados obtidos pelos sistemas inteligentes implementados.\n\nFinalmente, o Cap\u00edtulo 6 refere-se as conclus\u00f5es e recomenda\u00e7\u00f5es do \n\ntrabalho.\n\n\n\n2. AN\u00c1LISE DE \u00cdNDICES \nFINANCEIROS\n\n2.1 Introdu\u00e7\u00e3o\n\nUma empresa \u00e9 uma inter-rela\u00e7\u00e3o de decis\u00f5es, fluxos f\u00edsicos e informa\u00e7\u00f5es. \n\nExiste uma multiplicidade de fatores que determinam a lucratividade de um neg\u00f3cio e \n\nsuas chances de sobreviv\u00eancia. Um destes fatores de interesse particular da empresa \n\n(do gerente, especialmente) \u00e9 a efic\u00e1cia da tomada de decis\u00e3o. As informa\u00e7\u00f5es das \n\ndemonstra\u00e7\u00f5es financeiras (Balan\u00e7o Patrinomial, Demonstrativo de Resultados, \n\nDemonstra\u00e7\u00e3o de Fluxo de Caixa, e Demonstrativo das Origens e Aplica\u00e7\u00f5es de \n\nRecursos) da empresa servem como um sinal de que decis\u00f5es s\u00e3o necess\u00e1rias ou \n\nfornecem informa\u00e7\u00f5es que podem ser usadas na decis\u00e3o. Uma das t\u00e9cnicas principais \n\naceitas como ferramenta da An\u00e1lise de Declara\u00e7\u00f5es Financeira \u00e9 a an\u00e1lise de \u00edndices \n\nfinanceiros. A an\u00e1lise destes \u00edndices, al\u00e9m de auxiliar no gerenciamento da empresa, \n\nauxilia na previs\u00e3o estat\u00edstica de fal\u00eancia, an\u00e1lise da sa\u00fade financeira, e \n\nplanejamento de estrat\u00e9gias.\n\nNeste cap\u00edtulo apresentar-se-\u00e1 inicialmente um resumo sobre as \n\ndemonstra\u00e7\u00f5es financeiras mais usadas na An\u00e1lise de Demonstra\u00e7\u00f5es Financeiras. \n\nDevido a sua grande utilidade, falar-se-\u00e1 em seguida sobre a An\u00e1lise de \u00edndices \n\nFinanceiros: hist\u00f3rico, aspectos te\u00f3ricos, principais \u00edndices e algumas aplica\u00e7\u00f5es.\n\n2.2 Demonstra\u00e7\u00f5es Financeiras\n\n2.2.1 Introdu\u00e7\u00e3o\n\nUm dos elementos mais importantes na tomada de decis\u00f5es relacionadas a \n\numa empresa \u00e9 a an\u00e1lise das suas demonstra\u00e7\u00f5es financeiras. As Demonstra\u00e7\u00f5es\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 7\n\nF inanceiras relatam o que acontece na empresa em termos de vendas de bens, \n\ndespesas, lucros, dividendos, etc. Por exemplo, nas empresas de Sociedades \n\nAn\u00f4nimas, esta \u00e9 uma das informa\u00e7\u00f5es que os investidores fornecem e a comunidade \n\ndos investidores usam para formar expectativas sobre como a magnitude, risco de \n\nretomo da empresa, o pre\u00e7o de mercado das a\u00e7\u00f5es ser\u00e3o afetados. O entendimento \n\ndas demonstra\u00e7\u00f5es financeiras s\u00e3o, portanto, importantes para investidores e para o \n\ngerente da empresa.\n\nAs principais declara\u00e7\u00f5es financeiras baseadas na contabilidade s\u00e3o o Balan\u00e7o \n\nPatrimonial, Demonstra\u00e7\u00e3o do Resultado do Exerc\u00edcio, Demonstra\u00e7\u00e3o de Origens e \n\nAplica\u00e7\u00f5es de Recursos, e Demonstra\u00e7\u00e3o de Fluxo de Caixa.\n\n2.2.2 Principais Declara\u00e7\u00f5es Financeiras\n\nAs demonstra\u00e7\u00f5es financeiras fornecem uma s\u00e9rie de dados sobre a empresa, \n\nde acordo com regras cont\u00e1beis. A An\u00e1lise de Demonstra\u00e7\u00f5es F inanceiras \n\ntransforma esses dados em informa\u00e7\u00f5es e ser\u00e1 tanto mais eficiente quanto melhores \n\ninforma\u00e7\u00f5es produzir. Estas informa\u00e7\u00f5es auxiliam o tomador de decis\u00e3o na avalia\u00e7\u00e3o \n\nda posi\u00e7\u00e3o financeira passada ou corrente da empresa assim como na previs\u00e3o do \n\nfuturo da empresa. O escopo da an\u00e1lise financeira depende de seu objetivo, variando \n\nde uma an\u00e1lise total dos pontos fortes e fracos da empresa a uma an\u00e1lise mais \n\nsimplificada de sua liquidez a curto prazo.\n\nO Balan\u00e7o Patrim onial (Figura 2.1) \u00e9 a demonstra\u00e7\u00e3o que apresenta todos os \n\nbens e direitos da empresa - Ativo - assim como as obriga\u00e7\u00f5es - Passivo Exig\u00edvel - \n\nem determinada data e o P atrim \u00f4nio L\u00edquido. No ativo relacionam-se todas as \n\naplica\u00e7\u00f5es de recursos efetuadas pela empresa. Estes recursos poder\u00e3o estar \n\ndistribu\u00eddos em ativos circulantes, assim denominado por apresentarem uma maior \n\nrota\u00e7\u00e3o em rela\u00e7\u00e3o aos chamados \u201cativos fixos\u201d, como: valores em caixa, valores a \n\nreceber a curto prazo, etc.; em ativos realiz\u00e1veis a longo prazo; e em ativos \n\nclassificados como permanentes, como: pr\u00e9dios, terrenos,... os quais servem a \n\nv\u00e1rios ciclos operacionais. Por outro lado, o Passivo Exig\u00edvel identifica a origem de \n\ntodos os recursos de terceiros levantados pela empresa. A diferen\u00e7a entre o Ativo e o \n\nPassivo Exig\u00edvel \u00e9 chamado Patrim\u00f4nio L\u00edquido e representa o capital investido pelos\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 8\n\npropriet\u00e1rios da empresa, quer atrav\u00e9s de recursos trazidos de fora da empresa, quer \n\ngerados por esta em suas opera\u00e7\u00f5es internamente.\n\nBALAN\u00c7O PATRIMONIAL\n\nATIVO PASSIVO E PATRIM\u00d4NIO L\u00cdQUIDO\n\nCIRCULANTE CIRCULANTE\nDisponibilidades\n\nCaixa e Bancos................... Fornecedores.............\nAplic. de liquidez Imediata....... Imposto a Pagar............\n\nDividendos a Pagar. ..\nClientes Contas a Pagar.........\n\nDuplicatas a Receber\nProvis\u00e3o p/ Devedores Duvidosos ...xxxx TOTAL DO PASSIVO CIRCULANTE XXXX\nDuplicatas Descontadas....\n\nEXIG\u00cdVEL A LONGO PRAZO\nEstoques\n\nProdutos Acabados.......... Empr\u00e9stimos Banc\u00e1rios...\nProdutos em Processo........\nMat\u00e9ria-Prima.................... ..xxxx TOTAL EXIG\u00cdVEL A LONGO PRAZO , xxxx\n\nTOTAL DA ATIVO CIRCULANTE xxxx PATRIM\u00d4NIO L\u00cdQUIDO\n\nPERMANENTE Capital Social\nSubscrito.................\n\nInvestimentos A realizar..............\nA\u00e7\u00f5es de outras empresas.........\nIncentivos Fiscais................. xxxx Reservas de Capital\n\nImobilizado\nCorre\u00e7\u00e3o Monet\u00e1ria do Capital xxxx\n\nIm\u00f3veis.................... .xxxx Reservas de Lucro\nVe\u00edculos................... .xxxx Reserva Legal........\nM\u00e1quinas e Equipamentos........ xxxx Lucros Acumulados.....\nDeprecia\u00e7\u00e3o Acumulada............. .xxxx\n\nDiferido\nTOTAL DO PATRIM\u00d4MIO L\u00cdQUIDO ,, xxxx\n\nDespesas Pr\u00e9-Operacionais.......... xxxx TOTAL DO PASSIVO.\n\nTOTAL DO ATIVO PERMANENTE xxxx\n\nTOTAL DO ATIVO...... .xxxx\n\nF igura 2.1 E s tru tu ra  do Balan\u00e7o Patrim onial.\n\nPor\u00e9m o bala\u00e7o apresenta a posi\u00e7\u00e3o de uma empresa em um dado momento. A \n\ninforma\u00e7\u00e3o que ele fornece \u00e9 totalmente est\u00e1tica, e muito provavelmente, a sua \n\nestrutura se apresentar\u00e1 relativamente diferente algum tempo ap\u00f3s o seu \n\nencerramento. O Balan\u00e7o fornece uma vis\u00e3o da empresa que exige do analista ou \n\ngerente muita experi\u00eancia para poder entender a situa\u00e7\u00e3o financeira da empresa.\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 9\n\nEntretanto, o Balan\u00e7o servir\u00e1 como elemento de partida para o conhecimento \n\nretrospectivo da situa\u00e7\u00e3o econ\u00f4mica e financeira de uma empresa, atrav\u00e9s das \n\ninforma\u00e7\u00f5es contidas nos seus v\u00e1rios grupos de contas. E, em fun\u00e7\u00e3o do \n\ncomportamento verificado nos \u00faltimos exerc\u00edcios, poder-se-\u00e1 identificar determinada \n\nposi\u00e7\u00e3o futura da empresa.\n\nA Dem onstra\u00e7\u00e3o do Resultado do Exerc\u00edcio (Figura 2.2) \u00e9 uma \n\ndemonstra\u00e7\u00e3o dos aumentos e redu\u00e7\u00f5es causados no Patrim\u00f4nio L\u00edquido pelas \n\nopera\u00e7\u00f5es da empresa. As receitas representam normalmente aumento no Passivo, \n\natrav\u00e9s do ingresso de novos elementos, como duplicata a receber ou dinheiro \n\nproveniente de transa\u00e7\u00f5es. Aumentando o Ativo, aumenta o Patrim\u00f4nio L\u00edquido. As \n\ndespesas representam redu\u00e7\u00e3o do Patrim\u00f4nio L\u00edquido, atrav\u00e9s de dois caminhos \n\nposs\u00edveis: redu\u00e7\u00e3o do Ativo e Aumento do Passivo exig\u00edvel.\n\nA Demonstra\u00e7\u00e3o do Resultado registra ent\u00e3o o fluxo de receitas e relata as \n\ndespesas de uma empresa entre duas datas, geralmente um ano. Por isto \u00e9 \n\nclassicamente chamada de Demonstra\u00e7\u00e3o do Resultado de Fluxo de Renda \n\n[Matarazzo, 1987],\n\nA Demonstra\u00e7\u00e3o do Resultado retrata somente o fluxo econ\u00f4mico e n\u00e3o o \n\nfluxo monet\u00e1rio. Para a Demonstra\u00e7\u00e3o do Resultado n\u00e3o importa se uma receita ou \n\ndespesa tem reflexos em dinheiro, basta apenas que afete o Patrim\u00f4nio L\u00edquido. \n\nComo as modifica\u00e7\u00f5es no Patrim\u00f4nio L\u00edquido produzidas por receitas e despesas \n\nafetam a riqueza dos propriet\u00e1rios, elas s\u00e3o retratadas na Demonstra\u00e7\u00e3o do Resultado \n\nque \u00e9 uma pe\u00e7a de car\u00e1ter eminentemente econ\u00f4mico (relacionada \u00e0 riqueza) e n\u00e3o \n\nfinanceiro (relacionado \u00e0 dinheiro).\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 1 0\n\nDEMONSTRA\u00c7\u00c3O DO RESULTADO\n\nRECEITA OPERACIONAL BRUTA\nVendas Brutas\n(-) Dedu\u00e7\u00f5es e descontos concedidos\n(-) Devolu\u00e7\u00f5es\n(-) Impostos Pagos\nRECEITA L\u00cdQUIDA OPERACIONAL:\n(-) Custo de produ\u00e7\u00e3o das mercadorias vendidas\n\nou Custo das mercadorias vendidas\nLUCRO BRUTO:\n\n(-) Despesas Operacionais\nDespesas de Administra\u00e7\u00e3o\nDespesas de Vendas\nDespesas Gerais\n\nLUCRO/PREJU\u00cdZO OPERACIONAL:\n(\u00b1) Receitas e Despesas Financeiras\nLUCRO/PREJU\u00cdZO OPERACIONAL L\u00cdQUIDO:\n(+) Receitas n\u00e3o operacionais\n(-) Despesas n\u00e3o operacionais\n(\u00b1) Saldo da conta de corre\u00e7\u00e3o monet\u00e1ria\nLUCRO/PREJU\u00cdZO L\u00cdQUIDO ANTES DO IR:\n(-) Provis\u00e3o para Imposta de Renda\nLUCRO/PREJU\u00cdZO L\u00cdQUIDO:\n(-) Participa\u00e7\u00f5es\n(-) Contribui\u00e7\u00f5es\n\nLUCRO (OU PREJU\u00cdZO) L\u00cdQUIDO DO EXERC\u00cdCIO\n\nF ig u ra 2.2: E s tru tu ra  da Dem onstra\u00e7\u00e3o do Resultado.\n\nA D em onstra\u00e7\u00e3o das O rigens e Aplica\u00e7\u00f5es de Recursos (DOAR) (Figura \n\n2.3) acrescenta um enorme conjunto de informa\u00e7\u00f5es sobre a din\u00e2mica financeira as \n\nempresa. A DOAR \u00e9 uma compara\u00e7\u00e3o de dois Balan\u00e7os consecutivos, os quais \n\nidentificam as varia\u00e7\u00f5es ocorridas na estrutura financeira da empresa durante o \n\nper\u00edodo considerado, permitindo, por conseguinte, melhores crit\u00e9rios para a an\u00e1lise \n\nfinanceira de empresa.\n\nDado que o Balan\u00e7o \u00e9 uma informa\u00e7\u00e3o totalmente est\u00e1tica, a DOAR \n\napresenta-se como um dos instrumentos mais importantes para que se conhe\u00e7am as \n\nmuta\u00e7\u00f5es verificadas na posi\u00e7\u00e3o financeira da empresa, evidenciando-se, de uma \n\nmaneira abrangente, os financiamentos (origens de recursos) e os investimentos \n\n(aplica\u00e7\u00f5es de recursos) verificados no per\u00edodo [Neto, 1983],\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 11\n\nDEMONSTRA\u00c7\u00c3O DAS ORIGENS E APLICA\u00c7\u00d5ES DE RECURSOS\n\nORIGENS DE RECURSOS\n\n\u2022  Das Opera\u00e7\u00f5es:\n?  Lucro L\u00edquido do ano\nB  Mais: Deprecia\u00e7\u00f5es e Amortiza\u00e7\u00f5es\n\nResultado da Corre\u00e7\u00e3o Monet\u00e1ria do Exerc\u00edcio (saldo devedor)\nVaria\u00e7\u00f5es Monet\u00e1rias de Empr\u00e9stimos e Financiamentos a Longo Prazo\n\n?  Menos: Participa\u00e7\u00e3o nos Resultados de Controladas e Coligadas\nResultado da Corre\u00e7\u00e3o Monet\u00e1ria (saldo credor)\nResultado na Aliena\u00e7\u00e3o de Bens do Imobilizado\n\nTotal das Opera\u00e7\u00f5es\n\n\u2022  Dos Acionista:\n?  Integraliza\u00e7\u00e3o de Capital\n\n\u2022  De Terceiros:\n?  Ingresso de Empr\u00e9stimos a Longo Prazo\n\u00ae Aliena\u00e7\u00e3o de Itens do Imobilizado (valor de venda)\nH Resgate de Investimentos Tempor\u00e1rios a Longo Prazo\n\nTotal das Origens\n\nAPLICA\u00c7\u00d5ES DE RECURSOS\n\n\u2022  Aquisi\u00e7\u00f5es de direitos do Imobilizado (ao custo)\n\n\u2022  Adi\u00e7\u00f5es ao Custo no Ativo Diferido\n\n\u2022  Aplica\u00e7\u00f5es em Investimentos Permanentes em outras Sociedades\n\n\u2022  Aplica\u00e7\u00f5es em investimentos Tempor\u00e1rios a Longo Prazo\n\n\u2022  Transfer\u00eancia para Curto prazo de Empr\u00e9stimos e financiamentos a Longo Prazo\n\u2022  Dividendos Propostos\n\nTotal das Aplica\u00e7\u00f5es\n\nACR\u00c9SCIMO (DECR\u00c9SCIMO) NO CAPITAL CIRCULANTE L\u00cdQUIDO___________________\n\nF igu ra 2.3: E stru tu ra da D em onstra\u00e7\u00e3o das O rigen s e A plica \u00e7\u00f5 es d e R ecursos.\n\nA D em on stra\u00e7\u00e3o do F luxo d e C aixa (Figura 2.4), apesar de ser uma das \n\ndemonstra\u00e7\u00f5es mais \u00fateis, n\u00e3o \u00e9 divulgada pelas empresas. Desta forma, o analista \n\nexterno precisa elabor\u00e1-la baseado nas demais demonstra\u00e7\u00f5es, como o DOAR.\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 12\n\nDEMONSTRA\u00c7\u00c3O DO FLUXO DE CAIXA\nExerc\u00edcio de \u2014 /\u2014 /\u2014\n\nLUCRO L\u00cdQUIDO DO EXERC\u00cdCIO \n+ Despesas n\u00e3o desembols\u00e1veis\n\nDeprecia\u00e7\u00e3o\nSaldo Da Corre\u00e7\u00e3o Monet\u00e1ria\n\n- Receitas n\u00e3o Embols\u00e1veis\nResultado da Equival\u00eancia Patrimonial\n\nGERA\u00c7\u00c3O BRUTA DE CAIXA\n+ Acr\u00e9scimo de Fontes Operacionais\n\nFornecedores\nObriga\u00e7\u00f5es de Funcionamento\n\n- Acr\u00e9scimo de Aplica\u00e7\u00f5es Operacionais\nDuplicatas a Receber \nEstoques \nOutras Contas\n\n= GERA\u00c7\u00c3O OPERACIONAL DE CAIXA\n\n+ Fontes n\u00e3o Operacionais\nRealiza\u00e7\u00e3o de Capital\nVenda de Imobilizado\nVenda de Investimentos\nAumento de Exig\u00edvel Longo Prazo\nDiminui\u00e7\u00e3o de realiz\u00e1vel Longo Prazo\nAcr\u00e9scimo de Empr\u00e9stimos de Curto Prazo\n\n- Aplica\u00e7\u00f5es n\u00e3o Operacionais\nDividendos\nAquisi\u00e7\u00e3o de Investimentos \nAquisi\u00e7\u00e3o de Imobilizado \nAumento de Ativo Diferido \nAumento de Realiz\u00e1vel Longo Prazo \nDiminui\u00e7\u00e3o de Exig\u00edvel Longo Prazo \nDiminui\u00e7\u00e3o de Empr\u00e9stimos Curto Prazo\n\n= GERA\u00c7\u00c3O L\u00cdQUIDA DE CAIXA \n+ Saldo Inicial de caixa \n= Saldo Final de caixa____________________\n\nF igu ra 2.4: E stru tura da D em on stra\u00e7\u00e3o do Fluxo de C aixa.\n\nMuitas vezes os problemas de insolv\u00eancia ou liquidez ocorrem por falta de \n\numa administra\u00e7\u00e3o adequada do fluxo de caixa, da\u00ed a import\u00e2ncia de sua an\u00e1lise.\n\nAs principais vantagens da Demonstra\u00e7ao de Fluxo de Caixa s\u00e3oi - avaliar \n\nalternativas de investimentos; - avaliar e controlar ao longo prazo as decis\u00f5es \n\nimportantes que s\u00e3o tomadas na empresa, com reflexos monet\u00e1rios; - avaliar a \n\nsitua\u00e7\u00e3o presente e futura do caixa da empresa, posicionando-a para que n\u00e3o chegue a\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 13\n\nsitua\u00e7\u00e3o de liquidez; - certificar que os excessos moment\u00e2neos de caixa est\u00e3o sendo \n\ndevidamente aplicados [Matarazzo, 1987],\n\nAs quatro Demonstra\u00e7\u00f5es financeiras citadas acima representam informa\u00e7\u00f5es \n\ndiferentes e complementares para o analista financeiro. Al\u00e9m das informa\u00e7\u00f5es, o \n\nanalista financeiro tem que identificar a melhor abordagem para o problema da \n\nan\u00e1lise da sa\u00fade financeira da empresa. Foster [Foster, 1987] classifica os diferentes \n\nesquemas de acordo com o objetivo da an\u00e1lise. Uma vis\u00e3o da classifica\u00e7\u00e3o de Foster \u00e9 \n\nmostrada na Figura 2.5.\n\n2.3 An\u00e1lise das Demonstra\u00e7\u00f5es Financeiras\n\nA An\u00e1lise Financeira de empresas \u00e9 tarefa bastante complexa e de \n\nfundamental import\u00e2ncia numa sociedade moderna [Silva, 1988], Como o pr\u00f3prio \n\nnome sugere, a An\u00e1lise Financeira \u00e9 a sele\u00e7\u00e3o, avalia\u00e7\u00e3o e interpreta\u00e7\u00e3o de dados \n\nfinanceiros e outros dados pertinentes. O analista financeiro deve determinar quais \n\ninforma\u00e7\u00f5es s\u00e3o necess\u00e1rias e como usa-las. Da mesma forma, um investigador que \n\npretende adquirir a\u00e7\u00f5es de determinada companhia tamb\u00e9m deve conhecer a referida \n\norganiza\u00e7\u00e3o.\n\nO primeiro objetivo da An\u00e1lise das Declara\u00e7\u00f5es Financeiras \u00e9 a an\u00e1lise Cross- \n\nSectional, que \u00e9, o estudo de empresas em um setor econ\u00f4mico espec\u00edfico. As \n\ndeclara\u00e7\u00f5es de tamanho comum e an\u00e1lise de \u00edndices financeiros s\u00e3o duas t\u00e9cnicas \n\npara comparar empresas. Uma das formas mais simples e direta de analisar mudan\u00e7as \n\nno tempo \u00e9 calcular declara\u00e7\u00f5es de tamanho-comum. O Balan\u00e7o de tamanho-comum \n\ntenta reduzir o efeito do tamanho da empresa quando se compara as declara\u00e7\u00f5es \n\nfinanceiras das empresas. A estrat\u00e9gia \u00e9 dividir todas as contas da declara\u00e7\u00e3o por uma \n\ndestas contas para coloc\u00e1-las em uma base de porcentagem comum. Por exemplo, um \n\ndemonstrativo de resultado de tamanho-comum \u00e9 constru\u00eddo dividindo-se os v\u00e1rios \n\ncomponentes pela renda l\u00edquida.\n\nO m\u00e9todo mais usado e muitas vezes confundido com a an\u00e1lise de declara\u00e7\u00f5es \n\nfinanceiras e a analise de \u00edndices financeiros. Estes \u00edndices comparam vari\u00e1veis \n\nfinanceiras que s\u00e3o extra\u00eddas, geralmente, do Balan\u00e7o Patrinomial e do demonstrativo \n\nde resultado. Esta t\u00e9cnica reduz a quantidade de informa\u00e7\u00f5es e enfatiza as rela\u00e7\u00f5es\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 14\n\nentre elementos financeiros ao inves de seus valores individuais. Na pr\u00f3xima se\u00e7\u00e3o \n\nfaz-se um estudo mais minucioso sobre a an\u00e1lise dos \u00edndices financeiros.\n\nEstm m ^d^ed\u00e3ra\u00e7\u00f5eTFina^ei^J\n\nCross-Sectional\n\nTamanho\nComum\n\n\u00edndice\nFinanceiro\n\nS\u00e9rie-Tempo\nCombina\u00e7\u00e3o d e  D eclara\u00e7\u00f5es \nFinanceiras com Informa\u00e7\u00f5es \nN\u00e3o-financeiras\n\nDeclara\u00e7\u00f5es \nde tend\u00eancias\n\nMedidas de \nVariabilidade\n\nMercado de \nProduto\n\nMercado de \nCapital\n\nFigura 2.5: Classifica\u00e7\u00e3o de Foster das T\u00e9cnicas de An\u00e1lise de Declara\u00e7\u00f5es \nFinanceiras [Foster, 1986].\n\nUm outro objetivo da an\u00e1lise de declara\u00e7\u00f5es financeiras \u00e9 a an\u00e1lise de S\u00e9rie- \n\nTempo. Esta an\u00e1lise consiste do estudo da performance da empresa no tempo afim de \n\nprever sua sa\u00fade financeira, baseado em informa\u00e7\u00f5es passadas e presentes. A S\u00e9rie- \n\nTempo usa informa\u00e7\u00f5es sobre a empresa para prever seu desenvolvimento futuro. A \n\nan\u00e1lise de S\u00e9rie-tempo e acompanhada tamb\u00e9m pela an\u00e1lise de \u00edndices e declara\u00e7\u00f5es \n\ndas tend\u00eancias. As declara\u00e7\u00f5es das tend\u00eancias s\u00e3o elaboradas fixando-se um per\u00edodo \n\nbase e expressando-se os elementos financeiros dos per\u00edodos subsequentes por seus \n\nvalores relativos no per\u00edodo base. A an\u00e1lise da S\u00e9rie-Tempo pode tamb\u00e9m ser \n\nidentificada pelo estudo de \u00edndices financeiros no tempo. A terceira abordagem para \n\ns\u00e9rie-tempo \u00e9 a an\u00e1lise da variabilidade onde os \u00edndices e as outras vari\u00e1veis s\u00e3o \n\nmedidos no tempo. Contudo, nesta abordagem o objetivo \u00e9 definir as rela\u00e7\u00f5es entre os \n\nvalores extremos (m\u00e1ximo e m\u00ednimo) e a m\u00e9dia sobre o per\u00edodo [Foster, 1986],\n\nO terceiro objetivo da An\u00e1lise Financeira \u00e9 estudar a performance afim de \n\nestabelecer as estrat\u00e9gias de investimentos no mercado de capitais. Isto envolve a \n\ncombina\u00e7\u00e3o de declara\u00e7\u00f5es financeiras e informa\u00e7\u00f5es n\u00e3o financeiras como mercado \n\nde produtos e mercado de capitais.\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 15\n\nParticularmente para o problema considerado aqui, a an\u00e1lise de declara\u00e7\u00f5es \ntem uma utilidade dupla:\n\n1) poss\u00edvel diagn\u00f3stico de problemas financeiros de pequenas empresas \n\nbaseado em seus \u00edndices financeiros (e tend\u00eancia) e no valor m\u00e9dio \n\ncorrespondente do setor econ\u00f4mico; e\n\n2) suportar a estrat\u00e9gia dedutiva para verificar as causas e oferecer solu\u00e7\u00f5es \n\npara os problemas financeiros.\n\nPortanto, de acordo com a Figura 2.5, a An\u00e1lise de Declara\u00e7\u00f5es Financeiras \u00e9 \n\nusada neste trabalho como uma t\u00e9cnica de an\u00e1lise cross-sectional e de s\u00e9rie-tempo \n\nbaseada em \u00edndices financeiros. Ent\u00e3o, na pr\u00f3xima se\u00e7\u00e3o direcionar-se-\u00e1 um estudo \n\nsobre a an\u00e1lise de \u00edndices financeiros.\n\n2.4 An\u00e1lise de \u00edndices Financeiros\n\n2.4.1 Introdu\u00e7\u00e3o\n\n\u00edndice financeiro \u00e9 a rela\u00e7\u00e3o (x/y) entre contas ou grupos de contas das \n\nDemonstra\u00e7\u00f5es Financeiras, que visa evidenciar determinado aspecto da situa\u00e7\u00e3o \n\necon\u00f4mica ou financeira de uma empresa. Se ambos x e y v\u00eam do Balan\u00e7o \n\nPatrimonial o \u00edndice pode ser chamado est\u00e1tico e se pelo menos um vem do \n\nDemonstrativo de Resultado pode ser chamado de din\u00e2mico [Salmi &amp; Martikainen, \n\n1994], A An\u00e1lise de \u00edndices Financeiros \u00e9 usada com v\u00e1rios objetivos por \n\nprofissionais como investidores, gerentes, financiadores assim como por acad\u00eamicos. \n\nNa pr\u00e1tica os \u00edndices s\u00e3o usados, por exemplo, para prever o sucesso da empresa, \n\nenquanto que o principal objetivo dos pesquisadores \u00e9 desenvolver modelos que \nexploram estes \u00edndices.\n\nQualquer sistema de an\u00e1lise financeira que \u00e9 baseado no uso de \u00edndices \n\nfinanceiros deve levar em considera\u00e7\u00e3o muitos outros indicadores, tais como \n\nsitua\u00e7\u00e3o econ\u00f4mica, pol\u00edtica da empresa, setor do neg\u00f3cio e princ\u00edpios cont\u00e1beis que \n\nest\u00e3o afetando a empresa. Este conjunto de requerimentos determina a valida\u00e7\u00e3o dos \n\ndados de entrada e a confid\u00eancia na an\u00e1lise.\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 16\n\n2.4.2 Hist\u00f3rico sobre o uso dos \u00edndices Financeiros\n\nA ado\u00e7\u00e3o de \u00edndices como uma ferramenta de an\u00e1lise financeira \u00e9 \n\nrelativamente recente. A An\u00e1lise de Declara\u00e7\u00f5es financeiras surgiu e desenvolveu-se \n\ndentro do sistema banc\u00e1rio que \u00e9 at\u00e9 hoje seu principal usu\u00e1rio.\n\nAs principais causas para o desenvolvimento de an\u00e1lise de \u00edndices financeiros \n\nforam a maturidade industrial na metade do s\u00e9culo XDC e principalmente a an\u00e1lise \n\nde cr\u00e9dito. Ambos ocorreram nos USA. Por\u00e9m, a abordagem de an\u00e1lise de cr\u00e9dito \n\ndominou o desenvolvimento dos \u00edndices financeiros. Seu in\u00edcio remonta ao final do \n\ns\u00e9culo passado, quando os banqueiros americanos passaram a solicitar Balan\u00e7os \u00e0s \n\nempresas tomadoras de empr\u00e9stimos. Durante o ano de 1890 o volume e fluxo de \n\ninforma\u00e7\u00f5es financeiras crescia muito e come\u00e7ou-se a an\u00e1lise de itens correntes e \n\nn\u00e3o correntes. Ent\u00e3o, o uso de \u00edndices financeiros, na an\u00e1lise de declara\u00e7\u00f5es \n\nfinanceiras, pode ser dito ter iniciado com o advento dos \u00edndices correntes. A medida \n\nganhou aceita\u00e7\u00e3o ampla quando, em 9 de fevereiro de 1895, o Conselho Executivo da \n\nAssocia\u00e7\u00e3o dos Bancos do estado de New York resolveu recomendar ao seus \n\nmembros que solicitassem aos tomadores de empr\u00e9stimos declara\u00e7\u00f5es escritas e \n\nassinadas de seus ativos e passivos. Em 1900, esta mesma associa\u00e7\u00e3o divulgou um \n\nformul\u00e1rio de proposta de cr\u00e9dito que inclu\u00eda o espa\u00e7o para o Balan\u00e7o. \u00c9 bem \n\nprov\u00e1vel que, nesta \u00e9poca, os Balan\u00e7os apresentassem dados que eram examinados \n\napenas superficialmente, sem nenhuma t\u00e9cnica anal\u00edtica ou tentativa de medi\u00e7\u00e3o \n\nquantitativa.\n\nA literatura cont\u00e1bil do come\u00e7o do s\u00e9culo atual menciona a import\u00e2ncia de \n\ncompara\u00e7\u00f5es de dados das demonstra\u00e7\u00f5es financeiras, por\u00e9m as id\u00e9ias eram, via de \n\nregra, vagas em rela\u00e7\u00e3o ao que comparar. Com o decorrer dos anos e o sucessivo \n\nrecebimento de balan\u00e7os foi-se desenvolvendo \u00e1 no\u00e7\u00e3o de compara\u00e7\u00e3o de diversos \n\nitens, sendo o mais comum a do Ativo Circulante com o Passivo Circulante.\n\nNo per\u00edodo anterior e durante a I Guerra Mundial (1900 - 1919) ocorreram \n\ntr\u00eas grandes desenvolvimentos: - foram definidos um grande n\u00famero de \u00edndices; - \n\ncrit\u00e9rio de \u00edndice absoluto; - alguns analistas come\u00e7aram a reconhecer a necessidade \n\nde an\u00e1lise entre empresas, e conseq\u00fcentemente a necessidade de \u00edndices relativos. \n\nPor\u00e9m, ainda poucos analistas usavam \u00edndices, e aqueles que usavam, utilizavam \n\napenas um \u00edndice, o \u00edndice corrente.\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 17\n\nPor volta de 1913, chamava-se a aten\u00e7\u00e3o para outros \u00edndices como: dep\u00f3sitos \n\nbanc\u00e1rios em rela\u00e7\u00e3o ao exig\u00edvel, percentual de contas a receber em rela\u00e7\u00e3o aos \n\ndemais itens do ativo, percentual de estoques em rela\u00e7\u00e3o a vendas anuais.\n\nEntretanto, as demonstra\u00e7\u00f5es financeiras na \u00e9poca n\u00e3o eram preparadas \n\nadequadamente para os fins a que se destinavam. N\u00e3o havia uniformidade nas \n\ndisposi\u00e7\u00f5es e na terminologia, nem na classifica\u00e7\u00e3o das rubricas.\n\nImportante contribui\u00e7\u00e3o para a melhoria da forma de apresenta\u00e7\u00e3o das \n\ndemonstra\u00e7\u00f5es financeiras foi feita pelo Federal Reserve Board, em 1918, quando \n\npadronizou a forma dos Balan\u00e7os e das Demonstra\u00e7\u00f5es de Lucros e Perdas.\n\nEm 1919, Alexander Wall, considerado o pai da An\u00e1lise de Balan\u00e7os, \n\napresentou um modelo de An\u00e1lise de Balan\u00e7o atrav\u00e9s de \u00edndices. Ele tamb\u00e9m \n\nmostrou e tomou popular a necessidade de considerar outras rela\u00e7\u00f5es (\u00edndices) al\u00e9m \n\nde Ativo circulante contra passivo circulante.\n\nParalelamente, mas na \u00e1rea de gerenciamento, o uso de margem de lucro e \n\nturnovers, j\u00e1  estava bem desenvolvida.\n\nAlexander Wall desenvolveu, posteriormente, em parceria com outros autores, \n\nf\u00f3rmulas matem\u00e1ticas de avalia\u00e7\u00e3o de empresas, ponderando diversos \u00edndices de \n\nBalan\u00e7o.\n\nTendo adotado o m\u00e9todo de computar v\u00e1rios coeficientes, os autores sentiam a \n\nnecessidade de padr\u00f5es de refer\u00eancias que os auxiliassem em suas avalia\u00e7\u00f5es.\n\nEm mais ou menos 1919, a compania Du Ponte come\u00e7ou a usar um sistema de \n\ntri\u00e2ngulo nas avalia\u00e7\u00f5es de seus resultados operantes. No topo do tri\u00e2ngulo estava um \n\n\u00edndice de investimento sobre o retorno (lucro/total de assets) e a base consistia do \n\n\u00edndice de margem de lucro (lucro/vendas) e um \u00edndice de capital tumover. Este \n\nsistema fornece estrutura onde os \u00edndices podem ser desenvolvidos em um estilo \n\nl\u00f3gico.\n\nA d\u00e9cada de 1920 foi um per\u00edodo de grande entusiasmo para as possibilidades \n\nde usar \u00edndices financeiros como ferramenta de an\u00e1lise.\n\nEm 1925, Stephen Gilman fez algumas cr\u00edticas \u00e0 an\u00e1lise de \u00edndices, como por \n\nexemplo, suas mudan\u00e7as no tempo n\u00e3o podem ser interpretadas pois o numerador e \n\no denominador variam\u201d. Ele prop\u00f4s que a constru\u00e7\u00e3o de \u00edndices encadeados que\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 18\n\nindicassem as varia\u00e7\u00f5es havidas nos principais itens em rela\u00e7\u00e3o a um ano (iniciando o \n\nque chamamos de an\u00e1lise vertical).\n\nNa pr\u00f3xima decada existiram dois desenvolvimentos significantes \n\nrelacionados diretamente com os \u00edndices financeiros. O primeiro foram as discuss\u00f5es \n\nsobre a determina\u00e7\u00e3o do grupo de \u00edndices mais eficaz. Aqui pode-se destacar o \n\ntrabalho de Roy A. Foulke. A abordagem de Foulke pode ser chamada de \u201cemp\u00edrica \n\npragm\u00e1tica\u201d, e provavelmente foi suficiente para as necessidades dos que usavam a \n\nanalise de \u00edndices, mas deixa o sujeito da an\u00e1lise de \u00edndices livre de qualquer teoria \n\ntest\u00e1vel. Contudo, o segundo desenvolvimento significante desta \u00e9poca foi o estudo \n\ndo uso de \u00edndices financeiros para previs\u00e3o de dificuldades financeiras. Winakor e \n\nSmith iniciaram este movimento. Trabalharam tamb\u00e9m nesta linha Fitzpatrick, \n\nRanser e Foster [Horrigan, 1968], Eles representaram um evento extremamente \n\nsignificante no desenvolvimento de \u00edndices financeiros pois foram os primeiros que \n\ncuidadosamente se esfor\u00e7aram em usar m\u00e9todos cient\u00edficos para determinar a \n\nutilidade dos \u00edndices.\n\nNa d\u00e9cada de 30 tamb\u00e9m surgiu, dentro da empresa Du Pont, um modelo de \n\nan\u00e1lise da rentabilidade que decompunha a taxa de retomo em taxas de margem de \n\nlucro e giro dos neg\u00f3cios, chamado an\u00e1lise de ROI ( retum  on Investiment).\n\nDesde o in\u00edcio dos anos 40, o desenvolvimento da an\u00e1lise de \u00edndices \n\nfinanceiros continuou por v\u00e1rios caminhos. Um aspecto importante deste per\u00edodo foi \n\na crescente \u00eanfase dada ao papel dos \u00edndices financeiros nas opera\u00e7\u00f5es de pequenos \n\nneg\u00f3cios. A administra\u00e7\u00e3o de pequenos neg\u00f3cios, em particular, gerou muito \n\ninteresse na utilidade de \u00edndices financeiros como um instrumento de gerenciamento. \n\nOutro aspecto importante, foi o interesse pela an\u00e1lise de \u00edndices financeiros por \n\noutros pa\u00edses como Austr\u00e1lia, Inglaterra, Fran\u00e7a, \u00edndia, Jap\u00e3o, Canad\u00e1 e outros \n\n[Matarazzo, 1987; Horrigan, 1968].\n\nNo Brasil, at\u00e9 1968, a An\u00e1lise de Balan\u00e7o era um instrumento ainda pouco \n\nutilizado na pratica. Nesse ano, foi criada a SERASA, empresa que passou a operar \n\ncomo central de An\u00e1lise de Balan\u00e7os de bancos comerciais. Atualmente, novas \n\npesquisas est\u00e3o sendo efetuadas pela DIEM - Diagn\u00f3sticos Empresariais \n\nComputadorizados S/C Ltda. - cujo Know-how nada deve aos centros internacionais \n\nmais avan\u00e7ados [Matarazzo, 1987],\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 19\n\nOs \u00edndices financeiros s\u00e3o usados como entrada para modelos estat\u00edsticos para \n\nprever v\u00e1rios tipos de neg\u00f3cios e identificar caracter\u00edsticas financeiras. Horrigan em \n\n1966 usou a an\u00e1lise de correla\u00e7\u00e3o [Horrigan, 1965], Pinches e Ming em 1973 usaram \n\na An\u00e1lise Discriminante M\u00faltipla [Pinches &amp; Mingo, 1973] enquanto Ingram e \n\nCopeland em 1984 utilizaram a An\u00e1lise de Regress\u00e3o [Ingram &amp; Copeland, 1984], \n\nMas o principal foco foi sobre o teste ( principalmente multivariado) de modelos \n\nestat\u00edsticos que usaram \u00edndices financeiros para prever a fal\u00eancia de empresas. Estes \n\ns\u00e3o baseados no trabalho de Beaver (1966) e Altman (1968) [Beaver, 1966; Altman, \n1968],\n\nExiste lima multiplicidade de fatores que determinam a lucratividade de um \n\nneg\u00f3cio e suas chances de sobreviv\u00eancia. Um destes fatores, de interesse particular \n\naos indiv\u00edduos no gerenciamento dos neg\u00f3cios, \u00e9 a efic\u00e1cia da tomada de decis\u00e3o do \n\ngerenciamento. As informa\u00e7\u00f5es dos registros cont\u00e1beis da empresa servem como \n\nsinal que decis\u00f5es s\u00e3o necess\u00e1rias ou fornecem dados que podem ser usados na \n\ndecis\u00e3o.\n\nA raz\u00e3o para o uso da an\u00e1lise de \u00edndices financeiros \u00e9 que ela expressa as \n\ndiversas figuras das declara\u00e7\u00f5es financeiras como \u00edndices e a informa\u00e7\u00e3o revelar\u00e1 o \n\nque est\u00e1 faltando quando n\u00fameros individuais s\u00e3o observados. A teoria \u00e9 que gerentes \n\npodem ent\u00e3o usar esta informa\u00e7\u00e3o para melhorar a efici\u00eancia e a lucratividade de suas \n\nopera\u00e7\u00f5es. Associado com esta teoria est\u00e1 a suposi\u00e7\u00e3o impl\u00edcita que a informa\u00e7\u00e3o da \n\nan\u00e1lise de \u00edndices, especialmente a tend\u00eancia dos \u00edndices, capacibilita o \n\ngerenciamento prever e possivelmente evita a fal\u00eancia dos neg\u00f3cios.\n\nBeaver, em 1966, deu uma contribui\u00e7\u00e3o substancial para suportar parte da \n\ninforma\u00e7\u00e3o em estudo de \u00edndices financeiros diferenciando entre o sucesso e o n\u00e3o \n\nsucesso da empresa. O trabalho de Beaver \u00e9 um marco para as pesquisas de \u00edndices \n\nfinanceiros. Mais tarde estudos forneceram evid\u00eancias de que os \u00edndices financeiros \n\npodem prever a fal\u00eancia de coorpora\u00e7\u00f5es, pelo menos estatisticamente, por \n\ndesenvolver e testar fun\u00e7\u00f5es discriminantes preditivas [Altman, 1968; Deakin, 1976], \n\nContudo, somente Edmister [Edmister, 1972] usou uma amostra de pequenas \n\nempresas para desenvolver fun\u00e7\u00f5es discriminantes preditivas. Embora alguns \n\nconceitos metodol\u00f3gicos terem sido expressados com respeito \u00e0 previs\u00e3o\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 20\n\nretrospectiva da fal\u00eancia do neg\u00f3cio [Eisenbeis, 1977], os estudos mencionados acima \n\nt\u00eam fornecido evid\u00eancias do conte\u00fado de informa\u00e7\u00f5es dos \u00edndices financeiros.\n\nAl\u00e9m do fato de que, o uso da an\u00e1lise de \u00edndices financeiros por pequenas \n\nempresas ser muito importante e essencial na averigua\u00e7\u00e3o de como a firma est\u00e1 \n\noperando (eficientemente ou n\u00e3o) [Brigham, 1979], existem algumas evid\u00eancias \n\nemp\u00edricas sobre o melhoramento da lucratividade e sobreviv\u00eancia de pequenas \n\nempresas que usam \u00edndices financeiros, quando comparado com aquelas que n\u00e3o \n\nusam [Thomas &amp; Evanson, 1986],\n\nMuito estudos foram e est\u00e3o sendo feitos sobre a an\u00e1lise de \u00edndices \n\nfinanceiros. Entre eles est\u00e3o os estudos que usaram t\u00e9cnicas de Intelig\u00eancia Artificial \n\ncomo Redes Neuronais, Sistemas Especialistas e Conjuntos Difusos em An\u00e1lise de \n\n\u00edndices Financeiros para o diagn\u00f3stico da sa\u00fade financeira de empresas [Whalen &amp; \n\nSchott, 1985, Pacheco, 1986],\n\n2.4.3 Aspectos a Serem Considerados\n\nOutros aspectos importantes a serem considerados s\u00e3o os seguintes:\n\na) n\u00e3o \u00e9 necess\u00e1rio considerar um grande n\u00famero de \u00edndices financeiros afim \n\nde analisar uma situa\u00e7\u00e3o espec\u00edfica devido ao fato que muitos \u00edndices t\u00eam \n\nvari\u00e1veis em comum;\n\nb) a relev\u00e2ncia dos \u00edndices diferentes depende completamente da compara\u00e7\u00e3o \n\ndos \u00edndices com dados similares da mesma atividade econ\u00f4mica \n\n[Bemstein, 1989],\n\nAs principais \u00e1reas de pesquisa de \u00edndices financeiros s\u00e3o [Salmi &amp; \n\nMartikainen, 1994]:\n\n\u00ae a forma de funcionalidade dos \u00edndices financeiros;\n\n? propriedades estat\u00edsticas atrav\u00e9s do tempo;\n\n? categoriza\u00e7\u00e3o dos problemas financeiros.\n\nForma Funcional dos \u00edndices Financeiros\n\nEm rela\u00e7\u00e3o a forma de distribui\u00e7\u00e3o dos \u00edndices e seus comportamentos \n\nestat\u00edsticos, n\u00e3o existe ainda consenso na literatura. As diferentes formas de\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 21\n\ndistribui\u00e7\u00e3o dos \u00edndices dependem basicamente do tipo de \u00edndice e atividade \n\necon\u00f4mica [Bames, 1987; Ezzamel &amp; Mar-Molinero, 1990; Foster, 1987], Em rela\u00e7\u00e3o \n\nao comportamento do \u00edndice financeiro ao longo do tempo, na maioria dos casos os \n\n\u00edndices n\u00e3o t\u00eam um comportamento rand\u00f4mico e seu ajustamento depende das \n\ncondi\u00e7\u00f5es ambientais do setor, dos objetivos estrat\u00e9gico e da informa\u00e7\u00e3o desejada. \n\n[Ezzamel &amp; Mar-Molinero, 1990; [Chu, 1992; Lee &amp; Wu, 1988],\n\nTradicionalmente o maior objetivo do uso de dados financeiros na forma de \n\n\u00edndices \u00e9 tom ar os resultados compar\u00e1veis atrav\u00e9s de empresas e atrav\u00e9s do tempo \n\npara controlar o tamanho. O requerimento determinado usualmente no controle por \n\ntamanho \u00e9 que o numerador e o denominador sejam proporcionais. O trabalho \n\nprecursor que est\u00e1 neste campo \u00e9 de Lev and Sunder [Lev &amp; Sander, 1979], Com o \n\nobjetivo de avaliar a hip\u00f3tese da proporcionalidade, deve ser assumido alguma \n\nsuposi\u00e7\u00e3o em rela\u00e7\u00e3o ao tamanho da empresa e o setor econ\u00f4mico. A forma \n\nfuncional do denominador do \u00edndice \u00e9 muito importante para a validade da hip\u00f3tese.\n\nAlguns pesquisadores [Bames, 1982] mostraram que a n\u00e3o normalidade de \n\nv\u00e1rios \u00edndices pode ser deduzida da an\u00e1lise de proporcionalidade dos \u00edndices. \n\nHorrigan [Horrigan, 1983] coloca que a pesquisa de an\u00e1lise financeira deveria estar \n\nmais interessada no papel dos \u00edndices financeiros por si s\u00f3 ao inv\u00e9s da \u201cnatureza dos \n\ncomponentes dos \u00edndices ou no papel incidental dos \u00edndices como o desvio do \n\ntamanho dos dados \u201d. A validade dos \u00edndices financeiros deveria ser determinada \n\npelo seu sucesso no processo de tomada de decis\u00e3o das diferentes partes interessadas \n\n(donos, gerentes, empregados) [Salmi &amp; Marttikainen, 1994], Para ilustrar, \n\nconsidera-se o impacto potencial da economia de escala. Para avaliar a efici\u00eancia do \n\ngerenciamento uma compara\u00e7\u00e3o direta dos \u00edndices financeiros de grandes e pequenas \n\nempresas teria que ser ajustada para o efeito do tamanho. Por outro lado, um \n\ninvestidor avaliando diferentes investimentos pode estar mais interessado no n\u00edvel \n\nde lucratividade sem considerar se \u00e9 ou n\u00e3o o resultado do efeito do tamanho.\n\nMcDonald e Morris [McDonald &amp; Morris, 1984; McDonald &amp; Morris, 1985] \n\napresentaram o primeiro estudo emp\u00edrico extensivo da validade estat\u00edstica do m\u00e9todo \n\nde \u00edndice. Os autores estudaram a hip\u00f3tese da heterocedasticidade do modelo Y/X \n\nonde Y(i) = a + bX(i) + e(i). O modelo acima \u00e9 a id\u00e9ia central nesta \u00e1rea. Eles \n\nencontram suporte para a An\u00e1lise de \u00edndices Financeiros para compara\u00e7\u00f5es dentro de\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 22\n\nramos da ind\u00fastria, por\u00e9m em compara\u00e7\u00f5es inter-ind\u00fastrias a proporcionalidade dos \n\n\u00edndices financeiros n\u00e3o \u00e9 suportada.\n\nAlguns autores como B eny e Nix [Beny &amp; Nix, 1991], contudo, lan\u00e7aram \n\nd\u00favidas em rela\u00e7\u00e3o a generalidade do trabalho de McDonald e Morris. Pela \n\ncompara\u00e7\u00e3o de valores e \u00edndices agregados com pesos iguais McLeay e Fieldsend \n\n[McLeay &amp; Fieldsend, 1987] conclu\u00edram que o comportamento n\u00e3o proporcional de \n\nalguns \u00edndices financeiros varia com cada \u00edndice, tamanho da empresa e setor \n\necon\u00f4mico diferentes. Suposto ser convertida em caixa durante o ciclo operacional, o \n\ntermo bens fixos n\u00e3o \u00e9 correto e responde a um aspecto hist\u00f3rico. Mais \n\nprecisamente, bens fixos s\u00e3o compostos por bens que afirma reserva em diversos \n\nper\u00edodos, a fim de manter o neg\u00f3cio. As despesas correntes s\u00e3o compostas e d\u00e9bito a \n\ncurto prazo que na maioria dos casos seus pagamentos est\u00e3o relacionados com a \n\nconvers\u00e3o de bens correntes em caixa. Os d\u00e9bitos a longo prazo s\u00e3o compostos por \n\nd\u00e9bitos cuja maturidade dos dados est\u00e3o a mais de um ano formando os dados do \n\nBalan\u00e7o Patrinomial corrente. A categoria das a\u00e7\u00f5es representa quantos destes bens \n\nest\u00e3o financiados pelos donos da empresa.\n\nE digno mencionar que o desvio da proporcionalidade dos \u00edndices financeiros \n\nest\u00e1 na verdade relacionado \u00e0 hip\u00f3tese de distribui\u00e7\u00e3o. Por exemplo, Fieldsend, \n\nLongford e McLeay [Fieldsend et al., 1987] notaram que alguns \u00edndices s\u00e3o \n\nesperados ser uma distribui\u00e7\u00e3o log-normal devido ao limite inferior. \n\nConsequentemente eles testaram empiricamente um modelo de regress\u00e3o log-normal \n\nlnY(ij) = a + blnX(ij) + g(j) + e(ij) onde o efeito da ind\u00fastria g(j) \u00e9 especificado \n\nexplicitamente pelo modelo. Outros trabalhos est\u00e3o em correspond\u00eancia com as \n\npesquisas mencionadas: a hip\u00f3tese da proporcionalidade tem suporte te\u00f3rico somente \n\nse os efeitos da atividade econ\u00f4mica espec\u00edfica s\u00e3o considerados.\n\nOutro aspecto importante em rela\u00e7\u00e3o a forma de funcionalidade dos \u00edndices \n\nfinanceiros \u00e9 a exist\u00eancia de \u00edndices baseado no mercado; estes \u00edndices n\u00e3o ser\u00e3o \n\nconsiderados neste trabalho devido \u00e0 suposi\u00e7\u00e3o em rela\u00e7\u00e3o ao tamanho da empresa \n\n(trabalha-se com pequenas empresa). Mas por outro lado \u00e9 importante mencionar que \n\neste tipo de \u00edndices tamb\u00e9m apresentam desvios da hip\u00f3tese da proporcionalidade\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 23\n\ncomo foi mostrado na an\u00e1lise do \u00edndice E/P2 por Booth, Martikainen, Perttunen e Yli- \n\nOlli [Booth et al., 1994],\n\nCaracter\u00edsticas de Distribui\u00e7\u00e3o dos \u00edndices Financeiros\n\nA motiva\u00e7\u00e3o para olhar para as propriedades da distribui\u00e7\u00e3o normal dos \n\n\u00edndices financeiros \u00e9 porque geralmente na an\u00e1lise de \u00edndices financeiros assume-se \n\nque os \u00edndices tenham uma distribui\u00e7\u00e3o normal. Isto \u00e9 devido \u00e0 import\u00e2ncia dos testes \n\nnos m\u00e9todos param\u00e9tricos que prevalecem nas pesquisas de an\u00e1lise de \u00edndices \n\nfinanceiros. Podemos citar, por exemplo, a an\u00e1lise de regress\u00e3o e a an\u00e1lise \n\ndiscriminante que confiam na suposi\u00e7\u00e3o da normalidade.\n\nUm dos trabalhos pioneiros neste \u00e1rea foi feito por Mecimore. Usando \n\nmedidas estat\u00edsticas descritivas (desvio padr\u00e3o, m\u00e9dia) ele encontrou a n\u00e3o \n\nnormalidade cross-seccional e assimetria positiva na amostra de 500 empresas Fortum \n\nselecionadas randomicamente [Mecimore, 1968],\n\nO trabalho mais citado na literatura, e tamb\u00e9m o trabalho pioneiro neste \n\ncampo foi feito por Deakin [Deakin, 1976], Suas descobertas qui-quadradas rejeitam \n\n(com uma exce\u00e7\u00e3o) a normalidade de onze \u00edndices numa amostra de 1114 \n\ncompanhias. Desvio menores foram observados quando transforma\u00e7\u00f5es logar\u00edtmicas \n\ne raiz-quadrada foram aplicadas, mas a normalidade n\u00e3o foi ainda suportada.\n\nOutros pesquisadores posteriores [Bird &amp; McHugh, 1977] tamb\u00e9m \n\nconfirmaram a hip\u00f3tese da n\u00e3o normalidade. Estas evid\u00eancias guiaram muitos \n\npesquisadores a procurar alguns m\u00e9todos que pudessem restituir a hip\u00f3tese da \n\nnormalidade. Os m\u00e9todos mais comuns usados foram transforma\u00e7\u00f5es funcionais e \n\nremover os pontos discrepantes.\n\nFinalmente, \u00e9 bom mencionar que a pesquisa conduzida por Watson [Watson, \n\n1990] que examinou as propriedades das distribui\u00e7\u00f5es de quatro \u00edndices de \n\nquatrocentas amostras de empresas. O principal resultado foi que a distribui\u00e7\u00e3o \n\nnormal multivariada e rejeitada se os pontos discrepantes n\u00e3o s\u00e3o removidos.\n\n2 E/P = Eamings/price (Lucro/Pre\u00e7o)\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 24\n\nC ategoriza\u00e7\u00e3o dos \u00edndices Financeiros\n\nUma quest\u00e3o principal em An\u00e1lise de \u00edndices Financeiros e na pr\u00e1tica \u00e9 \n\ndeterminar um conjunto de \u00edndices financeiros que cubra as atividades da empresa. \n\nExistem na literatura quatro abordagens principais em rela\u00e7\u00e3o a classifica\u00e7\u00e3o dos \n\n\u00edndices financeiros. A descri\u00e7\u00e3o b\u00e1sica \u00e9 mostrada abaixo:\n\na) Abordagem Pragm \u00e1tica: Baseada na experi\u00eancia pr\u00e1tica ou nas vis\u00f5es dos\n\nautores [Lev, 1974; Foster, 1978; Bemstein, 1989; White et al., 1994].\n\nb) Abordagem  Dedutiva: Baseada no sistema do tri\u00e2ngulo Du Pont da Figura\n\n2.6 (( lucro/ bens totais), (lucro/vendas) e (vendas/bens totais)) [Courtis, \n\n1978; Laitinen, 1983],\n\nc) Abordagem  Indutiva: Baseada principalmente nos dados e m\u00e9todos \n\nestat\u00edsticos [Pinches &amp; Mingo, 1973; Chen &amp; Shimerda,1981; Aho, 1980; \n\nYli-Olli &amp; Virtanen, 1986; Yli-Olli &amp; Virtanen, 1989; Yli-Olli &amp; Virtanen, \n\n1990],\n\nd) Abordagem C onfirm at\u00f3ria: Sup\u00f5e uma classifica\u00e7\u00e3o a priori e ent\u00e3o tenta \n\nconfirmar a classifica\u00e7\u00e3o com evid\u00eancias emp\u00edricas [Laurent, 1979; Luoma \n\n&amp; Ruuhela, 1991; Kandel &amp; Langholz, 1992],\n\nVendas /\n\nLucro\n\n/ \\\nSv Bens totais\n\nF igura 2.6: T ri\u00e2ngulo Du Pont [M atarazo, 1887].\n\nClassifica\u00e7\u00e3o dos \u00edndices\n\nNa literatura, duas esp\u00e9cies de padr\u00f5es de classifica\u00e7\u00e3o de \u00edndices financeiros \n\ntem sido apresentado. Tradicionalmente, a fim de ilustrar a dimens\u00e3o chave da \n\nempresa os \u00edndices s\u00e3o classificados de acordo com sua interpreta\u00e7\u00e3o conceituai \n\nconvencional. O padr\u00e3o de classifica\u00e7\u00e3o tradicional apresentado por LEV divide \n\n\u00edndices financeiros em 4 categorias [Lev, 1974]:\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 25\n\n\u00edndice de Lucratividade: S\u00e3o constru\u00eddos para avaliar a performance \n\noperacional da empresa\n\n\u00edndice de liquidez: Foi definida para definir para indicar a habilidade da\n\nempresa saldar suas obriga\u00e7\u00f5es financeiras a curto prazo.\n\n\u00edndice de alavancagem  financeira (solv\u00eancia a longo prazo): Indica como a\n\nempresa pode saldar o juro e o capital das obriga\u00e7\u00f5es a longo prazo.\n\n\u00edndice de efici\u00eancia (giro): S\u00e3o designados para medir a efici\u00eancia operacional\n\nda empresa.\n\nA classifica\u00e7\u00e3o de LEV \u00e9 mais popular, mas existem tamb\u00e9m, por exemplo, a \n\nclassifica\u00e7\u00e3o de Horrigan, Courtis e de Tamari [Horrigan, 1965; Courtis, 1978; \nTamari, 1978],\n\nA segunda forma de criar padr\u00f5es de classifica\u00e7\u00e3o de \u00edndices financeiros \u00e9 \n\nselecionar uma faixa ampla de \u00edndices financeiros diferentes e estudar como estes \n\n\u00edndices est\u00e3o classificados empiricamente. O principal objetivo nestes estudos tem \n\nsido expressar a quantidade m\u00e1xima de informa\u00e7\u00e3o nos \u00edndices financeiros originais \n\npor um conjunto reduzido de fatores. O estudo b\u00e1sico desta \u00e1rea foi feito por Pinches \n\ne Mingo em 1973 que classificaram 48 \u00edndices de 221 empresas em 7 categorias \n\nemp\u00edricas [Pinches &amp; Mingo, 1973]:\n\n? retomo sobre investimentos\n\n? grau de utiliza\u00e7\u00e3o do capital\n\n? grau de utiliza\u00e7\u00e3o do estoque\n\n? alavancagem financeira\n\n? grau de depend\u00eancia das vendas a prazo\n\n? liquidez a curto prazo\n\n? posi\u00e7\u00e3o do caixa\n\nJohnson, usando an\u00e1lise de componentes principais e o m\u00e9todo de rota\u00e7\u00e3o \n\nortogonal, reportou 9 fatores emp\u00edricos para 41 \u00edndices [Johnson, 1978], Outros \n\nautores tamb\u00e9m classificaram os \u00edndices em categorias [Laurent, 1979; Aho, 1980' \n\nGombola &amp; Ketz, 1983; Yli-Olli &amp; Virtanen, 1986] - Tabela 2.1).\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 9 fs\n\nClassifica\u00e7\u00e3o dos \u00edndices em categorias\nLev(1974) lucratividade, liquidez, alavancagem \n\nfinanceira, efici\u00eancia (siro)\nPmches, Mingo e Carruthes (1973) retomo sobre investimentos, grau de \n\nutiliza\u00e7\u00e3o do capital, grau de utiliza\u00e7\u00e3o do \nestoque, alavancagem financeira, grau de \ndepend\u00eancia das vendas a prazo, liquidez a \ncurto prazo, posi\u00e7\u00e3o do caixa\n\nAho (1980) estrutura financeira, lucratividade, liquidez, \n\u00edndices de giro e \u00edndice de capital de giro, e \noportunidades financeiras para \ninvestimento\n\nYli-Olli (1986) lucratividade, fluxo de caixa de opera\u00e7\u00f5es \ne estrutura de gastos, liquidez a curto \nprazo, estrutura do capital, receivable \nintensiveness.\n\nTabela 2.1 Classifica\u00e7\u00e3o dos \u00edndices F inanceiros segundo alguns pesquisadores.\n\nQuando se interpreta os resultados concernentes aos padr\u00f5es de classifica\u00e7\u00e3o\n\nemp\u00edricos de \u00edndices financeiros deve-se levar em conta que a classifica\u00e7\u00e3o depende\n\nmuito dos \u00edndices selecionados, e a utilidade destas categorias em problemas pr\u00e1ticos\n\n\u00e9 relativamente baixa se os fatores emp\u00edricos n\u00e3o puderem ser interpretados \nclaramente.\n\n2.4.4 Principais \u00edndices Financeiros\n\nA an\u00e1lise atrav\u00e9s de \u00edndices \u00e9 certamente a mais conhecida, chegando mesmo \n\na ser confundida com a an\u00e1lise de Balan\u00e7o. Ao longo do tempo, diversos estudos t\u00eam \n\ndemonstrado a validade dos \u00edndices financeiros, como \u201cferramenta\u201d que propicia a \n\nmedida de desempenho e a solidez das empresas [Silva, 1988],\n\nNo Quadro 2.1 que resume os principais \u00edndices que s\u00e3o utilizados na an\u00e1lise de \n\nBalan\u00e7o. Para facilitar, dividimos estes \u00edndices em 6 categorias:\n\n\u2022 \u00edndices de e stru tu ra  de capitais : Estes \u00edndices s\u00e3o aqueles que relacionam a \n\ncomposi\u00e7\u00e3o de capitais (pr\u00f3prios e de terceiros), que medem os n\u00edveis de \n\nimobiliza\u00e7\u00e3o de recursos e que buscam diversas rela\u00e7\u00f5es na estrutura da d\u00edvida da \n\nempresa. De certa forma, estes \u00edndices est\u00e3o ligados \u00e0s decis\u00f5es financeiras de \n\nfinanciamento e investimento.\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 27\n\n\u2022 \u00edndices de E s tru tu ra  do Ativo C irculante: Estes \u00edndices fornecem elementos \n\npara an\u00e1lise e controle das v\u00e1rias contas do circulante.\nr\n\n\u2022 \u00edndices de C apital de Giro: Estes fornecem valores para uma melhor avalia\u00e7\u00e3o da \n\nparticipa\u00e7\u00e3o e liquidez dos recursos pr\u00f3prios a curto prazo.\nr\n\n\u2022 \u00edndices de Liquidez: Estes \u00edndices visam fornecer uma medida, ou melhor, um \n\nindicador da capacidade da empresa de pagar suas d\u00edvidas a partir da compara\u00e7\u00e3o \n\nentre os direitos realiz\u00e1veis ( a curto e a longo prazo) e a exigibilidade (tamb\u00e9m de \n\na curto e a longo prazo).\n\n\u2022  \u00edndices de Rota\u00e7\u00e3o: os \u00edndices de rota\u00e7\u00e3o constituem-se em categorias de elevada \n\nimport\u00e2ncia para o analista. O balan\u00e7o da empresa representa sua situa\u00e7\u00e3o \n\npatrimonial em determinado momento, isto \u00e9, como se fosse um fato que mostra \n\nalgo de forma est\u00e1tica, sem refletir sua mobilidade, seu d in a m ism o  A empresa, em \n\nsuas opera\u00e7\u00f5es, compra, fabrica, estoca, vende e recebe num processo din\u00e2mico e \n\ncont\u00ednuo. Os \u00edndices de rota\u00e7\u00e3o t\u00eam grande contribui\u00e7\u00e3o na interpreta\u00e7\u00e3o da \n\nliquidez e da rentabilidade da empresa, \u00e0 medida que servem de indicadores dos \n\nprazos m\u00e9dios de rota\u00e7\u00e3o de estoques, recebimentos das vendas e pagamento das \n\ncompras.\nw\n\n\u2022 \u00edndices de Retorno: Os \u00edndices de retomo, tamb\u00e9m conhecidos por \u00edndices de \n\nlucratividade ou mesmo rentabilidade, indicam qual o retomo que o \n\nempreendimento est\u00e1 propiciando aos seus acionistas ou propriet\u00e1rios. Podem-se \n\nobter, atrav\u00e9s da an\u00e1lise das compara\u00e7\u00f5es financeiras, os indicadores de retomo \n\nsobre o investimento, retomo sobre vendas e retomo sobre capital pr\u00f3prio, entre \noutros.\n\nE bom lembrar aqui que esta classifica\u00e7\u00e3o n\u00e3o \u00e9 muito f\u00e1cil, pois os \u00edndices \n\nest\u00e3o inter-relacionados e s\u00e3o interdependentes entre si (servindo este agrupamento \n\npor categorias como uma forma did\u00e1tica de apresent\u00e1-los). Um mesmo \u00edndice pode \n\nser usado como indicador de mais de um problema (embora, eles n\u00e3o forne\u00e7am o \n\nmesmo n\u00edvel de informa\u00e7\u00e3o em cada caso). Al\u00e9m disto, a an\u00e1lise de \u00edndices \u00e9 mais \n\ncomplexa na medida que a conclus\u00e3o final depende da an\u00e1lise conjunta de um \n\nconjunto de \u00edndices que refletem a empresa.\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 28\n\n2.4.5 Outros Aspectos\n\nEmbora autores e profissionais de An\u00e1lise de Balan\u00e7o tenham alguns pontos \n\nem comum quanto aos principais \u00edndices de que se valem, existem algumas \n\ndiferen\u00e7as em suas an\u00e1lises. Certos \u00edndices como Participa\u00e7\u00e3o de Terceiros, Liquidez \n\nCorrente e Rentabilidade do patrim\u00f4nio L\u00edquido, s\u00e3o usados por praticamente todos \n\nos analistas. Outros por\u00e9m, como Composi\u00e7\u00e3o do Endividamento, Liquidez Seca, \n\nRentabilidade do Ativo, Margem L\u00edquida de Lucro, nem sempre fazem parte dos \n\nmodelos de an\u00e1lise.\n\nO importante n\u00e3o \u00e9 um grande n\u00famero de \u00edndices, mas de um conjunto de \n\n\u00edndices que permita conhecer a situa\u00e7\u00e3o da empresa, segundo o grau de profundidade \n\ndesejada da an\u00e1lise.\n\nEntretanto, a an\u00e1lise de \u00edndices \u00e9 do tipo que come\u00e7a muito bem e vai \n\nperdendo f\u00f4lego \u00e0 medida que se acrescentam novos \u00edndices [Matarazzo, 1987], \n\nQuando, por exemplo, se dobra o n\u00famero de \u00edndices, n\u00e3o se consegue dobrar a \n\nquantidade de informa\u00e7\u00f5es. Isto pode ser ilustrado pela Figura 2.7.\n\nk Quantidade de\nInforma\u00e7\u00f5es\n\nA2 { .....\n\n*{/ !  1\n: \u201e Ouantidade de\n\nAxi Ax2 \u00edndices.\n\nF ig u ra 2.7: C urva da rela\u00e7\u00e3o quantidade de inform a\u00e7\u00e3o versus quantidade de \u00edndices \n[M atarazzo, 1987].\n\nE importante saber quais \u00edndices devem ser selecionados como referencial de \n\navalia\u00e7\u00e3o da empresa e quais ter\u00e3o fun\u00e7\u00e3o complementar no aux\u00edlio ao analista, em \n\nsua interpreta\u00e7\u00e3o da tend\u00eancia da empresa. Tamb\u00e9m \u00e9 necess\u00e1rio conhecer a \n\nimport\u00e2ncia relativa de cada \u00edndice no contexto geral, no sentido de se determinar se \n\ncada \u00edndice receber\u00e1 um peso espec\u00edfico ou se ser\u00e3o atribu\u00eddos pesos iguais a todos os \n\n\u00edndices.\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 29\n\nO n\u00famero de \u00edndices a ser utilizado deve levar em considera\u00e7\u00e3o os seguintes\n\npontos:\n\na) Utilidade dos \u00edndices: Os \u00edndices devem ter uma rela\u00e7\u00e3o direta com o que \n\ndeseja-se analisar. Eles devem ser abrangentes e um pouco sens\u00edveis em \n\nrela\u00e7\u00e3o \u00e0 sa\u00fade financeira da empresa (bom ,m\u00e9dio e ruim); mas n\u00e3o t\u00e3o \n\nsens\u00edveis em rela\u00e7\u00e3o aos aspectos de tamanho da empresa.\n\nb) Contribui\u00e7\u00e3o: como pode ser visto na Figura 2.7, deve-se levar em conta \n\nrela\u00e7\u00e3o quantidade de \u00edndices versus o benef\u00edcio adicional na avalia\u00e7\u00e3o da \n\nempresa.\n\nc) Praticidade: um n\u00famero muito grande de \u00edndices tende a confundir o \n\nanalista (principalmente se o analista ainda n\u00e3o tem muita experi\u00eancia).\n\nd) Seguran\u00e7a: o n\u00famero de \u00edndices utilizados deve propiciar ao analista \n\nrazo\u00e1vel grau de tranq\u00fcilidade quanto a efic\u00e1cia da avalia\u00e7\u00e3o do risco.\n\nAl\u00e9m da escolha dos \u00edndices, \u00e9 importante atribuir um peso (um conceito) a \n\ncada um dos \u00edndices, de modo que se tenha uma avalia\u00e7\u00e3o final da empresa, em face \n\ndos padr\u00f5es adotados. Tais padr\u00f5es devem ser constitu\u00eddos com base em empresas de \n\nmesma atividade, da mesma regi\u00e3o geogr\u00e1fica e, se poss\u00edvel, do mesmo porte.\n\nExistem tr\u00eas tipos b\u00e1sicos de avalia\u00e7\u00f5es de um \u00edndice [Matarazzo, 1987]:\n\n1. pelo significado intr\u00ednseco;\n\n2. pela compara\u00e7\u00e3o ao longo de v\u00e1rios exerc\u00edcios;\n\n3. pela compara\u00e7\u00e3o com \u00edndices de outras empresas - \u00edndices-padr\u00e3o.\n\nNa avalia\u00e7\u00e3o intr\u00ednseca de um \u00edndice \u00e9 poss\u00edvel, de maneira grosseira, avaliar \n\n\u00edndices pelo seu significado intr\u00ednseco. Por exemplo, pode-se tentar qualificar a \n\nsitua\u00e7\u00e3o financeira de uma empresa com base no \u00edndice de Liquidez Corrente: se \n\napresentar valor de 1,5, sabe-se que para cada unidade monet\u00e1ria de d\u00edvida a curto \n\nprazo existem 1,5 unidades monet\u00e1rias de investimento a curto prazo. A folga de 50%\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 30\n\npode ser considerada suficiente como margem de seguran\u00e7a \u00e0 empresa, essa \n\nconclus\u00e3o \u00e9 feita ou por intui\u00e7\u00e3o ou por experi\u00eancia do analista.\n\nMas, a an\u00e1lise do valor intr\u00ednseco de um \u00edndice \u00e9 limitada e s\u00f3 deve ser usada \n\nquando n\u00e3o disp\u00f5e de \u00edndices-padr\u00f5es proporcionados pela an\u00e1lise de um conjunto \n\nde empresas.\n\nN a compara\u00e7\u00e3o dos \u00edndices no tempo, a compara\u00e7\u00e3o dos \u00edndices de uma \n\nempresa com os valores observados nos anos anteriores revela-se bastante \u00fatil por \n\nmostrar tend\u00eancias seguidas pela empresa. Por exemplo, se por um lado uma empresa \n\npode endividar-se mais a cada exerc\u00edcio e, simultaneamente, apresentar aumento de \n\nsua rentabilidade, por outro lado pode ocorrer redu\u00e7\u00e3o dos \u00edndices de liquidez. Essas \n\ninforma\u00e7\u00f5es permitem ao analista formar uma opini\u00e3o a respeito de diversas pol\u00edticas \n\nseguidas pela empresa, bem como das tend\u00eancias que est\u00e3o sendo registradas. \u00c9 \n\nfundamental em qualquer avalia\u00e7\u00e3o que os \u00edndices sejam analisados conjuntamente.\n\nNa compara\u00e7\u00e3o com padr\u00f5es, a avalia\u00e7\u00e3o de um \u00edndice e a sua conceitua\u00e7\u00e3o \n\ncomo \u00f3timo, bom, satisfat\u00f3rio, razo\u00e1vel ou deficiente s\u00f3 pode ser feita atrav\u00e9s da \n\ncompara\u00e7\u00e3o com padr\u00f5es. Assim \u00e9 preciso definir um conjunto (universo) e, em \n\nseguida, comparar um elemento com os demais do conjunto para atribuir-lhe \n\ndeterminada qualifica\u00e7\u00e3o. Este \u00e9 um processo natural do racioc\u00ednio humano onde \n\ntodas avalia\u00e7\u00f5es s\u00e3o feitas por compara\u00e7\u00f5es, ainda que dificilmente tabuladas \n\nmetodologicamente (por isso as diverg\u00eancias de opini\u00f5es).\n\nNo Brasil, a Serasa \u00e9 certamente quem possui um dos maiores arquivos de \n\nempresas analisadas, as quais s\u00e3o utilizadas para elabora\u00e7\u00e3o de \u00edndices-padr\u00f5es, \n\ncompreendendo praticamente todo o territ\u00f3rio nacional e todos os segmentos e \n\natividades empresariais. Tais padr\u00f5es s\u00e3o usados pela pr\u00f3pria Serasa para atribui\u00e7\u00e3o \n\nde avalia\u00e7\u00e3o \u00e0s empresas por ela analisadas.\n\nO processo geral de extra\u00e7\u00e3o de informa\u00e7\u00f5es importantes para suportar \n\ndecis\u00f5es numa empresa n\u00e3o \u00e9 simples. Este processo depende do setor econ\u00f4mico, do \n\ntamanho da empresa, do padr\u00e3o de compara\u00e7\u00e3o e al\u00e9m disso \u00e9 din\u00e2mico. Portanto, a \n\nAn\u00e1lise Financeira \u00e9 um processo que requer especialistas com muita experi\u00eancia. A \n\nprimeira quest\u00e3o em An\u00e1lise Financeira \u00e9 a categoriza\u00e7\u00e3o do problema. Por\u00e9m, \u00e9 \n\nimportante notar que os limites entre cada uma das categorias n\u00e3o \u00e9 r\u00edgida. A\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 31\n\nprincipal raz\u00e3o \u00e9 devido ao fato que as categorias sobrep\u00f5em-se no tempo; isto \u00e9, um \n\nproblema de d\u00e9bito pode transformar-se em um problema de lucratividade no futuro \n\ne vice versa. Isto mostra a que uma figura financeira (por exemplo, \u00edndices) n\u00e3o \n\nperten\u00e7a estritamente a uma categoria. O que sem d\u00favida est\u00e1 presente s\u00e3o graus \n\ndiferentes de rela\u00e7\u00f5es entre cada uma das categorias.\n\nA principal conclus\u00e3o extra\u00edda do trabalho de Salmi e Martikainen [Salmi &amp; \n\nMarttikainen, 1994] \u00e9 que a melhor abordagem para a classifica\u00e7\u00e3o dos \u00edndices \n\ndepende do problema, isto \u00e9, depende do objetivo da an\u00e1lise de \u00edndices e o meio da \n\naplica\u00e7\u00e3o. Particularmente para o diagn\u00f3stico da sa\u00fade financeira de pequenas \n\nempresas, atrav\u00e9s do racioc\u00ednio indutivo, uma abordagem adequada identificada por \n\nMartins [Martins, 1996] \u00e9 a metodologia emp\u00edrica-pragm\u00e1tica de LEV citada na se\u00e7\u00e3o \n\n1.4.3.3.\n\nS\u00edmbolo \u00edndice F\u00f3rmula , Indica - \u2019 '\nEstrutura de \n\nCapital w? m\u00casms\u00ca&amp;m\n1. CT/PL \u2022  Participa\u00e7\u00e3o de \n\ncapitais de \nterceiros \n(endividamento)\n\nCapital de terceiros/ \nPatrim\u00f4nio L\u00edquido\n\n0  percentual de capitais de terceiros em \nrela\u00e7\u00e3o ao Patrim\u00f4nio L\u00edquido, retratando a \ndepend\u00eancia da empresa em rela\u00e7\u00e3o aos \nrecursos externos.\n\n2. PC/CT \u2022  Composi\u00e7\u00e3o do \nendividamento\n\nPassivo Circulante/ \nCapitais de terceiros\n\nIndica quanto da d\u00edvida total da empresa \ndever\u00e1 ser pado a curto prazo, isto \u00e9, comp\u00f5e \no ativo circulante.\n\n3. AP/PL \u2022  Imobiliza\u00e7\u00e3o do \nPatrim\u00f4nio \nL\u00edquido\n\nAtivo Permanente/ \nPatrim\u00f4nio L\u00edquido\n\nQuanto do Patrim\u00f4nio L\u00edquido da empresa \nest\u00e1 aplicado no ativo permanente.\n\n4. AP/ \nPL+ELP\n\n\u2022  Imobiliza\u00e7\u00e3o dos \nRecursos n\u00e3o \ncorrentes\n\nAtivo Permanente/ \n(Patrim\u00f4nio L\u00edquido + \n\nExig\u00edvel a Longo Prazo)\n\nQuanto dos recursos n\u00e3o concorrentes \n(Patrim\u00f4nio L\u00edquido e Exig\u00edvel a longo prazo) \nfoi destinado ao Ativo Permanente\n\nEstrutura do \nPassivo wmm\u00camm\u00cai\n\n1. PL/PC \u2022  Participa\u00e7\u00e3o do \nexig\u00edvel a curto \nprazo\n\nPatrim\u00f4nio L\u00edquido/ \nPassivo Circulante\n\nIndica a propor\u00e7\u00e3o de recursos propnos em \nrela\u00e7\u00e3o aos recursos de terceiros aplicados a \ncurto prazo. O inverso (Passivo Circulante/PL) \nfornece o n\u00edvel de endividamento a curto prazo \nda empresa.\n\n2. PL/ELP \u2022  Participa\u00e7\u00e3o do \nexig\u00edvel a longo \nprazo\n\nPatrim\u00f4nio L\u00edquido/ \nExig\u00edvel a longo Prazo\n\nIndica a propor\u00e7\u00e3o de recursos pr\u00f3prios em \nrela\u00e7\u00e3o aos recursos de terceiros a longo \nprazo. 0  inverso (Exig\u00edvel a LP/PL) fornece o \nn\u00edvel de endividamento a longo prazo da \nempresa.\n\n3. PL/ET \u2022  Participa\u00e7\u00e3o do \nexig\u00edvel total\n\nPatrim\u00f4nio L\u00edquido/ \nExig\u00edvel Total\n\nIndica a propor\u00e7\u00e3o de recursos pr\u00f3prios em \nrela\u00e7\u00e3o ao total de recursos de terceiros \nexistentes na empresa.\n\n4. PL/PT \u2022  Participa\u00e7\u00e3o do \npassivo total\n\nPatrim\u00f4nio L\u00edquido/ \nPassivo Total\n\nIndica a propor\u00e7\u00e3o de recursos pr\u00f3prios em \nrela\u00e7\u00e3o ao total de recursos (pr\u00f3prios e de \nterceiros) existentes na empresa.\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 32\n\n.. ' '.... ... .. \u2022 ' ? Estrutura da Ativo \nCirculante 1\n\n1. Disp/AC \u2022  Participa\u00e7\u00e3o do \nDispon\u00edvel\n\nDispon\u00edvel/ \nAtivo Circulante\n\nIndica a porcentagem de participa\u00e7\u00e3o das \ndisponibilidades no ativo circulante.\n\n2. RLP/AC \u2022  Participa\u00e7\u00e3o do \nRealiz\u00e1vel\n\nRealiz\u00e1vel a curto prazo/ \nAtivo Circulante\n\nIndica a porcentagem de participa\u00e7\u00e3o dos \ndireitos realiz\u00e1veis a curto prazo no ativo \ncirculante.\n\n3. E/AC \u2022  Participa\u00e7\u00e3o dos \nEstoques\n\nEstoques/ \nAtivo Circulante\n\nIndica a porcentagem de participa\u00e7\u00e3o dos \nestoques no ativo circulante.\n\n4. AC/AT \u2022  Participa\u00e7\u00e3o do \nCirculante Total\n\nAtivo Circulante/ \nAtivo Total\n\nIndica a participa\u00e7\u00e3o relativa do ativo \ncirculante no total do Ativo.\n\n5. Emp/AC \u2022  Participa\u00e7\u00e3o de \nrecursos de \nterceiros\n\nEmpr\u00e9stimos/ \nAtivo Circulante\n\nIndica a participa\u00e7\u00e3o relativa dos empr\u00e9stimos \nno ativo circulante.\n\n6 . Fom/AC \u2022  Participa\u00e7\u00e3o de \ncredores\n\nFornecedores/ \nAtivo Circulante\n\nIndica a participa\u00e7\u00e3o relativa de fornecedores \nno ativo circulante.\n\nCapital de Giro\n1. CG/AC \u2022  Volume de \n\nrecursos pr\u00f3prios \naplicados a curo \nprazo\n\nCapital de Giro/ \nAtivo Circulante\n\nIndica a porcentagem dos recursos pr\u00f3prios da \nempresa aplicados no ativo circulante.\n\n2. CG/PL \u2022  Liquidez dos \nrecursos pr\u00f3prios\n\nCapital de Giro/ \nPatrim\u00f4nio L\u00edquido\n\nIndica a porcentagem de liquidez dos recursos \npr\u00f3prios da empresa; ou seja, do total do seu \npatrim\u00f4nio l\u00edquido, qual o volume aplicado em \nitens de r\u00e1pida convers\u00e3o\n\nLiquidez\n1. LG \u2022  Liquidez Geral (Ativo Cir. + Realiz. a \n\nLongo Prazo)/ \n(Passivo Cir. + Exig.a \n\nLongo Prazo)\n\nIndica quanto a empresa possuem em dinheiro, \nbens e direitos realiz\u00e1veis a curto e longo \nprazo, para fazer face \u00e0s suas d\u00edvidas.\n\n2. LC \u2022  Liquidez Corrente .Ativo Circulante/ \nPassivo Circulante\n\nIndica quanto a empresa possui em dinheiro \nmais bens e direitos realiz\u00e1veis no pr\u00f3ximo \nexerc\u00edcio, comparado com suas d\u00edvidas a \nserem pagas no mesmo per\u00edodo.\n\n3. LS \u2022  Liquidez Seca (Dispon\u00edvel+T\u00edtulos a \nRec. + Outros Ativos de \n\nR\u00e1pida Conversibilidade)/ \nPassivo Circulante\n\nIndica quanto a empresa possui em dinheiro, \nmais aplica\u00e7\u00f5es financeiras, mais T\u00edtulos a \nReceber e Outros Ativos de R\u00e1pida \nConversibilidade, para fazer face ao seu \nPassivo Circulante.\n\n4. LA \u2022  Liquidez Absoluta Dispon\u00edvel / \nPassivo Circulante\n\nIndica a porcentagem das d\u00edvidas a curto prazo \nem condi\u00e7\u00f5es de serem saldadas \nimediatamente.\n\n5. LE \u2022  Liquidez \nEstimada\n\n(Dispon\u00edvel +Previs\u00e3o de \nentradas de caixa a curto \n\nprazo)/\nPrevis\u00e3o de sa\u00eddas de \ncaixa a curto prazo\n\nIndica a liquidez a curto prazo atrav\u00e9s de uma \nprevis\u00e3o de entradas e sa\u00eddas de caixa.\n\nRentabilidade  ? v \"\n1. LB/VL \u2022  Margem Bruta Lucro Bruto/ \n\nVendas L\u00edquidas\nIndica o desempenho dos custos de produ\u00e7\u00e3o. \nDado que o lucro bruto \u00e9 obtido pela diferen\u00e7a \nentre vendas e o custo de produ\u00e7\u00e3o de \nmercadorias ou dos produtos vendidos, um \naumento deste \u00edndice denotar\u00e1 melhor \nefici\u00eancia produtiva da empresa, no que se \nrefere aos seus custos fabris.\n\n2. V/AT \u2022  Giro do Ativo Vendas L\u00edquidas/ Estabelece rela\u00e7\u00e3o entre as vendas efetuadas\n\n\n\n0 . \u00a3 ? 3 .  2 S  a. -  \u00e3 L\nCapitulo 2 - An\u00e1lise de \u00edndices Financeiros libliotec\u00e3 Universit\u00e1ria: 3\n\nUFSC\n\nAtivo M\u00e9dio no per\u00edodo e os investimentos totais da \nempresa.\n\n3. LL/V \u2022  Margem L\u00edquida Lucro L\u00edquido/ \nVendas L\u00edquidas\n\nCompara o lucro l\u00edquido em rela\u00e7\u00e3o \u00e0s vendas \nl\u00edquidas do per\u00edodo, fornecendo percentual de \nlucro que a empresa est\u00e1 obtendo em rela\u00e7\u00e3o \nao seu faturamento.\n\n4. LL/AT \u2022  Rentabilidade do \nAtivo\n\nLucro L\u00edquido/ \nAtivo Total\n\nIndica a lucratividade que a empresa propicia \nem rela\u00e7\u00e3o aos investimentos totais.\n\n5. LL/PL \u2022  Rentabilidade do \nPatrim\u00f4nio \nL\u00edquido\n\nLucro L\u00edquido/ \nPatrim\u00f4nio L\u00edquido - \n\nLucro L\u00edquido\n\nIndica o retomo dos recursos pr\u00f3prios \ninvestidos na empresa. Este \u00edndice, espresso \npela rela\u00e7\u00e3o entre os recursos l\u00edquidos obtidos \nem determinado per\u00edodo e o capital pr\u00f3prio \nempregado, \u00e9 de grande import\u00e2ncia para os \nacionistas ou propriet\u00e1rios da empresa.\nExerce, inclusive, decisiva influ\u00eancia a m\u00e9dio e \nlongo prazo sobre o valor de mercado das \na\u00e7\u00f5es ou da pr\u00f3pria empresa.\n\n* ?' , - Rota\u00e7\u00e3o - - , V , ,\n1. PMRE \u2022  Prazo m\u00e9dio de \n\nrota\u00e7\u00e3o de \nEstoques\n\nEstoque M\u00e9dio * DP3/ \nCusto da mercadoria \n\nvendido\n\nIndica quantos dias, em m\u00e9dia, os produtos \nficam armazenados na empresa antes de serem \nvendidos4.\n\n2. PMRV \u2022  Prazo m\u00e9dio de \nrecebimentos das \nvendas\n\nDuplicatas a Receber * \nD P /\n\nVendas\n\nIndica quantos dias, em m\u00e9dia, a empresa leva \npara receber suas vendas.\n\n3. PMPC \u2022  Prazo m\u00e9dio de \npagamento das \ncompras\n\nFornecedores * DP/ \nCompras\n\nIndica quantos dias, em m\u00e9dia, a empresa \ndemora para pagar seus fornecedores.\n\n\u00edndices de \ndepend\u00eancia e \nindepend\u00eancia \nfinanceira\n\n1. PL/AT \u2022  Independ\u00eancia \nFinanceira\n\nPatrim\u00f4nio L\u00edquido / \nAtivo Total\n\nIndica a independ\u00eancia financeira da empresa, \nou seja, do montante investido pela empresa \nno seu ativo, qual a participa\u00e7\u00e3o dos recursos \npr\u00f3prios.\nA empresa alcan\u00e7a uma independ\u00eancia \nabsoluta quando este \u00edndice for igual a 1\n\n2. ET/AT \u2022  Depend\u00eancia \nFinanceira\n\nExig\u00edvel Total/ \nAtivo Total\n\nIndica a depend\u00eancia financeira da empresa. \u00c9 \num complemento do \u00edndice anterior. Indica a \nparticipa\u00e7\u00e3o do capital de terceiros nos \ninvestimentos efetuados no ativo.\n\nQ uadro 2.1: Q uadro Resumo dos \u00edndices Financeiros.\n\n2.5 Aplica\u00e7\u00f5es dos \u00edndices Financeiros\n\nOs \u00edndices Financeiros tem sido usados como entradas para modelos \n\nestat\u00edsticos avan\u00e7ados para prever muitos tipos de neg\u00f3cios e para identificar\n\n3 DP - Dias do per\u00edodo considerado.\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 34\n\ncaracter\u00edsticas financeiras [Bames, 1987]. Not\u00e1veis estudos incluem Ingram e \n\nCopeland [Ingram &amp; Copeland, 1984] que usaram An\u00e1lise de regress\u00e3o parra medir a \n\nrela\u00e7\u00e3o entre as diferen\u00e7as nos \u00edndices Financeiros atrav\u00e9s das municipalidades e os \n\nriscos em seus b\u00f4nus ( e.g. JunkBonds).\n\nHorrigan usou an\u00e1lise de correla\u00e7\u00e3o [Horrigan, 1966] enquanto Pinches e \n\nMingo usaram An\u00e1lise Discriminante Multivariada (ADM) para prever a cota\u00e7\u00e3o dos \n\nb\u00f4nus da empresa por meio de \u00edndices individuais [Pinches &amp; Mingo, 1973], Rege e \n\nBelkaoui realizaram estudos onde usaram \u00edndices Financeiros para identificar \n\ncaracter\u00edsticas de takeover targets [Rege, 1984], [Belkaoui, 1978],\n\nO principal foco tem sido os modelos estat\u00edsticos (principalmente \n\nmultivariada) que usaram \u00edndices Financeiros para prever a fal\u00eancia de neg\u00f3cios. \n\nEstes s\u00e3o baseados no trabalho original de Beaver e Altmam [Beaver, 1966], \n\n[Altmam, 1968],\n\nBeaver comparou uma amostra de firmas falidas com uma amostra de f irma\u00ab; \n\nn\u00e3o falidas e estudou seus \u00edndices financeiros durante mais ou menos 5 anos antes da \n\nfal\u00eancia e descobriu que eles tem grande habilidade de previs\u00e3o[Beaver, 1966] . A \n\nt\u00e9cnica usada por Beaver \u00e9 conhecida como a an\u00e1lise de classifica\u00e7\u00e3o e \u00e9 \n\nessencialmente univariada.\n\nAltmam usou a t\u00e9cnica bem conhecida em estat\u00edstica, ADM. Ele mostrou que \n\nos press\u00e1gios dos perigos financeiros s\u00e3o discrimin\u00e1veis usando uma combina\u00e7\u00e3o de \n\n\u00edndices financeiros. Os \u00edndices espec\u00edficos s\u00e3o determinados usando ADM [Altmam, \n\n1968], O modelo de Altmam popularizou-se com o nome de Z-score e foi \n\ncomercializado com sucesso para an\u00e1lise de cr\u00e9dito, an\u00e1lise de investimentos e \n\navalia\u00e7\u00e3o para ver se existe ou n\u00e3o problemas de concordata ou fal\u00eancia na empresa.\n\nDesde 1968, ADM tem sido a principal abordagem para identificar os \n\nproblemas financeiros em uma grande variedade de \u00e1reas em neg\u00f3cios. Contudo, a \n\nt\u00e9cnica de ADM tem sido criticada pois a validade de seus resultados depende de \n\nsuposi\u00e7\u00f5es restritivas sobre a separabilidade linear, na normalidade multivariada e \n\nindepende das vari\u00e1veis preditivas [Ohlson, 1980; Odom &amp; Shardo, 1990; Karels &amp; \n\nPrakash, 1987], Infelizmente, \u00edndices financeiros, em sua grand e maioria, violam as\n\n4 A Administra\u00e7\u00e3o dos estoques \u00e9 t\u00e3o importante que, por si s\u00f3, representa complexo tema da administra\u00e7\u00e3o\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 35\n\nsuposi\u00e7\u00f5es da ADM. As restri\u00e7\u00f5es da ADM s\u00e3o incompat\u00edveis com a natureza \n\ncomplexa, os limites e a inter-rela\u00e7\u00e3o dos \u00edndices. Ent\u00e3o os poderes da ADM para \n\n\u00edndices financeiros est\u00e1 comprometida [Lacher et al, 1991],\n\nMas, apesar dos muito estudos, os pesquisadores n\u00e3o descobriam nada melhor \n\nque a ADM at\u00e9 os recentes desenvolvimentos das Redes Neuronais Artificias.\n\nA primeira compara\u00e7\u00e3o de an\u00e1lise discriminate com Redes Neuronais \n\nArtificiais na \u00e1rea de previs\u00e3o de fal\u00eancia foi apresentada por [Odom e Shardo, 1990], \n\nNeste trabalho Redes Neuronais Artificiais mostram-se superiores \u00e0 an\u00e1lise \n\ndiscriminante. J\u00e1 no trabalho apresentados por Erxleben e Baetge em 1991 a an\u00e1lise \n\ndiscriminante mostrou ser superior, enquanto no trabalho apresentado em 1992, a \n\nan\u00e1lise discriminante e as redes neuronais apresentaram resultados semelhantes \n\n[Refenes, 1995], N\u00e3o \u00e9 poss\u00edvel determinar se as redes Neuronais s\u00e3o superiores \n\n(existem muitos tipos de redes neuronais) [Refenes, 1995] mas j\u00e1  se pode afirmar \n\nque elas apresentam uma performance t\u00e3o boa quanto a an\u00e1lise discriminante\n\nMuitos outros pesquisadores est\u00e3o usando redes Neuronais, como Lacher et al. \n\nque usaram uma Rede Neuronal Artificial para a classifica\u00e7\u00e3o da sa\u00fade financeira de \n\numa firma [Lacher et al, 1991]. Whalen que usou uma Rede Neuronal Difusa para \n\ndiagn\u00f3stico de empresas [Whalen &amp; Schott, 1985]; Pacheco em sua tese de doutorado \n\ntamb\u00e9m usou uma Rede Neuronal Difusa para diagn\u00f3sticos de pequenas empresas \n[Pacheco, 1996],\n\n2.6 Conclus\u00e3o\n\nA An\u00e1lise de Declara\u00e7\u00f5es Financeiras \u00e9 tarefa bastante complexa e de \n\nfundamental import\u00e2ncia numa sociedade moderna. O m\u00e9todo mais usado e muitas \n\nvezes confundido com a an\u00e1lise de declara\u00e7\u00f5es financeiras \u00e9 a an\u00e1lise de \u00edndices \n\nfinanceiros. Estes \u00edndices comparam vari\u00e1veis financeiras e s\u00e3o extra\u00eddos, geralmente, \n\ndo Balan\u00e7o Patrimonial e do demonstrativo de resultado. Esta t\u00e9cnica reduz a \n\nquantidade de informa\u00e7\u00f5es e enfatiza as rela\u00e7\u00f5es entre elementos financeiros ao inv\u00e9s \n\nde seus valores individuais.\n\nfinanceira e da administra\u00e7\u00e3o da produ\u00e7\u00e3o.\n\n\n\nCap\u00edtulo 2 - An\u00e1lise de \u00edndices Financeiros 36\n\nA an\u00e1lise destes \u00edndices, al\u00e9m de auxiliarem no gerenciamento da empresa, \n\nauxilia na previs\u00e3o estat\u00edstica de fal\u00eancia, na an\u00e1lise da sa\u00fade financeira, e no \n\nplanejamento de estrat\u00e9gias.\n\nAs pesquisas sobre a forma funcional e as propriedades da distribui\u00e7\u00e3o dos \n\n\u00edndices financeiros apontam uma rela\u00e7\u00e3o dos mesmos com o tamanho e atividade da \n\nempresa, requerendo per\u00edodos de an\u00e1lise pequenos. Quanto \u00e0 categorizar\u00e3o dos \n\n\u00edndices, esta depende do objetivo da an\u00e1lise e do meio da aplica\u00e7\u00e3o e tamb\u00e9m do \n\ntempo.\n\nPortanto, o processo geral de extra\u00e7\u00e3o de informa\u00e7\u00f5es importantes para \n\nsuportar decis\u00f5es numa empresa n\u00e3o \u00e9 simples. Depende do setor econ\u00f4mico, do \n\ntamanho da empresa, do padr\u00e3o de compara\u00e7\u00e3o e al\u00e9m disso \u00e9 din\u00e2mico.\n\n\n\n3. T\u00c9CNICAS DE INTELIG\u00caNCIA \nARTIFICIAL\n\n3.1 Introdu\u00e7\u00e3o\n\nO termo Intelig\u00eancia Artificial (IA) foi proposto em 1956 por Jonh MacCarhy, \n\num dos pioneiros, da Universidade de Stantford, nos Estados Unidos.\n\nIA \u00e9 um termo que abrange muitas defini\u00e7\u00f5es [Turban, 1992]. Mas a maioria \n\ndos especialistas concordam que a IA est\u00e1 baseada em duas id\u00e9ias b\u00e1sicas: primeiro \n\nenvolve o estudo do processo do pensamento humano (para entender o que \u00e9 \n\nintelig\u00eancia), segundo, trata com a representa\u00e7\u00e3o destes processos via m\u00e1quina \n\n(computador, rob\u00f4s,...).\n\nNos \u00faltimos anos tem-se presenciado um crescente interesse pela inter- \n\ndisciplinaridade em aplica\u00e7\u00f5es de Intelig\u00eancia Artificial (IA). O t\u00f3pico est\u00e1 sendo \n\nabordado em muitas publica\u00e7\u00f5es. Muitos peri\u00f3dicos5 t\u00eam publicado e dedicado muita \n\naten\u00e7\u00e3o sobre IA. Dezenas de livros sobre IA tem aparecido no mercado. Muitos \n\nartigos novos em IA est\u00e3o sendo publicados regularmente, e confer\u00eancias e \n\nconven\u00e7\u00f5es neste t\u00f3pico est\u00e3o sendo realizados mundialmente. E al\u00e9m disto, as \n\naplica\u00e7\u00f5es comerciais est\u00e3o projetadas para alcan\u00e7ar milh\u00f5es de d\u00f3lares at\u00e9 o ano \n\n2000 [Turban, 1995],\n\nEste desenvolvimento pode ter um impacto signif\u00edcante em muitas \n\norganiza\u00e7\u00f5es p\u00fablicas e privadas, e no modo que elas s\u00e3o administradas.\n\nAtualmente, dentro do campo da IA, existem diversas linhas de pesquisa e \n\nt\u00e9cnicas diferentes em estudo, como Sistemas Especialistas, Redes Neuronais \n\nArtificiais, Sistemas Difusos, Algoritmos Gen\u00e9ticos, entre outras. Essas t\u00e9cnicas t\u00eam\n\n5 Muitos peri\u00f3dicos tem publicado artigos na \u00e1rea de IA como por exemplo, IEEE Transaction in Fuzzy Systems, \nFuzzy Sets and Systems, Intelligent Decision Analysis.\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 38\n\nmudado constantemente a cada nova adapta\u00e7\u00e3o, a cada novo problema, tomando-se \n\ncada vez mais elaboradas, mais complexas e naturalmente mais \u201cinteligentes\u201d. Ao \n\nmesmo tempo, encontra-se com mais freq\u00fc\u00eancia a combina\u00e7\u00e3o destas t\u00e9cnicas para a \n\nsolu\u00e7\u00e3o de problemas mais complexos. Essa combina\u00e7\u00e3o \u00e9 chamada na literatura \n\ncomo Sistemas H\u00edbridos.\n\nO surgimento dos Sistemas H\u00edbridos foi muito natural, afinal o pr\u00f3prio \n\nhomem constitui-se de muitos elementos como evolu\u00e7\u00e3o, adapta\u00e7\u00e3o, sinapses, \n\nmem\u00f3ria e processamento de muitas outras facetas que ainda se desconhece ou n\u00e3o se \n\nconsegue entender. O corpo humano \u00e9 um grande Sistema H\u00edbrido e extremamente \n\ncomplexo. Seguindo nesta linha, tem-se um campo de pesquisa extremamente vasto.\n\nNeste cap\u00edtulo apresenta-se, de uma forma simplificada, as bases de cinco \n\nt\u00e9cnicas inteligentes cuja aplica\u00e7\u00e3o no presente trabalho tem relev\u00e2ncia: Sistemas \n\nEspecialistas, Redes Neuronais Artificiais, Sistemas Difusos, Algoritmos Gen\u00e9ticos e \n\nRacioc\u00ednio Baseado em Casos, assim como, sistemas inteligentes h\u00edbridos, uma \n\nt\u00e9cnica emergente na \u00e1rea de IA. Todas estas t\u00e9cnicas que ser\u00e3o vistas, est\u00e3o hoje \n\nsendo aplicadas para resolver problemas na \u00e1rea de finan\u00e7as, indo desde an\u00e1lise de \n\npequenos neg\u00f3cios at\u00e9 previs\u00e3o de bolsa de valores.\n\n3.2 T\u00e9cnicas de Intelig\u00eancia Artificial\n\n3.2.1 Introdu\u00e7\u00e3o\n\nAs companias est\u00e3o sempre reunindo uma grande quantidade de dados como \n\nos balan\u00e7os das empresas, \u00edndices de bolsas de valores, vendas de a\u00e7\u00f5es. Detalhes s\u00e3o \n\nregistrados em uma base de dados. As companias inovadoras est\u00e3o considerando a \n\ngrande quantidade de dados que elas mant\u00e9m como um tesouro em potencial que \n\npode ser explorado para encontrar padr\u00f5es e rela\u00e7\u00f5es importantes, talvez \n\nfundamentais, e que podem trazer solu\u00e7\u00f5es para muitos problemas.\n\nSistemas Inteligentes s\u00e3o uma categoria de inventos computacionais que \n\npodem encontrar padr\u00f5es e descobrir rela\u00e7\u00f5es numa quantidade grande de dados. \n\nEstes sistemas cercam um repertorio de t\u00e9cnicas incluindo Redes Neuronais, Sistemas \n\nDifusos, Algoritmos Gen\u00e9ticos e Sistemas Especialistas.\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 39\n\nO dom\u00ednio de aplica\u00e7\u00e3o est\u00e1 crescendo rapidamente (Figura 3.1). Countrywide \n\nFunding, a maior criador de hipotecas dos Estados Unidos, usa um sistema baseado \n\nem regras adaptativo para subscrever suas hipotecas. A Internacional Visa tem um \n\nsistema de rede Neuronal para detectar o uso fraudulento de cat\u00f5es de cr\u00e9ditos e o \n\nBanco Fiji usa sistemas Difusos para bond trading.\n\nEm todas estas companhias o fator de motiva\u00e7\u00e3o para usar sistemas \n\ninteligentes \u00e9 similar - o aumento da qualidade de seus servi\u00e7os e redu\u00e7\u00e3o de custos.\n\nRetail Banking\nAvalia\u00e7\u00e3o de \n\nhipotecas\n\nBanco de Vigil\u00e2ncia\nInvstimento Detec\u00e7\u00e3o de\n\nGerenciamento de fraude em cart\u00f5es\nportfolio de cr\u00e9dito\n\nPlanejamento\nDistribui\u00e7\u00e3o de \n\nProdutos\n\nFigura 3.1: Areas de Aplica\u00e7\u00e3o de Sistema Inteligentes [Goonatilake &amp; Treleaven. \n1995a].\n\nUm tema comum em sistemas inteligentes \u00e9 a sua imita\u00e7\u00e3o da natureza \n\n(humana). Redes Neuronais, por exemplo, s\u00e3o inspiradas na funcionalidade das \n\nc\u00e9lulas nervosas no cerebro. Semelhante a humanos, as Redes Neuronais podem \n\naprender a reconhecer padr\u00f5es pela exposi\u00e7\u00e3o repetida de exemplos diferentes. Elas \n\npodem ser usadas para reconhecer padr\u00f5es ou salientar caracter\u00edsticas, quer eles \n\nsejam caracteres manuscritos, empr\u00e9stimos ou decis\u00f5es de bons neg\u00f3cios. Assim \n\ncomo os humanos tem a capacidade de reconhecer um caracter manuscrito produzido \n\npor pessoas diferentes que possuem estilos distintos, as Redes Neuronais podem \n\ntamb\u00e9m reconhecer padr\u00f5es em dados que s\u00e3o inexatos e incompletos.\n\nNa seq\u00fc\u00eancia, faz-se uma revis\u00e3o das t\u00e9cnicas de IA: Sistema Especialistas, \n\nRedes Neuronais, Sistemas Difusos, Algoritmos Gen\u00e9ticos e Racioc\u00ednio Baseado em\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 40\n\nCasos. Para cada t\u00e9cnica introduz-se as opera\u00e7\u00f5es b\u00e1sicas, seus pontos fortes e fracos \n\ne algumas aplica\u00e7\u00f5es. Tamb\u00e9m apresenta-se a integra\u00e7\u00e3o destas t\u00e9cnicas (Sistemas \nH\u00edbridos).\n\n3.2.2 Sistemas especialistas\n\nSistemas Especialistas representam os primeiros e mais estabelecidos sistemas \n\ninteligentes. Existem centenas de Sistemas Especialistas (SE) operacionais em \n\ndom\u00ednios abrangendo desde diagn\u00f3sticos imprecisos at\u00e9 com\u00e9rcio de mercadorias. \n\nUm SE segundo Feigenbaum, \u00e9 um programa inteligente de computador que \n\nsoluciona problemas dif\u00edceis os quais o ser humano n\u00e3o d\u00e1 conta de resolv\u00ea-los \n\n[Feigenbaum, 1977], Como o nome sugere, os SE tentam incorporar o conhecimento \n\nem um dom\u00ednio espec\u00edfico (limitado) de um especialista humano em um programa de \n\ncomputador. O processo de aquisi\u00e7\u00e3o de conhecimento de um especialista - elicita\u00e7\u00e3o \n\ndo conhecimento - tipicamente envolve uma s\u00e9rie de entrevistas e o registro \n\ncuidadoso das observa\u00e7\u00f5es quando o especialista est\u00e1 realizando as tarefas.\n\nUma vez que o conhecimento esta adquirido ele \u00e9 representado em uma forma \n\nque possa ser manipulada pelo computador. Existem muitas pesquisas sobre como \n\nencontrar bons esquemas de representa\u00e7\u00e3o do conhecimento que s\u00e3o eficientes e \n\nf\u00e1ceis de usar. Entre os esquemas de representa\u00e7\u00e3o do conhecimento mais usados \n\ntem-se as regras de produ\u00e7\u00e3o, fram es, e redes sem\u00e2nticas.\n\nUma regra de produ\u00e7\u00e3o tem a seguinte forma:\n\nSE (condi\u00e7\u00e3o-1) E (condi\u00e7\u00e3o-2) ENT\u00c3O (a\u00e7\u00e3o-1) E (a\u00e7\u00e3o-2)\n\nUm SE geralmente constitui-se dos seguintes componentes b\u00e1sicos (Figura\n3.2):\n\n? base de conhecimento, que cont\u00e9m conhecimentos necess\u00e1rios para entender, \n\nformular e solucionar os problemas (s\u00e3o os fatos conhecidos pelo sistema);\n\n? m\u00e1quina de infer\u00eancia, que \u00e9 o mecanismo de controle para guiar o processo de \n\nracioc\u00ednio do sistema. Tamb\u00e9m conhecido como estrutura de controle ou \n\ninterpretador de regras (em SE baseados em regras);\n\n? mem\u00f3ria de trabalho (.Blackboad), que \u00e9 a por\u00e7\u00e3o da mem\u00f3ria reservada para \n\nguardar a trilha das entradas, conclus\u00f5es intermedi\u00e1rias e a sa\u00edda;\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 41\n\n? Interface com o usu\u00e1rio, que \u00e9 designada para fornecer um meio conveniente de \n\ncomunica\u00e7\u00e3o entre o usu\u00e1rio e o engenho de infer\u00eancia;\n\n? Mecanismo de aquisi\u00e7\u00e3o do conhecimento, que \u00e9 usado para adquirir experi\u00eancia \n\nhumana e transformar em base de conhecimento.\n\nM\u00e1quina de \nInfer\u00eancia\n\nMem\u00f3ria de \ntrabalho\n\nMecanismo de Aquisi\u00e7\u00e3o \nde conhecimento\n\nInterface com o usu\u00e1rio\n\nBase de \nconhecimento\n\nFigura 3.2 Estrutura gen\u00e9rica de um Sistema Especialista\n\nOs SEs representam uma transi\u00e7\u00e3o revolucion\u00e1ria do processamento de dados \n\ntradicional para o processamento do conhecimento. Eles oferecem um meio para \n\nincorporar a capacidade dos humanos e o poder dos computadores.\n\nVantagens e Limita\u00e7\u00f5es dos Sistemas Especialistas\n\nUma grande vantagem dos SE \u00e9 a representa\u00e7\u00e3o expl\u00edcita do conhecimento, de \n\nmodo que o conhecimento contido nos programas seja relativamente f\u00e1cil de ler e \n\nentender (s\u00e3o capazes de tratar com informa\u00e7\u00e3o simb\u00f3lica). Os SEs podem gerar \n\nexplica\u00e7\u00f5es de como ele chegou a uma conclus\u00e3o particular e tamb\u00e9m podem \n\ninteragir com o usu\u00e1rio melhorando sua produtividade.\n\nComo uma limita\u00e7\u00e3o particular dos SEs, uma das principais desvantagens, \u00e9 \n\nque eles n\u00e3o t\u00eam mecanismos de aprendizagem autom\u00e1tica das regras. Al\u00e9m disto, \n\neles n\u00e3o se adaptam ou aprendem com as mudan\u00e7as no meio no qual eles operam.\n\nEm algumas \u00e1reas, especialistas descrevem suas a\u00e7\u00f5es como sendo difusas e \n\nintuitivas e t\u00eam dificuldades para transformar suas experi\u00eancias em regras de sistemas \n\nespecialistas, que usualmente tem defini\u00e7\u00f5es de l\u00f3gica bin\u00e1ria. Desta forma,\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 42\n\nesquemas de representa\u00e7\u00e3o de conhecimento, tal como L\u00f3gica Difusa, s\u00e3o mais \n\nflex\u00edveis e necess\u00e1rias.\n\nAplica\u00e7\u00f5es\nAs aplica\u00e7\u00f5es dos SEs s\u00e3o muita amplas atingindo desde jogos at\u00e9 sistemas de \n\ncontrole. As aplica\u00e7\u00f5es em finan\u00e7as e neg\u00f3cios podem ser divididas nas \u00e1reas de \n\ncorpora\u00e7\u00e3o financeira, mercado financeiro e institui\u00e7\u00f5es financeiras de seguros \n\nDentre as aplica\u00e7\u00f5es em neg\u00f3cios que tiveram sucesso pode-se destacar:\n\n? controle de fraude de cart\u00f5es de cr\u00e9ditos [Newquist, 1987];\n\n? an\u00e1lise de \u00edndices financeiros [Pau, 1991];\n\n? libera\u00e7\u00e3o de cr\u00e9dito [Enrado, 1991; Weber, 1993];\n\n? planejamento financeiro [Brown et al., 1990];\n\n? contabilidade [Brown et al., 1990];\n\n? avalia\u00e7\u00e3o de risco [Radding, 1991];\n\n? an\u00e1lise de portfolio [Ram, 1990],\n\nOs dois sistemas especialistas que s\u00e3o dirigidos para an\u00e1lise financeira s\u00e3o \n\nAnswers [Blocher, 1990] e Financial Statement Analyzer (FSA) [Mui et al., 1990],\n\nAnswers \u00e9 um SE que constitui-se de dois m\u00f3dulos, um que realiza uma \n\nan\u00e1lise financeira e o outro uma an\u00e1lise de proje\u00e7\u00f5es. A fun\u00e7\u00e3o da an\u00e1lise de \u00edndices \n\n\u00e9 provocar coment\u00e1rios das varia\u00e7\u00f5es observadas em \u00edndices financeiros chaves \n\nusados pelo sistema. O objetivo destes coment\u00e1rios \u00e9 sugerir aos gerentes quest\u00f5es a \n\nserem endere\u00e7adas ou t\u00f3picos a serem analisados. Originalmente, este sistema foi \n\nconcebido para auditoria, mas mais tarde foi usado para treinamento e \n\nrecomenda\u00e7\u00f5es.\n\nO FSA \u00e9 um SE comissionado pelos U.S. Securies e Commision Exchange \n\nState (SEC) para Arthur Andersen a fim de extrair informa\u00e7\u00f5es valiosas das \n\ndeclara\u00e7\u00f5es financeiras correntes. Originalmente, o FSA tinha por objetivo processar \n\nautomaticamente o c\u00e1lculo dos \u00edndices. O sistema FSA calcula \u00edndices padr\u00f5es das \n\ndeclara\u00e7\u00f5es financeiras das empresas.\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial\n43\n\nH ist\u00f3rico\n\nDistingui-se tr\u00eas per\u00edodos no desenvolvimento de SE:\n\n? 1960-1969 - Durante este per\u00edodo, os SE foram desenvolvidos em dom\u00ednio \n\ncientifico. Uma das primeiras aplica\u00e7\u00f5es (em Qu\u00edmica) foi o DENTRAL, \n\ndesignado para interpretar dados de espectr\u00f4metros de massas e determinar a \n\nestrutura de mol\u00e9culas. Um SE para entender a fala HEARSAY, e o MACSYMA \n\npara solu\u00e7\u00e3o de problemas matem\u00e1ticos, foi tamb\u00e9m desenvolvidos neste per\u00edodo.\n\n? 1970-1979 - O in\u00edcio dos anos setenta foi marcado pelo desenvolvimento de \n\ndiversos SE no campo de Medicina. MYCIN foi designado para ajudar em \n\ndiagn\u00f3sticos de meningite e infec\u00e7\u00f5es no sangue. CASNET e INTERNIST tamb\u00e9m \n\nforam projetados neste per\u00edodo. No final dos anos setenta, o PROSPESTOR foi \n\nprojetado para prever dep\u00f3sitos de minerais. Foi tamb\u00e9m desenvolvido o primeiro \n\nSE cujo sujeito de dom\u00ednio era a educa\u00e7\u00e3o, SOPHIE. Este SE ensinava a resolver \n\nproblemas dif\u00edceis em circuitos eletr\u00f4nicos.\n\n? 1980 - presente - O in\u00edcio dos anos 80 trouxe grande popularidade e interesse \n\ncomercial para os SE seguindo o sucesso dos SE desenvolvidos no per\u00edodo \n\nanterior. Este per\u00edodo \u00e9 caracterizado pela comercializa\u00e7\u00e3o de ferramentas \n\ndesenvolvidas em SE conhecidas como expert system shells (ESS).\n\nNo per\u00edodo de 1960 a 1979 os SE eram hand-crafted, isto \u00e9, todos os \n\ncomponentes de software, assim como a base de conhecimento, eram codificadas \n\npelas pessoas que o tinham desenvolvido. O desenvolvimento destes SE envolveu \n\nmuitas pessoas e recursos computacionais. Em seus esfor\u00e7os para reduzir os custos de \n\ndesenvolvimento, pesquisadores discutiram a id\u00e9ia do ESSs. Um ESS \u00e9 simplesmente \n\num esqueleto de um sistema especialista com todos os componentes de um sistema \n\nexceto o conhecimento de uma dada \u00e1rea espec\u00edfica.\n\nPor exemplo, a shell EMYCIN \u00e9 o SE MYCIN sem seu conhecimento. O \n\nEMYCIN foi usado com sucesso no desenvolvimento do SE PUFF que fornece \n\nconsultas diagnosticas no dom\u00ednio de doen\u00e7a nos pulm\u00f5es. Foi desenvolvido \n\nsimplesmente pelo povoamento da base de conhecimento vazia do EMYCIN com\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 44\n\nconhecimentos em doen\u00e7as nos pulm\u00f5es e usando as fun\u00e7\u00f5es do SE dispon\u00edveis do \nEMYCIN.\n\n3.2.3 Redes Neuronais Artificiais\n\nUma Rede Neuronal Artificial (RNA) \u00e9 um modelo que emula uma rede \n\nneuronal biol\u00f3gica. Por\u00e9m, uma RNA usa um conjunto muito limitado dos conceitos \n\ndo sistema biol\u00f3gico. Os conceitos s\u00e3o usados para implementar softwares de \n\nprocessos massivamente paralelos que envolve elementos de processamentos \n\n(tamb\u00e9m chamados de neur\u00f4nios artificiais) interconectados em uma arquitetura de \n\nrede. Os neur\u00f4nios artificiais recebem entradas que s\u00e3o an\u00e1logas aos impulsos que os \n\ndetritos dos neur\u00f4nios biol\u00f3gicos recebem dos outros neur\u00f4nios. A sa\u00edda dos \n\nneur\u00f4nios artificiais corresponde aos sinais enviados de um neur\u00f4nio biol\u00f3gico \n\natrav\u00e9s de seu ax\u00f4nio. Estes sinais artificiais podem ser mudados similarmente \u00e0s \n\nmudan\u00e7as ocorridas nas sinapses.\n\nO estado da arte nas RNAs baseia-se sobre o entendimento das redes \n\nneuronais biol\u00f3gicas. Contudo, ainda se esta longe de ter uma m\u00e1quina semelhante ao \n\nc\u00e9rebro. Apesar dos estudos extensivos em neurobiologia e psicologia, quest\u00f5es \n\nimportantes permanecem sobre como o c\u00e9rebro e a mente trabalham. Entretanto, \n\npesquisas e desenvolvimentos nesta \u00e1rea de RNAs est\u00e3o produzindo sistemas \u00fateis e \n\ninteressantes que usam algumas caracter\u00edsticas do sistema biol\u00f3gico.\n\nUma RNA \u00e9 composta de elementos de processamento, organizados em \n\ndiferentes modos para formar a estrutura da rede:\n\n? Elementos de processamento: Uma RNA \u00e9 composta de neur\u00f4nios artificiais (que \n\ns\u00e3o referidos como neur\u00f4nios, n\u00f3s ou nodos); estes s\u00e3o os elementos de \n\nprocessamentos. Cada um destes neur\u00f4nios recebem entradas, processa as \n\nentradas, e emite uma \u00fanica sa\u00edda. Este processo \u00e9 mostrado na Figura 3.3. Uma \n\nentrada pode ser a entrada inicial ou a sa\u00edda de outro neur\u00f4nio.\n\n? Rede: Cada RNA \u00e9 composta de uma cole\u00e7\u00e3o de neur\u00f4nios que est\u00e3o agrupados \n\nem camadas. Uma estrutura t\u00edpica \u00e9 mostrada na Figura 3.4. Nesta figura tem-se \n\ntr\u00eas camadas: entrada, intermedi\u00e1ria (chamada camada escondida), e a sa\u00edda, mas \n\ndiversas camadas podem ser colocadas entre a camada de entrada e de sa\u00edda.\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 45\n\n? E s tru tu ra  da rede: Similar as redes biol\u00f3gicas, uma RNA pode ser organizada de \n\nv\u00e1rios modos diferentes (topologias); isto \u00e9, os neur\u00f4nios podem ser conectados de \n\nv\u00e1rios modos distintos. Portanto, as RNAs aparecem em muitas configura\u00e7\u00f5es. No \n\nprocessamento da informa\u00e7\u00e3o, muitos dos elementos de processamento executam \n\nseus c\u00e1lculos ao mesmo tempo. Este processamento paralelo assemelha-se ao \n\nmodo que o c\u00e9rebro trabalha, e difere do processamento serial, dos c\u00e1lculos \n\ntradicionais.\n\nF ig u ra 3.3: Modelo de um neur\u00f4nio F igura 3.4: P erceptron de m\u00faltiplas \nartificial. cam adas com um a cam ada escondida e\n\num neur\u00f4nio de sa\u00edda.\n\nUma vez que a estrutura da rede est\u00e1 determinada, informa\u00e7\u00f5es podem ser \n\nprocessadas. Os principais conceitos relacionados ao processamento (Figura 3.3) s\u00e3o:\n\n? entradas: Cada entrada corresponde a um simples atributo. Por exemplo, se o \n\nproblema \u00e9 decidir sobre a prova\u00e7\u00e3o ou desaprova\u00e7\u00e3o de um empr\u00e9stimo, um \n\natributo pode ser o n\u00edvel de renda ou a idade. O valor num\u00e9rico de um atributo \u00e9 a \n\nentrada da rede. Diversos tipos de dados podem ser usados como entradas (valores \n\ndos pixels de caracteres ou outros gr\u00e1ficos, padr\u00f5es digitalizados de imagens ou \n\nvoz, dados codificados,...). Contudo, o pr\u00e9-processamento muitas vezes \u00e9 \n\nnecess\u00e1rio.\n\n? Sa\u00eddas: A sa\u00edda da rede \u00e9 a solu\u00e7\u00e3o do problema. Por exemplo, no caso do \n\nempr\u00e9stimo, a sa\u00edda pode ser \u201csim\u201d ou \u201cn\u00e3o\u201d. A RNA atribui valores num\u00e9ricos,\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 46\n\npor exemplo, 1 para sim e 0 para \u201cn\u00e3o\u201d. O objetivo da rede \u00e9 computar os \n\nvalores da sa\u00edda.\n\n? Pesos. Um elemento chave em uma RNA \u00e9 o peso. Os pesos expressam pot\u00eancias \n\nrelativas (ou valor matem\u00e1tico) dos dados de entradas ou das v\u00e1rias conex\u00f5es que \n\ntransferem dados de uma camada para outra. Em outras palavras, os pesos \n\nexpressam a import\u00e2ncia relativa de cada entrada para um elemento de \n\nprocessamento. Os pesos s\u00e3o cruciais e \u00e9 atrav\u00e9s do ajustamento repetido dos \n\npesos que a rede \u201caprende\u201d.\n\n? Fun\u00e7\u00e3o Soma: A fun\u00e7\u00e3o soma obt\u00e9m a soma dos pesos de todos os elementos que \n\nentram em cada elemento de processamento. Esta fun\u00e7\u00e3o soma fornece o \n\nsomat\u00f3rio de todos os produtos de cada valor de entrada (x,) pelo seus pesos (w,). \n\nA f\u00f3rmula para p entradas no k-\u00e9simo elemento de processamento (neur\u00f4nios) \u00e9:\n\n-E*.JWQ (3. 1)\n\n? Fun\u00e7\u00e3o de Ativa\u00e7\u00e3o (ou Fun\u00e7\u00e3o de T ransfer\u00eancia): A fun\u00e7\u00e3o soma calcula a \n\nestimula\u00e7\u00e3o interna, ou o n\u00edvel de ativa\u00e7\u00e3o, de um neur\u00f4nio. Baseado neste n\u00edvel, o \n\nneur\u00f4nio pode ou n\u00e3o produzir uma sa\u00edda. A rela\u00e7\u00e3o entre o n\u00edvel de ativa\u00e7\u00e3o \n\ninterno e a sa\u00edda pode ser linear ou n\u00e3o linear. Tais rela\u00e7\u00f5es s\u00e3o expressadas pela \n\nF un\u00e7\u00e3o de Ativa\u00e7\u00e3o). Existem diversos tipos diferentes de fun\u00e7\u00f5es de \n\ntransfer\u00eancia que s\u00e3o utilizadas e uma das mais utilizadas \u00e9 a chamada fun\u00e7\u00e3o \n\nsigmoide:\n\n* v ) = -------- !--------  (3.2)\n1 + exp(-av)\n\nonde a \u00e9 um par\u00e2metro.\n\nO objetivo desta transforma\u00e7\u00e3o \u00e9 modificar o n\u00edvel de sa\u00edda para valores \n\nrazo\u00e1veis (por exemplo, entre 0 e 1). Esta transforma\u00e7\u00e3o \u00e9 feita para limitar a \n\namplitude da sa\u00edda de um neur\u00f4nio (este valor poderia ser muito grande\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 47\n\nprincipalmente quando se tem muitas entradas). Algumas vezes, ao inv\u00e9s da fun\u00e7\u00e3o \n\ntransfer\u00eancia, \u00e9 usado um valor limiar. Por exemplo, qualquer valor maior ou igual a \n\n0,5 muda para 1 e abaixo de 0,5 muda-se para 0.\n\nUma transforma\u00e7\u00e3o pode ocorrer na sa\u00edda de cada elemento de \n\nprocessamento, ou pode ser feito na sa\u00edda final da rede.\n\nUma RNA aprende de suas experi\u00eancias. O processo usual de aprendizagem \n\nenvolve tr\u00eas tarefas (Figura 3.5):\n\n1. Calcula as sa\u00eddas (yk).\n\n2. Compara as sa\u00eddas com a resposta desejada (dk).\n\n3. Ajusta os pesos e repete o processo.\n\nO processo de aprendizagem come\u00e7a pela declara\u00e7\u00e3o dos pesos atrav\u00e9s de \n\nalguma regra ou randomicamente. A diferen\u00e7a entre a sa\u00edda desejada (dk) e a sa\u00edda da \n\nrede (yk) \u00e9 chamada de erro ek (ek = dk - yk). O objetivo da rede \u00e9 m in im iz a r  este erro. \n\nA redu\u00e7\u00e3o do erro \u00e9 feita atrav\u00e9s de mudan\u00e7as nos pesos. A quest\u00e3o \u00e9 mudar os pesos \n\nna dire\u00e7\u00e3o correta, isto \u00e9, fazer mudan\u00e7as que promovam a redu\u00e7\u00e3o do erro. Durante \n\no est\u00e1gio de aprendizagem, os pesos das interconex\u00f5es mudam em resposta ao \n\nconjunto de treinamento apresentado ao sistema.\n\nExistem diversas formas de calcular o erro, dependendo do algoritm o de \n\naprendizagem  utilizado. Existem muitos algoritmos de aprendizagem, mas pode-se \n\ndividi-los em duas categorias: Aprendizagem supervisionada e n\u00e3o supervisionada. Na \n\naprendizagem supervisionada \u00e9 fornecido \u00e0 rede a resposta desejada enquanto na \n\naprendizagem n\u00e3o supervisionada n\u00e3o se conhece a resposta desejada. Neste \u00faltimo \n\ns\u00f3 fomece-se a rede os dados de entrada. Um algoritmo de aprendizado muito usado \u00e9 \n\no Algoritmo Back-Propagation. Um padr\u00e3o de entrada \u00e9 apresentado na camada de \n\nentrada e \u00e9 propagado atrav\u00e9s das camadas intermedi\u00e1rias, passando por todos os \n\nprocessos, para produzir uma sa\u00edda. Esta sa\u00edda \u00e9 ent\u00e3o comparada com a sa\u00edda \n\nobjetivo e o erro \u00e9 propagado para tr\u00e1s (da \u00faltima camada para a camada de entrada) \n\natrav\u00e9s das camadas da rede. O erro propagado \u00e9 usado para ajustar os pesos das \n\nconex\u00f5es. Este processo de treinamento \u00e9 ent\u00e3o repetido com um novo par de entrada, \n\ne um novo erro \u00e9 propagado para tr\u00e1s. Este processo \u00e9 repetido muitas vezes com\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 48\n\nmuitos pares de amostras de padr\u00f5es at\u00e9 que o erro seja minimizado. Terminado este \n\nprocesso a rede esta treinada.\n\nContudo, se quando qualquer t\u00e9cnica de aprendizado, deve-se ter muito \n\ncuidado para que a rede n\u00e3o aprenda padr\u00f5es muito espec\u00edficos em seu treinamento \n\n(super-treinamento). As rela\u00e7\u00f5es de aprendizagem deveriam ser verdadeiramente \n\nrepresentativas das tarefas e n\u00e3o meramente refletir as propriedades contidas nos \n\ndados de treinamento que podem ser estatisticamente n\u00e3o representativos. Se uma \n\nRNA for submetida a um super-treinamento, ela somente seria capaz de aprender a \n\nreconhecer os padr\u00f5es no conjunto de dados - ela n\u00e3o ser\u00e1 capaz de reconhecer \n\npadr\u00f5es fora do conjunto de treinamento. Isto significa que ela n\u00e3o teria flexibilidade \n\nou capacidade de generaliza\u00e7\u00f5es que os problemas exigem. A fim de evitar esta \n\nsitua\u00e7\u00e3o todas as RNA deveriam validar completamente os dados que est\u00e3o fora do \n\nconjunto de treinamento. Existem diversos m\u00e9todos para determinar quando um \n\nsistema de aprendizado tem um n\u00edvel \u201ccorreto\u201d de treinamento [Haykin, 1994],\n\nVantagens e Limita\u00e7\u00f5es das RNA\n\nAs RNA fornecem uma forma relativamente f\u00e1cil para modelar e prever \n\nsistemas n\u00e3o lineares. Esta \u00e9 portanto uma vantagem sobre muitos m\u00e9todos \n\nestat\u00edsticos que s\u00e3o comumente usados em neg\u00f3cios e finan\u00e7as que s\u00e3o primariamente\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 49\n\nlineares. Elas tamb\u00e9m s\u00e3o muito eficientes na aprendizagem de padr\u00f5es em dados \n\ncom ru\u00eddo, incompletos e que podem conter dados contradit\u00f3rios. A habilidade de \n\naprender e a capacidade para tratar com dados imprecisos tom a as RNA muito \u00fateis e \n\neficientes no processamento de informa\u00e7\u00f5es de neg\u00f3cios.\n\nA principal limita\u00e7\u00e3o das RNA e que lhes faltam a capacidade de explica\u00e7\u00e3o. \n\nElas n\u00e3o fornecem ao usu\u00e1rio detalhes de como as mesmas raciocinaram com os \n\ndados para chegar as conclus\u00f5es. As RNAs s\u00e3o portanto melhores para aplica\u00e7\u00f5es que \n\nrequerem reconhecimento de padr\u00f5es com ru\u00eddo, dados incompletos e para tarefas \n\nonde especialistas s\u00e3o ineficazes ou onde regras claras n\u00e3o podem ser facilmente\n\nformul\u00e1veis. Elas n\u00e3o s\u00e3o adequadas para aplica\u00e7\u00f5es onde a explica\u00e7\u00e3o do racioc\u00ednio \n\n\u00e9 crucial.\n\nAplica\u00e7\u00f5es de Redes N euronais Artificiais\n\nAs RNAs podem ser \u00fateis em modelos estruturados de estat\u00edstica, problemas \n\nde otimiza\u00e7\u00e3o e gerenciamento. Elas podem ajudar a resolver muitos problemas \n\ndif\u00edceis de otimiza\u00e7\u00e3o, de loca\u00e7\u00e3o que n\u00e3o s\u00e3o sol\u00faveis com modelos padr\u00f5es. Os \n\nexemplos incluem:\n\nReconhecimento de Padr\u00f5es (gerar fala, transmiss\u00e3o de dados, detec\u00e7\u00e3o de bombas, \n\nreconhecimento de caracteres, sistema de reconhecimento de voz, ...), interpreta\u00e7\u00e3o \n\nde dados (an\u00e1lise financeira, avalia\u00e7\u00e3o de empr\u00e9stimos, diagn\u00f3sticos m\u00e9dicos,...) e \n\notimiza\u00e7\u00e3o.\n\nExistem hoje muitos sistemas de RNA em setores de finan\u00e7as. Aqui descreve- \n\nse alguns exemplos representativos:\n\n? aprova\u00e7\u00e3o de cr\u00e9dito [Klymasauskas, 1991];\n\n? previs\u00e3o de fal\u00eancia [Odom &amp; Shardo, 1993];\n\n? predi\u00e7\u00e3o do mercado de a\u00e7\u00f5es [Kimoto et al\u201e 1990];\n\n? previs\u00e3o de \u00edndices da corporate bonds [Dutta &amp; Shekhar, 1988],\n\nBreve H ist\u00f3rico sobre as RNA\n\nAs pesquisas em RNA passou por tr\u00eas per\u00edodos de extensa atividade. O \n\nprimeiro pico nos anos quarenta foi devido a McCulloch e Pitts [McCulloch &amp; Pitts,\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 50\n\n1943], os pioneiros neste trabalho. O segundo ocorreu nos anos sessenta com o \n\nteorema da converg\u00eancia do perceptron de Rosenblatt [Rosenblatt, 1962] e com o \n\ntrabalho de Minsky e Paper [Minsky e Papert, 1969] mostrando as limita\u00e7\u00f5es do \n\nperceptron simples. Os resultados de Mmsky e Papert abalaram o entusiasmo da \n\nmaioria dos pesquisadores, especialmente os da comunidade das ci\u00eancias \n\ncomputacionais. O resultado acalmou as pesquisas sobre RNA por quase 20 anos. \n\nDesde o in\u00edcio dos anos oitenta, as RNA t\u00eam recebido consider\u00e1vel interesse. O maior \n\ndesenvolvimento deste ressurgimento inclui a abordagem de energia de Hopfield \n\n[Hopfield, 1982] em 1982 e o algoritmo de aprendizagem back-propagation para o \n\nperceptron multicamadas, primeiro proposto por Werbos [Werbos, 1982], reinventado \n\ndiversas vezes, e ent\u00e3o popularizado por Rumelhart et al. em 1986 [Rumelhart et al., \n\n1986],\n\n3.2.4 Sistemas Difusos\n\nOs sistemas difusos s\u00e3o baseados na teoria dos conjuntos Difusos iniciada por \n\nLolfl Zadeh em 1965 [Zadeh, 1965], Um objetivo desta abordagem \u00e9 imitar os \n\naspectos da cogni\u00e7\u00e3o humana que pode ser chamado de racioc\u00ednio aproximado. Os \n\nSistemas Difusos podem ser menos precisos que os sistemas convencionais mas s\u00e3o \n\nmais semelhantes \u00e0s experi\u00eancias do dia-a-dia, como a tomada de decis\u00e3o humana. A \n\ntend\u00eancia \u00e9 falar em termos difusos como \u201calto\u201d e \u201craramente\u201d. Estes termos n\u00e3o s\u00e3o \n\nprecisos, mas eles s\u00e3o significativos e permitem que as pessoas descrevam situa\u00e7\u00f5es \n\ndo mundo real e raciocinem sobre eles.\n\nA L\u00f3gica Difusa [Cox, 1994; Zadeh, 1984; Kosko, 1992] \u00e9 designada para \n\nmanusear com conceitos ling\u00fc\u00edsticos imprecisos tal como pequeno, grande, alto, \n\nvelho ou jovem. Os sistemas baseados em l\u00f3gica difusa exibem uma flexibilidade \n\ninerente e t\u00eam provado ser \u00fateis em uma grande variedade de tarefas de controle \n\nindustrial e tarefas de reconhecimento de padr\u00f5es, abrangendo desde reconhecimento \n\nde manuscritos \u00e0 avalia\u00e7\u00e3o de cr\u00e9ditos. Existem hoje diversos produtos incluindo \n\nm\u00e1quinas de lavar, fornos micro-ondas e c\u00e2maras com foco autom\u00e1tico que usam a \n\nl\u00f3gica difusa no controle de seus mecanismos. O Jap\u00e3o \u00e9 o pa\u00eds que est\u00e1 conduzindo \n\nas aplica\u00e7\u00f5es de t\u00e9cnicas de l\u00f3gica di\u00e1isa.\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 51\n\nA id\u00e9ia central da flexibilidade que a l\u00f3gica difusa fornece \u00e9 a no\u00e7\u00e3o de um \n\nconjunto difuso. Na teoria dos conjuntos convencionais um elemento x pertence ou \n\nn\u00e3o a um determinado conjunto. A no\u00e7\u00e3o de pertin\u00eancia \u00e9 dicot\u00f4mica. Um valor de \n\npertin\u00eancia \u00e9 0 ou 1. Por exemplo, em uma aplica\u00e7\u00e3o de mercado pode-se classificar \n\no pre\u00e7o de um produto dizendo que o pre\u00e7o de uma a\u00e7\u00e3o \u00e9 barato ou caro.\n\ni i\n\nCaro\n\nBarato\n\n20\n\nFigura 3.6: Interpreta\u00e7\u00e3o para barato e caro na L\u00f3gica tradicional.\n\nComo pode ser visto na Figura 3.6 existe uma mudan\u00e7a brusca da condi\u00e7\u00e3o \n\nbarato para a condi\u00e7\u00e3o caro quando o pre\u00e7o \u00e9 de 20. Em outras palavras, quando o \n\npre\u00e7o for 19,5 \u00e9 considerado barato e quando for 20,5 \u00e9 considerado caro, embora \n\nexista uma diferen\u00e7a de apenas 1 nos dois pre\u00e7os . Contudo, tal corte n\u00e3o tem \n\ncorrespond\u00eancia com a vida di\u00e1ria, do qual considera-se ser barato ou caro. Se, \n\nconsidera-se 19 ser barato, ent\u00e3o 21 pode ser barato tamb\u00e9m, mas com grau de \n\n\u2019\u2019barateza\u201d menor. \u00c9 esta varia\u00e7\u00e3o no grau de medida da linguagem tal como \n\nbarato , \u201ccaro\u201d, \u201cbaixo\u201d, \u201calto\u201d que a l\u00f3gica difusa tenta capturar.\n\nUma representa\u00e7\u00e3o mais real\u00edstica do fen\u00f4meno dos pre\u00e7os \u00e9 de um conjunto \n\ndifuso onde existe um decl\u00ednio gradual no grau do conjunto barato e um aumento \n\ngradual no conjunto caro quando os pre\u00e7os aumentam. Isto \u00e9 representado na \n\ndiagrama de fun\u00e7\u00f5es de pertin\u00eancias mostrado na Figura 3.7.\n\nFigura 3.7: Interpreta\u00e7\u00e3o para barato e caro na L\u00f3gica Difusa.\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 52\n\nO intervalo dos valores de uma vari\u00e1vel (pre\u00e7o da a\u00e7\u00e3o) representado ao \n\nlongo do eixo x na Figura 3.7 \u00e9 referido como o universo de discurso X. O valor da \n\nfun\u00e7\u00e3o de pertin\u00eancia, que \u00e9 o grau para qual um pre\u00e7o particular pertence aos dois \n\nconjuntos difusos \u00e9 representado no eixo vertical e \u00e9 representado por / / x (x). O \n\nintervalo dos valores de pertin\u00eancia geralmente \u00e9 [0,1] (intervalo normalizado).\n\nGenericamente tem-se: Dado um espa\u00e7o de objetos (elementos) X, um \n\nconjunto A difuso \u00e9 um conjunto de pares ordenados definidos p o r :\n\nA = { (x, fXA(x)) I  x \u20ac X a  nA(x) e  [0,1]} ( 3\n\nonde fJ-A (x) \u00e9 chamado o grau de pertin\u00eancia de x pertencer a X .\n\nTodo conjunto difuso estabelece um mapeamento de um universo de discurso \n\nX  ao intervalo [0,1], chamada fun\u00e7\u00e3o de pertin\u00eancia ( | j .a ) .  Este mapeamento \n\nrepresenta a no\u00e7\u00e3o de elemento pertencer parcialmente em uma classe.\n\nOs dados que foram convertidos pelas fun\u00e7\u00f5es de pertin\u00eancias s\u00e3o referidos \ncomo fuzificados.\n\nUsualmente as formas e o universo da fun\u00e7\u00e3o de pertin\u00eancia s\u00e3o definidas por \n\num especialista humano. Na Tabela 3.1 apresenta-se algumas fun\u00e7\u00f5es de pertin\u00eancias \n\nusadas pelos especialista.\n\nFun\u00e7\u00e3o F\u00f3rm ula\ntriangular M'a ( x )  = max[min{(x-a)/(b-a);(c-xV(c-b)};01\ntrapezoidal Ma ( x )  = max [min f(x-a)/(b-a);(d-x)/( d-c));01\nsigmoidal Ma ( x )  = (1 - exp(-afx-c))'1\nTabela 3.1: Fun\u00e7\u00f5es de pertin\u00eancias mais comuns.\n\nAs opera\u00e7\u00f5es sobre conjuntos difusos s\u00e3o importantes para sistemas \n\nespecialistas pois o processo de infer\u00eancia \u00e9 baseado no processamento de conectivos \n\nl\u00f3gicos que t\u00eam quantificadores equivalentes \u00e0 Teoria dos Conjuntos Cl\u00e1ssicos. Por \n\nexemplo, dado a regra: Se (A e B) ent\u00e3o C, onde A, B e C s\u00e3o conjuntos difusos, o \n\nvalor verdade de C \u00e9 o valor verdade da conjun\u00e7\u00e3o (A e B), ou seja, (AnB). Pela\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 53\n\nmesma raz\u00e3o, opera\u00e7\u00f5es sobre conjuntos difusos s\u00e3o cruciais para infer\u00eancias em \n\nsistemas especialistas difusos. As tr\u00eas opera\u00e7\u00f5es b\u00e1sicas uni\u00e3o, intersec\u00e7\u00e3o e \n\ncomplemento difusos foram originalmente definidos por Zadeh [Zadeh, 1965]:\n\nUni\u00e3o: A o u B o  A u B  = { x ,m a x ( n A(x), juB(x)) } (3.4)\n\nInterse\u00e7\u00e3o: A e B  o  A n B  = { x , m i n ( n A(x), ^ B(x)) } (3.5)\n\nComplemento: n\u00e3o(A)&lt;=> - i A  = { x , 1 - jiA(x) } (3.6)\n\nEstas opera\u00e7\u00f5es s\u00e3o chamadas de opera\u00e7\u00f5es difusas padr\u00f5es [Klir &amp; Yuan, \n\n1995], Elas representam precisamente as opera\u00e7\u00f5es correspondentes para conjuntos \n\ncl\u00e1ssicos quando o intervalo dos graus de pertin\u00eancia \u00e9 o conjunto {0, 1}. Isto \u00e9, estas \n\nopera\u00e7\u00f5es s\u00e3o generaliza\u00e7\u00f5es correspondentes \u00e0s opera\u00e7\u00f5es sobre conjuntos cl\u00e1ssicos.\n\nNo entanto, as opera\u00e7\u00f5es de uni\u00e3o, interse\u00e7\u00e3o e complemento n\u00e3o s\u00e3o \u00fanicas como \n\nnos conjuntos cl\u00e1ssicos, e existem outras classes de opera\u00e7\u00f5es [Klir &amp; Yuan, 1995] \n\nque tamb\u00e9m s\u00e3o generaliza\u00e7\u00f5es das opera\u00e7\u00f5es cl\u00e1ssicas. As opera\u00e7\u00f5es de uni\u00e3o e \n\ninterse\u00e7\u00e3o difusas s\u00e3o usualmente referidas na literatura como t-norma e t-conorma, \n\nrespectivamente. J\u00e1 que, estas opera\u00e7\u00f5es difusas n\u00e3o s\u00e3o \u00fanicas, diferentes fun\u00e7\u00f5es \n\npodem ser apropriadas para representar estas opera\u00e7\u00f5es em diferentes contextos. A \n\ncapacidade de determinar as fun\u00e7\u00f5es de pertin\u00eancias apropriadas e tamb\u00e9m as \n\nopera\u00e7\u00f5es em um contexto particular \u00e9 crucial para o sucesso da Teoria dos \n\nConjuntos Difusos. Na grande maioria das aplica\u00e7\u00f5es os autores usam as opera\u00e7\u00f5es \npadr\u00f5es.\n\nRegras Difusas\n\nUma regra difusa SE - ENT\u00c3O (ou implica\u00e7\u00e3o difusa) assume a forma:\n\n\u201cS E x  \u00e9  A ent\u00e3o y  \u00e9  B \u201d (3.7)\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 54\n\nonde A e B s\u00e3o valores ling\u00fc\u00edsticos definidos por conjuntos difusos sobre um universo \n\nde discurso X e Y, respectivamente. Freq\u00fcentemente, \u201cx \u00e9 A\u201d \u00e9 chamado de premissa \n\nenquanto \u201cy \u00e9 B\u201d\u00e9 chamado de conseq\u00fcente (ou conclus\u00e3o) da regra.\n\nAntes de poder empregar as regras difusas SE - ENT\u00c3O para modelar e \n\nanalisar um sistema, primeiro tem-se que formalizar qual o significado da express\u00e3o \n\n\u201cSE x  \u00e9 A ent\u00e3o y  \u00e9 B \u201d, que algumas vezes \u00e9 abreviada por A \u2014\u00bb B. Em ess\u00eancia, a \n\nexpress\u00e3o descreve uma rela\u00e7\u00e3o entre duas vari\u00e1veis x e y; isto sugere que a regra \n\ndifusa SE - ENT\u00c3O seja definida como uma rela\u00e7\u00e3o bin\u00e1ria difusa R sobre o produto \n\ncartesiano no espa\u00e7o XxY. Note que R \u00e9 uma extens\u00e3o do produto cartesiana cl\u00e1ssico, \n\nonde cada elemento (x, y) e XxY est\u00e1 associado com o grau de pertin\u00eancia denotado \n\npor HR(x,y). Alternativamente, uma rela\u00e7\u00e3o difusa bin\u00e1ria R pode ser vista como um \n\nconjunto difuso com universo de discurso XxY, e seu conjunto difuso \u00e9 caracterizado \n\npela fun\u00e7\u00e3o de pertin\u00eancia bi-dimensional\n\nGeralmente, para calcular jiR(x,y) usa-se a f\u00f3rmula do Modus Pones \n\nGeneralizado:\n\nMafoy) = sup{c / nA(x) * c &lt; (nB(y) e 0 &lt;c &lt;1} (3 .\n\no n d e R ^ A ^ B ,  *\u00e9um operadort-norm a.\n\nRacioc\u00ednio Difuso (ou Racioc\u00ednio Aproximado)\n\nO Racioc\u00ednio Difuso tamb\u00e9m conhecido como Racioc\u00ednio Aproximado \u00e9 um \n\nprocedimento de infer\u00eancia usado para derivar conclus\u00f5es de um conjunto de regras \n\ndifusas SE - ENT\u00c3O em uma ou mais condi\u00e7\u00f5es.\n\nO racioc\u00ednio difuso de infer\u00eancia \u00e9 uma generaliza\u00e7\u00e3o da seguinte no\u00e7\u00e3o \n\nfamiliar. Suponha que tem-se uma curva y = f(x) que relaciona x com y. Quando, \n\ndado x = a ent\u00e3o de y = f(x) pode-se inferir que y = b = f(a), ver Figura 3.8.\n\nUma generaliza\u00e7\u00e3o do processo acima permite que \u2018a \u2019 seja um intervalo e f(x) \n\numa fun\u00e7\u00e3o intervalar, como mostra a Figura 3.9. Para encontrar o intervalo resultante \n\ny=b correspondente ao intervalo x=a, primeiro constr\u00f3i-se uma extens\u00e3o cil\u00edndrica de\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 55\n\na (isto \u00e9, estende-se o dom\u00ednio de \u2018a \u2019 para X  x Y) e ent\u00e3o encontra-se sua interse\u00e7\u00e3o \n\nI com a curva intervalar. A proje\u00e7\u00e3o de I sobre o eixo y produz o intervalo y = b.\ni k\n\ni k \\\\\\\\\n\n/ fOO\n\ny=b f ( x ) / y=b 1\n\nj\n\nx=a x=a\n-\u2014 ?\n\nFigura 3.8. Deriva\u00e7\u00e3o de y\u2014b a partir de Figura 3.9: Deriva\u00e7\u00e3o de y=b a partir de \nx=a e y=f(x), onde a e b s\u00e3o pontos e f(x) x=a e y=f(x), onde a e b s\u00e3o intervalos e \n\u00e9 uma curva [Jang &amp; Sun, 1995]. f(x) \u00e9 uma fun\u00e7\u00e3o intervalar [Jang &amp;\n\nSun, 1995].\n\nSeguindo um passo a mais na generaliza\u00e7\u00e3o, assumi-se que A \u00e9 um conjunto\n\ndifuso de X e F \u00e9 um conjunto difuso da rela\u00e7\u00e3o X x Y, como mostrado na Figura\n\n3.10 e na Figura 3.11. Para encontrar o conjunto resultante B, novamente constr\u00f3i-se a\n\nextens\u00e3o cil\u00edndrica cilin(A) com base A (isto \u00e9, expande-se o dom\u00ednio de A de X para\n\nX x Y para obter cilin(A)). A interse\u00e7\u00e3o de cilin(A) e F (Figura 3.12) forma uma\n\nregi\u00e3o de intersec\u00e7\u00e3o an\u00e1loga a regi\u00e3o I da Figura 3.9. Pela proje\u00e7\u00e3o de cilin(A) r\\ F\n\nsobre o eixo y, infere-se y como um conjunto difuso B sobre o eixo y, como mostra a \nFigura 3.13.\n\nB d ensio Cil\u00edndrica de tr(>0. tfiO ^ tr iX y )\n\nFigura 3.10: Extens\u00e3o cil\u00edndrica A.\n\nX.Y:K-*Kx,t\u00f3 K x .y .2 .3 ,1 5 ) \u2014\n\nFigura 3.11: Rela\u00e7\u00e3o difusa F sobre x e\ny-\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial_________________________________\n\n?;n\u00edK:ri)\n\nFigura 3.12: Opera\u00e7\u00e3o min.\n\n0.8\n\n0.6\n0 .4\n\n0.2\n\nProje\u00e7\u00e3o de mr<K,tn) sobre Oyz \n\nHs \n\n%\n? ' 1 '  ? 1 ? 1 1 1  ? ? ? 1 ? ?\n\nFigura 3.13: Proje\u00e7\u00e3o sobre o eixo y.\n\nEspecificamente, seja jj.a , Mo/m, Me e jj.f as fun\u00e7\u00f5es de pertin\u00eancias de A, \n\ncilin(A), B e F ,  respectivamente, onde M c / / / \u00ab ( A )  est\u00e1 relacionado com jaA atrav\u00e9s\n\n\u2022MC;7m(A)(x,y) =  | l A(x ). (3-9)\n\nEnt\u00e3o:\n\nMo/m(A) n  F (x ,y ) =  m in [^ C\u00ed/l\u201e (A )(x ,y ), |aF(x ,y )] \n\n=  m in[)aA( x ) , M F (x ,y )].\n\n(3.10)\n\nPela proje\u00e7\u00e3o cilin(A) n  F sobre o eixo y, tem-se:\n\nMb(y)  =  m a x  min[jnA( x ) , MF(x,y)]. (3.11)\n\nEsta f\u00f3rmula \u00e9 referida na literatura como composi\u00e7\u00e3o max min e B \u00e9 \n\nrepresentado como:\n\nB = A \u00b0 F (3.12)\n\nonde \u00b0 denota o operador de composi\u00e7\u00e3o. Se for escolhido o produto para t-norma (E) \n\ne max para t-conorma (OU), ent\u00e3o tem-se a composi\u00e7\u00e3o max-produto e jaB(y) ser\u00e1 \n\ndado por:\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 57\n\nHs(y) -  max [juA(x) p.F(x,y)]. (3.13)\n\nUsando a regra composicional de infer\u00eancia, pode-se formalizar um \n\nprocedimento de infer\u00eancia, chamado Racioc\u00ednio Difuso, sobre um conjunto de regras \n\ndifusas. A regra b\u00e1sica de infer\u00eancia na l\u00f3gica tradicional (bi-valorada) \u00e9 o Modus \n\nPones, de acordo com que se pode inferir a verdade da proposi\u00e7\u00e3o B sabendo que A e \n\na implica\u00e7\u00e3o A \u2014> B s\u00e3o verdades. Este conceito \u00e9 ilustrado como:\n\npremissa 1 (fato): x \u00e9 A\n\npremissa 2 (regra):______ se x \u00e9 A ent\u00e3o v \u00e9 B\n\nconseq\u00fcente (conclus\u00e3o): y \u00e9 B\n\nContudo, na maioria dos racioc\u00ednios humanos, o Modus Ponens \u00e9 empregado \n\nde uma maneira aproximada. Por exemplo, tendo-se a regra de implica\u00e7\u00e3o \u201cSe a \n\ncrian\u00e7a est\u00e1 p\u00e1lida ent\u00e3o a crian\u00e7a est\u00e1 com anemia\u201d e sabe-se que a \u201ccrian\u00e7a est\u00e1 \n\nquase p\u00e1lida\u201d ent\u00e3o pode-se inferir que a \u201ccrian\u00e7a est\u00e1 quase com anemia\u201d. Isto \u00e9 \n\nescrito c o m o :\n\npremissa 1 (fato): x \u00e9 A \u2019\n\npremissa 2 (regra): se x \u00e9 A ent\u00e3o v \u00e9 B \n\nconseq\u00fcente (conclus\u00e3o): y \u00e9 B \u2019\n\nonde A \u2019 est\u00e1 pr\u00f3ximo de A e B \u2019 est\u00e1 pr\u00f3ximo de B. Quando A, A \u2019, B e B \u2019 s\u00e3o \n\nconjuntos difusos de universos apropriados, o procedimento de infer\u00eancia acima \u00e9 \n\nchamado de Racioc\u00ednio Difuso ou Racioc\u00ednio Aproximado (tamb\u00e9m chamado de \n\nModus Ponens generalizado desde que se tenha o Modus Ponens como caso especial).\n\nUsando a regra de composi\u00e7\u00e3o de infer\u00eancia introduzido inicialmente pode-se \n\nformular o processo de infer\u00eancia do Racioc\u00ednio Difuso com a seguinte defini\u00e7\u00e3o.\n\nDefini\u00e7\u00e3o: Racioc\u00ednio Difuso Baseado sobre a composi\u00e7\u00e3o Max-Mim Seja A, A \u2019 e B \n\nconjuntos Difusos de X, X' e Y respectivamente. Assume-se que a implica\u00e7\u00e3o difusa\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 58\n\nA-\u00bbB seja expressada como uma rela\u00e7\u00e3o difusa R sobre XxY. Ent\u00e3o o conjunto \n\nDifuso B \u2019 induzido por \u201cx \u00e9 A \u2019 \u201d e a regra difusa \u201cse x \u00e9 A ent\u00e3o y \u00e9 B\u201d \u00e9 definido \n\npor\n\nMB*(y) = max min[|iA<x), nR(x,y)] (3.16)\n\nou equivalentemente\n\nB \u2019 = A \u2019 \u00b0 R =  A \u2019 0 (A\u2014>B) (3.17)\n\nRelembrando que (3.17) \u00e9 uma express\u00e3o gen\u00e9rica para o Racioc\u00ednio Difuso, \n\nenquanto (3.16) \u00e9 um exemplo de Racioc\u00ednio Difuso onde o max e min s\u00e3o os \n\noperadores difusos para a t-conorma e t-norma, respectivamente.\n\nAgora pode-se usar o processo de infer\u00eancia do Modus Ponens Generalizado \n\npara derivar as conclus\u00f5es, desde que a implica\u00e7\u00e3o difusa A\u2014>B seja definida como \n\numa rela\u00e7\u00e3o difusa bin\u00e1ria apropriada.\n\nV antagens e Limita\u00e7\u00f5es dos Sistemas Difusos\n\nUm dos principais pontos fortes da l\u00f3gica difusa comparado com outros \n\nm\u00e9todos \u00e9 a forma de tratar dados imprecisos. Sua base de conhecimento, que \u00e9 em \n\nforma de regras, \u00e9 facilmente examinada e entendida. O formato das regras tamb\u00e9m \n\ntom a f\u00e1cil a atualiza\u00e7\u00e3o e manuten\u00e7\u00e3o da base de conhecimento.\n\nComo limita\u00e7\u00e3o da l\u00f3gica difusa e principal defici\u00eancia \u00e9 que as fun\u00e7\u00f5es de \n\npertin\u00eancia e as regras tem que ser especificadas manualmente. A determina\u00e7\u00e3o das \n\nfun\u00e7\u00f5es de pertin\u00eancias pode consumir algum tempo num processo de tentativa e \n\nerro. Al\u00e9m disto, a elicita\u00e7\u00e3o das regras de especialistas humanos pode ser um \n\nprocesso caro e propenso a erro. E mais, elas n\u00e3o podem adaptar-se automaticamente \n\npara as mudan\u00e7as no meio em que se est\u00e1 operando. Novas regras tem que ser \n\nmanualmente alteradas se as condi\u00e7\u00f5es do problema mudarem.\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 59\n\nAplica\u00e7\u00f5es\n\nAs \u00e1reas nas quais a l\u00f3gica difusa foi aplicada com \u00eaxito s\u00e3o freq\u00fcentemente \n\nbem concretas. A primeira aplica\u00e7\u00e3o comercial importante foi na \u00e1rea de controle de \n\nfomos de cimento. \u00c9 uma opera\u00e7\u00e3o que requer que um operador controle quatro \n\nestados internos do forno, controle quatro jogos de opera\u00e7\u00f5es, e dinamicamente \n\nadministre 40 ou 50 \"regras thumb\u201d sobre sua inter-rela\u00e7\u00e3o, tudo com a meta de \n\ncontrolar um conjunto altamente complexo de intera\u00e7\u00f5es qu\u00edmicas. Um relato \n\ncompleto deste sistema, muito bem sucedido, pode ser encontrado em Umbers e King \n\n[Umbers e King, 1980],\n\nA l\u00f3gica difusa pode ser aplicada em muitas \u00e1reas como classifica\u00e7\u00e3o, \n\ntomadas de decis\u00f5es e reconhecimento de padr\u00f5es. Mas, a l\u00f3gica difusa tem um valor \n\nparticular nas aplica\u00e7\u00f5es de controle onde \u00e9 dif\u00edcil ou imposs\u00edvel desenvolver um \n\ncontrolador tradicional. No momento, o Jap\u00e3o est\u00e1 sendo o l\u00edder no desenvolvimento \n\nde sistemas de controle l\u00f3gico-difuso para diversas aplica\u00e7\u00f5es como ar \n\ncondicionados, c\u00e2maras, m\u00e1quinas de lavar, micro-ondas e sistemas de estradas de \n\nferro [Self, 1990] e [Waller, 1989],\n\nA MIRC (Market Intelligence Research Corporation) espera que a renda total \n\npara produtos baseados em l\u00f3gica difusa combinados com redes neuronais cres\u00e7a para \n\n10 bilh\u00f5es at\u00e9 1998 [Kandel, 1993], Maiers e Sherif [Maiers e Sherif, 1985] \n\nforneceram 450 refer\u00eancias de aplica\u00e7\u00f5es de l\u00f3gica difusa e teoria. Levy [Levy et al., \n\n1991] descreve uma avalia\u00e7\u00e3o de aplica\u00e7\u00f5es para empr\u00e9stimos comerciais.\n\nOs sistemas especialistas foram os recipientes bem \u00f3bvios dos benef\u00edcios de \n\nl\u00f3gicas difusas, desde que seu dom\u00ednio \u00e9 freq\u00fcentemente inerentemente difuso. \n\nExemplos de sistemas especialistas com l\u00f3gica difusa s\u00e3o os sistemas de apoio \u00e0 \n\ndecis\u00e3o, planejadores financeiros, sistemas de diagn\u00f3sticos para determinar patologia \n\nde soja, e um sistema especialista meteorol\u00f3gico na China para determinar \u00e1reas que \n\ndevem plantar pomares de seringueiras [Zadeh, 1984], Outra \u00e1rea de aplica\u00e7\u00e3o, \n\nsemelhante aos sistemas especialistas, \u00e9 a recupera\u00e7\u00e3o de informa\u00e7\u00e3o [Radecki, \n1982],\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 60\n\nHist\u00f3rico\n\nA precis\u00e3o matem\u00e1tica deve seu \u00eaxito em grande parte aos esfor\u00e7os de \n\nAristote e aos fil\u00f3sofos que o precederam que se esfor\u00e7aram para inventar uma teoria \n\nconcisa de l\u00f3gica. A matem\u00e1tica, chamada \"Leis do Pensamento\" foram descritas em \n\n[Komer, 1967], Uma destas, a \"Lei do Meio Exclu\u00eddo\u201d, declara que qualquer \n\nproposi\u00e7\u00e3o deve ser Verdadeira ou Falsa. At\u00e9 Parminedes propor a primeira vers\u00e3o \n\ndesta lei (em tomo de 400 A.C.) haviam obje\u00e7\u00f5es imediatas e fortes: por exemplo, \n\nHeraclitus prop\u00f4s que coisas podiam ser simultaneamente Verdadeiras e n\u00e3o \n\nVerdadeiras.\n\nFoi Plato que colocou a fundamenta\u00e7\u00e3o para o que teria tomado-se l\u00f3gica\n\ndifusa, indicando que havia uma terceira regi\u00e3o (al\u00e9m de Verdade e Falso) onde estas\n\ncontradi\u00e7\u00f5es deixam de valer. Outros fil\u00f3sofos mais modernos ecoaram seus\n\nsentimentos, destacando notavelmente Hegel, Marx, e Engels. Mas foi Lukasiewicz\n\nque primeiro prop\u00f4s uma alternativa sistem\u00e1tica \u00e0 l\u00f3gica bi-valorada de Aristotle \n[Lejewsk, 1967],\n\nNo in\u00edcio dos anos de 1900, Lukasiewicz descreveu uma l\u00f3gica tri-valorada. O \n\nterceiro valor proposto pode melhor ser traduzido como o termo \"poss\u00edvel\", e ele \n\ndesignou um valor num\u00e9rico entre Verdade e Falso. Eventualmente, prop\u00f4s uma \n\nnota\u00e7\u00e3o completa e um sistema axiom\u00e1tico do qual ele esperava derivar a matem\u00e1tica \nmodema.\n\nMais tarde, ele explorou l\u00f3gicas de quatro valores, l\u00f3gicas de cinco valores, e \n\nent\u00e3o declarou que em princ\u00edpio n\u00e3o havia nada para impedir a deriva\u00e7\u00e3o de uma \n\nl\u00f3gica infinito-valorada. Lukasiewicz percebeu que l\u00f3gicas de tr\u00eas e infinitos valores \n\neram mais intrigantes, mas ele finalmente determinou uma l\u00f3gica quadro-valorada \nporque pareceu ser\n\nmais f\u00e1cil para adaptar \u00e0 l\u00f3gica Aristoteliana.\n\nKnuth prop\u00f4s uma l\u00f3gica tri-valorada semelhante a de Lukasiewicz, do qual \n\nele especulou que aquela matem\u00e1tica tomar-se-ia mais elegante que a l\u00f3gica bi- \n\nvalorada tradicional. Sua introspec\u00e7\u00e3o, aparentemente perdida por Lukasiewicz, era \n\nusar o conjunto {1, 0, -1} ao inv\u00e9s de {0,1, 2}. N\u00e3o obstante, esta alternativa n\u00e3o \n\nconseguiu ganhar aceita\u00e7\u00e3o e passou em obscuridade relativa.\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 61\n\nFoi s\u00f3 muito recentemente que a no\u00e7\u00e3o de uma l\u00f3gica de infinitos-valores \n\ntomou-se segura. Em 1965 Lotfi A. Zadeh publicou seu trabalho seminal \"Conjuntos \n\nDifusos\u201d [Zadeh, 1965; Zadeh, 1968] onde descreveu a matem\u00e1tica da teoria dos \n\nconjuntos difusos, e por extens\u00e3o a l\u00f3gica difusa. Esta teoria prop\u00f4s uma fun\u00e7\u00e3o de \n\npertin\u00eancia (ou os valores Falso e Verdadeiro) que opera sobre o intervalo de n\u00fameros \n\ndos reais [0, 1], Novas opera\u00e7\u00f5es para o c\u00e1lculo de l\u00f3gica foram propostas, e foram \n\nmostradas ser em princ\u00edpio pelo menos uma generaliza\u00e7\u00e3o de l\u00f3gica cl\u00e1ssica.\n\n3.2.5 Algoritmos Gen\u00e9ticos\n\nOs Algoritmos Gen\u00e9ticos [Goldberg, 1989] s\u00e3o basicamente t\u00e9cnicas de busca, \n\nque foi primeiro sugeridas por John Holland [Holland, 1975], e que se baseiam nos \n\nprocessos observados em evolu\u00e7\u00e3o natural. Estes algoritmos t\u00eam sido muito usados na \n\nsolu\u00e7\u00e3o de problemas de otimiza\u00e7\u00e3o. Eles s\u00e3o capazes de performar uma busca \n\nrobusta, altamente eficiente e rapidamente localizar solu\u00e7\u00f5es muito boas para \n\nproblemas de buscas dif\u00edceis.\n\nEm geral, os AGs performam buscas rand\u00f4micas diretas atrav\u00e9s de um \n\nconjunto de dados de alternativas com o objetivo de encontrar a melhor alternativa \n\ncom respeito a um dado crit\u00e9rio. Estes crit\u00e9rios devem ser expressados em termos de \n\numa fun\u00e7\u00e3o objetivo, que \u00e9 usualmente referida como uma fun\u00e7\u00e3o de ajustamento.\n\nO primeiro passo para aplica\u00e7\u00e3o de AGs a um problema \u00e9 representar \n\n(codificar) solu\u00e7\u00f5es poss\u00edveis no espa\u00e7o de busca como uma seq\u00fc\u00eancia de s\u00edmbolos \n\ngerados a partir de um dado alfabeto finito A. Geralmente se usa o alfabeto bin\u00e1rio \n\nA={0,1}. Cada seq\u00fc\u00eancia corresponde a um cromossomo, e cada elemento da \n\nseq\u00fc\u00eancia \u00e9 equivalente a um gene. O conjunto de cromossomos \u00e9 chamado \n\npopula\u00e7\u00e3o.\n\nPor exemplo, dado um conjunto de pontos (x,y) pode-se querer ajust\u00e1-los a \n\numa reta. Para isto, codifica-se o conjunto de par\u00e2metros para uma reta y = Pjx + p 2 ? \n\npara criar seq\u00fc\u00eancias de s\u00edmbolos independentes para as duas constantes \n\ndesconhecidas P! e P2 e ent\u00e3o concatena-se (concatena\u00e7\u00e3o de seq\u00fc\u00eancias). As \n\nseq\u00fc\u00eancias de s\u00edmbolos geralmente s\u00e3o combina\u00e7\u00f5es de 0\u2019s e l \u2019s, que representam o \n\nvalor de um n\u00famero na forma bin\u00e1ria. Uma cadeia de n-bits pode acomodar todos os\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 62\n\ninteiros at\u00e9 2n-l. Por exemplo, o n\u00famero 7 requer uma cadeia de 3 bit (23-l= 7) e o \n\nn\u00famero 10 (10102) de um cadeia de 4 bits. Esta cadeia de bits pode ser mapeada pelos \n\nvalores de um par\u00e2metro dado por:\n\nonde b \u00e9 o n\u00famero decimal que est\u00e1 sendo representado em bin\u00e1rio, L \u00e9 o \n\ncomprimento da cadeia de bits, P ^  e P ^  s\u00e3o constantes que dependem do problema \n\ne representam os valores m\u00e1ximo e m\u00ednimo que P; pode assumir.\n\nAp\u00f3s definir a codifica\u00e7\u00e3o para os par\u00e2metros, uma popula\u00e7\u00e3o inicial de n \n\nseq\u00fc\u00eancias (cromossomos) de comprimento L \u00e9 criada (de forma rand\u00f4mica). Cada \n\numa das seq\u00fc\u00eancias e decodificada dentro de um conjunto de par\u00e2metros que o \n\nrepresenta. Este conjunto de par\u00e2metros \u00e9 passado atrav\u00e9s de um modelo num\u00e9rico do \n\nespa\u00e7o do problema. Os modelos num\u00e9ricos d\u00e3o uma solu\u00e7\u00e3o baseada no conjunto de \n\nentrada dos par\u00e2metros. Baseado na qualidade desta solu\u00e7\u00e3o cada cromossomo recebe \n\num valor de ajustamento. Com estes valores de ajustamento, os operadores gen\u00e9ticos \n\nreprodu\u00e7\u00e3o, crossover e muta\u00e7\u00e3o, s\u00e3o usados para gerar uma nova popula\u00e7\u00e3o de \n\nsolu\u00e7\u00f5es, que se espera ser melhor que as gera\u00e7\u00f5es pr\u00e9vias (melhor valor de \n\najustamento). O novo conjunto de cromossomos \u00e9 novamente decodificado e \n\navaliado, e uma nova popula\u00e7\u00e3o \u00e9 criada usando os operadores b\u00e1sicos dos AGs. Este \n\nprocesso continua at\u00e9 que um crit\u00e9rio de parada seja atingido (converg\u00eancia).\n\nEntre os tr\u00eas operadores, a reprodu\u00e7\u00e3o copia um indiv\u00edduo de uma gera\u00e7\u00e3o \n\npara pr\u00f3xima; crossover (Figura 3.14 (A)) combina caracter\u00edsticas de dois ou mais \n\npais para produzir um ou mais filhos, muta\u00e7\u00e3o (Figura 3.14(B)) faz pequenas \n\nmudan\u00e7as locais. A reprodu\u00e7\u00e3o e o crossover de ajuste individual fornecem um \n\nimpulso para melhorar, enquanto muta\u00e7\u00e3o (menos utilizada) mant\u00e9m a popula\u00e7\u00e3o \n\ndiversificada e permite uma explora\u00e7\u00e3o mais ampla.\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 63\n\nFigura 3.14: (A) Crossover entre dois cromossomos. (B) Muta\u00e7\u00e3o no alelo 3.\n\nO desenvolvimento de um AG para solucionar um problema particular \n\nenvolve dois tipos de decis\u00e3o. A primeira concerne na forma no qual o problema ser\u00e1 \n\nmodelado dentro das exig\u00eancia do AG, o que inclui a defini\u00e7\u00e3o do espa\u00e7o de solu\u00e7\u00f5es \n\nposs\u00edveis, a forma da fun\u00e7\u00e3o e ajustamento, e o caminho no qual os indiv\u00edduos s\u00e3o \n\nrepresentados como seq\u00fc\u00eancia de s\u00edmbolos (cromossomos). A segunda refere-se aos \n\npar\u00e2metros dos AGs por si s\u00f3 e inclui as propor\u00e7\u00f5es da popula\u00e7\u00e3o para ser \n\nreproduzida como um resultado de reprodu\u00e7\u00e3o, crossover e muta\u00e7\u00e3o, o procedimento \n\nde sele\u00e7\u00e3o, o tamanho da popula\u00e7\u00e3o, o n\u00famero de gera\u00e7\u00f5es e um n\u00famero de outras \n\ndecis\u00f5es que dizem respeito as variantes deste algoritmo b\u00e1sico.\n\nVantagens e Limita\u00e7\u00f5es dos AGs\n\nDevido \u00e0 sua estrutura paralela os AGs provaram ser muito eficientes nas \n\nbuscas em conjuntos de dados muito grandes [Goldberg, 1989], Este processo de \n\nbusca tem tamb\u00e9m outra vantagem sendo altamente desej\u00e1vel para implementa\u00e7\u00e3o em \n\ncomputadores paralelos. Eles tem tido um sucesso particular em problemas de \n\notimiza\u00e7\u00e3o incluindo job-shop scheduling, escala de hor\u00e1rios e otimiza\u00e7\u00e3o de \n\nportif\u00f3lio [Davis, 1991; Deboeck, 1994], Os AGs podem aprender rela\u00e7\u00f5es \n\ncomplexas, conjunto de dados incompletos e podem ser como as ferramentas \u201cdata \n\nmining\u201d para descobrir padr\u00f5es desconhecidos previamente. Eles podem adaptar \n\nmudan\u00e7as no meio onde est\u00e3o operando e podem fornecer explica\u00e7\u00f5es das decis\u00f5es \n\nque produzem em um formato que os humanos possam entender.\n\nUma limita\u00e7\u00e3o dos AGs \u00e9 que a declara\u00e7\u00e3o dos par\u00e2metros assim como as \n\ntaxas de muta\u00e7\u00e3o e crossover \u00e9 dependente do problema e consome muito tempo no \n\nprocesso de tentativa-e-erro. Al\u00e9m disto, a performance do AG \u00e9 afetada pelo\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 64\n\nesquema de representa\u00e7\u00e3o que \u00e9 empregado. A sele\u00e7\u00e3o de um esquema apropriado \n\npode requerer experimentos extensos.\n\nAplica\u00e7\u00f5es\n\nOs AGs podem ser vistos como um tipo de m\u00e1quina de aprendizagem para \n\nautomaticamente resolver problemas complexos. Eles fornecem um conjunto de \n\nheur\u00edsticas de busca, independente do dom\u00ednio e eficientes para um amplo espectro \n\nde aplica\u00e7\u00f5es. Austin [Austin, 1990] tem indicado algumas \u00e1reas de aplica\u00e7\u00f5es gerais \n\ncomo controle de processo din\u00e2mico, indu\u00e7\u00e3o de otimiza\u00e7\u00e3o de regras, descobrimento \n\nde novas topologias conexionistas, simula\u00e7\u00e3o de modelos biol\u00f3gicos de \n\ncomportamento e evolu\u00e7\u00e3o, projeto complexo de estruturas de engenharia e \n\nreconhecimento de padr\u00f5es.\n\nO AG \u00e9 uma ferramenta muito interessante. Ela rejeita solu\u00e7\u00f5es inferiores e \n\nacumula as boas. Tamb\u00e9m, os AGs s\u00e3o desej\u00e1veis para processamento paralelo \n\n[Austin, 1990], Finalmente, os AGs s\u00e3o tamb\u00e9m usados em l\u00f3gica difusa [Karr,\n\n1991],\n\nAs aplica\u00e7\u00f5es em neg\u00f3cios est\u00e1 crescendo rapidamente em aplica\u00e7\u00f5es com \n\nsucesso em com\u00e9rcio financeiro, avalia\u00e7\u00e3o de cr\u00e9dito e detec\u00e7\u00e3o de fraude. Eles est\u00e3o \n\ntamb\u00e9m sendo usados para prever fal\u00eancia de corpora\u00e7\u00f5es [Kingdon &amp; Feldman, \n\n1995], Quando concede-se um empr\u00e9stimo ou cr\u00e9dito a uma companhia, uma \n\navalia\u00e7\u00e3o de sua capacidade de pagar seus d\u00e9bitos \u00e9 uma considera\u00e7\u00e3o fundamental. \n\nSe existe a possibilidade da companhia estar indo a fal\u00eancia, ent\u00e3o a organiza\u00e7\u00e3o que \n\nfornece o cr\u00e9dito pode n\u00e3o conceder o empr\u00e9stimo ou mudar para um n\u00edvel muito alto \n\nde juro para compensar o tal risco. Correntemente o m\u00e9todo prim\u00e1rio de predi\u00e7\u00e3o de \n\nfal\u00eancia envolve t\u00e9cnicas de modelagem linear, principalmente an\u00e1lise discriminante \n\nmultivariada.\n\nKingdon e Feldman usaram os AGs para inferir regras para previs\u00e3o de \n\nfal\u00eancia, usando \u00edndices financeiros extra\u00eddos dos balan\u00e7os das companias. Exemplos \n\nde \u00edndices financeiros, usados no processo de aprendizagem das regras, s\u00e3o \n\nvendas/ativo total, ativo circulante/passivo circulante e receita/vendas. Em m\u00e9dia o \n\nm\u00e9todo AG foi 15% melhor em acur\u00e1cia que o modelo de an\u00e1lise discriminante\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 65\n\nm\u00faltipla, comumente usado, e aproximadamente compar\u00e1vel com a performance das \n\nRNA usada com os mesmos dados.\n\nPackard [Packard, 1990] usa os AGs para auxiliar o governo na aloca\u00e7\u00e3o de \nrecursos.\n\nOutros exemplos de aplica\u00e7\u00e3o s\u00e3o os seguintes trabalhos:\n\n\u2022 Reconhecimento de Suspeitos Criminosos [Caldwell &amp; Johnston, 1991];\n\n\u2022 Composi\u00e7\u00e3o de M\u00fasica [Homer &amp; Goldberg, 1989];\n\n\u2022 Scheduling [Gabbert et al., 1989; Syswerda &amp; Palmucci, 1991];\n\n\u2022 Otimiza\u00e7\u00e3o de data de base query [Bennett et al., 1989];\n\n\u2022 Projeto de avi\u00f5es [Bramlette &amp; Bouchard, 1991];\n\n\u2022  Aposta em corridas de cavalos [de la Maza, 1989];\n\nH ist\u00f3rico\n\nEmbora Charles Darwin tenha formulado a Teoria da Evolu\u00e7\u00e3o no final do \n\ns\u00e9culo passado [Darwm, 1985], foi s\u00f3 recentemente que se tentou idealizar um \n\nmodelo matem\u00e1tico do processo evolutivo. Nos anos 60, John Holland, da \n\nUniversidade de Michigan, come\u00e7ou a definir as bases de algoritmos de otimiza\u00e7\u00e3o \n\nde inspira\u00e7\u00e3o gen\u00e9tica. Seu trabalho culminou na publica\u00e7\u00e3o do livro Adapta\u00e7\u00e3o em \n\nSistemas Naturais e Artificiais em 1975 [Holland, 1975], O livro, que \u00e9 hoje muito \n\ncitado, mas pouqu\u00edssimo lido, foi pouco divulgado na \u00e9poca, em grande parte ao \n\nestilo pesado com nota\u00e7\u00e3o muito complexa. Felizmente Holland e seus muitos \n\ndisc\u00edpulos, quase todos seus alunos de p\u00f3s gradua\u00e7\u00e3o, continuaram sua linha de \n\ninvestiga\u00e7\u00e3o, publicando resultados com alguma timidez mas com perseveran\u00e7a.\n\nA grande popularidade que os AGs atingiram recentemente se deve a dois \n\nimportantes fatores: a publica\u00e7\u00e3o de um livro tutorial sobre AGs [Goldberg, 1989] por \n\num dos alunos de doutorado de Holland, David Goldberg, um pesquisador \n\nextremamente ativo e com excelente potencial did\u00e1tico, e \u00e0s confer\u00eancias \n\nInternacionais sobre Algoritmos Gen\u00e9ticos (IC-GAs), que t\u00eam se realizado a cada dois \n\nanos nos Estados Unidos, desde 1985.\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 66\n\n3.2.6 Racioc\u00ednio Baseado em Casos\n\nO Racioc\u00ednio Baseado em Casos (RBC) \u00e9 uma abordagem recente da IA que \n\ntem recebido muita aten\u00e7\u00e3o nos \u00faltimos anos. Seu objetivo principal \u00e9 buscar uma \n\nsolu\u00e7\u00e3o semelhante, para um problema atual, atrav\u00e9s do estabelecimento de graus de \n\nsimilaridade, com uma experi\u00eancia passada, armazenada na base de casos \n\n[Kolodner, 1992],\n\nO RBC \u00e9 um conjunto de m\u00e9todos e t\u00e9cnicas usadas para representar a forma \n\ncomo os homens raciocinam. O RBC modela a habilidade humana de relembrar e \n\nadaptar um fato passado para resolver um problema novo, semelhante de alguma \n\nforma a esta experi\u00eancia passada.\n\nO RBC \u00e9 um paradigma para resolver problemas que em muitos aspectos s\u00e3o \n\nfundamentalmente diferente das outras t\u00e9cnicas de IA. Ao inv\u00e9s de contar somente \n\ncom o conhecimento geral de um problema dom\u00ednio, ou fazer associa\u00e7\u00f5es junto com \n\nrela\u00e7\u00f5es generalizadas entre o problema descrito e conclus\u00f5es, o RBC \u00e9 capaz de \n\nusar o conhecimento espec\u00edfico de experi\u00eancias pr\u00e9vias, situa\u00e7\u00f5es de problemas \n\nconcretos (casos). Um novo problema \u00e9 resolvido encontrando um caso passado mais \n\nsimilar, e reusando na situa\u00e7\u00e3o do novo problema. Uma segunda diferen\u00e7a importante \n\n\u00e9 que o RBC \u00e9 uma abordagem com aprendizagem com incremento cont\u00ednuo, desde \n\nque uma experi\u00eancia nova pode ser retida na base de casos cada vez que um problema \n\nfoi resolvido, tornando imediatamente dispon\u00edvel para problemas futuros.\n\nMas o que \u00e9 um caso? De uma forma mais simples, \u00e9 a representa\u00e7\u00e3o de um \n\nfato ou de uma experi\u00eancia atrav\u00e9s de suas caracter\u00edsticas (atributos). Estes atributos \n\ndevem descrever n\u00e3o apenas o conte\u00fado da experi\u00eancia, como tamb\u00e9m, o contexto \n\nem que esta se passou. Alguns exemplos incluem as informa\u00e7\u00f5es sobre uma forma de \n\nempr\u00e9stimo-pessoal e se o empr\u00e9stimo foi concedido ou n\u00e3o, e o hist\u00f3rico de uma \n\nempresa com o diagn\u00f3stico associado. Os casos formam a base de casos.\n\nUm novo problema \u00e9 resolvido seguindo os seguintes passos:\n\n\u2022 recupera\u00e7\u00e3o de um ou mais casos previamente armazenado na base de\n\ncasos;\n\n\u2022 sele\u00e7\u00e3o de um ou mais casos dentre os casos recuperados;\n\n\u2022 revis\u00e3o deste(s) caso(s) para determinar a necessidade de adapta\u00e7\u00e3o;\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 67\n\n\u2022 reutiliza\u00e7\u00e3o do caso adaptado para resolver o problema de entrada;\n\n\u2022 avalia\u00e7\u00e3o da solu\u00e7\u00e3o do problema de entrada;\n\n\u2022 inclus\u00e3o do caso adaptado na base de casos (aprendizagem).\n\nO desenvolvimento do CBR \u00e9 uma tarefa complexa que est\u00e1 formulada em \n\nquatro etapas distintas [Weber-Lee, 1996] e [Aamodt, 1991].:\n\n\u2022 representa\u00e7\u00e3o dos casos\n\n\u2022 recupera\u00e7\u00e3o do(s) caso(s) mais similares\n\n\u2022 adapta\u00e7\u00e3o dos casos\n\n\u2022 reutiliza\u00e7\u00e3o, avalia\u00e7\u00e3o e aprendizagem ;\n\nAlguns autores apresentam estas etapas com diferentes enfoques. Algumas \n\netapas s\u00e3o dif\u00edceis de serem apresentadas isoladamente, da\u00ed a raz\u00e3o do agrupamento \n\nde algumas delas, em face dos tipos de sistemas implementados.\n\nR epresenta\u00e7\u00e3o dos Casos\n\nO problema da representa\u00e7\u00e3o dos casos representa um dos primeiros t\u00f3picos a \n\nserem cuidadosamente estudados, na medida em que, uma ou outra orienta\u00e7\u00e3o na \n\nabstra\u00e7\u00e3o do caso, pode definir o sucesso ou fracasso do sistema a ser implementado.\n\nA representa\u00e7\u00e3o da base de conhecimento num sistema de CBR consiste em \n\nmodelar os casos e definir o estilo de mem\u00f3ria que organize estes casos. A execu\u00e7\u00e3o \n\ndestas etapas est\u00e3o fortemente ligadas entre si e estas, por sua vez, dependem \n\nfortemente das outras etapas do sistema. As outras etapas do sistema, recupera\u00e7\u00e3o, \n\nadapta\u00e7\u00e3o e aprendizagem devem ser projetadas simultaneamente \u00e0 representa\u00e7\u00e3o.\n\nO conhecimento no CBR \u00e9 representado atrav\u00e9s da mem\u00f3ria de casos. A \n\nrepresenta\u00e7\u00e3o do conhecimento trata de como descrever os casos e, de como \n\norganiz\u00e1-los na mem\u00f3ria. Na representa\u00e7\u00e3o dos casos existem dois componentes \n\nb\u00e1sicos: a descri\u00e7\u00e3o do problema e da solu\u00e7\u00e3o, como um algoritmo. Kolodner \n\n[Kolodner, 1983a] inclui um terceiro componente, o resultado da aplica\u00e7\u00e3o da \n\nsolu\u00e7\u00e3o do problema. Entretanto, o resultado da solu\u00e7\u00e3o \u00e9 descritivo.\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 68\n\nA indexa\u00e7\u00e3o \u00e9 uma quest\u00e3o que pode ser bastante importante conforme a \n\nestrutura e o conte\u00fado da mem\u00f3ria. A mem\u00f3ria deve ser indexada para p ro p o rcio nar \n\numa recupera\u00e7\u00e3o e reutiliza\u00e7\u00e3o eficientes. As caracter\u00edsticas dos casos tomam-se \n\n\u00edndices que caracterizam um evento.\n\nR ecupera\u00e7\u00e3o dos Casos\n\nA partir de um problema a ser resolvido [problema de entrada], a etapa de \n\nrecupera\u00e7\u00e3o parte da identifica\u00e7\u00e3o das caracter\u00edsticas deste problema, ap\u00f3s faz uma \n\nbusca na mem\u00f3ria de casos e, ent\u00e3o seleciona a melhor solu\u00e7\u00e3o, atrav\u00e9s de algoritmos \n\nque estabelecem as similaridades. As subtarefas seguem a seguinte orienta\u00e7\u00e3o: \n\nidentifica\u00e7\u00e3o das caracter\u00edsticas, matches iniciais, pesquisa e sele\u00e7\u00e3o.\n\nA identifica\u00e7\u00e3o das tarefas b\u00e1sicas come\u00e7a num conjunto relevante de \n\nidentifica\u00e7\u00e3o, que orienta a busca da melhor solu\u00e7\u00e3o inicial, atrav\u00e9s de uma \n\nsimilaridade que selecionar\u00e1 a melhor solu\u00e7\u00e3o final. A tarefa de identifica\u00e7\u00e3o \u00e9 \n\nsomente necess\u00e1ria em dom\u00ednios de aplica\u00e7\u00e3o, onde as caracter\u00edsticas n\u00e3o sejam \n\ndiretas ou n\u00e3o estejam claras.\n\nA recupera\u00e7\u00e3o e a etapa em que uma fun\u00e7\u00e3o \u00e9 utilizada para recuperar os \n\ncasos mais similares. Esta fun\u00e7\u00e3o pode utilizar uma m\u00e9trica, ou pode ser orientada \n\npor metas ou restri\u00e7\u00f5es. M\u00e9todos de classifica\u00e7\u00e3o tamb\u00e9m podem ser utilizados. \n\nEsta recupera\u00e7\u00e3o requer que um limiar seja estabelecido, para definir limites de \n\ncasos que podem ser recuperados. Em recupera\u00e7\u00f5es orientadas por restri\u00e7\u00f5es, alguns \n\n\u00edndices podem ser mais ou menos importantes podendo at\u00e9 excluir casos.\n\nA sim ilaridade \u00e9 a primeira quest\u00e3o a ser estudada na etapa de recupera\u00e7\u00e3o. O \n\nque faz um caso ser similar ao outro, depende do dom\u00ednio do conhecimento da \n\naplica\u00e7\u00e3o. Quando a recupera\u00e7\u00e3o \u00e9 do tipo que busca a similaridade diretamente \n\ncomparando os \u00edndices, uma m\u00e9trica de similaridade \u00e9 usada para este c\u00e1lculo. A \n\nSimilaridade \u00e9 a ess\u00eancia do CBR. \u00c9 em raz\u00e3o de haver uma experi\u00eancia similar \u00e0 \n\natual na mem\u00f3ria, que o sistema \u00e9 validado.\n\nO caso escolhido como solu\u00e7\u00e3o para o problema de entrada \u00e9 tratado na \n\nliteratura como B est Match. Normalmente, esta sele\u00e7\u00e3o \u00e9 uma etapa mais elaborada\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 69\n\ndo que a busca pelo conjunto de casos mais similares. A import\u00e2ncia desta etapa \n\nreside no fato de que seu resultado \u00e9 exatamente a sa\u00edda do sistema.\n\nE tap a de A dapta\u00e7\u00e3o\n\nAssim que o best match \u00e9 escolhido, o pr\u00f3ximo passo \u00e9 revisar a solu\u00e7\u00e3o, \n\npara verificar a necessidade de adapta\u00e7\u00e3o em rela\u00e7\u00e3o ao problema de entrada.\n\nA A dapta\u00e7\u00e3o no contexto de CBR, significa modificar um caso para \n\nsolucionar um problema de entrada. A adapta\u00e7\u00e3o avalia as diferen\u00e7as entre o \n\nproblema escolhido e, o problema de entrada. V\u00e1rias t\u00e9cnicas de IA podem ser \n\nconsideradas para desempenhar a fun\u00e7\u00e3o de adapta\u00e7\u00e3o. O estabelecimento de regras \n\nrepresenta uma maneira simples e satisfat\u00f3ria de ajuste.\n\nE ta p a  de Reutiliza\u00e7\u00e3o, Avalia\u00e7\u00e3o e Aprendizagem\n\nR eu tilizar um caso, significa gerar a possibilidade de utiliz\u00e1-lo para resolver \n\no problema de entrada numa outra consulta.\n\nOs objetivos da avalia\u00e7\u00e3o s\u00e3o mensurar a qualidade da solu\u00e7\u00e3o adaptada ao \n\nproblema de entrada, para definir se esta tem condi\u00e7\u00f5es de ser adicionada \u00e0 \n\nmem\u00f3ria. Alguns sistemas sugerem que a solu\u00e7\u00e3o que n\u00e3o foi bem avaliada deve \n\npossuir uma observa\u00e7\u00e3o que permita o sistema agregar este conhecimento, para ap\u00f3s \n\nrepetidas situa\u00e7\u00f5es, ser retirado da mem\u00f3ria.\n\nA aprendizagem  consiste no caso que foi avaliado, revisado e armazenado na \n\nmem\u00f3ria, sem restri\u00e7\u00f5es. A etapa de aprendizagem constitui-se num dos diferenciais \n\ndo CBR em rela\u00e7\u00e3o aos outros sistemas inteligentes, por armazenar na mem\u00f3ria, \n\ncasos que podem ser recuperados em situa\u00e7\u00f5es futuras atrav\u00e9s de algoritmos.\n\nAplica\u00e7\u00f5es\n\nOs problemas mais comuns para o desenvolvimento de aplica\u00e7\u00f5es em CBR \n\ns\u00e3o. interpreta\u00e7\u00e3o, diagn\u00f3stico, an\u00e1lise e elabora\u00e7\u00e3o de projetos, forma\u00e7\u00e3o de pre\u00e7os, \n\ndesenvolvimento de propostas, planejamento, configura\u00e7\u00e3o, scheduling, \n\nmonitoramento, debugging, consertos, an\u00e1lise situacional, classifica\u00e7\u00e3o, instru\u00e7\u00e3o, \n\naprendizagem e controle.\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 70\n\nNa \u00e1rea de finan\u00e7as tem-se ainda poucas aplica\u00e7\u00f5es, dentre elas pode-se citar:\n\n? Previs\u00e3o e Fluxo de caixa [Weeber-Lee et al., 1995];\n\n? An\u00e1lise da Sa\u00fade Financeira de Empresas [Martins et al., 1996],\n\nVantagens e Limita\u00e7\u00f5es de RBC\n\nUma das principais vantagens da t\u00e9cnica RBC, \u00e9 a sua capacidade de explicar \n\nseus resultados. As justificativas s\u00e3o sempre consistentes com as solu\u00e7\u00f5es por serem \n\nas pr\u00f3prias experi\u00eancias, representando mais um aspecto de proximidade ao \n\ncomportamento humano do sistema. Al\u00e9m disso, as justificativas podem avisar sobre \n\nposs\u00edveis riscos que o uso de determinada abordagem pode implicar. Outra vantagem \n\ndo RBC \u00e9 a forma de representa\u00e7\u00e3o do conhecimento que resume-se em escolher o \n\ntipo de estrutura da base de casos.\n\nUma dos principais problema de RBC \u00e9 determinar quais os casos da base s\u00e3o \n\nsimilares \u2019 ao caso corrente. A relev\u00e2ncia das solu\u00e7\u00f5es da base necessitam ser \n\norganizadas na mem\u00f3ria de modo que a descri\u00e7\u00e3o dos problemas de entradas possam \n\nser recuperada eficientemente.\n\nHist\u00f3rico\n\nAs ra\u00edzes do CBR na Intelig\u00eancia Aplicada s\u00e3o oriundas dos trabalhos de\n\nSchank [Schank, 1982], sobre mem\u00f3ria din\u00e2mica e recupera\u00e7\u00e3o de situa\u00e7\u00f5es\n\npassadas. A mem\u00f3ria din\u00e2mica usa uma estrutura hier\u00e1rquica denominada de Pacotes\n\nde Organiza\u00e7\u00e3o de Mem\u00f3ria rMOP - Memory Organization Packtes], que agrupam\n\num conjunto de casos com caracter\u00edsticas similares. Nesta estrutura, os casos s\u00e3o\n\ncaracterizados pelos epis\u00f3dios aos quais est\u00e3o associados e, seus atributos n\u00e3o s\u00e3o\n\napenas nomes pr\u00f3prios, mas atributos das abstra\u00e7\u00f5es que juntas modelam o contexto \ndo caso.\n\nUm MOP \u00e9 caracterizado por ser mut\u00e1vel durante sua utiliza\u00e7\u00e3o e, possuir \n\nregras atrav\u00e9s das quais, os casos possam ser indexados, atrav\u00e9s de nomes, valores e \n\n\u00edndices que diferenciam os casos indexados ao mesmo MOP.\n\nO primeiro sistema de racioc\u00ednio baseado em casos, chamava-se CYRUS. Este \n\nsistema foi desenvolvido por Kolodner [Kolodner, 1983b], na Universidade de Yale,\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 71\n\nno grupo de pesquisa de Schank [Schank, 1982], Cyrus era fundamentado no modelo \n\nde mem\u00f3ria din\u00e2mica e, na teoria de solu\u00e7\u00e3o de problemas e aprendizagem MOP. O \n\nsistema funcionava basicamente, com pergunta-resposta. Sua base de conhecimento \n\nera a agenda de viagens/reuni\u00f5es do Secret\u00e1rio de Estado Norte-Ame ricano Cyrus \n\nVance.\n\nO modelo de mem\u00f3ria de casos desenvolvida para este sistema, foi utilizado \n\nmais tarde para muitos outros sistemas de CBR, como o MEDIATOR, desenvolvido \n\npor Simpson [Simpson, 1985] que tinha por objetivos mediar disputas, num sistema \n\nde planejamento e diagn\u00f3stico, PERSUADER [Sycara,1985] utilizado para mediar \n\nnegocia\u00e7\u00f5es sindicais, CHEF [Hammond,1989] para planejamento, JULIA [Hinrichs,\n\n1992] para desenvolvimento de projetos e CASEY [Katon, 1989] utilizado para \n\ndignosticar a causa e solu\u00e7\u00f5es para problemas card\u00edacos.\n\nPorter [Porter at al, 1986] na Universidade do Texas, desenvolveu um modelo \n\npara resolver problemas de aprendizagem com m\u00e1quinas, atrav\u00e9s de classifica\u00e7\u00e3o de \n\ntarefas. Este sistema, originou o sistema PROTOS [Bareiss, 1988] que utilizava \n\nclassifica\u00e7\u00e3o heur\u00edstica para diagn\u00f3stico e, enfatizava a integra\u00e7\u00e3o geral de dom\u00ednios \n\ndo conhecimento, com conhecimento de casos espec\u00edficos unificados numa estrutura \n\nde representa\u00e7\u00e3o.\n\nA combina\u00e7\u00e3o de casos com estruturas de dom\u00ednios de conhecimento, \n\norientou a cria\u00e7\u00e3o do sistema GREBE [Branting, 1991], que \u00e9 utilizado no dom\u00ednio \n\ndo Direito.\n\nNa Europa os resultados da pesquisa sobre CBR iniciaram-se com os trabalhos \n\nde Richter [Richter, 1993] da Universidade de Kaiserslauten, que desenvolveu o sistema \n\nMOLTKE. Mais tarde ele aprimorou este sistema criando o sistema PATDEX. Lopez \n\ne Plaza [Lopez &amp; Plaza, 1993] desenvolveram um sistema de aprendizagem baseado \n\nem casos para diagn\u00f3stico m\u00e9dico.\n\nEm outros pa\u00edses as pesquisas sobre CBR s\u00e3o pontuais, conforme pode-se \n\nverificar na \u00edndia [Ventakamaran, 1993] e no Jap\u00e3o [Kitano, 1993],\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 72\n\n3.3 Sistemas H\u00edbridos\n\nEnquanto sistemas inteligentes est\u00e3o sendo aplicados com sucesso numa \n\nvariedade de tarefas, certos problemas mais complexos n\u00e3o podem ser resolvidos \n\nusando uma \u00fanica t\u00e9cnica de IA. Cada t\u00e9cnica de IA tem seus pontos fortes e \n\nlimita\u00e7\u00f5es particulares que as tomam mais adequadas para aplica\u00e7\u00f5es particulares e \n\nn\u00e3o para outras. Como mencionou-se previamente, enquanto as RNA s\u00e3o boas para \n\nReconhecimento de Padr\u00f5es, elas n\u00e3o s\u00e3o adequadas para explicar como elas \n\nalcan\u00e7am seus resultados. Sistemas de L\u00f3gica Difusa explicam suas decis\u00f5es mas n\u00e3o \n\npodem automaticamente adquirir regras que usam para tomar decis\u00f5es. Estas \n\nlimita\u00e7\u00f5es tem sido o principal motivo para a cria\u00e7\u00e3o de Sistemas Inteligentes \n\nH\u00edbridos onde duas ou mais t\u00e9cnicas s\u00e3o combinadas para superar as limita\u00e7\u00f5es de \n\ncada t\u00e9cnica individual [Goonatilake &amp; Treleaven, 1995a],\n\nPor exemplo, quando usar um sistema difuso para avaliar um empr\u00e9stimo, um \n\nespecialista em avalia\u00e7\u00f5es de empr\u00e9stimos tem que especificar todas as regras \n\nnecess\u00e1rias para o sistema tomar a decis\u00e3o. As RNA com a sua capacidade de \n\naprendizagem podem ser usadas para aprender estas regras de decis\u00e3o difusas \n\nautomaticamente, ent\u00e3o criando um sistema h\u00edbrido que supera os limites de um \n\nsistema difuso.\n\nA Tabela 3.1 fomece uma avalia\u00e7\u00e3o de algumas t\u00e9cnicas de IA com respeito \n\nas 5 propriedades desej\u00e1veis (aprendizagem, adapta\u00e7\u00e3o, flexibilidade, explica\u00e7\u00e3o e \n\ndescobertas). Como se pode ver na Tabela 3.1 um sistema h\u00edbrido neuro-difuso pode \n\nser visto como,uma combina\u00e7\u00e3o de uma t\u00e9cnica particular (sistema difuso) com baixa \n\ncapacidade em uma propriedade particular (aprendizagem) com uma t\u00e9cnica (RNA) \n\ncom alta capacidade nessa propriedade. Outros exemplos similares de sistemas \n\nh\u00edbrido s\u00e3o os que usam AG para encontrar as fun\u00e7\u00f5es de pertin\u00eancia difusas [Karr, \n\n1995], ou usam RNA como padr\u00f5es de matchers em sistemas especialistas [Tirri, \n\n1995] ou ainda usam AG para encontrar os pesos de uma RNA [Montana, 1995],\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 73\n\nTecnologia Aprendizagem Flexibilidade Adapta\u00e7\u00e3o Explica\u00e7\u00e3o Descobertas\nRedes Neuronais ????? V ??\nAlgoritmos Gen\u00e9ticos S S S\nSistemas DifL sos ? ? S S - / ?\nSistemas Especialistas ? ? V V S S S S ?\nRBC ??? ??\n\nTabela 3.1: Compara\u00e7\u00e3o das T\u00e9cnicas Inteligentes [Goonatilake e Treleaven, 1995a - \nmodificado].\n\nOs Sistemas H\u00edbridos s\u00e3o tamb\u00e9m importantes quando se considera a natureza \n\nvariada das aplica\u00e7\u00f5es. A maioria dos dom\u00ednios complexos tem muitos problemas \n\ncom componentes diferentes, cada um deles podendo requerer processamentos \n\ndiferentes. Por exemplo, se um problema complexo (como o problema de or\u00e7amento \n\ne planejamento) tem tr\u00eas componentes principais - uma tarefa de previs\u00e3o, uma de \n\notimiza\u00e7\u00e3o e outra de racioc\u00ednio em s\u00e9rie - ent\u00e3o uma RNA, um AG e um SE podem \n\nser usados para resolver estes problemas componentes respectivamente. Os diferentes \n\nsistemas inteligentes componentes comunicam seus resultados entre eles para \n\nproduzir o resultado final. Os Sistemas H\u00edbridos deste tipo s\u00e3o referidos por \n\nGoonatilake e Khebbal [Goonatilake &amp; Khebbal, 1995b] como h\u00edbridos por \n\nintecomunica\u00e7\u00e3o.\n\nExistem diversas classifica\u00e7\u00f5es dos sistemas h\u00edbridos. A Tabela 3.2 mostra \n\ncinco diferentes estrat\u00e9gias h\u00edbridas de desenvolvimento que tem sido identificadas \n\nsegundo [Medsker &amp; Bailey, 1992]: modelos independentes, transformacional, \n\nacoplamento livre, acoplamento r\u00edgido e totalmente integrado. Na Tabela 3.3 mostra- \n\nse o esquema de classifica\u00e7\u00e3o proposto por Goonatilake e Khebbal [Goonatilake &amp; \n\nKhebbal, 1995b], onde as tr\u00eas classes, substitui\u00e7\u00e3o de fun\u00e7\u00f5es, intercomunica\u00e7\u00e3o e \n\npolimorfismo, est\u00e3o de acordo com a funcionalidade, arquitetura de processamento e \n\nrequerimentos de comunica\u00e7\u00e3o.\n\nO esquema de Medsker diferencia sistemas sobre uma base de quest\u00f5es de \n\nimplementa\u00e7\u00e3o, enquanto o esquema Goonatilake e Khebbal \u00e9 um esquema mais \n\ngen\u00e9rico que diferencia sistema sobre uma base de funcionalidade [Goonatilake &amp; \n\nKhebbal, 1992], Tabela 3.3.\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 74\n\nModelo\n\nIndependentes\n\nES NN\n\nDescri\u00e7\u00e3o\nS\u00e3o compostos por m\u00f3dulos independentes n\u00e3o \nexistindo nenhuma intera\u00e7\u00e3o entre os m\u00f3dulos. \nN\u00e3o s\u00e3o uma proposta de integra\u00e7\u00e3o \npropriamente, mas eles s\u00e3o prop\u00edcios para \ncomparar o desempenho de duas t\u00e9cnicas para \numa aplica\u00e7\u00e3o especifica.\n\n__________ Exemplo__________\nCompara\u00e7\u00e3o de diferentes \ndiagn\u00f3sticos em consertos de \ncomputador.\n\nTransformacional\n\nES NN\n\nS\u00e3o similares ao modelo independente n\u00e3o \nhavendo uma intera\u00e7\u00e3o um com o outro. A \ndiferen\u00e7a \u00e9 que ele come\u00e7a com um modelo e \ntermina com o outro, um exemplo \u00e9 come\u00e7ar \ncom um sistema especialista e em seguida partir \npara uma rede neuronal ou vice versa.\n\nSistemas de ajuda na tomada de \ndecis\u00e3o, onde por exemplo uma \nrede neuronal \u00e9 usada para \nidentificar tend\u00eancias e rela\u00e7\u00f5es, \ne em seguida os resultados s\u00e3o \nusados em um sistema \nespecialista para assistir a \ntomada de decis\u00e3o.\n\nAcoplamento Livre \n\n~\u00caS ] - i = 4  NN\n\n\u00c9 a primeira forma verdadeira de integra\u00e7\u00e3o. O \nproblema \u00e9 decomposto em sistemas separados \nque se comunicam via arquivos de dados. Entre \nas varia\u00e7\u00f5es dos modelos de acoplamento livre \nest\u00e3o pr\u00e9-processadores, pos-processadores, \ncoprocessadores, e interface de usu\u00e1rios.\n\nModelo para prever a utiliza\u00e7\u00e3o \nde for\u00e7a de trabalho. Usa-se \numa rede neuronal que prediz a \ncarga de trabalho, atrav\u00e9s dos \ndados. A previs\u00e3o \u00e9 repassada \npara um arquivo de dados, e \nent\u00e3o um sistema especialista \nusa a carga de trabalho para \ndeterminar a utiliza\u00e7\u00e3o da forca \nde trabalho.\n\nR\u00edgido\n\nES 1\u2014 I NN\n\nTotalmente integrado\n\nAssemelha-se ao anterior, onde a diferen\u00e7a recai \nem como os dados s\u00e3o transferidos de um \nsistema para outro. Neste caso com dados \nresidentes na mem\u00f3ria. Logo, s\u00e3o mais \nadequados para problemas embutidos.\n\nES NN\n\nEstes modelos compartilham estruturas de dados \ne representa\u00e7\u00e3o do conhecimento. A \ncomunica\u00e7\u00e3o entre os diferentes componentes \u00e9 \ncompleta via a natureza dual das estruturas. O \nracioc\u00ednio \u00e9 feito por coopera\u00e7\u00e3o ou por \ncomponentes designados como controladores. \nExiste uma grande variedade de sistemas deste \nl\u00edfio._________________\n\nUsados como modelos de \ncoopera\u00e7\u00e3o, s\u00e3o aplicados para \nmonitoramento e controle, \ntomada de decis\u00e3o, etc..\n\nSistemas para identifica\u00e7\u00e3o de \nobjetos, uma rede neuronal \nrecebe os dados de sensores e \ndados do ambiente do sistema \nespecialista.\n\nTabela 3.2: Modelos p a ra  in te g ra r sistemas inteligentes [M edsker &amp; Bailey, 1992].\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 75\n\nClasse Descri\u00e7\u00e3o Exemplo \u2022 - ,\nSubstituindo Fun\u00e7\u00f5es\n\n/ \u00e1 i l S I i v\nMOS\n\nRefere-se a composi\u00e7\u00e3o funcional de \numa t\u00e9cnica inteligente \u00fanica. A \nfun\u00e7\u00e3o principal de uma dada t\u00e9cnica \n\u00e9 substitu\u00edda por uma outra t\u00e9cnica de \nprocesso inteligente.\n\nAjuste de pesos em uma rede \nneuronal via algoritmos gen\u00e9ticos \n[Montana, 1995], ajuste das fun\u00e7\u00f5es \nde pertin\u00eancia em sistema difuso via \nalgoritmo gen\u00e9tico rKarr. 19951.\n\nIntercomunica\u00e7\u00e3o\n\nc g \u00ab\nM\u00f3dulos de processo inteligente \nindependentes que permutam \ninforma\u00e7\u00e3o. Se um problema pode ser \nsubdividido em varias subtarefas \ndistintas, ent\u00e3o t\u00e9cnicas \nindependentes podem ser aplicada \npara resolver cada parte.\n\nSe um problema inclui \nreconhecimento de padr\u00f5es, \nracioc\u00ednio serial e otimiza\u00e7\u00e3o, ent\u00e3o \numa rede neuronal, um sistema \nespecialista e um algoritmo gen\u00e9tico \npodem executar estas respectivas \nsubtarefas.\n\nPolimorfismo a\n\n......\n\nS\u00e3o sistemas que usam uma \narquitetura de processamento \u00fanica \npara realizar a funcionalidade de \nt\u00e9cnicas de processos inteligentes \ndiferentes.\n\nUm exemplo classe polimorfismo s\u00e3o \nredes neuronais que funcionam como \nse elas estivessem fazendo procura \ngen\u00e9tica.\n\nTabela 3.3: Tr\u00eas classes h\u00edbridas proposta [Goonatilake &amp; Khebbal, 1995b].\n\nOs sistemas h\u00edbridos inteligentes n\u00e3o inclui em somente a combina\u00e7\u00e3o de \n\ndiferentes t\u00e9cnicas inteligentes mas tambem a integra\u00e7\u00e3o de t\u00e9cnicas inteligentes com \n\nsistemas computacionais convencionais tal como a base de dados [Khebbal &amp; \n\nShamhong, 1995], Para sistemas inteligentes aumentarem a capacidade de decis\u00f5es \n\norganizacionais devem ser capazes de extrair e usar informa\u00e7\u00f5es de origens muito \n\nvariadas. Al\u00e9m disto, as decis\u00f5es ou resultados produzidos por sistemas inteligentes \n\ndeveriam ser propagados para aplica\u00e7\u00f5es existentes ou outros sistemas al\u00e9m do \n\nprocessamento. Por estas raz\u00f5es \u00e9 vital que existam m\u00e9todos e protocolos para \n\nintegrar sistemas inteligentes com outros sistemas computacionais convencionais. Um \n\ndestes m\u00e9todos \u00e9 a programa\u00e7\u00e3o orientada a objetos [Wiener &amp; Pinson, 1988] que \u00e9 \n\numa metodologia de engenharia de software que pode fornecer a \u201ccola\u201d para unir \n\ndiferentes t\u00e9cnicas de processamento. Isto forma um modelo natural para os sistemas \n\ninteligentes h\u00edbridos pois t\u00e9cnicas individuais podem ser definidas como objetos que \n\ninteragem enviando um conjunto comum de mensagens [Khebbal &amp; Shamhong,\n1995],\n\nSistemas h\u00edbridos inteligentes s\u00e3o uma classe muito poderosa de m\u00e9todos \n\ncomputacionais que podem fornecer solu\u00e7\u00f5es para problemas que n\u00e3o podem ser \n\nsolucionados com uma \u00fanica t\u00e9cnica. Por\u00e9m, como os desenvolvimentos e aplica\u00e7\u00f5es\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 76\n\ns\u00e3o ainda relativamente novos, n\u00e3o existe a mesma disponibilidade de ferramentas e \n\nambientes de desenvolvimento como nas t\u00e9cnicas estabelecidas como RNA e SE.\n\nUm problema associado com o desenvolvimento de sistemas h\u00edbridos \n\ninteligentes \u00e9 educacional . Para desenvolver sistemas com sucesso, necessita-se \n\nestar bem informado dos detalhes de diversas t\u00e9cnicas inteligentes, diferente de \n\nquando se trabalha com uma s\u00f3 t\u00e9cnica. E hoje existem poucos pesquisadores que \n\nt\u00eam experi\u00eancia e treinamento suficiente no desenvolvimento e aplica\u00e7\u00f5es de mais de \n\numa t\u00e9cnica. Para obter benef\u00edcios de sistemas h\u00edbridos deve-se ter uma vis\u00e3o \n\npragm\u00e1tica de v\u00e1rias t\u00e9cnicas.\n\nJ\u00e1 existem muitas aplica\u00e7\u00f5es usando sistemas inteligentes h\u00edbridos, como:\n\n\u2022  Diagn\u00f3stico M\u00e9dico [Gallant, 1988]\n\n\u2022 Pr\u00e9-clasifica\u00e7\u00e3o de amostras de DNA em estudos do HTV [Benachenhou et al., \n1990]\n\n\u2022 Controle de Qualidade [Rosen &amp; Silverman, 1992]\n\n\u2022 Diagn\u00f3stico de falhas e realiza\u00e7\u00e3o de controle em sistemas de telecomunica\u00e7\u00f5es \n\n[Senjen et al., 1993]\n\n\u2022 Previs\u00e3o do pre\u00e7o de a\u00e7\u00f5es [Yonn et al., 1994]\n\n\u2022 Controle para sistemas ca\u00f3ticos adaptativos (sat\u00e9lite) [Dracopoulos &amp; Jones, 1995]\n\n\u2022 Predi\u00e7\u00e3o da tend\u00eancia global de curto prazo do mercado de a\u00e7\u00f5es [Neto, 1995]\n\n\u2022 Controle (adaptativo) de ve\u00edculo [Spooner &amp; Passino, 1996]\n\n\u2022 Diagn\u00f3stico e solu\u00e7\u00e3o de problemas financeiros de pequenas empresas [Pacheco,\n1996]\n\n3.4 Conclus\u00f5es\n\nEm poucos anos os sistemas inteligentes cresceram muito, representando um \n\npapel importante na solu\u00e7\u00e3o de muitos problemas. Agora, com o desenvolvimento de \n\nt\u00e9cnicas inteligentes h\u00edbridas, problemas mais complexos poder\u00e3o ser solucionados.\n\nEstas t\u00e9cnicas fornecem uma alternativa para os m\u00e9todos de an\u00e1lise de dados \n\ncomumente usados como an\u00e1lise de regress\u00e3o e para m\u00e9todos de busca como \n\nprograma\u00e7\u00e3o linear. Al\u00e9m da capacidade de precis\u00e3o algumas t\u00e9cnicas inteligentes\n\n\n\nCap\u00edtulo 3 - T\u00e9cnicas de Intelig\u00eancia Artificial 77\n\nt\u00eam a capacidade de produzir modelos de decis\u00e3o que s\u00e3o facilmente entendidas pelo \n\nusu\u00e1rio, outras tem a capacidade de aprendizagem e generaliza\u00e7\u00e3o, outras mecanismo \n\nde racioc\u00ednio semelhante ao do homem, conhecimento amb\u00edguo e impreciso.\n\nUma tend\u00eancia emergente \u00e9 embutir as t\u00e9cnicas inteligentes em outra \u00e1reas de \n\naplica\u00e7\u00f5es. As Redes Neuronais est\u00e3o agora sendo incorporadas em ferramentas de \n\nprevis\u00e3o sobre dados financeiros e sistemas difusos em produtos de recupera\u00e7\u00e3o de \n\ndados.\n\nUma \u00e1rea significante de crescimento prov\u00e1vel \u00e9 o uso de sistemas \n\ninteligentes h\u00edbridos. A maioria dos problemas aparentemente intrat\u00e1veis se \n\nbeneficiar\u00e3o do uso das m\u00faltiplas t\u00e9cnicas inteligentes. Uma das \u00e1reas que certamente \n\nser\u00e1 beneficiada ser\u00e1 a previs\u00e3o de s\u00e9ries temporais, como a previs\u00e3o de mercado \n\nfuturo.\n\nPara problemas de classifica\u00e7\u00e3o (como diagn\u00f3stico de empresas) uma das \n\nt\u00e9cnicas mais usadas hoje na \u00e1rea de IA s\u00e3o as redes neuronais. Por\u00e9m, como existem \n\nv\u00e1rias arquiteturas distintas, dedicar-se-\u00e1 o pr\u00f3ximo cap\u00edtulo \u00e0 an\u00e1lise de algumas \n\narquiteturas, buscando as que mais se adaptam ao problema de diagn\u00f3stico.\n\n\n\n4. REDES NEURONAIS \nARTIFICIAIS\n\n4.1 Introdu\u00e7\u00e3o\n\nComo foi visto no cap\u00edtulo anterior as redes neuronais artificiais (RNAs) \n\nrepresentam uma tecnologia emergente enraizada em muitas disciplinas. Elas s\u00e3o \n\ndotadas de alguns atributos como: aproximador universal (mapeamento de \n\nentrada/sa\u00edda), classificador, habilidade de aprender do meio e adaptar-se ao meio, \n\nhabilidade de trabalhar dados com ru\u00eddo.\n\nSendo que se tem um problema de classifica\u00e7\u00e3o (diagn\u00f3stico de empresas) e \n\nsabendo das capacidades das RNA como classificadores, este cap\u00edtulo trar\u00e1 um \n\nestudo um pouco mais profundo sobre as redes neuronais (arquiteturas).\n\nEnt\u00e3o, este cap\u00edtulo tem como um dos objetivos explicar e ilustrar os \n\nprinc\u00edpios b\u00e1sicos de algumas redes neuronais, tal como, Kohonen, LVQ, Hopf\u00edeld, \n\nARTs, MLPs e RBF.\n\nAinda considerando o problema de diagn\u00f3stico, tamb\u00e9m estudar-se-\u00e1 um \n\nsistema h\u00edbrido, FAN (Free Association Neuron). O FAN \u00e9 um sistema h\u00edbrido que \n\nest\u00e1 sendo desenvolvido por Roberto Raittz, em seu mestrado neste Programa de P\u00f3s- \n\nGradua\u00e7\u00e3o em Engenharia de Produ\u00e7\u00e3o.\n\n4.2 Algumas Caracter\u00edsticas das RNAs\n\n4.2.1 Introdu\u00e7\u00e3o\n\nAs Redes neuronais artificiais (RNAs) s\u00e3o sistemas computacionais, de \n\nimplementa\u00e7\u00e3o em hardware ou software, que imitam as habilidades computacionais \n\ndo sistema nervoso biol\u00f3gico, usando neur\u00f4nios (tamb\u00e9m chamados de elementos de \n\nprocessamento ou n\u00f3s) artificiais interconectados em arquiteturas espec\u00edficas.\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 79\n\nOs neur\u00f4nios artificiais s\u00e3o emula\u00e7\u00f5es simples dos neur\u00f4nios biol\u00f3gicos. Eles \n\nrecebem informa\u00e7\u00f5es de sensores ou de outros neur\u00f4nios artificiais, produzindo \n\nopera\u00e7\u00f5es simples sobre estes dados, e passam os resultados para outros neur\u00f4nios. \n\nAs redes funcionam atrav\u00e9s de seus neur\u00f4nios, que processam seus dados usando \n\nparalelismo l\u00f3gico combinado com opera\u00e7\u00f5es seriais (quando a informa\u00e7\u00e3o de uma \n\ncamada \u00e9 transferida para neur\u00f4nios de outra camada). Existem tr\u00eas caracter\u00edsticas \n\nprincipais que descrevem uma rede neuronal, e que contribuem para sua habilidade \n\nfuncional: estrutura (arquitetura), din\u00e2mica e aprendizado.\n\nAs RNAs s\u00e3o tamb\u00e9m chamadas de modelos conexionistas devido \u00e0 \n\nimport\u00e2ncia das conex\u00f5es entre os neur\u00f4nios. Os pesos das conex\u00f5es s\u00e3o a \u201cmem\u00f3ria\u201d \ndo sistema.\n\nEsta se\u00e7\u00e3o descreve um hist\u00f3rico sobre as principais pesquisas sobre RNAs. \n\nIsto \u00e9 seguido pela apresenta\u00e7\u00e3o dos principais tipos de arquiteturas, algoritmos de \n\naprendizagem e \u00e1reas de atua\u00e7\u00e3o. Finalmente, uma taxinomia sobre as RNAs.\n\n4.2.2 Hist\u00f3rico sobre as pesquisas sobre as RNAs\n\nO interesse em redes neuronais data do in\u00edcio da d\u00e9cada de 1940, com o \n\ntrabalho pioneiro de McCulloch e Pitts [McCulloch &amp; Pitts, 1943], Warren \n\nMcCulloch foi um psiquiatra e neuroanatomista que estudou por 20 anos a \n\nrepresenta\u00e7\u00e3o de um evento no sistema nervoso. Walter Pitts foi um prod\u00edgio \n\nmatem\u00e1tico, que juntou-se a McCulloch em 1942 e em 1943 escreveram um artigo \n\nque se tomou cl\u00e1ssico, e recebeu muita aten\u00e7\u00e3o da comunidade que estudava o \n\nmodelo do neur\u00f4nio. Um grupo da Universidade de Chicago, sob a lideran\u00e7a de \n\nRashevsky, vinha estudando o neur\u00f4nio pelo menos 5 anos antes da publica\u00e7\u00e3o do \nartigo [Haykin, 1994],\n\nOutro resultado foi publicado por Hebb [Hebb, 1949], que foi um dos \n\nprimeiros a sugerir um processo plaus\u00edvel para rede neuronal aprender. At\u00e9 hoje, \n\nmuitos dos modelos de aprendizagem usados por pesquisadores s\u00e3o de alguma forma \n\nbaseados na aprendizagem Hebbiana.\n\nProvavelmente a primeira simula\u00e7\u00e3o computacional de RNAs foi relatada por \n\nRochester e seus colegas (1956) na confer\u00eancia de ver\u00e3o de Dartmouth onde\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 80\n\nreconheceram como data do in\u00edcio oficial da Intelig\u00eancia Artificial. Conduzindo \n\nsimula\u00e7\u00f5es do modelo de Hebb, este grupo descobriu que algumas mudan\u00e7as eram \n\nessenciais para que o modelo exibisse certas propriedades preditas pelo modelo. Eles \n\ngeneralizaram o modelo, incluindo inibi\u00e7\u00e3o, de modo que c\u00e9lulas ativas pudessem \n\ninibir outros. Eles tamb\u00e9m introduziram normaliza\u00e7\u00e3o dos pesos para prevenir o \n\ncrescimento ilimitado de alguns pesos. Embora este trabalho n\u00e3o fosse muito \n\nconclusivo, foi importante como precursor de muitos estudos de simula\u00e7\u00e3o.\n\nUmas das realiza\u00e7\u00f5es mais sensacionais da pesquisa neste per\u00edodo foi o \n\ntrabalho de Rosenblatt sobre os perceptrons [Rosenblatt, 1958], Rosenblatt era um \n\npsic\u00f3logo que acreditou que o c\u00e9rebro funcionava como um associador de \n\naprendizagem que classifica em resposta a est\u00edmulos. Ele desenvolveu diversas \n\nvaria\u00e7\u00f5es de redes que ele chamou de perceptrons e estudou formas diferentes de \n\naprendizagem. A rede b\u00e1sica do perceptron era uma unidade l\u00f3gica limiar composta \n\nde tr\u00eas camadas: uma camada de entrada (foto) sens\u00f3ria que foi randomicamente \n\nligada a uma camada de associa\u00e7\u00e3o que foi, por sua vez conectada a uma camada de \n\nsa\u00edda ou camada de classifica\u00e7\u00e3o. Se as entradas cumulativas da camada sens\u00f3ria \n\nexcederem algum limiar, aquela unidade \u00e9 ativada e passa um impulso \u00e0 camada de \n\nresposta. A camada de resposta ent\u00e3o produzir uma sa\u00edda de +1 (classe 1) se a entrada \n\ncumulativa exceder algum limiar e, uma sa\u00edda de 0 se n\u00e3o (n\u00e3o classe 1). Mas, \u00e9 \n\nimportante notar aqui que muitas das id\u00e9ias e conceitos estudados por Rosenblatt s\u00e3o \n\nainda objetos de pesquisas hoje.\n\nBemard Widrow foi um dos primeiros pesquisadores a desenvolver aplica\u00e7\u00f5es \n\npr\u00e1ticas de RNAs. Ele desenvolveu um modelo de neur\u00f4nio simples semelhante ao \n\nPerceptron chamado ADALINE (ADAptive Linear Neuron), e redes de ADALINEs \n\nque ele chamou MADALINE (M\u00faltiple ADALINEs). Estes tipos de unidades est\u00e3o \n\nem uso ainda hoje para redu\u00e7\u00e3o de eco para circuitos telef\u00f4nicos de longa dist\u00e2ncia e \n\npara redu\u00e7\u00e3o de ru\u00eddos em MODEMS de alta velocidade. Widrow e seu colegas s\u00e3o \n\ntamb\u00e9m respons\u00e1veis pelo desenvolvimento de um procedimento de aprendizagem \n\nsupervisionado conhecido como m\u00ednimos quadrados (Least Mean Square -LMS) ou \n\nm\u00e9todo de aprendizagem de Widrow-Hoff [Widrow &amp; Hoff, 1960] usado para \n\naprender associa\u00e7\u00f5es de pares de entrada-sa\u00edda. O LMS foi importante n\u00e3o s\u00f3 pelo\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 81\n\nm\u00e9todo em si, mas tamb\u00e9m porque serviu como um precursor do m\u00e9todo de \n\naprendizagem backpropagation usado nas redes multicamadas feedforward. A \n\nprincipal diferen\u00e7a entre o \u201cperceptron\u201d, apresentado por Rosemblatt, e o ADALINE \n\nde Widrow situa-se no procedimento de treinamento. Ap\u00f3s a apresenta\u00e7\u00e3o do \n\nperceptron em 1960, acreditava-se que redes neuronais (perceptrons) poderiam fazer \n\nqualquer coisa, ou seja, resolver qualquer problema.\n\nAs possibilidades de LA introduzido pelos perceptrons produziram uma grande \n\nquantidade de pesquisas durante os anos sessenta. Ent\u00e3o, em dire\u00e7\u00e3o ao fim da \n\nd\u00e9cada, Minsky e Papert publicaram seu tratado cr\u00edtico sobre Perceptrons [Minsky &amp; \n\nPapert, 1969], Este livro era uma an\u00e1lise matem\u00e1tica elegante das capacidades \n\ncomputationais e limita\u00e7\u00f5es dos perceptrons. Ele essencialmente mostrou quais \n\nfun\u00e7\u00f5es l\u00f3gicas simples o perceptrons podia e n\u00e3o podia calcular\n\nAp\u00f3s a publica\u00e7\u00e3o do livro de Minsky e Papert, das limita\u00e7\u00f5es quanto a \n\ncomputadores e esta\u00e7\u00f5es de trabalhos para conduzir experimentos, e tamb\u00e9m, por n\u00e3o \n\nhaver suporte financeiro para conduzir projetos nesta \u00e1rea, as pesquisas com redes \n\nneuronais ficaram esquecidas pelo menos at\u00e9 o in\u00edcio de 1980. S\u00f3 alguns \n\npesquisadores valentes continuaram seus trabalhos, James Anderson, Teuvo Kohonen, \n\nStephen Grossberg, Bemard Widrow, Chr. Von der Malsburg, Amari e alguns poucos \n\noutros.\n\nDurante o in\u00edcio dos anos setenta, um n\u00famero de investiga\u00e7\u00f5es foram \n\nconduzidas sobre as mem\u00f3rias associativas por pesquisadores tal como Kohonen \n\n[Kohonen, 1972], Anderson [Anderson, 1972] e outros. Os modelos usados nestes \n\ntrabalhos foram os associadores de camada linear \u00fanica. Eles usaram uma forma de \n\naprendizagem Hebbiana ou Correlativa. O trabalho destes pesquisadores propiciaram \n\nmuitos insight sobre comportamento de associadores lineares e fen\u00f4menos \n\nrelacionados tal como o \u201ccrosstalk\u201d que est\u00e1 relacionado \u00e0 armazenagem de muitos \n\npadr\u00f5es n\u00e3o ortogonais.\n\nJames Anderson da Universidade Brown e seus companheiros de trabalho \n\ntamb\u00e9m desenvolveram modelos de mem\u00f3rias associativas endere\u00e7ado por conte\u00fado \n\nbaseado na aprendizagem de Hebb [Patterson, 1995], Os padr\u00f5es eram armazenados \n\ncomo superimposition (a soma) de matrizes e recuperados quando entradas\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 82\n\nsuficientemente semelhantes fossem apresentadas para a rede. Anderson foi tamb\u00e9m \n\nrespons\u00e1vel por uma extens\u00e3o do modelo associador linear chamado de Brain-State- \n\nin-a-Box (BSB). Neste modelo, a sa\u00edda \u00e9 truncada para prevenir crescimento ilimitaHn \n\ncomo o modelo iterativo para achar uma solu\u00e7\u00e3o. Os valores truncados definem um \n\nhipercubo a qual a sa\u00edda est\u00e1 contida nele.\n\nStephen Grossberg, fundador e diretor do Centro para Sistemas Adaptivos e \n\num professor de matem\u00e1tica, psicologia, e engenharia biom\u00e9dica na universidade de \n\nBoston, foi um pesquisador ativo em processamento de informa\u00e7\u00e3o psicol\u00f3gica e \n\nbiol\u00f3gica e no uso de redes neuronais artificiais para modelar a percep\u00e7\u00e3o e cogni\u00e7\u00e3o \n\nhumana desde o in\u00edcio dos anos sessenta. O trabalho inicial de Grossberg focalizou-se \n\nsobre sistemas de aprendizagem cooperativo-competitivo. O trabalho posterior feito \n\npor Grossberg e seus colegas focalizou sobre propriedades din\u00e2micas matem\u00e1ticas Ha<s \n\nRNAs. Este trabalho levou a um importante teorema sobre a converg\u00eancia global das \n\nredes din\u00e2micas. Grossberg \u00e9 talvez mais conhecido pelo alto sucesso das redes ARTs \n\n(Adaptive Resonance Theory), que ele inventou. Ele e seus colegas, particularmente \n\nGail Carpenter, estudaram, generalizaram e caracterizaram as redes ART \n\nextensivamente [Carpenter &amp; Grossberg, 1987],\n\nEm 1982, John Hopfleld apresentou um artigo na Academia Nacional de \n\nCi\u00eancia descrevendo como uma an\u00e1lise de pontos est\u00e1veis poderia ser realizada por \n\nredes recorrentes sim\u00e9tricas. A an\u00e1lise foi baseada no uso de uma fun\u00e7\u00e3o de energia \n\nde Lyapunov para equa\u00e7\u00f5es n\u00e3o lineares. Ele mostrou que a fun\u00e7\u00e3o energia dissipava \n\ne convergia para um m\u00ednimo e permanecia ali. Assim, padr\u00f5es s\u00e3o armazenados na \n\nmem\u00f3ria como atratores dinamicamente est\u00e1veis. As redes, que agora s\u00e3o chamadas \n\nHopfleld, podem ser usadas como redes de mem\u00f3ria associativa ou para encontrar \n\nsolu\u00e7\u00f5es de problemas com restri\u00e7\u00f5es tal como \u201co problema do cacheiro viajante\u201d. \n\nHopfleld, que foi um ganhador de um pr\u00eamio nobel em f\u00edsica, recebeu o cr\u00e9dito por \n\nressuscitar o interesse das pesquisas em redes neuronais no in\u00edcio dos anos oitenta.\n\nUm dos desenvolvimentos mais importantes das recentes pesquisas em RNAs \n\nfoi o descobrimento de um algoritmo de aprendizagem para ajustar os pesos em redes \n\nmulti camadas feedforward (tamb\u00e9m referidas como perceptrons multi camadas). O \n\nalgoritmo \u00e9 conhecido como backpropaga\u00edion j\u00e1  que os pesos s\u00e3o ajustados da\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 83\n\ncamada de sa\u00edda para tr\u00e1s camada-a-camada para reduzir os erros de sa\u00edda. O m\u00e9todo \n\nfoi descoberto em diferentes tempos por Werbos [Werbos, 1974], Parker [Parker, \n\n1985], Rumelhart, Hinton e Williams do Grupo de Processamento Distribu\u00eddo \n\nParalelo [Rumelhart et al., 1986], Este desenvolvimento abriu caminho para \n\nelabora\u00e7\u00e3o de redes neuronais mais gen\u00e9ricas superando as limita\u00e7\u00f5es dos \n\nperceptrons de camada simples. Tais redes s\u00e3o capazes de resolver problemas n\u00e3o \n\nlineares tal como a fun\u00e7\u00e3o l\u00f3gica XOR.\n\nO pesquisador japon\u00eas Kunihiko Fukushima \u00e9 o fundador das redes Cognitron \n\ne Neocognitron [Fukushima, 1988; Fukushima et al., 1983], A rede mais recente, o \n\nNeocognitron, \u00e9 uma rede feedforw ard hier\u00e1rquica que aprende atrav\u00e9s de m\u00e9todos \n\nsupervisionados ou n\u00e3o. O Fukushima e seus colegas publicaram resultados \n\nmostrando que o neocognitron \u00e9 capaz de reconhecer caracteres manuscritos, \n\nindependente de escala, posi\u00e7\u00e3o e alguma deforma\u00e7\u00e3o nos caracteres. Um dos \n\naspectos raros dos Neocognitrons \u00e9 a conectividade das camadas da rede. As camadas \n\ns\u00e3o conectadas de tal modo que caracter\u00edsticas de baixo-n\u00edvel s\u00e3o reconhecidas e \n\nsucessivamente combinadas em uma forma completa coerente para identifica\u00e7\u00e3o de \n\nobjetos.\n\nEm 1988, Broomhead e Lowe descreveram um procedimento para o projeto \n\nde uma rede neuronal (feedforward) usando fun\u00e7\u00f5es de base radial, conhecida na \n\nliteratura como \u201cradial basis function\u201d (RBF), que proporcionou um perceptron \n\nalternativo [Broomhead &amp; Lowe, 1988], Bashkirov, Braverman e Muchnick em 1964 \n\ndesenvolveram um m\u00e9todo de fun\u00e7\u00f5es potenciais. A id\u00e9ia b\u00e1sica da RBF lembra \n\nbastante este m\u00e9todo [Haykin, 1994], Um trabalho suplementar apareceu em 1990 \n\ncom Poggio e Girosi, que enriqueceram a teoria de redes RBF aplicando a teoria da \n\nregulariza\u00e7\u00e3o de Tikhonov [Poggio &amp; Girosi, 1990],\n\nOs acontecimentos precedentes s\u00e3o resumidos na Figura 4.1.\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 84\n\nORIGENS INTERESSE PAUSA RENASCEN\u00c7A MATURIDADE \nINICIAL\n\n1940 1950 I960 1970 1980 1990\n\nConceitos iniciais e Redu\u00e7\u00e3o das Pesquisas caladas Interesse Renovado \nTeoria vaga pesquisas Progresso s\u00f3lido Produtos Comerciais\n\nFinanciamento de \npesquisas\n\nFigura 4.1: Eventos significantes no desenvolvimento de Redes Neuronais \u00cdPatterson, \n1995].\n\n4.2.3 Arquiteturas\n\nAs RNAs podem ser vistas como grafos direcionados com pesos na qual os \n\nneur\u00f4nios artificiais s\u00e3o os n\u00f3s e as extremidades (com pesos) s\u00e3o as conex\u00f5es entre \n\nneur\u00f4nios de entrada e de sa\u00edda.\n\nBaseado nos padr\u00f5es de conex\u00f5es (arquitetura), as RNAs podem ser agrupadas \n\nem duas categorias:\n\n\u2022 redes fe e d  forward, nas quais os grafos n\u00e3o t\u00eam loop (canto superior esquerdo da \n\nFigura 4.1), e\n\n\u2022 redes recorrentes (ou feedback) , nas quais os loops ocorrem devido as conex\u00f5es \n\nfeedback (canto superior direito da Figura 4.1).\n\nNa fam\u00edlia mais comum de redes feed-forward, redes Multicamadas, os \n\nneur\u00f4nios s\u00e3o organizados nas camadas que t\u00eam conex\u00f5es unilaterais entre eles. A \n\nFigura 4.2 tamb\u00e9m mostra redes t\u00edpicas para cada categoria.\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 85\n\nRedes Neuronais Artificiais\n\nRedes Feed-forward Redes Recorrentes/feedback\n\nPerceptron Redes Fun\u00e7\u00e3o Redes SOM Rede Modelos\nSimples e de Base Radial Competitivas Kohonen Hopfleld ARTs\n\nMulticamadas (RBF)\n\nF igura 4.2:Uma taxinomia de arq u ite tu ras de redes feed-forw ard e recorrentes/feedback.\n\n4.2.4 Aprendizagem\n\nA habilidade para aprender \u00e9 uma caracter\u00edstica fundamental da intelig\u00eancia.\n\nEmbora uma defini\u00e7\u00e3o precisa de aprendizagem seja dif\u00edcil de formular, um processo \n\nde aprendizagem no contexto de RNAs pode ser visto como um problema da \n\narquitetura da rede e dos pesos entre as conex\u00f5es adaptarem-se de modo que a rede \n\npossa eficientemente realizar uma tarefa espec\u00edfica.\n\nPara entender o processo de aprendizagem, primeiro se deve ter um modelo do \n\nmeio no qual uma rede neuronal opera, isto \u00e9, deve-se conhecer quais informa\u00e7\u00f5es \n\nest\u00e3o dispon\u00edveis para a rede. Este modelo \u00e9 referido na literatura como um \n\nparadigma da aprendizagem [Haykin, 1994], Segundo, deve-se entender como os \n\npesos das redes s\u00e3o adaptados, isto \u00e9, que regras de aprendizagem que governam o \n\nprocesso de adapta\u00e7\u00e3o. Um algoritmo de aprendizagem refere-se ao procedimento no \n\nqual regras de aprendizagem s\u00e3o usadas para ajustar os pesos.\n\nExistem tr\u00eas principais paradigmas de aprendizagem: supervisionada, n\u00e3o \n\nsupervisionada e h\u00edbrida:\n\n\u2022 Na aprendizagem Supervisionada, ou aprendizagem com \u201cprofessor\u201d, o ajuste \n\nocorre quando o sistema diretamente compara a sa\u00edda y  da rede com a resposta \n\ncorreta conhecida d. Os pesos s\u00e3o ajustados de modo a permitir que a rede produza\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 86\n\nsa\u00eddas mais pr\u00f3ximas da resposta desejada (conhecida). A aprendizagem com \n\nrefor\u00e7o \u00e9 uma variante da aprendizagem supervisionada, onde o sistema conhece \n\nsomente se a sa\u00edda da rede \u00e9 correta ou n\u00e3o, mas n\u00e3o conhece a sa\u00edda correta. \n\nNeste caso, a rede tenta aprender atrav\u00e9s de tentativa e erro com objetivo de \n\nmaximizar um \u00edndice de performance chamado de sinal de refor\u00e7o.\n\n\u2022 Na aprendizagem N\u00e3o Supervisionada, ou aprendizagem \"sem professor\u201d, a rede \n\nn\u00e3o requer uma resposta correta associada com cada padr\u00e3o de entrada no conjunto \n\ndos dados de treinamento. A rede explora a estrutura impl\u00edcita ou a correla\u00e7\u00e3o \n\nentre os padr\u00f5es de entradas nos dados, e organiza estes padr\u00f5es em categorias em \n\nfun\u00e7\u00e3o desta correla\u00e7\u00e3o.\n\n\u2022  A aprendizagem H\u00edbrida combina aprendizagem supervisionada e n\u00e3o \n\nsupervisionada. Partes dos pesos s\u00e3o usualmente determinados atrav\u00e9s de \n\naprendizagem supervisionadas, enquanto outros s\u00e3o obtidos atrav\u00e9s da \n\naprendizagem n\u00e3o supervisionada.\n\nA teoria da aprendizagem deve levar em considera\u00e7\u00e3o tr\u00eas quest\u00f5es \n\nfundamentais e pr\u00e1ticas associadas com a aprendizagem atrav\u00e9s das amostras: \n\ncapacidade, complexidade da amostra e complexidade computacional:\n\n\u2022 Capacidade, concerne em como muitos padr\u00f5es podem ser armazenados, e quais \n\nfun\u00e7\u00f5es e limites de decis\u00f5es uma rede pode formar.\n\n\u2022 Complexidade da amostra, determina qual o n\u00famero de padr\u00f5es de treinamento \n\ns\u00e3o necess\u00e1rios para treinar uma rede de modo a garantir uma generaliza\u00e7\u00e3o \n\nv\u00e1lida.\n\n\u2022 Complexidade Computacional, refere-se ao tempo requerido para um algoritmo de \n\naprendizagem estimar uma solu\u00e7\u00e3o dos padr\u00f5es de treinamento. Muitos algoritmos \n\nde aprendizagem tem alta complexidade computacional. Designar algoritmos \n\neficientes para a aprendizagem de uma rede neuronal ainda \u00e9 um t\u00f3pico ativo de \n\nmuitas pesquisas.\n\nExistem quatro tipos b\u00e1sicos de regras de aprendizagem: aprendizagem \n\nHebbiana, de corre\u00e7\u00e3o do erro, estoc\u00e1stica, e competitiva.\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 87\n\nA p r e n d iz a g e m  d e  H ebb: A regra de aprendizagem mais antiga \u00e9 o postulado de \n\nHebb de aprendizagem [Hebb, 1949], Hebb baseou-se na seguinte observa\u00e7\u00e3o de \n\nexperimentos neurobiol\u00f3gico: se neur\u00f4nios em ambos os lados de uma sinapse s\u00e3o \n\nativados sincronicamente e repedidamente ent\u00e3o o comprimento da sinapse \u00e9 \n\nseletivamente aumentado.\n\nMatematicamente, a regra de Hebb pode ser descrita como\n\nw ij (* +  0  =  ( 0  +  n y j  ( 0 * , ( 0  (4 .\n\nonde Xi e y} s\u00e3o os valores de sa\u00eddas dos neur\u00f4nio i e j ,  respectivamente, os quais s\u00e3o \n\nconectados pela sinapse Wy, e jj \u00e9  a taxa de aprendizagem. Note que, x t \u00e9 a sa\u00edda para \n\na sinapse.\n\nUma importante propriedade desta regra \u00e9 que a aprendizagem \u00e9 feita \n\nlocalmente, isto \u00e9, a mudan\u00e7a nos pesos depende somente da ativa\u00e7\u00e3o dos dois \n\nneur\u00f4nios conectados pelo peso. Isto simplifica significantemente a complexidade da \n\naprendizagem.\n\nC o r r e \u00e7 \u00e3 o  d o  e r r o :  N o paradigma da aprendizagem supervisionada, a rede recebe \n\numa sa\u00edda desejada para cada padr\u00e3o de entrada. Durante o processo de \n\naprendizagem, a sa\u00edda y gerada pela rede pode n\u00e3o ser igual a sa\u00edda desejada d. O \n\nprinc\u00edpio b\u00e1sico da regra de aprendizagem corre\u00e7\u00e3o do erro \u00e9 usar o sinal de erro (d - \n\ny) para modificar os pesos das conex\u00f5es para gradualmente reduzir este erro.\n\nA regra de aprendizagem do Perceptron e o algoritmo de aprendizagem \n\nbackpropagation s\u00e3o baseados neste princ\u00edpio de corre\u00e7\u00e3o de erro.\n\nESTOC\u00c1STICA: A regra de aprendizagem estoc\u00e1stica \u00e9 acompanhada pelo ajuste dos \n\npesos de uma maneira probabil\u00edstica. Exemplos de aprendizagem estoc\u00e1stica s\u00e3o \n\nencontradas nas m\u00e1quinas de Boltzmann e de Cauch, onde os estados de todos os \n\nneur\u00f4nios s\u00e3o determinados por uma distribui\u00e7\u00e3o de probabilidade. Durante a fase de \n\naprendizagem, o sistema e operado em dois modos; clamped, no qual neur\u00f4nios\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 88\n\nvis\u00edveis (entrada/sa\u00edda) s\u00e3o clamped em estados espec\u00edficos determinados pelo meio; \n\ne free-running, aos quais, neur\u00f4nios vis\u00edveis e escondidos, \u00e9 permitido operar \n\nlivremente. Permite-se que a rede opere em ambos os modos at\u00e9 que um equil\u00edbrio \n\n\u201ct\u00e9rmico\u201d seja alcan\u00e7ado. Neste momento, os pesos wy nas conex\u00f5es entre os n\u00f3s i e j \n\ns\u00e3o ent\u00e3o ajustados com base na diferen\u00e7a entre as duas propabilidades pij(C) e pij(U). \n\nAqui Pij(C) \u00e9 a probabilidade do i-\u00e9simo e o j-\u00e9simo elementos estarem ambos no \n\nmodo clamped, enquanto pjj(U) \u00e9 a probabilidade de ambos estarem no modo free- \n\nrunning. Como a rede \u00e9 sim\u00e9trica \u00e9 poss\u00edvel definir uma fun\u00e7\u00e3o de energia para o \n\nsistema como:\n\n\u00a3 = - } \u00ea \u00a3 w &lt;4\nz i=1 y=i\n\nonde S; \u00e9 o estado bin\u00e1rio {0 , 1 } ou estado bipolar {-1, 1 } da i-\u00e9sina unidade. O \n\nequil\u00edbrio \u00e9 alcan\u00e7ado quando a fun\u00e7\u00e3o de energia alcan\u00e7a um m \u00edn im o\n\nC o m p e t it iv a :  Ao contr\u00e1rio da regra de Hebb, na aprendizagem competitiva as \n\nunidades de sa\u00edda competem entre elas para ativa\u00e7\u00e3o. Como um resultado, somente \n\numa unidade de sa\u00edda \u00e9 ativada de cada vez. Este fen\u00f4meno \u00e9 conhecido como \n\nwinner-take-all. A aprendizagem competitiva \u00e9 encontrada nas redes neuronais \n\nbiol\u00f3gicas.\n\nEste tipo de aprendizagem freq\u00fcentemente categoriza os dados de entradas. \n\nPadr\u00f5es similares s\u00e3o agrupados pela rede e representados por uma \u00fanica unidade. \n\nEste agrupamento \u00e9 feito automaticamente baseado na correla\u00e7\u00e3o dos dados.\n\nO exemplo mais conhecido de aprendizagem competitiva \u00e9 a quantiza\u00e7\u00e3o de \n\nvetor para compress\u00e3o de dados.\n\n4.2.5 Aplica\u00e7\u00f5es e Principais \u00c1reas de Atua\u00e7\u00e3o\n\nA t\u00e9cnica de RNA pode tratar de diversos problemas, que se pode dividir em \n\nquatro categorias principais [Folgelman-Souli\u00e8, 1995]:\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 89\n\n1. Classifica\u00e7\u00e3o e diagn\u00f3stico: Um padr\u00e3o \u00e9 apresentado para a rede, que tem que \n\ndecidir em qual das classes pr\u00e9-definidas aquele padr\u00e3o pertence. Esta situa\u00e7\u00e3o \n\ntipicamente ocorre em problemas de Reconhecimento de Padr\u00f5es.\n\n2. Aproxima\u00e7\u00e3o de Fun\u00e7\u00e3o: A rede deve associar ao padr\u00e3o de entrada um valor \n\npr\u00f3ximo ao valor da fun\u00e7\u00e3o desconhecida que representa um fen\u00f4meno \u201creal\u201d. \n\nEste problema ser\u00e1 encontrado em previs\u00e3o de s\u00e9ries temporais, identifica\u00e7\u00e3o e \n\nprocessos de controle.\n\n3. Compress\u00e3o, extra\u00e7\u00e3o de caracter\u00edsticas e quantiza\u00e7\u00e3o: N a maioria das \n\naplica\u00e7\u00f5es, dados brutos, tal como aqueles vindo de sensores, tem alta \n\ndimensionalidade e ru\u00eddos. As Redes Neuronais podem ser usadas para reduzir a \n\ndimens\u00e3o e o ru\u00eddo, tanto por compress\u00e3o, como atrav\u00e9s de extra\u00e7\u00e3o das \n\ncaracter\u00edsticas relevantes. Quantiza\u00e7\u00e3o, supervisionada e n\u00e3o-supervisionada \n\npodem tamb\u00e9m ser usadas para representar os dados atrav\u00e9s de um conjunto \n\nlimitado de refer\u00eancias.\n\n4. Otimiza\u00e7\u00e3o: RNAs podem ser definidas de modo que seus pesos possam \n\nrepresentar uma fun\u00e7\u00e3o objetivo a ser otimizada, e as restri\u00e7\u00f5es nas vari\u00e1veis. Uma \n\nsolu\u00e7\u00e3o (usualmente aproximada) \u00e9 ent\u00e3o obtida como um estado limite da \n\ndin\u00e2mica da rede.\n\nA maioria das aplica\u00e7\u00f5es de RNAs desenvolvidas usam um conjunto muito \n\nrestrito de algoritmos: Redes Multicamadas (principalmente Perceptron \n\nMulticamadas (MLP) com backpropagation e Radial Base Function (RBF)), \n\nLearning Vector Quantization (LVQ) e os mapas topol\u00f3gicos de Kohonen (SOFM) \n\n(que usam mecanismo \u201cwinner-take-air). Aproximadamente 90% de todas as \n\naplica\u00e7\u00f5es s\u00e3o usadas para classifica\u00e7\u00e3o, identifica\u00e7\u00e3o, diagn\u00f3stico e predi\u00e7\u00e3o. \n\nEmbora os primeiros desenvolvimentos de aplica\u00e7\u00f5es com sucesso datam nos anos \n\n50, a introdu\u00e7\u00e3o das RNAs na ind\u00fastria em larga escala tem seu in\u00edcio nos meados \n\ndos anos 80 com as redes MLP.\n\nOs principais dom\u00ednio de aplica\u00e7\u00f5es onde as RNAs est\u00e3o sendo usadas s\u00e3o os \n\nseguintes:\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 90\n\n\u2022  Setor M ilitar: Processamento de sinais para identifica\u00e7\u00e3o de alvos ou origens, \n\nfus\u00e3o de dados, an\u00e1lise de imagens para localiza\u00e7\u00e3o e identifica\u00e7\u00e3o do alvo.\n\n\u2022 Processamento de Imagens-. Reconhecimento de objetos, an\u00e1lise de cenas, an\u00e1lise \n\nde imagens de sat\u00e9lites e teledetec\u00e7\u00e3o.\n\n\u2022 Telecomunica\u00e7\u00f5es: controle, codifica\u00e7\u00e3o, filtros, canal de transmiss\u00e3o/ \n\nequaliza\u00e7\u00e3o.\n\n\u2022 Manufatura-, previs\u00e3o do consumo de energia (\u00e1gua, eletricidade), identifica\u00e7\u00e3o e \n\ncontrole de processos industriais.\n\n\u2022 Rob\u00f3tica', ve\u00edculos aut\u00f4nomos, controle do bra\u00e7o de um rob\u00f4.\n\n\u2022 Biologia e Medicina: an\u00e1lise de imagens, processamento de sinais, diagn\u00f3stico \n\nautom\u00e1tico, an\u00e1lise de genoma.\n\n\u2022 Setor Terci\u00e1rio: leitura autom\u00e1tica de textos (digitado e manuscrito), autentica\u00e7\u00e3o \n\nde assinaturas, detec\u00e7\u00e3o de fraudes.\n\n\u2022  Finan\u00e7as: previs\u00e3o do pre\u00e7o de a\u00e7\u00f5es e de \u00edndices econ\u00f4micos, an\u00e1lise de riscos, \n\ndiagn\u00f3stico de empresas.\n\n4.2.6 Taxinomia das Redes Neuronais\n\nA Tabela 4.1 resume v\u00e1rios algoritmos de aprendizagem e as principais \n\narquiteturas associadas. Os paradigmas de aprendizagem supervisionado e n\u00e3o \n\nsupervisionado empregam regras de aprendizagem baseadas nas aprendizagens \n\nCorre\u00e7\u00e3o do Erro, Hebbiana e Competitiva. Regras de aprendizagem baseadas na \n\nCorre\u00e7\u00e3o do Erro podem ser usadas para redes de treinamento feed-forward, enquanto \n\na aprendizagem de Hebb tem sido usada para todos os tipos de arquiteturas. Contudo, \n\ncada algoritmo de aprendizagem \u00e9 projetado para treinamento de uma arquitetura \n\nespec\u00edfica. Portanto, quando discuti-se um algoritmo de aprendizagem, uma \n\narquitetura particular est\u00e1 subentendida. Cada algoritmo pode realizar bem somente \n\numas poucas tarefas. A \u00faltima coluna da Tabela 4.1 lista tarefas que cada algoritmo \npode realizar.\n\n\n\ntow\u00bb\u00ab\n.\n\n:S ;\n* \u20193&amp;?o\noa\n\nCO C/5o a>to IObi (V\n\u2019S c\nOh i n &lt;d\n\n*o *o\n\n*4* S?o \u00a9<u fc* V S\nm .\n\n\u00e2  > i u  o  ^ &lt;u co 2  z o E o in .s m \n\u00c4  X  o\nCO Q \u2022 \u2014m y \n\n-2 a. 2\nO &lt; \u00a3\n\n4>\n*8\nO'\n4>T3\nO\n% O led O\n\ncd>\n\nOoco\n43\u00ab \"7\n\ns  I  :\u00a7\n\u00ab \u00a7 E\n-  5  \u00ab\u00eb \u00fc o l\n\nSS&lt;u O T3 T3 \ncd T3\n\n\u2022O\n\u00aby c\u00e7\nS \u00fcoK\u00d6 \n\n\u00ab g \n\u00a3 I\na- s\ng sO O\nO ai\n\nim\nr-'\u00ab: _ \u00abtj \u2022**\n\nH E\n\nSa>W). \u00ab \u2022. \n.aT5 ;:;-C , \nfi\n\n\u00ab-D .-\n: r\n\n&amp;?\n\nW c3\n1 ' *  O h  - O\n\nS \u00b0 \n\u00a7 \\5\na  \u00ab s  -P \nft&lt;<\n\nj\u00fc\nCl\nS\n\nK\n\n* o  52xZ&lt;2 \ncd ^\n\ne  s\ned O\n\n4>\u2022a\n\n\u00ea\nw\u00efo\n*edO*\n\u00ebo\nO\n\n?u o\nC T3 4> cd \nl -  Sa  o\n\n*60 \n'g  Oex3VD\n\nO\nffl\no\u2022o\n\u00c4 \u2022\u00ab \n\n\u2022\u00a7 j ? \u2019\"  \ni - l u\u00e2  S o \nS u f f i\n\ncd\nE3\n\nSoo\n\n0) \nc\n\n^ 8  \u00eb  &lt;2 | &lt;2 - \u00a7\n\u2019S 3  \u00a7 -g g-g I\ntS 5  iS f? \u00a7 r\u00fc \u00ab\u00c4 Pi \u00d6H o o\n\n\u00abM\n\ni \n<2 ^\n\nO'\n>\nJ\ned\nE\n\nEoo\n\n\u00ab\n\n\u2022s \u00a3  *\n\ncdo\n\n'So\nco\nw\n\n*r>\n\u2019S\nH\n\n?\no>Q-\nEO\nU\n\no\n\u00cf cd O\n\nX)\n\nex\n\noT3\n\nC\n\nE\n\n\u00a3  \u00ae \ned\n*5oGO\n43\n\nICQ E  \n\n8 \" g  O 2S . ( S M S  S to T jj S W\n1  \u00eb  1  \u201c  1  \u00eb  \nH J j J \u00edP\u00cd Oh S  O  p 4 eu\n\nS*\u2019\u00ae\nc?o<43\n\n\u2018 co\nco\ned\nn  \u00b0  u  so\no* .\u00a7<\u20acd 5 \n\u00a3* \u00ab \ns  ?\u00a7\nS  O\u2022S g\nO pi\n\ngo\n\n2  \u20191Al TVooo\n\ned-D\ned\n\nT30)<u\nUh\n\nc\n\u00eboo4>\n(*\n\nOcn\ncd\nE3\n\nEoo\n\n<2 -g\n-O g\n\u00a3 s\n\nr0  C\u00abto O\n\ncd>\n<uo.\nEo\nu\n\nVi<DiOOc3b  o)\n<U s \n\n- \u00b0  s\n?i u  \nSf \u00ab \nE \u00b0\n\u20223 *3.\nS \u2022\u00a7\n3- \u00a3 \n^  CL.\u00d6 c\n\nK\na.\nEo\nCJ\n\nWiOmo-<u\n\nU\n\nseO\ns\u20183V\nX !\nS\nO\u00ab\n\na\nS\nS4>\nMa\nN\n\n\u2022 M?oaVh\na.\n\n<\n\u00ab\n\nTJ\nseO\n\nb.\nO\noc\n\n*T\ne:\n\npfi\na\n\n\n\n4.3 Caracteriza\u00e7\u00e3o das Principais Redes Neuronais\n\n4.3.1 Introdu\u00e7\u00e3o\n\nNesta se\u00e7\u00e3o apresenta-se a estrutura b\u00e1sica das redes de Kohonen, LVQ, \n\nHopfleld, ART, MLP e RBF assim como suas limita\u00e7\u00f5es, vantagens e algumas \n\naplica\u00e7\u00f5es.\n\n4.3.2 Rede de Kohonen\n\nOs Mapas de Caracter\u00edsticas Auto-Organiz\u00e1veis (Self-Organizing Feature \n\nMaps -  SOFM) ou a rede de Kohonen, introduzido por Teuvo Kohonen [Kohonen, \n\n1982; Kohonen, 1988; Kohonen, 1990] (pesquisador da Universidade de Helsinki), \u00e9 \n\num dos modelos de redes neuronais mais usados, principalmente para quantiza\u00e7\u00e3o de \n\nvetor e an\u00e1lise de dados, mas tamb\u00e9m aplic\u00e1vel em quase todas as tarefas onde redes \n\nneuronais tiveram sucesso.\n\nO modelo de Kohonen \u00e9 do tipo fe e d  forward, de treinamento n\u00e3o \n\nsupervisionado com competi\u00e7\u00e3o. O esquema b\u00e1sico do modelo t\u00eam a propriedade de \n\nmodificar a si pr\u00f3prio. Assim, os neur\u00f4nios pr\u00f3ximos ao modificado respondem \n\nsimilarmente. Os neur\u00f4nios da camada competem entre si para serem os vencedores \n\nem cada modifica\u00e7\u00e3o. Os neur\u00f4nios cujo vetor dos pesos gerar a menor dist\u00e2ncia \n\nEuclidiana (ou outra dist\u00e2ncia) com o vetor de entrada \u00e9 o vencedor, mas tamb\u00e9m os \n\npesos dos seus vizinhos (dentro de senso f\u00edsico) s\u00e3o ajustados.\n\nEste comportamento tem por objetivo fazer com que a rede simule uma \n\natividade cerebral. Este paradigma \u00e9 baseado na teoria de que as c\u00e9lulas nervosas \n\ncorticais est\u00e3o arranjadas anatomicamente em rela\u00e7\u00e3o aos est\u00edmulos que recebem dos \n\nsensores \u00e0s quais est\u00e3o ligadas. Alguns cientistas, rasteando a atividade cerebral, \n\nnotaram que, apesar de todas as c\u00e9lulas nervosas estarem ligadas e coligadas entre si, \n\nexistem centros da atividades mais intensificados conforme a atividade exercitada no \n\nmomento. Quando assiste-se um filme, por exemplo, ou quando se est\u00e1 efetuando um \n\nracioc\u00ednio matem\u00e1tico, existem \u00e1reas do c\u00e9rebro diferentes com maior atividade. Este \n\n\u00e9 o paradigma topol\u00f3gico.\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 93\n\nTeuvo Kohonen introduziu um conceito muito interessante de mapas de \n\ncaracter\u00edsticas topologicamente auto-organizados, que s\u00e3o mapas que preservam a \n\ntopologia de uma representa\u00e7\u00e3o multidimensional dentro de uma matriz de neur\u00f4nios \n\nde 1 , 2  ou mais dimens\u00f5es.\n\nO conceito de topologia (ou melhor, o conceito de preserva\u00e7\u00e3o topol\u00f3gica) \n\ntomou-se a caracter\u00edstica essencial da abordagem de Kohonen na pesquisa de RNA.\n\nA rq u ite tu ra\n\nO SOFM \u00e9 provavelmente a RNA mais pr\u00f3xima entre todas as arquiteturas e \n\nesquemas de aprendizagem de RNA da rede neuronal biol\u00f3gica. Como uma regra, a \n\nrede Kohonen \u00e9 baseada em uma \u00fanica camada de neur\u00f4nios arranjados em um plano \n\nbi-dimensional, por exemplo, tendo uma topologia bem definida (Figura 4.3).\n\nF igura 4.3 : A rq u ite tu ra da rede Kohonen, caso de duas dimens\u00f5es \u00cdPandva &amp; M acv.\n1995].\n\nUma topologia definida significa que cada neur\u00f4nio tem um n\u00famero de \n\nneur\u00f4nios como vizinhos mais pr\u00f3ximos, segundo vizinhos mais pr\u00f3ximos, etc.. A \n\nvizinhan\u00e7a de um neur\u00f4nio \u00e9 usualmente arranjada em quadrados ou hex\u00e1gonos, o \n\nque significa que cada neur\u00f4nios tem 4 ou 6  vizinhos mais pr\u00f3ximos. O conceito de\n\nCam;\nenti\n\nPadr\u00f5es de entrada\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n94\n\nvizinhos mais pr\u00f3ximos necessita de alguma elabora\u00e7\u00e3o quando se fala em topologia. \n\nPor exemplo, a vizinhan\u00e7a topol\u00f3gica quadrada \u00e9 freq\u00fcentemente considerada como \n\ntendo 8  e n\u00e3o quadro vizinhos mais pr\u00f3ximos (Figura 4.4). Os pontos dos cantos est\u00e3o \n\nmais distantes do centro que os verdadeiros vizinhos mais pr\u00f3ximos; mas o interesse \u00e9 \n\nna topologia, isto \u00e9, nas conex\u00f5es e n\u00e3o na verdadeira dist\u00e2ncia. Na concep\u00e7\u00e3o de \n\nKohonen sobre rede neuronais, o sinal de similaridade est\u00e1 relacionado com a rela\u00e7\u00e3o \n\nespacial (topol\u00f3gica) entre os neur\u00f4nios na rede.\n\nO SOFM de Kohonen tenta mapear as entradas de maneira que sinais \n\nsimilares excitem neur\u00f4nios que est\u00e3o pr\u00f3ximos (em termos de dist\u00e2ncia espacial). \n\nEsta rela\u00e7\u00e3o dist\u00e2ncia-por-similaridade deve ser generalizada para incluir todas as \n\nrela\u00e7\u00f5es de similaridade entre diferentes sinais tamb\u00e9m. A aprendizagem de Kohonen \n\nrepresenta uma tentativa de ajustar o espa\u00e7o de sinais dentro de uma rede neuronal \n\npor uma esp\u00e9cie de procedimento suave. O objetivo da aprendizagem de Kohonen \u00e9 \n\nmapear sinais similares em dire\u00e7\u00e3o \u00e0s posi\u00e7\u00f5es de neur\u00f4nios similares.\n\nF ig u ra 4.4: Topologia q u ad rad a [Pandya &amp; M acy, 1995].\n\nEm uma rede de Kohonen, pode-se falar de duas camadas: entrada e sa\u00edda. \n\nSomente a camada de sa\u00edda ativa e usualmente arranjada como uma grade de \n\nneur\u00f4nios (mas pode tamb\u00e9m ser arranjada como um vetor).\n\nPode-se trabalhar tamb\u00e9m com mapas mais complexos, como espa\u00e7os de 3 ou \n\n4 dimens\u00f5es. Neste caso, os mapeamentos topol\u00f3gicos podem ser usados para \n\ntransformar a superf\u00edcie de 3 dimens\u00f5es, por exemplo, em uma superf\u00edcie plana.\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n95\n\nTodos os neur\u00f4nios na camada ativa recebem a mesma entrada. O aspecto \n\nmais caracter\u00edstico da rede de Kohonen \u00e9 existe somente um feedback local, isto \u00e9, a \n\nsa\u00edda de cada neur\u00f4nio n\u00e3o est\u00e1 conectada para todos os outros neur\u00f4nios no plano \n\n(como na rede de Hopf\u00edeld), mas somente para um n\u00famero pequeno que est\u00e3o \n\ntopologicamente pr\u00f3ximos a ele. Portanto, os neur\u00f4nios topologicamente pr\u00f3ximos \n\ncomportam-se de forma similar quando sinais similares s\u00e3o apresentados (Figura 4 .5 ).\n\nNa aprendizagem competiviva, somente um neur\u00f4nio \u00e9 ativo numa camada \n\nap\u00f3s cada entrada. A rede de Kohonen seleciona o neur\u00f4nio vencedor \u201cc\u201d como sendo \n\naquele que est\u00e1 mais pr\u00f3ximo do vetor de entrada. Ap\u00f3s encontrar o neur\u00f4nio \n\nvencedor deve-se corrigir os pesos do neur\u00f4nio vencedor e de sua vizinhan\u00e7a.\n\nVantagens e Limita\u00e7\u00f5es\n\nO SOFM tem uma s\u00e9rie de desvantagens computacionais que afetam a \n\nperformance de aplica\u00e7\u00f5es de grande porte executadas em computadores paralelos \n\n(mas n\u00e3o em s\u00e9rie). A fim de encontrar o neur\u00f4nio vencedor (e vizinhan\u00e7a), o \n\nprograma deve verificar todos os n neur\u00f4nios. Esta \u00e9 uma restri\u00e7\u00e3o s\u00e9ria quando redes \n\ngrandes est\u00e3o sendo treinadas. At\u00e9 em computadores paralelos, isto envolve n\\2 \n\ncompara\u00e7\u00f5es paralelas, que requerem pelo menos log2n passos. Em m\u00e1quinas \n\ncomuns, todos os c\u00e1lculos devem ser feitos seq\u00fcencialmente, e guardando a maior \n\nsa\u00edda n\u00e3o afeta muito o desempenho total.\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n96\n\nA rede de Kohonen ou uma camada de Kohonen pode ser constru\u00edda em uma \n\nrede complexa como uma de suas camadas [Wasserman &amp; Schwartz, 1988] ou \n\nimplementada como em combina\u00e7\u00e3o com outras t\u00e9cnicas [Ritter et al., 1990],\n\nAplica\u00e7\u00f5es\n\nA rede de Kohonen tem encontrado aplica\u00e7\u00f5es nas \u00e1reas de quantiza\u00e7\u00e3o de \n\nvetores para compress\u00e3o de dados, corre\u00e7\u00e3o de erros e a gera\u00e7\u00e3o de c\u00f3digos de \n\npalavras. Al\u00e9m disto, podem ser efetivamente usadas para otimiza\u00e7\u00e3o, controle, \n\nreconhecimento de voz e mapeamentos sensoriais.\n\nTeuvo Kohonen [Kohonen, 1988] e seus colega desenvolveram um \u201cphonetic \n\ntypewriter no in\u00edcio dos anos oitentas. O phonetic typewriter \u00e9 um sistema de \n\nreconhecimento que pode transcrever discursos em textos ortograficamente corretos.\n\nA rede de Kohonen unidimensional foi usada com sucesso para resolver o \n\nproblema de otimiza\u00e7\u00e3o do Caixeiro Viajante [Angeniol et al., 1988],\n\nPara ilustrar a habilidade de uma rede de Kohonen na realiza\u00e7\u00e3o de \n\nmapeamentos n\u00e3o lineares pode-se citar tamb\u00e9m a aplica\u00e7\u00e3o: controle do bra\u00e7o de um \n\nrob\u00f4 [Ritter et al., 1992],\n\nEm classifica\u00e7\u00e3o de padr\u00f5es, o objetivo \u00e9 classificar os sinais de entrada em \n\num n\u00famero finito de classes tal que a probabilidade m\u00e9dia do erro seja minimizada. \n\nEm tais tarefas, a quest\u00e3o de particular import\u00e2ncia \u00e9 delinear os limites das classes \n\nonde as decis\u00f5es s\u00e3o feitas. Para encontrar melhores resultados para classifica\u00e7\u00e3o de \n\npadr\u00f5es, o uso dos SOFMs deveria ser acompanhado por um esquema de aprendizado \n\nsupervisionado. Uma possibilidade \u00e9 o uso de abordagem h\u00edbrida como mostrado na \n\nFigura 4.6, que envolve uma combina\u00e7\u00e3o de SOFM e o LVQ (pr\u00f3xima se\u00e7\u00e3o) para \n\nclassifica\u00e7\u00e3o de padr\u00f5es.\n\nEntrada Sa\u00edda\n\nF ig u ra 4.6 Classifica\u00e7\u00e3o de padr\u00f5es em dois est\u00e1gios.\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n97\n\n4.3.3 Rede LVQ (Learning Vector Quantization)\n\nUma caso particular dos SOFM s\u00e3o as redes VQ (vector quantization). Ao \n\ncontr\u00e1rio das redes SOFM, nas redes VQ n\u00e3o existe o feedback lateral. A nnidade \n\nvencedora \u00e9 a \u00fanica beneficiada no momento da aprendizagem. Ou seja,\n\nonde c \u00e9 a unidade vencedora, w \u00e9 o vetor de pesos, x \u00e9 a entrada e a(t) \u00e9 uma fim\u00e7\u00e3o \n\npara a taxa de aprendizagem.\n\nEstas redes s\u00e3o capazes de aprender uma forma efetiva de quantiza\u00e7\u00e3o6 de \n\nvetor. As redes VQs aprendem a quantizar ou comprimir padr\u00f5es de entrada de algum \n\nmeio, um processo que tamb\u00e9m \u00e9 aprendido em redes biol\u00f3gicas. Em aplica\u00e7\u00f5es tal \n\ncomo reconhecimento de fala e processamento de imagens, uma grande quantidade \n\nde dados deve ser armazenada, processada e possivelmente transmitidas. Tipicamente \n\nexiste muita redund\u00e2ncia nos dados deste tipo e existe a necessidade de comprim\u00ed-los. \n\nUm m\u00e9todo de compress\u00e3o \u00e9 a rede VQ. Nestas redes os vetores de entrada x de \n\ndimens\u00e3o n s\u00e3o transformados em um n\u00famero finito de classes onde cada classe est\u00e1 \n\nrepresentada por um prot\u00f3tipo Wi (i= l,..\u201e m). Esta aproxima\u00e7\u00e3o causa alguma \n\ndistor\u00e7\u00e3o na representa\u00e7\u00e3o, mas esta desvantagem \u00e9 compensada pela consider\u00e1vel \n\neconomia na armazenagem e redu\u00e7\u00e3o na complexidade computacional do processo de \ncompress\u00e3o de dados.\n\nExistem tamb\u00e9m as formas supervisionadas de VQ que s\u00e3o chamadas LVQ \n\n(Leaming Vector Quantization). Esta redes permitem a especifica\u00e7\u00e3o das categorias \n\nno qual as entradas estar\u00e3o classificadas. A designa\u00e7\u00e3o das categorias para o conjunto \n\nde treinamento s\u00e3o conhecidos a priori e fazem parte do conjunto de treinamento \n\n(como em qualquer m\u00e9todo supervisionado). A arquitetura da LVQ \u00e9 exatamente a \n\nmesma que a SOFM com a \u00fanica exce\u00e7\u00e3o que cada neur\u00f4nio na camada de sa\u00edda \u00e9 \n\ndesignado a pertencer a uma das categorias de classifica\u00e7\u00e3o. Isto \u00e9 ilustrado na Figura\n\nQuantiza\u00e7\u00e3o \u00e9 o processo de transformar vari\u00e1veis de valores cont\u00ednuos em vari\u00e1veis discretas.\n\n(4.3)\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n98\n\n4.7. Em geral, diversos neuronios s\u00e3o atribu\u00eddos para cada classe. Como antes, o vetor \n\npeso (chamado vetor de refer\u00eancia ou prot\u00f3tipo para a classe que ele representa), para \n\numa dada unidade de sa\u00edda representa um exemplar dos vetores da entrada para o \n\nqual ele responde mais fortemente.\n\nDurante o treinamento, como mostra a Figura 4.8, o neur\u00f4nio vencedor c \u00e9 \n\npremiado se ele pertence \u00e0 categoria correta, movendo-se em dire\u00e7\u00e3o ao vetor de \n\nentrada. Contrariamente, se o neur\u00f4nio vencedor n\u00e3o pertence \u00e0 categoria correta, ele \n\n\u00e9 punido, sendo for\u00e7ado a mover-se para longe do vetor de entrada. Isto \u00e9,\n\nDepois do treinamento, uma rede LVQ classifica um vetor de entrada \ndesignando-o \u00e0 mesma classe cujo vetor de peso da unidade de sa\u00edda (vetor \nrefer\u00eancia) \u00e9 o mais pr\u00f3ximo do vetor de entrada.\n\nw/ IOT0 -  + a (x  -  w *010), se c \u00e9 a classe correta \nM>n\u2122 = w ^ 0 -  a (x  -  w\u2122010), caso contr\u00e1rio. (4.4)\n\nCamada de Sa\u00edda \n\nCategoria 1 Categoria 2 Categoria n\n\nCamada de Entrada\n\nF ig u ra 4.7 A rq u ite tu ra da LVQ [Pandya &amp; M acy, 1995].\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n99\n\n(^M odifica\u00e7\u00e3o para o peso vencedorA\n\u2014... se correto\n\nEntrad\u00e0^\u00bb* ------- ------------- ----------\n\n/  S * \\  (^M odifica\u00e7\u00e3o para o peso vencedorA  \n/ ^ P e s o  T s e  incorreto ____\n\n^  Vencendor\n\nF ig u ra 4.8 Treinam ento da LVQ [Pandya &amp; M acy, 1995].\n\nForam desenvolvidas varia\u00e7\u00f5es do algoritmo b\u00e1sico LVQ (LVQ 2, LVQ 2.1 e \n\nLV Q  3). No LVQ original - tamb\u00e9m chamado de LVQ1 - somente o vetor de \n\nrefer\u00eancia que est\u00e1 mais pr\u00f3ximo do vetor de entrada \u00e9 atualizado. A dire\u00e7\u00e3o que este \n\nvetor se move depende do vetor de refer\u00eancia pertence \u00e0 mesma classe do vetor de \n\nentrada ou n\u00e3o. Nos algoritmos aperfei\u00e7oados, dois vetores (o vencedor e o segundo) \n\naprendem, se v\u00e1rias condi\u00e7\u00f5es s\u00e3o satisfeitas. A id\u00e9ia \u00e9 a de que se a entrada est\u00e1 \n\nmais ou menos a mesma dist\u00e2ncia tanto do vencedor quanto do segundo, ent\u00e3o ambos \n\ndevem aprender.\n\nV antagens e Limita\u00e7\u00f5es\n\nEstes classificadores tipicamente apresentam taxas de erros que s\u00e3o \n\nsemelhantes ao backpropagation, mas freq\u00fcentemente o treinamento \u00e9 mais r\u00e1pido, e \n\nrequer mais mem\u00f3ria e tempo de computa\u00e7\u00e3o durante a classifica\u00e7\u00e3o. Tamb\u00e9m \n\ngeralmente fornecem taxas de erros menores quando comparado com o SOFM, \n\nespecialmente quando o n\u00famero de n\u00f3s \u00e9 pequeno.\n\nAplica\u00e7\u00f5es\n\nAs redes LVQ s\u00e3o usadas principalmente para classifica\u00e7\u00e3o, reconhecimento \n\nde padr\u00f5es e compress\u00e3o de imagens.\n\nBaykal e Yalabki [Baykal &amp; Yalabki, 1992] usaram uma rede LVQ em \n\nconjunto com uma rede fe e d  forw ard no reconhecimento de caracteres de m\u00faltiplas\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n100\n\nfontes. Eles registraram uma taxa de reconhecimento de 87% at\u00e9 mesmo com \n\ncaracteres distorcidos, alterados ou rotacionados.\n\nO classificador LVQ tem sido comparado com o classificador MLP com \n\nbackpropagation usando problemas artificiais, problemas de reconhecimento de \n\nfonemas [McDermott &amp; Katagiri, 1988] e para previs\u00e3o de fal\u00eancia [Refenes, 1995], \n\nNestas compara\u00e7\u00f5es verificou-se a equival\u00eancia entre as duas redes.\n\n4.3.4 Rede ART (Adaptative Resonance Theory)\n\nOutra importante classe de redes recorrentes s\u00e3o as redes ARTs. Estas redes \n\nforam desenvolvidas nos meados dos anos setenta e oitenta por Stefhen Grossberg em \n\nparceria com membros do Centro de Sistemas Adaptativos de Boston, principalmente \n\ncom Gail Carpenter, sua esposa. A principal preocupa\u00e7\u00e3o de Grossberg era \n\ndesenvolver uma rede que tivesse plasticidade (discrimina\u00e7\u00e3o) e estabilidade \n\n(generalidade).\n\nNo desenvolvimento de uma RNA espera-se que algumas das propriedades \n\nb\u00e1sicas do c\u00e9rebro exibidas pela RNA sejam compar\u00e1veis com a rede biol\u00f3gica. Em \n\nparticular, deseja-se que a RNA tenha habilidade de continuamente adaptar-se quando \n\nmudan\u00e7as no meio ocorrem. Isto significa, ser capaz de reter fatos e informa\u00e7\u00f5es \u00fateis \n\nna mem\u00f3ria enquanto, ao mesmo tempo, aprender fatos novos e importantes. Os fatos \n\nnovos aprendidos n\u00e3o deveriam \u201capagar\u201d informa\u00e7\u00f5es antigas e \u00fateis. Ao mesmo \n\ntempo, deseja-se que o modelo fosse capaz de ignorar fatos irrelevantes e at\u00e9 mesmo \n\nesquecer informa\u00e7\u00f5es antiquadas ou n\u00e3o importantes. Em outras palavras, deseja-se \n\nque as redes exibissem um alto grau de estabilidade na aprendizagem adaptativa de \n\nnovos conceitos ou categorias. Por outro lado, ela n\u00e3o deveria esquecer (ou perder) os \n\nfatos \u00fateis previamente armazenados na mem\u00f3ria para acomodar o novo \n\nconhecimento aprendido. Naturalmente, tal rede deveria ser capaz de discriminar \n\nentre as informa\u00e7\u00f5es \u00fateis e as irrelevantes. Este conflito, estabilidade e plasticidade, \n\ns\u00e3o chamados por Grossberg de dilema da estabilidae/plasticidade [Carpenter &amp; \n\nGrossberg, 1987],\n\nAs RNA convencionais t\u00eam falhado na resolu\u00e7\u00e3o do dilema \n\nestabilidade/plasticidade. Muito freq\u00fcentemente, em outros modelos de redes como\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 101\n\nfe e d fo rw a rd  com aprendizagem backpropagation, ou na rede Counterpropagation, o \n\naprendizado de um novo padr\u00e3o apaga ou modifica os padr\u00f5es treinados \n\nanteriormente. Caso uma rede completamente treinada necessite aprender um novo \n\npadr\u00e3o de treinamento, ela pode modificar tanto os pesos que um outro treinamento \u00e9 \n\nnecess\u00e1rio.\n\nEm alguns casos isto n\u00e3o tem import\u00e2ncia, como na situa\u00e7\u00e3o em que o \n\nconjunto de treinamento permanece fixo. Mas, em muitos casos do mundo real, a rede \n\nestar\u00e1 exposta a uma constante mudan\u00e7a ambiental; com isto pode-se n\u00e3o ter nunca o \n\nmesmo conjunto de treinamento duas vezes. Sobre tais circunst\u00e2ncias, uma rede com \n\naprendizagem backpropagation, por exemplo, freq\u00fcentemente n\u00e3o aprender\u00e1 nada; \n\nisto \u00e9, ir\u00e1 continuamente modificar seus pesos sem proveito, nunca chegando a um \n\nconjunto satisfat\u00f3rio.\n\nA Teoria da Resson\u00e2ncia Adaptativa foi desenvolvida como uma extens\u00e3o aos \n\nsistemas de aprendizagem competi ti vo/cooperativo. Ela foi desenvolvida na tentativa \n\nde superar o problema da estabilidade/plasticidade e outras caracter\u00edsticas da \n\naprendizagem inst\u00e1vel associada com redes competitivas. A rede resultante (ART) \n\nteve um n\u00famero importante de caracter\u00edsticas que outras arquiteturas n\u00e3o t\u00eam, \n\nincluindo: aprendizagem em tempo-real (on-line); capacidade de auto-organiza\u00e7\u00e3o \n\n(aprendizagem n\u00e3o supervisionada); mem\u00f3ria auto-est\u00e1vel em rela\u00e7\u00e3o aos muitos \n\npadr\u00f5es de entradas arbitr\u00e1rios; busca adaptativa r\u00e1pida para melhor match de padr\u00f5es \n\narmazenados; habilidade de aprendizagem r\u00e1pida (ou lenta); rejei\u00e7\u00e3o de padr\u00f5es de \n\nentradas n\u00e3o familiares quando a capacidade de mem\u00f3ria for alcan\u00e7ada; crit\u00e9rio de \n\nerro vari\u00e1vel que permite um regulamento vari\u00e1vel de agrupamentos em categorias e \n\nreten\u00e7\u00e3o bem sucedida das caracter\u00edsticas de estabilidade e plasticidade\n\nAs redes ARTs mapeiam padr\u00f5es de entradas n-dimensional em categorias ou \n\nclasses de sa\u00eddas baseadas nas caracter\u00edsticas dos padr\u00f5es de entradas. Os padr\u00f5es de \n\nentradas similares (vizinhos mais pr\u00f3ximos) s\u00e3o agrupados dentro da mesma classe e \n\nos padr\u00f5es dissimilares em classes distintas. O grau de similaridade requerido para \n\ngrupos de padr\u00f5es \u00e9 ajust\u00e1vel de modo que muitos grupos de classe de padr\u00f5es \n\naltamente semelhantes sejam criados quando um limiar de semelhan\u00e7a \u00e9 posto a um \n\nn\u00edvel alto. No outro extremo, menos classes s\u00e3o criadas quando o limiar \u00e9 posto a um\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n102\n\nvalor baixo. Neste \u00faltimo caso, os membros de classe podem possuir um grau de\n\nsimilaridade menor. A defini\u00e7\u00e3o do limiar pode ser ajustado manualmente ou\n\ndinamicamente durante opera\u00e7\u00f5es da rede dependendo da aplica\u00e7\u00e3o especifica. Isto\n\npermite que uma rede ART tome-se mais ou menos seletiva enquanto continua a \nadaptar.\n\nA aprendizagem nas redes ARTs ocorre naturalmente em tempo real durante \n\nopera\u00e7\u00e3o normal da rede. Esta \u00e9 uma forma de aprendizagem cont\u00ednua e adaptativa \n\nn\u00e3o supervisionada onde uma nova categoria \u00e9 automaticamente formada sempre que \n\num padr\u00e3o de entrada novo (dissimilar aos j\u00e1  apresentados) \u00e9 apresentado a rede. \n\nNovas categorias continuar\u00e3o sendo formadas da nova entrada at\u00e9 que a rede esgote \n\nseu limite de neuronios de categorias de sa\u00eddas neutros (neur\u00f4nios n\u00e3o categorizados). \n\nNeste momento rejeitar\u00e1 qualquer novo padr\u00e3o de entrada. Padr\u00f5es de entradas que \n\ns\u00e3o similares a categorias j\u00e1  estabelecidas s\u00e3o prontamente \u201creconhecidos\u201d \n\nproduzindo uma sa\u00edda alta no neur\u00f4nio da categoria selecionada. Entradas que \n\nassemelham-se as categorias existentes tamb\u00e9m iniciam algum grau de aprendizagem \n\npara a categoria selecionada, sem ao mesmo tempo perturbar a estabilidade das \n\ncategorias aprendidas.\n\nA arquitetura b\u00e1sica inclui tr\u00eas grupos de neur\u00f4nios (Figura 4.9): um campo de \n\nprocessamento das entradas (camada Fj), as unidades de cluster (categoriza\u00e7\u00e3o) \n\n(camada F2), e um mecanismo para controlar o grau de similaridade de padr\u00f5es \n\ncolocados no mesmo cluster (um mecanismo de reajuste). Denota-se a parte da \n\nentrada da camada Fj como F,(a) e a parte de interface como Fj(b).\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 103\n\nCama\u00e1a F2 \n(Unidades de \n\ncateg\u00abriza\u00e7\u00e3*)\n\ng t  Camada Fi(a) \nW  (Interface)\n\nCama\u00e1a F 1(1\u00bb) \n(Entradas)\n\nF ig u ra 4.9: E s tru tu ra  b\u00e1sica da ART1 [Fauset, 1994].\n\nExistem dois conjuntos de conex\u00f5es entre cada unidade na parte de interface \n\npara o campo de entrada e cada unidade de cluster. b;j conex\u00e3o da i-\u00e9sima unidade Fi \n\npara a j-\u00e9sima unidade F2 (pesos bottom-up); tj; conex\u00e3o da j-\u00e9sim a nni<fade F! para a \n\ni-\u00e9sima unidade Fj (pesos top-dowri).\n\nA camada F2 \u00e9 uma camada competitiva. A unidade de interface combina \n\ninforma\u00e7\u00f5es das unidades de entrada e unidades de categoriza\u00e7\u00e3o. Se a nnirfade de \n\ncluster pode aprender ou n\u00e3o, o padr\u00e3o de entrada, depende da unidade de reajuste.\n\nUma tentativa de aprendizagem em ART consiste da apresenta\u00e7\u00e3o de um \n\npadr\u00e3o de entrada. A atualiza\u00e7\u00e3o \u00e9 feita pela: ativa\u00e7\u00e3o, inativa\u00e7\u00e3o e/ou inibi\u00e7\u00e3o de \n\ntodas as unidades. Assim que um padr\u00e3o \u00e9 apresentado, ele continua enviando seus \n\nsinais de entrada at\u00e9 que a tentativa de aprendizagem seja completada. O grau de \n\nsimilaridade para padr\u00f5es em um mesmo cluster \u00e9 controlado por um par\u00e2metro \n\nespecificado pelo usu\u00e1rio, conhecido como par\u00e2metro de vigil\u00e2ncia [Fauset, 1994],\n\nV antagens e limita\u00e7\u00f5es\n\nAlgumas das vantagens das redes ARTs s\u00e3o:\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n104\n\n1. Teoremas [Carpenter &amp; Grossberg, 1987] mostram que as redes ARTs exibem \n\nconsider\u00e1vel estabilidade e n\u00e3o s\u00e3o perturbadas por dados esp\u00farios.\n\n2. A rede adapta-se para refletir os tipos de padr\u00f5es mais freq\u00fcentemente observados \n\nno meio, atualizando os prot\u00f3tipos das categorias de forma adequada.\n\n3. A arquitetura da ART pode facilmente ser integrada com outras teorias \n\nhier\u00e1rquicas de cogni\u00e7\u00e3o.\n\n4. Teoria da resson\u00e2ncia adaptativa.\n\nA arquitetura da ART \u00e9 suposta manter a plasticidade requerida para novos \n\npadr\u00f5es, enquanto previne a modifica\u00e7\u00e3o de padr\u00f5es que foram apresentados \u00e0 rede \n\nanteriormente. Contudo, para a rede ART1 o problema da estabilidade n\u00e3o est\u00e1 \n\ncompletamente resolvido. Se a rede recebe um n\u00famero de varia\u00e7\u00f5es sobre um padr\u00e3o \n\nde entrada armazenado, a rede pode gradativamente mudar em uma dada dire\u00e7\u00e3o no \n\nespa\u00e7o dos padr\u00f5es. Cada varia\u00e7\u00e3o pode assemelhar-se ao prot\u00f3tipo da categoria \n\narmazenada previamente, aproximando-se o suficiente para ser substitu\u00edda dentro da \n\nmesma categoria. Isto resultaria em uma mudan\u00e7a suficientemente grande, de modo \n\nque a rede n\u00e3o possa mais reconhecer o padr\u00e3o original. Outro problema da rede ART \n\n\u00e9 a sensibilidade \u00e0 ordem com o qual os padr\u00f5es s\u00e3o apresentados a rede [Kung, \n\n1993],\n\nO grau que a ART usa para discriminar classes distintas de padr\u00f5es de entrada \n\npode ser variado por uma escolha adequada do valor do par\u00e2metro de vigil\u00e2ncia. \n\nEnt\u00e3o a granularidade com o qual os padr\u00f5es de entradas s\u00e3o classificados \u00e9 \n\ndeterminado pelo fator de vigil\u00e2ncia. Um valor grande causaria uma discrimina\u00e7\u00e3o \n\nmais fina entre as classes para uma dado conjunto de padr\u00f5es de entrada (ou seja, o \n\nn\u00famero de categorias formadas \u00e9 maior). Por outro lado, um valor menor deste \n\npar\u00e2metro permitiria que padr\u00f5es com ru\u00eddos fossem classificados dentro da mesma \ncategoria.\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n105\n\nAplica\u00e7\u00f5es\n\nRedes ARTs est\u00e3o sendo usadas em grande n\u00famero de aplica\u00e7\u00f5es importantes, \n\nincluindo diagn\u00f3stico, processamento de voz e imagens, controle, avalia\u00e7\u00e3o de riscos. \n\nPara exemplificar pode-se citar:\n\n\u2022  Classifica\u00e7\u00e3o [Carpenter &amp; Grossberg, 1987]\n\n\u2022 Diagn\u00f3stico de falhas [Kalkunte et al, 1992]\n\n\u2022 An\u00e1lise do mercado de a\u00e7\u00f5es [Szu et al., 1992]\n\n\u2022  Sistema de recupera\u00e7\u00e3o de Informa\u00e7\u00f5es [Patterson, 1995]\n\n\u2022 Processo de Monitoramento e Controle [Whiteley &amp; Davis, 1993],\n\n\u2022 Reconhecimento de Caracteres [Gan &amp; L u a , 1992],\n\n4.3.5 Rede de Hopfield\n\nEm 1982, o f\u00edsico americano J.J. Hopfield trouxe as Redes Neuronais \n\nArtificiais (RNA) de volta da avers\u00e3o do qual elas tinham sofrido nos anos setenta e \n\nin\u00edcio dos anos oitenta. Seu artigo \u201cNeural Networks and Physical Systems with \n\nEmergent Collective Computational Abilities\u201d [Hopfield, 1982] foi um marco para \n\nemergir a nova era das pesquisas de RNA, introduzindo a fun\u00e7\u00e3o de transfer\u00eancia n\u00e3o \n\nlinear para a avalia\u00e7\u00e3o da sa\u00edda final dos neur\u00f4nios.\n\nA rede de Hopfield performa uma das tarefas mais interessantes que o c\u00e9rebro \n\n\u00e9 capaz de fazer, auto-associa\u00e7\u00e3o, por meio do qual uma imagem armazenada (ou \n\nqualquer outra informa\u00e7\u00e3o armazen\u00e1vel atrav\u00e9s de um vetor ou uma matriz \n\nmultidimensional) \u00e9 regenerada de dados parciais ou corruptos.\n\nHopfield dedicou sua aten\u00e7\u00e3o a duas propriedades da interconex\u00e3o das c\u00e9lulas \n\nde sistemas n\u00e3o lineares simples: primeiro, que tais sistemas t\u00eam estados est\u00e1veis que \n\nsempre ser\u00e3o alcan\u00e7ados se a rede for iniciada em um estado similar e, segundo, o \n\nfato que tais estados podem ser criados pela mudan\u00e7a do comprimento das \n\ninterconex\u00f5es entre as c\u00e9lulas.\n\nA an\u00e1lise \u00e9 feita baseada em uma defini\u00e7\u00e3o de \u201cenergia\u201d na rede e a prova que \n\na rede opera para minimizar esta energia quando instalado dentro do padr\u00e3o est\u00e1vel. \n\nPara alcan\u00e7ar um m\u00ednimo, a fun\u00e7\u00e3o de energia deve diminuir sempre que um \n\nneur\u00f4nio muda de estado.\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n106\n\nHopf\u00edeld ilustrou uma aplica\u00e7\u00e3o clara na F\u00edsica (modelo de spin-glass) na \n\nminimiza\u00e7\u00e3o da superf\u00edcie de energia para encontrar solu\u00e7\u00f5es est\u00e1veis no padr\u00e3o da \n\nrede de ativa\u00e7\u00e3o. Esta aplica\u00e7\u00e3o contribuiu para uma compreens\u00e3o formal matem\u00e1tica \n\nque seria usada para estabilizar uma base de trabalho renovada das RNAs.\n\nAs redes de Hopf\u00edeld s\u00e3o redes recorrentes de camada \u00fanica com matriz de \n\npesos sim\u00e9trica no qual os elementos da diagonal principal s\u00e3o todos nulos. Um \n\nexemplo de uma rede de Hopf\u00edeld \u00e9 dado na Figura 4.10.\n\nEstas redes armazenam algum n\u00famero P de padr\u00f5es prot\u00f3tipos x 1, x2, ..., xp \n\nchamados atratores de ponto-f\u00edxo. A localiza\u00e7\u00e3o dos atratores s\u00e3o determinadas pela \n\nmatriz de pesos W. Os padr\u00f5es armazenados podem ser especificados calculando-os \n\ndiretamente tal como na aprendizagem de Hebb ou podem ser aprendidas atrav\u00e9s de \n\nalgum esquema de atualiza\u00e7\u00e3o gradiente descendente tal como a Regra Delta.\n\nUma vez que a rede aprendeu os P padr\u00f5es prot\u00f3tipos, eles podem ser usados \n\npara um relembrar associativo. Para recordar um padr\u00e3o xk, a rede opera \n\nrecursivamente pela alimenta\u00e7\u00e3o dos sinais de sa\u00eddas da rede de volta \u00e0s entradas \n\nrepetidamente em cada tempo t at\u00e9 a rede finalmente estabilizar. Iniciando em algum \n\nestado inicial arbitr\u00e1rio, um sinal de entrada x(0 ) \u00e9 \u201cclam ped\u2019 dentro das conex\u00f5es da \n\nrede no tempo 0, e as sa\u00eddas s\u00e3o ent\u00e3o calculadas pelas unidades. Para sistemas de \n\ntempo discreto, as sa\u00eddas s\u00e3o determinadas pela equa\u00e7\u00e3o:\n\npara i -  1,2,...,\u00ab, onde o limiar 9  \u00e9 uma constante n\u00e3o-negativa e onde usa-se a \n\nfun\u00e7\u00e3o de ativa\u00e7\u00e3o bipolar, x, e  { - 1, 1} com\n\n\u2022*, 0  + 1) = s g n ( \u00a3  wijXj (t) -  9)\n(4.5)\n\nse x  > 0  \nse x  &lt;0\n\n(4.6)\n\ne por conven\u00e7\u00e3o\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 107\n\nx t (t + 1) = x ({t) se x  = 0. (4.7)\n\nCome\u00e7ando com um vetor x como entrada, as sa\u00eddas s\u00e3o calculadas de acordo \n\ncom a equa\u00e7\u00e3o (4.5) e usadas como entradas (feed back) atrav\u00e9s de algum esquema de \n\nrecurs\u00e3o/adapta\u00e7\u00e3o. Novas sa\u00eddas s\u00e3o ent\u00e3o calculadas e novamente usadas como \u00e0s \n\nentradas no pr\u00f3ximo tempo. Este processo \u00e9 repetido recursivamente que at\u00e9 a rede \n\nestabilize em um ponto fixo, correspondendo a um padr\u00e3o aprendido.\n\nDurante o relembrar, uma rede Hopf\u00edeld gen\u00e9rica pode alcan\u00e7ar um dos dois \n\nestados: ( 1) um ciclo, no qual para algum t suficientemente grande e um per\u00edodo fixo \n\nT>1, x(t +T) = x(t) ou (2) um ponto fixo definido por x(t +1) = x(t) para t \n\nsuficientemente grande.\n\nPara funcionar como uma mem\u00f3ria associativa, a rede deveria convergir para \n\nalgum ponto fixo pr\u00f3ximo do vetor de entrada x(0 ) ap\u00f3s algum n\u00famero finito de \n\nitera\u00e7\u00f5es. Este seria o caso para uma matriz de pesos W sim\u00e9trica.\n\nC aracteriza\u00e7\u00e3o da Fun\u00e7\u00e3o energia\n\nUm dos aspectos mais interessantes das Redes Hopf\u00edeld \u00e9 a caracteriza\u00e7\u00e3o do \n\nestado da rede com uma fun\u00e7\u00e3o energia. Devido ao fato que a matriz dos pesos nesta \n\nrede ser sim\u00e9trica \u00e9 poss\u00edvel definir uma fun\u00e7\u00e3o energia E, onde\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 108\n\n(4.8)\n\nEsta fun\u00e7\u00e3o \u00e9 similar a fun\u00e7\u00e3o energia que caracteriza materiais magn\u00e9ticos em f\u00edsica, \n\nusando um simples modelo \u201cspin\u201d onde os \u00e1tomos do material podem assumir uma \n\ndas duas orienta\u00e7\u00f5es + ou - (para cima ou para baixo). Esta analogia f\u00edsica pode ser \n\nusada para provar v\u00e1rias propriedades das Redes Hopf\u00edeld j\u00e1  que existe um \n\nisomorfirmo entre o modelo \u201cspin\u201d e as redes.\n\nHopf\u00edeld foi capaz de provar que, como os sistemas de RNA evoluem de \n\nacordo com suas din\u00e2micas, a energia deve eventualmente alcan\u00e7ar um estado \n\nest\u00e1vel, pois a defini\u00e7\u00e3o da fun\u00e7\u00e3o energia E n\u00e3o pode crescer ap\u00f3s cada adapta\u00e7\u00e3o \n\n[Hopf\u00edeld, 1982], Ela deve decrescer ou pelo menos permanecer a mesma. Devido ao \n\nfato que existem um n\u00famero finito de estados, a rede deve eventualmente convergir \n\npara um m\u00ednimo local. A energia m\u00ednima corresponde a um atrator de ponto-fixo. O \n\nestado do sistema na converg\u00eancia determina o padr\u00e3o de sa\u00edda. Ele, na verdade, \n\ndepende do estado inicial da rede e da matriz de pesos W. Para W fixo, todos os \n\nestados iniciais dentro de uma certa dist\u00e2ncia de um ponto atrator formam a chamada \n\nbacia de atra\u00e7\u00e3o como ilustrado na Figura 4.11. De qualquer estado inicial \n\ndeterminado por um padr\u00e3o de entrada, o sistema evolui movimentando-se abaixo da \n\nsuperf\u00edcie de energia at\u00e9 um m\u00ednimo local a ser alcan\u00e7ado.\n\nFigura 4.11: Atratores de pontos fixos e bacias de atra\u00e7\u00e3o [Patterson, 1995].\n\nA discuss\u00e3o acima aplica-se a Rede de Hopf\u00edeld discreta. A rede foi \n\ngeneralizada para operar em tempo cont\u00ednuo e produzir sa\u00eddas com valores cont\u00ednuos.\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n109\n\nA vers\u00e3o cont\u00ednua da Rede Hopfield [Hopf\u00edeld, 1984] \u00e9 uma generaliza\u00e7\u00e3o \n\ndireta da discreta atrav\u00e9s do uso de fun\u00e7\u00f5es de ativa\u00e7\u00e3o cont\u00ednuas no lugar da fun\u00e7\u00e3o \n\nbipolar. Tipicamente a fun\u00e7\u00e3o de ativa\u00e7\u00e3o sigm\u00f3ide ou tangente hiperb\u00f3lica \u00e9 usada. \n\nA  din\u00e2mica da rede \u00e9 modelada em tempo cont\u00ednuo e a fun\u00e7\u00e3o de energia \u00e9 dada por:\n\nE  = - \\ \u00cd L l L \u2122 i j x j X j + \u00ed l \\ X\u2018 r \\ x ) d x  (4\nZ&lt;=1 J i = l  \u00b0\n\nV antagens e Limita\u00e7\u00f5es\n\nEm cada uso das redes de Hopfield para mem\u00f3ria associativa e otimiza\u00e7\u00e3o os \n\nproblemas de aplica\u00e7\u00e3o s\u00e3o resolvidos quando a rede alcan\u00e7a um estado de equil\u00edbrio \n\nem um m\u00ednimo de energia.\n\nA r\u00e1pida capacidade computacional da rede \u00e9 sua maior vantagem. Ela surge \n\ncomo conseq\u00fc\u00eancia da natureza paralela de seu processamento de converg\u00eancia.\n\nA rede apresenta tamb\u00e9m uma s\u00e9rie de limita\u00e7\u00f5es:\n\n\u2022 Capacidade de mem\u00f3ria: Um \u201cesquecimento\u201d catastr\u00f3fico pode ocorrer se \n\ntentarmos memorizar mais padr\u00f5es do que a rede pode suportar. O n\u00famero m de \n\npadr\u00f5es de treinamento deve ser aproximadamente o n\u00famero de neur\u00f4nios n, ou \n\nmenor. Isto significa que a capacidade de mem\u00f3ria de uma rede Hopfield \u00e9 \n\nseveramente limitada..\n\n\u2022 Limita\u00e7\u00f5es de discrep\u00e2ncia: O novo padr\u00e3o a ser reconhecido como os dos padr\u00f5es \n\nde treinamento n\u00e3o deveria diferir de qualquer padr\u00e3o de treinamento por mais que \n25%.\n\n\u2022 Ortogonalidade entre os padr\u00f5es: Quanto maior a ortogonalidade (dissimilaridade) \n\nentre os padr\u00f5es de treinamento melhor o reconhecimento.\n\n\u2022  Pesos sim\u00e9tricos: A matriz de pesos tem de ser sim\u00e9trica a fim da rede alcan\u00e7ar \n\num equil\u00edbrio. Os pesos sin\u00e1pticos sim\u00e9tricos n\u00e3o s\u00e3o todos plaus\u00edveis \n\nbiologicamente, mas s\u00e3o uma limita\u00e7\u00e3o \u00fatil aqui.\n\n\u2022 Problema de m\u00ednimo local. Um desvantagem maior na rede de Hopfield \u00e9 que ela \n\npode repousar em um m\u00ednimo local em vez de um m\u00ednimo global do estado de \n\nenergia, assim associa-se um novo padr\u00e3o de entrada com um estado esp\u00fario\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n110\n\nAplica\u00e7\u00f5es\n\nPode-se citar aplica\u00e7\u00f5es desta rede em reconhecimento de padr\u00f5es, \n\nprocessamento de palavras, restaura\u00e7\u00e3o de base de dados e processamento de \nimagens.\n\nA vers\u00e3o cont\u00ednua das redes de Hopf\u00edeld foi usada primariamente em \n\naplica\u00e7\u00f5es de otimiza\u00e7\u00e3o tal como o problema do caixeiro viajante, scheduling e \n\notimiza\u00e7\u00e3o de fun\u00e7\u00f5es. Outras aplica\u00e7\u00f5es incluem processamento de imagens [Bilbro \n\net al., 1988], e controle [Patterson, 1995],\n\nQuando cria-se uma rede para resolver um problema de otimiza\u00e7\u00e3o, os pesos e \n\no bias s\u00e3o usados de modo a expressar as restri\u00e7\u00f5es do problema. Encontrar um bom \n\nconjunto de equa\u00e7\u00f5es para as restri\u00e7\u00f5es \u00e9 a chave para encontrar uma solu\u00e7\u00e3o com \n\nsucesso. Geralmente, a solu\u00e7\u00e3o da rede n\u00e3o ser\u00e1 \u00f3tima, somente pr\u00f3xima do \u00f3timo, \n\nmas \u00fatil para muitas situa\u00e7\u00f5es.\n\n4.3.6 Perceptron Multicamadas\n\nO conceito de perceptron [Rosemblatt, 1958] foi um dos desenvolvimentos \n\nmais empolgantes durante o in\u00edcio das redes neuronais artificiais. \u00c9 uma rede de \n\nprocessadores elementares (arranjados de um modo que recorda as redes neuronais \n\nbiol\u00f3gicas) que podem aprender a reconhecer e classificar padr\u00f5es automaticamente. \n\nOs processadores s\u00e3o elementos simples arranjados em uma camada. Neste \n\nperceptron cl\u00e1ssico de uma \u00fanica camada, dada duas classes de padr\u00f5es, tenta \n\nencontrar um limite de decis\u00e3o linear que separe as duas classes. Se os dois conjuntos \n\nde padr\u00f5es s\u00e3o linearmente separ\u00e1veis , o algoritmo perceptron com certeza encontra \n\num hiperplano que separa as duas classes em um n\u00famero finito de passos. Contudo, \n\nse o espa\u00e7o dos padr\u00f5es n\u00e3o \u00e9 linearmente separ\u00e1veis, o perceptron falha\n\nA demonstra\u00e7\u00e3o das limita\u00e7\u00f5es de uma rede neuronal com uma \u00fanica camada \n\nfoi um fator signif\u00edcante no decl\u00ednio do interesse por redes neuronais nos anos \n\nsetentas. O descobrimento (por diversos autores independentemente) e propaga\u00e7\u00e3o de \n\num m\u00e9todo efetivo de treinamento para uma rede neuronal multicamadas [Rumelhart \n\net al., 1986] teve um papel importante no ressurgimento das redes neuronais como \n\numa ferramenta para resolver uma ampla variedade de problemas. Neste t\u00f3pico\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n111\n\ndiscuti-se uma das arquiteturas mais populares e vers\u00e1teis, as redes fe e d  forw ard \n\nmulticamadas com aprendizado backpropagation. Este tipo de rede \u00e9 tamb\u00e9m \n\nchamada de Percetrom Multicamadas ou simplesmente backpropagation. Este \n\nm\u00e9todo de treinamento, conhecido como backpropagation ou regra delta \n\ngeneralizada \u00e9 um m\u00e9todo gradiente descendente (corre\u00e7\u00e3o de erro) simples para \n\nminimizar o erro quadrado total da sa\u00edda da rede.\n\nUma rede MLP consiste de uma camada de entrada, pelo menos uma camada \n\nintermedi\u00e1ria ou escondida, e uma camada de sa\u00edda, os neur\u00f4nios de cada camada \n\nest\u00e3o completamente interconectados (em algumas aplica\u00e7\u00f5es particulares, \n\nparcialmente interconectados) com todos os neur\u00f4nios da pr\u00f3xima camada (Figura \n4.13 - lado esquerdo).\n\nAs MLPs foram colocadas em pr\u00e1tica somente quando algoritmos de \n\naprendizagem foram desenvolvidos para elas, um deles foi o t\u00e3o conhecido algoritmo \n\nbackpropagation [Werbos, 1990; Rumelhart et al., 1986; e outros],\n\nO termo backpropagation surgiu ap\u00f3s 1985. Contudo, a id\u00e9ia b\u00e1sica do\n\nbackpropagation foi primeiro descrita por Werbos em sua tese de Ph.D. [Werbos,\n\n1974], Subseq\u00fcentemente, foi redescoberto por Rumelhart, Hinton, e Williams em\n\n1986. Uma generaliza\u00e7\u00e3o similar do algoritmo foi desenvolvido por Parker em 1985,\n\ne um algoritmo de aprendizagem similar, foi tamb\u00e9m estudado por LeCun [Lecun,\n1985],\n\nO desenvolvimento do algoritmo backpropagation representa \u201clandmark\u201d em \n\nRNA em que fornece um m\u00e9todo computacionalmente eficiente para o treinamento \n\nde perceptrons multicamadas. Embora n\u00e3o se possa dizer que o algoritmo \n\nbackpropagation resolva todos os problemas (que tem solu\u00e7\u00e3o), \u00e9 bom ressaltar que \n\nele acabou com o pessimismo sobre redes neuronais, que pode ter sido inferido pelo \n\nlivro de Minsky e Papert [Misnky &amp; Papert, 1969],\n\nDe fato, tem se tomado t\u00e3o popular que para muitos autores o termo \u201credes \n\nneuronais\u201d simplesmente significa o m\u00e9todo backpropagation. A atratividade pelo \n\nm\u00e9todo vem do conjunto de equa\u00e7\u00f5es bem-definidas e expl\u00edcitas para corre\u00e7\u00e3o dos \n\npesos. Estas equa\u00e7\u00f5es s\u00e3o aplicadas atrav\u00e9s das camadas, come\u00e7ando com a corre\u00e7\u00e3o\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n112\n\ndos pesos da \u00faltima camada (camada de sa\u00edda), e ent\u00e3o continuando para tr\u00e1s (por isto \n\no nome) em dire\u00e7\u00e3o da primeira camada (Figura 4 .12).\n\nEntrada\n\nF ig u ra  4.12 A presenta\u00e7\u00e3o esquem \u00e1tica da corre\u00e7\u00e3o dos pesos p o r backpropagation.\n\nOs neur\u00f4nios na rede MLP tem valores de entrada e sa\u00eddas cont\u00ednuos, e a \n\nfun\u00e7\u00e3o de ativa\u00e7\u00e3o n\u00e3o linear (geralmente usa-se a fun\u00e7\u00e3o sigmode). Uma regra de \n\ngradiente descendente pode ser usada para encontrar os pesos das conex\u00f5es \u00f3timas Wy \n\nque minimizam o erro global E. Uma mudan\u00e7a em um peso Awjj em um ciclo (t+1) \n\nocorre na dire\u00e7\u00e3o do gradiente negativo do erro E:\n\nAwy (t + 1) = - r j ( \u00e2 E  / \u00e2wy(t)) (4 J 0 )\n\nonde ri \u00e9 a taxa de aprendizagem. A regra do gradiente garante que ap\u00f3s um n\u00famero \n\nde ciclos, o erro E alcan\u00e7a um valor m\u00ednimo, ou o menor \u201cplat\u00f4\u201d, se o erro E  \u00e9 \n\nrepresentado como uma superf\u00edcie no espa\u00e7o dos pesos. Um erro global para o \n\ntreinamento de uma entrada pode ser calculado como segue:\n\nE  = ' L ' L Errj( P X  (4.11)\n(p) O)\n\nonde o erro pode ser dado, por exemplo, por Errj (p ) = ( y {.p) -  d j P)) 2 / 2.\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n113\n\nA regra do gradiente descendente para mudar um peso entre os neur\u00f4nios / e j \n\npode ser expresso pela regra delta:\n\nAwiJ{t + \\) = r1ErrJy i (4.12)\n\nou alternativamente pela regra delta generalizada:\n\nAwtJ (t + l) = Tj Errj g '(Uj ) yt , (4.13)\n\nonde Errj \u00e9 o erro entre o valor de sa\u00edda desejado dj e o valor yj produzido pelo\n\nneur\u00f4nio j  que pode ser simplesmente expressado por Errj = y y -  d} | . 0  valor de\n\ng  (uj) \u00e9 a derivada \u00f4 g t\u00f4 u  da fun\u00e7\u00e3o de ativa\u00e7\u00e3o g  para o net de entrada u, para um \n\nvalor particular de u/, e y t \u00e9 o valor de sa\u00edda para o neur\u00f4nio i. Quando a fun\u00e7\u00e3o de \n\nativa\u00e7\u00e3o g \u00e9 uma fun\u00e7\u00e3o log\u00edstica a derivada g \u2019(uj) \u00e9 expressada como y /l-y j). A  \n\nf\u00f3rmula acima pode ser simplificada como segue:\n\nAwy (t + 1) = ijErrjdj { \\ - d j  )dt (4.14)\n\nCada ciclo de aprendizagem (um ciclo, tamb\u00e9m chamado \u00e9poca, \u00e9 definido como o \n\nprocesso de propaga\u00e7\u00e3o atrav\u00e9s da rede usando o conjunto de treinamento e o c\u00e1lculo \n\ndo erro E) constitui-se de dois passos: (1) um passo forward, quando as entradas s\u00e3o \n\nfornecidas e propagadas atrav\u00e9s das camadas intermedi\u00e1rias para a camada de sa\u00edda;\n\n(2 ) um passo backward, quando um erro calculado na sa\u00edda e propagado para traz \n\npara calcular as mudan\u00e7as dos pesos. Esta \u00e9 a maior caracteriza\u00e7\u00e3o deste algoritmo. \n\nDurante o passo backward, um erro Ett\u00ed para um n\u00f3 interno i \u00e9 calculado pela \n\nmultiplica\u00e7\u00e3o dos erros Err} de todos os neur\u00f4nios j  para os quais o neur\u00f4nio est\u00e1 \n\nconectado pelos pesos correspondentes w&amp;. Este erro \u00e9 ent\u00e3o usado backward para \n\najustar os pesos dos neur\u00f4nios de uma camada anterior, conectada ao neur\u00f4nio /. O \n\nprocesso de treinamento \u00e9 repetido por muitas \u00e9pocas com a mesma amostra de \n\ntreinamento at\u00e9 que o erro global E  seja suficientemente pequeno.\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 114\n\nO c\u00e1lculo do erro e as mudan\u00e7a dos pesos podem tamb\u00e9m ser feitos de um \n\nmodo batch (uma agrega\u00e7\u00e3o ou um erro m\u00e9dio \u00e9 calculado para todos ou algumas \n\namostras de treinamento) ou em um modo individual (o erro \u00e9 calculado e os pesos \n\ns\u00e3o alterados ap\u00f3s cada amostra de treinamento).\n\nCada peso pode ter sua taxa de aprendizagem individual (regra delta bar \n\ndelta) [Jacobs, 1988], Se os pesos mudam alternativamente em sinal a taxa de \n\naprendizagem deveria ser diminu\u00edda. Se as mudan\u00e7as nos pesos \u00e9 est\u00e1vel, a taxa de \n\naprendizagem deve ser aumentada.\n\nExistem muitas modifica\u00e7\u00f5es e melhoramentos do algoritmo backpropagation, \n\nmas estes n\u00e3o ser\u00e3o explorados aqui [Haykin, 1994], Esta modifica\u00e7\u00f5es diferem nos \n\nseguintes pontos: c\u00e1lculo do erro, fun\u00e7\u00e3o de ativa\u00e7\u00e3o, forma de atualiza\u00e7\u00e3o dos pesos, \n\nn\u00famero de \u00e9pocas para adapta\u00e7\u00e3o dos pesos, e outros par\u00e2metros.\n\nIndependente do algoritmo de treinamento usado para uma rede MLP, existem \n\nalgumas caracter\u00edsticas comuns da arquitetura MLP. Algumas delas s\u00e3o:\n\n\u2022 As redes MLPs s\u00e3o aproximadores universais [Homik, et al. 1989; e outros]\n\n\u2022 MLPs s\u00e3o modelos de regress\u00e3o n\u00e3o linear multivariada.\n\n\u2022 MPLs podem aprender probabilidades condicionais.\n\nV antagens e limita\u00e7\u00f5es\n\nAs redes MLPs s\u00e3o capazes, pelo menos em teoria, de aproximar fun\u00e7\u00f5es \n\narbitr\u00e1rias com acur\u00e1cia desde que se forne\u00e7a um n\u00famero suficiente de camadas \n\nescondidas. Tais redes tamb\u00e9m s\u00e3o bons aproximadores de regress\u00e3o n\u00e3o linear n\u00e3o \n\nparam\u00e9tricas e s\u00e3o capazes de aprender mapeamentos desejados se um n\u00famero \n\nsuficiente de amostras de treinamento est\u00e3o dispon\u00edveis.\n\nAs redes MLPs s\u00e3o provavelmente as redes mais usadas. Contudo existem \n\ndiversos problemas. Alguns deles s\u00e3o citados abaixo:\n\n\u2022 A quest\u00e3o de como escolher no n\u00famero de neur\u00f4nios nas camadas intermedi\u00e1rias, \n\ne uma quest\u00e3o mais geral, como escolher a estrutura da rede. Existem algumas \n\nheur\u00edsticas que tentam solucionar este problema [Haykin, 1996],\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 115\n\n\u2022 Esquecimento catastr\u00f3fico, fen\u00f4meno que representa a habilidade de uma rede \n\nesquecer o que ela aprendeu de amostras anteriores quando elas n\u00e3o s\u00e3o mais \n\napresentadas, mas outras s\u00e3o. Isto \u00e9 devido a mudan\u00e7a dos pesos de acordo com o \n\nnovo padr\u00e3o apresentado [Kasabov, 1996],\n\n\u2022 Overffiting, fen\u00f4meno que indica que a RN aprendeu muito bem os dados de \n\ntreinamento (decorou), que podem conter ru\u00eddos. Em tais casos a rede pode n\u00e3o \n\ngeneralizar os novos dados. Existem alguns caminhos para superar este problema: \n\ncessar o treinamento antes da rede chegar ao erro m\u00ednimo ou usar menos neur\u00f4nios \n\nescondidos (mais neur\u00f4nios escondidos leva a melhores aproxima\u00e7\u00f5es) [Kasabov,\n1996],\n\n\u2022 A taxa de convergencia do algoritmo de aprendizagem backpropagation tende a \n\nser muito lento (ordem de converg\u00eancia linear), o que o toma computacionalmente \n\ncaro [Haykin, 1996],\n\n\u2022 A superf\u00edcie de erro pode influenciar na performance da rede quando existem \n\nm\u00ednimos locais al\u00e9m do m\u00ednimo global. A rede, neste caso pode convergir para um \n\nm\u00ednimo local.\n\n\u2022 Existem problemas na escolha do n\u00famero \u00f3timo de camadas escondidas e de n\u00f3s. \n\nAplica\u00e7\u00f5es\n\nAs redes MLP t\u00eam provado ser eficiente como ferramentas de mapeamento \n\npara uma ampla variedade de problemas, e consequentemente, t\u00eam sido usadas \n\nextensivamente e com sucesso pelos pesquisadores em v\u00e1rios dom\u00ednios de aplica\u00e7\u00f5es, \n\nincluindo engenharia, direito, ci\u00eancia da computa\u00e7\u00e3o, controle, estat\u00edstica, medicina, \n\nmanufatura, transportes, finan\u00e7as, telecomunica\u00e7\u00f5es, e muito mais. Elas podem \n\ncompetir com outras arquiteturas para a maioria das \u00e1reas de aplica\u00e7\u00f5es com poss\u00edvel \n\nexce\u00e7\u00e3o de categorias que dependem de uma aprendizagem n\u00e3o supervisionada. A \n\nampla popularidade das redes MLP para tal gama de aplica\u00e7\u00f5es, naturalmente, vem \n\nde sua habilidade de fazer mapeamentos. Se tem-se um bom conjunto de dados de \n\ntreinamento para alguma aplica\u00e7\u00e3o, \u00e9 prov\u00e1vel que uma rede MLP com uma ou duas \n\ncamadas escondidas pode aprender os padr\u00f5es para uma tarefa determinada. Embora \n\nsua performance ser t\u00e3o boa quanto outras redes e outras t\u00e9cnicas (n\u00e3o neural) na\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n116\n\nsolu\u00e7\u00e3o de diversos problemas, pode ser dif\u00edcil trein\u00e1-las. Mas, em geral, quando \n\nexiste d\u00favida em rela\u00e7\u00e3o a qual arquitetura usar para uma dada aplica\u00e7\u00e3o, as redes \n\nMLP com backpropagation podem sempre ser consideradas. Isto se um conjunto de \n\ntreinamento apropriado estiver dispon\u00edvel.\n\nDevido a variedade de aplica\u00e7\u00f5es das redes MLP, s\u00e3o citados alguns exemplos \n\nonde estas redes foram usadas com sucesso:\n\nClassifica\u00e7\u00e3o e Diagn\u00f3stico: Classifica\u00e7\u00e3o de c\u00e9lulas para Diagn\u00f3stico de C\u00e2ncer \n\n[Moallemi, 1991] e Identifica\u00e7\u00e3o de Falhas no Sistema Telef\u00f4nico [Sone, 1993], \n\nC ontrole e Otimiza\u00e7\u00e3o: Autonomouly Driven Land Vehicle [Thorpe et al., 1991] e \n\n[Kanade et al., 1994] e Controlador Inteligente para Fabrica\u00e7\u00e3o de A\u00e7o [Widrow et \n\nal., 1994],\n\nPrevis\u00e3o e Predi\u00e7\u00e3o: Previs\u00e3o de S\u00e9rie Temporais Financeiras [Patterson et al.,\n\n1993], Previs\u00e3o dos Retornos de A\u00e7\u00f5es [Barr &amp; Mani, 1994], Previs\u00e3o de S\u00e9ries \n\nTemporais Ca\u00f3ticas [Lapedes &amp; Farber, 1988] e Predicting Creditworthiness for Loan \n\nApplications [Morose, 1990; Morose, 1993],\n\nReconhecimento de Padr\u00f5es: Reconhecimento de Caracteres Manuscritos \n\n[Yanicoglu &amp; Sandon, 1993], Detec\u00e7\u00e3o de Ataque Epil\u00e9tico [Hamilton &amp; Hufnagel, \n\n1992] e Identifica\u00e7\u00e3o Autom\u00e1tica de Indiv\u00edduos [Colombi et al., 1993],\n\n4 .3 .7  Fun\u00e7\u00e3o de Base Radial (Radial Base Function - RBF)\n\nAs redes MLP com seus algoritmos de aprendizagem foram um passo gigante \n\nna \u00e1rea de RNAs. Elas influenciaram muito no desenvolvimento de outros modelos de \n\nredes que usaram algumas de suas id\u00e9ias, mas que tamb\u00e9m geraram novas id\u00e9ias. \n\nUma destas redes \u00e9 a Fun\u00e7\u00e3o de Base Radial.\n\nAs perspectivas (combinada com simplicidade) \u00e9 a atra\u00e7\u00e3o principal RBFs \n\nno contexto das pesquisas de RNAs. De v\u00e1rias maneiras as redes RBFs agem como \n\nponte, ligando uma variedade de \u00e1reas da ci\u00eancia aparentemente diferentes.\n\nA Fun\u00e7\u00e3o de Base Radial foi usada como um o artif\u00edcio de c\u00e1lculo desde o \n\n\u00faltimo s\u00e9culo em termos da intera\u00e7\u00e3o eletromagn\u00e9tica entre part\u00edculas carregadas. \n\nEsta analogia foi explorada pela Corpora\u00e7\u00e3o NESTOR no in\u00edcio dos anos oitenta na\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n117\n\nintrodu\u00e7\u00e3o da rede Reduced Coulomb Energy - uma arquitetura originalmente n\u00e3o \n\nsupervisionada e com categariza\u00e7\u00e3o que pode ser considerada como a precursora da \n\nrede RBF. Alguns dos princ\u00edpios b\u00e1sicos das redes neuronais incorporado na Rede \n\nRBF tem emergido nas \u00faltimas duas d\u00e9cadas da neurobiologia na forma de modelos \n\nde mem\u00f3ria (como o SOFM de K ohonen).\n\nA incorpora\u00e7\u00e3o da Fun\u00e7\u00e3o de Base Radial dentro da \u00e1rea de redes neuronais \n\nfoi originalmente performada a fim de trazer algum tipo de interpreta\u00e7\u00e3o do que \n\nsignifica aprendizagem e generaliza\u00e7\u00e3o\u201d em redes neuronais artificiais. A \n\nmotiva\u00e7\u00e3o prim\u00e1ria foi dentro da teoria de aproxima\u00e7\u00e3o de fun\u00e7\u00f5es por um processo \n\nde interpola\u00e7\u00e3o, principalmente por Powell [Powell, 1985] e Micchelli [Micchelli,\n1986],\n\nUma arquitetura geral das redes RBFs \u00e9 mostrada no lado direito da Figura \n\n4.13. Uma rede RBF consiste de 3 camadas. A primeira \u00e9 a camada das p entradas. \n\nElas s\u00e3o completamente interconectadas aos neur\u00f4nios da segunda camada. Um n\u00f3 \n\nescondido tem uma fun\u00e7\u00e3o de base radial (por isto o nome da rede) como uma fun\u00e7\u00e3o \n\nde ativa\u00e7\u00e3o. Esta fun\u00e7\u00e3o \u00e9 sim\u00e9trica radialmente (por exemplo, fun\u00e7\u00e3o gaussiana);\n\nf ( x )  = exp[- (x -  //)* / 2 cr2] (4.15)\n\nonde ( i e a  s\u00e3o dois par\u00e2metros significando a m\u00e9dia e o desvio padr\u00e3o da vari\u00e1vel de \n\nentrada x. Para um n\u00f3 intermedi\u00e1rio particular i, sua R B F j est\u00e1 centrada em c; e \u00e9 \n\nrepresentada pelo vetor de pesos (wj\u201e w2i, ..., wp;) entre os p n\u00f3s de entradas e o n\u00f3 \n\nescondido i. O desvio padr\u00e3o para este cluster define o range para a R B Fj. Uma \n\nfun\u00e7\u00e3o de base radial \u00e9 n\u00e3o monot\u00f4nica em constraste com a fun\u00e7\u00e3o sigmoidal. A \n\nsegunda camada \u00e9 conectada com a camada de sa\u00edda. Os n\u00f3s na sa\u00edda realizam uma \n\nfun\u00e7\u00e3o soma simples com uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o de limear linear.\n\nO treinamento de uma rede RBF consiste de duas fases: (1) ajustar as fun\u00e7\u00f5es \n\nde base radial dos neur\u00f4nios escondidos aplicando um m\u00e9todo de clusteriza\u00e7\u00e3o \n\nestat\u00edstica; isto representa a fase de aprendizagem n\u00e3o supervisionada; (2 ) aplicando \n\num algoritmo gradiente descendente (como backpropagation) ou um algoritmo de\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n118\n\nregress\u00e3o n\u00e3o linear para ajustar as conex\u00f5es da segundo camada; est\u00e1 \u00e9 uma fase de \n\naprendizagem supervisionada.\n\nDurante o treinamento os seguintes par\u00e2metros das redes RBFs s\u00e3o ajustados:\n\n\u2022  A posi\u00e7\u00e3o n-dimensional dos centros c{ das RBF\u00ed. Isto pode ser encontrado usando \n\no algoritmo de clusteriza\u00e7\u00e3o K-means; o algoritmo encontra k (n\u00famero de \n\nneur\u00f4nios escondidos) centros que minimizam a dist\u00e2ncia m\u00e9dia entre as amostras \n\nde treinamentos e os centros mais pr\u00f3ximos;\n\n\u2022  o par\u00e2metro de desvio Oj para cada RBFj; \u00e9 definido usando dist\u00e2ncia m\u00e9dia aos \n\ncentros dos m-clusters mais pr\u00f3ximos;\n\n<Tt =\nahs(ct - c S 1/2\n\nm\n\n(4.16)\n\nonde Ciq \u00e9 o centro do p-\u00e9simo cluster mais pr\u00f3ximo do cluster i;\n\n\u2022 os pesos da segunda camada de conex\u00f5es.\n\nA Figura 4.13 contrasta as redes MLP e RBF. Primeiramente note a \n\nheterogeneidade dos neur\u00f4nios da RBF (neur\u00f4nios lineares e n\u00e3o lineares). A \n\ndiferen\u00e7a prim\u00e1ria entre as duas redes est\u00e1 na natureza de suas fun\u00e7\u00f5es de ativa\u00e7\u00e3o. \n\nOs n\u00f3s nas camadas escondidas em uma MLP formam uma fun\u00e7\u00e3o de base sigmoidal \n\nque \u00e9 diferente de zero sobre uma regi\u00e3o infinitamente grande da espa\u00e7o de entrada, \n\nenquanto a fun\u00e7\u00e3o de base em uma RBF cobre somente regi\u00f5es localizadas pequenas. \n\nEnquanto alguns problemas podem ser resolvidos mais eficientemente com fun\u00e7\u00e3o de \n\nbase sigmoidal outros s\u00e3o mais eficientes para fun\u00e7\u00e3o de base localizadas. Por\u00e9m \n\nRBFs t\u00eam maior poder de clusteriza\u00e7\u00e3o local que o perceptron convencional (como a \nMLP).\n\n\n\nCap\u00edtulo 4  - Redes Neuronais Artificiais\n119\n\n*\n\nE w x\n\n'T '\nS ( x  -W ) 2 A\n\n^^?Pj52\u00c8x*.V\n\nFigura 4.13: Estrutura das redes MLP e RBF [Pandya &amp; Macy, 1995].\n\nVantagens e Limita\u00e7\u00f5es\n\nTanto a RBF quanto a MLP s\u00e3o exemplos de redes neuronais (feedforward) \n\nn\u00e3o-lineares. Ambas s\u00e3o aproximadores universais, sendo sempre poss\u00edvel uma RBF \n\nser capaz de precisamente imitar uma espec\u00edfica MLP, ou vice-versa (Haykin, 1990). \n\nContudo, as seguintes vantagens das redes RBFs sob as redes MLP com \n\nbackpropagation tem sido experimentalmente e teoricamente provados:\n\n1. O treinamento nas Redes RBFs s\u00e3o mais r\u00e1pidos que o treinamento em um MLP \n\ncom backpropagtion de tamanho compar\u00e1vel;\n\n2. Uma melhor generaliza\u00e7\u00e3o \u00e9 encontrada nas redes RBFs;\n\n3. As redes RBFs tem converg\u00eancia muito mais r\u00e1pida que as redes multicamadas \n\nconvencionais com fun\u00e7\u00e3o e ativa\u00e7\u00e3o sigmoidal, pois qualquer fun\u00e7\u00e3o pode ser\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n120\n\naproximadamente uma combina\u00e7\u00e3o linear de fun\u00e7\u00f5es de bases fatoriz\u00e1veis \najustada localmente.\n\n4. N\u00e3o existe o problema do m\u00ednimo local.\n\n5. A rede RBF pode ser interpretada como um modelo conexionista difuso pois as \n\nfun\u00e7\u00f5es de base radial podem ser consideradas como as fun\u00e7\u00f5es de pertin\u00eancias.\n\n6 . A camada escondida t\u00eam uma interpreta\u00e7\u00e3o muito mais clara que as redes MT.P \n\ncom backpropagation. \u00c9 mais f\u00e1cil explicar o que uma rede RBF aprende que uma \n\nMLP com backpropagation.\n\nExistem tamb\u00e9m as desvantagens de usar uma RBF, uma delas \u00e9 encontrar o \n\nn\u00famero apropriado de neur\u00f4nios escondidos (centros). Uma aprendizagem n\u00e3o \n\nsupervisionada pode ser necess\u00e1ria para encontrar o n\u00famero de clusters. O n\u00famero de \n\nneuronios escondidos e ent\u00e3o setado igual a este n\u00famero.\n\nAplica\u00e7\u00f5es\n\nO range de aplica\u00e7\u00f5es das redes RBFs cobertos na literatura \u00e9 muito amplo, \n\ncomo ilustrado pela seguinte lista representativa:\n\n\u2022 Processamento de Imagens :[ Saha et al., 1991]; [Poggio e Edelman, 1990]\n\n\u2022 Reconhecimento de Voz [Ng e Lippmann, 1991]; [Niranjan e Fallside, 1990]\n\n\u2022 An\u00e1lise de S\u00e9ries Temporais [He &amp; Lapedes, 1991]; [Moody &amp; Darken, 1989]; \n\n[Broomhead &amp; Lowe, 1988]\n\n\u2022 Equaliza\u00e7\u00e3o Adaptativa [Chen et al., 1992]; [Kassam &amp; Cha, 1993]\n\n\u2022 Diagn\u00f3stico M\u00e9dico [Lowe &amp; Webb, 1990],\n\n4.4 Um m\u00e9todo h\u00edbrido: FAN ( Free Associative Neurons)\n\n4.4.1 Introdu\u00e7\u00e3o\n\nFree Associative Neurons (FAN) \u00e9 um exemplo de sistema h\u00edbrido. A base do \n\nFAN s\u00e3o as redes conexionistas, modelagem difusa e representa\u00e7\u00e3o de padr\u00f5es. FAN \n\n\u00e9 baseado fracamente na no\u00e7\u00e3o do aprendizado por adapta\u00e7\u00e3o neuronal; utiliza \n\nt\u00e9cnicas de conjuntos difusos para promover a granularidade de informa\u00e7\u00f5es; e\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 121\n\npermite incluir diferentes m\u00e9todos de associa\u00e7\u00e3o de padr\u00f5es para melhorar a sua \n\ncapacidade de aprendizado [Raitz, et al. 1997],\n\n4.4.2 FAN\n\nA motiva\u00e7\u00e3o para o desenvolvimento de FAN foi elaborar um m\u00e9todo capaz \n\nde simular abstra\u00e7\u00f5es. Devido a esta capacidade cognitiva, os seres humanos \n\ncompreendem um cen\u00e1rio completo baseado apenas nas partes que o comp\u00f5em. De \n\nfato, na linguagem natural as pessoas resumem a informa\u00e7\u00e3o, classificando objetos \n\nem estruturas de categorias de similares (palavras), evitando a sobrecarga de dados \n\n[Zadeh, 1996], Em FAN, a no\u00e7\u00e3o de classifica\u00e7\u00e3o de padr\u00f5es \u00e9 feita por tr\u00eas \n\nprocessos: (a) expans\u00e3o do espa\u00e7o de entrada; (b) proje\u00e7\u00e3o da vizinhan\u00e7a do padr\u00e3o \n\nresultante; (c) quantifica\u00e7\u00e3o e aprendizado do grau de similaridade entre as classes \n\nFAN e as proje\u00e7\u00f5es dos padr\u00f5es.\n\nEm FAN, cada padr\u00e3o de entrada \u00e9 expandido em uma vizinhan\u00e7a difusa. \n\nCada conjunto suporte desta vizinhan\u00e7a \u00e9 a combina\u00e7\u00e3o dos valores das \n\ncaracter\u00edsticas pr\u00f3ximos dos originais. O grau de similaridade entre a vizinhan\u00e7a \n\ndifusa e o padr\u00e3o original de entrada \u00e9 feita atrav\u00e9s das t\u00e9cnicas utilizadas na teoria \n\ndos conjuntos difusos [Klir &amp; Yuan, 1995], O aprendizado acontece atrav\u00e9s da \n\nproje\u00e7\u00e3o de toda a vizinhan\u00e7a difusa no espa\u00e7o FAN. Existe uma unidade FAN para \n\ncada classe do dom\u00ednio do problema. Cada unidade \u00e9 um grid composto por todas as \n\ncombina\u00e7\u00f5es de caracter\u00edsticas observadas em sua classe correspondente (Figura \n\n4.14). Durante o treinamento, cada combina\u00e7\u00e3o \u00e9 representada por uma c\u00e9lula difusa \n\nque cont\u00e9m um peso correspondente \u00e0 sua freq\u00fc\u00eancia de ocorr\u00eancia e grau de \n\npertin\u00eancia. O treinamento \u00e9 baseado no refor\u00e7o na c\u00e9lula (se a classifica\u00e7\u00e3o foi \n\ncorreta) ou em esquecimento (se houve uma classifica\u00e7\u00e3o incorreta).\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais\n122\n\nFigura 4.14: Arquitetura do FAN.\n\nAplica\u00e7\u00f5es\n\nFAN foi aplicado em problemas pr\u00e1ticos. Resultados excelentes foram obtidos\n\nem tr\u00eas problemas de classifica\u00e7\u00e3o [Raittz et al., 1997]: (a) Os dados da IRIS de\n\nFisher; (b) Classifica\u00e7\u00e3o de cromossomos, segundo o grupo de Denver, com os dados\n\nde Copenhagen; e (c) Diagn\u00f3stico financeiro de empresas baseados em testes \nfinanceiros.\n\nCaracter\u00edsticas\n\nA principal caracter\u00edstica observada nestas aplica\u00e7\u00f5es \u00e9 a capacidade de \n\ndescobrir gradualmente as classes. FAN define as classes durante a primeira \u00e9poca de \n\ntreinamento. Ou seja, ele reconhece uma classe antes mesmo de processar todo o \n\nconjunto de treinamento. Este comportamento parece indicar que o treinamento em \n\nFAN ocorre com crescente capacidade de generaliza\u00e7\u00e3o. As unidades FAN acumulam \n\nconhecimento durante o processo de treinamento de forma que as modifica\u00e7\u00f5es nos \n\npesos se tomam progressivamente menores. Em grandes conjuntos de treinamento, os\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 123\n\n\u00faltimos padr\u00f5es s\u00e3o vistos mais como dados de teste, causando modifica\u00e7\u00f5es muito \n\npequenas na rede FAN.\n\nOs resultados obtidos usando FAN s\u00e3o compar\u00e1veis aos m\u00e9todos tradicionais \n\nde redes neuronais , em termos de classifica\u00e7\u00e3o e superior em termos de estabilidade \n\nno aprendizado e capacidade de generaliza\u00e7\u00e3o\n\n4.5 Conclus\u00f5es\n\nDiversos modelos conexionistas foram introduzidos neste cap\u00edtulo. Eles s\u00e3o \n\ncaracterizados pelos tipos de neur\u00f4nios usados, a organiza\u00e7\u00e3o de sua estrutura \n\nconexionista e pelos m\u00e9todos de aprendizagem. Por esta raz\u00e3o, eles apresentam \n\ndiferentes propriedades que podem ser usadas para muitos problemas distintos. \n\nPor\u00e9m, todos os modelos s\u00e3o caracterizadas por algumas caracter\u00edsticas em comum: \n\naprendizagem, generalidade, robustez e processamento massivamente paralelo.\n\nUma destas caracter\u00edsticas, o processamento paralelo, torna as RNAs muito \n\natrativas para realiza\u00e7\u00e3o de hardwares. Este processamento massivamento paralelo \n\ntom a poss\u00edvel a constru\u00e7\u00e3o de m\u00e1quinas que s\u00e3o mais r\u00e1pidas que o c\u00e9rebro humano \n\npara resolver problemas dif\u00edceis.\n\nDepois de mais de 10 anos em que as pesquisas sobre RNAs permaneceram \n\nem laborat\u00f3rios, a d\u00e9cada de oitenta viu uma explos\u00e3o de interesse pelo dom\u00ednio.\n\nHoje, aplica\u00e7\u00f5es v\u00e3o desde reconhecimento de padr\u00f5es at\u00e9 previs\u00f5es \n\nfinanceiras. Todas estas aplica\u00e7\u00f5es s\u00e3o baseadas nas habilidades das RNs aprenderem \n\nde dados ou regras e generalizar sobre dados n\u00e3o vistos anteriormente. As redes \n\nfornecem uma aproxima\u00e7\u00e3o de uma fun\u00e7\u00e3o objetivo que mapeia o espa\u00e7o do dom\u00ednio \n\ndentro de um espa\u00e7o solu\u00e7\u00e3o. As RNAs facilitam o mapeamento de dados \n\naproximados, o que significa que elas podem trabalhar com dados ausentes, dados \n\nincompletos e dados corrompidos (com ru\u00eddos). As sa\u00eddas das redes podem ter \n\ndiversos significados, isto \u00e9, probabilidades, certezas, valores reais, conceitos \n\nsimb\u00f3licos, categorias, etc..\n\nReconhecimento e classifica\u00e7\u00e3o de padr\u00f5es foi uma das primeiras aplica\u00e7\u00f5es \n\ndas RNAs. Com efeito, o perceptron foi concebido principalmente como instrumento \n\ncapaz de reconhecer letras. A principal raz\u00e3o \u00e9 que reconhecimento e classifica\u00e7\u00e3o de\n\n\n\nCap\u00edtulo 4 - Redes Neuronais Artificiais 124\n\npadr\u00f5es \u00e9 uma tarefa geralmente desempenhado muito melhor usando a capacidade \n\ncognitiva do homem do que a execu\u00e7\u00e3o de um algoritmo.\n\nOs paradigmas mais comum de aprendizagem no caso de reconhecimento de \n\npadr\u00f5es \u00e9 o supervisionado associado com uma rede multi-camadas (MLP e RBF). \n\nDevido a sua disponibilidade, a regra back-propagation \u00e9 freq\u00fcentemente usada, \n\nassim como suas variantes. Entretanto bons resultados s\u00e3o obtidos tamb\u00e9m com \n\naprendizagem competitiva de Kohonen. Este \u00faltimo \u00e9 bastante usado quando n\u00e3o se \n\nsabe quantas classes poss\u00edveis existem a identificar. Tamb\u00e9m tem se usado, mas com \n\nmenos freq\u00fc\u00eancia, uma varia\u00e7\u00e3o supervisionada da rede de Kohonen, a LVQ.\n\nNeste cap\u00edtulo foi apresentado um m\u00e9todo de aprendizagem h\u00edbrida, o qual \n\nrepresenta uma nova forma de reconhecimento de padr\u00f5es. FAN \u00e9 baseado no \n\naprendizado conexionista e modelagem difusa. FAN \u00e9 constitu\u00eddo por unidades \n\nindependentes com capacidade aut\u00f4noma de aprendizagem. O poder de \n\naprendizagem de FAN \u00e9 baseado na associa\u00e7\u00e3o entre suas unidades e o uso de \n\ngranularidade para representar informa\u00e7\u00e3o. Os primeiros resultados obtidos usando \n\nFAN s\u00e3o compar\u00e1veis aos m\u00e9todos tradicionais de redes neuronais , em termos de \n\nclassifica\u00e7\u00e3o e superior em termos de estabilidade no aprendizado e capacidade de \n\ngeneraliza\u00e7\u00e3o.\n\n\n\n5. APLICA\u00c7\u00c3O: CLASSIFICA\u00c7\u00c3O \nDA SA\u00daDE FINANCEIRA DE \nPEQUENAS EMPRESAS \nCATARINENSES\n\n5.1 Introdu\u00e7\u00e3o\n\nNeste cap\u00edtulo apresenta-se a aplica\u00e7\u00e3o desta disserta\u00e7\u00e3o: a classifica\u00e7\u00e3o de \n\npequenas empresas quanto a sa\u00fade financeira usando Redes Neuronais Artificias \n\n(Backpropagation, RBF e LVQ) e um Sistema H\u00edbrido (FAN).\n\nEstes modelos visam fornecer um \u201cespecialista\u201d \u00e0s pequenas empresas com \n\nmenor custo. A relev\u00e2ncia deste trabalho se deve a import\u00e2ncia das pequenas \n\nempresas na economia nacional\n\nInicialmente, apresenta-se a defini\u00e7\u00e3o e relev\u00e2ncia do problema no campo \n\nfinanceiro e a escolha das vari\u00e1veis financeiras (\u00edndices financeiros).\n\nAp\u00f3s analisar o problema do ponto de vista financeiro, ser\u00e3o expostos os \n\nresultados obtidos nos treinamentos e nos testes das tr\u00eas rede neuronais e do FAN.\n\nO estudo observa a efic\u00e1cia de t\u00e9cnicas de IA que usa padr\u00f5es para classificar \n\na sa\u00fade financeira das pequena empresas e tamb\u00e9m faz uma compara\u00e7\u00e3o nos \n\ndesempenhos dos quatro sistemas usados, levantando em considera\u00e7\u00e3o pontos fortes e \nfracos de cada um.\n\n5.2 Aplica\u00e7\u00e3o\n\nA fim de superar a aus\u00eancia de um especialista nas pequenas empresas, \n\npodemos incluir o conhecimento especialista em um modelo computacional. Para \n\nisto, implementou-se tr\u00eas redes neuronais (MLP, RBF e LVQ) e um sistema h\u00edbrido \n\n(FAN). Estes sistemas modelam o primeiro est\u00e1gio da an\u00e1lise da sa\u00fade financeira no\n\n\n\nCap\u00edtulo 5 - Classifica\u00e7\u00e3o da Sa\u00fade Financeira de Pequenas Empresas \u00c7atarinpncps 126\n\nqual o especialista procura por desvios financeiros (diagn\u00f3stico). O segundo est\u00e1gio, \n\nque poderia ser feito por um Sistema Especialista Difuso, modela o processo do \n\nespecialista de verifica\u00e7\u00e3o, entendimento e obten\u00e7\u00e3o de uma solu\u00e7\u00e3o para o problema \n\ndiagnosticado. Neste trabalho explorou-se apenas o primeiro est\u00e1gio.\n\nComo o objetivo \u00e9 a classifica\u00e7\u00e3o de pequenas empresas quanto a situa\u00e7\u00e3o da \n\nsa\u00fade financeira, a primeira quest\u00e3o a ser endere\u00e7ada \u00e9 a escolha de um conjunto \n\nadequado de \u00edndices que cubra suas atividades. Com estes \u00edndices pode-se chegar a \n\nclassifica\u00e7\u00e3o dos problemas financeiros a serem diagnosticados.\n\nDados das Em presas\n\nOs dados financeiros empregados neste trabalho foram obtidos junto ao \n\ncontador S\u00e9rgio Farraco (Presidente do Conselho Regional de Contabilidade). Os \n\n\u00edndices calculados foram extra\u00eddos do Balan\u00e7o Patrimonial e do Demonstrativos de \n\nResultados de 56 pequenas empresas catarinenses da regi\u00e3o da Grande Florian\u00f3polis, \n\ndos anos de 1994 e 1995. Dentre estas empresas temos, postos, transportadores, \n\ndistribuidoras, ag\u00eancias de turismo, entre outras.\n\nNo primeiro cap\u00edtulo viu-se quatro abordagens para a classifica\u00e7\u00e3o dos \n\nproblemas financeiros: pragm\u00e1tica, dedutiva, indutiva e confirmat\u00f3ria. Por\u00e9m, os \n\n\u00edndices usados para classifica\u00e7\u00e3o depende do problema [Salmi &amp; Martikainen, 1994], \n\nisto \u00e9, depende do objetivo da an\u00e1lise dos \u00edndices e o dom\u00ednio onde ser\u00e1 aplicado. \n\nNeste presente trabalho utilizou-se a abordagem pr\u00e1tica de Lev [Lev, 1974], tamb\u00e9m \n\nconsiderada no trabalho de [Martins, 1996],\n\nDas quatro categorias identificadas por Lev, foram escolhidos tr\u00eas como \n\ngrupos representativo dos problemas financeiros que provavelmente s\u00e3o advertidos \n\npor rela\u00e7\u00f5es financeiras no caso de pequenas empresas. As categorias escolhidas s\u00e3o: \n\nrentabilidade, endividamento e giro.\n\n\u00edndices de R entabilidade (Retorno): O lucro \u00e9 o principal est\u00edmulo do empres\u00e1rio e \n\numa das formas de avalia\u00e7\u00e3o de \u00eaxito de um empreendimento. Os \u00edndices de retomo \n\ntamb\u00e9m chamados de \u00edndices de lucratividade ou de rentabilidade indicam qual o\n\n\n\nCap\u00edtulo 5 - Classifica\u00e7\u00e3o da Sa\u00fade Financeira de Pequenas Empresas Catarinenses 127\n\nretomo sobre o investimento, retomo sobre as vendas, retomo sobre o capital pr\u00f3prio, \nentre outros.\n\nAqui trabalhar-se-\u00e1 com dois \u00edndices de retomo:\n\n1 C Ope \u2014 ^ uxo ~?'a \u2018xa Oper? _  Lucro L\u00edquido + IR  + Deprecia\u00e7\u00e3o \nReceita Bruta Receita Bruta\n\n- Este \u00edndice mede a capacidade da empresa gerar caixa.\n\n2 LLiq ~ ^ ucro L\u00edquido \nReceita Bruta\n\n- Indicador mais f ie l da lucratividade.\n\nEstes \u00edndices s\u00e3o calculados a partir de dados do Demonstrativo de Resultado \nde cada empresa.\n\n\u00edndices de G iro (rota\u00e7\u00e3o): Os \u00edndices de rota\u00e7\u00e3o constituem-se em categorias de \n\nelevada import\u00e2ncia para o analista. Como vimos na cap\u00edtulo um, o balan\u00e7o da \n\nempresa mostra sua situa\u00e7\u00e3o patrimonial em determinando momento, isto \u00e9, mostra a \n\nempresa de forma est\u00e1tica, sem refletir sua mobilidade, seu dinamismo. A empresa, \n\nem suas opera\u00e7\u00f5es de compra, estocagem, vende e recebe num processo din\u00e2mico e \n\ncont\u00ednuo. Os \u00edndices de rota\u00e7\u00e3o t\u00eam grande contribui\u00e7\u00e3o na interpreta\u00e7\u00e3o da liquidez \n\ne da rentabilidade da empresa, \u00e0 medida que servem de indicadores dos prazos \n\nm\u00e9dios e rota\u00e7\u00e3o de estoques, recebimentos das vendas e pagamento das compras.\n\nSer\u00e1 utilizado um \u00edndice de rota\u00e7\u00e3o:\n\n3. CF -  Ciclo Financeiro = ----- NLCG----- ^ 3 6 5\nReceita Bruta\n\n1NLCG (Necessidade L\u00edquida de capital de Giro) = (Ativo Circulante - Caixa) - ( Passivo Circulante - D\u00edvida)\n\n\n\nCap\u00edtulo 5 - Classifica\u00e7\u00e3o da Sa\u00fade Financeira de Pequenas Empresas Catarinenses 128\n\nEste \u00edndice \u00e9 calculados a partir do Demonstrativo de Resultado e do Balan\u00e7o \n\nPartriminial.\n\nr\n\n\u00edndices de Endividamento: Fornecem informa\u00e7\u00f5es sobre o grau de financiamento e \n\nobriga\u00e7\u00f5es fixas da empresa e sua habilidade para satisfazer estas obriga\u00e7\u00f5es \n\nfinanceiras. S\u00e3o \u00edndices de muita import\u00e2ncia pois indicam a rela\u00e7\u00e3o de depend\u00eancia \n\nda empresa com rela\u00e7\u00e3o a capital de terceiros.\n\nSer\u00e3o usados dois \u00edndices de endividamento:\n\n4. TIE = Lajir\nDespesas Operacionais Financeiras \n\n? Indica quantas vezes o lucro corresponde \u00e0s despesas operacionais.\n\n- r, j. D\u00edvida\n5. Endiv =\n\nCapital Pr\u00f3prio\n\n- Este \u00edndice deve manter um equil\u00edbrio, pois um valor muito alto indica muita d\u00edvida \n\ne valor baixo indica pouco uso de alavancagem.\n\nEstes \u00edndices s\u00e3o calculados a partir do Demonstrativo de Resultado e do \nBalan\u00e7o Patrimonial.\n\nNa Tabela 5.1, tem-se os cinco \u00edndices acima e o que eles indicam para uma \n\nempresa. No ap\u00eandice B encontram-se o histograma de cada um destes \u00edndices, onde \n\npode-se notar claramente que este \u00edndices n\u00e3o apresentam distribui\u00e7\u00f5es normais.\n\nDas 56 empresas, 40 foram usadas para o treinamento dos modelos e 16 para o \n\nteste (Ap\u00eandice A). As empresas foram classificadas por Alejandro Martins em 7\n\nLajir (Lucro antes de juros e impostos) \u2014 Lucro L\u00edquido + IR + Despesas Operacionais Financeiras.\n\n\n\nCap\u00edtulo 5 - Classifica\u00e7\u00e3o da Sa\u00fade Financeira de Pequenas Empresas Catarinenses 129\n\ncategorias, de acordo com o(s) problemas apresentados pelos \u00edndices: \n\nrentabilidade(l), giro(2), endividamento(3), rentabilidade e giro(4), rentabilidade e \n\nendividamento(5), giro e endividamento(6 ), e nenhum dos anteriores(7).\n\n\u00edndice Relev\u00e2ncia Problema relacionado\n\nC O p e\nPoderoso indicador da capacidade de gera\u00e7\u00e3o de fluxo \nde caixa pois mede a quantidade relativa de fundos \noriginado por vendas e/ou produtividade.\n\nRentabilidade\n\nLLiq\nIndica a rentabilidade das vendas. Particularmente no \nBrasil, a margem \u00e9 mais restrita. Um aumento excessivo \nda margem pode levar a perda do mercado enquanto \nredu\u00e7\u00f5es intensas podem levar a problemas financeiros\n\nRentabilidade\n\nCF\nIndica (a) quantos dias do faturamento s\u00e3o necess\u00e1rios \npara financiar as necessidades de capital de giro (b) \nqu\u00e3o sens\u00edvel est\u00e1 o fluxo de caixa a mudan\u00e7as nas \nvendas ou lucros.\n\nRotatividade\n\nTIE\nMede a capacidade de lucro da empresa em \ncorrespond\u00eancia com sua posi\u00e7\u00e3o de alavancagem \nfinanceira.\n\nEndividamento\n\nEndiv Retrata o posicionamento da empresa com rela\u00e7\u00e3o aos \ncapitais de terceiros. Indica a estrutura do capital da \nempresa.\n\nEndividamento\n\nTabela 5.1: Im port\u00e2ncia de cada \u00edndice financeiro.\n\nNa Tabela 5.2 encontram-se os \u00edndices financeiros de duas empresas A e B e \n\no(s) problema(s) que estes \u00edndices detectam.\n\nA empresa A, por exemplo, tem capacidade de gerar caixa, refletindo em \n\nlucro, giro baixo e pouco endividamento (pouco uso de alavancagem financeira).\n\nEmpresa C Ope\n(%)\n\nLLiq \n. (%)\n\nCF\n(dias)\n\nTIE\n(u)\n\nEndiv\n-\u00edu)\n\nCategoria\n\nA 53.0 50.2 48.6 141 24 3\nB 1.2 0.9 38.1 231 109 5\n\nTabela 5.2 : \u00edndices Financeiros de duas em presas e a categoria o qual eles \npertencem .\n\nJ\u00e1, na empresa B temos um exemplo um pouco mais complexo. A empresa \n\ntem pouca gera\u00e7\u00e3o de caixa, pouco lucro l\u00edquido, pouco giro e baixo endividamento \n\nComo pode-se perceber nos exemplo, nem sempre a classifica\u00e7\u00e3o \u00e9 um \n\nproblema simples. Muito pelo contr\u00e1rio, \u00e9 uma tarefa bastantes complexa, pois a\n\n\n\nCap\u00edtulo 5 - Classifica\u00e7\u00e3o da Sa\u00fade Financeira de Pequenas Empresas Catarinenses 130\n\ninterpreta\u00e7\u00e3o dos \u00edndices est\u00e3o relacionados entre si, ou seja, a interpreta\u00e7\u00e3o de um \n\n\u00edndice depende dos outros \u00edndices.\n\n5.3 Diagn\u00f3stico atrav\u00e9s de RN\n\nDesde 1968, a principal abordagem usada, para identificar problemas \n\nfinanceiros nas empresas, \u00e9 a t\u00e9cnica ADM (An\u00e1lise Discriminante M\u00faltipla). \n\nContudo esta t\u00e9cnica tem sido agudamente criticada pois a validade de seus \n\nresultados dependem de suposi\u00e7\u00f5es restritivas sobre normalidade, separabilidade, \n\nnormalidade multivariada, e independ\u00eancia das vari\u00e1veis preditivas [Ohlson, 1980; \n\nOdom &amp; Shardo, 1990; Karels &amp; Prakash, 1987] . \u00edndices financeiros, na grande \n\nmaioria, violam as suposi\u00e7\u00f5es da ADM. As restri\u00e7\u00f5es de ADM s\u00e3o incompat\u00edveis \n\ncom a natureza complexa, limitada e o inter-relacionamento dos \u00edndices financeiros. \n\nEnt\u00e3o o poder da ADM para an\u00e1lise de \u00edndices financeiros est\u00e1 comprometido. \n\nPor\u00e9m, nenhuma t\u00e9cnica melhor foi desenvolvida at\u00e9 o desenvolvimento das Redes \n\nNeuronais Artificiais.\n\nEste estudo foi motivado pelo fato que uma an\u00e1lise dos mesmos \u00edndices \n\nfinanceiros usado por Altman, para o mesmo objetivo, \u00e9 poss\u00edvel sem qualquer uma \n\ndas suposi\u00e7\u00f5es da ADM [Lacher et ali, 1993], Uma rede neuronal \u00e9 uma forma de \n\nprocessar conjunto de informa\u00e7\u00f5es de entradas e suas sa\u00eddas associadas (ou respostas) \n\nde tal maneira a convergir num padr\u00e3o que satisfatoriamente reflete o relacionamento \nde entrada-sa\u00edda.\n\nO uso de RNA para este problema segue tamb\u00e9m de sua habilidade de analisar\n\ne modelar dados de neg\u00f3cios. A habilidade de generalizar dos dados de treinamento\n\ncapacita a rede prever os novos dados subseq\u00fcentemente apresentado ao sistema. As\n\nredes s\u00e3o tamb\u00e9m apropriada para este problema devido a falta de entendimento dos\n\nprinc\u00edpios e regras sobre previs\u00e3o de fal\u00eancia e: a rede \u00e9 n\u00e3o-param\u00e9trica e faz\n\nsuposi\u00e7\u00f5es mais delicadas a respeito da distribui\u00e7\u00e3o dos dados de entrada do que\n\nm\u00e9todos estat\u00edsticos freq\u00fcentemente utilizados; uma RNA \u00e9 capaz de formar\n\nfronteiras de decis\u00e3o altamente n\u00e3o-lineares no espa\u00e7o de caracter\u00edsticas [Haykin,\n1994],\n\n\n\nCap\u00edtulo 5 - Classifica\u00e7\u00e3o da Sa\u00fade Financeira de Pequenas Empresas Catarinenses 131\n\nAl\u00e9m disto, apresentam todas as caracter\u00edsticas vistas no cap\u00edtulo anterior, \n\ncomo toler\u00e2ncia com dados ruidosos e faltosos.\n\nComo viu-se no cap\u00edtulo 4, existem v\u00e1rias arquiteturas de redes. Cada uma \u00e9 \n\nmais adequada para determinado tipo de tarefa. Como o problema \u00e9 de classifica\u00e7\u00e3o \n\n(de padr\u00f5es complexos - padr\u00f5es n\u00e3o linearmente separ\u00e1veis), usou-se 3  das redes \n\nmais usadas para o problema de classifica\u00e7\u00e3o: MLP com backpropagation, RBF, LVQ \n\ne o sistema h\u00edbrido FAN, analisando a performance de cada um. Estas redes foram \n\nescolhidas em virtude da capacidade de trabalhar com padr\u00f5es complexos.\n\n5.3.1 MLP com Backpropagation\n\nA elabora\u00e7\u00e3o desta rede foi baseada na toolbox sobre redes neuronais do \n\nMATLAB [Demuth &amp; Beale, 1994], Foram usadas as fun\u00e7\u00f5es IN IT FF , TRAINBPX \n\nE SIM U FF (ver Tabela 5.1).\n\nFun\u00e7\u00e3o O  que realiza?\nIN1TFF Inicia os pesos e bias para a rede backpropagation\nTRAINBPX Treina a rede usando momentum e taxa de aprendizagem adaptativa. \n\nTreinamento mais r\u00e1pido do backpropagation\nSIMUFF Simula a rede (teste).\nT abela 5.1 : Fun\u00e7\u00f5es principais p a ra  a rede backpropagation do MATLAB.\n\nA rede apresenta uma \u00fanica camada escondida, com 5 neur\u00f4nios na camada \n\nde entrada e 1 na camada de sa\u00edda. Os dados de entradas foram normalizados.\n\nForam realizados in\u00fameros testes variando os par\u00e2metros (taxa de \n\naprendizagem e momentum9), a fun\u00e7\u00e3o de ativa\u00e7\u00e3o, o n\u00famero de neur\u00f4nios na \n\ncamada escondida e o n\u00famero de \u00e9pocas. Os dados de entradas tamb\u00e9m foram \n\ntrabalhados de duas formas distintas: - normalizados no intervalo [-1, 1] e - \n\nnormalizados no intervalo [0, 1], Por\u00e9m, como poder ser visto no ap\u00eandice C, a rede\n\n9 A\nmomentum pode ser visto como um supervisor na aprendizagem: acelera a converg\u00eancia para intera\u00e7\u00f5es que \n\nconservam sinal (sinal do ajuste anterior e sinal do gradiente corrente); diminui a oscila\u00e7\u00e3o quando os sinais s\u00e3o \ndiferentes; previne m\u00ednimos locais.\n\n\n\nCap\u00edtulo 5 - Classifica\u00e7\u00e3o da Sa\u00fade Financeira de Pequenas Empresas Catarinenses 132\n\napresentou uma performance melhor quando os dados de entrada foram normalizados \nno intervalo [-1, 1],\n\nNo ap\u00eandice C encontram-se as tabelas C -l, C-2, C-3 e C-4 que mostram \n\nvarios resultados obtidos com a rede backpropagation.\n\nPara ilustrar a performance da rede, alguns resultados s\u00e3o apresentados na \nTabela 5.2.\n\nComo pode-se observar nesta tabela, existem v\u00e1rias combina\u00e7\u00f5es de \n\npar\u00e2metros que fornecem os mesmos resultados. Apesar dos dados serem bastante \n\nreduzidos, a rede backpropagation conseguiu alcan\u00e7ar uma boa generaliza\u00e7\u00e3o. Um \n\nfator essencial para obten\u00e7\u00e3o dos resultados melhores foi a utiliza\u00e7\u00e3o da combina\u00e7\u00e3o \n\nde fun\u00e7\u00f5es de ativa\u00e7\u00e3o n\u00e3o linear na camada escondida e linear na camada de sa\u00edda.\n\nNeur\u00f4nios Epocas Taxa de ? \nAprendizaoem\n\nMomentum F\u00e7. De \nAtiva\u00e7\u00e3o\n\nTreinamento\n(%)\n\nTeste (%) Tempo (s)\n\n7 2000 0,100 0,90 sig/lin 87,50 68,75 27 907 2500 0,100 0,90 sig/lin 87,50 75,00 34 767 3000 0,100 0,90 sig/lin 90,00 81,25 41 527 3000 0,001 0,90 tan/lin 85,00 81,25 40 266 3000 0,001 0,90 tan/lin 85,00 75,00 38 559 3000 0,001 r 0,80 tan/lin 87,50 75,00 42,137 1000 0,010 0,90 tan/sig 35,00 31,25 12 9620 1000 0,010 0,90 tan/sig 35,00 31,25 18 627 1000 0,900 0,10 tan/sig 35,00 31,25 I 12,97\n\nno intervalo [-1,1J.\n\nA taxa de aprendizagem e momentum tamb\u00e9m t\u00eam uma contribui\u00e7\u00e3o especial.\n\nPode-se observar durante os teste realizados que: - quando a taxa de aprendizagem \u00e9\n\npequena (por exemplo, 0.01) e o momentum \u00e9 grande (0.9) a aprendizagem \u00e9 r\u00e1pida e\n\na generaliza\u00e7\u00e3o \u00e9 boa; - quando a taxa de aprendizagem \u00e9 grande (por exemplo, 0 .9 ) e\n\no momentum \u00e9 pequeno (0 . 1) a aprendizagem \u00e9 mais lenta mas a generaliza\u00e7\u00e3o\n\ntamb\u00e9m \u00e9 boa; - agora, quando as duas taxas est\u00e3o pr\u00f3ximas a generaliza\u00e7\u00e3o \u00e9\n\nrazo\u00e1vel e a aprendizagem da rede \u00e9 oscilante. O melhor resultado (81,25%) foi\n\nobtido quando a taxa de aprendizagem era pequena (0 .0 0 1 ) e o momentum grande \n(0.9).\n\n\n\nCap\u00edtulo 5 - Classifica\u00e7\u00e3o da Sa\u00fade Financeira de Pequenas Empresa^atarinenses\n\nBiblioteca Universit\u00e1ria \n\nU F S C ________\n\nQuanto ao n\u00famero de neur\u00f4nios na camada escondida para obter bons \n\nresultados varia de 7 a 11 neur\u00f4nios. Por isto a maioria dos teste foram feitos usando \n\n7 neur\u00f4nios, visando maior velocidade.\n\nComeg\u00eanda\n\nos\n03\n\n0.7\n\nJo.6 I .\nI I\n\n,8 06 >L\n0.4\n\n0.3\n\n02\n\n01\nc 500 1000 1500 2000\n\n\u00c9pocas\n\nf \u00ae r  v j f c i g \u00ed i n w i \u00e2  U3AUUU o  ll\u00e7 U r U I llU S }  l a X a  U 3\naprendizagem  0.08, momentum 0.8 e 1000 \u00e9pocas. Com esta a rq u ite tu ra  obtemos \n81.25% de acerto nos dados de teste; (b) Converg\u00eancia da Backpropagation usando 8  \nneur\u00f4nios, taxa da aprendizagem  0.08, momentum 0.8 e 2000 \u00e9pocas. Com esta \na rq u ite tu ra  obtemos 68.75% de acerto nos dados de teste.\n\nUm dos problemas da Backpropagation \u00e9 a falta de estabilidade em rela\u00e7\u00e3o a \n\ngeneraliza\u00e7\u00e3o. As Figuras 5.1 (a) e (b) mostram os resultados da converg\u00eancia da rede \n\ncom 1000 e 2000 \u00e9pocas. Como pode ser visto a taxa de erro \u00e9 descrente, por\u00e9m, a \n\nrede generalizou melhor com 1 0 0 0  \u00e9pocas (81.25%) do que com 2 0 0 0  \u00e9pocas \n\n(68.75%). Isto mostra o problema de overtraining, mencionado no cap\u00edtulo anterior.\n\nOs resultados tamb\u00e9m dependem dos pesos iniciais. Tem-se, por exemplo, \n\numa classifica\u00e7\u00e3o de 75% de acertos com 400 \u00e9pocas. Mas o melhor resultado \n\n81.25% foi obtido com 3000 \u00e9pocas (mais comum) e at\u00e9 com apenas 1000 \u00e9pocas \n\n(devido a inicializa\u00e7\u00e3o dos pesos).\n\n5.3.2 RBF\n\nA elabora\u00e7\u00e3o desta rede tamb\u00e9m foi baseada na toolbox sobre redes neuronais \n\ndo MATLAB P e m u th  &amp; Beale, 1994], Foram usadas as fun\u00e7\u00f5es SOLVERB e \n\nSIMURB (Tabela 5.1).\n\n\n\nCap\u00edtulo 5 - Classifica\u00e7\u00e3o da Sa\u00fade Financeira de Pequenas Empresas Catarinenses 134\n\nFun\u00e7\u00e3o 0  que realiza?\nSOLBERB Encontra uma RBF com centros suficiente \n\npara ajustar uma fun\u00e7\u00e3o dentro da meta de \nerro (0 .0 2 ) e treina esta rede.\n\nSIMURB Simula a RBF.\nTabela 5.1 : Fun\u00e7\u00f5es principais para a rede RBF do MATLAB.\n\nDa mesma forma que a backpropagation, temos uma rede RBF com cinco \n\nneur\u00f4nios na camada de entrada e um na camada de sa\u00edda. A fun\u00e7\u00e3o de ativa\u00e7\u00e3o \n\nusada na camada escondida foi a gaussiana.\n\nA performance da rede depende dos par\u00e2metros (centro e largura da fun\u00e7\u00e3o \n\ngaussiana) e \u00e9 bastante sens\u00edvel ao n\u00famero de \u00e9pocas. No ap\u00eandice D encontra-se os \n\nresultados obtidos combinando os par\u00e2metros de formas distintas.\n\nComo pode ser observado nas Figura 5.2 (a) e (b), se o n\u00famero de \u00e9pocas for \n\nmaior que o n\u00famero de centros, a rede aprende muito melhor, por\u00e9m perde a \n\ngeneralidade, apresentando o mesmo problema de overtraining da Backpropagation. \n\nMas na Backpropagation, como depende dos pesos iniciais, \u00e9 muito dif\u00edcil, sen\u00e3o \n\nimposs\u00edvel, determinar o n\u00famero de \u00e9pocas ideal. Isto j\u00e1  n\u00e3o acontece com a RBF.\n\nOutro fator importante que influencia na performance da rede \u00e9 a forma de \n\nnormaliza\u00e7\u00e3o dos dados. Usando os dados normalizados entre [-1,1] a rede consegue \n\ngeneralizar melhor que quando normalizados entre [0,1] (ver Ap\u00eandice D).\n\nDentre os teste realizados, os resultados melhores foram obtidos usando 14 ou \n\n15 centros com raio de 1.3, e trabalhando com os dados normalizados no intervalo [- \n\n1, 1].\n\nSe o n\u00famero de centros for muito grande (30, por exemplo) a rede aprende \n\n1 0 0 % por\u00e9m perde a generalidade.\n\n\n\nCap\u00edtulo 5 - Classifica\u00e7\u00e3o da Sa\u00fade Financeira de Pequenas Empresas Catarinenses 135\n\nCentros Raio Epocas Treinamento\n(%)\n\nTeste (%) Tempo(s)\n\n13 1,30 12 65,00 68,75 1,38\n14 1,30 13 77,50 81,25 1,32\n15 1,30 14 77,50 81,25 1,38\n16 1,30 15 82,50 75,00 - 1,38\n\n.. 15 1,30 34 | 100.00 37.50 3.19\n\nintervalo [-1,1].\n\nFigura 5.2: (a) Converg\u00eancia da rede RBF com 15 centros, 1.3 de raio e 14 \u00e9pocas. \nCom esta arquitetura rede acertou 77.5% no treinamento e 81.25% teste; (b) \nConverg\u00eancia da rede RBF com 15 centros, 1.3 de raio e 34 \u00e9pocas. Com esta \narquitetura rede acertou 100% no treinamento e 37.50% teste.\n\n5.3.3 LVQ\n\nO algoritmo da LVQ foi implementado em MATLAB baseado no algoritmo \n\nencontrado no livro da Fausett [Fausett, 1994],\n\nO pesos foram iniciados com os primeiros dados do conjunto de treinamento. \n\nForam feitos in\u00fameros testes usando os dados normalizados no intervalo [-1,1] e n\u00e3o \n\nnormalizados. Como pode ser visto na ap\u00eandice E, com os dados normalizados a rede \n\napresentou uma performance um pouco melhor.\n\nTestou-se duas formas distintas de variar (diminuir) a taxa de aprendizagem: \n\nlinear e n\u00e3o linearmente em fun\u00e7\u00e3o do n\u00famero de \u00e9pocas. Com as duas formas \n\nobt\u00e9m-se bons resultados (62.50%). Por\u00e9m, quando usou-se a forma n\u00e3o linear, a rede\n\n\n\nCap\u00edtulo 5 - Classifica\u00e7\u00e3o da Sa\u00fade Financeira de Pequenas Empresas Catarinenses 136\n\naprende e generaliza seu limite e n\u00e3o perde a generalidade mesmo quando muitas \n\n\u00e9pocas s\u00e3o realizadas (ver Figura 5.3 (a) e (b)).\n\nTaxa de \nAprendizagem\n\nVana\u00e7\u00e3o da \nTaxa da Apren\n\n\u00c9pocas Treinamento\n(%)\n\nTeste\n(%)\n\nTempo\n(s)0,10 N\u00e3o linear 45 62,50 50,00 24,450\n\n0,20 N\u00e3o linear 45 72,50 62,50 18,950\n0,20 N\u00e3o linear 80 72,50 62,50 33,170\n0,20 N\u00e3o linear 200 70,00 62,50 87,280\n0,15 N\u00e3o linear h 40 60,00 50,00 6,480\n0,20 linear 45 80,00 62,50 23,78\n0,20 linear 100 15,00 31,25 53,82\n0,10 linear 50 72,50 62,50 25,98\n\nT abela 5 .1 : Resultado da LVQ com dados norm alizados no intervalo \n[!>!]\u2022\n\nF ig u ra 5.3: (a) Converg\u00eancia da rede LVQ, trabalhando com os dados normalizados \nno intervalo [-1,1] com taxa de aprendizagem  0.2 decrescendo n\u00e3o linearm ente e 45 \nepocas. Com esta a rq u ite tu ra  rede acertou 72.5% no treinam ento e 62.25% no teste- \n(b) Converg\u00eancia da rede LVQ, trabalhando com os dados normalizados no intervalo \n[-1,1] com taxa de aprendizagem  0.2 decrescendo n\u00e3o linearm ente e 200 \u00e9pocas \nCom esta a rq u ite tu ra  rede acertou 70.00% no treinam ento e 62.25% no teste. \u2019\n\n5.3.4 FAN\n\nO algoritmo do FAN foi implementado por Raittz [Raittz et al., 1997] usando \n\nClipper. Este algoritmo h\u00edbrido ainda esta em fase de testes.\n\nO diagn\u00f3stico realizado com o sistema h\u00edbrido apresenta tamb\u00e9m suas \n\nsensibilidade com alguns par\u00e2metros, normaliza\u00e7\u00e3o das vari\u00e1veis (range), raio de\n\n\n\nCapitulo 5 - Classifica\u00e7\u00e3o da Sa\u00fade Financeira de Pequenas Empresas Catarinenses\n137\n\ndecomposi\u00e7\u00e3o (raio da fun\u00e7\u00e3o de fusifica\u00e7\u00e3o - D) e grau de combina\u00e7\u00e3o das vari\u00e1veis \n\n(H). Nos teste realizados a grau de combina\u00e7\u00e3o usado foi 1.\n\nAlguns dos resultados obtidos usando o modelo FAN s\u00e3o apresentados na\n\nTabela 5.1. Com raio de decomposi\u00e7\u00e3o 2 a rede conseguiu alcan\u00e7ar uma taxa de\n\nacerto de 75% nos dados de teste com apenas uma \u00e9poca de treinamento. Isto mostra\n\na capacidade do FAN generalizar com pouca aprendizagem. Esta caracteriza uma das\n\nvantagens do FAN. Uma outra caracter\u00edstica do modelo \u00e9 que a partir de uma entrada\n\nele ja  consegue prever a qual classe o pr\u00f3ximo padr\u00e3o estaria, ou seja, um modelo \nantecipat\u00f3rio.\n\nFun\u00e7\u00e3o de \nPertin\u00eancia\n\nRaio Range Epocas Treinamento\n(%)\n\nTeste\n(%)\n\nGaussiana 1 19 5 85.00\ni:\u2014-? * \" \u2022 \n\n75.00\nTriangular 1 21 5 92.50 75.00\nTriangular 2 20 1 55.00 75.00\n\nT abela 5 .1 : Resultado do FAN (Porcentagem  de acerto).\n\n5.4 Compara\u00e7\u00e3o dos Resultados\n\nApresentou-se na Tabela 5.1 os resultados obtidos usando quatro sistemas \n\ndistintos para classifica\u00e7\u00e3o de empresas. Como p\u00f4de-se notar, as redes RBF e \n\nbackpropagation apresentaram o mesmo desempenho (81.25% de acerto nos dados de \n\nteste). Mas, como j\u00e1  esper\u00e1vamos, a RBF \u00e9 muito mais r\u00e1pida que a rede \n\nbackpropagation (a RBF leva aproximadamente 1 segundo para fornecer este \n\nresultado enquanto a backpropagation leva aproximadamente 40s10).\n\nO FAN, apesar de ser um sistema ainda em testes, apresentou uma boa \n\ngeneraliza\u00e7\u00e3o (75%). Mas o FAN conseguiu esta performance com apenas 1 itera\u00e7\u00e3o \n\nquando o raio da fun\u00e7\u00e3o de pertin\u00eancia era 2 e levou 6 \u00e9pocas quando o raio era 1. O \n\nFAN mant\u00e9m este resultado se mais itera\u00e7\u00f5es forem feitas, ou seja ele n\u00e3o perde a \n\ngeneraliza\u00e7\u00e3o como acontece com a RBF e a Backpropagation . Por\u00e9m, se houver \n\numa superaprendizagem (por exemplo, 100% quando o range de normaliza\u00e7\u00e3o usado\n\n10 Todos os resultados foram obtido num Pentim 166.\n\n\n\nCap\u00edtulo 5 - Classifica\u00e7\u00e3o da Sa\u00fade Financeira de Pequenas Empresas Catarinenses 138\n\nfoi 100) ele perde a generalidade, assim como acontece com a RBF quando usamos \n30 centros.\n\nA rede LVQ n\u00e3o conseguiu uma performance t\u00e3o boa quanto Backpropagation \n\ne a RBF, mas esta rede apresenta uma maior estabilidade na sua aprendizagem. Cada \n\npeso na LVQ representa uma das classes, ent\u00e3o no momento do treinar a rede seria \n\ninteressante termos um n\u00famero de amostras semelhantes para cada classe, o que n\u00e3o \n\nacontece com nossos dados (Ap\u00eandice A e B). Talvez, por este motivo, a rede n\u00e3o \n\napresentou um desempenho t\u00e3o bom quanto as outras.\n\nA tabela abaixo apresenta as redes em ordem quanto aos melhores \n\ndesempenhos em rela\u00e7\u00e3o a tempo de execu\u00e7\u00e3o, n\u00famero de \u00e9pocas, aprendizagem e \n\ngeneraliza\u00e7\u00e3o. Podemos ent\u00e3o concluir que a rede RBF foi a mais r\u00e1pida em quest\u00e3o \n\nde tempo, o FAN foi mais r\u00e1pido em rela\u00e7\u00e3o ao n\u00famero de \u00e9pocas e aprendeu melhor \n\nos dados de treinamento, e a RBF e a backpropagation g e n e r alizaram  melhor.\n\n1\u00ab 2a 3- ? 40 ???\nTempo Back FAN\n\nN~ de \u00e9pocas RBF '\n} ~ '\u00ed? K \u00edm\n\nLVQ Back\n\nTreinamento -\u00ed -Soi\n\"  -90% - :\n\nRBF \n77 5%\n\nLVQ\n72.5%\n\nTeste \"\u00a3AN~ t \nr  75%\n\nLVQ \n62 5%\n\nTabela 5 .1 : Com para\u00e7\u00e3o dos resultados.\n\n5.5 Conclus\u00e3o\n\nOs resultados vistos acima comprovam a efici\u00eancia de t\u00e9cnicas de IA \n\naplicadas \u00e0 problemas de classifica\u00e7\u00e3o de empresas. Mesmo trabalhando com t\u00e3o \n\npoucos dados os sistemas apresentaram boa performance. Este tipo de trabalho sendo \n\nrealizado em um sistema pode ser muito \u00fatil para as empresas que podem ter uma \n\nvis\u00e3o de como anda a sa\u00fade de sua empresa, principalmente para pequenas empresas \n\nque n\u00e3o podem ter acesso a um especialista para executar esta tarefa. Com isto, a\n\n\n\nCap\u00edtulo 5 - Classifica\u00e7\u00e3o da Sa\u00fade Financeira de Pequenas Empresas Catarinpngps 139\n\nempresa pode detectar que tipos de problemas sua empresa apresenta, podendo desta \n\nforma tomar medidas que possam evitar fal\u00eancia ou melhorar a sua lucratividade.\n\nQuanto ao desempenho das redes e do sistema h\u00edbrido, n\u00e3o \u00e9 apropriado dizer \n\nqual \u00e9 o melhor ou mais adequado para o problema de classifica\u00e7\u00e3o de empresas. O \n\nque pode-se concluir \u00e9 que para estes 56 dados com os quais trabalhou-se, a RBF \n\ndestacou-se pelo bom desempenho e rapidez em termos de tempo de execu\u00e7\u00e3o. A \n\nbackpropagation teve um bom desempenho, por\u00e9m \u00e9 muito lenta. O FAN destacou-se \n\npela sua habilidade de generaliza\u00e7\u00e3o com pouco treinamento, mas tamb\u00e9m foi lento. \n\nA LVQ, apesar de n\u00e3o apresentar um desempenho t\u00e3o bom, mostrou-se bastante \n\nest\u00e1vel em rela\u00e7\u00e3o a aprendizagem, ou seja , ela n\u00e3o perde a generalidade se muitas \n\n\u00e9pocas forem executadas.\n\nConcluindo, para estes dados a RBF foi a rede que apresentou uma melhor \n\nperformance de um modo geral. Mas vale ressaltar aqui que os modelos trabalhados \n\ntiveram um bom desempenho, levando em considera\u00e7\u00e3o a pequena quantidade de \n\ndados dispon\u00edveis para o treinamento.\n\n\n\n6. CONCLUS\u00d5ES E \nRECOMENDA\u00c7\u00d5ES\n\n6.1 Conclus\u00f5es\n\nO presente trabalho foi motivado pela necessidade de um maior conhecimento \n\nde como avaliar em termos emp\u00edricos a sa\u00fade financeira das pequenas empresa \n\n(catarinenses). O monitoramento da sa\u00fade financeira das empresas \u00e9 um fator critico \n\npara seu sucesso. Este representa mais um passo para dar suporte estrat\u00e9gico aos \n\nmicro-empres\u00e1rios a verificar a situa\u00e7\u00e3o financeira da empresa, sem precisar \n\ndispender muitos recursos. Para tal fim, toma-se imprescind\u00edvel o desenvolvimento de \nsistemas inteligentes\n\nPara an\u00e1lise de empresas existem muitos sistemas inteligentes, por\u00e9m estes\n\neram voltados mais para an\u00e1lise de cr\u00e9dito e previs\u00e3o de fal\u00eancia que s\u00e3o problemas\n\ndiferentes de determinar a sa\u00fade financeira. No caso da an\u00e1lise de cr\u00e9dito, estuda-se\n\nas condi\u00e7\u00f5es financeiras de uma empresa com objetivo exclusivo de verificar se um\n\nempr\u00e9stimo \u00e9 seguro; j\u00e1  no caso de previs\u00e3o de fal\u00eancia prev\u00ea a \u201cvida\u201d ou fal\u00eancia da\n\nempresa. A determina\u00e7\u00e3o da sa\u00fade financeira \u00e9 um problema mais complexo pois\n\ndeve analisar v\u00e1rios aspectos da empresa (giro, endividamento, liquidez, \nlucratividade).\n\nUma t\u00e9cnica central para endere\u00e7ar situa\u00e7\u00f5es financeiras problem\u00e1ticas \u00e9 a \n\nAn\u00e1lise de Declara\u00e7\u00f5es Financeiras, um processo no qual os especialistas \n\nreorganizam as informa\u00e7\u00f5es da firma e outras origens, criam vari\u00e1veis auxiliares \n\n(como os \u00edndices financeiros), e fazem uma compara\u00e7\u00e3o com padr\u00f5es a fim de \n\nidentificar e entender os desvios.\n\nPara elabora\u00e7\u00e3o deste estudo, iniciou-se analisando as declara\u00e7\u00f5es financeiras \n\n(Balan\u00e7o Patrimonial e Demonstrativos de resultados) de 56 pequenas empresas\n\n\n\nCap\u00edtulo 6 - Conclus\u00f5es e recomenda\u00e7\u00f5es 141\n\ncatarinenses, extraindo deles cinco (5) \u00edndices financeiros (Caixa Operacional, Lucro \n\nL\u00edquido, CG_V, TIE e Endividamento) com os quais classificou-se as empresas em \n\nsete (7) categorias quanto aos problemas de rentabilidade, giro e endividamento.\n\nO racioc\u00ednio indutivo foi modelado por quatro (4) algoritmos alternativos que \n\nusam t\u00e9cnicas de Intelig\u00eancia Artificial: tr\u00eas (3) redes neuronais distintas \n\n(Backpropagation, RBF e LVQ) e um sistema h\u00edbrido (FAN). O objetivo era \n\ncomparar os desempenhos buscando os que mais se adaptam ao problema de \n\ndiagn\u00f3stico de empresas\n\nDos 56 padr\u00f5es de entradas, usou-se quarenta (40) para treinar os sistemas e o \n\nrestante (16) usou-se para a valida\u00e7\u00e3o. Apesar de dispor-se de poucos dados os \n\nresultados encontrados de um modo geral foram muito bons, mostrando a capacidade \n\nde aprendizagem das redes com poucos dados. Como pode-se observar na Tabela 6.1, \n\nem rela\u00e7\u00e3o a valida\u00e7\u00e3o, as redes Backpropagation e RBF apresentaram o melhor \n\nresultado, por\u00e9m, como j\u00e1  esper\u00e1vamos, a RBF e muito mais r\u00e1pida que a \n\nBackpropagation. O FAN tamb\u00e9m conseguiu um resultado bom, por\u00e9m ele foi \n\nrelativamente mais lento que a Backpropagation. Mas devemos lembrar que o FAN \n\nfoi programado em Cliper e o Backpropagation em Matlab. A LVQ foi a que \n\napresentou o desempenho mais baixo, mas vale lembrar que usamos a vers\u00e3o mais \n\nsimples das LVQs. Existem outros modelos de LVQ, como LVQ1 e LVQ2, que s\u00e3o \n\num pouco mais elaboradas. Al\u00e9m disto, estamos trabalhando com poucos dados. \n\nAcredita-se que com mais dados os resultados podem melhorar, principalmente, se \n\nhouver uma n\u00famero semelhante de padr\u00f5es para cada cluster. Isto n\u00e3o s\u00f3 para a LVQ, \n\nmas para as outras redes tamb\u00e9m.\n\nMas sem levantar mais hip\u00f3teses, analisando resultados que foram obtidos \n\ncom estes modelos, sejam eles os mais elaborados ou n\u00e3o, nesta ou naquela \n\nlinguagem, pode-se concluir que a rede RBF foi a melhor em termos de generaliza\u00e7\u00e3o \n\ne rapidez e o FAN foi o melhor em termos de aprendizagem.\n\nPara problemas de classifica\u00e7\u00e3o com caracter\u00edsticas semelhantes ao problema \n\nque foi trabalhado nesta disserta\u00e7\u00e3o, recomenda-se o uso da rede RBF pois apresenta \n\nas seguintes caracter\u00edsticas:\n\n\u2022 Rapidez para treinamento\n\n\n\nCap\u00edtulo 6 - Conclus\u00f5es e recomenda\u00e7\u00f5es 142\n\n\u2022 Facilidade para determinar os par\u00e2metros que fornecem o melhor desempenho.\n\n\u2022  Boa capacidade de generaliza\u00e7\u00e3o.\n\n\u2022 Capacidade de classificar dados complexos (n\u00e3o linearmente separ\u00e1veis).\n\nModelo Treinamento (%) Teste (\u00b0o)\n\nBackpropagation 90.00 81.25\nLVQ 72.50 62.50\nFAN 92.50 75.00\nRBF 77.50 81.25\n\nTabela 6 .1 : P ercentual de acerto de cada modelo.\n\n6 . 2  Recomenda\u00e7\u00f5es\n\nUm das principais limita\u00e7\u00f5es dos modelos utilizados \u00e9 que eles n\u00e3o fornecem \n\numa explica\u00e7\u00e3o dos resultados obtidos, eles simplesmente fornecem um indicador \n\nnum\u00e9rico. E os usu\u00e1rios deste tipo de sistemas necessitam de uma explica\u00e7\u00e3o sobre as \n\ncausas do diagn\u00f3stico apresentado. Tendo em vista esta limita\u00e7\u00e3o prop\u00f5e-se os \n\nseguintes trabalhos futuros:\n\n1) Constru\u00e7\u00e3o de um sistema h\u00edbrido, que al\u00e9m do diagn\u00f3stico, pudesse detectar as \n\ncausas e sugerir solu\u00e7\u00f5es aos problemas diagnosticados. J\u00e1 existe trabalhos nesta \n\nlinha como o sistema h\u00edbrido inteligente desenvolvido por Pacheco [Pacheco, \n\n1996], por\u00e9m n\u00e3o aplicado a empresas brasileiras. Este sistema usa Redes \n\nNeuronais Artificiais e um Sistema Especialista Difuso. A sugest\u00e3o \u00e9 trabalhar \n\ncom um sistema h\u00edbrido que trabalhe com RNA, Conjuntos Difusos e Racioc\u00ednio \n\nBaseado em Casos. Neste sistema, uma RNA seria usada para fazer o diagn\u00f3stico, \n\neste diagn\u00f3stico seria fuzificado e o resultado seria um dos atributos de cada caso . \n\nO RBC, forneceria as causas e poss\u00edveis solu\u00e7\u00f5es para o problema diagnostico pela \n\nRNA. A Figura 6.1 abaixo mostra o esquema b\u00e1sico do modelo sugerido.\n\n\n\nCap\u00edtulo 6 - Conclus\u00f5es e recomenda\u00e7\u00f5es 143\n\n\u00edndices\n\nO u tro s\nDados\n\nDiagn\u00f3stico Valora\u00e7\u00e3o\nD ifiis a\n\nSolu\u00e7\u00f5es\n\nCausas\n\nFigura 6.1: Arquitetura h\u00edbrida para an\u00e1lise da situa\u00e7\u00e3o financeira.\n\n2) Uma outra forma de melhorar os modelos \u00e9 a aplica\u00e7\u00e3o de algoritmos de extra\u00e7\u00e3o \n\nde conhecimento (regras) da rede treinada. J\u00e1 existem alguns trabalhos neste linha \n\ncomo [Andrews, et al. 1995; Fu, 1994],\n\n3) Uma outra rede que poderia ser usada para o diagn\u00f3stico de empresas \u00e9 a rede de \n\nKohonen (SOFM - Self-Organizing Features Maps). Os mapas de Kohonen n\u00e3o \n\nresolveriam o problema de explicar os resultados obtidos, mas fornecem \n\ninforma\u00e7\u00f5es (visuais) mais completas sobre a situa\u00e7\u00e3o financeira das empresas \n\n[Martin-del-Brio &amp; Serrano-Cinca, 1995],\n\nAl\u00e9m disto, prop\u00f5e-se a implementa\u00e7\u00e3o destes algoritmos para uso atrav\u00e9s da \nrede Internet.\n\n\n\nREFER\u00caNCIAS BIBLIOGR\u00c1FICAS\n\n[Aamodt, 1991] AAMODT, A. Case-based Reasoning: Foundational Issues: \n\nMethodological Variations and Systems Approaches. AICOM, v7, n. 1, 1991.\n\n[Aho, 1980] AHO, T. Empirical classification o f financial ratios. Management \n\nScience in Finland Proceedings, ed. C.Carlsson, 1980.\n\n[Altman, 1968] ALTMAN, E.I. Financial Ratios, Discriminant Analysis and the \n\nPrediction o f Corporate Bankruptcy. Journal o f  Finance, September, pp. 589-609, \n1968.\n\n[Anderson, 1972] ANDERSON, J. A. \u201cA Simple Neural Network Generating an \n\nInteractive Memory \u201d, Mathematical Biosciences 14, pp. 197-220,1972.\n\n[Andrews, et al. 1995] ANDREWS, R.; DIEDERICH, J. e TICKLE, A. B. A Survey \n\nand Critique o f Technics for Rule Extracting Rules from Trained Artificial Neural \n\nNetworks, Neural Computer Research Centre, Queensland University o f \n\nTechnoloy, Autralia, Technical Report, 1995.\n\n[Angeniol et al., 1988] ANGENIOL, B\u201e G. DE LA CRAIX V. e LE TEXIER J.-Y.\n\nSelf-Organizing Feature Maps and the Traveling Salesman Problem, Neural \n\nNetworks, Vol. 1, pp. 289-293,1988.\n\n[Austin, 1990] AUSTIN, S. An Introduction to Genetic Algorithms. A l  Expert, 1990.\n\n[Bareiss, 1988] BAREISS, R. PROTOS A unified approarch to concept \n\nrepresentation, classification and learning. Ph.D. Dissertation. University o f Texas \n\nat Austin, Dep. o f Computer Sciences Technical Report Al, pp. 88-83,1988.\n\n[Barker, 1990] BARKER, D., Analysing Financial Health: Integrating Neural \n\nNetworks and Expert Systems, P C  A l, May/June, 1990.\n\n[Barnes, 1982] BARNES, P., Methodological implications o f non-normally \n\ndistributed financial ratios, Journal o f  Business Finance and Accounting, pp.51- \n62, 1982.\n\n[Barnes, 1987] BARNES, P. The Analysis and Use o f Financial Ratios, Journal o f  \n\nBusiness Finance and Accounting, Vol. 14, N^ 4, pp. 449-461, 1987\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 145\n\n[Barr &amp; Mani, 1994] BARR, D. S. e MANI, G. Using Neural Nets to Manage \n\nInvestments. AJ Expert, Vol.9, N\u00b0 2, pp. 16-21,1994.\n\n[Batalha &amp; Demori, 1990] BATALHA, M., 0 ., &amp; DEMORI, F. \u201cA Pequena e M\u00e9dia \n\nInd\u00fastria em Santa Catarina\u201d, Editora da Universidade Federal de Santa Catarina \n\n(UFSC), Florian\u00f3polis, Santa Catarina, 1990.\n\n[Baykal &amp; Yalabki, 1992] BAYKAL, N. &amp; YALABKI, N. Object Orientation \n\nDetection and Character Recognition using Optimal Feed-forword Network and \n\nKohone\u2019s Feature Map, SPIE, Vol. 1709, pp. 292-303, 1992.\n\n[Beaver, 1966] BEAVER, W. H. Financial Ratios as Predictors o f  Failure, Journal o f  \n\nAccounting Research, pp. 77 - 111, 1966.\n\n[Belkaoui, 1978] BELKAOUI, A. Financial Ratios as Predictors o f Canadian \n\ntakeovers, Journal o f  Business Finance and Accounting, pp. 93-67,1978.\n\n[Benachenhou et al\u201e 1990] BENACHENHOU, D.; CADER, M.; SZU, H.; \n\nMEDSKER, L.; WITTWER, C. &amp; GARLING, D. Neural Networks for Computing \n\nInvariant Clustering o f a Large Open Set o f DNA-PCR Primers Generated by a \n\nfeature-knowledge based system. Proceedings ofIJCNNN-90, San Diego, CA, Vol. \nH, pp. 83-89,1990.\n\n[Bennett et al\u201e 1989] BENNETT, K.; FERRIS, M. C. e IOANNIDIS, Y. E\u201e A Genetic \n\nAlgorithm for Database Query Optimization, In Proceedings o f  the Fourth \n\nInternational Conference on Genetic Algorithms, R. K. Belew e L. B. Booker \n\n(eds.), San Mateo, 1991.\n\n[Bernstein, 1989] BERNSTEIN, L., Financial Statement Analysis, Theory, \n\nApplication and Interpretation. Richard D. Irwin, Inc., Homewwod, 1989.\n\n[Berry &amp; Nix, 1991] BERRY, R.H., and NIX, S. Regression analysis v. ratios in the \n\ncross-section analysis o f financial statements, Accounting and Business Research \n21/82, pp 107-117,1991.\n\n[Bilbro et al., 1988] BILBRO, G. et al. Optimization by Mean Field Annealing. In \n\nAdvance In Neural Information Processing systems, I. D. S. Touretzky (Ed.), \n\nMorgan Kalfmann, San Mateo, CA, pp. 91-98,1988.\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 146\n\n[Bird &amp; McHugh, 1977] BIRD, R.G., and MCHUGH, A.J. Financial ratios - an \n\nempirical study, Journal o f  Business Finance and Accounting 4/1,29-45, 1977.\n\n[Blocher, 1990] BLOCHER, E. ANSWERS: An Expert System for Financial \n\nAnalysis. Em [Liebowitz, 1990], (1990) pp. 101-125.\n\n[Booth et al., 1994] BOOTH, G., MARTDCAINEN, T\u201e PERTTUNEN, J., and YLI- \n\nOLLI, P. , On the functional form o f earnings and stock prices: international \n\nevidence and implications for the E/P anomaly, Journal o f  Business Finance and \n\nAccounting, 21/3, pp.395-408,1994.\n\n[Bramlette &amp; Bouchard, 1991] BRAMLETTE, M. F. &amp; BOUCHARD, E. E. Genetic \n\nAlgorithm in Parametric Design o f Aircraft, In Handbook o f  Genetic Algorithm, \n\nEdited by L. Davis. New York: Van Nostrand Reinhold, 1991.\n\n[Branting, 1991] BRANTING, K. Exploiting the complementary o f rules and \n\nprecedents with reciprocity and fairness. In: Proceedings fro m  the Case-Based \n\nReasoning Workshop, Washington DC, May 1991. Sponsored by DARPA. Morgan \n\nKaufmann, pp. 39-50,1991.\n\n[Brigham, 1979] BRIGHAM, E. F., Financial Management: Theory and Practice. \n\nDryden Press, p. 769, 1979.\n\n[Broomhead &amp; Lowe, 1988] BROOMHEAD, D. S. &amp; LOWE, D. Multivariable \n\nFunctional Interpolation and Adaptative Networks, Complex Systems 2, pp. 321- \n355, 1988.\n\n[Brown et al., 1990] BROWN, C. &amp; PHILLIPS, M. E. Expert Systems fo r  \n\nManagement Accounts. Management Accounting, pp. 18-23, January, 1 9 9 0 .\n\n[Caldwell &amp; Johnston, 1991] CALDWELL, C. &amp; JOHNSTON, V. S., Tracting a \n\nCriminal Suspect Through \u2018Face-Space\u2019 with a Genetic Algorithm, In Proceedings \n\no f  the Fourth International Conference on Genetic Algorithms, R. K. Belew e L. B. \n\nBooker (eds.), San Mateo, 1991.\n\n[Carpenter &amp; Grossberg, 1987] CARPENTER, G. A. &amp; GROSSBERG, S. A \n\nMassively Parallel Architecture for a Self-Organizing Neural Pattern Recognition \n\nMachine, Computer, Vision Graphics and Image Processing, 37, pp. 54-115, 1987\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas\n147\n\n[Chen &amp; Shimerda, 1981] CHEN, K. H. &amp; SHIMERDA, T. A. An Empirical Analysis \n\no f Useful Financial Ratios. Financial Management, pp. 51-60,1981.\n\n[Chen et al., 1992] CHEN, S; MULGREW, B.; McLAUGHLIN,S. and GRANT,P. M. \n\nAdaptative Bayesian Equalizer with Feedback for Mobile Radio Channels. \n\nWorkshop on Adaptative Algorithms in Communications, Bordeaux, France, 1992.\n\n[Chu, 1992] CHU, Pai-Cheng, Applying Object-Oriented Concepts To Developing \n\nFinancial Systems \u2019, Journal o f  Systems Management, Vol. 43, No. 5, May 1992.\n\n[Colombi et al., 1993] CO LO M BI, J. M. et al. Auditory Model Representation for \n\nSpeaker Recognition. Proceedings o f  the SP1E Applications o f  Artificial Neural \nNetworks IV, Orland, FL, pp. 9-14,1993.\n\n[Courtis, 1978] COURTIS, J.K. Modeling a financial ratios categorical framework. \n\nJournal o f  Business Finance and Accounting 5/4 , 371-386, 1978.\n\n[Cox, 1994] COX, E. \u201cThe Handbook o f Fuzzy Systems\u201d. Academic Press, New \nYork, 1994.\n\np a r w m , 1985] DARWIN, C. R. \u201cOn the Origins o f  Species by Means o f  Natural \nSelection \u201d. Penguin Classics, 1985.\n\nP a v is , 1991] DAVIS, L. \u2018\u2018Handbook o f  Genetic Algorithms\u201d. Van Nostrand \nReinhold, New York, 1991.\n\n[de la Maza, 1989] DE LA MAZA, M, A SEAGUL Visits the Race Tracking. In \n\nProceedings o f  the Third International Conference on Genetic Algorithms, Edited \nby J. D. Schafeer, San Mateo, 1989.\n\n[Deakin, 1976] DEAKIN, E.B Distributions o f financial accounting ratios: some \n\nempirical evidence. Accounting Review, Janeiro, pp. 90-96, 1976.\n\nP eb o eck , 1994] DEBOECK, G\u201e (ed.), Trading on the Edge: Neural, Genetic, Fuzzy \n\nSystems fo r  Chaotic Finantial Marketes, John Wiley, Chichester, 1994.\n\n[Demuth &amp; Beale, 1994] DEMUTH, H. e BEALE, M  Neural Network Toolbox \n\nU ser\u2019s Guide, the Math Works, 1994.\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 148\n\n[Dracopoulos &amp; Jones, 1995] DRACOPOULOS, D. C. e JONES, A. J. Adaptative \n\nNeuro-Genetic Control o f Chaos applied to the Attitude Control Problem. IEEE \n\nTransactions on systems man and Cybernetics, Vol. XX, N5 Y, pp. 1-12 1995.\n\np u t t a  &amp; Shekhar, 1988] DUTTA, S. e SHEKHAR, S. Bond Rating: A non\u00ad\n\nconservative Application o f Neural Networks, Proceeding o f  IEEE International \n\nConference on Neural Networks, San Diego, 1988.\n\n[Edmister, 1972] EDMISTER, R. O. An Empirical Test o f Financial Ratio Analysis \n\nfor Small Business Failure Prediction. Jornal o f  Financila and Qauntitative \n\nAnalysis, Mar\u00e7o, pp. 1477-1493,1982.\n\n[Eisenbeis, 1977] EISENBLES, R. A. Pitfalls in the Applications o f discriminant \n\nAnalysis in Business Fdinance, and economics. Jo m a l o f  Finance, Junho, pp. 875- \n899, 1977.\n\n[Enrado, 1991] ENRADO, P. Application Watch, A I  Expert, September, p. 64,1991. \n\n[Ezzamel &amp; Mar-Molinero, 1990] EZZAMEL, M. and MAR-MOLENERO, C. The \n\nDistributional Properties o f Financial Ratios in UK Manufacturing Companies. \n\nJournal o f  Business Finance and Accounting, v l7 , n l, pp. 1-29, 1990.\n\n[Fauset, 1994] FAUSET, L. Fundamentals o f  Neural Networks - Architectures, \n\nAlgoritms, and applications. Prentice Hall International, Inc., 1994.\n\n[Feigenbaum, 1977] FEIGENBAUM, E. The art o f artificial intelligent: Themes and \n\ncase studies o f knowledge engineering. Proc, Fifth Int. Joint C onf On Artificial \n\nInteligent, Morgan Kaufmann, CA, pp. 1014-1029, 1977.\n\n[Fieldsend et al., 1987] FIELDSEND, S., LONGFORD, N\u201e and MCLEAY, S. Industry \n\neffects and the proportionality assumption in ratio analysis: a variance component \n\nanalysis. Journal o f  Business Finance and Accounting 14/4,497-517 1987\n\n[Folgelman-Souli\u00e8, 1995] FOLGELMAN-SOULI\u00c8, F. Applications o f Neural \n\nNetworks. In the Handbook o f  Brain Theory and Neuro Network, Cambridge, pp. \n94-98, 1995.\n\n[Foster, 1978] FOSTER, G. Financial Statement Analysis. Prentice-Hall, Primeira ed., \n1978.\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 149\n\n[Foster, 1987]----------------Financial Statement Analysis. Prentice-Hall, Englewood\nCliffs, NJ, 1987.\n\n[Foster, 1986] __________  Financial Statement Analysis. Prentice-Hall, 2nd ed.,\n1986.\n\n[Fu, 1994] FU, L. M. Rule Generation from Neural Networks. IEEE Transactions on \n\nSystems, Man and Cybernetics, Vol. 28, No. 8, pp. 1114 - 1124, 1994.\n\n[Fukushima et al\u201e 1983] FUKUSHIMA, K.; MIYAKE, S.; ITO, T\u201e Neocognitron: A \n\nNeural Network Model for a Mechanism o f Visual Pattern Recognition. IEEE \n\nTransaction on Systems, Man, andCybertics SMC-13, pp. 826-834, 1983.\n\n[Fukushima, 1988] FUKUSHIMA, K, Neocognitron: A Hierarchical Neural Network \n\nCapable o f Visual Pattern Recognition. Neural Networks 1, pp. 119-130, 1988\n\n[Gabbert et al\u201e 1989] GABBERT, P. S. et al. A system for Learning Routes and\n\nSchedules whit Genetic Algorithm. In Proceedings o f  the Fourth International\n\nConference on Genetic Algorithms, R. K. Belew e L. B. Booker (eds.), San Mateo, \n1991.\n\n[Gallant, 1988] GALLANT, S., Connectionist Expert Systems. Communications o f  \n\nthe ACM, Vol. 31, No 2 February, pp. 114-136, 1988.\n\n[Goldberg, 1989] GOLDBERG, D. E. Genetic Algorithmis in Search, Optimization, \n\nand Machine Learning. Addison-Wesley, p. 412,1989.\n\n[Gombola &amp; Ketz, 1983] GOMBOLA, M.J., and KETZ, J.E. A  note on cash flo w  and\n\nclassification patterns o f  financial ratios\", Accounting Review 63/1, 105-114, \n1983.\n\n[Goonatilake &amp; Khebbal, 1995a] GOONATILAKE, S. e KHEBBAL, S. Intelligent \n\nHybrid Systems. Jonh Wiley &amp;sons Ltd., 1995.\n\n[Goonatilake &amp; Khebbal, 1995b] _____________ ____________ ___  intelligent\n\nHybrid Systems: Issues, Classifications, and Future Directions, in [Goonatilake &amp; \nKhebbal, 1995a].\n\n[Goonatilake &amp; Treleaven, 1995] GOONATILAKE, S. e TRELEAVEN, P. Intelligent \n\nSystem fo r  Finance and Busines\u2019\u2019s. Jonh Wiley &amp;sons Ltd., 1995.\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 150\n\n[Hamilton &amp; Hufnagel, 1992] HAMILTON, A. e HUFNAGEL, Early Detection o f \n\nEpileptic Attacks . In Applications in Neural Networks, H. G. Schuster (ed.), \nWeinheim, pp. 173-8,1992.\n\n[Hammond, 1989] HAMMOND. C. Case-based planning. Academic Press, 1989.\n\n[Haykin, 1994] HAYKIN, S. Neural Networks: A comprehensive Foundation. \n\nMacmillan College Publish Company, p. 895, New York, 1994.\n\n[He &amp; Lapedes, 1991] HE, X. e LAPEDES, A. Nonlinear Modeling and Predction by \n\nSuccessive Approximation Using Radial Basis Function. Technical Report LA-UR- \n\n91-1375. Los Alamos National Laboratori, Los Alamos, NM, 1991.\n\n[Hebb, 1949] HEBB, D. O. The Organization o f  Behavior, John Wiley &amp; Sons, New \nYork, 1949.\n\n[Hinrichs, 1992] HINRICHS,T. Problem solving in open worlds. Lawrence Erlbaum \nAssociates, 1992.\n\n[Holland, 1975] HOLLAND, J. H. Adaptation in Natural and Artificial Systems. Univ. \no f Michigan Press, 1975.\n\n[Hopfield, 1982] HOPFIELD, J. J. Neural Networks and Physical Systems with \n\nEmergent Collective Computational Abilities. Proc. Natl. Acad. Science. USA 79 \npp. 2555-2558,1982.\n\n[Hopfield, 1984] HOPFIELD, J. J. Neurons with Graded Responde Have Collective \n\nComputational Properties like those o f two-state Neurons. Proceedings o f  the \n\nNational Academy o f  Science, Vol. 81, pp. 3080-3092, 1984.\n\n[Homer &amp; Goldberg, 1989] HORNER, A. &amp; GOLDBERG, D. E. Genetic Algorithms \n\nand Computer-Assisted Music Compositioa In Proceedings o f  the Fourth \n\nInternational Conference on Genetic Algorithms, R. K. Belew e L. B. Booker \n(eds.), San Mateo, 1991.\n\n[Homik, et al. 1989] HORNIK, K, et al.. Multilayer feedforward networks are \n\nuniversal approximators. Neural Networks 2 ,  pp.359-366,1989.\n\n[Horrigan, 1965] HORRIGAN, J.O. Some empirical bases o f financial ratio analysis. \n\nAccounting Review, Julho, pp. 558-568, 1965.\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 151\n\n[Homgan, 1966]______________ The Determination o f Long-Term Credit Standing\n\nWith Financial ratio. Empirical Research in Accounting: Selected Studies, \n\nSupplement to Journal o f  Accounting Research 4, pp. 44-62, 1966.\n\n[Horrigan, 1 9 6 8 ]---------------------- A short History o f  Financial ratio analysis. The\n\nAccounting Review, Abril, pp. 284-294,1968.\n\n[Horrigan, 1983] --- ------------------  Methodological implications o f non-normally\n\ndistributed financial ratios: a comment. Journal o f  Business Finance and \n\nAccounting 10/4, pp. 683-689,1983.\n\n[Ingram &amp; Copeland, 1984] INGRAM R. W. &amp; COPELAND R.M. The Association \n\nBetween Municipal Accounting Numbers and Credit Risk and Returns. In \n\nAdvances in Accounting, Vol. l,p p . 19-40, 1984.\n\n[Jacobs, 1988] JACOBS , R. Increased rates o f  convergence through learning rate \n\nadaptation. Neural Networks 1, pp. 295-307, 1988.\n\n[Jang &amp; Sun, 1995] JANG, J. S. R. &amp; SUN, C. T. Neuro-Fuzzy Modeling and Control. \n\nProceedings o f  the IEEE, Vol. 83, No. 3, pp. 378-406, 1995.\n\n[Jonhson, 1978] JOHNSON, W.B. The cross-sectional stability o f financial patterns. \n\nJournal o f  Business Finance and Accounting 5/2, pp. 207-214, 1978.\n\n[Kalkunte et al, 1992] Kalkunte, S. S., KIMAR, M, e PATNAIK, L. M. A neural \n\nnetwork approach for high resolution fault Diagnosis in Digital Circuits. \n\nProceedings o f  the IJCNN-92, Beijing, Vol. I, pp. 1-83,1-88,1992.\n\n[Kanade et al., 1994] KANADE, T.; REED, M. L. e WEISS, L. E. New Tecnologies \n\nand applications in Robotics, Communications o f  the ACM, Vol. 37, N5 3, pp 58- \n67, 1994.\n\n[Kandel &amp; Langholz, 1992] KANDEL, A. e LANGHOLZ, G. Hybrid Architectures fo r  \n\nIntelligent Systems. Ed. CRC Press. Inc., 1992.\n\n[Kandel, 1993] KANDEL, A. Interview. P C A I, pp. 40-41, Mar./Abr, 1993.\n\n[Karels &amp; Prakash, 1987] KARELS, G. V., e PRAKASH, A. Multivariate Normality \n\nand Forecasting o f Business Bankruptcy. Journal o f  Business Finance and \nAccounting, Winter, 1987.\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 152\n\n[Karr, 1991] KARR, C. Applying Genetics to Fuzzy Logic. A I  Expert, 1991.\n\n[Karr, 1995] Karr, C. Genetic Algorithms and Fuzzy Logic for adaptive control, in\n\n[ Goonatilake &amp; Kheball, 1995a] .\n\n[Kasabov, 1996] Kasabov, K. Foundations o f  Neural Networks, Fuzzy Systems and \n\nKnowledge Enginnering. MIT Press, 1996.\n\n[Kassam &amp; Cha, 1993] KASSAM, S. A. &amp; Cha, I. Radial Basis Functions Networks in \n\nNonlinear Signal Processing Applications. 27s Annual Asilomar Conference on \n\nSignals, Systems, and Computers Pacific Grove, CA, 1993.\n\n[Katon, 1989] KATON, P. Using experience in lerarning and problem solving . \n\nMassachusetts Institute o f Technology, Laboratory o f Computer Science (Ph. D. \n\nDiss, October, 1988). MIT/LCS/TR-441. 1989.\n\n[Khebbal &amp; Shamhong, 1995] KHEBBA1, S. e SHAMHONG, D. Tools and \n\nEnvironments fo r  Hybrid Systems, in [Goonatilake &amp; Khebbal, 1995a].\n\n[Kimoto et al., 1990] KIMOTO, T. et. All. Stock Market Prediction System with \n\nModular Neural Networks. In proceeding o f  the IEEE International Joint \n\nConference or Neural Network, IEEE, pp. 11 - 16, San Diego, CA, 1990.\n\n[Kingdon &amp; Feldman, 1995] KINGDON, J. &amp; FELDMAN, K. Genetic Algorithms for \n\nBankruptcy Prediction. SearchSpace Research Report 01, SearchSpace Ltda, \nLondon, 1995.\n\n[Kitano, 1993] KITANO, K. Challenges for massive parallelism. IJCAI-93, \n\nProceedings o f  the Thirteenth International Conference on Artificial Intelligence, \n\nChambeiy, France. Morgan Kaufmann .pp. 813-834,1993.\n\n[Klir &amp; Yuan, 1995] KLIR, G. J. &amp; YUAN, B. Fuzzy sets and fu zzy logic - theory and \n\napplications. Prentice Hall, p.574, 1995.\n\n[Klymasauskas, 1991] KLYMASAUSKAS, C. C. Using ANNs for Credit Approval. \n\nP C  AI, Jan/Fev, 1991, pp. 30 - 33 and Mar/Apr, pp. 27 - 34, 1991.\n\n[Kohonen, 1972] KOHONEN, T. Correlation Matrix Memories. IEEE Transaction on \n\nComputers C-21, pp. 353-359, 1972.\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 153\n\n[Kohonen, 198 2 ]-------------------- Self-organized formation o f  topologically correct\n\nfeature maps. Biological Cybernetics, v. 43, p. 59-69, 1982.\n\n[Kohonen, 1988] ------------------ -- The \u201cNeural\u201d Phonetic Typewriter. IEEE\n\nComputer, Vol. 21, N2 3, pp. 11 -22, 1988.\n\n[Kohonen, 1990]-------------------- The self-organizing map. Proceedings o f  the IEEE,\n78:1464-1497,1990.\n\n[Kolodner, 1983a] KOLODNER, J. Maintaining organization in a dinamic long-term \n\nmemory. Cognitive Science, Vol.7, s.243-280,1983.\n\n[Kolodner, 1983b] -------------------- Reconstructive memory, a computer model.\n\nCognitive Science, Vol.7. s.281-328, 1983.\n\n[Kolodner, 1992] --------------- ----  An Introduction to case-based Reasoning\n\nArtificial Intelligence Review 6 (1], pp .3 .3 4 ,1992.\n\n[Komer, 1967] KORNER, S. Laws o f  thought Encyclopedia o f  Philosophy, Vol. 4, \nMacMillan, NY:, pp. 414-417,1967.\n\n[Kosko, 1992] KOSKO, B. Neural Networks and Fuzzy Systems. Prentice Hall, \nEnglewood Cliffs, NJ, 1992.\n\n[Kung, 1993] KUNG, S. Y. Digital Neural Networks. Prentice-Hall, Englewood \nCliffs, NJ, 1993.\n\n[Lacher et al, 1993] LACHER, R. C.; COATS, P. K.; SHARMA, S. C. e FANT, L. F.\n\nA neural Network fo r  Classifying the Financial Health o f  a First. Technical Report \n\no f  the Florida State University, Dept, o f Computer Science, 1993.\n\n[Laitmen, 1983] LAITINEN, E.K. A multivariate model o f the financial relationship \n\nin the firm. Finnish Journal o f  Business Economics 32/4, 317-333, 1983\n\n[Lapedes &amp; Farber, 1988] LAPEDES, A. e FARBER, R. How Neural Nets Work. In \n\nNeural Information Processing Systems, D. Z. Anderson (ed.), American Institute \nO f Physics, New York, 1998.\n\n[Laurent, 1979] LAURENT, C.R. Improving the Efficiency and Effectiveness o f \n\nFinancial Ratio Analysis. Journal o f  Business Finance &amp; Accounting Vol. 6, No.\n3, pp.401-413, 1979.\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 154\n\n[Lecun, 1985] LECUN, Y. Une Procedure d \u2019aprendissage pour Receau a seuil \n\nAssymetrique, Cognitiva 85, pp. 599-604, 1985.\n\n[Lee &amp; Wu, 1988] LEE, C. F.; WU, C. Expectation Formation and Financial Ratio \n\nAdjustment Process. The Acounting Review, v53, n2, 1988.\n\n[Lejewsk, 1967] LEJEWSK, C. I. Jan Lukasiewicz. Encyclopedia o f  Philosophy, Vol.\n\n5, MacMillan, NY:, pp. 104-107,1967.\n\n[Lev &amp; Sander, 1979] LEV, B\u201e and SUNDER, S. Methodological issues in the use of \n\nfinancial ratios. Journal o f  Accounting and Economics 1/3, pp. 187-210, 1979.\n\n[Lev, 1974] LEV, B. Financial Statement Analysis. Prentice-Hall, Englewood Cliffs, \nNJ, 1974.\n\n[Levy et al., 1991] LEVY J., et al. A Fuzzy Logic Evaluation System for Commercial \n\nLoan Analysis. Omega, Vol. 19, N^\u00f6, 1991.\n\n[Liebowitz, 1990] LIEBOWITZ, J. (editor), Expert System fo r  Business and \n\nManagemen. Englewood Cliffs, NJ: Prentice-Hall, 1990.\n\n[Lopez &amp; Plaza, 1993] LOPEZ, B, PLAZA, E. Case-based planning for medical \n\ndiagnosis, In: J. Komorowski, Z.W. Ras (Eds.) Methodologies fo r  Intelligent \n\nSystems: 7th International Symposium, p. 96-105. Lecture Notes in Artificial \n\nIntelligence 689. Springer Verlag, 1993.\n\n[Lowe &amp; Webb, 1990] LOWE, D. e WEBB, A. R. Exploiting prior knowledge in \n\nnetwork optimization: An Illustration from medical prognosis. Network 1, pp. 299- \n323, 1990.\n\n[Luoma &amp; Ruuhela, 1991] LUOMA, M., and RUUHELA, R. Consistency and \n\nComovement o f Financial Ratios: a Firm-Specific Approach. Finnish Journal o f  \nBusiness Economics 1, pp. 39-49, 1991.\n\n[Maiers e Sherif, 1985] MAIERS, J. e SHERIF, Y. S. Applications o f Fuzzy Set \n\nTheory. IEEE Trans. Systems, Man and Cybernetics, vol. SMC-15, N2 1, pp. 175- \n189, Fev. 1985.\n\n[Martin-del-Brio &amp; Serrano-Cinca, 1995] MARTIN-DEL-BRIO, B. &amp; SERRANO- \n\nCINCA, C. Self Organizing Neural Networks: The Finantial State o f Spanish \n\nCopanies. Universidad the Zaragoza, Spain, in [Refenes, 1995].\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 155\n\n[Martins, 1996] MARTINS, A. R., \u201cM odellinf Financial Statements Analysis fo r  \n\nIndicating Correstive Actions to Financial Problems \u201d, Disserta\u00e7\u00e3o de Doutorado, \n\nUniversidade Federal de Santa Catarina, Departamento de Engenharia de \n\nProdu\u00e7\u00e3o, 1996.\n\n[Martins et al\u201e 1996] MARTINS, A., PACHECO, R., WEBER-LEE, R., BARCIA, R. \n\nM., Integrating Expert Networks and CBR in a Hybrid Architecture to Analyze the \n\nFinancial Health o f a Firm. Brazil 2nd International Congress o f  Industrial \n\nEngineering and 16th National Congress o f  Production Engineering - ENEGEP , \n\nOctober, 7 -1 0 , Piracicaba, S\u00e3o Paulo, Brasil, 1996.\n\n[Matarazzo, 1987] MATARAZZO, D. C. An\u00e1lise Financeira de Balan\u00e7os - \n\nAbordagem B \u00e1 sica , 2~ Edi\u00e7\u00e3o, S\u00e3o Paulo, Ed. Atlas, 1987.\n\n[McCulloch &amp; Pitts, 1943] MCCULLOCH, W. S. &amp; PITTS, W. A Logical Calculus of \n\nIdeas Immanent in Nervous Activity. Bulletin o f  Mathematical Biophysics 5, pp. \n115-133, 1943.\n\n[McDonald &amp; Morris, 1984] MCDONALD, B., and MORRIS, M.H. The statistical \n\nvalidity o f  the ratio method in financial analysis: an empirical examination. \n\nJournal o f  Business Finance and Accounting 11/1, pp. 89-97, 1984.\n\n[McDonald &amp; Morris, 1985]___________________________  The functional\n\nspecification o f financial ratios: an empirical examination. Accounting and \n\nBusiness Research 15/59, (1985), pp. 223-228.\n\n[McLeay &amp; Fieldsend, 1987] MCLEAY, S., and FIELDSEND, S. Sector and size \n\neffects in ratio analysis: an indirect tests o f a ratio proportionality. Accounting and \n\nBusiness Research 17/66, pp. 133-140, 1987.\n\n[Mecimore, 1968] MECIMORE, C.D. Some empirical distributions o f financial \n\nratios. Management Accounting 50/1, pp. 13-16, 1968.\n\n[Medsker &amp; Bailey, 1992] MEDSKER, L. e BAILEY, D. Models and Guidelines for \n\nIntegrating Expert Systems and Neural Networks. In Hybrid Architectures fo r \n\nIntelligent Systems, Ed. by Abraham Kandel and Gideon Langholz, CRC Press, \n\nBoca Raton, Florida, USA, 1992.\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 156\n\n[Micchelli, 1986] M CCHELLI, C. A. Interpolation o f Scattered Data: Distance \n\nMatrices and Conditionally Positive Definite Function. Constructive \n\nApproximation 2, pp. 11-22, 1956.\n\n[Minsky &amp; Papert, 1969] MINSKY, M. L. &amp; PAPERT, S. A. Perceptrons. \n\nCambridge, MA: MIT Press, 1969.\n\n[Moallemi, 1991] MOALLEMI, C. Classifing Cells for Cancer Diagnosis Using \n\nNeural Networks. IEEE Expert, December, pp. 8-12,1991.\n\n[Montana, 1995] MONTANA, D. Neural Network weight selection using genetic \n\nalgorithms, in [Goonatilake &amp; Kheball, 1995a].\n\n[Moody &amp; Darken, 1989] MOODY, J. E. &amp; DARKEN, C. J. Fast Learning in \n\nNetworks o f Locally-tuned Processing U nit Neural Computation 1, pp. 281- \n294,1989.\n\n[Morose, 1990] MOROSE, R. A. A Financial Neural-Network Application. A I  Expert, \nMaio, pp. 50-53, 1990.\n\n[Morose, 1993] MOROSE, R. A. A Financial Neural-Network Application. Neural \n\nNetworks in Finance and Investing, R . R . Trippi e E. Turban (eds.), Probus \n\nPublishing, Chicago, pp. 75-83,1993.\n\n[Mui et al\u201e 1990] MUI, C. K ; HAFELL, C. e COURTIS, L. The Financial \n\nStatements Analyser. In [Liebowitz, 1990] pp. 127-142,1990.\n\n[Neto, 1983] NETO, A. A. Estrutura e An\u00e1lise de Balan\u00e7o - Um enfoque Econ\u00f4mico- \n\nfinanceiro. 2\u00ae Edi\u00e7\u00e3o, S\u00e3o Paulo, Ed. Atlas, 1983.\n\n[Neto, 1995] NETO, J. S. Uma estrutura Fuzzy-Neural-Gen\u00e9tica-Ca\u00f3tica para \n\npredi\u00e7\u00e3o da tend\u00eancia global de curto prazo do mercado de a\u00e7\u00f5es. I I  Congresso \n\nBrasileiro de Redes Neuronais - III Escola de Redes Neuronais, Curitiba, \nNovembro, 1995.\n\n[Newquist, 1987] NEWQUIST m , Harvey P. In Practice: American Express and AI: \n\nD on\u2019t Leave Home Without Them. A I Expert, pp. 63-65, April 1987.\n\n[Ng e Lippmann, 1991] NG, K. e LIPPMAN, R. P. Practical Characteristics o f Neural \n\nNetwork and Conventional Pattern Classifiers. In Advance In Neural Information\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 157\n\nProcessing systems 3, R. P. Lippmann, J. E. Moody and D. S. Touretzky (Eds.), \n\nMorgan Kalfmann, SanM ateo, CA, pp. 970-976,1991.\n\n[Niranjan e Fallside, 1990] NIRANJAN, M. e FALLSIDE, J. Neural Networks and \n\nRadial Basis Functions in Classifyng Static Speech Patterns. Computer Speech \n\nand Language 4, pp. 275-289,1990.\n\n[Odom &amp; Shardo, 1990] ODOM, M. &amp; SHARDO, R. A Neural Network Model for \n\nBankruptcy Prediction. In Proceedings o f  the International Joint Conference on \n\nNeural Networks, 1990.\n\n[Odom &amp; Shardo, 1993]________________________ A Neural Network Model for\n\nBankruptcy Prediction. Decision Support Systems, Vol. 9, N. 6,1993.\n\n[Ohlson, 1980] OHLSON, J, A. Financial Ratios and the Probabilistic Prediction o f \n\nBankruptcy. Journal o f  Accounting Research, Spring, pp 109-131,1980.\n\n[Pacheco, 1996] PACHECO, R. C. S. A Hybrid Intelligent System fo r  Diagnosing and \n\nSolving Financial Problems o f  Small Retail Firms. Ph.D. Dissertation, \n\nUniversidade Federal de Santa Catarina UFSC, Programa de P\u00f3s-gradua\u00e7\u00e3o em \n\nEngenharia de Produ\u00e7\u00e3o, Brasil, 1996.\n\n[Packard, 1990] PACKARD, N. H  A Genetic Learning Algorithm for the Analysis of \n\nComplex D ata Complex Systems 4, pp. 543-572, 1990.\n\n[Pandya &amp; Macy, 1995] PANDYA, A. &amp; MACY,R.B. Pattern Recognition with \n\nNeural Networks in C++. CRC Press, 1995.\n\n[Parker, 1985] PARKER, D. B. Learning-Logic: Casting the Cortex o f  the Human \n\nBrain in Silicon. Technical Report TR-47. Center for Computational Research in \n\nEconomics and Manegement Science, MIT, Cambridge, MA, 1985.\n\n[Patterson et al\u201e 1993] PATTERSON, D. W.; CHAN, K. H. e TAN, C. M. Time \n\nSeries Forecasting with Neural Networks: A Comparative Study. Proceedings o f  \n\nthe International Conference on Neural Network Applications to signal \n\nProcessings (NNASP-93), Singapore, pp. 269-74,1993.\n\n[Patterson, 1995] PATTERSON, D. W. Artificial Neural Networks - Theory and \n\nApplications. Prentice Hall, 1995.\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 158\n\n[Pau, 1991] PAU, L. F. Artificial Intelligence and Financial Services. IEEE \n\nTransactions on Knowledge and Data Engineering, Vol. 3, No. 2 , pp. 137-148, \nJune 1991.\n\n[Pinches &amp; Mingo, 1973] PINCHES, G. E., &amp; MINGO, K.A. A multivariate analysis \n\no f  industrial bond ratings. Journal o f  Finance, 28/1, 1-18, 1973.\n\n[Poggio &amp; Girosi, 1990] POGGIO, T. , GIROSI, F. Networks fo r  approximation and \n\nlearning. Proceedings o f  the IEEE, v. 78, p. 1481-1497, 1990.\n\n[Poggio e Edelman, 1990] POGGIO, T. e EDELMAN, S. A Network that Learns to \n\nRecognize three-dimensional Objects. Nature (London) 343, pp. 263-266,1990.\n\n[Porter et al\u201e 1986] PORTER, B.; BAREISS, R. e PROTOS, D. An experiment ine \n\nknowledge acquisition for heuristic classification cases, m . Proceedings o f  the \n\nFirst International Meeting on Advances in Learning (IMAL), Les Arcs, France, \n\npp. 159-174,1986.\n\n[Powell, 1985] POWELL, M. J. D. Radial Bases Function for Multivariable \n\nInterpolation: A Review. In IMA Conference on Algorithms fo r  the Approximation \n\no f  Functions and Data., RMCS, Shrivenham, pp. 143-167, 1985.\n\n[Radding, 1991] RADDING, A. C. Loan Experts in the Struggle to Limit Risk. Bank \n\nManagement, pp. 48-50, July 1991. (also reprinted in [Zahed, 1993] pp. 102-104)\n\n[Radecki, 1982] RADECKI, T. An Evaluation o f the Fuzzy Set Theory Approach to \n\nInformation Retrieval, in R. Trappl, N. V. Findler, and W. Horn, Progress in \n\nCybernetics and System Research, Vol. 11: Proceedings o f a Symposium \n\nOraganized by the Austrian Society for Cybernetic Studies, Hemisphere Publ. \nCo.,NY: 1982.\n\n[Raitz et al., 1997] RAITZ, R; SOUZA, J.A.; DANDOLINI, G. A.; PACHECO, R.; \n\nMARTINS, A., GAUTHIER, F &amp; BARCIA, R.. Learning by Means o f Free \n\nAssociative Neurons. NAFIPS 97: Annual Meeting O f The North American Fuzzy \n\nInformation Processing Society, September 21-24, Syracuse, New York, 1997.\n\n[Ram, 1990] RAM, S. e RAM, S. Screening Financial Innovations: An Expert System \n\nApproach. IEEE Expert, Vol. 5, No. 9, pp. 20-27, August - 1990.\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 159\n\n[Refenes, 1995] REFENES, A. (Editor) Neural Networks in the Capital Markets. \n\nWiley Finance Edition, 1995.\n\n[Rege, 1984] REGE, U. P. Accounting Ratios to Locate takeover Targets. Journal o f  \n\nBusiness Finance and Accounting, pp. 391-41 l,outono, 1984.\n\n[Richter, 1993] RICHTER. MM. Similarity, uncertainty and case-based reasoning in \n\nPATDEX. In R.S. Boyer (ed.): Automated reasoning, essays in honour ofW ooody \n\nBledsoe. Kluwer, pp. 249-265,1993.\n\n[Ritter et al\u201e 1992] RITTER, H. I ,  MARTINETZ, T. e SCHULTEN, K. J. Neural \n\nComputation and Self-Organizing Maps: An Introduction. Addison-Wesley, \nReading, MA, 1992.\n\n[Rosen &amp; Silverman, 1992] ROSEN, E. M. e SILVERMAN, D. C. Corrosion \n\nPrediction from Polarization Scans Using an Artificial Neural Network Integrated \n\nwith an Expert System Corrosion, September, pp. 734-744,1992.\n\n[Rosenblatt, 1958] ROSENBLATT, F. The Perceptron: A probabilistic model for \n\ninformation storage and organization in the brain. Psychological Review 65, 386- \n408, 1958.\n\n[Rosenblatt, 1962]__________________  Principles o f  Neurodynamics. Washington,\nDC: Spartan Books, 1962.\n\n[Rosenfeld, 1993] ROSENFELD, E. Intelligence , (a periodical). To subscribe, call \n\n800-NEURALS, ou send e-mail to ier@aol.com.\n\n[Rumelhart et al., 1986] RUMELHART, D. E; HINTON, G. E. e WILLIAMS, R  J. \n\nLearning internal representation by error propagation. In Romelhart DE., \n\nMcClelland JL (eds.), Parallel Distributed Processings Exploration in the \n\nMicrostructure o f  Cognition, vol. 1 foundations. Cambridge, Mass, MIT Press, \n1986.\n\n[Saha et al., 1991] SAHA, A. et al. Oriented non-radial basis functions for Image \n\nCoding and analysis. In Advance In Neural Information Processing systems 3, R.\n\nP. Lippmann, J. E. Moody and D. S. Touretzky (Eds.), Morgan Kalfmann, San \n\nMateo, CA, pp. 728-134,1991.\n\nmailto:ier@aol.com\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 160\n\n[Salmi &amp; Martikainen, 1994] SALMI, T., &amp; MARTDCAINEN, T. A Review o f the \n\nTheoretical and Empirical Basis o f Financial Ratio Analysis. Finish Journal o f  \n\nBusiness Economics 4(94), 1994.\n\n[Schank, 1982] SCHANK, R. Dynamic Memory: a theory o f  reminding and learning \n\nin computers and people. Cambridge University Press, 1982.\n\n[Self, 1990] SELF, K. Designing with Fuzzy Logic. IEEE Spectrum, pp. 42-44, Nov. \n1990.\n\n[Senjen et al\u201e 1993] SENJEN, R.; BELER, M.; LECKIE, C. e ROWLES, C. Hybrid \n\nExpert Systems for Monitoring and Fault Diagnosis. Proceedings o f  9th IEEE \n\nConference on Artificial Intelligence fo r  Applications, Orlando, FL, M arch 1-5, pp. \n235-241,1993.\n\n[Silva, 1988] SILVA, J. P. An\u00e1lise Financeira das Empresas., Ed. Atlas, 1988.\n\n[Simpson, 1985] SIMPSON. L. A computed model o f case-based reasoning in \n\nproblem solving. An investigation in the domain o f dispute mediation. Technical \n\nReport GIT-ICS-85/18, Georgia Institute o f Technology, 1985.\n\n[Sone, 1993] SONE, T. Using Distributed Neural Networks to Identify Faults in \n\nSwitching Systems, Proceedings o f  the International Workshop on applications o f  \n\nNeural Netwosks to Telecommunications, J. Alspector, R. Goodman e T. X. Brown \n\n(eds.), Lawrence Erlbaum Assocoates, Hillsdale, NJ, 1993.\n\n[Souza, 1995] SOUZA, M. C. A. F.de. Pequenas e M\u00e9dias Empresas na \n\nReestrutura\u00e7\u00e3o Industruial, Sebrae, 1995.\n\n[Spooner &amp; Passino, 1996] SPOONER, J.T. e PASSINO, K. M. Stable Adaptative \n\nControl Using Fuzzy Systems and Neural Networks, IEEE Transactions on Fuzzy, \n\nVol. 4, N2- 3, pp. 339-359, Agosto, 1996.\n\n[Sycara, 1988] SYCARA, K. Using case-based reasoning for plan adaptation and \n\nrepair. ProceedingsCase-Based Reasoning Workshop, DARPA. Clearwater beach, \n\nFlorida, Morgan Kaufman, pp. 425-434, 1988.\n\n[Syswerda &amp; Palmucci, 1991] SYSWERDA, G. e PALMUCCI, J. The Application o f \n\nGenetic Algorithm to Resource Scheduling. In Proceedings o f  the Fourth\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 161\n\nInternational Conference on Genetic Algorithms, R. K. Belew e L. B. Booker \n\n(eds.), San Mateo, 1991.\n\n[Szu et al\u201e 1992] SZU, W. K.; LIU, W.; CHAO, C. C.; LIN, H. F.; HSU, T. e \n\nMEDSKER, L. Proceedings o f  the IJCNN-92, Beijing, pp. 1-333,1-339,1992.\n\n[Tamari, 1978] TAMARI, M. Financial Ratios. Analysis and Prediction. Paul Elek \n\nLtd., London, 1978.\n\n[Thomas &amp; Evanson, 1986] THOMAS, J. &amp; EVANSON, R. V. An Empirical \n\nInvestigation o f  Association Between Financial Ratio use and Small Business \n\nSuccess, pp. 555-565, 1986.\n\n[Thorpe et al\u201e 1991] THORPE, C.; KANADE, T. e SHAFER, S. Toward \n\nAutonomous Driving: The CMU NavLab, IEEE Expert, Agosto, pp. 31-42,1991.\n\n[Tirri, 1995] TIRRI, H. Replacing the pattern matcher o f na expert system with a \n\nneural network. Em [Goonatilake &amp; Kheball, 1995J.\n\n[Turban, 1992] TURBAN, E. Expert Systems and Applied Artificial Intelligence. New \nYork: Macmillan, 1992.\n\n[Turban, 1995] __________ Decision Support and Expert Systems - Management\n\nSupport Systems, 4~ Edi\u00e7\u00e3o, Ed. Prentice Hall International, 1995.\n\n[Umbers e King, 1980] UMBERS, I.G. and KING, P.J. An analysis o f  human \n\ndecision-making in cement kiln control and the implications for automation Int. \n\nJrnl. o f  Man-Mach. Stud., Vol. 12, pp. 11-23, 1980.\n\n[Ventamakaran, 1983] VENTAMAKARAN, S. A rule-rule-case based system for \n\nimage analysis. In. First European Workshop on Case-based Reasoning, Posters \n\nand Presentations, 1-5 November 1993. Vol.H. University o f  Kaiserslaustem, pp. \n410-415. 1993.\n\n[Waller, 1989] WALLER, L. Fuzzy Logic: It\u2019s Comprehensible, It\u2019s Plactical - And \n\nIt\u2019s Commerical. Electronics, pp. 102-103, 1989.\n\n[Wasserman &amp; Schwartz, 1988] WASSERMAN, P. D. e SCHWARTZ, T. Neural \n\nNetworks, Part 2: What are They and Why is Everybody so Interested inThem \n\nNow? IEEE Expert, Spring, pp. 10-12, 1988.\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 162\n\n[Watson, 1990] WATSON, C. J. Multivariate Distributional Properties, Outliers, and \n\nTransformation o f  Financial Ratios\u201d Accounting Review 65/3, 682-695, 1990.\n\n[Weber, 1993] WEBER, R.O. Sistema Especialista Difuso Para An\u00e1lise De Cr\u00e9dito. \n\nMaster Thesis, Universidade Federal de Santa Catarina UFSC, Programa de P\u00f3s- \n\nGradua\u00e7\u00e3o em Engenharia de Produ\u00e7\u00e3o, Florian\u00f3polis, 1993.\n\n[Weber-Lee, 1996] WEBER-LEE, R.. Case-Based Reasoning. Home page. EPS- \nUFSC.BR, 1996.\n\n[Weber-Lee et al., 1995] WEBER-LEE, R; BARCIA, R. M., KHATOR, S., Case- \n\nBased Reasoning for Cash Flow Forecasting using Fuzzy Retrieval, in M. Veloso, \n\n..and A. Aamodt, (Eds.), Case-Based Reasoning Research and Development, First \n\nInternational Conference, ICCBR-95, Sesimbra, Portugal, October 23 - 26,1995.\n\n[Werbos, 1974] WERBOS, P. J. Beyond Regression: New tools fo r  Prediction and \n\nAnalysis in the Behavioral Sciences. Ph.D. Thesis, Harvard University, Cambridge, \nMA, 1974.\n\n[Werbos, 1982] _____________ Application o f Advances in Nonlinear Sensitivity\n\nAnalysis. Em System Modeling and Optimization: Proc. O f  the Int. Federation fo r  \n\nInformation Processes, R. Drenick &amp; F. Kozin (eds.), pp. 762-770,1982.\n\n[Werbos, 1 9 9 0 ]---------------------- Backpropagation through time: What it does and\n\nhow to do it. Proceedings o f  the IEEE, 87:10, 1990.\n\n[Whalen &amp; Schott, 1985] WHALEN, T. &amp; SCHOTT, B. Generalized Network \n\nModeling and Diagnosis Usilg Financial Ratios. Information Sciences 37, 1985, pp \n179-192.\n\n[White et al., 1994] WHITE, G.I., SOHNDI, A  C. &amp; FRIED, D. The Analysis and \n\nUse o f  Financial Statements. John Wiley &amp; Sons, Inc., New York, 1994.\n\n[Whiteley &amp; Davis, 1993] WHITELEY, J. R. &amp; DAVIS, J. F. Qualitative \n\nInterpretation o f Sensor Patterns. IEEE Expert, Abril, pp. 54-63, 1993.\n\n[Widrow &amp; Hoff, 1960] WIDROW, B. &amp; Hoff, M. E. Adaptative Switching Circuits. \n\nIR E  WESCON Convention Record, pp. 56-104, 1960.\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 163\n\n[Widrow et al., 1994] WIDROW, B.; RUMELHART, D., e LEHR, M.. Neural \n\nNetworks. Applications in Industry, Business and Science. Communications o f  the \n\nACM, Vol. 37, No 3, pp. 490-501,1994.\n\n[Wiener &amp; Pinson, 1988] WIENER, R. S. &amp; PINSON, J. An Introduction to Object- \n\nOriented Programming and C+ +. Addison-Wesley, Reading, MA, 1988.\n\n[Wilson &amp; Hoff, 1994] WILSON, R. L. &amp; HOFF, R. Bankrupty Prediction Using \n\nNeural Networks. Decision Support Systems, Vol. 11, N\u00b0 5, pp. 545-557, 1994.\n\n[Yanicoglu &amp; Sandon, 1993] YANICOGLU, B. A., e SANDON, P. A. O ff Line \n\nCursive Handwriting Recognition Using Neural Networks. Proceedings o f  the \n\nSPIE Applications o f  Artificial Neural Networks IV, Orland, FL, pp. 102-6,1993.\n\n[Yli-Olli &amp; Virtanen, 1986] YLI-OLLI, P., AND VIRTANEN, I. Classification pattern \n\no f financial ratios. A comparative analysis between US and Finnish firms on the \n\naggregate level. Finnish Journal o f  Business Economics 2, 112-132, 1986.\n\n[Yli-Olli &amp; Virtanen, 1989] YLI-OLLI, P., &amp; VIRTANEN, I., \u201cOn the long-term \n\nstability and cross-country invariance o f  financial ratio patterns\u201d. European \n\nJournal o f  Operational Research 39/1,40-53, 1989.\n\n[Yli-Olli &amp; Virtanen, 1990] YLI-OLLI, P., &amp; VIRTANEN, I. Transformation analysis \n\napplied to long-term stability and structural invariance o f financial ratio patterns: \n\nU.S. vs. Finnish firms. American Journal o f  Mathematical and Management \n\nSciences 10/1-2, pp. 73-125, 1990.\n\n[Yonn et al., 1994] YONN, Y\u201e GUIMAR\u00c3ES, T. &amp; SWALES, G. Integrating \n\nArtificial Neural Networks with Rule-Based Expert Systems. Decision Support \n\nSystems, Vol. 11, pp. 497-507, 1994.\n\n[Zadeh, 1965] ZADEH, L.A. Fuzzy sets. Information and Control, Vol. 8, 1965, pp. \n\n338-353.\n\n[Zadeh, 1968]_____________ Fuzzy algorithms. Info. &amp; Ctl., Vol. 12, 1968, pp. 94-\n102.\n\n[Zadeh, 1984]_____________ _ Making computers think like people. IEEE Spectrum\n8, pp. 26-32,1984.\n\n\n\nRefer\u00eancias Bibliogr\u00e1ficas 164\n\n[Zahed, 1993] _____________ Intelligence Systems fo r  Busines. Expert Sytems with\n\nNeural Networks, Belmont California, 1993.\n\n\n\nAP\u00caNDICE A\n\nDADOS DE TREINAMENTO E TESTE\n\ns ANO C Ope Lliq CG V TIE Endiv SITUA\u00c7\u00c3O'\n1 95 1.7 1.4 3.2 376 1222 6\n2 94 -0.7 -0.7 5.3 -88 390 2\n3 95 26.9 25.6 75.0 9 13 3\n4 94 -9.0 -9.0 259.4 -1171 120 5\n5 95 3.5 3.1 25.0 2 75 4\n6 94 0.8 0.5 28.5 1 75 6\n7 95 1.7 1.4 6.5 177 58 2\n8 94 -0.2 -0.2 3.8 -49 64 2\n9 95 -2.4 -2.4 63.1 0 32 5\n10 94 13.5 12.1 47.8 6 12 3\n11 95 35.4 27.5 0.1 464 6 1\n12 94 46.9 40.5 8.5 22253 14 1\n13 95 15.5 13.0 1.5 67 39 1\n14 94 27.4 27.4 0.5 265 27 1\n15 95 0.1 0.1 82.4 1 231 7\n16 93 7.4 5.2 265.9 18 62 3\n17 95 3.7 2.8 104.2 2 28 3\n18 94 29.4 28.0 68.2 13 12 3\n19 95 36.5 28.8 3.1 102 10 1\n20 95 9.5 8.1 116.1 10 76 3\n21 94 6.3 4.7 67.2 23 26 3\n22 95 -3.4 -3.4 r 20.6 1 20 2\n23 93 87.3 79.9 62.3 196 15 3\n24 95 3.7 2.1 3.2 95 8 1\n25 94 6.0 6.0 3.9 284 30 1\n26 95 68.0 65.5 1.6 682 11 1\n27 95 5.8 4.4 43.0 117 30 3\n28 94 1.2 0.9 38.1 231 109 5\n29 95 56.0 53.6 1.4 2681 3 1\n30 94 31.0 29.6 0.2 222 5 1\n31 95 1.9 1.4 55.2 4 494 7\n32 93 0.1 0.1 11.3 1 900 6\n33 95 3.4 2.5 3.6 803 4 1\n34 94 1.7 1.2 5.4 159 1 2\n35 95 18.8 17.1 2.5 66 16 1\n36 94 21.4 14.6 5.5 1003 72 1\n37 95 2.8 2.2 5.7 2 171 2\n38 94 0.8 0.8 5.5 2 125 2\n39 95 53.2 50.7 1.8 324 1 1\n40 94 -55.7 -55.7 0.8 1 110 2\n\nTabela A -l : Dados de treinamento.\n\n\n\nAp\u00eandice\n166\n\nN\u201c ANO C Ope ... Lliq CG V TIE Endiv SITUA\u00c7\u00c3O'40 94 -55.7 -55.7 0.8 1 110 2\n41 95 55.0 52.6 -7.6 477 1 1\n42 94 10.8 8.1 6.0 147 30 1\n43 95 1.2 0.9 73.9 2 1178 7\n44 94 -0.2 -0.2 6.9 1 743 6\n45 95 24.7 17.3 5.2 156 70 1\n46 94 -3.6 -3.6 18.2 -7 179 6\n47 95 1.3 1.0 7.4 817 144 248 95 -5.5 -5.5 8.9 -2 600 6\n\nN 49 95 91.8 84.3 10.7 191 6 1\n\\  50 95 -23.7 -24.9 115.9 -33 238 7\n\n\\51 94 1.6 1.4 97.8 4 792 752 95 -0.1 -0.1 295.2 0 1198 7\n53 95 -1.6 -1.6 12.5 0 13 2\n54 95 14.0 10.5 1.5 528 1 1\n55 95 47.8 47.8 219.8 107 62 356 93 53.0 50.2 48.6 141 24 3\n\nTabela A-2  : Dados de Teste.\n\nObserva\u00e7\u00e3o: A classifica\u00e7\u00e3o da \u00faltima coluna indica: (1) rentabilidade\n(2) giro\n(3) endividamento\n(4) rentabilidade e giro\n(5) rentabilidade e \n\nendividamento\n(6) giro e endividamento\n(7) nenhum dos anteriores\n\n\n\nAP\u00caNDICE B\n\nHISTOGRAMAS DOS \u00cdNDICES \nFINANCEIROS\n\n25.0000\n\n20.0000 -\n\n15.0000 -\n\n10.0000 \n\n5,0000 +  \n\n0,0000\n\nCaixa Op\n\nnP vP o\"\n8  ?\n\n1 s? sP ^o oT\u201c\nos\n\n1\n%\n\n\n\nAp\u00eandice\n168\n\nCG d de V\n\no\nCM\n\nO o o o o\n(D CM CM o LO\n\ni T ~ ?*\u201c CM CM\nO 1 i i i\n\nO O O o00 CM o\nT\u201c- T \u2014 CM\n\nOin\nCM\n\n\n\nAp\u00eandice 169\n\nEndividamento\n\n%\n\n\n\nAP\u00caNDICE C \n\nRESULTADOS DA BACKPROPAGATION\n\nBACKPROPAGATION COM DADOS NORMALIZADOS NO\nINTERVALO f-1,11 E FTJN\u00c7\u00c2\u00d2 DE ATTVAC\u00c2O SIGMOID AT\nUne Epocas 1 T \u2014  r**: : r = ' -\u2014 ---------------------Neur\u00f4nios\n\n1000\n\nTaxa de \nAprendizagem\n\nMomentum\n\n0,010 0,90\n\nTreinamento\n\n60,00\n\nTeste (%\n\n50,00\n\nTempo (s\n\n11,20_3_\n5\n\n1000\n1000\n\n0,010\n0,010\n\n0,90 72,50\n0,90\n\n68,75\n75,00 56,25\n\n11,75\n12,53\n\n9\n1000\n1000\n\n0,010 0,90 82,50\n0,010 0,90\n\n62,50\n80,00 62,50\n\n13,35\n14,0111\n\n13\n1000\n1000\n\n0,010 0,90 87,50 75,00 14,77\n0,010 0,90 80,00 50,00 15,6015\n\n17\n1000\n1000\n\n0,010 0,90 85,00 68,75 16,21\n19\n21\n\n1000\n1000\n\n0,010 0,90\n0,010\n\n82.50\n0,90\n\n68,75\n87,50 75,00\n\n16,81\n17,68\n\n23\n30\n\n11\n11\n_9_\n7\n\n11\n\n1000\n1000\n3000\n2000\n2000\n2000\n2000\n3000\n3000\n1500\n3000\n2000\n1500\n\n0,010 0,90\n0,010 0,90\n0,010\n0,001\n0,001\n\n0,90\n0,90\n\n0,010\n0,100\n0,700\n0,800\n0,010\n0,010\n0,001\n0,010\n0,600\n\n0,90\n0,90\n0,80\n0,10\n0,10\n0,90\n0,90\n0,90\n0,80\n0,01\n\n82,50 68,75\n77,50 68,75\n85,00 62,50\n90,00 68,75\n82,50 68,75\n87,50 68,75\n82,50 68,75\n65,00 56,25\n75,00 56,25\n92.50\n85,00\n\n56,25\n62,50\n\n87,50\n80,00\n\n68,75\n56,25\n\n72,50 68,75\n\n18,29\n19,22\n22,24\n39,76\n29,44\n29,28\n29,06\n27,95\n39,93\n41,74\n21,04\n39,93\n26,15\n22,2413 1000\n\n2000\n200\n400\n600\n\n0,200\n0,001\n0,010\n0,010\n\n0,90 77.50 56,25\n0,95 90,00\n0,90 57,50\n\n75,00\n\n0,010\n0,90\n\n56,25\n67,50\n\n0,90 57,50\n56,25\n50,00\n\n15,44\n26,86\n2,80\n5,22\n7,58\n\n5\n10\n\n700\n900\n1000\n1400\n\n0,010 0,90\n0,010\n\n72,50\n0,90\n\n68,75\n65,00\n\n0,010 0,90\n0,010\n\n75,00\n0,90\n\n50,00\n68,75\n\n82,50 68,75\n\n9,01\n11,26\n12,52\n\n2000\n1000\n\n0,020\n0,200\n\n0,90 87,50 68,7510\n10\n\n0,80 75,00 75; 00 14,06\n7_\n7\n\n_7_\n9\n\n2000\n2000\n2000\n2000\n3000\n3000\n2500\n\n0,200 0,80\n0,700\n\n80,00\n0,40\n\n56,25\n87,50\n\n0,001 0,90 87,50\n0,900\n\n62,50\n56,25\n\n0,10\n0,0010\n\n77,50\n0,80\n\n56,25\n\n0,010\n82,50 75,00\n\n0,90 90,00 75,00\n\n28,02\n25,59\n25,76\n26,26\n41,14\n39.10\n34,490,001 0,90 85,00 68,75\n\n\n\nAp\u00eandice\n\n11 2500 0,600 0,20 80,00 68,75 36,03\n6 3000 0,800 0,10 82,50 68,75 38,29\n6 3000 0,800 0,30 82,50 56,25 36,64\n7 3000 0,200 0,90 87,50 \u00ed 75,00 39,05\n7 5000 0,900 0,01 87,50 56,25 66,62\n13 1000 0,700 0,50 72,50 56,25 15,32\n13 1000 0,010 0,90 87,50 68,75 15,43\n11 2000 0,100 0,80 82,50 62,50 28,94\n7 : 3000 0.001 0,90 90,00 75.00 38,95\n\n? : 7 2500 0,001 : 0,90 90,00 75,00 32,41\n7 2000 0,001 0,90 82,50 68,75 25,98\n7 2000 0,001 0,90 80,00 68,75 25,87\n\n??? 7 3000 0,001 0,93 90,00 75,00 38,94\n9 3000 0,050 0,92 85,00 56,25 41,30\n7 3000 0,050 0,90 87,50 68,75 38,95\n7 3000 0,0010 0,90 85,00 62,50 38,77\n5 3000 0,020 0,92 87,50 56,25 36,69\n10 500 0,010 0,80 67,50 50,00 7,30\n10 1000 0,010 0,80 70,00 62,50 14,11\n11 2000 0,300 0,80 87,50 62,50 31,80\n7 2500 0,700 0,20 72,50 56,25 34,05\n15 1000 0,010 0,80 82,50 68,75 16,757 1200 0,100 0,90 85,00 68,75 16,81\n7 2000 0,100 0,90 87,50 68,75 27,90\n7 2500 0,100 0,90 87,50 75,00 34,76\n\nm m ? ' ? j\n7 1000 0,100 0,90 85,00 62,50 14,18\n7 2000 0,100 0,90 87,50 62,50 27,96\n7 2500 0,100 0,90 87,50 62,50 35,04\n7 3000 0,010 0,90 87,50 62,50 42,137 500 0,010 0,80 60,00 56,25 7,25\n7 2000 0,010 0,90 77,50 50,00 27,687 3000 0,100 0,90 82,50 56,25 41,47\n9 1000 0,010 0,90 77,50 50,00 13,85\n9 500 0,200 0,80 77,50 68,75 7,58\n9 800 0,020 0,80 77,50 68,75 11,919 2000 0,020 0,80 90,00 68,75 29,551 3000 0 , 0 3 0  : 0,80 87,50 75,00 44,21\n9 5000 0,001 0,80 87,50 50,00 74,159 2500 0,001 : 0,90 87,50 75,00 37,13\n9 ?? 2800 0,001 0,90 87,50 75,00 41,309 3200 0,001 0,90 87,50 62,50 47,349 4000 0,800 0,20 90,00 68,75 58,999\n\n'P. ?_? _ y\u2014\u00bb  ? i\n2000 0,900 0,10 77,50 68,75 29,77\n\nTabela C -l: Resultado da Backpropagation usando fun\u00e7\u00e3o de ativa\u00e7\u00e3o sigmoide na camada \nescondida e linear na \u00faltima camada.\n\n\n\nAp\u00eandice\n173\n\nIN\niCKPROPAGATION COM DADOS NORMALIZADOS NO \nTERVALO {-1,1] E FUN\u00c7\u00c3O DE ATIVA\u00c7\u00c3O TANGENTE \n\nHIPERB\u00d3LICA.\nNeur\u00f4nios Epocas Taxa de \n\nAprendizaaem\nMomenturr Treinamento\n\n(%)\nTeste (%; Tempo (s)\n\n13 2000 0,100 0,90 87,50 68,75 31,20\n9 2000 0,200 - 0,90 90,00 75,00 28,23\n7 2000 0,010 0,90 85,00 68,75 26,47\n7 3000 0,010 0,90 85,00 62,50 40,10\n7 2000 0,100 0,90 72,50 68,75 26,36\n9 1000 0,100 0,90 82,50 56,25 14,17\n5 2000 0,200 0,95 82,50 62,50 25,05\n5 2000 0,500 0,80 80,00 68,75 24,71\n7 1000 0,600 0,10 75,00 68,75 13,46\n7 1000 0,600 0,01 67,50 56,25 13,51\n7 1000 0,600 0,20 75,00 68,75 13,23\n7 2000 0,600 0,01 65,00 56,25 26,86\n9 1000 0,600 0,10 72,50 68,75 14,23\n6 1000 0,500 0,50 75,00 62,50 12,74\n6 1000 0,800 0,40 70,00 68,75 12,75\n7 2000 0,010 0,90 80,00 68,75 26,47\n\n1 \"v; i:' ..\n6 3000 o,ooi : 0,90 85,00 75,00 38,55\n\n'? ' ? 9 3000 0,001 0,80 87,50 75,00 42,13\n8 2000 0,800 0,10 62,50 62,50 27,46\n9 200 0,100 0,90 77,50 68,75 3,13\n9 400 0,100 0,90 77,50 75,00 5,88\n9 500 0,900 0,20 70,00 62,50 7,36\n9 600 0,900 0,20 70,00 68,75 8,51\n9 800 0,900 0,20 77,50 68,75 11,20\n9 1000 0,900 0,10 72,50 68,75 14,06\n9 1500 0,900 0,20 82,50 75,00 20,98\n9 2000 0,900 0,20 52,50 43,75 27,58\n9 2000 0,900 0,20 82,50 56,25 27,96\n9 2000 0,200 0,90 85,00 75,00 28,23\n9 200 0,200 0,90 70,00 43,75 3,13\n9 400 0,200 0,90 75,00 62,50 5,82\n9 500 0,200 0,90 72,50 68,75 7,30\n\n? 7 / 1000 0,300 0,80 75,00 75,00 14,01\n7 1500 0,100 0,90 80,00 62,50 20,99\n7 2000 0,200 0,80 85,00 62,50 27,85\n9 3000 0,020 0,90 90,00 68,75 45,04\n7\n\nrr\u00bb _ i_i _ a i\n3000 0,010 0,80 87,50 56,25 41,86\n\nTabela C-2 : Resultado da Backpropagation usando fun\u00e7\u00e3o de ativa\u00e7\u00e3o tangente hiperb\u00f3lica \nna camada escondida e linear na ultima camada.\n\n\n\nAp\u00eandice\n174\n\nBA\n1 ? IN'\n\nCKPR(\nr E R V A\n\n)PAGATION COM DADOS NORMALIZADOS \nLO [0,11 E FUNC\u00c3O DE A T I V A \u00c7 \u00c3 O  s r c M n f t\n\nNO\n)AL\n\nNeur\u00f4nios \u00c9pocas Taxa de \nAprendizaaem\n\nMomentum Treinamento\n\u00ed%)\n\nTeste (%) Tempo (s)\n9 4000 0,100 0,90 82,50 37,50 54 987 2000 0,010 0,90 82,50 56,25 26 0915 1000 0,800 0,20 62,50 37,50 15 9313 800 0,400 0,10 60,00 56,25 13 246 2000 0,010 I 0,90 87,50 43,75 25 1511 2000 0,100 0,90 82,50 56,25 28 8411 3000 0,010 0,90 77,50 50,00 43 0611 5000 0,001 0,90 87,50 43,75 72 8820 1000 0,010 0,90 75,00 50,00 17 6320 1000 0,200 0,90 82,50 43,75 17 6315 2000 0,700 0,10 72,50 31.25 32 35\n\nla b ela  C-3 : Resultado da Backpropagation usando fun\u00e7\u00e3o de ativa\u00e7\u00e3o sigmoidi \ncamada escondida e linear na \u00faltima camada.\n\nil na\n\nBACKPROPAGATION COM DADOS NORMALIZADOS NO\nINTERVALO [-1,1] E FUN\u00c7\u00c3O DE ATIVA\u00c7\u00c3O N\u00c3O LINEAR NAS\n\nDUAS CAMADAIS mmm\nNeur\u00f4nios \u00c9pocas Taxa de Momentum Treinamento Teste (%) Tempo\n\nAprendizaaem (%) ' ' \u00eds)1 500 0,700 0,30 35,00 31,25 5,665 1000 0,800 0,10 35,00 31,25 12,411 500 0,010 0,90 35,00 31,25 5,7110 1000 0,700 0,20 35,00 31,25 14,395 1000 r 0,010 0,90 35,00 r 31,25 12,366 1000 0,010 0,90 35,00 31,25 12,637 1000 0,010 0,90 35,00 31,25 12,9620 1000 0,010 0,90 35,00 31,25 18,627 1000 0,900 0,10 35,00 31,25 12,97\nTabela C-4 : Resultado da Backpropagation usando fun\u00e7\u00e3o de ativa\u00e7\u00e3o n\u00e3o linear \n(sigmoidal e tangente hiperb\u00f3lica) na camada escondida e na camada de sa\u00edda.\n\n\n\nAP\u00caNDICE D\n\nRESULTADOS DA RBF\n\nRBF COM DADOS NORMALIZADOS NO T N T F R V A T  n  r.i 11\nCentros Raio Epocas Treinamento\n\n<%)\nTeste (%) Tempo(s)\n\n20 1,10 20 87,50 56,25 15,00\n10 1,50 10 70,00 68,75 6,31\n6 1,30 6 57,50 56,25 13,40\n9 1,80 9 62,50 50,00 8,68\n12 1,20 12 60,00 75,00 10,05\n11 1,30 11 65,00 56,25 7,03\n12 1,50 12 67,50 68,75 5,11\n11 1,50 11 62,50 75,00 15,98\n10 1,00 10 60,00 50,00 12,96\n17 1,00 17 87,50 50,00 10,33\n16 1,00 16 85,00 56,25 5,99\n15 1,00 15 75,00 62,50 3,35\n18 1,00 18 85,00 31,25 5,49\n15 1,30 15 77,50 81,25 6,21\n12 1,60 12 72,50 50,00 20,05\n30 1,20 30 90,00 43,75 7,36\n30 1,50 30 90,00 31,25 12,25\n39 1,00 40 100,00 31,25 12,14\n10 1,80 10 65,00 56,25 13,57\n35 1,20 34 100,00 37,50 15,32\n20 1,20 20 85,00 68,75 7,25\n20 1,60 20 87,50 56,25 9,28\n20 1,40 20 87,50 68,75 9,34\n20 1,50 20 90,00 62,50 10,88\n20 1,70 20 85,00 68,75 6,16\n20 1,50 20 90,00 62,50 13,13\n30 1,20 30 90,00 43,75 8,13\n30 1,20 30 90,00 43,75 16,37\n30 2,00 30 90,00 25,00 13,56\n30 1,50 30 90,00 31,25 6,92\n30 1,40 30 90,00 31,25 7,80\n30 1,20 30 90,00 43,75 10,21\n3 1,20 2 50,00 37,50 9,28\n7 1,00 6 65,00 56,25 4,07\n11 1,40 10 62,50 56,25 6,43\n7 1,00 6 65,00 56,25 8,19\n7 1,00 6 65,00 56,25 0,77\n8 1,00 7 57,50 56,25 0,88\n9 1,00 8 57,50 56,25 0,94\n10 | 1,00 9 60,00 50,00 0,99\n\n\n\nAp\u00eandice\n176\n\n11 1,00 10 6 0 ,0 0 5 0 ,0 0 0,9 9\n12 1,00 11 6 5 ,0 0 50 ,0 0 1,15\n13 1,00 12 6 2 ,5 0 6 2 ,5 0 1,21\n14 1,00 13 75 ,0 0 56 ,2 5 1,26\n15 1,00 14 75 ,0 0 6 2 ,5 0 1,32\n16 1,00 15 85 ,0 0 5 6 ,2 5 1,37\n7 1,10 6 6 0 ,0 0 50 ,0 0 0,7 7\n8 1,10 7 6 0 ,0 0 5 6 ,2 5 0,9 3\n9 1,10 8 6 2 ,5 0 56 ,2 5 . 0 ,9 3\n10 1,10 9 6 5 ,0 0 6 2 ,5 0 0 ,9 3\n11 1,10 10 6 5 ,0 0 6 8 ,7 5 1,04\n12 1,10 11 6 5 ,0 0 75 ,0 0 1,21 ,\n13 1,10 12 6 7 ,5 0 6 2 ,5 0 1,16\n14 1,10 13 70 ,0 0 6 2 ,5 0 1,27\n15 1,10 14 8 0 ,0 0 6 2 ,5 0 1,32\n16 1,10 15 8 0 ,0 0 6 8 ,7 5 1,54\n7 1,20 6 6 5 ,0 0 50 ,0 0 0,7 7\n8 1,20 7 6 2 ,5 0 56 ,2 5 0 ,8 8\n9 1,20 8 70 ,0 0 6 2 ,5 0 0,9 4\n\n10 1,20 9 62 ,5 0 5 0 ,0 0 0,9 9\n11 1,20 10 6 5 ,0 0 75 ,0 0 0 ,9 9\n12 1,20 ; 11 6 0 ,0 0 75 ,0 0 1,15\n13 1,20 12 72 ,5 0 6 8 ,7 5 1,21\n14 1,20 13 80 ,0 0 7 5 ,0 0 1,43\n15 1,20 14 80 ,0 0 6 8 ,7 5 1,37\n16 1,20 15 8 2 ,5 0 6 8 ,7 5 1,38\n7 1,30 6 6 2 ,5 0 50 ,0 0 0 ,8 3\n8 1,30 7 6 5 ,0 0 56 ,2 5 0 ,9 3\n9 1,30 8 57 ,5 0 5 0 ,0 0 0 ,9 9\n\n10 1,30 9 6 2 ,5 0 5 6 ,2 5 1,05\n11 1,30 10 6 5 ,0 0 56 ,2 5 1,04\n12 1,30 11 6 5 ,0 0 4 3 ,7 5 1,21\n13 1,30 12 65 ,0 0 68 ,7 5 1,38\n14 1,30 13 77 ,5 0 ^ ^ 3 2 ^ - 4 '\n15 1,30 14 7 7 ,5 0\n16 1,30 15 8 2 ,5 0 75 ,0 0 1,38\n7 1,40 6 6 5 ,0 0 56 ,2 5 0 ,8 3\n8 1,40 7 6 5 ,0 0 5 6 ,2 5 0 ,9 4\n9 1,40 8 6 2 ,5 0 50 ,0 0 0 ,9 4\n\n10 1,40 9 6 2 ,5 0 56 ,2 5 0 ,9 9\nTabela D - l : Resultados do desempenho da rede RBF usando os dados nen \nintervalo [-1,1].\n\nmalizados no\n\n\n\nAp\u00eandice\n177\n\nRBFCOM\nCentrai\n\nDADOS NORMALIZADOS NO INTERVALO fO,l]\nRaio \u00c9pocas Treinamento\n\n(%)\nTeste Tempo\n\n- J \u00eaL15.00\n10.00\n15.00\n16.00 \n16,00\n16,00\n16,00\n13.00\n11.00\n7.00\n7.00\n7.00\n7.00\n7.00\n9.00\n\n20.00\n19.00\n12.00\n12,00\n12,00\n12,00\n12,00\n12,00\n18,00\n5.00\n5.00\n8.00\n9.00\n9.00\n10.00\n7.00\n7.00\n7.00\n5.00\n\n30.00\n15.00\n25.00\n11.00\n11,00\n14.00\n7.00\n8.00\n9.00\n10.00\n11,00\n12,00\n\n1.30 \n1,00\n1.30 \n0,80 \n1,20\n1.30\n1.50 \n1,20\n1.30\n1.50 \n1,20\n1.30 \n1,00 \n1,00\n1.30 \n1,00 \n1,20 \n2,00\n1.50 \n1,40\n1.30 \n1,20 \n1,10 \n1,20\n1.50 \n1,00\n1.30 \n0,80 \n0,50 \n0,80 \n0,50 \n0,90 \n1,00 \n1,00 \n1,00 \n1,60 \n0,70 \n0,90 \n0,70 \n1,10 \n1,00 \n1,00 \n1,00 \n1,00 \n1,00 \n1,00\n\n14.00\n9.00\n14.00\n15.00\n15.00\n15.00\n15.00\n12.00 \n10,00 \n6,00 \n6,00 \n6,00 \n6,00 \n6,00 \n8,00\n19.00\n18.00\n11,00\n11,00\n11,00\n11,00\n11,00\n11,00\n17.00\n4.00\n4.00\n7.00\n8.00 \n8,00\n9.00\n6.00 \n6,00 \n6,00\n4.00\n\n29.00\n14.00\n24.00\n10.00\n10,00\n13.00\n6.00\n7.00\n8.00\n9.00\n10.00\n11,00\n\n77.50\n60,00\n77.50\n77.50\n77.50\n75.00\n77.50\n70.00\n65.00\n65.00\n62.50\n65.00\n65.00\n65.00\n67.50\n87.50\n85.00\n65.00\n65.00\n65.00\n65.00\n65.00\n65.00\n77.50\n47.50\n50.00\n65.00\n62.50\n62.50\n67.50\n62.50\n65.00\n65.00\n50.00\n90.00\n77.50\n90.00\n67.50\n67.50\n77.50\n65.00\n67.50\n57.50\n60.00\n72.50\n70,00\n\n50.00\n25.00\n50.00\n31.25\n43.75\n50.00\n50.00\n50.00\n43.75\n56.25\n62.50\n56.25\n25.00\n25.00\n50.00\n31.25\n43.75\n50.00\n62.50\n62.50\n50.00\n62.50\n43.75\n50.00\n43.75\n37.50\n43.75\n50.00\n31.25\n50.00\n31.25\n50.00\n25.00\n37.50\n6.25\n50.00\n6.25\n\n56.25\n31.25\n37.50\n25.00\n31.25\n25.00\n25.00\n50.00\n50.00\n\n7,85\n4,45\n5,60\n10,32\n7,52\n8,79\n4.88 \n8,02 \n5,49 \n5,71 \n4,67 \n6,26\n3.35 \n4,18 \n6,15 \n16,81\n8.35 \n19,45\n7.85\n4.88\n5.66 \n6,20 \n5,44 \n12,20\n5.66\n8.35\n5.66 \n6,92\n6.86 \n6,20 \n9,78 \n8,85 \n0,93 \n0,77 \n2,42 \n1,37\n2.14 \n1,10 \n1,10 \n1,32 \n0,88 \n0,93\n1.15 \n1,04 \n1,10 \n1,26\n\n\n\nAp\u00eandice\n\n13,00\n14,00\n15.00\n16.00\n\n1,00\n1,00\n1,00\n\n12,00\n13,00\n14,00\n\n80,00\n80,00\n77,50\n\n56,25\n56,25\n56,25\n\n1,32\n1,37\n1,43\n\n1,00 15,00 77,50 43,75 1,60\n7,00 0,90 6,00 65,00 50,00 0,82\n8,00 0,90 7,00 65,00 56,25 0,94\n9,00 0,90 8,00 62,50 62,50 0,94\n10,00 0,90 9,00 72,50 50,00 0,99\n11,00\n12,00\n\n0,90 10,00 67,50 56,25 1,04\n\n13,00\n0,90\n0,90\n\n11,00 67,50 50,00\n12,00 70,00 43,75\n\n1,21\n1,26\n\n14,00 0,90 13,00 77,50 50,00 1,32\n15.00\n16.00\n\n0,90 14,00 80,00 50,00 1,43\n\n7.00\n8.00\n\n0,90\n0,80\n\n15,00 80,00 56,25\n6,00 65,00 50,00\n\n1,43\n0,82\n\n0,80 7,00 62,50 50,00 0,88\n9,00 0,80 8,00 62,50 50,00 0,9910,00 0,80 9,00 67,50 50,00 1,04\n11,00 0,80 10,00 67,50 50,00 1,10\n12,00 0,80 11,00 77,50 56,25 1,21\n13,00 0,80 12,00 72,50 43,75 1,37\n14,00 0,80 13,00 75,00 62,50 1,32\n15,00 0,80 14,00 77,50 50,00 1,38\n16,00 0,80 15,00 77,50 31,25 1,37\n7,00 0,70 6,00 57,50 31,25 0,83\n8,00 0,70 7,00 60,00 31,25 0,94\n9.00\n10.00\n\n0,70 8,00 60,00 43,75 0,99\n\n11,00\n0,70\n0,70\n\n9,00 60,00 37,50\n10,00 67,50 31,25\n\n1,04\n1,05\n\n12,00\n13,00\n14,00\n15,00\n\n0,70\n0,70\n0,70\n0,70\n\n11,00 80,00 43,75\n12,00 82,50 43,75\n13,00 80,00 43,75\n14,00 80,00 25,00\n\n1,38\n1,26\n1,37\n1,37\n\n16,00\n7,00\n8,00\n9,00\n\n0,70\n0,50\n0,50\n0,50\n\n15,00 85,00 25,00\n6,00 62,50 31,25\n7,00 60,00 31,25\n8,00 62,50 31,25\n\n1,49\n0,82\n0,93\n0,9810,00 0,50 9,00 60,00 31,25 1,15\n\n11,00\n12,00\n13,00\n\n0,50\n0,50\n0,50\n\n10,00 65,00 37,50\n11,00 70,00 31,25\n12,00 82,50 25,00\n\n1,10\n1,21\n1,27\n\n14,00\n15,00\n\n0,50\n0,50\n\n13,00 80,00 25,00\n14,00 77,50 18,75\n\n1,32\n1,42\n\n16,00\n7,00\n8,00\n9,00\n10,00\n11,00\n\n0,50\n0,30\n0,30\n0,30\n0,30\n0,30\n\n15,00 85,00 25,00\n6,00 50,00 31,25\n7,00 52,50 31,25\n8,00 65,00 31,25\n9,00 72,50 31,25\n10,00 75,00 31,25\n\n1,43\n0,82\n1,04\n0,93\n0,99\n1,04\n\n\n\nAp\u00eandice\n179\n\n12,00 0,30 11,00 85,00 31,25 1,21\n13,00 0,30 12,00 82,50 31,25 1,27\n14,00 0,30 13,00 82,50 31,25 1,26\n15,00 0,30 14,00 80,00 31,25 1,37\n16,00 0,30 15,00 75,00 31,25 1,53\n7,00 0,10 6,00 62,50 31,25 0,82\n8,00 0,10 7,00 72,50 31,25 0,88\n9,00 0,10 8,00 72,50 31,25 ' 0,99\n10,00 0,10 9,00 75,00 31,25 1,04\n11,00 0,10 10,00 75,00 31,25 1,10\n12,00 0,10 11,00 77,50 31,25 1,21\n13,00 0,10 12,00 80,00 31,25 1,31\n14,00 0,10 13,00 77,50 31,25 1,32\n15,00 0,10 14,00 80,00 31,25 1,59\n16,00 0,10 15,00 80,00 31,25 1,43\n7,00 1,10 6,00 62,50 62,50 0,82\n8,00 1,10 7,00 65,00 31,25 0,93\n9,00 1,10 8,00 65,00 50,00 0,99\n10,00 1,10 9,00 65,00 56,25 1,04\n11,00 1,10 10,00 62,50 43,75 1,05\n12,00 1,10 11,00 65,00 43,75 1,26\n13,00 1,10 12,00 70,00 31,25 1,43\n14,00 1,10 13,00 77,50 37,50 1,32\n15,00 1,10 14,00 75,00 50,00 1,43\n16,00 1,10 15,00 75,00 56,25 1,43\n7,00 1,20 6,00 62,50 62,50 0,83\n8,00 1,20 7,00 62,50 37,50 0,94\n9,00 1,20 8,00 65,00 50,00 0,99\n10,00 1,20 9,00 65,00 62,50 1,04\n11,00 1,20 10,00 65,00 43,75 1,20\n12,00 1,20 11,00 65,00 62,50 1,27\n13,00 1,20 12,00 70,00 50,00 1,32\n14,00 1,20 13,00 75,00 43,75 1,31\n15,00 1,20 14,00 75,00 43,75 1,38\n16,00 1,20 15,00 77,50 43,75 1,43\n7,00 1,30 6,00 65,00 56,25 0,88\n8,00 1,30 7,00 65,00 43,75 0,94\n9,00 1,30 8,00 67,50 50,00 1,16\n10,00 1,30 9,00 65,00 62,50 1,10\n11,00 1,30 10,00 65,00 43,75 1,10\n12,00 1,30 11,00 65,00 50,00 1,21\n13,00 1,30 12,00 72,50 43,75 1,26\n14,00 1,30 13,00 70,00 37,50 1,32\n15,00 1,30 14,00 77,50 50,00 1,37\n16,00 1,30 15,00 75,00 50,00 1,43\n7,00 1,50 6,00 65,00 56,25 1,05\n8,00 1,50 7,00 65,00 43,75 0,93\n9,00 1,50 8,00 67,50 56,25 0,99\n10,00 1,50 9,00 65,00 62,50 0,99\n\n\n\nAp\u00eandice 180\n\n11,00 1,50 10,00 65,00 43,75 1,04\n12,00 1,50 11,00 65,00 62,50 1,21\n13,00 1,50 12,00 72,50 50,00 1,27\n14,00 1,50 13,00 67,50 43,75 1,32\n15,00 1,50 14,00 77,50 50,00 1,37\n16,00 1,50 15,00 77,50 50,00 1,59\n\nTabela D-2 : Resultados do desempenho da rede RBF usando os dados normalizados no \nintervalo [0,1].\n\n\n\nAP\u00caNDICE E\n\nRESULTADOS DA LVQ\n\nResultados da LVQ com os Dados N\u00e3o Nnrm?i;7arios\nTaxa de \n\nAprendizaaerr\n\u00c9pocas Treinamentc\n\n(%)\n- Teste \n\n(%)\nTempo\n\n(s)\n0,10 23,00 37,50 50,00 4,17\n0,10 20,00 32,50 25,00 3,57\n0,10 21,00 50,00 50,00 3,79\n0,10 22,00 37,50 43,75 3,95\n0,10 24,00 40,00 50,00 4,45\n0,10 2,00 27,50 0,00 0,33\n0,10 25,00 50,00 43,75 4,45\n0,10 26,00 45,00 43,75 4,66\n0,10 19,00 37,50 12,50 3,52\n0,10 27,00 37,50 43,75 4,83\n0,10 28,00 40,00 50,00 4,99\n0,20 23,00 17,50 31,25 3,68\n0,10 25,00 50,00 31,25 3,96\n0,01 20,00 27,50 0,00 3,19\n0,01 50,00 37,50 0,00 7,96\n0,40 40,00 20,00 31,25 6,43\n0,30 20,00 17,50 31,25 3,19\n0,90 20,00 25,00 0,00 3,52\n0,80 40,00 5,00 18,75 6,21\n0,60 50,00 20,00 0,00 7,86\n0,50 25,00 32,50 31,25 3,95\n0,40 25,00 12,50 31,25 3,90\n0,40 40,00 20,00 31,25 6,32\n0,20 25,00 22,50 31,25 3,90\n0,20 4,00 12,50 0,00 0,66\n0,10 20,00 32,50 31,25 3,24\n0,01 25,00 30,00 12,50 3,95\n0,01 30,00 30,00 12,50 4,84\n0,01 15,00 30,00 0,00 2,47\n0,10 23,00 37,50 31,25 3,68\n0,10 24,00 40,00 31,25 3,85\n0,10 21,00 50,00 31,25 3,35\n\nTabela E - l : Resultados da rede LVQ usando os dados n\u00e3o normalizados \ne a taxa de aprendizagem decresce linearmente em fun\u00e7\u00e3o do n\u00famero de \n\u00e9pocas.\n\n\n\nAp\u00eandice\n\nResultados da LVQ com os Dados N\u00e3o Normafizadns\nTaxa de \n\nAprendizaaerr\n\u00c9pocas Tremamentc\n\n(%)\nTeste\n(%)\n\nTempo\n(s)\n\n0,100 20 20,00 37,50 3,57\n0,100 10 32,50 25,00 1,86\n0,100 15 20,00 18,75 2,64\n0,100 21 17,50 12,50 3,74\n0,100 22 30,00 12,50 3,96\n0,100 23 27,50 12,50 4,23\n0,100 24 32,50 12,50 4,34\n0,100 30 20,00 31,25 5,38\n0,100 32 22,50 12,50 5,93\n0,700 13 35,00 31,25 2,37\n0,600 20 25,00 12,50 3,63\n2,000 30 12,50 31,25 5,43\n0,600 20 25,00 12,50 3,73\n0,400 20 20,00 12,50 3,62\n0,300 21 15,00 12,50 3,74\n0,300 23 17,50 0,00 4,07\n0,100 50 40,00 31,25 8,41\n0,200 25 25,00 31,25 4,01\n0,100 20 20,00 31,25 3,18\n0,200 20 25,00 31,25 3,18\n0,600 20 25,00 0,00 3,13\n0,010 ' 20 7,50 62,50 3,13\n0,050 20 12,50 31,25 3,18\n0,020 20 7,50 50,00 3,19\n0,001 20 7,50 62,50 3,18\n0,010 50 5,00 31,25 7,85\n0,100 10 32,50 0,00 1,60\n0,100 40 45,00 31,25 6,37\n0,200 50 7,50 31,25 7,96\n0,010 25 5,00 62,50 4,01\n0,010 15 7,50 31,25 2,42\n0,010 25 5,00 62,50 4,06\n0,010 30 5,00 43,75 4,83\n0,001 20 7,50 62,50 3,24\n0,001 10 10,00 31,25 1,65\n0,050 20 12,50 31,25 3,19\n0,003 20 7,50 62,50 | 3,18\n\nTabela E-2: Resultados da rede LVQ usando os dados n\u00e3o normalizados \ne a taxa de aprendizagem decresce n\u00e3o linearmente em fun\u00e7\u00e3o do \nn\u00famero de \u00e9pocas.\n\n\n\nAp\u00eandice\n\nResultados da LVQ com os Dados N o rm a liz a rin s\nTaxa de \n\nAprendizagerr\n\u00c9pocas Treinamento\n\n(%>\nTeste\n\n(%)\nTempo * \n\n(s)\n0,1C 2c 6 2 ,5C 5 0 ,0C 12,80\n0,1C 22 5 7 ,5C 5 0 ,0C 11,75\n0.1C 24 5 5 ,0C 43,75 12,96\n0,1C 1C 5 2 ,5C 43,75 5,27\n0,1C 1\u00a3 5 7 ,5C 43,75 ' 8,02\n0,20 1C 50,00 50,00 5,21\n0,20 3C 60,00 56,25 15,81\n0,2C 40 77,50 6 2 ,5 0 2 0 ,7 6\n\nv 0,20 45 80,00 62 ,5 0 2 3 ,7 8\n0,10 50 72,50 6 2 ,5 0 2 5 ,9 8\n0 ,2 0 6 0 6 2 ,5 0 5 0 ,0 0 31,64\n0,1 0 72,50 6 2 ,5 0 28 ,5 6\n0,3 0 20 2 7 ,5 0 3 1 ,2 5 10,98\n0 ,3 0 4 0 2 7 ,5 0 31 ,2 5 21,81\n0,05 2 0 6 5 ,0 0 4 3 ,7 5 11,26\n0,0 5 4 0 6 2 ,5 0 6 2 ,5 0 21,91\n0,0 5 50 6 5 ,0 0 6 2 ,5 0 27 ,2 4\n0 ,1 0 6 0 70 ,0 0 5 6 ,2 5 32 ,3 5\n0,1 0 72,50 6 2 ,5 0 2 6 ,4 7\n0 ,1 0 ' ? .^ .^ ? ^ 5 0 7 2 ,5 0 6 2 ,5 0 2 7 ,5 7\n0 ,2 0 ? ?;? % f ^ : 4 0 77 ,5 0 6 2 ,5 0 2 3 ,3 4\n0,2 0 3 4 7 2 ,5 0 5 6 ,2 5 19,17\n0,60 2 0 15,00 3 1 ,2 5 11,53\n0 ,5 0 2 0 2 7 ,5 0 31 ,2 5 10,66\n0 ,6 0 6 0 2 7 ,5 0 3 1 ,2 5 32 ,3 5\n0 ,2 0 100 15,00 31 ,2 5 53,82\n0 ,2 0 19 6 5 ,0 0 56 ,2 5 10,38\n0,1 0 19 6 2 ,5 0 50 ,0 0 10,54\n0,0 5 19 57 ,5 0 3 1 ,2 5 10,71\n0,2 0 100 15,00 31 ,2 5 52 ,4 0\n0 ,2 0 45 80 ,0 0 6 2 ,5 0 2 4 ,4 5\n0,3 0 2 0 2 7 ,5 0 3 1 ,2 5 11,48\n0 ,1 5 50 7 7 ,5 0 6 2 ,5 0 2 7 ,7 4\n0,1 5 2 5 6 2 ,5 0 56 ,2 5 13,62\n0 ,1 5 7 0 ,0 0 6 2 ,5 0 16,53\n0,1 8 30 6 2 ,5 0 56 ,2 5 16,04\n0,17 4 0 4 7 ,5 0 3 7 ,5 0 2 1 ,8 6\n0,2 0 2 0 0 2 0 ,0 0 3 1 ,2 5 4 3 ,0 6\n\nTabela E-3 : Resultados da rede LVQ usando os dados normalizados \nentre [-1,1] e a taxa de aprendizagem decresce linearmente em fun\u00e7\u00e3o do \nn\u00famero de \u00e9pocas.\n\n\n\nAp\u00eandice\n\nResultados da LVQ com os Dados Normalizados\nTaxa de \n\nAprendizagem\nEpocas Treinamento\n\n(%)\nTeste\n(%)\n\nTempo i \n(s)\n\n0,200 20 65,00 50,00 11,150\n0,200 v 40 ^ 72,50 62,50 21,750\n0,300 40 25,00 31,25 22,910\n0,100 45 62,50 50,00 24,440\n0,100 20 60,00 50,00 10,820\n0,100 23 57,50 43,75 12,420\n0,100 40 62,50 50,00 21,640\n0,100 45 62,50 50,00 24,450\n0,200 v 45 72,50 62,50 18,950\n0,200 50 70,00 62,50 20,870\n0,200 70 ^ 67,50 62,50 29,060\n0,200 80 72,50 62,50 33,170\n0,200 100 72,50 62,50 43,830\n0,200 200 70,00 . 62,50 87,280\n0,900 30 35,00 31,25 4,730\n0,800 20 35,00 31,25 3,240\n0,700 25 35,00 31,25 4,010\n0,600 15 25,00 12,50 2,480\n0,500 30 17,50 25,00 4,880\n0,500 50 27,50 12,50 7,910\n0,400 30 10,00 12,50 4,890\n0,300 30 15,00 0.00 4,720\n0,100 13 52,50 43,75 2,090\n0,200 50 70,00 62,50 7,910\n0,200 20 65,00 50,00 3,240\n0,200 25 67,50 62,50 4,010\n0,150 25 52,50 50,00 4,010\n0,150 40 60,00 50,00 6,480\n\nTabela E-4 : Resultados da rede LVQ usando os dados normalizados \nentre [-1 , 1 ] e a taxa de aprendizagem decresce n\u00e3o linearmente em \nfun\u00e7\u00e3o do n\u00famero de \u00e9pocas.\n\n\n\nAP\u00caNDICE F\n\nRESULTADOS DO FAN\n\nFAN COM DADOS NORMALIZADOS NO INTERVALO [0,1]\n\nFun\u00e7\u00e3o de \nPertin\u00eancia\n\nRaio Range Epocas \u00bb Treinamento\n(%)\n\nTeste\n' ' (%) *\n\nTriangular 1 18 2 82.50 50.00\nTriangular 1 18 3 87.50 50.00\nTriangular 1 18 4 90.00 50.00\nTriangular 1 18 5 87.50 50.0\nGaussiana 1 19 1 50.00 56.25\nGaussiana 1 19 2 80.00 62.50\nGaussiana 1 19 3 82.50 62.50\nGaussiana 1 19 4 85.00 68.75\nGaussiana 1 : r - ^ S 85! 00 75.00 :\nGaussiana 19 82.50 .. 75.00\nGaussiana 1 13 1 42.50 56.25\nGaussiana 1 13 2 75.00 56.25\nGaussiana 1 13 3 82.50 56.25\nTriangular 1 21 1 47.50 50.00\nTriangular 1 21 2 80.00 62.50\nTriangular 1 21 3 90.00 68.75\nTriangular 1 21 4 95.00 68.75\nTriangular v -\u00ed.'2 1 :y \u00ab ; 92.50 75.00\nTriangular ???>\u20182-1 ?&amp; * 6 92.50 75.00\nTriangular 20 55.00 75.00\nTriangular 77.50 75.00\nTriangular 2 20 3 82.50 68.75\nTriangular 1 100 1 40.00 62.50\nTriangular 1 100 2 97.00 31.25\nTriangular 1 100 3 100.00 31.25\nTriangular 1 30 1 42.50 56.25\nTriangular 1 30 2 85.00 62.50\nTriangular 1 30 3 90.00 62.50\nTriangular 1 30 4 90.00 62.50\n\nTabela F -l: Resultados da FAN com H=1 (grau de combina\u00e7\u00e3o das vari\u00e1reis)."}]}}}