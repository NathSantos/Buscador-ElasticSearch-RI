{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.23779"}, {"@name": "filename", "#text": "8015_kokubum_cnc_me_prud.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNIVERSIDADE ESTADUAL PAULISTA\nFaculdade de Ci\u00eancias e Tecnologia\n\nC\u00e2mpus de Presidente Prudente\n\n                       \n\nESTUDO DE M\u00c9TODOS PARA CLASSIFICA\u00c7\u00c3O E \n\nLOCALIZA\u00c7\u00c3O PRECISA DE PADR\u00d5ES USANDO UM \n\nSISTEMA DE LUZ ESTRUTURADA   \n\nChristiane Nogueira de Carvalho Kokubum     \n\nPresidente Prudente \n\n2004 \n\n\n\n \nUNIVERSIDADE ESTADUAL PAULISTA\n\nFaculdade de Ci\u00eancias e Tecnologia\nC\u00e2mpus de Presidente Prudente\n\n \n                  P\u00f3s-Gradua\u00e7\u00e3o em Ci\u00eancias Cartogr\u00e1ficas   \n\nCHRISTIANE NOGUEIRA DE CARVALHO KOKUBUM   \n\nESTUDO DE M\u00c9TODOS PARA CLASSIFICA\u00c7\u00c3O E \n\nLOCALIZA\u00c7\u00c3O PRECISA DE PADR\u00d5ES USANDO \n\nUM SISTEMA DE LUZ ESTRUTURADA          \n\nPresidente Prudente \n\n2004 \n\nDisserta\u00e7\u00e3o apresentada ao Programa \nde P\u00f3s-Gradua\u00e7\u00e3o em Ci\u00eancias \nCartogr\u00e1ficas da Faculdade de \nCi\u00eancias e Tecnologia da UNESP, \ncomo parte dos requisitos exigidos \npara a obten\u00e7\u00e3o do t\u00edtulo de Mestre em \nCi\u00eancias Cartogr\u00e1ficas.   \n\nOrientador:  \n\nProf. Dr. Antonio M. G. Tommaselli \n\n\n\n \nRESUMO  \n\nAlgumas das tarefas mais significativas em Vis\u00e3o Computacional e em \n\nFotogrametria Digital \u00e0 curta dist\u00e2ncia est\u00e3o associadas \u00e0 segmenta\u00e7\u00e3o, ao \n\nreconhecimento de objetos na imagem e \u00e0 posterior reconstru\u00e7\u00e3o. Esta disserta\u00e7\u00e3o \n\napresenta uma metodologia para a identifica\u00e7\u00e3o e para a medi\u00e7\u00e3o autom\u00e1ticas de \n\nalvos projetados em imagens tomadas \u00e0 curta-dist\u00e2ncia, usando o sistema ativo \n\ndenominado luz estruturada. Para a classifica\u00e7\u00e3o de tais padr\u00f5es, dois m\u00e9todos de \n\ncorrespond\u00eancia s\u00e3o comparados: correspond\u00eancia por padr\u00e3o  (template matching) \n\ne por assinatura. O m\u00e9todo de correspond\u00eancia por padr\u00e3o consiste na classifica\u00e7\u00e3o \n\npor correla\u00e7\u00e3o, que mede a similaridade entre as janelas de refer\u00eancia e de busca \n\nutilizando uma fun\u00e7\u00e3o de correla\u00e7\u00e3o adequada. Os problemas existentes neste \n\nm\u00e9todo est\u00e3o relacionados com os ru\u00eddos na imagem, varia\u00e7\u00f5es de brilho, \n\ndistor\u00e7\u00f5es geom\u00e9tricas, o grande n\u00famero de padr\u00f5es a serem comparados e a \n\nescolha do tamanho do padr\u00e3o. O m\u00e9todo de assinatura consiste na compara\u00e7\u00e3o da \n\nrepresenta\u00e7\u00e3o funcional unidimensional da fronteira do padr\u00e3o. Este m\u00e9todo de \n\nassinatura n\u00e3o varia em rela\u00e7\u00e3o \u00e0 transla\u00e7\u00e3o, mas depende da rota\u00e7\u00e3o e da \n\nmudan\u00e7a de escala. Para a localiza\u00e7\u00e3o precisa, dois m\u00e9todos foram comparados: \n\ncorrespond\u00eancia por m\u00ednimos quadrados e detector de cantos. O m\u00e9todo de \n\ncorrespond\u00eancia por m\u00ednimos quadrados refina a correspond\u00eancia obtida por \n\ncorrela\u00e7\u00e3o, estimando os par\u00e2metros de transforma\u00e7\u00e3o radiom\u00e9tricos e geom\u00e9tricos \n\nentre as janelas de refer\u00eancia e de pesquisa, de acordo com o crit\u00e9rio de erro dos \n\nm\u00ednimos quadrados. J\u00e1 o detector de cantos determina as coordenadas subpixel \n\nusando uma combina\u00e7\u00e3o dos operadores de Moravec e de F\u00f6rstner. Experimentos \n\nrealizados com dados simulados e reais foram conduzidos com o objetivo de \n\nverificar a efic\u00e1cia da metodologia com respeito \u00e0 detec\u00e7\u00e3o e a localiza\u00e7\u00e3o precisa. \n\nOs resultados mostram que a metodologia de classifica\u00e7\u00e3o funciona \n\nadequadamente, identificando 98% de alvos em superf\u00edcies planas e 93% em \n\nsuperf\u00edcies obl\u00edquas. Os m\u00e9todos de correspond\u00eancia por m\u00ednimos quadrados e \n\ndetector de cantos mostraram-se equivalentes para a localiza\u00e7\u00e3o precisa.    \n\nPalavras-chave: Correla\u00e7\u00e3o, correspond\u00eancia por m\u00ednimos quadrados, luz \nestruturada, assinatura, reconhecimento de padr\u00f5es, detec\u00e7\u00e3o de cantos. \n\n\n\n \nABSTRACT  \n\nSome of the main tasks in computer vision and close range Photogrammetry are \n\nrelated to the processes of segmentation, object recognition in the image and later \n\nreconstruction. The aim of this work is to study an automatic recognition system to \n\nidentify and to measure targets projected with a structured light system. For target \n\nrecognition two methods are compared: template matching and the signature \n\nmethod. The template matching method consists in the detection of area similarity by \n\ncorrelation. The idea of correlation is to compare the gray level distribution of a small \n\nsub image with its homologous in the search image. In this paper, the function used \n\nis the modified cross covariance which presented the best results. The problems in \n\nthis method are related to illumination differences between the two images, geometric \n\ndistortions, noise, the great number of templates to be compared and determination \n\nof template size. The signature method is based in the analysis of the one-\n\ndimensional representation of target border. The signature depends on the rotation \n\nand the scale changes of the target. Two methods were compared for precise \n\nlocalization: LSM (least square matching) and corner detection. The idea of least \n\nsquares matching is to minimize the gray level differences between the image patch \n\nand the matching window; the geometric and radiometric parameters from the \n\ntemplate to the matching window are determined in the adjustment process. The \n\ncorner detection consists in the determination of the subpixel coordinates of corners \n\nusing the F\u00f6rstner and Moravec operators. Experiments were performed, in order to \n\nverify the performance of the methodology for detection and precise localization. The \n\nresults showed that the classification works appropriately, identifying 98% of targets \n\nin plane surfaces and 93% in oblique surfaces. Besides, the results of precise \n\nlocalization were equivalent in both methods: LSM and corner detection.        \n\nKeywords: Template matching, structured light, signature, recognition of targets, \ncorner detection.  \n\n\n\n \nLISTA DE FIGURAS  \n\nFIGURA 1 - Princ\u00edpio de forma\u00e7\u00e3o de uma imagem digital......................................... 25 \n\nFIGURA 2  Defini\u00e7\u00e3o do sistema de coordenadas de uma imagem digital............... 26 \n\nFIGURA 3  Regi\u00f5es definidas no processo de limiariza\u00e7\u00e3o local.............................. 37 \n\nFIGURA 4 \n\n \n\nRepresenta\u00e7\u00e3o das magnitudes dos gradientes e do \u00e2ngulo de dire\u00e7\u00f5es \n\ndas bordas................................................................................................................ 39 \n\nFIGURA 5 \n\n \n\nM\u00e1scaras usadas no operador de Sobel(a) Gradiente em x; (b) Gradiente \n\nem y.......................................................................................................................... 40 \n\nFIGURA 6 - Janelas 3x3 mostrando os vetores de 0\u00ba, 45\u00ba, 90\u00ba e 135\u00ba, respectivamente \n\n................................................................................................................................. 42 \n\nFIGURA 7 - Ferramenta de produ\u00e7\u00e3o automotiva ...................................................... 47 \n\nFIGURA 8 - Padr\u00e3o desenvolvido por Dunn e Keizer (1989)...................................... 53 \n\nFIGURA 9 - Detalhe do padr\u00e3o bin\u00e1rio projetado. ...................................................... 54 \n\nFIGURA 10 - O padr\u00e3o de ilumina\u00e7\u00e3o composto de quatro primitivas. ....................... 54 \n\nFIGURA 11  Pesquisa bidimensional de imagens correlatas. ................................... 59 \n\nFIGURA 12 - Representa\u00e7\u00e3o do pixel reamostrado.................................................... 69 \n\nFIGURA 13 \n\n \n\nPadr\u00f5es que reduzem a quantidade de par\u00e2metros a serem \n\ndeterminados pelo modelo matem\u00e1tico mencionado nesta se\u00e7\u00e3o. (a) escala em y; (b) \n\nrota\u00e7\u00e3o; (c) duas escalas; (d) todos na dire\u00e7\u00e3o y; (e) todos na dire\u00e7\u00e3o y e escala em \n\nx; (f) todos................................................................................................................. 70 \n\nFIGURA 14  Fronteiras e suas respectivas assinaturas............................................ 71 \n\nFIGURA 15  Assinatura: (a) Princ\u00edpio da constru\u00e7\u00e3o (b) Assinaturas para um c\u00edrculo e \n\num tri\u00e2ngulo.  ........................................................................................................... 71 \n\nFIGURA 16  Alvo codificado...................................................................................... 78 \n\nFIGURA 17  Seq\u00fc\u00eancia das opera\u00e7\u00f5es e  processamentos realizados. ................... 80 \n\nFIGURA 18 - Padr\u00f5es primitivos. ................................................................................ 82 \n\nFIGURA 19  Vizinhan\u00e7a dos padr\u00f5es. ...................................................................... 83 \n\nFIGURA 20 - Sistema sensor e projetor...................................................................... 84 \n\nFIGURA 21 \n\n \n\nConfigura\u00e7\u00e3o da janela do limiar local. ................................................. 86 \n\nFIGURA 22  Fluxograma do algoritmo de segmenta\u00e7\u00e3o de padr\u00f5es........................ 89 \n\nFIGURA 23 - Padr\u00e3o com diferentes rota\u00e7\u00f5es e id\u00eanticas assinaturas. ..................... 93 \n\nFIGURA 24  Pontos iniciais dos padr\u00f5es utilizados. ................................................. 93 \n\n\n\n \nFIGURA 25  Dire\u00e7\u00f5es obtidas dos pontos................................................................. 94 \n\nFIGURA 26  Exemplo de uma imagem de padr\u00f5es. ............................................... 101 \n\nFIGURA 27 - Dimens\u00e3o dos padr\u00f5es projetados em pixel........................................ 101 \n\nFIGURA 28 \n\n \nResultados da limiariza\u00e7\u00e3o. (a) Imagem original; (b) M\u00e9todo de \n\nexpans\u00e3o do histograma; (c) M\u00e9todo de transforma\u00e7\u00e3o local. ............................... 102 \n\nFIGURA 29 - (a) Imagem original (tomada de um dorso humano) com o sistema de luz \n\nestruturada; (b) Parte da imagem original; (c) (d) Limiariza\u00e7\u00e3o com o m\u00e9todo de Otsu \n\nlocal; (e) (f) Limiariza\u00e7\u00e3o com Pun local ................................................................. 104 \n\nFIGURA 30 \n\n \n\nResultados de imagens segmentadas. (a) Todos os alvos foram \n\nsegmentados. (b) Alguns alvos n\u00e3o foram segmentados. ...................................... 105 \n\nFIGURA 31 \n\n \n\nResultados da correspond\u00eancia por correla\u00e7\u00e3o usando padr\u00f5es bin\u00e1rios \n\n(imagens invertidas). (a) Imagem dos alvos projetados em um cilindro; (b) Imagem \n\nreal\u00e7ada de uma imagem sem varia\u00e7\u00e3o de rota\u00e7\u00e3o; (c) Classifica\u00e7\u00e3o dos alvos para \n\na imagem com padr\u00f5es projetados distorcidos; (d) Imagem real\u00e7ada de uma imagem \n\ncom varia\u00e7\u00e3o na rota\u00e7\u00e3o; (e) Classifica\u00e7\u00e3o dos alvos para a imagem com padr\u00f5es \n\nprojetados distorcidos............................................................................................. 110 \n\nFIGURA 32 - Classifica\u00e7\u00e3o dos alvos de um cilindro ap\u00f3s a segmenta\u00e7\u00e3o.............. 111 \n\nFIGURA 33 - Classifica\u00e7\u00e3o dos alvos ap\u00f3s a segmenta\u00e7\u00e3o de um dorso humano .. 111 \n\nFIGURA 34 \n\n \n\nResultados da correspond\u00eancia por correla\u00e7\u00e3o usando padr\u00f5es \n\nsuavizados pela m\u00e9dia (imagens invertidas) (a) Imagem real\u00e7ada de uma imagem \n\nsem varia\u00e7\u00e3o de rota\u00e7\u00e3o; (b) Classifica\u00e7\u00e3o dos alvos para a imagem sem varia\u00e7\u00e3o \n\nda rota\u00e7\u00e3o; (c) Imagem real\u00e7ada de uma imagem com padr\u00f5es projetados \n\ndistorcidos; (d) Classifica\u00e7\u00e3o dos alvos para a imagem com padr\u00f5es projetados \n\ndistorcidos. ............................................................................................................. 113 \n\nFIGURA 35 \n\n \n\nResultados da correspond\u00eancia por correla\u00e7\u00e3o usando padr\u00f5es \n\nreamostrados (Padr\u00f5es 23 pixels x 23 pixels) (imagens invertidas) (a) Imagem \n\nreal\u00e7ada de uma imagem sem varia\u00e7\u00e3o de rota\u00e7\u00e3o; (b) Classifica\u00e7\u00e3o dos alvos para \n\na imagem sem varia\u00e7\u00e3o da rota\u00e7\u00e3o; (c) Imagem real\u00e7ada de uma imagem com \n\npadr\u00f5es projetados distorcidos; (d) Classifica\u00e7\u00e3o dos alvos para a imagem com \n\npadr\u00f5es projetados distorcidos. .............................................................................. 115 \n\nFIGURA 36  Reamostragem dos padr\u00f5es primitivos sem moldura. ........................ 116 \n\nFIGURA 37 \n\n \n\nResultados da correspond\u00eancia por correla\u00e7\u00e3o usando padr\u00f5es \n\nreamostrados sem bordas (Padr\u00f5es 90 pixels x 90 pixels) (a) Imagem real\u00e7ada de \n\numa imagem sem varia\u00e7\u00e3o de rota\u00e7\u00e3o; (b) Classifica\u00e7\u00e3o dos alvos para a imagem \n\n\n\n \nsem varia\u00e7\u00e3o da rota\u00e7\u00e3o; (c) Imagem real\u00e7ada de uma imagem com padr\u00f5es \n\nprojetados distorcidos; (d) Classifica\u00e7\u00e3o dos alvos para a imagem com padr\u00f5es \n\nprojetados distorcidos............................................................................................. 117 \n\nFIGURA 38 \n\n \nResultados da correspond\u00eancia por correla\u00e7\u00e3o usando padr\u00f5es \n\nreamostrados usando molduras (Padr\u00f5es 90 pixels x 90 pixels) (a) Imagem real\u00e7ada \n\nde uma imagem sem varia\u00e7\u00e3o de rota\u00e7\u00e3o; (b) Classifica\u00e7\u00e3o dos alvos para a imagem \n\nsem varia\u00e7\u00e3o da rota\u00e7\u00e3o; (c) Imagem real\u00e7ada de uma imagem com padr\u00f5es \n\nprojetados distorcidos; (d) Classifica\u00e7\u00e3o dos alvos para a imagem com padr\u00f5es \n\nprojetados distorcidos............................................................................................. 118 \n\nFIGURA 39 \n\n \n\nExtra\u00e7\u00e3o de fronteiras usando o m\u00e9todo de persegui\u00e7\u00e3o de \n\nfronteiras.(a) Extra\u00e7\u00e3o de fronteiras dos alvos projetados em um cilindro;(b) Detalhe \n\nda imagem com as fronteiras dos alvos extra\u00eddos.................................................. 120 \n\nFIGURA 40 - Assinatura dos padr\u00f5es armazenados. ............................................... 121 \n\nFIGURA 41  Assinaturas dos padr\u00f5es e dos alvos segmentados........................... 123 \n\nFIGURA 42  Resultado da classifica\u00e7\u00e3o usando o m\u00e9todo de assinatura. ............. 124 \n\nFIGURA 43 - Localiza\u00e7\u00e3o precisa dos alvos usando padr\u00f5es pr\u00e9-definidos............. 126 \n\nFIGURA 44 \n\n \n\nLocaliza\u00e7\u00e3o precisa usando o m\u00e9todo de reamostragem dos padr\u00f5es.\n\n............................................................................................................................... 127 \n\nFIGURA 45 \n\n \n\nLocaliza\u00e7\u00e3o precisa por detec\u00e7\u00e3o de cantos usando padr\u00f5es \n\nreamostrados.......................................................................................................... 128 \n\nFIGURA 46  Uma das quatro imagens usadas para calibra\u00e7\u00e3o da c\u00e2mara............ 129   \n\n\n\n \nLISTA DE TABELAS    \n\nTABELA 1  Resolu\u00e7\u00e3o espacial. ............................................................................... 24 \n\nTABELA 2  Resolu\u00e7\u00e3o radiom\u00e9trica. ......................................................................... 25 \n\nTABELA 3  Exemplos de aplica\u00e7\u00f5es de reconhecimento de padr\u00f5es....................... 58 \n\nTABELA 4 - Par\u00e2metros de orienta\u00e7\u00e3o interior calibrados.......................................... 85 \n\nTABELA 5 - Padr\u00f5es pr\u00e9-definidos e as suas inst\u00e2ncias armazenadas. .................... 90 \n\nTABELA 6  Exemplo de sa\u00edda do reconhecimento de padr\u00f5es. ............................. 129 \n\nTABELA 7 - M\u00e9todos usados e respectivos erros m\u00e9dios quadr\u00e1tico usando apenas \n\nos alvos do tipo A. .................................................................................................. 131 \n\nTABELA 8  Resultados da reconstru\u00e7\u00e3o usando o m\u00e9todo de detector de cantos para \n\ntodos os cinco padr\u00f5es........................................................................................... 132            \n\n\n\n \nCONTE\u00daDO  \n\nCAP\u00cdTULO I  \n\n1. INTRODU\u00c7\u00c3O .................................................................................................. 18 \n\n1.1. Considera\u00e7\u00f5es iniciais ............................................................................ 18 \n\n1.2. Objetivos................................................................................................. 21 \n\n1.2.1. Objetivo geral ....................................................................................... 21 \n\n1.2.1. Objetivos espec\u00edficos ........................................................................... 21 \n\n1.3 . Estrutura do trabalho ............................................................................ 23  \n\nCAP\u00cdTULO II  \n\n2. IMAGENS DIGITAIS: AQUISI\u00c7\u00c3O E PROCESSAMENTO ............................... 24 \n\n2.1. Imagem Digital............................................................................................ 24 \n\n2.2. C\u00e2maras digitais ......................................................................................... 25 \n\n2.3. Sistemas de coordenadas .......................................................................... 26 \n\n2.4. Efeitos sistem\u00e1ticos .................................................................................... 27 \n\n2.5. Melhoramento de contraste linear .............................................................. 29 \n\n2.5.1. M\u00e9todo de expans\u00e3o do histograma .................................................... 29 \n\n2.5.2. Transforma\u00e7\u00e3o local ............................................................................ 30 \n\n2.6. Segmenta\u00e7\u00e3o ............................................................................................. 32 \n\n2.7. Limiariza\u00e7\u00e3o ............................................................................................... 33 \n\n2.7.1. M\u00e9todo de Otsu ................................................................................... 34 \n\n2.7.2. M\u00e9todo de Pun..................................................................................... 36 \n\n2.7.3. Limiariza\u00e7\u00e3o local ................................................................................ 37 \n\n2.8. Detec\u00e7\u00e3o de bordas ................................................................................... 38 \n\n2.8.1. Operadores de gradiente ..................................................................... 38 \n\n2.8.1.1. Operadores de Sobel .................................................................... 40 \n\n2.9. Detector de cantos ..................................................................................... 41 \n\n2.9.1. Operadores de interesse...................................................................... 41 \n\n2.9.1.1. Operador de Moravec.................................................................... 41 \n\n\n\n \n2.9.1.2. Operador de F\u00f6rstner .................................................................... 43 \n\n    2.9.2. T\u00e9cnica h\u00edbrida usada para detec\u00e7\u00e3o de cantos ................................. 44  \n\nCAP\u00cdTULO III  \n\n3. FOTOGRAMETRIA \u00c0 CURTA DIST\u00c2NCIA ....................................................... 46 \n\n3.1. Aplica\u00e7\u00f5es da Fotogrametria \u00e0 curta dist\u00e2ncia ........................................... 46 \n\n3.2. Luz estruturada........................................................................................... 49 \n\n3.2.1. T\u00e9cnicas utilizando o sistema de luz estruturada................................. 50  \n\nCAP\u00cdTULO IV  \n\n4. RECONHECIMENTO DE PADR\u00d5ES ................................................................ 57 \n\n4.1. Correspond\u00eancia por padr\u00e3o (Template matching) .................................... 59 \n\n4.1.1. Fun\u00e7\u00f5es b\u00e1sicas de correla\u00e7\u00e3o ........................................................... 60 \n\n4.1.1.1. Fun\u00e7\u00e3o covari\u00e2ncia cruzada.......................................................... 61 \n\n4.1.1.2. Fun\u00e7\u00e3o covari\u00e2ncia cruzada modificada ou coeficiente de \n\ncorrela\u00e7\u00e3o................................................................................................... 62 \n\n4.1.1.3. Fun\u00e7\u00e3o correla\u00e7\u00e3o cruzada ........................................................... 63 \n\n4.1.2. Correspond\u00eancia por m\u00ednimos quadrados ........................................... 63 \n\n4.2. Correspond\u00eancia por assinatura................................................................. 70 \n\n4.2.1. Determina\u00e7\u00e3o da discrep\u00e2ncia entre as assinaturas ........................... 72 \n\n4.3. Outras t\u00e9cnicas para o reconhecimento de padr\u00f5es .................................. 75  \n\nCAP\u00cdTULO V  \n\n5. MATERIAIS E M\u00c9TODOS ................................................................................. 79 \n\n5.1. Materiais ..................................................................................................... 79 \n\n5.2. M\u00e9todos...................................................................................................... 80 \n\n5.2.1. Gera\u00e7\u00e3o de padr\u00f5es ............................................................................ 81 \n\n5.2.2. Coleta de dados ................................................................................... 83 \n\n5.2.3. Limiariza\u00e7\u00e3o local ................................................................................ 85 \n\n\n\n \n5.2.4. Segmenta\u00e7\u00e3o....................................................................................... 87 \n\n5.2.5 Classifica\u00e7\u00e3o ......................................................................................... 88 \n\n5.2.5.1 Correla\u00e7\u00e3o ...................................................................................... 90 \n\n5.2.5.2 Assinatura ...................................................................................... 92 \n\n5.2.6. Localiza\u00e7\u00e3o precisa ............................................................................. 95 \n\n5.2.6.1. M\u00e9todo de correspond\u00eancia de imagens por m\u00ednimos quadrados e \n\nreamostragem ............................................................................................ 95 \n\n5.2.6.2. Detec\u00e7\u00e3o de cantos....................................................................... 97 \n\n5.2.7. Crit\u00e9rio para avalia\u00e7\u00e3o do m\u00e9todo de localiza\u00e7\u00e3o precisa ................... 98  \n\nCAP\u00cdTULO VI  \n\n6. DESENVOLVIMENTO E IMPLEMENTA\u00c7\u00c3O.................................................. 100 \n\n6.1. Gera\u00e7\u00e3o autom\u00e1tica de padr\u00f5es .............................................................. 100 \n\n6.2. Limiariza\u00e7\u00e3o local ..................................................................................... 102 \n\n6.3. Segmenta\u00e7\u00e3o ........................................................................................... 105 \n\n6.4. Classifica\u00e7\u00e3o ............................................................................................ 106 \n\n6.4.1. Correspond\u00eancia por correla\u00e7\u00e3o ........................................................ 107 \n\n6.4.4.1. Compara\u00e7\u00e3o dos alvos segmentados com os padr\u00f5es pr\u00e9-definidos \n\ne com as suas inst\u00e2ncias armazenadas................................................... 108 \n\n6.4.4.2. Compara\u00e7\u00e3o dos alvos segmentados com os padr\u00f5es pr\u00e9-definidos \n\nsuavizados e com as suas inst\u00e2ncias suavizadas armazenados ............. 112 \n\n6.4.4.3. Compara\u00e7\u00e3o dos alvos segmentados com os padr\u00f5es pr\u00e9-definidos \n\nreamostrados ........................................................................................... 113 \n\n6.5. Localiza\u00e7\u00e3o precisa .................................................................................. 125 \n\n6.5.1. Correspond\u00eancia de imagens por m\u00ednimos quadrados...................... 125 \n\n6.5.2. Detec\u00e7\u00e3o de cantos ........................................................................... 127  \n\nCAP\u00cdTULO VII  \n\n7. CONCLUS\u00d5ES E RECOMENDA\u00c7\u00d5ES .......................................................... 133  \n\nREFER\u00caNCIAS BIBLIOGR\u00c1FICAS .................................................................... 135 \n\n\n\n  \nLISTA DE SIGLAS  \n\nA/D Anal\u00f3gico/Digital \n\nAMD        Advanced Micro Devices \n\nCC Calibra\u00e7\u00e3o de c\u00e2maras \n\nCCD Charge Coupled Device  Dispositivo de carga acoplada \n\nDC Detector de cantos \n\nDPI           Dots per inch  Pontos por polegadas \n\nEMQ Erro m\u00e9dio quadr\u00e1tico \n\nFAPESP\n\n \n\nFunda\u00e7\u00e3o de Amparo \u00e0 Pesquisa do Estado de S\u00e3o Paulo \n\nFCT Faculdade de Ci\u00eancias e Tecnologia \n\nGB Gigabytes \n\nMB Megabytes \n\nMMQ M\u00e9todo dos m\u00ednimos quadrados \n\nMQ M\u00ednimos quadrados \n\nNC N\u00edvel de cinza \n\nPPD Padr\u00f5es pr\u00e9-definidos \n\nPPP Pontos por polegadas \n\nPR Padr\u00f5es reamostrados \n\nRAM Random Acess Memory  Mem\u00f3ria de acesso aleat\u00f3rio \n\nUNESP Universidade Estadual Paulista \n\nUPTK Unesp Photogrammetric ToolKit   \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n18\n\n \nCAP\u00cdTULO I    \n\n1. INTRODU\u00c7\u00c3O   \n\n1.1. Considera\u00e7\u00f5es iniciais   \n\nAtualmente, a reconstru\u00e7\u00e3o tridimensional \u00e9 um dos assuntos mais \n\nabordados na literatura relacionada \u00e0 Fotogrametria Digital e a Vis\u00e3o Computacional.  \n\nH\u00e1 diversos sistemas para reconstru\u00e7\u00e3o 3D no mercado, por\u00e9m, \n\napresentam algumas das desvantagens: alto custo, necessidade de operadores \n\naltamente qualificados, impossibilidade de resposta em tempo real em curto per\u00edodo \n\nde tempo e dificuldade de reconstru\u00e7\u00e3o em superf\u00edcies com texturas homog\u00eaneas.            \n\nPensando nestas desvantagens, decidiu-se criar um sistema que \n\npossu\u00edsse as seguintes caracter\u00edsticas: baixo custo e facilidade de opera\u00e7\u00e3o com \n\nalto grau de automa\u00e7\u00e3o. Dos v\u00e1rios sistemas de reconstru\u00e7\u00e3o pesquisados, aqueles \n\ncujas caracter\u00edsticas mais se aproximam destes requisitos s\u00e3o os sistemas de \n\nreconstru\u00e7\u00e3o por luz estruturada. Neste tipo de sistema utiliza-se uma fonte de luz, \n\nque projeta um padr\u00e3o de luz conhecido na cena medida. \n\nInicialmente, um sistema de reconstru\u00e7\u00e3o composto por uma c\u00e2mara \n\ndigital Kodak DC 40 e um projetor de padr\u00f5es foi constru\u00eddo. Os padr\u00f5es projetados \n\npara este sistema eram brancos e circulares. A identifica\u00e7\u00e3o autom\u00e1tica para estes \n\nalvos \u00e9 f\u00e1cil, por\u00e9m, nos objetos de superf\u00edcies com relevo muito irregular ocorreram \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n19\n\n \noclus\u00f5es de alguns alvos, acarretando em incorretas identifica\u00e7\u00f5es (TOMMASELLI, \n\n1997). Uma solu\u00e7\u00e3o para este problema de oclus\u00e3o de padr\u00f5es foi usar padr\u00f5es \n\ncoloridos com tr\u00eas diferentes formas, por\u00e9m, em superf\u00edcies coloridas, alguns alvos \n\nficaram oclusos dificultando na sua identifica\u00e7\u00e3o (SCALCO, 2000). \n\nObservando estes inconvenientes em trabalhos anteriores, resolveu-\n\nse usar padr\u00f5es brancos com cinco diferentes formas neste trabalho. Al\u00e9m disso, um \n\nsistema formado por uma c\u00e2mara de maior resolu\u00e7\u00e3o foi criado para a captura da \n\nimagem em substitui\u00e7\u00e3o \u00e0 c\u00e2mara anterior.  \n\nComo a reconstru\u00e7\u00e3o tridimensional \u00e9 uma etapa muito complexa, \n\ndividiu-se o processo em duas etapas: reconstru\u00e7\u00e3o 3D e reconhecimento de \n\npadr\u00f5es. A etapa em que consiste esta disserta\u00e7\u00e3o objetiva encontrar um m\u00e9todo \n\napropriado para a identifica\u00e7\u00e3o e a medi\u00e7\u00e3o autom\u00e1tica de alvos, em uma ou mais \n\nimagens, procedimento fundamental na reconstru\u00e7\u00e3o. As vantagens da automa\u00e7\u00e3o \n\ndestes processos s\u00e3o: processos fotogram\u00e9tricos mais flex\u00edveis, maior agilidade e \n\nmenor possibilidade de ocorrer erros grosseiros uma vez que \u00e9 menor a interven\u00e7\u00e3o \n\ndo operador. Al\u00e9m disto, alguns m\u00e9todos permitem, ainda, a medi\u00e7\u00e3o das \n\ncoordenadas com precis\u00e3o subpixel. \n\nPara a identifica\u00e7\u00e3o e medi\u00e7\u00e3o de alvos, um dos m\u00e9todos mais \n\nutilizados \u00e9 a correspond\u00eancia por padr\u00e3o (template matching). Achar um padr\u00e3o na \n\nimagem vincula detec\u00e7\u00e3o (m\u00e9todos de correla\u00e7\u00e3o cruzada e correla\u00e7\u00e3o baseada em \n\nfei\u00e7\u00f5es), localiza\u00e7\u00e3o precisa (m\u00e9todos baseados em \u00e1reas e m\u00e9todos baseados em \n\nfei\u00e7\u00f5es) e verifica\u00e7\u00e3o. A correla\u00e7\u00e3o mede a similaridade de uma m\u00e1scara de \n\nrefer\u00eancia com uma janela de busca utilizando uma fun\u00e7\u00e3o de correla\u00e7\u00e3o adequada. \n\nJ\u00e1 a correla\u00e7\u00e3o por m\u00ednimos quadrados procura refinar esta correspond\u00eancia pela \n\nestima\u00e7\u00e3o dos par\u00e2metros de transforma\u00e7\u00e3o radiom\u00e9tricos e geom\u00e9tricos entre as \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n20\n\n \njanelas de refer\u00eancia e de pesquisa, de acordo com o crit\u00e9rio dos m\u00ednimos \n\nquadrados. Esses m\u00e9todos baseados em \u00e1rea s\u00e3o sens\u00edveis ou afetados por \n\nproblemas como: \n\n- Ilumina\u00e7\u00e3o n\u00e3o adequada; \n\n- Distor\u00e7\u00e3o dos padr\u00f5es; \n\n- Ru\u00eddos; \n\n- Tamanho da janela de refer\u00eancia; e, \n\n- Grande n\u00famero de janelas de refer\u00eancia a serem comparadas.   \n\nPor estes problemas mencionados acima, resolveu-se comparar os \n\nm\u00e9todos de classifica\u00e7\u00e3o por correla\u00e7\u00e3o com o m\u00e9todo de assinatura e o m\u00e9todo de \n\nlocaliza\u00e7\u00e3o precisa por m\u00ednimos quadrados  com os por detector de cantos. \n\nA assinatura \u00e9 um m\u00e9todo de correspond\u00eancia que consiste na \n\ncompara\u00e7\u00e3o da representa\u00e7\u00e3o funcional unidimensional de uma fronteira. H\u00e1 v\u00e1rias \n\nmaneiras de se adquirir uma assinatura. Uma das mais f\u00e1ceis de obt\u00ea-la \u00e9 a partir do \n\ngr\u00e1fico da dist\u00e2ncia da fronteira do alvo ao centr\u00f3ide em fun\u00e7\u00e3o da dire\u00e7\u00e3o. Esta \n\nassinatura n\u00e3o varia em rela\u00e7\u00e3o \u00e0 transla\u00e7\u00e3o, mas depende da rota\u00e7\u00e3o e mudan\u00e7a \n\nde escala (GONZALES e WOODS, 2000). A efic\u00e1cia deste processo depende dos \n\noperadores que s\u00e3o utilizados para a etapa de extra\u00e7\u00e3o de fei\u00e7\u00f5es. \n\nA detec\u00e7\u00e3o de cantos, neste trabalho, \u00e9 obtida pela combina\u00e7\u00e3o de \n\ndois operadores: Moravec e F\u00f6rstner. O operador de Moravec gera coordenadas \n\ncom precis\u00e3o pixel que s\u00e3o posteriormente usadas como coordenadas aproximadas \n\npara a determina\u00e7\u00e3o subpixel das coordenadas com o operador de F\u00f6rstner. \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n21\n\n \nOs experimentos s\u00e3o apresentados e discutidos, mostrando as \n\nvantagens e desvantagens de cada metodologia, al\u00e9m de indicar o m\u00e9todo mais \n\neficaz para a detec\u00e7\u00e3o e localiza\u00e7\u00e3o precisa para os tipos de alvos usados.   \n\n1.2. Objetivos   \n\n1.2.1. Objetivo geral   \n\nEste trabalho tem como objetivo o estudo e o desenvolvimento de \n\nm\u00e9todos de classifica\u00e7\u00e3o e de localiza\u00e7\u00e3o autom\u00e1ticos de alvos em imagens \n\ntomadas \u00e0 curta-dist\u00e2ncia usando o sistema de luz estruturada.   \n\n1.2.1. Objetivos espec\u00edficos   \n\n \n\nImplementar programas relacionados aos m\u00e9todos de \n\nreconhecimento e localiza\u00e7\u00e3o autom\u00e1ticos de alvos em \n\nimagens tomadas \u00e0 curta-dist\u00e2ncia: \n\n-    Gera\u00e7\u00e3o autom\u00e1tica de padr\u00f5es para cria\u00e7\u00e3o de fotolitos, \n\nos quais ser\u00e3o projetados na cena desejada, usando o sistema \n\nde luz estruturada; \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n22\n\n \n- Limiariza\u00e7\u00e3o local da imagem; \n\n- Segmenta\u00e7\u00e3o da imagem por crescimento de regi\u00f5es; \n\n-  Determina\u00e7\u00e3o da fronteira pelo m\u00e9todo de persegui\u00e7\u00e3o \n\nde fronteiras; \n\n- Assinatura; \n\n- Correspond\u00eancia por correla\u00e7\u00e3o; \n\n- Correspond\u00eancia por m\u00ednimos quadrados.  \n\n \n\nRealizar experimentos para compara\u00e7\u00e3o dos resultados: \n\n-    Compara\u00e7\u00e3o dos m\u00e9todos de correla\u00e7\u00e3o e de assinatura \n\npara a detec\u00e7\u00e3o autom\u00e1tica dos alvos projetados; \n\n-  Compara\u00e7\u00e3o dos m\u00e9todos de m\u00ednimos quadrados e de \n\ndetector de cantos para a localiza\u00e7\u00e3o autom\u00e1tica precisa dos \n\nalvos; \n\n- An\u00e1lise dos m\u00e9todos a partir da compara\u00e7\u00e3o das \n\ndiscrep\u00e2ncias dos dados a partir de uma reconstru\u00e7\u00e3o.   \n\n \n\nIntegra\u00e7\u00e3o \u00e0 biblioteca de classes e de fun\u00e7\u00f5es UPTK (Unesp \n\nPhotogrammetric ToolKit) desenvolvida no Departamento de \n\nCartografia.      \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n23\n\n \n1.3 . Estrutura do trabalho  \n\nEste trabalho \u00e9 composto de sete cap\u00edtulos. No primeiro cap\u00edtulo \n\napresenta-se uma abordagem geral sobre algumas t\u00e9cnicas empregadas e os seus \n\nproblemas para realiza\u00e7\u00e3o do reconhecimento autom\u00e1tico de alvos. \n\nNo segundo cap\u00edtulo, efetua-se uma revis\u00e3o a respeito de imagens \n\ndigitais e os conceitos envolvidos em sua aquisi\u00e7\u00e3o. \n\nNo cap\u00edtulo seguinte, \u00e9 feita uma revis\u00e3o a respeito da Fotogrametria \n\n\u00e0 curta dist\u00e2ncia, suas aplica\u00e7\u00f5es, al\u00e9m de enfatizar o m\u00e9todo ativo denominado luz \n\nestruturada.  \n\nNo quarto cap\u00edtulo s\u00e3o revisados alguns m\u00e9todos de detec\u00e7\u00e3o e de \n\nlocaliza\u00e7\u00e3o precisa utilizados no trabalho.  \n\nNo quinto cap\u00edtulo s\u00e3o apresentados os materiais utilizados no \n\ndesenvolvimento do trabalho, bem como os m\u00e9todos desenvolvidos e \n\nimplementados. \n\nO sexto cap\u00edtulo descreve o desenvolvimento, a implementa\u00e7\u00e3o e os \n\nexperimentos realizados da metodologia discutida anteriormente. \n\nO s\u00e9timo cap\u00edtulo traz as considera\u00e7\u00f5es finais e as recomenda\u00e7\u00f5es \n\npara os futuros trabalhos nesta \u00e1rea de pesquisa.       \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n24\n\n \nCAP\u00cdTULO II   \n\n2. IMAGENS DIGITAIS: AQUISI\u00c7\u00c3O E PROCESSAMENTO   \n\n2.1. Imagem Digital   \n\nSegundo Schenk (1999), imagem \u00e9 uma fun\u00e7\u00e3o cont\u00ednua yxF , na \n\nqual as coordenadas x, y s\u00e3o as vari\u00e1veis espaciais e o valor da fun\u00e7\u00e3o s\u00e3o os \n\nn\u00edveis de cinza. A discretiza\u00e7\u00e3o desta fun\u00e7\u00e3o resulta na imagem digital com uma \n\nfun\u00e7\u00e3o discreta yxf , .  \n\nA qualidade de uma imagem depende de dois fatores:  \n\n- Resolu\u00e7\u00e3o espacial: relacionada com o tamanho do pixel e \u00e9 \n\nfreq\u00fcentemente expressa em ppp (pontos por polegadas; dpi - dots \n\nper inch). Na Tabela 1 pode-se observar a dimens\u00e3o do pixel para \n\ndiferentes resolu\u00e7\u00f5es.  \n\nTABELA 1  Resolu\u00e7\u00e3o espacial. \n\nppp 300 600 1200\n\n \n\n1270\n\n \n\n2540\n\n \n\nTamanho do pixel ( m) 84 42 21 20 10 \n\n \n\n- Resolu\u00e7\u00e3o radiom\u00e9trica: Depende dos n\u00edveis de quantiza\u00e7\u00e3o \n\n(transforma\u00e7\u00e3o da fun\u00e7\u00e3o cont\u00ednua em valores de cinza discretos) \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n25\n\n \nempregados. A Tabela 2 mostra o n\u00famero de bits necess\u00e1rios para \n\nrepresentar certos n\u00edveis de cinza.  \n\nTABELA 2  Resolu\u00e7\u00e3o radiom\u00e9trica. \n\nn Bits 1\n\n \n\n2\n\n \n\n3\n\n \n\n4 5 6 7 8 \n\n2n N\u00edveis de cinza\n\n \n\n2\n\n \n\n4\n\n \n\n8\n\n \n\n16\n\n \n\n32\n\n \n\n64\n\n \n\n128\n\n \n\n256\n\n   \n\n2.2. C\u00e2maras digitais  \n\nSegundo Tommaselli et al (2000), c\u00e2maras digitais s\u00e3o dispositivos \n\ncompostos de um sistema de lentes, um chip sensor, que pode ser do tipo CCD \n\n(Charge Coupled Device) ou CMOS (Complementary Metal Oxide Semiconductor), \n\nprocessadores e uma mem\u00f3ria para a coleta e armazenamento de imagens digitais. \n\nO princ\u00edpio de forma\u00e7\u00e3o de uma imagem digital pode ser observado na Figura 1.         \n\nFIGURA 1 - Princ\u00edpio de forma\u00e7\u00e3o de uma imagem digital.  \n\n(Adaptado de TOMMASELLI et al, 2000)  \n\n \n\nCircuitos \neletr\u00f4nicos \n\nConversor \nAnal\u00f3gico/\n\nDigital \n(A/D) \n\nFrame \nbuffer \n\nEixo \u00f3ptico \n\nSistema de \n\nlentes \n\nSensor \n\nCCD \n\nFiltro \n\ncolorido \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n26\n\n \nO conversor A/D possui como objetivo transformar o sinal el\u00e9trico \n\nanal\u00f3gico gerado pelo CCD em um sinal digital, que \u00e9 armazenado em uma mem\u00f3ria \n\ntempor\u00e1ria (frame buffer).     \n\n2.3. Sistemas de coordenadas   \n\nO sistema de coordenadas de uma imagem digital \u00e9 um sistema \n\nplano-retangular com origem no canto superior esquerdo, sendo o eixo das \n\nabscissas coincidente com a primeira linha e o eixo das ordenadas com a primeira \n\ncoluna (Figura 2).  \n\nPara realiza\u00e7\u00e3o de procedimentos fotogram\u00e9tricos com as imagens \n\ndigitais, utiliza-se um sistema intermedi\u00e1rio (x, y) com origem definida no centro da \n\nimagem (Figura 2).          \n\nFIGURA 2  Defini\u00e7\u00e3o do sistema de coordenadas de uma imagem digital.  \n\nx \n\nj (colunas) \n\ni (linhas) \n\nCentro da imagem \n\n0 \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n27\n\n \nA transforma\u00e7\u00e3o das coordenadas do sistema imagem para o \n\nsistema intermedi\u00e1rio depende de uma transla\u00e7\u00e3o entre as origens dos sistemas, \n\numa reflex\u00e3o no eixo das ordenadas e um fator de escala equivalente ao tamanho \n\ndo pixel, a fim de estabelecer as coordenadas num sistema m\u00e9trico (Equa\u00e7\u00e3o 1).  \n\n                      \nyy\n\nxx\n\nSciy\n\nScjx\n\n*)(\n\n*)(\n                                             (1)  \n\nOnde: \n\n2\n\n1\n2\n\n1\n\nH\nc\n\nW\nc\n\ny\n\nx \n\nyx,  coordenadas referidas ao sistema intermedi\u00e1rio; \n\nji,\n\n \n\n coordenadas referidas ao sistema da imagem; \n\nyx cc , - coordenadas do centro da imagem no sistema de imagem; \n\nWH , \n\n \n\nn\u00fameros de linhas e colunas, respectivamente; \n\nyx SS\n\n \n\ndimens\u00f5es do pixel nas componentes x e y, respectivamente.     \n\n2.4. Efeitos sistem\u00e1ticos   \n\nNo processo de forma\u00e7\u00e3o de uma imagem digital, h\u00e1 efeitos \n\nsistem\u00e1ticos que produzem distor\u00e7\u00f5es, com causas e caracter\u00edsticas distintas. Estes \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n28\n\n \nefeitos ocorrem com freq\u00fc\u00eancia e podem ser modelados matematicamente, a fim de \n\nque se possam minimizar os efeitos de afastamento da geometria projetiva.  \n\nAlguns dos efeitos sistem\u00e1ticos existentes na forma\u00e7\u00e3o das imagens \n\ndigitais, segundo Galo (1993) e Mikhail et al (2001) s\u00e3o: \n\n- Deslocamento do ponto principal; \n\n- Distor\u00e7\u00e3o das lentes.  \n\nO deslocamento do ponto principal ocorre pela n\u00e3o coincid\u00eancia do \n\neixo \u00f3ptico com o centro da imagem. \n\nSegundo Mikhail et al (2001), a distor\u00e7\u00e3o das lentes \u00e9 a aberra\u00e7\u00e3o \n\nmais relevante para a pr\u00e1tica fotogram\u00e9trica. Estas distor\u00e7\u00f5es s\u00e3o causadas pelos \n\ndesvios dos raios que, ao atravessar em um sistema de lentes, prejudicam a \n\ngeometria por meio de deslocamentos na imagem. Esta aberra\u00e7\u00e3o pode ser dividida \n\nem: distor\u00e7\u00e3o radial sim\u00e9trica e distor\u00e7\u00e3o descentrada.  \n\nA distor\u00e7\u00e3o radial sim\u00e9trica \u00e9 o deslocamento radial de um ponto na \n\nimagem, isto \u00e9, uma mudan\u00e7a no \u00e2ngulo entre o raio de luz e o eixo \u00f3ptico sofrida \n\npor um raio de luz ao atravessar uma lente ou um sistema de lentes (MIKHAIL et al, \n\n2001).  \n\nA distor\u00e7\u00e3o descentrada \u00e9 um deslocamento da imagem advindo da \n\nimpossibilidade do fabricante em alinhar perfeitamente os eixos \u00f3pticos das lentes \n\nde uma objetiva.  \n\n   \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n29\n\n \n2.5. Melhoramento de contraste linear   \n\nO melhoramento de contraste linear consiste no processamento de \n\numa imagem, de modo que o resultado seja mais apropriado para uma aplica\u00e7\u00e3o \n\nespec\u00edfica do que a imagem original. O contraste nas imagens \u00e9 afetado pela \n\nilumina\u00e7\u00e3o n\u00e3o homog\u00eanea e abertura incorreta do diafragma da c\u00e2mara durante a \n\naquisi\u00e7\u00e3o da imagem. \u00c9 normalmente usado como uma etapa de pr\u00e9-processamento \n\npara sistemas de reconhecimento de padr\u00f5es (GONZALES e WOODS, 2000). \n\nDentre os m\u00e9todos existentes para solucionar este problema \n\nencontram-se: m\u00e9todo denominado expans\u00e3o do histograma, m\u00e9todo de contraste \n\nlinear percentual e m\u00e9todo de transforma\u00e7\u00e3o local.      \n\n2.5.1. M\u00e9todo de expans\u00e3o do histograma   \n\nEste m\u00e9todo de melhoramento ocupa todo o intervalo de cinza, n\u00e3o \n\nprovocando nenhuma perda. Esta opera\u00e7\u00e3o \u00e9 realizada a partir de uma interpola\u00e7\u00e3o \n\nlinear (Equa\u00e7\u00e3o 2) (SPRING, 2003).  \n\nnivelmaior\nGG\n\nGG\nG it _*\n\nminmax\n\nmin                                         (2)   \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n30\n\n \nOnde: \n\nminG  menor n\u00edvel de cinza encontrado na imagem; \n\nmaxG  maior n\u00edvel de cinza encontrado na imagem; \n\niG  n\u00edvel de cinza original de um pixel na imagem; \n\ntG  n\u00edvel de cinza resultante de um pixel ap\u00f3s a transforma\u00e7\u00e3o; \n\nmaior_n\u00edvel \n\n \n\nindica o maior n\u00edvel de quantiza\u00e7\u00e3o dispon\u00edvel. Por exemplo: se a \n\nimagem possui 8 bits, o maior n\u00edvel \u00e9 dado por 128   = 255.   \n\nOutra forma de melhoramento do contraste \u00e9 denominada de \n\ncontraste linear percentual. Este processo \u00e9 utilizado quando se deseja especificar \n\nos valores de minG e maxG para real\u00e7ar determinado intervalo de cinza. Neste caso, \n\nutiliza-se uma certa percentagem de pixels a partir da m\u00e9dia do histograma. O \n\nproblema deste processo \u00e9 a perda de informa\u00e7\u00e3o em benef\u00edcio do realce da \n\ninforma\u00e7\u00e3o que se deseja real\u00e7ar. Al\u00e9m disso, como escolher a percentagem de \n\npixels a se trabalhar porque depende da imagem original (GONZALES e WOODS, \n\n2000).    \n\n2.5.2. Transforma\u00e7\u00e3o local   \n\nOs m\u00e9todos mostrados na Se\u00e7\u00e3o 2.4.1 s\u00e3o globais no sentido de que \n\nos pixels s\u00e3o modificados atrav\u00e9s de uma fun\u00e7\u00e3o de transforma\u00e7\u00e3o baseada na \n\ndistribui\u00e7\u00e3o dos n\u00edveis de cinza sobre uma imagem inteira, n\u00e3o garantindo o realce \n\nlocal desejado. Uma transforma\u00e7\u00e3o local baseada nas propriedades de intensidades \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n31\n\n \nda m\u00e9dia e do desvio-padr\u00e3o de pixels pode ser observada na Equa\u00e7\u00e3o 3 \n\n(GONZALES e WOODS, 2000).     \n\nyxmyxmyxfyxAyxg ,,,,,                                  (3)  \n\nOnde:  \n\nyxkMyxA ,/, ; \n\nyxf , - n\u00edveis de cinza da imagem original; \n\nyxg , - n\u00edveis de cinza da imagem resultante; \n\nyxm , - n\u00edvel de cinza m\u00e9dio calculado numa vizinhan\u00e7a centrada em yx, ; \n\nyx,\n\n \n\n- desvio-padr\u00e3o calculado numa vizinhan\u00e7a centrada em yx, ; \n\nM\n\n \n\n-  m\u00e9dia global de yxf , ; \n\nk - constante variando no intervalo 1,0 .  \n\nEste m\u00e9todo possui um melhor resultado em rela\u00e7\u00e3o ao m\u00e9todo de \n\nexpans\u00e3o do histograma pelo fato de realizar um melhoramento local, por\u00e9m, possui \n\numa desvantagem na automa\u00e7\u00e3o do processo, j\u00e1 que, a constante k a ser sugerida \n\ndepende das caracter\u00edsticas da imagem original.       \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n32\n\n \n2.6. Segmenta\u00e7\u00e3o   \n\nA segmenta\u00e7\u00e3o consiste em subdividir uma imagem em regi\u00f5es \n\nhomog\u00eaneas usando propriedades desejadas como: n\u00edvel de cinza, cor ou textura. \n\nOs principais objetivos da segmenta\u00e7\u00e3o s\u00e3o reduzir a quantidade de dados a serem \n\nprocessados na an\u00e1lise de imagens e obter importantes informa\u00e7\u00f5es a respeito de \n\nobjetos e fei\u00e7\u00f5es contidas nelas (EL-HAKIM, 1996).  \n\nOs m\u00e9todos de segmenta\u00e7\u00e3o podem ser divididos em dois tipos: \n\nbaseados em bordas e baseados em regi\u00f5es (SONKA et al, 1998).  \n\nOs m\u00e9todos de segmenta\u00e7\u00e3o baseados em bordas procuram \n\ndiscriminar os objetos pelos contornos detectados a partir das descontinuidades em \n\nalgumas das propriedades. O problema deste m\u00e9todo est\u00e1 no fato de n\u00e3o haver \n\npixels com valores de gradientes nulos, resultante de ru\u00eddos ou varia\u00e7\u00f5es de \n\nilumina\u00e7\u00e3o.  \n\nOs m\u00e9todos de segmenta\u00e7\u00e3o baseados em regi\u00f5es procuram dividir \n\na imagem em regi\u00f5es que devem corresponder \u00e0s \u00e1reas de interesse da aplica\u00e7\u00e3o. \n\nEstas regi\u00f5es consistem no conjunto de pixels cont\u00edguos que se espalham \n\nbidirecionalmente e que apresentam uniformidade (SPRING, 2003).   O m\u00e9todo mais \n\nconhecido para este tipo de segmenta\u00e7\u00e3o \u00e9 o crescimento de regi\u00f5es. Este m\u00e9todo \n\nconsiste em agrupar pixels vizinhos que apresentam regi\u00f5es homog\u00eaneas segundo \n\ncrit\u00e9rios de similaridade. Um dos crit\u00e9rios que pode ser usado \u00e9 comparar se a \n\nm\u00e9dia e o desvio-padr\u00e3o dos n\u00edveis de cinza de duas regi\u00f5es e verificar se estes \n\nvalores s\u00e3o estatisticamente compat\u00edveis.     \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n33\n\n \nPara o reconhecimento de padr\u00f5es, a etapa de segmenta\u00e7\u00e3o \u00e9 \n\ninteressante porque n\u00e3o necessita que cada alvo armazenado percorra toda a \n\nimagem comparando os n\u00edveis de cinza, otimizando o processo, evitando diferentes \n\nrespostas para o mesmo tipo de alvo e proporcionando resultados mais confi\u00e1veis.   \n\n2.7. Limiariza\u00e7\u00e3o   \n\nSegundo Gonzales e Woods (2000), a etapa de limiariza\u00e7\u00e3o \u00e9 uma \n\ndas abordagens mais importantes para a segmenta\u00e7\u00e3o de imagens.  \n\nA limiariza\u00e7\u00e3o pode ser resolvida a partir de t\u00e9cnicas globais e locais. \n\nAs t\u00e9cnicas globais consistem em determinar um \u00fanico limiar para toda a imagem. A \n\nescolha da modifica\u00e7\u00e3o dos n\u00edveis de cinza depende da signific\u00e2ncia do objeto na \n\nimagem. Isto \u00e9, caso o objeto significativo possua valores de n\u00edveis de cinza altos, \n\ntodos os valores acima do limiar permanecem com o n\u00edvel de cinza original e abaixo \n\ndeste limiar recebem zero.  \n\nPor\u00e9m, esta t\u00e9cnica traz problemas causados pela reflect\u00e2ncia, \n\nsombras e ilumina\u00e7\u00e3o n\u00e3o adequada. O sucesso deste m\u00e9todo depende de um \n\nhistograma bimodal.  \n\nUma das maneiras de determinar o limiar (T) \u00e9 a partir da m\u00e9dia (m) \n\ne do desvio-padr\u00e3o (s) dos n\u00edveis de cinza da imagem, a partir da Equa\u00e7\u00e3o 4.  \n\nsmT 3                                                          (4)  \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n34\n\n \nUma melhor alternativa, portanto, s\u00e3o as t\u00e9cnicas locais, que \n\nconsistem em determinar um limiar para cada regi\u00e3o da imagem, que pode ser \n\ndelimitada por uma janela. \n\nOutras t\u00e9cnicas destinadas \u00e0 obten\u00e7\u00e3o de um valor de limiar s\u00e3o \n\ndescritas resumidamente nas se\u00e7\u00f5es seguintes. Para maiores detalhes ver Sonka et \n\nal\n\n \n\n(1998) e Artero (1999).     \n\n2.7.1. M\u00e9todo de Otsu   \n\nO m\u00e9todo de Otsu \u00e9 baseado na an\u00e1lise discriminante e o valor do \n\nlimiar \u00e9 obtido supondo que os pixels da imagem podem ser classificados em duas \n\nclasses: fundo ( 1C :n\u00edveis de cinza no intervalo t,1 ) e objeto ( 2C :n\u00edveis de cinza no \n\nintervalo Lt ,1 ) (OTSU, 1979). Neste caso, a distribui\u00e7\u00e3o de probabilidade de \n\nambas as classes podem ser descritas por:  \n\nt\n\np\n\nt\n\np\nC t\n\n11\n\n1\n1 ,...,:      e     \n\nt\n\np\n\nt\n\np\nC Lt\n\n22\n\n1\n2 ,...,:                          (5)   \n\nOnde: \n\nt\n\ni\nipt\n\n1\n1  e \n\nL\n\nti\nipt\n\n1\n2\n\n   \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n35\n\n \nAs m\u00e9dias para as classes C1 e C2 s\u00e3o dadas por:  \n\nt\n\ni i\n\ni\n\nt\n\npi\n\n1\n1\n\n.\n               e               \n\nL\n\nti\n\ni\n\nt\n\npi\n\n1 2\n2\n\n.\n                        (6)  \n\nSendo T  a intensidade m\u00e9dia para toda a imagem, ent\u00e3o: \n\n            \n\nTtt 2211                                          (7) \n\ne \n\n                              121 tt                                                 (8)  \n\nUtilizando a an\u00e1lise discriminante, a vari\u00e2ncia entre as classes da \n\nimagem limiarizada \u00e9 definida por:  \n\n                 \n2\n\n122\n2\n\n211\n2 ttB                             (9)  \n\nO limiar \u00f3timo t* \u00e9 determinado como sendo aquele cuja vari\u00e2ncia \n\nentre as classes 2B  \u00e9 m\u00e1xima, isto \u00e9: \n\n                       \n\n \n\nLttt B 1,maxarg*\n2                                   (10)     \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n36\n\n \n2.7.2. M\u00e9todo de Pun   \n\nO m\u00e9todo de Pun est\u00e1 relacionado com a teoria da informa\u00e7\u00e3o, que \n\nse baseia na premissa de que a gera\u00e7\u00e3o de informa\u00e7\u00e3o pode ser modelada como \n\num processo probabil\u00edstico (GONZALES, 1993). \n\nA partir desta teoria, define-se a entropia da imagem como:  \n\n                   xxxEntropia log                                            (11)  \n\nComo neste m\u00e9todo pretende-se segmentar em duas classes (fundo \n\ne objeto), t\u00eam-se duas entropias (Equa\u00e7\u00e3o 12).  \n\n                  \nt\n\ni\nieib ppH\n\n0\n\nlog                                                 (12) \n\n                           \n1\n\n1\n\nlog\nl\n\nti\nieiw ppH  \n\nO limiar, neste m\u00e9todo, \u00e9 obtido por:  \n\n            tHtHArgMaximoT wb                                           (13)     \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n37\n\n \n2.7.3. Limiariza\u00e7\u00e3o local   \n\nArtero (1999) utilizou uma t\u00e9cnica de limiariza\u00e7\u00e3o local da imagem \n\nque consiste em determinar um limiar utilizando os pixels pertencentes a uma janela \n\nde 60 pixels x 60 pixels. O valor de limiar assim obtido \u00e9 utilizado para todos os \n\npixels localizados na regi\u00e3o central desta janela (uma regi\u00e3o de tamanho 20 pixels x \n\n20 pixels). As dimens\u00f5es destas janelas foram definidas empiricamente e podem ser \n\nalteradas dependendo das caracter\u00edsticas da imagem. \n\nComo algumas regi\u00f5es n\u00e3o possuem todos os blocos vizinhos, \n\nalgumas altera\u00e7\u00f5es devem ser realizadas no momento da implementa\u00e7\u00e3o. No total, \n\ns\u00e3o nove regi\u00f5es da borda da imagem que necessitam ser diferenciada em rela\u00e7\u00e3o \n\nao tamanho da m\u00e1scara a ser percorrida e a regi\u00e3o que ser\u00e1 alterada pelo limiar \n\ndeterminado (Figura 3).           \n\nFIGURA 3  Regi\u00f5es definidas no processo de limiariza\u00e7\u00e3o local.   \n\n(Fonte: ARTERO, 1999).  \n\n1 2 2 2 ...\n\n \n\n2 3 \n4 5 5 5 ...\n\n \n\n5 6 \n4 5 5 5 ...\n\n \n\n5 6 \n...\n\n \n\n...\n\n \n\n...\n\n \n\n...\n\n \n\n...\n\n \n\n5 6 \n4 5 5 5 ...\n\n \n\n5 6 \n7 8 8 8 ...\n\n \n\n8 9 \n\n \n\n20x20 \n\nSitua\u00e7\u00e3o 1  \n40x40 \n\n20x20 \n\nSitua\u00e7\u00e3o 2 \n60x40 \n\n \n\n20x20 \n\nSitua\u00e7\u00e3o 3 \n40x40 \n\n \n\n20x20\n\n \n\nSitua\u00e7\u00e3o 6 \n40x60 \n\n \n\n20x20\n\n \n\nSitua\u00e7\u00e3o 8 \n     60x40 \n\n \n\n20x20\n\n \n\nSitua\u00e7\u00e3o 7 \n40x40 \n\n \n\n20x20 \nSitua\u00e7\u00e3o 4 \n\n40x60 \n\n \n\nSitua\u00e7\u00e3o 9 \n40x40 \n\n \n\n20x20\n\n \n\nSitua\u00e7\u00e3o 5 \n60x60 \n\n20x20\n\n \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n38\n\n \n2.8. Detec\u00e7\u00e3o de bordas   \n\nA etapa de detec\u00e7\u00e3o de bordas \u00e9 essencial para o c\u00e1lculo das \n\ncoordenadas subpixel. Este m\u00e9todo consiste na aplica\u00e7\u00e3o de um detector de bordas, \n\nque normalmente \u00e9 baseado na aplica\u00e7\u00e3o de opera\u00e7\u00f5es de detec\u00e7\u00e3o de varia\u00e7\u00f5es \n\nde brilho na imagem. Para a detec\u00e7\u00e3o de bordas, os operadores de gradiente s\u00e3o \n\nimprescind\u00edveis. Estes gradientes s\u00e3o apresentados a seguir.    \n\n2.8.1. Operadores de gradiente   \n\nSegundo Gonzales e Woods (2000), o gradiente ( f ) de uma \n\nimagem yxf ,  na posi\u00e7\u00e3o yx,  \u00e9 dado pelo vetor na Equa\u00e7\u00e3o 14.  \n\n                          \n\ny\n\nf\nx\n\nf\n\nGy\n\nGx\nf                                                    (14)  \n\nOnde: \n\nyx GG ,  gradientes em x e y, respectivamente.  \n\nNos m\u00e9todos de detec\u00e7\u00e3o de bordas, a magnitude deste vetor \u00e9 \n\nmuito importante porque o alto valor da magnitude indica a presen\u00e7a de bordas, isto \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n39\n\n \n\u00e9, uma grande varia\u00e7\u00e3o entre os n\u00edveis de cinza na imagem. A magnitude deste \n\nvetor \u00e9 obtida pela raiz quadrada da soma dos quadrados dos gradientes em x e y \n\n(Equa\u00e7\u00e3o 15).     \n\n22 )()( GyGxf       (a)                                         (15) \n\n                      GyGxf                (b)   \n\nOutro valor importante na detec\u00e7\u00e3o de bordas \u00e9 a dire\u00e7\u00e3o do vetor \n\n( ) para cada pixel em rela\u00e7\u00e3o ao eixo x. Este \u00e2ngulo \u00e9 determinado pela Equa\u00e7\u00e3o \n\n16. \n\nx\n\ny\n\nG\n\nG\narctg                                                 (16)  \n\nA representa\u00e7\u00e3o geom\u00e9trica das grandezas calculadas nas Equa\u00e7\u00f5es \n\n15a e 16 pode ser percebida por meio da Figura 4.        \n\nFIGURA 4  Representa\u00e7\u00e3o das magnitudes dos gradientes e do \u00e2ngulo de dire\u00e7\u00f5es \n\ndas bordas.  \n\n \n\nGx \n\nGy \n\nMagnitude \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n40\n\n \n2.8.1.1. Operadores de Sobel   \n\nO operador de Sobel \u00e9 definido com valores maiores na parte central \n\ndas m\u00e1scaras, o que equivale, considerar que os pixels centrais t\u00eam uma maior \n\ninflu\u00eancia em rela\u00e7\u00e3o aos pixels das bordas. Os gradientes s\u00e3o determinados a partir \n\nde duas m\u00e1scaras representando os gradientes em x e y. Estas m\u00e1scaras podem \n\nser observadas na Figura 5.         \n\nFIGURA 5  M\u00e1scaras usadas no operador de Sobel.  \n\n(a) Gradiente em x; (b) Gradiente em y.  \n\nUma vantagem do operador de Sobel em rela\u00e7\u00e3o a outros \n\noperadores de gradiente \u00e9 conseguir detectar bordas em qualquer dire\u00e7\u00e3o. \n\nA detec\u00e7\u00e3o de bordas, neste m\u00e9todo, consiste em realizar a \n\nconvolu\u00e7\u00e3o das m\u00e1scaras na imagem desejada. Para cada convolu\u00e7\u00e3o, determinam-\n\nse os gradientes em x e y para o pixel central. No final do procedimento, a imagem \n\nresultante dos gradientes possui o mesmo tamanho da imagem original. Como em \n\ncada convolu\u00e7\u00e3o, os gradientes em x e y s\u00e3o determinados apenas para os pixels \n\ncentrais, uma implementa\u00e7\u00e3o utilizando-se as vizinhan\u00e7as parciais \u00e9 necess\u00e1ria para \n\ndeterminar os gradientes nas bordas da imagem.   \n\n-1 0 1 \n\n-2 0 2 \n\n-1 0 1 \n\n(a) \n\n-1 -2 -1 \n\n0 0 0 \n\n1 2 1 \n\n(b) \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n41\n\n \n2.9. Detector de cantos  \n\n2.9.1. Operadores de interesse   \n\nOs operadores de interesse podem ser definidos como um  operador \n\nde vizinhan\u00e7a que objetiva localizar com uma alta precis\u00e3o as coordenadas pixel ou \n\nsubpixel (HARALICK e SHAPIRO (1993) apud GALO e TOZZI (2002)).  Dentre os \n\ndiversos operadores de interesse pode-se citar: operador de Moravec e operador de \n\nF\u00f6rstner.   \n\n2.9.1.1. Operador de Moravec   \n\nEste operador baseia-se na medida de vari\u00e2ncia direcional \n\nconsiderando os quadrados das diferen\u00e7as de tons de cinza em quatro dire\u00e7\u00f5es: 0\u00ba, \n\n45\u00ba, 90\u00ba e 135\u00ba (Figura 6).   \n\nLevando-se em conta uma janela com n x n pixels e admitindo que o \n\nelemento inteiro (n/2, n/2) \u00e9 o pixel central, pode-se obter a resposta do operador de \n\ninteresse Moravec pelo c\u00e1lculo das equa\u00e7\u00f5es 17.     \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n42\n\n      \n\nFIGURA 6 - Janelas 3x3 mostrando os vetores de 0\u00ba, 45\u00ba, 90\u00ba e 135\u00ba, respectivamente \n\n(GALO e TOZZI, 2002).   \n\nN\n\nr\n\nN\n\nc\n\nN\n\nr\n\nN\n\nc\n\nN\n\nr\n\nN\n\nNc\n\nN\n\nr\n\nN\n\nNc\n\ncrgcrg\nn\n\nV\n\ncrgcrg\nnn\n\nV\n\ncrgcrg\nn\n\nV\n\ncrgcrg\nnn\n\nV\n\ncrOI\n\n0 0\n\n2\n\n2135\n\n0\n\n2\n\n0\n\n2\n\n90\n\n0\n\n2\n2\n\n245\n\n2\n\n0\n\n2\n2\n\n0\n\n1,1(),(\n1\n\n1\n\n,1(),(\n1\n\n1\n\n1,1(),(\n1\n\n1\n\n1,(),(\n1\n\n1\n\nmin]][[                    (17)  \n\nOnde: \n\ncr,\n\n \n\n- linhas e colunas da imagem, respectivamente; \n\n),( crg - n\u00edveis de cinza para posi\u00e7\u00e3o ),( cr ;  \n\n2/)1(nN ; e, \n\nOI  operador de interesse.  \n\nA Equa\u00e7\u00e3o 17 determina, para cada ponto da imagem, o valor \n\nm\u00ednimo do operador de interesse nas quatro dire\u00e7\u00f5es. A partir do valor do operador \n\nde interesse obtido na Equa\u00e7\u00e3o 17, para cada ponto da imagem, os m\u00e1ximos locais \n\nde crOI podem ser encontrados. Pixels com valores de crOI superiores a um \n\nC \n\n \n(0,0) \n\nL \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n43\n\n \nlimiar pr\u00e9-estabelecido correspondem a pontos de quina. O resultado deste operador \n\nser\u00e3o as coordenadas dos cantos com precis\u00e3o pixel. \n\nVale ressaltar que o uso de janelas de dimens\u00e3o \u00edmpar (Equa\u00e7\u00e3o \n\n17) n\u00e3o \u00e9 uma restri\u00e7\u00e3o do operador de Moravec, mas uma op\u00e7\u00e3o de Galo e Tozzi \n\n(2002). Esta restri\u00e7\u00e3o deve ao fato de se ter escolhido o pixel central da janela como \n\norigem, sendo a janela sim\u00e9trica a este ponto.    \n\n2.9.1.2. Operador de F\u00f6rstner    \n\nPara determina\u00e7\u00e3o da posi\u00e7\u00e3o das quinas com acur\u00e1cia subpixel \n\npode-se usar o fato de que uma quina \u00e9 formada pela intersec\u00e7\u00e3o de pelo menos \n\ndois segmentos lineares, isto \u00e9, a quina \u00e9 localizada pela intersec\u00e7\u00e3o dos vetores \n\nperpendiculares \u00e0s dire\u00e7\u00f5es de m\u00e1ximo gradiente sobre as bordas. \n\nUm dos operadores mais usados para detec\u00e7\u00e3o de quinas \n\n(operadores de interesse) \u00e9 o operador de F\u00f6rstner.  \n\nAs coordenadas destes operadores de interesse (cantos) s\u00e3o \n\ndeterminadas com precis\u00e3o subpixel usando a Equa\u00e7\u00e3o 18. (F\u00d6RSTNER, 1988 \n\napud GALO e TOZZI, 2002). \n\n      \nCiLiiCii\n\nCiLiiLii\n\nCiCiLi\n\nCiLiLi\n\nggLgC\n\nggCgL\n\nggg\n\nggg\n\nC\n\nL\n2\n\n21\n\n2\n\n2\n\n0\n\n0                      (18) \n\nOnde: \n\n0,0 CL - coordenadas dos cantos com precis\u00e3o subpixel; \n\nii CL , - coordenadas do pixel de uma janela m x m; \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n44\n\n \nCiLi gg , - gradientes em y e x, respectivamente.  \n\nComo pode ser observado na Equa\u00e7\u00e3o 18, a estima\u00e7\u00e3o da posi\u00e7\u00e3o \n\ndos cantos com precis\u00e3o subpixel depende das posi\u00e7\u00f5es com precis\u00e3o pixel e os \n\ngradientes ao longo das linhas e colunas. Os gradientes em x e y podem ser \n\ndeterminados a partir dos operadores de Sobel (Se\u00e7\u00e3o 2.7.1.1).  \n\nA matriz inversa 2 x 2 na Equa\u00e7\u00e3o 18 pode ser vista como a matriz \n\nvari\u00e2ncia-covari\u00e2ncia do ajustamento. Esta matriz pode ser usada para obter a elipse \n\ndos erros associada \u00e0 quina 00 , CL e fazer a discrimina\u00e7\u00e3o de pontos com \n\ndiferentes caracter\u00edsticas (HARALICK e SHAPIRO, 1993 apud GALO e TOZZI, \n\n2002).   \n\n2.9.2. T\u00e9cnica h\u00edbrida usada para detec\u00e7\u00e3o de cantos    \n\nGalo e Tozzi (2002) desenvolveram um m\u00e9todo para a extra\u00e7\u00e3o de \n\npontos com acur\u00e1cia subpixel em imagens digitais usando uma combina\u00e7\u00e3o dos \n\nm\u00e9todos de detec\u00e7\u00e3o de quinas: Moravec e F\u00f6rstner. Primeiramente, detectam-se \n\nos cantos usando o operador de Moravec com precis\u00e3o pixel que s\u00e3o usados, \n\nposteriormente, como pontos iniciais para obten\u00e7\u00e3o das coordenadas de cantos \n\nsubpixel. Esta etapa \u00e9 realizada normalizando a matriz dos valores de OI (Equa\u00e7\u00e3o \n\n17) no intervalo 255,0  e fazendo-se a supress\u00e3o dos n\u00e3o m\u00e1ximos aplicando-se um \n\ncerto limiar que pode ser expresso de modo percentual (Tp). Os pixels com n\u00edveis de \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n45\n\n \ncinza superiores ao limiar ( pTLim ) determinado s\u00e3o rotulados como pixels \n\nprov\u00e1veis de serem de quinas.   \n\n100\n\n255\n*100 Pp TTLim                                               (19)  \n\nCom esta segmenta\u00e7\u00e3o, a imagem original fica subdividida em duas \n\nclasses. Como em torno das quinas tem-se um conjunto de pontos, podem-se \n\nagrupar estes pontos e usar o centro de massa destas regi\u00f5es como posi\u00e7\u00f5es \n\naproximadas das quinas. O centro de massa de cada regi\u00e3o \u00e9 ent\u00e3o rotulado como \n\n255 e, portanto, tem-se como resultado uma imagem composta de tr\u00eas classes. \n\nEstes pixels com r\u00f3tulos iguais a 255 s\u00e3o usados como centro da janela a ser \n\nselecionada para o c\u00e1lculo das coordenadas subpixel usando o operador de \n\nF\u00f6rstner (Se\u00e7\u00e3o 2.8.1.2). Um cuidado a ser tomado, neste procedimento, est\u00e1 \n\nrelacionado ao tamanho da janela a ser selecionada para determina\u00e7\u00e3o dos \n\ngradientes em x e y. Caso a janela a ser selecionada seja muito pequena, a \n\nlocaliza\u00e7\u00e3o precisa torna-se prec\u00e1ria; por\u00e9m, se a janela for muito grande tamb\u00e9m, \n\npode-se capturar dados que n\u00e3o fa\u00e7am parte do canto a ser determinado, \n\ndeteriorando os resultados. Outro cuidado que merece aten\u00e7\u00e3o \u00e9 o fato de se usar \n\nlimiar global para a supress\u00e3o dos n\u00e3o m\u00e1ximos. Uma solu\u00e7\u00e3o para evitar que \n\nquinas em regi\u00f5es de baixo contraste sejam selecionadas \u00e9 realizar todos os \n\nprocedimentos em \u00e1reas locais selecionadas da imagem.  \n\nOutro problema existente \u00e9 advindo da aquisi\u00e7\u00e3o da imagem, \n\nacarretando em cantos arredondados e dificultando na intersec\u00e7\u00e3o das retas.   \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n46\n\n \nCAP\u00cdTULO III   \n\n3. FOTOGRAMETRIA \u00c0 CURTA DIST\u00c2NCIA   \n\nFotogrametria terrestre \u00e9 o ramo da Fotogrametria realizada com \n\nfotografias obtidas com c\u00e2maras situadas na superf\u00edcie terrestre. Um caso especial \n\nda Fotogrametria terrestre, com fotografias tiradas at\u00e9 uma dist\u00e2ncia de 100 m, \u00e9 \n\ndenominado de Fotogrametria \u00e0 curta dist\u00e2ncia (WOLF, 1983).  \n\nUm m\u00e9todo alternativo deste ramo da Fotogrametria e muito \n\nutilizado para a identifica\u00e7\u00e3o e medi\u00e7\u00e3o autom\u00e1tica de superf\u00edcies \u00e9 o m\u00e9todo ativo \n\ndenominado luz estruturada. Este m\u00e9todo possui como objetivo substituir uma das \n\nc\u00e2maras por uma fonte de luz, facilitando no processo de determina\u00e7\u00e3o de \n\ncorrespond\u00eancia.    \n\n3.1. Aplica\u00e7\u00f5es da Fotogrametria \u00e0 curta dist\u00e2ncia   \n\nAs aplica\u00e7\u00f5es da Fotogrametria \u00e0 curta dist\u00e2ncia encontram-se, \n\nprincipalmente, nas seguintes \u00e1reas: \n\n- Ind\u00fastria: Os principais setores envolvidos, de acordo com \n\nFraser (1996), englobam a fabrica\u00e7\u00e3o de aeronaves e autom\u00f3veis, as \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n47\n\n \nind\u00fastrias aeroespaciais, qu\u00edmicas e nucleares e o controle de \n\nqualidade da produ\u00e7\u00e3o.  \n\nPeipe e Schneider (1995) apud Fraser (1996) aplicaram um sistema \n\ndenominado DPA-Win VM para inspe\u00e7\u00e3o das ferramentas de produ\u00e7\u00e3o automotiva \n\n(Figura 7). A tarefa envolveu a medida de 30 suportes, os quais foram sinalizados \n\ncom quatro alvos para obten\u00e7\u00e3o dos par\u00e2metros de orienta\u00e7\u00e3o e posi\u00e7\u00e3o. Uma rede \n\ncomposta de 40 c\u00e2maras foi necess\u00e1ria para obter a cobertura total dos alvos para \n\numa imagem com escala 1:50 e maior. A acur\u00e1cia obtida ap\u00f3s a triangula\u00e7\u00e3o por \n\nfeixes de raios foi de 0.05 mm ou 1:70.000.   \n\n        \n\nFIGURA 7 - Ferramenta de produ\u00e7\u00e3o automotiva (PEIPE e SCHNEIDER (1995) apud \n\nFRASER (1996)).  \n\n- Medicina: Utilizada na reconstru\u00e7\u00e3o e na determina\u00e7\u00e3o de \n\nformas e dimens\u00f5es de \u00f3rg\u00e3os e membros do corpo humano, \n\ninclusive com uso de ondas eletromagn\u00e9ticas em outras faixas do \n\nespectro que abrange o vis\u00edvel, como por exemplo, os raios-X. \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n48\n\n \nWong et al (1992) apud Newton e Mitchell (1996) empregaram \n\nm\u00e9todos fotogram\u00e9tricos para estudar o crescimento e a distribui\u00e7\u00e3o de massa \n\ncorporal. A cobertura completa foi obtida atrav\u00e9s de nove c\u00e2maras digitais \n\nagrupadas 3 a 3. Cada conjunto de 3 c\u00e2maras formava um tri\u00e2ngulo com dist\u00e2ncia \n\nde 2 m do paciente.   \n\n- Arquitetura: Utilizada na representa\u00e7\u00e3o de fachadas ou eleva\u00e7\u00f5es \n\nde monumentos hist\u00f3ricos e estruturas.  \n\nSegundo Dallas (1996), um exemplo de aplica\u00e7\u00e3o \u00e9 o levantamento \n\nda igreja St. Mary, North Yorkshire, realizado em 1994 pela ag\u00eancia governamental \n\nrespons\u00e1vel pela preserva\u00e7\u00e3o e gerenciamento de aproximadamente 400 \n\nmonumentos na Inglaterra denominada English Heritage.\n\n \n\nNesta igreja, foi realizada \n\numa cobertura est\u00e9reo, tanto na por\u00e7\u00e3o interior como exterior utilizando a c\u00e2mara \n\nUMK 30/1318 da Zeiss.  \n\n- Arqueologia: Utilizada na reconstru\u00e7\u00e3o de objetos arqueol\u00f3gicos \n\ne achados de s\u00edtios arqueol\u00f3gicos. \n\nSegundo Dallas (1996), um exemplo desta aplica\u00e7\u00e3o foi \u00e0 tomada de \n\nfotos do navio Romano-Celta, encontrado pr\u00f3ximo a Magor, a partir da c\u00e2mara Wild \n\nP31. No total, 15 fotografias foram necess\u00e1rias. \n\nHasegawa et al (1999) descreveram uma metodologia para \n\ndetermina\u00e7\u00e3o das coordenadas dos achados arqueol\u00f3gicos ao longo da margem do \n\nRio Paran\u00e1. As tomadas fotogr\u00e1ficas realizadas nas trincheiras eram quase na \n\nvertical e ocupavam geralmente uma \u00e1rea de um metro quadrado. A c\u00e2mara usada \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n49\n\n \npara este trabalho foi uma Kodak DC210. A etapa de reconstru\u00e7\u00e3o do objeto foi \n\nrealizada usando as equa\u00e7\u00f5es de colinearidade.    \n\n3.2. Luz estruturada   \n\nSegundo Battle et al (1996), a percep\u00e7\u00e3o de profundidade \u00e9 uma das \n\netapas mais importantes da Vis\u00e3o Computacional. A necessidade de conhecer \n\ninforma\u00e7\u00f5es 3D a respeito da superf\u00edcie pode ser resolvida a partir de m\u00e9todos \n\npassivos ou ativos, como j\u00e1 foi mencionado. Dentre os m\u00e9todos ativos encontra-se a \n\nt\u00e9cnica denominada de luz estruturada.  \n\nSegundo Newton e Mitchell (1996), esta t\u00e9cnica envolve o uso de \n\num projetor e uma c\u00e2mara, no qual o sistema de proje\u00e7\u00e3o \u00e9 usado para projetar o \n\npadr\u00e3o sobre o objeto na cena e uma c\u00e2mara captura a imagem dos padr\u00f5es que \n\ns\u00e3o distorcidos pela superf\u00edcie de proje\u00e7\u00e3o. O projetor \u00e9 equivalente a segunda \n\nc\u00e2mara usada na Fotogrametria e qualquer ponto projetado na cena com dire\u00e7\u00e3o e \n\ncom identifica\u00e7\u00e3o conhecidas pode ser reconstru\u00eddo usando os princ\u00edpios de \n\nintersec\u00e7\u00e3o dos raios de luz da Fotogrametria anal\u00edtica (rela\u00e7\u00e3o c\u00e2mara-projetor). A \n\ndetermina\u00e7\u00e3o das rela\u00e7\u00f5es geom\u00e9tricas existentes entre o sensor e os feixes de \n\nraios luminosos dos padr\u00f5es projetados \u00e9 conseguida por uma calibra\u00e7\u00e3o de \n\nsistema. O sistema de luz estruturada permite a reconstru\u00e7\u00e3o 3D para cada ponto de \n\nvista, sendo necess\u00e1ria \u00e0 combina\u00e7\u00e3o de v\u00e1rios pontos de vistas para criar um \n\nmodelo 3D completo do objeto. Uma das vantagens deste sistema \u00e9 quando este \n\nusa fontes de luz branca e conseq\u00fcentemente, n\u00e3o h\u00e1 a necessidade de cuidados \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n50\n\n \nespeciais de seguran\u00e7a, ao contr\u00e1rio de sistemas de varredura a laser, cuja luz \n\npossui algum n\u00edvel de radia\u00e7\u00e3o. Al\u00e9m disso, alguns sistemas de luz estruturada \n\npossuem precis\u00f5es compat\u00edveis com o sistema laser. Como vantagem deste sistema \n\nh\u00e1 a possibilidade de se capturar todos os alvos projetados e a imagem do objeto de \n\numa s\u00f3 vez, n\u00e3o sendo necess\u00e1rio manter o objeto est\u00e1tico durante a aquisi\u00e7\u00e3o. \n\nTamb\u00e9m pode haver a necessidade de tomada de m\u00faltiplas posi\u00e7\u00f5es para cobrir \n\ninteiramente um objeto, quando ele for maior que o campo de cobertura do sensor.  \n\nAs vantagens deste sistema em rela\u00e7\u00e3o a t\u00e9cnicas \n\nestereofotogram\u00e9tricas est\u00e3o relacionadas com (BATTLE et al, 1996): \n\n- Menor tempo entre a tomada de fotos e a resposta final; \n\n- Menor custo dos equipamentos; \n\n- N\u00e3o necessidade de pessoas especializadas para manusear os \n\nequipamentos; e, \n\n- Menor dificuldade ao medir superf\u00edcies homog\u00eaneas.   \n\n3.2.1. T\u00e9cnicas utilizando o sistema de luz estruturada   \n\nMuitas s\u00e3o as formas de identificar e medir pontos conjugados ou \n\ncorrespondentes. A seguir, s\u00e3o descritas algumas t\u00e9cnicas para solucionar este \n\nproblema, particularmente para sistemas \u00e0 curta dist\u00e2ncia.  \n\nBallard e Brown (1982) descreveram a t\u00e9cnica de luz estruturada, na \n\nqual a superf\u00edcie \u00e9 seccionada por um plano de luz e a cena \u00e9 imageada \n\ncontinuamente, enquanto a fonte de luz faz a varredura de toda a superf\u00edcie. A \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n51\n\n \nvantagem \u00e9 a simplifica\u00e7\u00e3o do processo de extra\u00e7\u00e3o de fei\u00e7\u00f5es, uma vez que \n\napenas uma linha aparece em cada imagem. O problema \u00e9 a necessidade de \n\nimobilizar tanto o objeto quanto a c\u00e2mara, durante o processo de aquisi\u00e7\u00e3o de \n\nimagens. \n\nHummel e Carrihill (1985) desenvolveram um sistema baseado no \n\nconceito de J. T. Schwartz, onde se pode reconstruir a profundidade a partir de duas \n\nimagens sem necessidade de resolver o problema de correspond\u00eancia. Este sistema \n\nutiliza-se do princ\u00edpio de plano de luz para reconstru\u00e7\u00e3o da geometria 3D, onde um \n\nponto objeto \u00e9 determinado pela intersec\u00e7\u00e3o do plano vertical passando atrav\u00e9s do \n\ncentro da lente do projetor e a linha de sinal determinada pela imagem da c\u00e2mara. \n\nEste plano vertical \u00e9 determinado de duas maneiras: com uma intensidade projetada \n\nuniformemente e com intensidades graduadas produzidas por um filtro linear. \n\nKeefe e Riley (1986) utilizaram o princ\u00edpio de luz estruturada para \n\nreconstru\u00e7\u00e3o 3D de formas faciais. Este sistema projeta uma linha de pontos \n\nverticais gerada por um laser. A partir de um estereopar das imagens da face \u00e9 \n\nposs\u00edvel reconstruir um contorno de uma parte desta. \n\nWang et al (1987) introduziram uma abordagem para a \n\ndetermina\u00e7\u00e3o das orienta\u00e7\u00f5es da superf\u00edcie com luz estruturada, sem \n\ncorrespond\u00eancia. Neste m\u00e9todo, assume-se que a geometria da c\u00e2mara e do \n\nprojetor podem ser aproximada por uma proje\u00e7\u00e3o ortogr\u00e1fica. A fun\u00e7\u00e3o de calibra\u00e7\u00e3o \n\ndetermina a orienta\u00e7\u00e3o relativa do plano da imagem da c\u00e2mara, o plano do slide e o \n\nplano base. Dois padr\u00f5es ortogonais de faixas paralelas s\u00e3o projetados sobre a \n\nsuperf\u00edcie do objeto. A orienta\u00e7\u00e3o da superf\u00edcie pode ser inferida das dire\u00e7\u00f5es das \n\nfaixas na imagem coletada pela c\u00e2mara. Para cada padr\u00e3o, uma injun\u00e7\u00e3o \n\ngeom\u00e9trica na orienta\u00e7\u00e3o da superf\u00edcie \u00e9 obtida. Esta orienta\u00e7\u00e3o pode ser obtida \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n52\n\n \npela intersec\u00e7\u00e3o das duas curvas na esfera gaussiana e interpoladas utilizando a \n\ninterpola\u00e7\u00e3o bic\u00fabica. Portanto, a profundidade relativa pode ser determinada da \n\norienta\u00e7\u00e3o da superf\u00edcie a partir da integra\u00e7\u00e3o de uma equa\u00e7\u00e3o diferencial. \n\nBoyer e Kak (1987) implementaram um esquema de c\u00f3digo colorido \n\nque projeta um padr\u00e3o de faixas verticais vermelhas, verdes, azuis e brancas sobre \n\na cena. O padr\u00e3o projetado possui diversos subpadr\u00f5es chaves. O padr\u00e3o chave \n\npode ser localizado na imagem da c\u00e2mara usando um conjunto de correlatores \n\nbin\u00e1rios. A localiza\u00e7\u00e3o dos padr\u00f5es chaves serve como semente para indexar as \n\nfaixas vizinhas. Este m\u00e9todo, como o de Scalco (2000), traz problemas pelo fato de \n\nutilizar alvos coloridos. Isto dificulta na identifica\u00e7\u00e3o dos alvos se o fundo for colorido. \n\nDunn e Keizer (1989), usando luz estruturada, recuperaram a forma \n\ntridimensional de partes do corpo humano. Este sistema projeta uma grade \n\nquadrada de 35 mm que aparece distorcida na imagem coletada pela c\u00e2mara devido \n\n\u00e0 curvatura e a varia\u00e7\u00e3o na orienta\u00e7\u00e3o da superf\u00edcie. As coordenadas 3D s\u00e3o \n\ndeterminadas pela intersec\u00e7\u00e3o das linhas da grade projetada seguida de uma \n\ntriangula\u00e7\u00e3o. Este sistema realiza o processamento em quatro passos: \n\n- Determina\u00e7\u00e3o das matrizes de calibra\u00e7\u00e3o da c\u00e2mara e do \n\nprojetor; \n\n- Processamento da imagem para localizar as interse\u00e7\u00f5es da \n\ngrade na imagem da c\u00e2mara; \n\n- Rotula\u00e7\u00e3o da grade; e, \n\n- Triangula\u00e7\u00e3o.  \n\nO padr\u00e3o desenvolvido por Dunn e Keizer (1989) pode ser \n\nobservado na Figura 8. Este padr\u00e3o apresenta problemas quando se trabalha com \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n53\n\n \nsuperf\u00edcies com descontinuidades porque as retas obl\u00edquas s\u00e3o desconectadas na \n\nimagem, n\u00e3o havendo possibilidade de identifica\u00e7\u00e3o do restante da imagem.              \n\nFIGURA 8 - Padr\u00e3o desenvolvido por Dunn e Keizer (1989).  \n\nSchalkoff (1989) descreveu um sistema de reconstru\u00e7\u00e3o, com luz \n\nestruturada. Neste sistema utiliza-se de um projetor como c\u00e2mara ativa que projeta \n\num conjunto de raios no plano da imagem. O objetivo desta t\u00e9cnica \u00e9 controlar a \n\nilumina\u00e7\u00e3o e simplificar o problema de determina\u00e7\u00e3o de correspond\u00eancias. Os \n\nproblemas deste m\u00e9todo est\u00e3o relacionados com a modelagem geom\u00e9trica da \n\nc\u00e2mara e do projetor.  \n\nOosterlinck e Vuylsteke (1990) desenvolveram um padr\u00e3o de \n\nilumina\u00e7\u00e3o para determinar a posi\u00e7\u00e3o espacial do ponto a partir de uma forma \n\nbin\u00e1ria. O padr\u00e3o de ilumina\u00e7\u00e3o utiliza-se de dois n\u00edveis de intensidade (preto e \n\nbranco) que definem uma grade de pontos e marca cada ponto individualmente com \n\num bit de codifica\u00e7\u00e3o. Os pontos da grade a serem reconhecidos na cena s\u00e3o \n\nlocalizados a partir da intersec\u00e7\u00e3o das bordas horizontais e verticais, isto \u00e9, onde \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n54\n\n \nquatro quadrados se encontram. Cada quadrado do tabuleiro \u00e9 marcado por um \n\nquadrado menor na forma de um sinal claro ou escuro. A escolha dos c\u00f3digos de \n\nbits para os pontos da grade \u00e9 baseada em duas seq\u00fc\u00eancias bin\u00e1rias. O tipo de \n\npadr\u00e3o utilizado por Oosterlinck e Vuylsteke (1990) pode ser visto nas Figuras 9 e \n\n10.    \n\nFIGURA 9 - Detalhe do padr\u00e3o bin\u00e1rio projetado. \n\n(Fonte: OOSTERLINCK e VUYLSTEKE, 1990).      \n\nFIGURA 10 - O padr\u00e3o de ilumina\u00e7\u00e3o composto de quatro primitivas. \n\n (Fonte: OOSTERLINCK e VUYLSTEKE, 1990).  \n\nMaas (1992) usou luz estruturada para a medi\u00e7\u00e3o de superf\u00edcies de \n\nobjetos que n\u00e3o apresentam textura na superf\u00edcie. Neste m\u00e9todo, trabalhou-se com \n\ndois tipos de objetos: um painel de carbono e um carro. Os padr\u00f5es de luz \n\nestruturada s\u00e3o projetados sobre o objeto por um projetor de slides e a imagem \u00e9 \n\ncapturada por duas ou mais c\u00e2maras. O estabelecimento de correspond\u00eancias \u00e9 \n\nrealizado usando informa\u00e7\u00f5es de linhas epipolares. A quantidade de c\u00e2maras a \n\nserem usadas depende da superf\u00edcie, dos valores aproximados das coordenadas e \n\ndo n\u00famero de pontos projetados.  \n\n0+ 0- 1+ 1- \n\n0 1 62 \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n55\n\n \nPlassman (1995) apud Scalco (2000) utilizou luz estruturada para a \n\nmedida de ulcera\u00e7\u00f5es cut\u00e2neas. O instrumento desenvolvido projeta uma seq\u00fc\u00eancia \n\nde faixas paralelas de luz sobre a superf\u00edcie da ulcera\u00e7\u00e3o. Estes padr\u00f5es s\u00e3o \n\ncapturados pela c\u00e2mara e processados em um sistema computacional conectado a \n\nela. O mapa de profundidade \u00e9 obtido por triangula\u00e7\u00e3o. \n\nSingh et al (1997) apud Scalco (2000) utilizaram o princ\u00edpio de luz \n\nestruturada na medi\u00e7\u00e3o de coordenadas 3D da superf\u00edcie sem textura. Estas \n\ncoordenadas s\u00e3o determinadas pela combina\u00e7\u00e3o de um m\u00e9todo de limiariza\u00e7\u00e3o \n\nconvencional e correla\u00e7\u00e3o por m\u00ednimos quadrados. \n\nScalco (2000) utilizou o sistema 3DScan com o princ\u00edpio de luz \n\nestruturada. Este sistema foi desenvolvido no Departamento de Cartografia da \n\nUnesp de Presidente Prudente (TOMMASELLI, 1997) e baseia-se na intersec\u00e7\u00e3o \n\ndas retas projetantes, calculadas a partir de pontos hom\u00f3logos na imagem e no \n\nprojetor, ap\u00f3s a correspond\u00eancia entre eles. A partir desta intersec\u00e7\u00e3o, as \n\ncoordenadas 3D dos pontos na superf\u00edcie s\u00e3o determinadas. As coordenadas do \n\ncentro do alvo s\u00e3o calculadas pela m\u00e9dia geom\u00e9trica entre os centros de massa. O \n\nalvo deve ser maior que uma determinada \u00e1rea informada anteriormente para n\u00e3o \n\nser considerado um ru\u00eddo. A imagem \u00e9 varrida pixel a pixel e, ao ser encontrado um \n\npixel colorido, este \u00e9 rotulado e \u00e9 obtido um centro inicial do alvo. A partir dos \n\nexperimentos realizados por Scalco (2000) com os algoritmos de correla\u00e7\u00e3o, alguns \n\ninconvenientes puderam ser percebidos como: \n\n- Necessidade de definir diferentes imagens de refer\u00eancia para \n\ncada tipo de alvo; \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n56\n\n \n- Necessidade de redefinir as imagens de refer\u00eancia para cada \n\ncena a ser reconstru\u00edda porque os alvos se modificam \n\nconsideravelmente, limitando a automa\u00e7\u00e3o do sistema;   \n\nAs vantagens deste processo s\u00e3o:  \n\n- Confiabilidade equivalente a sistemas est\u00e9reo-fotogram\u00e9tricos \n\nconvencionais;  \n\n- Componentes de baixo custo, dispon\u00edveis no mercado da \n\ninform\u00e1tica; \n\n- Redu\u00e7\u00e3o da complexidade do sistema devido \u00e0 introdu\u00e7\u00e3o do \n\nprojetor de padr\u00f5es, que possui geometria conhecida e que pode ser \n\ntratado como uma segunda c\u00e2mara.       \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n57\n\n \nCAP\u00cdTULO IV   \n\n4. RECONHECIMENTO DE PADR\u00d5ES    \n\nO reconhecimento de padr\u00f5es consiste em dotar uma m\u00e1quina com \n\na capacidade de aproximar, em um determinado sentido, a capacidade similar dos \n\nseres humanos. Por exemplo, em um sistema para a leitura autom\u00e1tica de imagens \n\nde documentos datilografados, os padr\u00f5es de interesse s\u00e3o caracteres \n\nalfanum\u00e9ricos, enquanto a meta \u00e9 atingir uma dada precis\u00e3o de reconhecimento de \n\ncaracteres que sejam a mais pr\u00f3xima poss\u00edvel \u00e0 excelente capacidade exibida por \n\nseres humanos na realiza\u00e7\u00e3o de tais tarefas (GONZALES e WOODS, 2000).  \n\nSegundo JAIN et al (2000), o sistema de reconhecimento de \n\npadr\u00f5es, na maioria das vezes, engloba cinco etapas: aquisi\u00e7\u00e3o de dados; pr\u00e9-\n\nprocessamento; extra\u00e7\u00e3o de caracter\u00edsticas; sele\u00e7\u00e3o de caracter\u00edsticas (an\u00e1lise dos \n\ndados) e classifica\u00e7\u00e3o (decis\u00e3o).  \n\nAlgumas aplica\u00e7\u00f5es do reconhecimento de padr\u00f5es est\u00e3o vinculadas \n\n\u00e0 classifica\u00e7\u00e3o de documentos (procurar textos em documentos); organiza\u00e7\u00e3o e \n\nrecupera\u00e7\u00e3o de base de dados; e, biom\u00e9trica (identifica\u00e7\u00e3o de pessoas a partir do \n\nconhecimento de atributos f\u00edsicos, tais como, face e impress\u00e3o digital). Outras \n\naplica\u00e7\u00f5es est\u00e3o descritas na Tabela 3.    \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n58\n\n \nTABELA 3  Exemplos de aplica\u00e7\u00f5es de reconhecimento de padr\u00f5es.  \n\n(Fonte: JAIN et al, 2000) \n\nDom\u00ednio do \nproblema \n\nAplica\u00e7\u00e3o Padr\u00e3o de \nentrada \n\nClasses do padr\u00e3o \n\nBioinform\u00e1tica An\u00e1lise de \nseq\u00fc\u00eancias \n\nDNA/ \nSeq\u00fc\u00eancia \n\nprot\u00e9ica \n\nConhecimento dos tipos \nde genes \n\nMinera\u00e7\u00e3o de \ndados \n\nProcura por \npadr\u00f5es \n\nsignificativos \n\nPontos em \nespa\u00e7os \n\nmultidimensionais\n\n \n\nAgrupamentos \ncompactos e bem \n\ndistribu\u00eddos \nClassifica\u00e7\u00e3o de \n\ndocumentos \nProcura na \n\nInternet \nTexto Categorias sem\u00e2nticas \n\n(esporte, turismo, etc). \nInd\u00fastria Inspe\u00e7\u00e3o na \n\nplaca de \ncircuitos \n\nImagem de \nintensidade \n\nNatureza do produto: \ndefeituosa ou n\u00e3o \n\nRecupera\u00e7\u00e3o de \ndados \n\nProcura na \nInternet \n\nV\u00eddeo clipe G\u00eaneros de filmes (a\u00e7\u00e3o, \nsuspense). \n\nReconhecimento \nbiom\u00e9trico \n\nIdentifica\u00e7\u00e3o \npessoal \n\nFace, \u00edris, \nimpress\u00e3o digital.\n\n \n\nUsu\u00e1rios autorizados \npara uma \u00e1rea de acesso\n\n \n\nSensoriamento \nremoto \n\nPrever o \nrendimento da \n\ncolheita \n\nImagens \nmultiespectrais \n\nCategorias de uso da \nterra, padr\u00e3o de \ncrescimento das \n\ncolheitas. \n\n  \n\nA etapa de reconhecimento de padr\u00f5es \u00e9 ainda um grande problema \n\npara pesquisas realizadas nas \u00e1reas de Fotogrametria e de Vis\u00e3o Computacional \n\nporque as propostas tendem a se concentrar em uma tarefa espec\u00edfica ou s\u00e3o \n\ndif\u00edceis de serem usadas. Al\u00e9m disto, segundo Gonzales e Woods (2000), como este \n\nprocedimento \u00e9 muito complexo, h\u00e1 a necessidade de formular algumas restri\u00e7\u00f5es e \n\nidealiza\u00e7\u00f5es para reduzir a complexidade da tarefa a um n\u00edvel trat\u00e1vel. \n\nSegundo Jain et al (2000), as quatro melhores abordagens para o \n\nreconhecimento de padr\u00e3o s\u00e3o: correspond\u00eancia por padr\u00e3o, classifica\u00e7\u00e3o \n\nestat\u00edstica, correla\u00e7\u00e3o estrutural ou sint\u00e1tica e redes neurais.   \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n59\n\n \n4.1. Correspond\u00eancia por padr\u00e3o (Template matching)   \n\nSegundo Schenk (1999), o m\u00e9todo de correspond\u00eancia por padr\u00e3o \u00e9 \n\num m\u00e9todo baseado em \u00e1rea, que consiste em comparar a distribui\u00e7\u00e3o de n\u00edveis de \n\ncinza de uma matriz amostra (padr\u00e3o) com matrizes candidatas pertencentes a uma \n\nmatriz de busca, usando uma fun\u00e7\u00e3o de correla\u00e7\u00e3o adequada (Figura 11).             \n\nFIGURA 11  Pesquisa bidimensional de imagens correlatas. \n\n (Adaptado de ANDRADE, 1998).   \n\nNa Fotogrametria, n\u00e3o h\u00e1 m\u00e9todos de correla\u00e7\u00e3o que possam ser \n\nempregados para todas as aplica\u00e7\u00f5es. Portanto, algumas considera\u00e7\u00f5es a respeito \n\ndo ambiente s\u00e3o necess\u00e1rias: localiza\u00e7\u00e3o aproximada dos alvos; ilumina\u00e7\u00e3o; se os \n\nMatriz \ncandidata \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n60\n\n \nalvos encontram-se parcialmente oclusos; tempo de resposta; precis\u00e3o; acur\u00e1cia; \n\nconfiabilidade; deforma\u00e7\u00e3o geom\u00e9trica e radiom\u00e9trica; e, rota\u00e7\u00e3o dos alvos.  \n\nAl\u00e9m disso, alguns aspectos devem ser discutidos neste m\u00e9todo \n\ncomo (SCHENK, 1999): \n\n- Dimens\u00e3o do padr\u00e3o: padr\u00f5es com dimens\u00f5es maiores garantem \n\numa melhor correspond\u00eancia, por\u00e9m, aumentam o custo computacional; \n\n- Localiza\u00e7\u00e3o e dimens\u00e3o da janela de busca \n\n \n\no m\u00e9todo de \n\ncorrespond\u00eancia baseado em \u00e1rea garante boas aproxima\u00e7\u00f5es, e, portanto, \n\nm\u00e9todos de redu\u00e7\u00e3o do espa\u00e7o de busca devem ser usados.   \n\n4.1.1. Fun\u00e7\u00f5es b\u00e1sicas de correla\u00e7\u00e3o   \n\nSegundo Schenk (1999), as t\u00e9cnicas de correla\u00e7\u00e3o possuem uma \n\ngrande tradi\u00e7\u00e3o na determina\u00e7\u00e3o de pontos conjugados na Fotogrametria. A id\u00e9ia \n\nfundamental da t\u00e9cnica de correla\u00e7\u00e3o \u00e9 medir a similaridade entre o padr\u00e3o e a \n\njanela de busca, calculando o coeficiente de correla\u00e7\u00e3o. Este coeficiente de \n\ncorrela\u00e7\u00e3o \u00e9 determinado para cada matriz candidata, pertencente \u00e0 matriz de \n\nbusca, e, dependendo da fun\u00e7\u00e3o escolhida, determina-se a matriz hom\u00f3loga ao \n\npadr\u00e3o, a partir do ponto de m\u00e1ximo ou m\u00ednimo.      \n\nAs principais fun\u00e7\u00f5es para a determina\u00e7\u00e3o de correspond\u00eancia  por \n\ncorrela\u00e7\u00e3o s\u00e3o: fun\u00e7\u00e3o correla\u00e7\u00e3o, fun\u00e7\u00e3o covari\u00e2ncia cruzada, fun\u00e7\u00e3o erro, fun\u00e7\u00e3o \n\nerro modificada e fun\u00e7\u00e3o quociente.   \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n61\n\n \n4.1.1.1. Fun\u00e7\u00e3o covari\u00e2ncia cruzada   \n\nA melhor janela de correla\u00e7\u00e3o, nesta fun\u00e7\u00e3o, ocorre quando o \n\ncoeficiente de correla\u00e7\u00e3o a ser determinado \u00e9 m\u00e1ximo. A fun\u00e7\u00e3o covari\u00e2ncia cruzada \n\npode ser observada na Equa\u00e7\u00e3o 20.  \n\n1\n\n0\n\n1\n\n0\n\n,,\n1 y x\n\nr\n\ni\n\nr\n\nj\nbbrr\n\nyx\n\ngbjaiggjig\nrr\n\n                  (20)  \n\nOnde: \n\n \n\n- coeficiente de correla\u00e7\u00e3o; \n\nbr gg , \n\n \n\nn\u00edveis de cinza da janela de refer\u00eancia (matriz amostra) e da matriz \n\ncandidata, respectivamente; \n\nyx rr , \n\n \n\ndimens\u00f5es da janela de refer\u00eancia na coluna e na linha, respectivamente; \n\nji,\n\n \n\n \u00edndices dos pixels na janela de refer\u00eancia e na matriz candidata; \n\nba, \n\n \n\nvalores para mudan\u00e7as de posi\u00e7\u00e3o em linha e coluna na janela de busca \n\n(matriz de busca).    \n\nbr gg , - m\u00e9dias dos n\u00edveis de cinza da janela de refer\u00eancia e da matriz candidata.       \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n62\n\n \n4.1.1.2. Fun\u00e7\u00e3o covari\u00e2ncia cruzada modificada ou coeficiente de correla\u00e7\u00e3o \n\n  \nEsta fun\u00e7\u00e3o de correla\u00e7\u00e3o \u00e9 resultado da normaliza\u00e7\u00e3o da fun\u00e7\u00e3o \n\ncovari\u00e2ncia cruzada (Se\u00e7\u00e3o 4.1.1.1) (Equa\u00e7\u00e3o 21). O coeficiente de correla\u00e7\u00e3o, \n\nneste caso, varia de 1 a 1. O valor 1 para o coeficiente de correla\u00e7\u00e3o corresponde \n\na medida de similaridade m\u00e1xima, o valor 0 indica que n\u00e3o h\u00e1 correla\u00e7\u00e3o e o valor -1 \n\nindica correla\u00e7\u00e3o inversa (KRAUS, 1993)  \n\n22\n,,\n\n,,\n\nbbrr\n\nbbrr\n\nbr\n\nrb\n\ngbjaiggjig\n\ngbjaiggjig\n          (21)  \n\nOnde: \n\nRB\n\n \n\n covari\u00e2ncia entre a janela de refer\u00eancia e a matriz candidata; \n\nR\n\n  \n\ndesvio-padr\u00e3o da janela de refer\u00eancia; \n\nB\n\n \n\n- desvio-padr\u00e3o da matriz candidata.  \n\nO problema desta fun\u00e7\u00e3o \u00e9 quando o denominador for igual a zero, \n\nisto \u00e9, quando a janela de refer\u00eancia ou a matriz candidata forem homog\u00eaneas.   \n\nPara evitar estes casos, \u00e9 importante fazer uma pr\u00e9-an\u00e1lise da janela \n\nde refer\u00eancia (COSTA et al, 2003).      \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n63\n\n \n4.1.1.3. Fun\u00e7\u00e3o correla\u00e7\u00e3o cruzada   \n\nEsta fun\u00e7\u00e3o de correla\u00e7\u00e3o consiste no produto entre os tons de cinza \n\nda janela de refer\u00eancia e a matriz candidata. O maior valor do coeficiente de \n\ncorrela\u00e7\u00e3o corresponde a melhor correspond\u00eancia na matriz hom\u00f3loga.  \n\n1\n\n0\n\n1\n\n0\n\n,,\n1 y x\n\nr\n\ni\n\nr\n\nj\nbr\n\nyx\n\nbjaigjig\nrr\n\n                                    (22)   \n\n4.1.2. Correspond\u00eancia por m\u00ednimos quadrados   \n\nEste m\u00e9todo de correspond\u00eancia tem como objetivo procurar o menor \n\nvalor para o somat\u00f3rio dos quadrados das diferen\u00e7as entre os n\u00edveis de brilho entre \n\nambas as imagens, isto \u00e9, refinar a solu\u00e7\u00e3o de tal modo que m\u00ednimoe2 \n\n(ANDRADE, 1998 e ACKERMAN, 1984).  \n\nGruen (1996) detalha o m\u00e9todo de correla\u00e7\u00e3o por m\u00ednimos \n\nquadrados bidimensionalmente. Inicialmente, assume-se que a janela de refer\u00eancia \n\ne a janela de pesquisa s\u00e3o id\u00eanticas. Como as imagens s\u00e3o afetadas por ru\u00eddo, \n\ninsere-se uma fun\u00e7\u00e3o erro a uma das imagens (Equa\u00e7\u00e3o 23).  \n\n                     yxgyxeyxf ,,,                                          (23)  \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n64\n\n \nA Equa\u00e7\u00e3o 23 pode ser considerada como uma equa\u00e7\u00e3o que associa \n\no vetor das observa\u00e7\u00f5es yxf , com uma fun\u00e7\u00e3o yxg , , na qual a localiza\u00e7\u00e3o na \n\njanela de pesquisa em rela\u00e7\u00e3o a janela de refer\u00eancia necessita ser estimada. Esta \n\nlocaliza\u00e7\u00e3o \u00e9 descrita por par\u00e2metros de deslocamento yx, relacionados \u00e0 \n\nposi\u00e7\u00e3o inicial de yxg , . \n\nPara determina\u00e7\u00e3o de uma melhor correspond\u00eancia, par\u00e2metros \n\nrelacionados \u00e0 geometria e \u00e0 radiometria s\u00e3o inseridos. Primeiramente, a \n\ntransforma\u00e7\u00e3o geom\u00e9trica \u00e9 modelada pelo seguinte polin\u00f4mio:  \n\nx\nT\ny\n\nx\nT\ny\n\ntBty\n\ntAtx\n                                                      (24)  \n\nOnde: \n\nmmmm\n\nm\n\nmmmm\n\nm\n\nmT\ny\n\nmT\nx\n\nbbb\n\nb\n\nbbb\n\nB\n\naaa\n\na\n\naaa\n\nA\n\nyyyt\n\nxxxt\n\n21\n\n21\n\n11211\n\n21\n\n21\n\n11211\n\n1\n0\n\n2\n00\n\n1\n0\n\n2\n00\n\n,\n\n...\n\n...\n\n...1\n\n...1\n\n                                               (25)  \n\n00 , yx - posi\u00e7\u00f5es da malha regular dos pontos de yxg ,\n0 ; \n\nyxg ,0 - aproxima\u00e7\u00e3o inicial da posi\u00e7\u00e3o de yxg , .  \n\nSendo a Equa\u00e7\u00e3o 23 n\u00e3o linear, esta pode ser linearizada da forma \n\nexpressa na Equa\u00e7\u00e3o 26.  \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n65\n\n \ndy\n\ny\n\nyxg\ndx\n\nx\n\nyxg\nyxgyxeyxf\n\n,),(\n,,,\n\n00\n0                         (26) \n\n                                        i\ni\n\ndp\np\n\nx\ndx                i\n\ni\n\ndp\np\n\ny\ndy\n\n \n\nOnde: \n\nip - par\u00e2metros da transforma\u00e7\u00e3o que ser\u00e3o obtidos posteriormente; \n\nA partir de uma transforma\u00e7\u00e3o afim com as matrizes \n021\n\n1211\n\na\n\naa\nA e \n\n021\n\n1211\n\nb\n\nbb\nB  , tem-se: \n\n              02101211 yaxaax                                                 (27) \n\n                                      02101211 ybxbby\n\n  \n\nOnde: \n\n1111 , ba - equivale aos par\u00e2metros de transla\u00e7\u00e3o x, y.  \n\nRealizando uma diferencia\u00e7\u00e3o da Equa\u00e7\u00e3o 27, tem-se:  \n\n02101211 ydaxdadadx                                         (28) \n\n                                       02101211 ydbxdbdbdy\n\n  \n\nSimplificando a Equa\u00e7\u00e3o 28 e acrescentando os par\u00e2metros \n\nradiom\u00e9tricos sr (deslocamento - brilho) e er (escala - contraste), a Equa\u00e7\u00e3o 26 \n\nequivale a:  \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n66\n\n \nes\n\no\n\nryxgrdbgyy\n\ndbgyxgydbdagxydagxxgxdayxgyxeyxf\n\n,\n\n,,,\n0\n\n210\n\n1201121012011        (29)  \n\nOnde: \n\n                                         \nx\n\nyx\ngx\n\ng ,\n0\n\n           \ny\n\nyx\ngy\n\ng ,\n0  \n\nCombinando os par\u00e2metros da Equa\u00e7\u00e3o 29 no vetor X, tem-se:  \n\nes\nT rrdbdbdbdadadaX ,,,,,,, 211211211211\n\n  \n\nPara estimar estes par\u00e2metros pode ser usado o m\u00e9todo param\u00e9trico \n\n(GEMAEL, 1994) que \u00e9 adequado para modelos do tipo expl\u00edcito.  \n\n11 XaFLa un                                               (30)  \n\nOnde: \n\nLa  vetor dos valores observados ajustados; \n\nXa  \n\n \n\nvetor dos par\u00e2metros ajustados; \n\nn \n\n \n\nn\u00famero de observa\u00e7\u00f5es; \n\nu  n\u00famero de inc\u00f3gnitas.  \n\nSabendo que VLbLa\n\n \n\ne XXoXa , a equa\u00e7\u00e3o acima \n\nlinearizada pode ser descrita por: \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n67\n\n \nX\n\nXa\n\nF\nXoFXXoFVLb\n\nXoXa\n\n                         (31)  \n\nSendo XoFLo\n\n \n\ne \nXoXaXa\n\nF\nA , a Equa\u00e7\u00e3o 31 pode ser reescrita \n\ncomo:  \n\nAXLoVLb                                             (32)  \n\nConsiderando LbLoL , a equa\u00e7\u00e3o torna-se:  \n\n    111 LXAV nuunn                                               (33)  \n\nOnde:  \n\nV  vetor dos res\u00edduos; \n\nA  matriz das derivadas parciais; \n\nX  vetor das corre\u00e7\u00f5es aos par\u00e2metros; \n\nLo   vetor dos valores aproximados; \n\nLb   vetor dos valores observados.  \n\nO vetor dos par\u00e2metros ajustados \u00e9 determinado a partir de:  \n\n                         XXoXa                                                  (34) \n\n            \n\n                                \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n68\n\n \nOnde: \n\nPLAPAAX TT\n1\n\n; \n\nXo - vetor dos par\u00e2metros aproximados; \n\nP  matriz peso.  \n\nAp\u00f3s a estima\u00e7\u00e3o dos par\u00e2metros geom\u00e9tricos e radiom\u00e9tricos, uma \n\ntransforma\u00e7\u00e3o afim direta \u00e9 aplicada para determina\u00e7\u00e3o das coordenadas e a janela \n\nde pesquisa \u00e9 reamostrada usando o m\u00e9todo de interpola\u00e7\u00e3o bilinear para o c\u00e1lculo \n\ndos novos n\u00edveis de cinza. A itera\u00e7\u00e3o deste processo ocorre at\u00e9 que os valores \n\nabsolutos dos par\u00e2metros geom\u00e9tricos sejam menores que o crit\u00e9rio de \n\nconverg\u00eancia adotado (Equa\u00e7\u00e3o 35).   \n\n111 cda           312 cda           521 cda                               (35) \n\n                                    211 cdb           412 cdb           621 cdb\n\n  \n\nOnde: \n\n61, ici - crit\u00e9rios de converg\u00eancia.   \n\nOs crit\u00e9rios de converg\u00eancia escolhidos dependem da imagem \n\nutilizada. Para isto, antes de realizar todo o processo autom\u00e1tico, necessita realizar \n\num treinamento.  \n\nO conceito b\u00e1sico da interpola\u00e7\u00e3o bilinear \u00e9 realizar a interpola\u00e7\u00e3o \n\nlinear nas dire\u00e7\u00f5es das linhas e das colunas. O modelo matem\u00e1tico para a \n\ninterpola\u00e7\u00e3o bilinear (Equa\u00e7\u00e3o 36)  pode ser estabelecido com base na Figura 12. \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n69\n\n        \n\nFIGURA 12 - Representa\u00e7\u00e3o do pixel reamostrado.  \n\n1,1**1,*1*\n\n,1*1*,*1*1\n\njiNCdydxjiNCdxdy\n\njiNCdydxjiNCdydxNC\n\nII\n\nIIIR          (36)  \n\nOnde: \n\nIRNC - n\u00edvel de cinza da imagem reamostrada; \n\nINC - n\u00edvel de cinza da janela de pesquisa; \n\nji,\n\n \n\n coordenadas da janela de pesquisa.  \n\nA estima\u00e7\u00e3o do modelo matem\u00e1tico deve acomodar os par\u00e2metros \n\nsuficientes para realizar uma boa modelagem das distor\u00e7\u00f5es radiom\u00e9tricas e \n\ngeom\u00e9tricas para n\u00e3o ocorrer o problema de superparametriza\u00e7\u00e3o. Isto quer dizer \n\nque o modelo a ser escolhido deve conter apenas os par\u00e2metros que conseguir\u00e3o \n\nser determinados porque, caso contr\u00e1rio, estes dados trar\u00e3o um efeito negativo ao \n\nresultado, deteriorando a qualidade do mesmo. Testes podem ser realizados para \n\ndeterminar aqueles par\u00e2metros que s\u00e3o n\u00e3o-determin\u00e1veis. Isto pode ser realizado \n\ntrabalhando com vari\u00e1veis estoc\u00e1sticas, associando pesos que devem estar \n\ndy \n\ndx ),( jiNC IR\n\n)1,( jiNC I \n\n),( jiNCI \n\n)1,1( jiNC I \n\n),1( jiNC I\n\n \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n70\n\n \nrelacionados ao tamanho da distor\u00e7\u00e3o a ser esperada. Alguns alvos bin\u00e1rios no \n\nquais certos par\u00e2metros n\u00e3o podem ser determinados encontram-se na Figura 13.    \n\nFIGURA 13  Padr\u00f5es que reduzem a quantidade de par\u00e2metros a serem \n\ndeterminados pelo modelo matem\u00e1tico mencionado nesta se\u00e7\u00e3o. (a) escala em y; (b) \n\nrota\u00e7\u00e3o; (c) duas escalas; (d) todos na dire\u00e7\u00e3o y; (e) todos na dire\u00e7\u00e3o y e escala em \n\nx; (f) todos (Fonte: GRUEN, 1996).   \n\nO modelo matem\u00e1tico pode ser simplificado, considerando apenas \n\nos par\u00e2metros geom\u00e9tricos supondo-se que uma normaliza\u00e7\u00e3o geom\u00e9trica tenha \n\nsido realizada previamente.   \n\n4.2. Correspond\u00eancia por assinatura   \n\nSegundo Gonzales e Woods (2000), a defini\u00e7\u00e3o de assinatura \u00e9 uma \n\nrepresenta\u00e7\u00e3o funcional unidimensional de uma fronteira. H\u00e1 v\u00e1rias maneiras de se \n\ndeterminar a assinatura de um alvo. Uma das maneiras mais f\u00e1ceis de obt\u00ea-la \u00e9 a \n\npartir do gr\u00e1fico da dist\u00e2ncia do limite ao centr\u00f3ide em fun\u00e7\u00e3o do \u00e2ngulo. Esta \n\nassinatura \u00e9 invariante \u00e0 transla\u00e7\u00e3o, mas depende da rota\u00e7\u00e3o e mudan\u00e7a de escala. \n\nExemplos deste tipo de assinatura podem ser observados na Figura 14.   \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n71\n\n        \n\nFIGURA 14  Fronteiras e suas respectivas assinaturas.  \n\nSegundo Sonka et al (1998), a assinatura pode ser obtida como uma \n\nseq\u00fc\u00eancia da dist\u00e2ncia dos contornos normais. Esta dist\u00e2ncia \u00e9 calculada para cada \n\nelemento da fronteira como uma fun\u00e7\u00e3o da dist\u00e2ncia, isto \u00e9, para cada ponto \n\npertencente \u00e0 fronteira s\u00e3o tra\u00e7adas a sua tangente e a sua normal at\u00e9 que a normal \n\nintercepte o outro lado da fronteira. Como as assinaturas s\u00e3o sens\u00edveis a ru\u00eddos, \n\numa suaviza\u00e7\u00e3o na fronteira \u00e9 necess\u00e1ria para redu\u00e7\u00e3o destes. A forma de obter \n\nesta assinatura pode ser vista na Figura 15.        \n\nFIGURA 15  Assinatura: (a) Princ\u00edpio da constru\u00e7\u00e3o (b) Assinaturas para um c\u00edrculo e \n\num tri\u00e2ngulo.  (Fonte: Adaptado de SONKA et al, 1998).  \n\n \n\nA\n\n  \n\nA \n\n \n\n(a) (b) \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n72\n\n \nComo o m\u00e9todo da assinatura depende da rota\u00e7\u00e3o, uma \n\nnormaliza\u00e7\u00e3o \u00e9 realizada atrav\u00e9s do estabelecimento do ponto inicial para a gera\u00e7\u00e3o \n\nda assinatura. Uma das maneiras de determinar este ponto \u00e9 escolher o ponto com \n\nmaior dist\u00e2ncia ao centr\u00f3ide, caso o mesmo seja \u00fanico e independente de rota\u00e7\u00e3o \n\ndos objetos de interesse.  \n\nUm outro problema da assinatura est\u00e1 relacionado com a mudan\u00e7a \n\nde amplitude advinda dos diferentes tamanhos dos padr\u00f5es. Para resolver isto, uma \n\nmudan\u00e7a simples de escala de todas as fun\u00e7\u00f5es de maneira que as mesmas variem \n\ndentro do mesmo dom\u00ednio \u00e9 necess\u00e1ria. Este m\u00e9todo \u00e9 bem simples, por\u00e9m, tem a \n\ndesvantagem da fun\u00e7\u00e3o depender apenas de dois valores: o m\u00e1ximo e o m\u00ednimo. \n\nUma melhor abordagem consiste na divis\u00e3o da amostra pela vari\u00e2ncia, desde que a \n\nmesma seja diferente de zero. A id\u00e9ia, neste caso, \u00e9 remover a depend\u00eancia, \n\npreservando a forma fundamental da fun\u00e7\u00e3o. \n\n  \n\nPara verificar a similaridade entre duas assinaturas, v\u00e1rios crit\u00e9rios \n\npodem ser usados. Na Se\u00e7\u00e3o 4.2.1, observa-se alguns crit\u00e9rios para a determina\u00e7\u00e3o \n\nda discrep\u00e2ncia entre as assinaturas.   \n\n4.2.1. Determina\u00e7\u00e3o da discrep\u00e2ncia entre as assinaturas    \n\nSegundo Mustafa et al (1999), esta discrep\u00e2ncia pode ser \n\ndeterminada a partir do c\u00e1lculo de quatro erros m\u00e9tricos entre as assinaturas \n\narmazenada e gerada na cena. Estes erros s\u00e3o: \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n73\n\n \n- Erro de dist\u00e2ncia: mede a dist\u00e2ncia entre duas distribui\u00e7\u00f5es \n\nespaciais das assinaturas. Valores pr\u00f3ximos a zero indicam que as distribui\u00e7\u00f5es \n\npossuem o mesmo valor m\u00e9dio e s\u00e3o distribu\u00eddas ao redor dos mesmos pontos de \n\nfreq\u00fc\u00eancia. Os valores pr\u00f3ximos a unidade refere-se a distribui\u00e7\u00f5es ao redor de \n\ndiferentes freq\u00fc\u00eancias. Este erro \u00e9 calculado por:  \n\n         2121\n1\n\n,\nnc\n\nSS                                           (37)  \n\nOnde: \n\n21 , SS - assinaturas a serem comparadas; \n\ncn constante de normaliza\u00e7\u00e3o; \n\n21 ,\n\n \n\n- m\u00e9dias das assinaturas.   \n\nUm problema na determina\u00e7\u00e3o deste erro est\u00e1 relacionado \u00e0 \n\ndefini\u00e7\u00e3o da constante de normaliza\u00e7\u00e3o j\u00e1 que o processo \u00e9 autom\u00e1tico e esta \n\nconstante de normaliza\u00e7\u00e3o depende dos dados de entrada usados.  \n\n- Erro na forma: mede a diferen\u00e7a de vari\u00e2ncia entre as assinaturas. \n\nValores pr\u00f3ximos a zero indicam que as formas de ambas as assinaturas s\u00e3o \n\nsimilares. Este erro \u00e9 dado por:  \n\n21\n\n21\n\n21\n\n21\n\n00\n, SS                                  (38)   \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n74\n\n \nOnde: \n\n21 ,\n\n \n- desvios-padr\u00e3o da distribui\u00e7\u00e3o;  \n\n- Erro de dispers\u00e3o: mede a diferen\u00e7a de dispers\u00e3o da distribui\u00e7\u00e3o \n\nentre duas assinaturas em rela\u00e7\u00e3o \u00e0 m\u00e9dia. Valores pr\u00f3ximos a zero indicam que as \n\nassinaturas s\u00e3o similares. Este erro \u00e9 dado por:   \n\n2211\n\n2211\n2,1\n\n,,\n\n,,\n)(\n\nSS\n\nSS\nSS                                        (39)  \n\n      \nk\n\nk\nkSS ,   e    21\n\n2\n\n1\n\n  \n\n- Erro de correla\u00e7\u00e3o: mede a correla\u00e7\u00e3o entre as duas assinaturas. \n\nValores pr\u00f3ximos a zero indicam forte correla\u00e7\u00e3o e conseq\u00fcentemente grande \n\nsimilaridade. A f\u00f3rmula para determinar este erro \u00e9:  \n\n2\n22\n\n2\n11\n\n2211\n21 1,\n\nSS\n\nSS\nSS                                  (40)  \n\nO problema encontrado para determina\u00e7\u00e3o deste erro de correla\u00e7\u00e3o \n\nest\u00e1 relacionado \u00e0s duas assinaturas terem que possuir a mesma quantidade de \n\npixels no alvo. Por isso, h\u00e1 a necessidade de realizar uma amostragem dos dados.    \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n75\n\n \n4.3. Outras t\u00e9cnicas para o reconhecimento de padr\u00f5es   \n\nMayr e Poth (1995) utilizaram o processo de correla\u00e7\u00e3o bin\u00e1ria para \n\na identifica\u00e7\u00e3o de marcas fiduciais. Cada marca fiducial \u00e9 localizada \n\nindependentemente. A boa qualidade da solu\u00e7\u00e3o no n\u00edvel anterior da pir\u00e2mide de \n\nimagens reduz a janela de procura, aumentando a velocidade do processo. Esta \n\nt\u00e9cnica denominada de pir\u00e2mide de imagens consiste de um conjunto de imagens \n\nreamostradas da imagem original, cada uma com um grau de resolu\u00e7\u00e3o menor. A \n\nacur\u00e1cia final obtida est\u00e1 em torno de 0.1 pixel.  \n\nPicard (1997) apud Jain (2000) identificou uma aplica\u00e7\u00e3o moderna \n\nde reconhecimento de padr\u00e3o, chamada de computa\u00e7\u00e3o afetiva que dar\u00e1 ao \n\ncomputador a habilidade de reconhecer e de expressar emo\u00e7\u00f5es, responder \n\ninteligentemente a emo\u00e7\u00e3o humana e empregar mecanismos de emo\u00e7\u00e3o nas \n\ndecis\u00f5es racionais.  \n\nDrewniok e Rohr (1997) desenvolveram uma abordagem autom\u00e1tica \n\npara orienta\u00e7\u00e3o exterior de imagens a\u00e9reas baseada no ajustamento anal\u00edtico de \n\nmodelos \u00e0 imagem. Esta t\u00e9cnica \u00e9 denominada ajustamento por modelo e possui \n\ncomo objetivo a detec\u00e7\u00e3o e localiza\u00e7\u00e3o das marcas artificiais (pontos pr\u00e9-\n\nsinalizados) ou naturais (pontos de controle). A utiliza\u00e7\u00e3o destes modelos \u00e9 \n\nrecomendada quando se deseja alta acur\u00e1cia no momento da localiza\u00e7\u00e3o e quando \n\nse tem uma alta variabilidade estrutural. \n\nMustafa et al (1999) descrevem um sistema para identifica\u00e7\u00e3o do \n\nobjeto. Dado um conjunto de objetos 3D e uma cena contendo um ou mais destes \n\nobjetos, o sistema identifica quais os objetos que aparecem na cena atrav\u00e9s do \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n76\n\n \nm\u00e9todo de assinatura. Neste trabalho, dois tipos de assinaturas s\u00e3o utilizados: \n\ncurvatura e espectral. Para testar a discrep\u00e2ncia entre duas assinaturas, quatro \n\nerros m\u00e9tricos s\u00e3o usados: erro de dist\u00e2ncia, erro na forma, erro de dispers\u00e3o e erro \n\nde correla\u00e7\u00e3o. Este sistema testou 95 objetos e conseguiu bons resultados em \n\naproximadamente 77 objetos.    \n\nHoward e Padgett\n\n \n\n(1999) implementaram um programa para o \n\nreconhecimento de padr\u00f5es em imagens de sat\u00e9lite em tempo real usando redes \n\nneurais. Primeiramente, realizou-se a segmenta\u00e7\u00e3o da imagem para separar os \n\ndiferentes tipos de alvos existentes nas imagens a partir de um agrupamento \n\n(clustering). Os alvos obtidos deste agrupamento foram treinados a partir de um \n\nclassificador de redes neurais para validar ou n\u00e3o se o alvo extra\u00eddo cont\u00e9m um dos \n\nalvos agrupados anteriormente. Valores acima de um limiar escolhido dependendo \n\nda imagem que se est\u00e1 trabalhando s\u00e3o considerados como objeto e os menores, \n\ncomo fundo. Testes realizados mostraram que o algoritmo conseguiu detectar 99% \n\ndos alvos quando usou imagens hiper-espectrais. Os problemas encontrados nas \n\nredes neurais para o reconhecimento de padr\u00f5es est\u00e3o relacionados \u00e0 demora do \n\nprocesso referente ao treinamento e aos valores de pesos a serem estipulados no \n\nin\u00edcio dos processos intermedi\u00e1rios. Al\u00e9m disto, os processos intermedi\u00e1rios n\u00e3o s\u00e3o \n\ntransparentes e nem de entendimento f\u00e1cil, atrapalhando o desenvolvimento. \n\nTing e Leung (1999) propuseram uma t\u00e9cnica baseada na descri\u00e7\u00e3o \n\nde estruturas lineares usando um conjunto de caracteres. Linhas, textos e espa\u00e7os \n\ns\u00e3o convertidos em representa\u00e7\u00f5es lineares. O documento \u00e9 lido da esquerda para \n\ndireita e de cima para baixo. A cada objeto encontrado, especifica-se o seu tipo, isto \n\n\u00e9, linha vertical, linha horizontal, caixa de texto ou espa\u00e7o em branco. Conhecendo o \n\nseu tipo, um conjunto de caracteres \u00e9 criado com todos os objetos do documento. \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n77\n\n \nPara saber se este documento \u00e9 id\u00eantico a outro, compara-se o conjunto de \n\ncaracteres de ambos os documentos. O uso desta t\u00e9cnica permite uma medida \n\nr\u00e1pida e robusta de similaridade entre dois documentos. Al\u00e9m disto, este processo \n\nde descri\u00e7\u00e3o de conjunto de caracteres\n\n \n\npermite uma toler\u00e2ncia significativa em \n\nrela\u00e7\u00e3o \u00e0s inconsist\u00eancias da segmenta\u00e7\u00e3o. Testes realizados mostraram boas \n\nsolu\u00e7\u00f5es. Por\u00e9m, esta t\u00e9cnica depende das primitivas usadas para determinar o \n\nconjunto de caracteres. Quanto maior o n\u00famero de primitivas, melhor o resultado a \n\nser encontrado, por\u00e9m, maior o custo computacional. Al\u00e9m disso, outros problemas \n\ndificultam este reconhecimento de padr\u00f5es: distor\u00e7\u00f5es do documento e s\u00edmbolos \n\nincompletos. \n\nHattori et al (2000) realizaram medidas simuladas de uma geladeira \n\ndom\u00e9stica com um desenho especial para os alvos codificados (Figura 16). Pela \n\ndificuldade em encontrar os alvos devido \u00e0s diferen\u00e7as de profundidade, estes \n\nnecessitam ser selecionado no pr\u00e9-processamento. Os alvos devem ser bem \n\ndistribu\u00eddos para facilitar na sua medi\u00e7\u00e3o.  \n\nO padr\u00e3o do desenho \u00e9 feito de um material circular refletivo que \u00e9 \n\nfixado no objeto. O tamanho do alvo \u00e9 ajustado para que um pequeno c\u00edrculo na \n\nimagem tenha aproximadamente 3 pixels. A codifica\u00e7\u00e3o \u00e9 realizada a partir dos bits \n\nassociados ao c\u00edrculo. \n\nPrimeiramente, um n\u00famero pequeno de alvos codificados foi \n\nidentificado para obter os par\u00e2metros de orienta\u00e7\u00e3o, enquanto, os alvos medidos \n\nforam identificados pela intersec\u00e7\u00e3o de m\u00faltiplos raios.  \n\nEste processo conseguiu reconhecer 97% dos alvos das imagens \n\npor uma simples binariza\u00e7\u00e3o de imagens.  \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n78\n\n         \n\nFIGURA 16  Alvo codificado (Fonte: HATTORI et al, 2000).   \n\n14 mm\n\n \n\n2 mm\n\n \n\n30 mm 24 mm \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n79\n\n \nCAP\u00cdTULO V  \n\n5. MATERIAIS E M\u00c9TODOS  \n\n5.1. Materiais    \n\nNesta se\u00e7\u00e3o est\u00e3o listados os equipamentos e programas \n\ncomputacionais que foram usados para a realiza\u00e7\u00e3o deste trabalho de pesquisa:    \n\n- Uma c\u00e2mara digital KODAK DX 3500; \n\n- Um computador AMD Athlon XP 2200+, 80 GB de disco r\u00edgido e \n\n256 MB de mem\u00f3ria RAM; \n\n- Um projetor de padr\u00f5es composto por: \n\ni. Sistema de lentes; \n\nii. Suporte para fixa\u00e7\u00e3o dos fotolitos a serem projetados; \n\niii. Sistema de ilumina\u00e7\u00e3o; \n\niv. Condensador interno e flash; \n\nv. Suporte para acoplar a c\u00e2mara digital. \n\n- Compilador Borland C/C++ Builder 5.0; \n\n- Software Microstation Bentley. \n\n- Microsoft Office 2000 Standard; \n\n- Software Paint Shop Pro 4.0. \n\n- Software Surfer 7.0 Demo. \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n80\n\n \n5.2. M\u00e9todos  \n\nPara compreens\u00e3o dos processos envolvidos para a classifica\u00e7\u00e3o e \n\na localiza\u00e7\u00e3o precisa dos alvos, um fluxograma \u00e9 apresentado na Figura 17.                        \n\nFIGURA 17  Seq\u00fc\u00eancia das opera\u00e7\u00f5es e  processamentos realizados.  \n\nProje\u00e7\u00e3o de padr\u00f5es \n\nColeta de imagem \n\nLimiariza\u00e7\u00e3o local \n\nSegmenta\u00e7\u00e3o \n\nAn\u00e1lise dos resultados \n\nLocaliza\u00e7\u00e3o precisa por \nm\u00ednimos quadrados \n\nLocaliza\u00e7\u00e3o precisa por \ndetec\u00e7\u00e3o de cantos \n\nClassifica\u00e7\u00e3o dos \nalvos \n\nExtra\u00e7\u00e3o de \nfronteiras \n\nC\u00e1lculo da altura e da \nlargura do alvo \n\nsegmentado \n\nReamostragem do \npadr\u00e3o  \n\nUtiliza\u00e7\u00e3o de alvos \npr\u00e9-definidos \nsuavizados \n\nReconhecimento por \nassinatura  \n\nUtiliza\u00e7\u00e3o de alvos \nbin\u00e1rios pr\u00e9-\n\ndefinidos \n\nDetermina\u00e7\u00e3o do \ncoeficiente de correla\u00e7\u00e3o \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n81\n\n \n5.2.1. Gera\u00e7\u00e3o de padr\u00f5es   \n\nNo m\u00e9todo de reconhecimento de padr\u00f5es a ser usado, cada padr\u00e3o \n\nnecessita ser classificado unicamente, pois a cada um est\u00e3o associados os \n\npar\u00e2metros de seu vetor diretor para determina\u00e7\u00e3o das coordenadas 3D.  \n\nEstudos anteriores utilizaram padr\u00f5es projetados com luz branca sob \n\nformas circulares e padr\u00f5es baseados em uma combina\u00e7\u00e3o de formas e cores. \n\nApesar das formas circulares serem de f\u00e1cil identifica\u00e7\u00e3o autom\u00e1tica, estas se \n\nmostraram inadequadas quando alguns padr\u00f5es eram oclusos, isto pois inviabilizava \n\na an\u00e1lise de vizinhan\u00e7a.  \n\nA utiliza\u00e7\u00e3o de padr\u00f5es com diferentes formas e cores possibilita a \n\nidentifica\u00e7\u00e3o autom\u00e1tica de alguns casos de oclus\u00e3o, por\u00e9m, as cores dos padr\u00f5es \n\nprojetados podem coincidir com a superf\u00edcie dos objetos, acarretando em erros na \n\nsegmenta\u00e7\u00e3o de alvos. \n\nObservando estes problemas, chegou-se a v\u00e1rias possibilidades de \n\nabordagens, sendo a mais adequada, a utiliza\u00e7\u00e3o de padr\u00f5es de luz branca com \n\nformas espec\u00edficas. Entretanto, haveria a necessidade de alguma t\u00e9cnica para que \n\nestes padr\u00f5es pudessem ser reconhecidos univocamente em rela\u00e7\u00e3o aos demais. \n\nUma solu\u00e7\u00e3o seria a utiliza\u00e7\u00e3o de padr\u00f5es com formas diferentes umas das outras. \n\nEsta solu\u00e7\u00e3o seria impratic\u00e1vel, pois haveria a necessidade de muitas formas para \n\ncompor todos os padr\u00f5es e de um banco de dados relativamente grande para \n\narmazenar cada uma das caracter\u00edsticas dos padr\u00f5es pr\u00e9-definidos. Isto traria um \n\naumento do custo computacional para a identifica\u00e7\u00e3o de cada padr\u00e3o e aumentaria \n\na possibilidade de redund\u00e2ncia no reconhecimento.  \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n82\n\n \nA solu\u00e7\u00e3o mais vi\u00e1vel foi utilizar um conjunto pequeno de formas e \n\nconcili\u00e1-las com uma an\u00e1lise de vizinhan\u00e7a. Al\u00e9m disto, procurou-se gerar padr\u00f5es \n\nde forma a privilegiar a exist\u00eancias de quinas, que poderiam ser usados como \n\npontos para localiza\u00e7\u00e3o precisa. Os padr\u00f5es escolhidos s\u00e3o mostrados na Figura 18.     \n\nFIGURA 18 - Padr\u00f5es primitivos.  \n\nCom estas cinco formas \u00e9 poss\u00edvel classificar cada padr\u00e3o dentro, \n\nnaturalmente, de cinco classes, que ser\u00e3o rotuladas pelas letras: A, B, C, D e E, \n\ncujas rela\u00e7\u00f5es entre forma e r\u00f3tulo s\u00e3o mostradas na Figura 18. Como a forma do \n\npadr\u00e3o representado pela letra A \u00e9 a que possui maior facilidade de ser detectada, \n\ndentre as demais formas, usando o m\u00e9todo de correla\u00e7\u00e3o de imagens, este padr\u00e3o \n\nfoi assumido como piv\u00f4 de uma estrutura bidimensional de vizinhan\u00e7a oito (Figura \n\n19). Al\u00e9m disto, a gera\u00e7\u00e3o dos padr\u00f5es seguiu algumas restri\u00e7\u00f5es:  \n\n- Padr\u00f5es do tipo A n\u00e3o possuem outro A como vizinho; \n\n- Assumindo-se que uma m\u00e1scara de padr\u00f5es \u00e9 formada por nove \n\nelementos em uma matriz 3x3 com um padr\u00e3o A como piv\u00f4, n\u00e3o h\u00e1 outra m\u00e1scara \n\nde padr\u00f5es semelhante dentro de um raio de quatro piv\u00f4s A, isto \u00e9, dentro deste \n\nraio, somente a metade dos padr\u00f5es \u00e9 id\u00eantica. \n\nPadr\u00e3o B Padr\u00e3o A Padr\u00e3o C Padr\u00e3o D Padr\u00e3o E \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n83\n\n  \n\nFIGURA 19  Vizinhan\u00e7a dos padr\u00f5es.   \n\nApenas com o intuito de facilitar na leitura, decidiu-se nomear os \n\nprot\u00f3tipos primitivos por padr\u00f5es e os prot\u00f3tipos projetados como alvos.   \n\n5.2.2. Coleta de dados   \n\nA coleta de dados \u00e9 realizada a partir de um sistema baseado no \n\nprinc\u00edpio de luz estruturada. Este sistema \u00e9 composto por um sistema projetor de \n\npadr\u00f5es de luz estruturada e um sensor (uma c\u00e2mara digital de pequeno formato e \n\nde foco fixo) (Figura 20).        \n\nPiv\u00f4 \n\n \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n84\n\n         \n\nFIGURA 20 - Sistema sensor e projetor.  \n\nA c\u00e2mara usada para a constru\u00e7\u00e3o deste prot\u00f3tipo com o sistema de \n\nluz estruturada foi a KODAK DX 3500 que possui uma dist\u00e2ncia focal nominal de 38 \n\nmm, resolu\u00e7\u00e3o m\u00e1xima de 1800 x 1200 pixels e tamanho do pixel de 19,44 m \n\nconsiderando um tamanho te\u00f3rico do sensor de 35 mm. As vantagens desta c\u00e2mara \n\ns\u00e3o: foco fixo e disparo de um \u00fanico flash por imagem.  \n\nEsta c\u00e2mara foi calibrada por meio de um processo de calibra\u00e7\u00e3o \n\npor feixe de raios (bundle method) usando o programa CC (GALO, 1993). Neste \n\nprocesso, apenas os quatro par\u00e2metros mais significativos foram considerados: \n\ndist\u00e2ncia focal, ponto principal ( 00 , yx ) e o primeiro par\u00e2metro de distor\u00e7\u00e3o radial \n\nsim\u00e9trica 1K . A quantidade de pontos de apoio, de fotocoordenadas e de imagens \n\nusada para a calibra\u00e7\u00e3o da c\u00e2mara foi de 28, 80 e 6, respectivamente. Os \n\nresultantes s\u00e3o mostrados na Tabela 4. Maiores informa\u00e7\u00f5es a respeito da \n\ncalibra\u00e7\u00e3o podem ser encontradas em Reiss e Tommaselli (2004).    \n\nControle do flash \ne bateria \n\nEspelho \n\nC\u00e2mara digital e \nfotoc\u00e9lula \n\nFotolito \nremov\u00edvel \n\nLentes \n\nCondensador interno \ne luz do flash \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n85\n\n \nTABELA 4 - Par\u00e2metros de orienta\u00e7\u00e3o interior calibrados. \n\n(REISS e TOMMASELLI, 2004). \n\nPar\u00e2metros Valores estimados Desvios-padr\u00e3o estimados \n\nf (mm) 38,329 0,012 \n\nx0 (mm) -0,297 0,008 \n\ny0 (mm) -0,226 0,013 \n\nK1 (mm) -0,000102184 0,3984 x 10\n-6 \n\n  \n\nO projetor de padr\u00f5es \u00e9 composto de fotoc\u00e9lula, condensador \n\ninterno, placa com os padr\u00f5es, bateria, lentes e espelho (Figura 20). O fotolito foi \n\nimpresso usando um processo fotogr\u00e1fico e encontra-se entre duas placas de vidro \n\nplanas, usadas para absorver parte do calor gerado pela l\u00e2mpada. O controlador do \n\nflash assegura a sincroniza\u00e7\u00e3o entre o instante de aquisi\u00e7\u00e3o da imagem pela c\u00e2mara \n\ne a ilumina\u00e7\u00e3o da cena pelo projetor. Este tipo de ilumina\u00e7\u00e3o instant\u00e2nea evita o \n\naquecimento do projetor e a deforma\u00e7\u00e3o do padr\u00e3o reproduzido no material \n\nfotogr\u00e1fico. A calibra\u00e7\u00e3o do projetor foi realizada por Reiss e Tommaselli (2004).   \n\n5.2.3. Limiariza\u00e7\u00e3o local   \n\nDevido \u00e0 lei de ilumin\u00e2ncia, a luz que atinge os cantos da imagem \u00e9 \n\natenuada por um fator de cos4 , onde  \u00e9 o \u00e2ngulo entre o eixo \u00f3ptico da c\u00e2mara e o \n\nponto em an\u00e1lise. Com isto a \u00e1rea central da imagem \u00e9 mais iluminada que a \n\nperiferia, gerando um efeito semelhante ao de vinhete, embora devido a causas \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n86\n\n \ndiferentes. Para reduzir este efeito, realizou-se uma etapa pr\u00e9via de limiariza\u00e7\u00e3o \n\nlocal, para separar o fundo do sinal gerado pelos alvos projetados. \n\nO m\u00e9todo usado foi o de limiariza\u00e7\u00e3o local (Se\u00e7\u00e3o 2.7.3) porque se \n\nverificou experimentalmente a necessidade de definir diferentes limiares para cada \n\nregi\u00e3o da imagem.  \n\nInicialmente, foi considerada a hip\u00f3tese de definir um valor de limiar \n\npara cada pixel da imagem (calculado a partir de uma pequena regi\u00e3o em torno do \n\npixel). Por\u00e9m, devido ao grande volume de processamento que isto implicaria, uma \n\nnova estrat\u00e9gia foi desenvolvida e, resolveu-se implementar uma variante da \n\nlimiariza\u00e7\u00e3o pelos m\u00e9todos de Otsu e de Pun. Neste caso, o limiar \u00e9 calculado a \n\npartir de uma subimagem 3w x 3w e aplicado em uma janela w x w (Figura 21). \n\nMaiores informa\u00e7\u00f5es podem ser encontradas em ARTERO (1999). Isto permite uma \n\ntransi\u00e7\u00e3o suave de uma janela para outra, evitando o efeito de ladrilho na imagem \n\nlimiarizada. Pixels com n\u00edveis de cinza inferiores ao limiar recebem zero enquanto os \n\noutros pixels permanecem com o n\u00edvel de cinza original. \n\nO processo desenvolvido \u00e9 uma variante do m\u00e9todo original, porque \n\na imagem n\u00e3o \u00e9 binarizada.  \n\nFIGURA 21 \n\n \n\nConfigura\u00e7\u00e3o da janela do limiar local.  \n\nw\n\nw\n\n3w\n\n3w R2\n\nR1\n\n\n\n  \n\nChristiane N. C. Kokubum \n\n87\n\n \n5.2.4. Segmenta\u00e7\u00e3o   \n\nA segmenta\u00e7\u00e3o dos alvos na imagem \u00e9 feita usando o m\u00e9todo de \n\ncrescimento de regi\u00f5es.  Esta t\u00e9cnica consiste no agrupamento e na rotula\u00e7\u00e3o de \n\ntodos os pixels de cada padr\u00e3o. Isto \u00e9 feito percorrendo toda a imagem at\u00e9 encontrar \n\num pixel que possua um limiar maior que um limiar global determinado. Este pixel \u00e9 \n\ndenominado de pixel semente e \u00e9 rotulado. A partir deste pixel semente, com \n\ncoordenadas (i, j), observam-se os pixels vizinhos: frente (i, j+1), abaixo (i+1, j) e \n\natr\u00e1s (i, j-1). Caso o n\u00edvel de cinza de um destes pixels seja maior que o limiar global \n\ndeterminado, ele \u00e9 agrupado ao pixel semente e rotulado. A segmenta\u00e7\u00e3o do padr\u00e3o \n\nfinaliza quando os n\u00edveis de cinza dos pixels vizinhos forem menor que o limiar. \n\nFinalizada a segmenta\u00e7\u00e3o do alvo, reinicia-se a varredura a partir do pixel semente \n\ndo padr\u00e3o segmentado anteriormente. Alvos pertencentes ao fundo recebem r\u00f3tulo \n\n1, zero indica que o pixel n\u00e3o foi rotulado e os padr\u00f5es segmentados recebem \n\nr\u00f3tulos de 2 at\u00e9 o n\u00famero de alvos segmentados. Este procedimento \u00e9 realizado at\u00e9 \n\nque todos os pixels da imagem tenham sido rotulados. As informa\u00e7\u00f5es geradas \n\nneste procedimento s\u00e3o: centro de massa de cada alvo segmentado; n\u00famero do \n\nr\u00f3tulo e coordenadas de todos os pixels pertencentes ao alvo; e, os valores m\u00e1ximos \n\ne m\u00ednimos para cada padr\u00e3o para a determina\u00e7\u00e3o da altura e da largura do alvo para \n\nposterior reamostragem. O centro de massa \u00e9 determinado a partir de uma m\u00e9dia \n\nponderada das discrep\u00e2ncias entre os n\u00edveis de cinza dos pixels segmentados e o \n\nlimiar global determinado. Um fluxograma da etapa de segmenta\u00e7\u00e3o de padr\u00f5es \n\npode ser observado na Figura 22.  \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n88\n\n \nEsta etapa de segmenta\u00e7\u00e3o de padr\u00f5es faz-se necess\u00e1ria para \n\ndiminuir o n\u00famero de m\u00e1scaras a serem comparadas nos m\u00e9todos de detec\u00e7\u00e3o de \n\nalvos por correspond\u00eancia por padr\u00e3o\n\n \ne assinatura. Isto torna menor o custo \n\ncomputacional porque este procedimento evita a busca de v\u00e1rios padr\u00f5es por toda a \n\nimagem, procedimento que \u00e9 pouco confi\u00e1vel, devido \u00e0s v\u00e1rias respostas diferentes \n\npara o mesmo tipo de alvo.    \n\n5.2.5 Classifica\u00e7\u00e3o   \n\nA etapa de classifica\u00e7\u00e3o de padr\u00f5es \u00e9 fundamental porque \u00e9 nesta \n\netapa que os alvos s\u00e3o identificados e s\u00e3o definidos os valores aproximados para a \n\nlocaliza\u00e7\u00e3o precisa. Esta classifica\u00e7\u00e3o visa atribuir a cada alvo segmentado, \n\nbaseado nas suas caracter\u00edsticas de forma, a qual classe de padr\u00f5es ele tem maior \n\nprobabilidade de pertencer, dentro das cinco classes pr\u00e9-definidas (Figura 18). \n\nPara a etapa de classifica\u00e7\u00e3o, dois m\u00e9todos foram implementados e \n\ncomparados neste trabalho: correspond\u00eancia por \u00e1rea usando as fun\u00e7\u00f5es de \n\ncorrela\u00e7\u00e3o e o m\u00e9todo de assinatura.        \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n89\n\n                                        \n\nFIGURA 22  Fluxograma do algoritmo de segmenta\u00e7\u00e3o de padr\u00f5es.   \n\nVarredura na imagem \n\nPixel \u00e9 rotulado \ncomo 1 S \n\nN \n\nPixel atual (i, j) \u00e9 rotulado. \n\nPixel recebe o mesmo  \nr\u00f3tulo que o pixel \n\nsemente \n\nS \n\nN N \n\nS \n\nS \n\nPixel recebe o mesmo  \nr\u00f3tulo que o pixel \n\nsemente \n\nPixel recebe o mesmo  \nr\u00f3tulo que o pixel \n\nsemente \n\nFim da \nsegmenta\u00e7\u00e3o do \n\nalvo \n\n \nReinicia a varredura \nno pixel semente do \n\nalvo segmentado \nanteriormente\n\n \n\nSe o NC(i, j) > \nlimiar\n\n \n\nS \n\nSe NC(i, j+1) > \nlimiar\n\n \n\nSe NC(i, j-1) > \nlimiar \n\nSe NC(i+1, j) > \nlimiar \n\nN \n\nRealiza-se o \nincremento dos \u00edndices\n\n \n\nPixel atual \u00e9 considerado pixel \nsemente e \u00e9 rotulado.\n\n \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n90\n\n \n5.2.5.1 Correla\u00e7\u00e3o   \n\nNesta etapa de classifica\u00e7\u00e3o, tr\u00eas metodologias foram avaliadas: \n\ncompara\u00e7\u00e3o dos alvos segmentados com os padr\u00f5es pr\u00e9-definidos e com as suas \n\ninst\u00e2ncias (c\u00f3pia de um objeto com altera\u00e7\u00f5es em escala ou rota\u00e7\u00e3o) armazenadas, \n\ncompara\u00e7\u00e3o dos alvos segmentados com os padr\u00f5es pr\u00e9-definidos suavizados e \n\ncom as suas inst\u00e2ncias armazenadas suavizadas, compara\u00e7\u00e3o dos alvos \n\nsegmentados com os padr\u00f5es pr\u00e9-definidos reamostrados.   \n\n- 1\u00aa Metodologia: Compara\u00e7\u00e3o dos alvos segmentados com os padr\u00f5es pr\u00e9-\n\ndefinidos e as suas inst\u00e2ncias armazenadas (imagens bin\u00e1rias).  \n\nNeste caso, 45 padr\u00f5es s\u00e3o armazenados para posterior \n\ncompara\u00e7\u00e3o (Tabela 5). Estes padr\u00f5es variam em rela\u00e7\u00e3o \u00e0 escala. Esta escala foi \n\nescolhida a partir de visualiza\u00e7\u00f5es realizadas na imagem original.   \n\nTABELA 5 - Padr\u00f5es pr\u00e9-definidos e as suas inst\u00e2ncias armazenadas. \n\n               Padr\u00e3o \n\nTamanho \n\n(pixels) \n\nA B C D E \n\n11 x 11 \n\n     \n\n13 x 13 \n\n     \n\n15 x 15 \n\n     \n\n17 x 17 \n\n     \n\n19 x 19 \n\n     \n\n13 x 15 \n\n     \n\n15 x 13 \n\n     \n\n15 x 17 \n\n     \n\n17 x 15 \n\n      \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n91\n\n \n- 2\u00aa Metodologia: Compara\u00e7\u00e3o dos alvos segmentados com os padr\u00f5es pr\u00e9-\n\ndefinidos e as suas inst\u00e2ncias armazenadas suavizadas.  \n\nNeste caso, os mesmos 45 padr\u00f5es s\u00e3o armazenados para posterior \n\ncompara\u00e7\u00e3o. Por\u00e9m estes padr\u00f5es sofreram uma suaviza\u00e7\u00e3o pela m\u00e9dia antes da \n\ncompara\u00e7\u00e3o com os alvos segmentados.  \n\nOs inconvenientes das duas metodologias anteriores est\u00e3o \n\nrelacionados ao n\u00famero de padr\u00f5es e inst\u00e2ncias a serem armazenados e que s\u00e3o \n\nnecess\u00e1rios para obter a melhor correspond\u00eancia e os melhores valores \n\naproximados para a determina\u00e7\u00e3o  das coordenadas subpixel.     \n\n- 3\u00aa Metodologia: Compara\u00e7\u00e3o dos alvos segmentados com os padr\u00f5es pr\u00e9-\n\ndefinidos reamostrados.  \n\nEste m\u00e9todo consiste em armazenar apenas 5 padr\u00f5es e reamostr\u00e1-\n\nlos de acordo com a dimens\u00e3o do alvo segmentado. A dimens\u00e3o do alvo \n\nsegmentado \u00e9 obtida a partir das discrep\u00e2ncias entre as coordenadas m\u00e1ximas e \n\nm\u00ednimas em x e y. Com estas coordenadas, determina-se a altura e a largura do alvo \n\nsegmentado. Com a dimens\u00e3o do alvo, reamostra os padr\u00f5es pr\u00e9-definidos que \n\npossuem uma dimens\u00e3o superior aos alvos segmentados. Este procedimento pode \n\nser usado porque as imagens sofrem uma pequena rota\u00e7\u00e3o que pode ser \n\ndesconsiderada. As vantagens deste m\u00e9todo em rela\u00e7\u00e3o aos dois primeiros est\u00e3o \n\nrelacionadas ao n\u00famero de padr\u00f5es armazenados e a melhor determina\u00e7\u00e3o das \n\ncoordenadas aproximadas para a localiza\u00e7\u00e3o precisa. \n\nOs resultados destes experimentos s\u00e3o mostrados na Se\u00e7\u00e3o 6.4.1 \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n92\n\n \n5.2.5.2 Assinatura   \n\nA outra t\u00e9cnica de classifica\u00e7\u00e3o a ser usada \u00e9 a de assinatura. Esta \n\nt\u00e9cnica consiste na compara\u00e7\u00e3o entre as assinaturas dos alvos armazenados e \n\nsegmentados.  \n\nAs etapas necess\u00e1rias para a classifica\u00e7\u00e3o, usando o m\u00e9todo de \n\nassinatura s\u00e3o: \n\n- Extra\u00e7\u00e3o da fronteira do alvo pelo m\u00e9todo de persegui\u00e7\u00e3o de \n\nfronteiras. Este m\u00e9todo consiste em obter as coordenadas de todos \n\nos pixels localizados na fronteira do alvo. Nesta etapa, observa-se a \n\nlista de alvos gerada na segmenta\u00e7\u00e3o de imagens. Se o r\u00f3tulo \n\narmazenado na lista for diferente de um (o que significa que o pixel \n\npertence ao fundo), armazenam-se as coordenadas do pixel e o \n\nn\u00famero do seu r\u00f3tulo em uma outra estrutura de lista. A partir do \n\nprimeiro pixel, observam-se os seus pixels vizinhos na seguinte \n\nordem: frente, abaixo e atr\u00e1s. Este procedimento ocorre at\u00e9 que \n\ntodos os alvos segmentados sejam percorridos. Pixels que n\u00e3o \n\npertencem \u00e0 fronteira s\u00e3o rotulados como 1, representando fundo. \n\n- Determina\u00e7\u00e3o do ponto inicial: O problema em determinar o ponto \n\ninicial est\u00e1 relacionado com padr\u00f5es de formas id\u00eanticas que variam \n\nem rela\u00e7\u00e3o \u00e0 rota\u00e7\u00e3o. Como este ponto \u00e9 determinado pela maior \n\ndist\u00e2ncia do centr\u00f3ide ao ponto pertencente \u00e0 fronteira, algumas \n\nassinaturas geradas s\u00e3o id\u00eanticas. Isto pode ser observado na Figura \n\n23 em que os padr\u00f5es B e E e C e D geram as mesmas assinaturas. \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n93\n\n \nA t\u00e9cnica utilizada, portanto, \u00e9 determinar o ponto que possui o \n\nmenor valor no eixo das abscissas e a partir deste procurar o menor \n\nvalor no eixo das ordenadas. Os pontos iniciais de cada alvo podem \n\nser observados na Figura 24.           \n\nFIGURA 23 - Padr\u00e3o com diferentes rota\u00e7\u00f5es e id\u00eanticas assinaturas.   \n\nFIGURA 24  Pontos iniciais dos padr\u00f5es utilizados. \n\n \n\n-  Determina\u00e7\u00e3o da dist\u00e2ncia de todos os pontos da fronteira ao \n\ncentr\u00f3ide e c\u00e1lculo da sua dire\u00e7\u00e3o. Como s\u00e3o conhecidas as \n\ncoordenadas de tr\u00eas pontos (ponto inicial, centr\u00f3ide e ponto da \n\nfronteira) (Figura 25), determina-se a dire\u00e7\u00e3o a partir da f\u00f3rmula dos \n\ncossenos dada por:  \n\nDist\u00e2ncia \n(pixels) \n\nPadr\u00f5es: B e E\n\n \n\nPadr\u00f5es: C e D\n\n \n\nDire\u00e7\u00e3o \n(radianos) \n\nDire\u00e7\u00e3o \n(radianos) \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n94\n\n \n                      cos2222 bccba                                             (41)  \n\nOnde:  \n\na\n\n  \n\ndist\u00e2ncia entre o ponto inicial e um ponto pertencente \u00e0 fronteira; \n\nb  dist\u00e2ncia entre o ponto inicial e o centr\u00f3ide; \n\nc\n\n \n\n dist\u00e2ncia de um ponto pertencente \u00e0 fronteira e o centr\u00f3ide; \n\n \n\n- dire\u00e7\u00e3o a ser calculada.        \n\nFIGURA 25  Dire\u00e7\u00f5es obtidas dos pontos.  \n\n- Normaliza\u00e7\u00e3o do gr\u00e1fico: o fato dos padr\u00f5es conterem tamanhos \n\ndiferentes e conseq\u00fcentemente, n\u00famero de pixels diferentes, \n\nacarreta na necessidade de realizar a normaliza\u00e7\u00e3o dos mesmos. \n\nIsto \u00e9 feito pela normaliza\u00e7\u00e3o dos dados no intervalo de [0,1].   \n\n- Cria\u00e7\u00e3o do gr\u00e1fico relacionando a dist\u00e2ncia em fun\u00e7\u00e3o do \u00e2ngulo; \n\n- Interpola\u00e7\u00e3o dos dados. Esta etapa \u00e9 necess\u00e1ria porque na \n\ndetermina\u00e7\u00e3o da m\u00e9trica de correla\u00e7\u00e3o, h\u00e1 necessidade dos padr\u00f5es \n\na serem comparados possu\u00edrem quantidades de pixels id\u00eanticas; \n\na \n\nCentr\u00f3ide \n\n \n\nb c \n\nPonto inicial \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n95\n\n \n- Determina\u00e7\u00e3o da discrep\u00e2ncia entre as assinaturas, usando a \n\nm\u00e9trica de correla\u00e7\u00e3o (Se\u00e7\u00e3o 4.2.1). O uso somente da m\u00e9trica de \n\ncorrela\u00e7\u00e3o est\u00e1 relacionado ao tipo de padr\u00f5es utilizados no trabalho. \n\nComo os padr\u00f5es s\u00e3o semelhantes, as m\u00e9tricas de dist\u00e2ncia, \n\ndispers\u00e3o e forma n\u00e3o se mostraram adequadas como crit\u00e9rio para \n\nestabelecer a correspond\u00eancia.   \n\n5.2.6. Localiza\u00e7\u00e3o precisa   \n\nA localiza\u00e7\u00e3o autom\u00e1tica precisa dos cantos dos alvos projetados \n\npossui a vantagem em rela\u00e7\u00e3o aos m\u00e9todos manual ou semi-autom\u00e1tico, por \n\ndiminuir o tempo de resposta do sistema e fornecer uma resposta com precis\u00e3o \n\nsubpixel. Nesta etapa, dois m\u00e9todos de localiza\u00e7\u00e3o precisa foram comparados com \n\no objetivo de refinar a solu\u00e7\u00e3o obtida na classifica\u00e7\u00e3o: correspond\u00eancia por m\u00ednimos \n\nquadrados e detec\u00e7\u00e3o de cantos.    \n\n5.2.6.1. M\u00e9todo de correspond\u00eancia de imagens por m\u00ednimos quadrados e \n\nreamostragem   \n\nO m\u00e9todo de correspond\u00eancia de imagens por m\u00ednimos quadrados \n\nconsiste em um refinamento na posi\u00e7\u00e3o dos cantos dos padr\u00f5es, obtida na etapa de \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n96\n\n \nclassifica\u00e7\u00e3o a uma precis\u00e3o subpixel. Para isto, determinaram-se os par\u00e2metros \n\nradiom\u00e9tricos e geom\u00e9tricos a partir do conhecimento dos n\u00edveis de cinza das \n\njanelas de refer\u00eancia e de pesquisa de acordo com a Se\u00e7\u00e3o 4.1.2. Por\u00e9m, os \n\nresultados obtidos para os par\u00e2metros radiom\u00e9tricos n\u00e3o ofereceram resultados \n\nsatisfat\u00f3rios. Uma melhor metodologia, portanto, foi determinar separadamente os \n\npar\u00e2metros radiom\u00e9tricos e geom\u00e9tricos. Primeiramente, realizou-se a corre\u00e7\u00e3o \n\nradiom\u00e9trica da imagem e, posteriormente, fez-se a sua corre\u00e7\u00e3o geom\u00e9trica. \n\nAmbos os par\u00e2metros foram obtidos por um ajustamento usando o m\u00e9todo \n\nparam\u00e9trico.  Ap\u00f3s a etapa de m\u00ednimos quadrados, realizou-se a reamostragem da \n\njanela de pesquisa a partir do conhecimento dos par\u00e2metros obtidos pelo m\u00e9todo de \n\ncorrespond\u00eancia por m\u00ednimos quadrados para determina\u00e7\u00e3o da posi\u00e7\u00e3o e dos n\u00edveis \n\nde cinza da nova imagem. As novas posi\u00e7\u00f5es dos pixels na imagem e seus \n\nrespectivos n\u00edveis de cinza s\u00e3o determinados a partir de uma transforma\u00e7\u00e3o afim \n\ndireta e de uma interpola\u00e7\u00e3o bilinear. \n\nA aplica\u00e7\u00e3o do m\u00e9todo de correspond\u00eancia por m\u00ednimos quadrados \n\ne a reamostragem ocorrem at\u00e9 o momento em que as corre\u00e7\u00f5es dos par\u00e2metros \n\ngeom\u00e9tricos determinados sejam menores que os crit\u00e9rios pr\u00e9-definidos inicialmente \n\n(crit\u00e9rios de converg\u00eancia = 0.00001).  \n\nAs coordenadas com precis\u00e3o subpixel s\u00e3o determinadas a partir do \n\nconhecimento das coordenadas aproximadas obtidas no processo de classifica\u00e7\u00e3o \n\npor correla\u00e7\u00e3o e os novos par\u00e2metros determinados.     \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n97\n\n \n5.2.6.2. Detec\u00e7\u00e3o de cantos   \n\nA detec\u00e7\u00e3o de cantos foi realizada usando o m\u00e9todo descrito na \n\nSe\u00e7\u00e3o 2.9.  \n\nPara a detec\u00e7\u00e3o de cantos, \u00e9 necess\u00e1rio realizar previamente a \n\ndetec\u00e7\u00e3o de bordas, neste caso usando-se os operadores de Sobel (Se\u00e7\u00e3o 2.8.1.1). \n\nEstes operadores permitem a determina\u00e7\u00e3o dos gradientes em x e y para os pixels \n\ncentrais ap\u00f3s a convolu\u00e7\u00e3o das m\u00e1scaras na imagem original.  \n\nPara determina\u00e7\u00e3o dos gradientes nas molduras na janela do alvo \n\nsegmentado, uma janela maior na imagem original \u00e9 selecionada, isto \u00e9, para se \n\nobter uma matriz 5 x 5 composta de gradientes em x e y, uma subimagem 7 x 7 deve \n\nser selecionada.  \n\nO tamanho da subimagem a ser analisada depende do tipo de \n\npadr\u00e3o. Em padr\u00f5es do tipo A, para todos os cantos, as subimagens podem ser \n\nmaiores que em outros padr\u00f5es porque a dist\u00e2ncia entre os cantos \u00e9 grande. Este \n\nfato tende a garantir uma melhor qualidade subpixel dos cantos do padr\u00e3o tipo A. \n\nPara os alvos B, C, D e E, o tamanho da subimagem a ser analisada depende da \n\nposi\u00e7\u00e3o em que se encontram os alvos. Quanto menor a dist\u00e2ncia entre os alvos, \n\nmenor a janela a ser analisada e menor a precis\u00e3o do detector de cantos na \n\nlocaliza\u00e7\u00e3o dos padr\u00f5es porque o n\u00famero de observa\u00e7\u00f5es \u00e9 pequeno.  \n\nUm problema est\u00e1 relacionado com os padr\u00f5es pr\u00e9-definidos, \n\nporque, por mais que estes garantam um grande n\u00famero de cantos com localiza\u00e7\u00e3o \n\nprecisa para reconstru\u00e7\u00e3o, a etapa de aquisi\u00e7\u00e3o da imagem acaba interferindo na \n\nforma dos alvos, arredondando os cantos e dificultando na localiza\u00e7\u00e3o precisa. \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n98\n\n \nAp\u00f3s a realiza\u00e7\u00e3o da detec\u00e7\u00e3o de bordas com os operadores de \n\nSobel e, portanto, com o conhecimento dos gradientes na imagem e a posi\u00e7\u00e3o \n\naproximada de cada v\u00e9rtice do alvo, obtida na classifica\u00e7\u00e3o dos alvos, determinam-\n\nse os cantos da imagem usando a metodologia citada na Se\u00e7\u00e3o 2.9.2.   \n\n5.2.7. Crit\u00e9rio para avalia\u00e7\u00e3o do m\u00e9todo de localiza\u00e7\u00e3o precisa   \n\nUma vez que as coordenadas reconstru\u00eddas a partir dos padr\u00f5es \n\nprojetados sobre uma imagem plana deveriam gerar uma superf\u00edcie plana perfeita, a \n\nforma encontrada para avaliar os resultados da calibra\u00e7\u00e3o dos vetores diretores foi a \n\nseguinte:  \n\n- Executar o processo de reconstru\u00e7\u00e3o sobre a imagem; \n\n- Efetuar a regress\u00e3o de uma superf\u00edcie plana sobre as coordenadas \n\n3D reconstru\u00eddas; e conseguinte, \n\n- Calcular as discrep\u00e2ncias entre as coordenadas Z\n\n \n\nobtidas na  \n\nreconstru\u00e7\u00e3o e as coordenadas Z\n\n \n\ncalculadas pelo plano ajustado \n\n(Equa\u00e7\u00e3o 42);  \n\nXAYAAYXZ 100100),(                                      (42)  \n\n Onde:  \n\nZ - profundidade dos pontos; \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n99\n\n \nYX , - coordenadas obtidas da reconstru\u00e7\u00e3o;  \n\n100100 ,, AAA - coeficientes do plano. Estes coeficientes foram obtidos usando o \n\nsoftware Surfer 7.0.  \n\n-  C\u00e1lculo do erro m\u00e9dio quadr\u00e1tico.  \n\nO m\u00e9todo de reconstru\u00e7\u00e3o usado neste trabalho \u00e9 uma \n\nimplementa\u00e7\u00e3o da modelagem matem\u00e1tica desenvolvida na primeira vers\u00e3o do \n\nsistema de reconstru\u00e7\u00e3o (TOMMASELLI, 1997).  \n\nA reconstru\u00e7\u00e3o da superf\u00edcie \u00e9 realizada conhecendo-se cada vetor \n\ndiretor dos cantos dos alvos e suas respectivas coordenadas subpixel. Os vetores \n\ndiretores dos v\u00e9rtices dos alvos s\u00e3o calculados por uma calibra\u00e7\u00e3o do projetor, a \n\npartir do conhecimento das coordenadas subpixel determinadas nos m\u00e9todos de \n\nlocaliza\u00e7\u00e3o precisa, da orienta\u00e7\u00e3o interior, da orienta\u00e7\u00e3o exterior, das coordenadas \n\ndo projetor e dos valores aproximados dos vetores diretores. Os par\u00e2metros de \n\norienta\u00e7\u00e3o interior e de orienta\u00e7\u00e3o exterior e as coordenadas do projetor s\u00e3o obtidos \n\npela calibra\u00e7\u00e3o da c\u00e2mara. Maiores detalhes de todo o processo de reconstru\u00e7\u00e3o \n\npodem ser vistos em Reiss e Tommaselli (2004).        \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n100\n\n \nCAP\u00cdTULO VI   \n\n6. DESENVOLVIMENTO E IMPLEMENTA\u00c7\u00c3O   \n\nPara atender aos objetivos deste trabalho, alguns programas foram \n\nimplementados em Linguagem C/C++ como: gera\u00e7\u00e3o autom\u00e1tica de padr\u00f5es, \n\nlimiariza\u00e7\u00e3o local, segmenta\u00e7\u00e3o por crescimento de regi\u00f5es, extra\u00e7\u00e3o de fronteiras, \n\ncorrespond\u00eancia por \u00e1rea, assinatura e detec\u00e7\u00e3o de bordas. Al\u00e9m disto, vale \n\nressaltar que os programas de segmenta\u00e7\u00e3o por crescimento de regi\u00f5es e \n\nlimiariza\u00e7\u00e3o foram implementados pelo Msc. M\u00e1rio Luiz Lopes Reiss. As fun\u00e7\u00f5es \n\nimplementadas podem ser encontradas na biblioteca UPTK, que est\u00e1 sendo \n\ndesenvolvida pelo Departamento de Cartografia da FCT/Unesp (TOMMASELLI, \n\n2003).     \n\n6.1. Gera\u00e7\u00e3o autom\u00e1tica de padr\u00f5es  \n\nO programa de gera\u00e7\u00e3o autom\u00e1tica de padr\u00f5es tem como resultado \n\na cria\u00e7\u00e3o de um padr\u00e3o composto pela combina\u00e7\u00e3o de cinco padr\u00f5es primitivos \n\n(Figura 18). Como mencionado anteriormente, esta combina\u00e7\u00e3o de padr\u00f5es possui \n\nalgumas restri\u00e7\u00f5es para ser realizada. Estes padr\u00f5es primitivos foram combinados \n\nem matrizes, gerando-se uma malha. A partir de um processo fotogr\u00e1fico foram \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n101\n\n \nent\u00e3o gerados fotolitos. No total, dez fotolitos foram criados, modificando-se o \n\ntamanho do padr\u00e3o e o espa\u00e7amento entre os mesmos (Figura 26).  \n\nO fotolito projetado neste trabalho possui padr\u00f5es com tamanho de 9 \n\npixels. x 9 pixels. e com espa\u00e7amento de 7 pixels entre os padr\u00f5es (Figura 27).  \n\nFIGURA 26  Exemplo de uma imagem de padr\u00f5es.          \n\nFIGURA 27 - Dimens\u00e3o dos padr\u00f5es projetados em pixel.    \n\n9 \n\n7 \n\n4 \n\n4 9 \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n102\n\n \n6.2. Limiariza\u00e7\u00e3o local   \n\nInicialmente, dois m\u00e9todos foram implementados para solucionar \n\neste problema: m\u00e9todo de expans\u00e3o do histograma e m\u00e9todo de transforma\u00e7\u00e3o local \n\nbaseado nas propriedades de intensidades da m\u00e9dia e de desvio-padr\u00e3o de pixels \n\n(Se\u00e7\u00e3o 2.5). Estes m\u00e9todos, entretanto, n\u00e3o proporcionaram um resultado \n\nsatisfat\u00f3rio como pode ser observado na Figura 28.         \n\nFIGURA 28  Resultados da limiariza\u00e7\u00e3o. (a) Imagem original; (b) M\u00e9todo de \n\nexpans\u00e3o do histograma; (c) M\u00e9todo de transforma\u00e7\u00e3o local.  \n\nO problema do m\u00e9todo de expans\u00e3o do histograma est\u00e1 relacionado \n\na este ser um m\u00e9todo global e, portanto, determina um \u00fanico limiar por toda a \n\nimagem.  \n\nO m\u00e9todo de transforma\u00e7\u00e3o local garante um melhor resultado que o \n\nm\u00e9todo de expans\u00e3o do histograma por este m\u00e9todo ser local, por\u00e9m, em \n\nprocedimentos totalmente autom\u00e1ticos, este m\u00e9todo possui a restri\u00e7\u00e3o em rela\u00e7\u00e3o \u00e0 \n\n(a) (b) (c) \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n103\n\n \nconstante k, pela necessidade de inform\u00e1-la inicialmente e esta ser dependente da \n\nimagem original a ser usada.  \n\nPortanto, como os m\u00e9todos anteriores n\u00e3o garantiram resultados \n\nsatisfat\u00f3rios, uma nova metodologia foi sugerida. Esta metodologia consistiu na \n\nimplementa\u00e7\u00e3o de uma limiariza\u00e7\u00e3o local (Se\u00e7\u00e3o 2.6.3) comparando dois \n\noperadores de limiariza\u00e7\u00e3o autom\u00e1tica: Otsu (Se\u00e7\u00e3o 2.6.1) e Pun (Se\u00e7\u00e3o 2.6.2). \n\nNeste m\u00e9todo de limiariza\u00e7\u00e3o informa-se o tamanho da m\u00e1scara a ser percorrida na \n\nimagem e o m\u00e9todo de limiariza\u00e7\u00e3o desejado. Para cada percurso da m\u00e1scara na \n\nimagem, um limiar \u00e9 determinado a partir do m\u00e9todo de Otsu ou de Pun e aplicado \u00e0 \n\nimagem, em fun\u00e7\u00e3o da regi\u00e3o central da m\u00e1scara. Os pixels com valores abaixo do \n\nlimiar determinado pelos m\u00e9todos de Otsu ou de Pun recebem n\u00edvel de brilho zero e \n\nos pixels com n\u00edveis de cinza superiores a este valor, permanecem com o mesmo \n\nvalor de n\u00edvel de cinza.  \n\nOs resultados deste processo podem ser observados na Figura 29. \n\nComo se podem perceber visualmente, ambos os m\u00e9todos de limiariza\u00e7\u00e3o \n\nconseguiram eliminar completamente os ru\u00eddos do fundo, sem prejudicar o processo \n\nde reconhecimento. Al\u00e9m disto, foram comparados tr\u00eas diferentes tamanhos de \n\nm\u00e1scaras (3x3, 5x5 e 7x7). A partir de testes, observou-se que a m\u00e1scara 3x3 \n\nusando o m\u00e9todo de Otsu proporcionou melhores resultados aliados a um menor \n\ncusto computacional. Conseq\u00fcentemente, pensando no custo computacional, \n\ndecidiu-se usar o m\u00e9todo de Otsu. Outra maneira de comparar os m\u00e9todos de \n\nlimiariza\u00e7\u00e3o \u00e9 observar os resultados das segmenta\u00e7\u00f5es, verificando o n\u00famero de \n\nalvos perdidos e suas respectivas formas.   \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n104\n\n                     \n\nFIGURA 29 - (a) Imagem original (tomada de um dorso humano) com o sistema de luz \n\nestruturada; (b) Parte da imagem original; (c) (d) Limiariza\u00e7\u00e3o com o m\u00e9todo de Otsu \n\nlocal; (e) (f) Limiariza\u00e7\u00e3o com Pun local (REISS e TOMMASELLI, 2004).   \n\n(a) (b) \n\n(d) \n\n(e) (f) \n\n(c) \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n105\n\n \n6.3. Segmenta\u00e7\u00e3o   \n\nA segmenta\u00e7\u00e3o consiste em subdividir uma imagem em regi\u00f5es \n\nhomog\u00eaneas usando crit\u00e9rios de similaridade. Neste caso, o m\u00e9todo de \n\nsegmenta\u00e7\u00e3o usado foi por crescimento de regi\u00f5es, usando como crit\u00e9rio de \n\nsimilaridade os n\u00edveis de cinza. Neste processo de segmenta\u00e7\u00e3o de regi\u00f5es, o fundo \n\nda imagem recebe o r\u00f3tulo 1 e os padr\u00f5es s\u00e3o rotulados com n\u00fameros desde 2 at\u00e9 o \n\nn\u00famero de padr\u00f5es segmentados. Ap\u00f3s a segmenta\u00e7\u00e3o de um alvo, adiciona-se +1 \n\nao n\u00famero do r\u00f3tulo. Simultaneamente \u00e0 segmenta\u00e7\u00e3o, s\u00e3o calculadas as \n\ncoordenadas dos centros de massa de cada padr\u00e3o. As coordenadas dos pixels \n\nsegmentados e o r\u00f3tulo de cada padr\u00e3o s\u00e3o armazenados em uma lista para ser \n\nusada nas pr\u00f3ximas etapas. Os resultados da etapa de segmenta\u00e7\u00e3o podem ser \n\nobservados na Figura 30. \n\nFIGURA 30  Resultados de imagens segmentadas. (a) Todos os \n\nalvos foram segmentados. (b) Alguns alvos n\u00e3o foram segmentados.  \n\nComo pode ser observado na Figura 30a, todos os alvos foram \n\nsegmentados. Na Figura 30b, entretanto, alguns alvos n\u00e3o foram segmentados. Isto \n\n(a) (b) \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n106\n\n \nocorreu porque foram feitas algumas considera\u00e7\u00f5es a respeito do tamanho do alvo, \n\nisto \u00e9, baseado na rela\u00e7\u00e3o da dist\u00e2ncia focal da c\u00e2mara com as dist\u00e2ncias m\u00e1xima e \n\nm\u00ednima do centro perspectivo da c\u00e2mara \u00e0 superf\u00edcie do objeto, foi poss\u00edvel \n\ndeterminar a quantidade aproximada de pixels de cada padr\u00e3o. Assim, alvos com \n\nquantidade de pixels n\u00e3o pertencentes ao intervalo estabelecido s\u00e3o eliminados \n\nap\u00f3s a segmenta\u00e7\u00e3o. Esta restri\u00e7\u00e3o ocorre para n\u00e3o adquirir pixels que sejam ru\u00eddos \n\nna imagem ou alvos muito grandes que s\u00e3o conseq\u00fc\u00eancia da deforma\u00e7\u00e3o dos alvos \n\nno objeto ou jun\u00e7\u00e3o de alvos, proporcionando um reconhecimento equivocado \n\nposteriormente.   \n\n6.4. Classifica\u00e7\u00e3o   \n\nA partir da imagem segmentada, inicia-se uma das etapas \n\nfundamentais para a realiza\u00e7\u00e3o da reconstru\u00e7\u00e3o: a classifica\u00e7\u00e3o dos alvos. Esta \n\netapa \u00e9 importante porque os seus resultados interferem completamente na \n\nlocaliza\u00e7\u00e3o precisa e posterior reconstru\u00e7\u00e3o pois as coordenadas aproximadas dos \n\ncantos dos alvos s\u00e3o determinadas nesta etapa. A classifica\u00e7\u00e3o de alvos objetiva \n\ninformar a melhor correspond\u00eancia do alvo segmentado quando comparado com os \n\npadr\u00f5es.  \n\nNesta etapa de classifica\u00e7\u00e3o, dois m\u00e9todos de correspond\u00eancia \n\nforam comparados: a correspond\u00eancia por padr\u00e3o e a assinatura.   \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n107\n\n \n6.4.1. Correspond\u00eancia por correla\u00e7\u00e3o   \n\nA correspond\u00eancia por correla\u00e7\u00e3o consiste na compara\u00e7\u00e3o entre os \n\nn\u00edveis de cinza de duas imagens sobrepostas usando uma fun\u00e7\u00e3o desejada. V\u00e1rias \n\nfun\u00e7\u00f5es podem ser utilizadas, por\u00e9m, neste trabalho foram comparadas cinco delas: \n\nerro, erro quadr\u00e1tico, correla\u00e7\u00e3o cruzada, covari\u00e2ncia cruzada e covari\u00e2ncia cruzada \n\nmodificada. A partir de testes realizados, observou-se que a fun\u00e7\u00e3o covari\u00e2ncia \n\ncruzada modificada \u00e9 a que apresentou melhores resultados. Os resultados das \n\noutras fun\u00e7\u00f5es acarretaram em erros de um e dois pixels em rela\u00e7\u00e3o ao valor exato \n\nnas imagens testadas. Por\u00e9m, esta fun\u00e7\u00e3o possui uma desvantagem em rela\u00e7\u00e3o \u00e0s \n\noutras fun\u00e7\u00f5es: maior custo computacional porque a fun\u00e7\u00e3o \u00e9 mais complexa. \n\nMesmo havendo o inconveniente do custo computacional, decidiu-se usar esta \n\nfun\u00e7\u00e3o para a classifica\u00e7\u00e3o dos alvos porque as imagens a serem comparadas s\u00e3o \n\npequenas e n\u00e3o prejudicariam o rendimento computacional. \n\nNa fun\u00e7\u00e3o de covari\u00e2ncia cruzada modificada, a melhor \n\ncorrespond\u00eancia ser\u00e1 aquela em que o coeficiente de correla\u00e7\u00e3o for o mais pr\u00f3ximo \n\nda unidade. Por\u00e9m, se a imagem sofre rota\u00e7\u00f5es, varia\u00e7\u00f5es na escala ou perda de \n\nparte do alvo, uma falsa correspond\u00eancia pode ocorrer ou o coeficiente de \n\ncorrela\u00e7\u00e3o ser t\u00e3o pequeno que n\u00e3o possa ser considerado. A partir de testes \n\nrealizados, observou-se que um limiar para este coeficiente de correla\u00e7\u00e3o poderia \n\nser 0.7 porque garantiria uma classifica\u00e7\u00e3o correta para as imagens usadas e n\u00e3o \n\nprovocaria uma perda significativa dos alvos. \n\nPortanto, tr\u00eas metodologias foram comparadas: compara\u00e7\u00e3o dos \n\nalvos segmentados com os padr\u00f5es pr\u00e9-definidos e com as suas inst\u00e2ncias \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n108\n\n \narmazenadas, compara\u00e7\u00e3o dos alvos segmentados com os padr\u00f5es pr\u00e9-definidos \n\nsuavizados e com as suas inst\u00e2ncias armazenadas suavizadas, compara\u00e7\u00e3o dos \n\nalvos segmentados com os padr\u00f5es pr\u00e9-definidos reamostrados.    \n\n6.4.4.1. Compara\u00e7\u00e3o dos alvos segmentados com os padr\u00f5es pr\u00e9-definidos e com \n\nas suas inst\u00e2ncias armazenadas   \n\nO m\u00e9todo consiste, portanto, na compara\u00e7\u00e3o de todos os alvos \n\nsegmentados na imagem com os cincos padr\u00f5es\n\n \n\narmazenados e suas inst\u00e2ncias \n\ngeradas por modifica\u00e7\u00e3o em rela\u00e7\u00e3o \u00e0 escala. No total s\u00e3o 45 padr\u00f5es bin\u00e1rios \n\narmazenados. A varia\u00e7\u00e3o de escala foi determinada a partir de observa\u00e7\u00f5es \n\nemp\u00edricas realizadas na imagem. Al\u00e9m das imagens de cada padr\u00e3o, foram \n\narmazenadas em uma estrutura de lista as coordenadas em pixels dos cantos, que \n\ns\u00e3o usadas posteriormente como valores aproximados na localiza\u00e7\u00e3o precisa. O \n\nresultado deste reconhecimento pode ser observado na Figura 31. Na Figura 31b, os \n\nalvos encontram-se sem rota\u00e7\u00e3o porque se concentram na parte central do cilindro, \n\nenquanto que na Figura 31d, os alvos est\u00e3o distorcidos.  \n\nPor uma quest\u00e3o de visualiza\u00e7\u00e3o, os alvos detectados foram \n\npintados em cores diferentes: padr\u00e3o A (preto); padr\u00e3o B (azul); padr\u00e3o C \n\n(vermelho); padr\u00e3o D (verde) e padr\u00e3o E (roxo).  \n\nNeste experimento, todos os alvos foram detectados corretamente \n\n(Figura 31c). Os alvos que n\u00e3o foram detectados apresentavam-se parcialmente \n\nincompletos ou deformados pela superf\u00edcie e n\u00e3o geraram um coeficiente de \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n109\n\n \ncorrela\u00e7\u00e3o maior que o pr\u00e9-definido como limiar (0.7) com nenhum dos padr\u00f5es ou \n\nsuas inst\u00e2ncias. \n\nUma dificuldade observada foi a detec\u00e7\u00e3o de alvos em escalas \n\ndiferentes em x e y e distorcidos (Figura 31d), j\u00e1 que n\u00e3o \u00e9 recomend\u00e1vel gerar \n\nmuitos padr\u00f5es\n\n \n\ninstanciados, porque isto aumentaria o custo computacional. Nestes \n\ncasos, como os alvos sofrem modifica\u00e7\u00f5es diferentes em escalas x e y, uma \n\ndetec\u00e7\u00e3o correta pode ocorrer, por\u00e9m, as coordenadas aproximadas n\u00e3o s\u00e3o \n\nconfi\u00e1veis. \n\nVale ressaltar que este procedimento proporciona bons resultados \n\nporque \u00e9 pequena a percentagem de alvos n\u00e3o reconhecidos (em torno de 15%). \n\nIsto garante um grande n\u00famero de v\u00e9rtices para a localiza\u00e7\u00e3o precisa e tende a \n\ngarantir uma melhor reconstru\u00e7\u00e3o do objeto se comparada com a reconstru\u00e7\u00e3o \n\nobtida apenas pelo centro de massa de cada alvo. Um exemplo de classifica\u00e7\u00e3o de \n\ntodos os alvos da imagem pode ser observado nas Figuras 32 e 33.            \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n110\n\n                    \n\nFIGURA 31 \n\n \n\nResultados da correspond\u00eancia por correla\u00e7\u00e3o usando padr\u00f5es bin\u00e1rios \n(imagens invertidas). (a) Imagem dos alvos projetados em um cilindro; (b) Imagem real\u00e7ada \nde uma imagem sem varia\u00e7\u00e3o de rota\u00e7\u00e3o; (c) Classifica\u00e7\u00e3o dos alvos para a imagem com \n\npadr\u00f5es projetados distorcidos; (d) Imagem real\u00e7ada de uma imagem com varia\u00e7\u00e3o na \nrota\u00e7\u00e3o; (e) Classifica\u00e7\u00e3o dos alvos para a imagem com padr\u00f5es projetados distorcidos.  \n\n(a) \n\n(b)\n\n \n\n(d)\n\n \n\n(c)\n\n \n\n(e)\n\n \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n111\n\n             \n\nFIGURA 32 - Classifica\u00e7\u00e3o dos alvos de um cilindro ap\u00f3s a segmenta\u00e7\u00e3o (imagem invertida).            \n\nFIGURA 33 - Classifica\u00e7\u00e3o dos alvos ap\u00f3s a segmenta\u00e7\u00e3o de um dorso humano  \n\n(imagem invertida).  \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n112\n\n \nPensando em melhorar os resultados da classifica\u00e7\u00e3o por \n\ncorrela\u00e7\u00e3o, usaram-se os mesmos padr\u00f5es armazenados e suas inst\u00e2ncias \n\nsuavizadas pela m\u00e9dia.    \n\n6.4.4.2. Compara\u00e7\u00e3o dos alvos segmentados com os padr\u00f5es pr\u00e9-definidos \n\nsuavizados e com as suas inst\u00e2ncias suavizadas armazenados   \n\nEsta escolha foi feita observando como eram os alvos projetados, j\u00e1 \n\nque a correspond\u00eancia com alvos bin\u00e1rios poderia ser prejudicada por causa da \n\nvaria\u00e7\u00e3o entre os n\u00edveis de cinza entre as imagens armazenadas e segmentadas. Os \n\nresultados ap\u00f3s estas considera\u00e7\u00f5es podem ser observados na Figura 34.   \n\nComo pode ser observada na Figura 34, a correspond\u00eancia por \n\ncorrela\u00e7\u00e3o usando padr\u00f5es armazenados suavizados garantiu melhores resultados \n\nque o m\u00e9todo usando imagens bin\u00e1rias. Em imagens com pouca varia\u00e7\u00e3o na \n\nrota\u00e7\u00e3o, este m\u00e9todo conseguiu classificar aproximadamente 94% dos alvos \n\nsegmentados enquanto em imagens com varia\u00e7\u00e3o na rota\u00e7\u00e3o, 90% dos alvos foram \n\nclassificados corretamente. \n\nMesmo considerando que os resultados eram bons com as \n\nmetodologias anteriores, decidiu-se refinar ainda mais os resultados. Como os alvos \n\nprojetados sofrem uma varia\u00e7\u00e3o diferente de escala em x e y, o alvo segmentado \n\npoderia ser correlacionado com um padr\u00e3o de diferente tamanho e proporcionar \n\ncoordenadas aproximadas incorretas para a localiza\u00e7\u00e3o precisa. Uma possibilidade \n\nseria aumentar o n\u00famero de padr\u00f5es armazenados, por\u00e9m, isto aumentaria o custo \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n113\n\n \ncomputacional. Uma melhor maneira, foi trabalhar com padr\u00f5es reamostrados em \n\ntempo real.              \n\nFIGURA 34 \n\n \n\nResultados da correspond\u00eancia por correla\u00e7\u00e3o usando padr\u00f5es \n\nsuavizados pela m\u00e9dia (imagens invertidas) (a) Imagem real\u00e7ada de uma imagem \n\nsem varia\u00e7\u00e3o de rota\u00e7\u00e3o; (b) Classifica\u00e7\u00e3o dos alvos para a imagem sem varia\u00e7\u00e3o \n\nda rota\u00e7\u00e3o; (c) Imagem real\u00e7ada de uma imagem com padr\u00f5es projetados \n\ndistorcidos; (d) Classifica\u00e7\u00e3o dos alvos para a imagem com padr\u00f5es projetados \n\ndistorcidos.  \n\n6.4.4.3. Compara\u00e7\u00e3o dos alvos segmentados com os padr\u00f5es pr\u00e9-definidos \n\nreamostrados   \n\nEsta metodologia consiste armazenar apenas os cinco padr\u00f5es \n\nprimitivos e a partir do conhecimento da dimens\u00e3o dos alvos segmentados, \n\n(d) \n\n(a)\n\n \n\n(b) \n\n(c) \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n114\n\n \nreamostr\u00e1-los em tempo real. Neste caso, tr\u00eas experimentos foram realizados: \n\nreamostrando padr\u00f5es primitivos com dimens\u00e3o 23 x 23 pixels, 90 x 90 pixels (com \n\nmoldura) e 90 x 90 pixels (sem moldura).   \n\n- 1\u00ba Experimento: Reamostrando padr\u00f5es primitivos com dimens\u00e3o 23 x 23 \n\npixels    \n\nEsta dimens\u00e3o dos padr\u00f5es armazenados foi escolhida \n\nempiricamente, a partir de observa\u00e7\u00f5es realizadas na imagem. A dimens\u00e3o dos \n\nalvos segmentados foi obtida a partir da diferen\u00e7a entre as coordenadas m\u00e1ximas e \n\nm\u00ednimas de cada alvo. Este procedimento pode ser usado, neste caso, porque as \n\nimagens usadas possuem uma pequena varia\u00e7\u00e3o da rota\u00e7\u00e3o. O m\u00e9todo usado para \n\na reamostragem dos alvos nas imagens foi o m\u00e9todo de interpola\u00e7\u00e3o bilinear (Se\u00e7\u00e3o \n\n4.1.2). Para este tipo de m\u00e9todo, aproximadamente 96% dos alvos conseguiram ser \n\nclassificados corretamente para imagens com pequena rota\u00e7\u00e3o e em regi\u00f5es com \n\num alto gradiente, todos os alvos foram classificados (Figura 35). \u00c9 importante \n\nressaltar que este procedimento conseguiu classificar corretamente mesmo alguns \n\nalvos estando incompletos.      \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n115\n\n              \n\nFIGURA 35 \n\n \n\nResultados da correspond\u00eancia por correla\u00e7\u00e3o usando padr\u00f5es \n\nreamostrados (Padr\u00f5es 23 pixels x 23 pixels) (imagens invertidas) (a) Imagem \n\nreal\u00e7ada de uma imagem sem varia\u00e7\u00e3o de rota\u00e7\u00e3o; (b) Classifica\u00e7\u00e3o dos alvos para \n\na imagem sem varia\u00e7\u00e3o da rota\u00e7\u00e3o; (c) Imagem real\u00e7ada de uma imagem com \n\npadr\u00f5es projetados distorcidos; (d) Classifica\u00e7\u00e3o dos alvos para a imagem com \n\npadr\u00f5es projetados distorcidos.   \n\nPosteriormente, observou-se, adicionalmente, que esta t\u00e9cnica de \n\nclassifica\u00e7\u00e3o poderia ser melhorada ainda mais a partir do uso de padr\u00f5es com \n\ndimens\u00e3o proporcional ao do alvo projetado ao inv\u00e9s da escolha emp\u00edrica de sua \n\ndimens\u00e3o, com base apenas na observa\u00e7\u00e3o dos alvos na imagem. Neste caso, a \n\ndimens\u00e3o escolhida para os padr\u00f5es armazenados foi de 90 pixels x 90 pixels.    \n\n(a)\n\n \n\n(b) \n\n(c) (d) \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n116\n\n \n- 2\u00ba Experimento: Reamostrando padr\u00f5es primitivos com dimens\u00e3o 90 x 90 \n\npixels (sem moldura)  \n\nNeste experimento, resolveu-se reamostrar apenas a parte branca \n\ndo alvo e posteriormente, inserir a moldura preta com dimens\u00e3o de 2 pixels (Figura \n\n36). Os resultados obtidos com este m\u00e9todo podem ser observados na Figura 37.      \n\nFIGURA 36  Reamostragem dos padr\u00f5es primitivos sem moldura.      \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n117\n\n                  \n\nFIGURA 37 \n\n \n\nResultados da correspond\u00eancia por correla\u00e7\u00e3o usando padr\u00f5es \n\nreamostrados sem bordas (Padr\u00f5es 90 pixels x 90 pixels) (a) Imagem real\u00e7ada de \n\numa imagem sem varia\u00e7\u00e3o de rota\u00e7\u00e3o; (b) Classifica\u00e7\u00e3o dos alvos para a imagem \n\nsem varia\u00e7\u00e3o da rota\u00e7\u00e3o; (c) Imagem real\u00e7ada de uma imagem com padr\u00f5es \n\nprojetados distorcidos; (d) Classifica\u00e7\u00e3o dos alvos para a imagem com padr\u00f5es \n\nprojetados distorcidos.   \n\n- 3\u00ba Experimento: Reamostrando padr\u00f5es primitivos com dimens\u00e3o 90 x 90 \n\npixels (com moldura)   \n\nComo o resultado obtido e mostrado na Figura 37 n\u00e3o proporcionou \n\nos resultados esperados, decidiu-se usar padr\u00f5es com dimens\u00e3o proporcional ao do \n\nalvo projetado (90 pixels x 90 pixels). Por\u00e9m, ao inv\u00e9s de reamostrar o alvo sem as \n\n(c) (d) \n\n(a)\n\n \n\n(b) \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n118\n\n \nmolduras, reamostrou-os com molduras de dimens\u00e3o 2 pixels. Os resultados desta \n\nmetodologia podem ser observados na Figura 38.             \n\nFIGURA 38 \n\n \n\nResultados da correspond\u00eancia por correla\u00e7\u00e3o usando padr\u00f5es \n\nreamostrados usando molduras (Padr\u00f5es 90 pixels x 90 pixels) (a) Imagem real\u00e7ada \n\nde uma imagem sem varia\u00e7\u00e3o de rota\u00e7\u00e3o; (b) Classifica\u00e7\u00e3o dos alvos para a imagem \n\nsem varia\u00e7\u00e3o da rota\u00e7\u00e3o; (c) Imagem real\u00e7ada de uma imagem com padr\u00f5es \n\nprojetados distorcidos; (d) Classifica\u00e7\u00e3o dos alvos para a imagem com padr\u00f5es \n\nprojetados distorcidos.   \n\nA partir destes experimentos realizados pode-se observar que os \n\nm\u00e9todos usando a reamostragem por interpola\u00e7\u00e3o bilinear em tempo real \n\nproporcionaram melhores resultados. Al\u00e9m disso, usando o m\u00e9todo de \n\nreamostragem por interpola\u00e7\u00e3o bilinear, pode-se diminuir o limiar at\u00e9 valores como \n\n0.5, e mesmo assim o procedimento ainda consegue correlacionar perfeitamente \n\n(c) (d) \n\n(a)\n\n \n\n(b) \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n119\n\n \nsem muitas perdas de alvos. Verificou-se, ainda, que n\u00e3o \u00e9 vi\u00e1vel reamostrar apenas \n\na imagem sem as molduras e depois inseri-las. Este procedimento faz com que a \n\nimagem n\u00e3o sofra uma suaviza\u00e7\u00e3o e os valores dos coeficientes de correla\u00e7\u00e3o \n\nsejam inferiores aos valores estipulados anteriormente. Realizando este mesmo \n\nprocedimento com os alvos pr\u00e9-definidos, a perda de alvos \u00e9 mais elevada e ainda, \n\nalguns alvos j\u00e1 come\u00e7am a ser correlacionados erroneamente. Por outro lado, o \n\nm\u00e9todo de classifica\u00e7\u00e3o usando alvos pr\u00e9-definidos tamb\u00e9m proporcionou bons \n\nresultados e poderia ser melhorado ainda mais, se o n\u00famero de padr\u00f5es \n\narmazenados fosse maior. Por\u00e9m, isso n\u00e3o \u00e9 vi\u00e1vel porque aumentaria muito o \n\ncusto computacional.    \n\n6.4.2. Assinatura  \n\n \n\nA assinatura de um alvo consiste de um gr\u00e1fico relacionando a \n\ndist\u00e2ncia e a dire\u00e7\u00e3o de cada pixel pertencente \u00e0 sua fronteira. Para determinar os \n\npixels que fazem parte da fronteira, uma extra\u00e7\u00e3o \u00e9 realizada usando o m\u00e9todo de \n\npersegui\u00e7\u00e3o de fronteiras (Figura 39). Neste m\u00e9todo, uma estrutura de lista \u00e9 criada \n\ncomposta do n\u00famero do r\u00f3tulo do alvo e as respectivas coordenadas dos pixels \n\npertencentes \u00e0 fronteira.  \n\nComo os alvos encontram-se com dimens\u00e3o pequena, a \n\nsegmenta\u00e7\u00e3o, em alguns casos, n\u00e3o proporciona resultados satisfat\u00f3rios, \n\ninterferindo na extra\u00e7\u00e3o da fronteira e prejudicando na detec\u00e7\u00e3o pelo m\u00e9todo da \n\nassinatura (ver Figura 39).  \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n120\n\n                 \n\nFIGURA 39  Extra\u00e7\u00e3o de fronteiras usando o m\u00e9todo de persegui\u00e7\u00e3o de fronteiras.  \n\n  (a) Extra\u00e7\u00e3o de fronteiras dos alvos projetados em um cilindro; \n\n(b) Detalhe da imagem com as fronteiras dos alvos extra\u00eddos.  \n\nPara a compara\u00e7\u00e3o entre as assinaturas armazenadas (relacionadas \n\naos padr\u00f5es) e assinaturas geradas (referentes aos alvos segmentados), resolveu-\n\nse primeiramente, armazenar as dist\u00e2ncias e as dire\u00e7\u00f5es em um arquivo com \n\nextens\u00e3o .dat. Por\u00e9m, o usu\u00e1rio poderia querer alterar os padr\u00f5es a serem \n\ncomparados e, para isto, decidiu-se determinar a assinatura dos padr\u00f5es \n\n(a) \n\n(b) \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n121\n\n \narmazenados juntamente com as dos alvos segmentados. As caracter\u00edsticas das \n\nassinaturas de cada padr\u00e3o armazenado podem ser vistas na Figura 40.  \n\nFIGURA 40 - Assinatura dos padr\u00f5es armazenados.  \n\nComo dito anteriormente, estes gr\u00e1ficos s\u00e3o gerados a partir do \n\nconhecimento das dist\u00e2ncias e das dire\u00e7\u00f5es. As dire\u00e7\u00f5es s\u00e3o obtidas a partir do \n\nconhecimento de tr\u00eas pontos: dois pontos da fronteira e o centr\u00f3ide usando a \n\nf\u00f3rmula dos cossenos.  Portanto, este gr\u00e1fico \u00e9 constru\u00eddo com as dire\u00e7\u00f5es (em \n\nfun\u00e7\u00e3o das dist\u00e2ncias) no eixo das abscissas e as dist\u00e2ncias no eixo das ordenadas \n\nPadr\u00e3o A\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n0\n\n0\n,3\n\n9\n\n0\n,9\n\n6\n\n1\n,4\n\n4\n\n1\n,7\n\n8\n\n2\n,3\n\n2\n,8\n\n4\n\n3\n,2\n\n3\n,6\n\n4\n\n4\n,2\n\n1\n\n4\n,6\n\n5\n\n5\n,0\n\n1\n\n5\n,5\n\n6\n\n6\n,0\n\n7\n\nPadr\u00e3o A\n\n \n\nPadr\u00e3o B\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n0\n\n0\n,4\n\n1\n\n5\n,6\n\n7\n\n5\n,6\n\n8\n\n4\n,0\n\n9\n\n4\n,0\n\n9\n\n3\n,7\n\n1\n\n3\n,3\n\n8\n\n3\n,3\n\n6\n\n4\n,0\n\n4\n\n4\n,5\n\n4\n\n5\n,0\n\n5\n\n5\n,7\n\n3\n\n6\n,1\n\n7\n\nPadr\u00e3o B\n\n \n\nPadr\u00e3o C\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\n12\n\n0\n\n0\n,4\n\n6\n\n0\n,7\n\n9\n\n1\n,2\n\n9\n\n1\n,9\n\n7\n\n2\n,4\n\n3\n\n2\n,9\n\n9\n\n3\n,6\n\n5\n\n4\n,0\n\n4\n\n4\n,4\n\n1\n\n4\n,7\n\n1\n\n4\n,7\n\n6\n,2\n\n8\n\n6\n,2\n\n8\n\nPadr\u00e3o C\n\n \n\nPadr\u00e3o D\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n0\n\n0\n,5\n\n1\n,1\n\n2\n\n1\n,5\n\n4\n\n1\n,9\n\n4\n\n2\n,3\n\n2\n\n2\n,3\n\n6\n\n3\n,7\n\n2\n\n3\n,8\n\n1\n\n4\n,0\n\n2\n\n4\n,4\n\n3\n\n4\n,8\n\n2\n\n5\n,3\n\n9\n\n5\n,9\n\n8\n\nPadr\u00e3o D\n\n \n\nPadr\u00e3o E\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n0\n\n0\n,3\n\n4\n\n0\n,9\n\n6\n\n1\n,5\n\n8\n\n2\n,0\n\n1\n\n2\n,6\n\n6\n\n3\n,2\n\n3\n\n3\n,5\n\n5 4\n\n4\n,0\n\n9\n\n4\n,0\n\n7\n\n5\n,6\n\n8\n\n5\n,6\n\n7\n\n6\n,1\n\n4\n\nPadr\u00e3o E\n\n \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n122\n\n \n(em fun\u00e7\u00e3o das coordenadas dos pixels pertencentes \u00e0 fronteira e o centro de \n\nmassa do padr\u00e3o).  \n\nPara comparar as assinaturas geradas e armazenadas, quatro erros \n\nm\u00e9tricos foram calculados: erro de dist\u00e2ncia, erro de forma, erro de dispers\u00e3o e erro \n\nde correla\u00e7\u00e3o. Para isto, necessitou-se realizar uma subamostragem dos dados para \n\ndeterminar o erro de correla\u00e7\u00e3o porque na determina\u00e7\u00e3o deste erro, necessita-se \n\nque tanto o padr\u00e3o armazenado quanto o alvo gerado tenham a mesma quantidade \n\nde pixels na fronteira. A subamostragem foi realizada fazendo com que o alvo com \n\nmaior quantidade de pixels na fronteira tivesse no final, um n\u00famero id\u00eantico ao outro \n\nalvo. O resultado desta subamostragem pode ser observado na Figura 41. Ap\u00f3s \n\ntestes realizados, observou-se que os erros m\u00e9tricos de dist\u00e2ncia, dispers\u00e3o e forma \n\nn\u00e3o poderiam ser usados para os tipos de alvos escolhidos neste trabalho porque os \n\nalvos B, C, D e E s\u00e3o id\u00eanticos, variando apenas na rota\u00e7\u00e3o. Portanto, preferiu-se \n\nusar apenas a m\u00e9trica de correla\u00e7\u00e3o.             \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n123\n\n                      \n\nFIGURA 41 \n\n \n\nAssinaturas dos padr\u00f5es e dos alvos segmentados.   \n\nA Figura 41 mostra os resultados da subamostragem da assinatura. \n\nS\u00e3o mostrados dois gr\u00e1ficos para cada tipo de alvo e cada gr\u00e1fico cont\u00e9m tr\u00eas \n\nPadr\u00e3o E \n\nPadr\u00e3o C \n\nT e m p late C\n\nTem pl at e\n\nP adr \u00e3o m ai or\n\nP adr \u00e3o\nsubam ost r ado\n\nT e m p late C\n\nTem pl at e\n\nP adr \u00e3o m enor\n\nTem pl at e\nsubam ost r ado\n\nPadr\u00e3o D\n\n \n\nT e mp l a t e D\n\nTempl ate\n\nPadr \u00e3o mai or\n\nPadr \u00e3o\nsubamostr ado\n\nTe m plate D\n\nTemplat e\n\nPadr \u00e3o menor\n\nTemplat e\nsubamost r ado\n\nTe m plate E\n\nTemplat e\n\nPadr \u00e3o maior\n\nPadr \u00e3o\nsubamost r ado\n\nTe m plate E\n\nTemplat e\n\nPadr \u00e3o menor\n\nTemplat e\nsubamost r ado\n\nPadr\u00e3o A\n\n \nTe m plate A\n\nPadr \u00e3o maior\n\nTemplat e\n\nPadr \u00e3o\nsubamost r ado\n\nTe m plate A\n\nTemplat e\n\nPadr \u00e3o menor\n\nTemplat e\nsubamost r ado\n\nPadr\u00e3o B\n\n \n\nT e m p late B\n\nP adr \u00e3o\nsubam ost r ado\n\nTem pl at e\n\nP adr \u00e3o m ai or\n\nT e m p late B\n\nTem pl at e\n\nP adr \u00e3o m enor\n\nTem pl at e\nsubam ost r ado\n\n\n\n  \n\nChristiane N. C. Kokubum \n\n124\n\n \nassinaturas. Os gr\u00e1ficos mostram a assinatura do padr\u00e3o, a assinatura do alvo \n\nsegmentado e a assinatura do padr\u00e3o ou do alvo subamostrado, dependendo da \n\nquantidade de pixels.  \n\nA partir destes gr\u00e1ficos, pode-se perceber a similaridade das \n\nassinaturas dos alvos ap\u00f3s a reamostragem. O problema de compatibiliza\u00e7\u00e3o das \n\nassinaturas por meio de reamostragem \u00e9 complicado, pois ao reamostrar pode-se \n\nperder informa\u00e7\u00e3o. Na Figura 41 podem ser vistos padr\u00f5es nos quais os picos s\u00e3o \n\nachatados, em fun\u00e7\u00e3o da reamostragem. Os resultados obtidos com o m\u00e9todo de \n\nassinatura usando a subamostragem dos dados proporcionaram uma classifica\u00e7\u00e3o \n\ncorreta de aproximadamente 67% dos alvos em regi\u00f5es com pequena varia\u00e7\u00e3o na \n\nrota\u00e7\u00e3o (centro do cilindro) e 55% em regi\u00f5es com alto gradiente. Os alvos \n\nvermelhos na Figura 42 indicam que estes n\u00e3o foram classificados.           \n\nFIGURA 42  Resultado da classifica\u00e7\u00e3o usando o m\u00e9todo de assinatura.  \n\nPensando em melhorar estes resultados, decidiu-se realizar uma \n\nsuperamostragem dos dados com uma freq\u00fc\u00eancia de, no m\u00ednimo, duas vezes \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n125\n\n \nsuperior a maior freq\u00fc\u00eancia para n\u00e3o haver perda de dados. Por\u00e9m, os resultados \n\nobtidos n\u00e3o proporcionaram melhores resultados que a subamostragem dos dados.      \n\n6.5. Localiza\u00e7\u00e3o precisa   \n\nA etapa de localiza\u00e7\u00e3o precisa possui como objetivo obter as \n\ncoordenadas dos cantos dos alvos projetados com precis\u00e3o subpixel. Os valores \n\naproximados para as coordenadas com precis\u00e3o pixel foram obtidos ap\u00f3s a \n\nclassifica\u00e7\u00e3o dos alvos. Para realizar esta etapa, dois m\u00e9todos foram comparados: \n\ncorrela\u00e7\u00e3o por m\u00ednimos quadrados e detec\u00e7\u00e3o de cantos. \n\n      \n\n6.5.1. Correspond\u00eancia de imagens por m\u00ednimos quadrados   \n\nA correspond\u00eancia de imagens por m\u00ednimos quadrados consiste em \n\nrefinar a solu\u00e7\u00e3o obtida na detec\u00e7\u00e3o de alvos a partir da determina\u00e7\u00e3o dos \n\npar\u00e2metros geom\u00e9tricos usando o ajustamento baseado no m\u00e9todo param\u00e9trico \n\n(Se\u00e7\u00e3o 4.1.2). Neste caso, dois experimentos foram comparados: um usando \n\npadr\u00f5es pr\u00e9-definidos e o outro com padr\u00f5es reamostrados.   \n\nO resultado do experimento referente \u00e0 localiza\u00e7\u00e3o precisa usando \n\nalvos pr\u00e9-definidos pode ser observado na Figura 43.  \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n126\n\n            \n\nCantos obtidos da classifica\u00e7\u00e3o \n\n \n\nazul \nCantos com coordenadas subpixel \n\n \n\ncor-de-rosa  \n\nFIGURA 43 - Localiza\u00e7\u00e3o precisa dos alvos usando padr\u00f5es pr\u00e9-definidos.  \n\nNa Figura 43 podem ser observados os cantos plotados a partir  dos \n\nvalores aproximados, resultantes do processo de classifica\u00e7\u00e3o de alvos como \n\nc\u00edrculos amarelo, e os cantos com coordenadas subpixel em verde.   \n\nComo pode ser observada na Figura 43, a localiza\u00e7\u00e3o precisa foi \n\ndificultada porque os valores aproximados resultantes do processo de detec\u00e7\u00e3o \n\nusando padr\u00f5es pr\u00e9-definidos, n\u00e3o foram precisos o suficiente. Isto ocorre porque h\u00e1 \n\nvaria\u00e7\u00f5es de escalas diferentes em x e y.  \n\nPara melhorar a localiza\u00e7\u00e3o precisa, decidiu-se gerar apenas cinco \n\npadr\u00f5es para serem comparados. Neste caso, como se conhecia a altura e a largura \n\ndo alvo, fez-se uma reamostragem dos alvos a partir de uma interpola\u00e7\u00e3o bilinear. \n\nComo as imagens usadas n\u00e3o possu\u00edam uma rota\u00e7\u00e3o muito elevada, este m\u00e9todo \n\nde reamostragem do alvo a partir do conhecimento da altura e da largura n\u00e3o \n\nacarretou em problemas. A localiza\u00e7\u00e3o precisa, neste caso, forneceu melhores \n\nresultados porque foram melhores as coordenadas aproximadas com precis\u00e3o pixel  \n\n(Figura 44).   \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n127\n\n             \n\nCantos obtidos da classifica\u00e7\u00e3o \n\n \n\nazul \nCantos com precis\u00e3o subpixel - amarelo  \n\nFIGURA 44  Localiza\u00e7\u00e3o precisa usando o m\u00e9todo de reamostragem dos padr\u00f5es.   \n\n6.5.2. Detec\u00e7\u00e3o de cantos   \n\nAntes de detectar os v\u00e9rtices com precis\u00e3o subpixel, foi necess\u00e1rio \n\ndeterminar os gradientes da imagem. Para isto, foram usados os operadores de \n\nSobel como descritos na Se\u00e7\u00e3o 2.8.1.1. Para cada convolu\u00e7\u00e3o das m\u00e1scaras na \n\nsubimagem, os gradientes em x e y para o pixel central s\u00e3o determinados a partir de \n\numa maior imagem recortada. Por exemplo, se a m\u00e1scara de gradientes a ser \n\ndeterminada \u00e9 5 pixels x 5 pixels, seleciona-se uma imagem 7 pixels x 7 pixels. Com \n\ntodos os gradientes em x e y da imagem obtidos e com a localiza\u00e7\u00e3o aproximada \n\ndos v\u00e9rtices dos alvos obtida pela correla\u00e7\u00e3o no momento da classifica\u00e7\u00e3o, \n\ndeterminou-se os cantos dos alvos com precis\u00e3o subpixel. As coordenadas subpixel \n\nforam obtidas a partir de um programa baseado em Galo e Tozzi (2002). Como a \n\nreamostragem por interpola\u00e7\u00e3o bilinear proporcionou melhores resultados que a \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n128\n\n \nutiliza\u00e7\u00e3o de padr\u00f5es pr\u00e9-definidos, resolveu-se fazer experimentos apenas com a \n\ndetec\u00e7\u00e3o de cantos usando padr\u00f5es reamostrados em tempo real (Figura 45).               \n\nCantos obtidos da classifica\u00e7\u00e3o  amarelo. \nCantos com precis\u00e3o subpixel  vermelho.  \n\nFIGURA 45  Localiza\u00e7\u00e3o precisa por detec\u00e7\u00e3o de cantos usando padr\u00f5es \n\nreamostrados.  \n\n \n\nComo visualmente \u00e9 dif\u00edcil afirmar qual o melhor m\u00e9todo de \n\nlocaliza\u00e7\u00e3o precisa, resolveu-se realizar a reconstru\u00e7\u00e3o de duas linhas selecionadas \n\nde uma imagem (linhas 14 e 15) (Figura 46). Inicialmente, escolheu-se uma imagem \n\nde um plano com quatro diferentes orienta\u00e7\u00f5es. Para cada imagem, determinaram-\n\nse as coordenadas de todos os v\u00e9rtices usando tr\u00eas m\u00e9todos: correspond\u00eancia por \n\nm\u00ednimos quadrados usando padr\u00f5es pr\u00e9-definidos e suas inst\u00e2ncias; \n\ncorrespond\u00eancia por m\u00ednimos quadrados reamostrando em tempo real os padr\u00f5es \n\narmazenados; e, detec\u00e7\u00e3o de cantos reamostrando os padr\u00f5es armazenados. A \n\nreamostragem destes padr\u00f5es \u00e9 feita a partir do conhecimento da altura e da largura \n\ndo alvo segmentado. Com as coordenadas determinadas, criaram-se tr\u00eas arquivos, \n\num para cada m\u00e9todo. Cada arquivo \u00e9 composto pelo nome da imagem, \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n129\n\n \nidentifica\u00e7\u00e3o do padr\u00e3o e as coordenadas de imagem de cada v\u00e9rtice (Tabela 6). \n\nAl\u00e9m disso, as coordenadas do centro de massa dos demais alvos foram usadas.        \n\nFIGURA 46  Uma das quatro imagens usadas para calibra\u00e7\u00e3o da c\u00e2mara.  \n\nTABELA 6 \n\n \n\nExemplo de sa\u00edda do reconhecimento de padr\u00f5es. \n\nCoordenadas (pixel) Nome da imagem \nsem extens\u00e3o \n\nIdentificador do \npadr\u00e3o X Y \n\n       DCP_2517           145413            1377,54            530,54 \n\n \n\nO identificador do padr\u00e3o \u00e9 dividido em quatro partes: os quatro \n\nprimeiros d\u00edgitos equivalem \u00e0 linha e a coluna do padr\u00e3o, respectivamente. O quinto \n\nd\u00edgito est\u00e1 relacionado ao n\u00famero do v\u00e9rtice do padr\u00e3o e o \u00faltimo ao tipo do padr\u00e3o. \n\nA numera\u00e7\u00e3o dos v\u00e9rtices de cada padr\u00e3o inicia-se no ponto inicial mostrado na \n\nFigura 24 e continua no sentido hor\u00e1rio. Em rela\u00e7\u00e3o ao tipo do padr\u00e3o, a numera\u00e7\u00e3o \n\n\u00e9 a seguinte: A (1), B (2), C (3), D (4) e E (5). \n\nPara a realiza\u00e7\u00e3o da reconstru\u00e7\u00e3o, dois procedimentos s\u00e3o \n\nnecess\u00e1rios anteriormente: calibra\u00e7\u00e3o da c\u00e2mara e calibra\u00e7\u00e3o do projetor.  \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n130\n\n \nA calibra\u00e7\u00e3o do projetor consiste na determina\u00e7\u00e3o dos vetores \n\ndiretores de cada padr\u00e3o projetado e das coordenadas do projetor no referencial da \n\nc\u00e2mara  (Xp, Yp e Zp). Para realiza\u00e7\u00e3o desta etapa, necessita-se: \n\n- Determina\u00e7\u00e3o dos par\u00e2metros de orienta\u00e7\u00e3o interior a partir da \n\ncalibra\u00e7\u00e3o de c\u00e2mara; \n\n- Resse\u00e7\u00e3o espacial para determina\u00e7\u00e3o dos par\u00e2metros de \n\norienta\u00e7\u00e3o exterior. Esta etapa depende das coordenadas dos alvos fixados na placa \n\nde calibra\u00e7\u00e3o (pontos de apoio \n\n \n\nsistema global) e das coordenadas dos mesmos \n\npontos na imagem; \n\n- Calibra\u00e7\u00e3o do projetor: nesta etapa, calculam-se, inicialmente, as \n\ncoordenadas dos pontos projetados no referencial global, usando suas coordenadas \n\nimagem, os par\u00e2metros de orienta\u00e7\u00e3o exterior obtidos na etapa anterior e a equa\u00e7\u00e3o \n\nde colinearidade inversa. Com v\u00e1rias nuvens de pontos, que correspondem a v\u00e1rios \n\nplanos de proje\u00e7\u00e3o, calculam-se os elementos do projetor (REISS e TOMMASELLI, \n\n2004).  \n\nCom as coordenadas X, Y e Z no espa\u00e7o objeto de cada ponto, \n\ndetermina-se a coordenada Z\n\n \n\na partir do ajuste de um plano (Se\u00e7\u00e3o 5.2.7). \n\nCalculam-se, ent\u00e3o, as discrep\u00e2ncias entre as coordenadas Z obtidas da \n\nreconstru\u00e7\u00e3o e as coordenadas Z\n\n \n\nobtidas pela equa\u00e7\u00e3o do plano ajustado, e, \n\nposteriormente, o erro m\u00e9dio quadr\u00e1tico para todas as discrep\u00e2ncias. O programa de \n\nreconstru\u00e7\u00e3o 3D foi baseado na modelagem matem\u00e1tica desenvolvida na primeira \n\nvers\u00e3o do sistema de reconstru\u00e7\u00e3o (TOMMASELLI, 1997). \n\nComo os alvos do tipo A oferecem uma detec\u00e7\u00e3o e uma localiza\u00e7\u00e3o \n\nprecisa melhor que outros alvos, decidiu-se realizar dois experimentos. O primeiro \n\nexperimento consiste em determinar o erro m\u00e9dio quadr\u00e1tico usando apenas os \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n131\n\n \nv\u00e9rtices dos padr\u00f5es do tipo A enquanto o segundo experimento, calcula o erro \n\nm\u00e9dio quadr\u00e1tico para os v\u00e9rtices de todos os alvos.   \n\nOs erros m\u00e9dios quadr\u00e1ticos determinados por cada m\u00e9todo no \n\nexperimento um podem ser observados na Tabela 7.  \n\nTABELA 7 - M\u00e9todos usados e respectivos erros m\u00e9dios quadr\u00e1tico usando apenas \n\nos alvos do tipo A. \n\nCoeficientes da regress\u00e3o \npolinomial \n\n \n\nM\u00e9todo \nusado A00 A01 A10 \n\nEMQ \n(mm) \n\nErro \nm\u00e1ximo \n\n(mm) \n\nErro \nm\u00ednim\no (mm)\n\n \n\nMQ (PPD) -1083.599 0.0065506\n\n \n\n0.0807629\n\n \n\n0.84 5.042 -3.146 \n\nMQ (PR) -1083.570 0.0069474\n\n \n\n0.0806655\n\n \n\n0.44 3.341 0.000 \n\nDC (PR) -1083.611 0.0066874\n\n \n\n0.0810187\n\n \n\n0.39 2.019 0.000 \n\nMQ  M\u00e9todo dos m\u00ednimos quadrados            DC  Detector de cantos \nPPD \n\n \n\nPadr\u00f5es pr\u00e9-definidos                           PR \n\n \n\nPadr\u00f5es reamostrados   \n\nComo pode ser observado pela Tabela 7, o m\u00e9todo que obteve \n\nmelhores resultados foi o detector de cantos usando imagens reamostradas. Os \n\nresultados da localiza\u00e7\u00e3o precisa com alvos reamostrados foram melhores do que os \n\ncom alvos pr\u00e9-definidos, o que j\u00e1 era esperado, porque n\u00e3o ocorre o problema de \n\ndetec\u00e7\u00e3o com alvos de tamanhos diferentes, acarretando em incertezas nas \n\ncoordenadas dos v\u00e9rtices aproximados da etapa de detec\u00e7\u00e3o de alvos. Como o erro \n\nm\u00e9dio quadr\u00e1tico obtido com o m\u00e9todo dos m\u00ednimos quadrados com alvos pr\u00e9-\n\ndefinidos foi elevado em rela\u00e7\u00e3o aos outros m\u00e9todos, decidiu-se comparar somente \n\nos outros dois m\u00e9todos: detec\u00e7\u00e3o de cantos e MMQ usando alvos reamostrados \n\n(Tabela 8).  \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n132\n\n \nTABELA 8  Resultados da reconstru\u00e7\u00e3o usando o m\u00e9todo de detector de cantos para \n\ntodos os cinco padr\u00f5es. \n\nCoeficientes da regress\u00e3o \npolinomial \n\n \nM\u00e9todo \nusado A00 A01 A10 \n\nEMQ \n(mm) \n\nErro \nm\u00e1ximo \n\n(mm) \n\nErro \nm\u00ednimo \n(mm) \n\nErro \nrelativo\n\n \n\nMQ (PR)\n\n \n\n-1083.711\n\n \n\n0.0069474 0.0806655 0.71 6.349 0.000 1/1600 \n\nDC (PR)\n\n \n\n-1083,585\n\n \n\n0,0066416 0,0799038 0.52 5.776 0.000 1/2000 \n\n  \n\nA partir destes resultados, pode-se dizer que ambos os m\u00e9todos \n\nofereceram bons resultados. A partir do EMQ pode-se afirmar que a detec\u00e7\u00e3o de \n\ncantos proporcionou melhores resultados para este trabalho, por\u00e9m, a diferen\u00e7a \n\nentre os dois m\u00e9todos \u00e9 pequena, o que permite afirmar que ambos os m\u00e9todos s\u00e3o \n\nbons para a localiza\u00e7\u00e3o precisa. Al\u00e9m disso, estes experimentos mostraram que o \n\nm\u00e9todo de reamostragem dos padr\u00f5es \u00e9 significativamente melhor que o m\u00e9todo \n\nusando padr\u00f5es pr\u00e9-definidos.            \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n133\n\n \nCAP\u00cdTULO VII   \n\n7. CONCLUS\u00d5ES E RECOMENDA\u00c7\u00d5ES  \n\nO processo de classifica\u00e7\u00e3o de alvos por correspond\u00eancia de \n\npadr\u00f5es, apresentado neste trabalho, produziu bons resultados em imagens \n\ncoletadas com um sistema de luz estruturada. Como p\u00f4de ser observado, a \n\nidentifica\u00e7\u00e3o de alvos usando o m\u00e9todo baseado em \u00e1rea proporcionou melhores \n\nresultados do que o m\u00e9todo baseado em assinatura. Isto pode ser conseq\u00fc\u00eancia dos \n\npr\u00e9-processamentos realizados como persegui\u00e7\u00e3o de fronteiras ou da dimens\u00e3o dos \n\nalvos. Com rela\u00e7\u00e3o ao tipo de padr\u00f5es pr\u00e9-definidos a serem usados (template), \n\nnotou-se que o uso de imagens suavizadas proporcionou melhores resultados do \n\nque padr\u00f5es bin\u00e1rios. Para classifica\u00e7\u00e3o, os padr\u00f5es reamostrados em tempo real \n\nfoi o que apresentou os melhores resultados. \n\nCom rela\u00e7\u00e3o \u00e0 localiza\u00e7\u00e3o precisa usando o m\u00e9todo de \n\ncorrespond\u00eancia por m\u00ednimos quadrados, o m\u00e9todo de reamostragem em tempo real \n\ndos padr\u00f5es primitivos provou ser melhor que o m\u00e9todo usando alvos pr\u00e9-definidos e \n\nsuas inst\u00e2ncias est\u00e1ticas. Verificou-se, ainda, que a diferen\u00e7a entre os  resultados \n\nproporcionados pelos m\u00e9todos de detec\u00e7\u00e3o de cantos e de correspond\u00eancia por \n\nm\u00ednimos quadrados \u00e9 pequena, permitindo afirmar que ambos os m\u00e9todos s\u00e3o \n\nequivalentes para a localiza\u00e7\u00e3o precisa. Em ambos os casos os cantos dos alvos \n\nforam localizados com precis\u00e3o subpixel. \n\nAl\u00e9m disso, podem-se mencionar os seguintes problemas da \n\ncorrespond\u00eancia por m\u00ednimos quadrados: determina\u00e7\u00e3o dos valores aproximados \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n134\n\n \ndos cantos dos padr\u00f5es e a forma dos padr\u00f5es projetados. O problema na forma dos \n\npadr\u00f5es est\u00e1 relacionado a retas em que os gradientes s\u00e3o id\u00eanticos nestas \u00e1reas. \n\nUma analogia muito interessante a se mencionar neste trabalho est\u00e1 \n\nrelacionada \u00e0s duas metodologias comparadas para localiza\u00e7\u00e3o precisa. Ambos os \n\nm\u00e9todos (Moravec e correspond\u00eancia por padr\u00e3o) determinam coordenadas \n\naproximadas com precis\u00e3o pixel e estas mesmas coordenadas s\u00e3o refinadas pelos \n\nm\u00e9todos de F\u00f6rstner e correspond\u00eancia por m\u00ednimos quadrados.   \n\nOutras estrat\u00e9gias que podem ser usadas para melhorar os \n\nresultados s\u00e3o: \n\n- Utilizar o conhecimento \u00e0 priori a respeito das posi\u00e7\u00f5es e das \n\norienta\u00e7\u00f5es da c\u00e2mara e do projetor em rela\u00e7\u00e3o ao espa\u00e7o objeto \n\npara fazer a predi\u00e7\u00e3o de localiza\u00e7\u00e3o e aspecto do alvo; \n\n- Realizar uma predi\u00e7\u00e3o da rota\u00e7\u00e3o e da escala do alvo a partir do \n\nconhecimento das dist\u00e2ncias e dos \u00e2ngulos entre os alvos \n\nsegmentados e a partir disto reamostrar os alvos primitivos. Esta \n\nestrat\u00e9gia parece ser confi\u00e1vel, por\u00e9m, possui problemas em \u00e1reas \n\nde descontinuidades; \n\n- Realizar a detec\u00e7\u00e3o de padr\u00f5es unindo os dados obtidos pelos \n\ndetectores baseados em \u00e1rea e baseados em contornos (assinatura); \n\n- Realizar uma opera\u00e7\u00e3o de melhoramento local da imagem por meio \n\nda t\u00e9cnica de especifica\u00e7\u00e3o do histograma, o que deve melhorar a \n\nlocaliza\u00e7\u00e3o precisa dos alvos; \n\n- Melhorar o sistema de proje\u00e7\u00e3o e captura com a aquisi\u00e7\u00e3o de uma \n\nnova c\u00e2mara de melhor resolu\u00e7\u00e3o e constru\u00e7\u00e3o.  \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n135\n\n \nREFER\u00caNCIAS BIBLIOGR\u00c1FICAS  \n\nACKERMAN, F. High precision digital image correlation. Proceedings of the 39th \n\nPhotogrammetric Week, Stuttgart, 1984, p. 231-243.  \n\nANDRADE, J. B. Fotogrametria. Curitiba. SBEE, 1998.  \n\nARTERO, A.O. T\u00e9cnicas para a extra\u00e7\u00e3o autom\u00e1tica de fei\u00e7\u00f5es retas em \nimagens digitais. Disserta\u00e7\u00e3o de Mestrado, Curso de P\u00f3s Gradua\u00e7\u00e3o em Ci\u00eancias \nCartogr\u00e1ficas, Presidente Prudente, 1999, 117p.    \n\nBALLARD, D.H.; BROWN, C.M. Computer Vision, New Jersey: Prentice-Hall, 1982, \n522p.  \n\nBATTLE, J.; MOUADIBB, E.; SALVI, J. Recent progress in coded structured light \nas a technique to solve the correspondence problem: a survey. Pattern \nRecognition, vol. 31, n\u00ba 7, p. 963-982, 1996.  \n\nBOYER, K. L; KAK, A. C. Color-encoded structured light for rapid range sensing. \nIEEE Transactions Pattern Analysis machine Intelligence, vol. PAMI-9, n\u00ba 1, p. 14-28, \n1987.  \n\nCARRIHILL, B; HUMMEL, R. Experiments with the intensity ratio depth sensor. \nComputer Vision Graphics Image Processing, vol. 32, p. 337-358, 1985.   \n\nCOSTA, E. R.; TOMMASELLI, A.M.G.; GALO, M.. Incorpora\u00e7\u00e3o da pr\u00e9-an\u00e1lise no \nprocesso de correspond\u00eancia de pontos em Fotogrametria Digital. XXI \nCongresso Brasileiro de Cartografia, Belo Horizonte, 2003.  \n\nDALLAS, R.W.A. Architectural and archaelogical Photogrammetry. In: ATKINSON, \nK.B. Close range photogrammetry and machine vision. Department of \nPhotogrammetry and Surveying, University College London. Whittles Publishing, 1996.  \n\nDREWNIOK, C.; ROHR, K. Exterior orientation \n\n \n\nan automatic approach based \non fitting analytic landmark models. ISPRS JOURNAL OF PHOTOGRAMMETRY \n&amp; REMOTE SENSING 52, 132-145, Alemanha, 1997.  \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n136\n\n \nDUNN, S. M.; KEIZER, R. L. Measuring the area and volume of the human body \nwith structured light. IEEE TRANSACTIONS ON SYSTEMS, MAN, AND \nCYBERNETICS, vol. 19, n\u00ba 6, 1989. \nEL-HAKIM, S. F. Vision-based automated measurement techniques. In: \nATKINSON, K.B. Close range photogrammetry and machine vision. Department of \nPhotogrammetry and Surveying, University College London. Whittles Publishing, 1996.  \n\nFRASER, C.S. Industrial measurement applications. In: ATKINSON, K.B. Close \nrange photogrammetry and machine vision. Department of Photogrammetry and \nSurveying, University College London. Whittles Publishing, 1996.  \n\nGALO, M. Calibra\u00e7\u00e3o e Aplica\u00e7\u00e3o de C\u00e2maras Digitais. Curitiba, 1993. \nDisserta\u00e7\u00e3o de Mestrado, Curso de P\u00f3s-Gradua\u00e7\u00e3o em Ci\u00eancias Geod\u00e9sicas, \nUFPR.  \n\nGALO, M; TOZZI, C. L. Extra\u00e7\u00e3o de pontos com acur\u00e1cia subpixel em imagens \ndigitais. S\u00e9rie em Ci\u00eancias Geod\u00e9sicas. Universidade Federal do Paran\u00e1, Curso de \nP\u00f3s-Gradua\u00e7\u00e3o em Ci\u00eancias Geod\u00e9sicas, Curitiba, volume 2, 2002.   \n\nGEMAEL, C. Introdu\u00e7\u00e3o ao ajustamento de observa\u00e7\u00f5es: aplica\u00e7\u00f5es geod\u00e9sicas. \nCuritiba, UFPR, 1994, 319p.  \n\nGONZALES, R.C., Digital Image Processing, Addison Wesley, New York, 1993.  \n\nGONZALEZ, R. C.; WOODS, R. E. Processamento de Imagens Digitais, Tradu\u00e7\u00e3o: \nRoberto Marcondes C\u00e9sar Junior e Luciano da Fontoura Costa, Ed, Edgard Bl\u00fccher, \nS\u00e3o Paulo, 2000, 509p.  \n\nGRUEN, A. Least squares matching: a fundamental measurement algorithm. In: \nATKINSON, K. B. Close range photogrammetry and machine vision. Department of \nPhotogrammetry and Surveying, University College London. Whittles Publishing, \n1996.  \n\nHARALICK, R.; SHAPIRO, L. G. Computer and robot vision.  Reading: Addison-\nWesley Publishing Company, 1993, Vol. II, 630 p. \nHASEGAWA, J. K.; K\u00dcNZLI, R.; THOMAZ, R. C. C. Corrida contra o tempo: \nSalvamento arqueol\u00f3gico. Geoconverg\u00eancia, vol. 2, n\u00ba 2, 1999.  \n\nHATTORI, S.; AKIMOTO, K.; OKAMOTO, A.; HASEGAWA, H.; FRASER, C.S. \nDesign and Use of Coded Targets for Automatic Measurement with a CCD \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n137\n\n \nCamera. ASPRS Annual Conference. Portland, Oregon, American Society of \nPhotogrammetry &amp; Remote Sensing: 11, 2000.   \n\nHOWARD, A; PADGETT, C. A generalized approach to real-time pattern \nrecognition in sensed data. Pattern Recognition 32, 1999, p. 2069-2071.   \n\nJAIN, A. K.; DUIN, R.P.W.; MAO, J.  Statistical Pattern Recognition: A Review. In: \nIEEE Transactions on Pattern Analysis and Machine Intelligence, Vol: 22, No. 1, 5-\n37:264-323, January 2000.  \n\nKEEFE, M; RILEY, D. R. Capturing facial surface information. Photogrammetric \nEngineering and Remote Sensing, vol. 52, p. 1539-1548, 1986.  \n\nKRAUS, K. Photogrammetry \n\n \n\nFundamentals and Standard Processes. \nD\u00dcMMLER / BONN, volume 1, 1993.  \n\nMAAS, H.G. Robust Automatic Surface Reconstruction with Structured Light. \nIn: INTERNATIONAL ARCHIVES OF PHOTOGRAMMETRY AND REMOTE \nSENSING. Proceedings. P.709-713. Washington, 1992.  \n\nMAYR, W.; POTH, Z. Automatic generation of stereomodels. JOINT ISPRS \nWORKSHOP WG III/2 AND IC WG II/III. Stockholm, Sweden, 1995.  \n\nMIKHAIL, E. M., BETHEL, J. S, MCGLONE, J. C. Introduction to Modern \nPhotogrammetry. Ed. John Wiley &amp; Sons, Inc. New York, 2001.  \n\nMUSTAFA, A. A. Y.; SHAPIRO, L.G.; GANTER, M.A. 3D object identification with \ncolor and curvature signatures. Pattern recognition, 1999, 339-355.  \n\nNEWTON, I.; MITCHELL, H.L. Medical Photogrammetry. In: ATKINSON, K. B. \nClose range photogrammetry and machine vision. Department of Photogrammetry \nand Surveying, University College London. Whittles Publishing, 1996.  \n\nOOSTERLINCK, A.; VUYLSTEKE, P. Range image acquisition with a single \nbinary-encoded light pattern. IEEE Transactions on pattern analysis and machine \nintelligence, vol. 12, n\u00ba 2, 1990.  \n\nOTSU, N. A threshold selection method from gray-level histogram. IEEE \nTransactions on System Man Cybernetics, Vol. SMC-9, n\u00ba 1, 1979, pp. 62-66. \n\n\n\n  \n\nChristiane N. C. Kokubum \n\n138\n\n  \nREISS, M.L.L; TOMMASELLI, A.M.G. Calibra\u00e7\u00e3o de um projetor de padr\u00f5es para \nreconstru\u00e7\u00e3o 3D por luz estruturada. I SIMGEO \n\n \nSimp\u00f3sio de Ci\u00eancias \n\nGeod\u00e9sicas e tecnologias da Geoinforma\u00e7\u00e3o, Recife, 2004.  \n\nSCALCO, P.A.P. Determina\u00e7\u00e3o autom\u00e1tica de correspond\u00eancia em um sistema \nde reconstru\u00e7\u00e3o com luz estruturada. Disserta\u00e7\u00e3o de Mestrado. Curso de P\u00f3s \nGradua\u00e7\u00e3o em Ci\u00eancias Cartogr\u00e1ficas, FCT/UNESP, Presidente Prudente, 2000.  \n\nSCHALKOFF, R.J. Digital image processing and computer vision. Department of \nElectrical and Computer Engineering Clemson University, 1989.  \n\nSCHENK, T. Digital Photogrammetry. The Ohio State University, volume 1, 1999.  \n\nSONKA, M.; VAKLAV, H; BOYLE, R. Image processing, analysis, and machine \nvision. PWS PUBLISHING. 770p, 1998.  \n\nSPRING: Tutorial de Geoprocessamento. Descri\u00e7\u00e3o geral do SPRING. \nDispon\u00edvel em:&lt;http://www.dpi.inpe.br/spring/teoria/index.html>. Acesso em: 03 de \nmar\u00e7o de 2003.  \n\nTING, A.; LEUNG, M. K. H.. Form recognition using linear structure. Pattern \nRecognition 32, 1999, p. 645-656.   \n\nTOMMASELLI, A.M.G. Implementa\u00e7\u00e3o de Um Sistema Fotogram\u00e9trico Digital \nPara Reconstru\u00e7\u00e3o de Imagens. Relat\u00f3rio Final de Bolsa de Pesquisa, n\u00edvel 2c, \napresentado ao CNPq, Faculdade de Ci\u00eancias e Tecnologia, Unesp, Presidente \nPrudente, 1997, 115p.  \n\nTOMMASELLI, A. M. G.; GALO, M.; HASEGAWA, J. K. Modernas Tecnologias de \nAquisi\u00e7\u00e3o de Imagens em Fotogrametria. BOLETIM DE CI\u00caNCIAS \nGEOD\u00c9SICAS. Curitiba, v. 6, n\u00ba 1, p. 49-64, 2000.  \n\nTOMMASELLI, A. M. G.; GALO, M.; HASEGAWA, J. K. Desenvolvimento de uma \nbiblioteca de fun\u00e7\u00f5es e classes para Fotogrametria. XXI Congresso Brasileiro de \nCartografia, Belo Horizonte, 2003.  \n\nWANG, Y. F.; MITICHE, A.; AGGARWAL, J. K. Computation of surface orientation \nand structure of objects using grid coding. IEEE Transactions on Pattern Analysis \nMachine Intelligence, vol. PAMI-9, n\u00ba 1, p. 129-137, 1987. \n\nhttp://www.dpi.inpe.br/spring/teoria/index.html>\n\n\n  \n\nChristiane N. C. Kokubum \n\n139\n\n \nWOLF, P.R. Elements of Photogrammetry, with air photo interpretation and \nremote sensing. McGRAW-HILL Internation Editions, 1983.  \n\n\n\nThis document was created with Win2PDF available at http://www.daneprairie.com.\nThe unregistered version of Win2PDF is for evaluation or non-commercial use only.\n\nhttp://www.daneprairie.com\n\n\tCAPA\n\tFOLHA DE ROSTO\n\tRESUMO\n\tABSTRACT\n\tLISTA DE FIGURAS\n\tLISTA DE TABELAS\n\tCONTE\u00daDO\n\tLISTA DE SIGLAS\n\tCAP\u00cdTULO I\n\t1. INTRODU\u00c7\u00c3O\n\t1.1. Considera\u00e7\u00f5es iniciais\n\t1.2. Objetivos\n\t1.3 . Estrutura do trabalho\n\n\n\tCAP\u00cdTULO II\n\t2. IMAGENS DIGITAIS: AQUISI\u00c7\u00c3O E PROCESSAMENTO\n\t2.1. Imagem Digital\n\t2.2. C\u00e2maras digitais\n\t2.3. Sistemas de coordenadas\n\t2.4. Efeitos sistem\u00e1ticos\n\t2.5. Melhoramento de contraste linear\n\t2.6. Segmenta\u00e7\u00e3o\n\t2.7. Limiariza\u00e7\u00e3o\n\t2.8. Detec\u00e7\u00e3o de bordas\n\t2.9. Detector de cantos\n\n\n\tCAP\u00cdTULO III\n\t3. FOTOGRAMETRIA \u00c0 CURTA DIST\u00c2NCIA\n\t3.1. Aplica\u00e7\u00f5es da Fotogrametria \u00e0 curta dist\u00e2ncia\n\t3.2. Luz estruturada\n\n\n\tCAP\u00cdTULO IV\n\t4. RECONHECIMENTO DE PADR\u00d5ES\n\t4.1. Correspond\u00eancia por padr\u00e3o (Template matching)\n\t4.2. Correspond\u00eancia por assinatura\n\t4.3. Outras t\u00e9cnicas para o reconhecimento de padr\u00f5es\n\n\n\tCAP\u00cdTULO V\n\t5. MATERIAIS E M\u00c9TODOS\n\t5.1. Materiais\n\t5.2. M\u00e9todos\n\n\n\tCAP\u00cdTULO VI\n\t6. DESENVOLVIMENTO E IMPLEMENTA\u00c7\u00c3O\n\t6.1. Gera\u00e7\u00e3o autom\u00e1tica de padr\u00f5es\n\t6.2. Limiariza\u00e7\u00e3o local\n\t6.3. Segmenta\u00e7\u00e3o\n\t6.4. Classifica\u00e7\u00e3o\n\t6.5. Localiza\u00e7\u00e3o precisa\n\n\n\tCAP\u00cdTULO VII\n\t7. CONCLUS\u00d5ES E RECOMENDA\u00c7\u00d5ES\n\tREFER\u00caNCIAS BIBLIOGR\u00c1FICAS"}]}}}