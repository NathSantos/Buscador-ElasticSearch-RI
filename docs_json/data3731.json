{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.08524"}, {"@name": "filename", "#text": "13362_000428231.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNIVERSIDADE FEDERAL DO RIO GRANDE DO SUL \nINSTITUTO DE INFORM\u00c1TICA\n\n PROGRAMA DE P\u00d3S-GRADUA\u00c7\u00c3O EM COMPUTA\u00c7\u00c3O \n \n\n \n \n \n \n \n \n \n\nVisualiza\u00e7\u00e3o em Tempo Real  \nde Dados Volum\u00e9tricos Din\u00e2micos  \n\nusando Hardware Gr\u00e1fico \n \n \n \n\npor \n \n\nAL\u00c9CIO PEDRO DELAZARI BINOTTO \n \n\n \n \n \n \n \n \n \n \n \n \n\nDisserta\u00e7\u00e3o submetida \u00e0 avalia\u00e7\u00e3o como \nrequisito parcial para a obten\u00e7\u00e3o do grau de \n\nMestre em Ci\u00eancia da Computa\u00e7\u00e3o \n \n \n \n \n\nProf.  Dr. Jo\u00e3o Luiz Dihl Comba \nOrientador \n\n \nProfa. Dra. Carla Maria Dal Sasso Freitas \n\nCo-Orientadora \n \n \n \n \n \n\nPorto Alegre, mar\u00e7o de 2003. \n\n\n\n 2\n\nCIP \u2013 CATALOGA\u00c7\u00c3O NA PUBLICA\u00c7\u00c3O \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\nBinotto, Al\u00e9cio Pedro Delazari \n\nVisualiza\u00e7\u00e3o em Tempo Real de Dados Volum\u00e9tricos\nDin\u00e2micos Usando Hardware Gr\u00e1fico / por Al\u00e9cio Pedro Delazari\nBinotto. \u2013 Porto Alegre: PPGC da UFRGS, 2003. \n\n73f.: il. \n\nDisserta\u00e7\u00e3o (Mestrado) \u2013 Universidade Federal do Rio Grande\ndo Sul. Programa de P\u00f3s-Gradua\u00e7\u00e3o em Computa\u00e7\u00e3o, Porto Alegre,\nBR-RS, 2003. Orientador: Comba, Jo\u00e3o Luiz Dihl. Co-Orientadora:\nFreitas, Carla Maria Dal Sasso. \n\n1. Visualiza\u00e7\u00e3o Volum\u00e9trica. 2. Compress\u00e3o de Dados. 3.\nHardware Gr\u00e1fico. 4. Texturas 3D. 5. Visualiza\u00e7\u00e3o Cient\u00edfica. I.\nComba, Jo\u00e3o Luiz Dihl. II. Freitas, Carla Maria Dal Sasso. III. T\u00edtulo. \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\nUNIVERSIDADE FEDERAL DO RIO GRANDE DO SUL \n\nReitora: Profa. Wrana Panizzi \n\nPr\u00f3-Reitor de Ensino: Prof. Jos\u00e9 Carlos Ferraz Hennemann \n\nPr\u00f3-Reitora Adjunta de P\u00f3s-Gradua\u00e7\u00e3o: Profa. Joc\u00e9lia Grazia \n\nDiretor do Instituto de Inform\u00e1tica: Prof. Philippe Olivier Alexandre Navaux \n\nCoordenador do PPGC: Prof. Carlos Alberto Heuser \n\nBibliotec\u00e1ria-Chefe do Instituto de Inform\u00e1tica: Beatriz Regina Bastos Haro \n\n \n\n\n\n 3\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\n\u201cSe buscas resultados distintos, nunca haja sempre da mesma maneira.\u201d \nAlbert Einstein (1879-1955) \n\n \nDedico este trabalho aos meus pais, Jurandyr e Mercedes, e a Maria Clara \n\n \n\n\n\n 4\n\nAgradecimentos \nAgrade\u00e7o aos meus pais, Jurandyr e Mercedes, e toda a minha fam\u00edlia pelo \n\nimensur\u00e1vel e incessante apoio durante esta jornada. \n\nA Maria Clara pelo incentivo e completa compreens\u00e3o durante este per\u00edodo de \nextrema dedica\u00e7\u00e3o. \n\nA Deus, por ter me guiado e me concedido muita sa\u00fade. \n\nAgrade\u00e7o de maneira veemente aos meus orientadores, Prof. Jo\u00e3o Comba e Profa. \nCarla Freitas, pela disponibilidade, presen\u00e7a atuante, incentivo, conhecimento e pela \nconviv\u00eancia durante estes anos, onde obtive oportunidade de crescer assimilando suas \nin\u00fameras li\u00e7\u00f5es n\u00e3o s\u00f3 profissionais, mas tamb\u00e9m de vida. Obrigado realmente por \npropiciarem este amadurecimento. \n\nAgrade\u00e7o a todos os professores do Grupo de Computa\u00e7\u00e3o Gr\u00e1fica pelos \nconselhos e questionamentos. \n\nA todos os meus colegas do Grupo de Computa\u00e7\u00e3o Gr\u00e1fica, em especial a Wilson \nGavi\u00e3o, Isabel Siqueira, Carlos Dietrich, Stefan Zanona e Christian Azambuja pelas \ndicas t\u00e9cnicas. \n\nA todos os meus amigos, em especial Bruno, Carolina, Cl\u00e1udio, Cl\u00f3vis, D\u00e9lcio, \nF\u00e1bio Braga, F\u00e1bio Lobo, C\u00e9sar, Dalton, Ot\u00e1vio, Fabr\u00edcio e Vin\u00edcius, muito obrigado. \n\nAgrade\u00e7o ao CNPq pelo apoio financeiro recebido. \n\n \n\n \n\n\n\n 5\n\nSum\u00e1rio \nLista de Abreviaturas .................................................................................... 7 \nLista de Figuras ............................................................................................. 8 \nLista de Tabelas........................................................................................... 10 \nResumo ........................................................................................................ 11 \nAbstract ....................................................................................................... 12 \n1 Introdu\u00e7\u00e3o............................................................................................. 13 \n2 Visualiza\u00e7\u00e3o Volum\u00e9trica e Compress\u00e3o............................................. 16 \n2.1 Introdu\u00e7\u00e3o .............................................................................................................16 \n2.2 T\u00e9cnicas de Visualiza\u00e7\u00e3o Volum\u00e9trica................................................................17 \n2.2.1 Extra\u00e7\u00e3o de Superf\u00edcies ..........................................................................................19 \n2.2.2 Visualiza\u00e7\u00e3o Direta de Volumes ............................................................................23 \n2.3 Compress\u00e3o de Dados Volum\u00e9tricos...................................................................31 \n2.3.1 Visualiza\u00e7\u00e3o Volum\u00e9trica com Multiresolu\u00e7\u00e3o Baseada em Octrees como \n\nRepresenta\u00e7\u00e3o de Texturas .....................................................................................31 \n2.3.2 Mapeamento de Texturas Adaptativas ...................................................................32 \n2.3.3 \u00c1rvores TSP ...........................................................................................................34 \n\n3 Hardware Gr\u00e1fico ................................................................................. 36 \n3.1 Unidade de Programa\u00e7\u00e3o de V\u00e9rtices (vertex shader) .......................................37 \n3.1.1 Efeitos Especiais.....................................................................................................38 \n3.1.2 Exemplo em Cg ......................................................................................................38 \n3.2 Unidade de Programa\u00e7\u00e3o de Fragmentos (pixel ou fragment shader) .............40 \n3.2.1 Unidade de Programa\u00e7\u00e3o de Texturas (texture shader)..........................................40 \n3.2.2 Efeitos Especiais.....................................................................................................42 \n3.2.3 Exemplo em CG .....................................................................................................42 \n\n4 Compress\u00e3o e Visualiza\u00e7\u00e3o de Dados Volum\u00e9tricos Din\u00e2micos  \nUsando Texturas 3D ............................................................................ 44 \n\n4.1 Compress\u00e3o ...........................................................................................................44 \n4.1.1 Propriedades B\u00e1sicas dos Dados ............................................................................44 \n4.1.2 Dados de Entrada para o Mecanismo .....................................................................45 \n4.1.3 O M\u00e9todo de Compress\u00e3o Gritex ...........................................................................46 \n4.2 Descompress\u00e3o e Visualiza\u00e7\u00e3o.............................................................................51 \n4.2.1 Detalhes de implementa\u00e7\u00e3o ....................................................................................54 \n\n5 Resultados............................................................................................. 57 \n5.1 Gera\u00e7\u00e3o dos Dados Volum\u00e9tricos Din\u00e2micos .....................................................57 \n5.2 Visualiza\u00e7\u00e3o dos Dados Volum\u00e9tricos.................................................................58 \n5.2.1 Visualiza\u00e7\u00e3o Usando Texturas 2D e 3D Simples ...................................................59 \n5.2.2 Visualiza\u00e7\u00e3o Usando a T\u00e9cnica de Compress\u00e3o Gritex .........................................61 \n \n \n\n \n\n\n\n 6\n\n6 Conclus\u00e3o ............................................................................................. 65 \nAnexo Real-Time Volume Rendering of Dynamic Data Using Graphics  \n\nHardware ............................................................................................. 66 \nBibliografia.................................................................................................. 71 \n\n \n\n\n\n 7\n\nLista de Abreviaturas \n       \n\nAPI Application  Program Interface \n\nCFD Computational Fluid Dynamics \n\nCg C for Graphics \n\nGPU Graphics Processing Unit \n\nRGBA Sistema de cor Red Green Blue Alpha \n\n \n\n \n \n \n\n \n\n\n\n 8\n\nLista de Figuras  \nFIGURA 1.1 - Processos envolvidos na compress\u00e3o e visualiza\u00e7\u00e3o de dados 4D .............. 15 \nFIGURA 2.1 - Grade ou matriz tridimensional representando um volume ......................... 16 \nFIGURA 2.2 - Visualiza\u00e7\u00e3o de tr\u00eas instantes de tempo de dados volum\u00e9tricos .................. 17 \nFIGURA 2.3 - Representa\u00e7\u00e3o esquem\u00e1tica das t\u00e9cnicas de visualiza\u00e7\u00e3o volum\u00e9trica ........ 18 \nFIGURA 2.4 - Processo para visualiza\u00e7\u00e3o volum\u00e9trica ....................................................... 19 \nFIGURA 2.5 - Algoritmo de conex\u00e3o de contornos............................................................. 20 \nFIGURA 2.6 - Modelos que podem ser gerados para um mesmo par de fatias ................... 20 \nFIGURA 2.7 - Fun\u00e7\u00e3o de interpola\u00e7\u00e3o para cada v\u00e9rtice..................................................... 22 \nFIGURA 2.8 - Os 15 casos b\u00e1sicos do algoritmo de marching cubes ................................ 23 \nFIGURA 2.9 - Esquema gen\u00e9rico do algoritmo de ray casting front-to-back .................... 25 \nFIGURA 2.10 - Footprint, onde \u00e1reas escuras indicam maior intensidade .......................... 26 \nFIGURA 2.11 - Esquema do algoritmo shear-warp ............................................................ 27 \nFIGURA 2.12 - Fatias ortogonais a cada eixo...................................................................... 28 \nFIGURA 2.13 - Mapeamento de textura 2D ........................................................................ 28 \nFIGURA 2.14 - Aplica\u00e7\u00e3o da textura 3D em uma seq\u00fc\u00eancia de pol\u00edgonos ......................... 29 \nFIGURA 2.15 - Visualiza\u00e7\u00e3o usando textura 3D: (a) planos ortogonais ao olhar do leitor \n\n(paralelos \u00e0 folha) e (b) planos ortogonais a dire\u00e7\u00e3o de observa\u00e7\u00e3o de O ... 30 \nFIGURA 2.16 - Mapeamento de um \u00fanico pol\u00edgono a textura 3D ...................................... 30 \nFIGURA 2.17 - Esquema geral do m\u00e9todo de visualiza\u00e7\u00e3o volum\u00e9trica com \n\nmultiresolu\u00e7\u00e3o baseada em octree ................................................................ 31 \nFIGURA 2.18 - Ilustra\u00e7\u00e3o em 2D do mapeamento de texturas adaptativas. (a) \u00cdndice: \n\nfator de escala e coordenadas para os dados comprimidos. (b) Dados \ncomprimidos ................................................................................................. 33 \n\nFIGURA 2.19 - Visualiza\u00e7\u00e3o de texturas na t\u00e9cnica de mapeamento adaptativo de \ntexturas ......................................................................................................... 33 \n\nFIGURA 2.20 - Textura 3D de \u00edndices (a) e textura 3D com dados comprimidos .............. 34 \nFIGURA 2.21 - Exemplo de \u00e1rvore TSP para dados 2D, representado 4 instantes de \n\ntempo ............................................................................................................ 35 \nFIGURA 3.1 - Fluxo de dados e unidades program\u00e1veis do hardware ............................... 36 \nFIGURA 3.2 - Modelo do vertex shader .............................................................................. 37 \nFIGURA 3.3 - Exemplo do efeito especial (a) e seu respectivo c\u00f3digo em CG (b) para \n\nvertex shader: Repulsive Ptential Fields ..................................................... 39 \nFIGURA 3.4 - Fragment shader do hardware GeForce4 .................................................... 41 \nFIGURA 3.5 - Par de planos adjacentes .............................................................................. 42 \nFIGURA 3.6 - Exemplo do efeito especial (a) e seu respectivo c\u00f3digo em CG para \n\nfragment shader: environment mapping....................................................... 43 \nFIGURA 4.1 - Exemplo de coer\u00eancia espacial e temporal................................................... 45 \nFIGURA 4.2 - Volume de dados .......................................................................................... 46 \nFIGURA 4.3 - Esquema geral do m\u00e9todo de compress\u00e3o.................................................... 46 \nFIGURA 4.4 - Estrutura de uma octree................................................................................ 47 \nFIGURA 4.5 - Estrutura de um grid para o n\u00edvel 2 .............................................................. 47 \nFIGURA 4.6 - Grid para um volume de 1283. No lado esquerdo da \u00e1rvore tem-se o \n\ntamanho de cada c\u00e9lula e no lado direito o n\u00edvel da subdivis\u00e3o \njuntamente com a quantidade m\u00e1xima comport\u00e1vel de sub-volumes .......... 48 \n\nFIGURA 4.7 - Esquema de armazenamento da primeira etapa de compress\u00e3o................... 49 \nFIGURA 4.8 - Esquema geral de armazenamento da compress\u00e3o....................................... 50 \nFIGURA 4.9 - Esquema hash utilizado................................................................................ 51 \n\n \n\n\n\n 9\n\nFIGURA 4.10 - C\u00e1lculo para a recupera\u00e7\u00e3o da origem de um tempo na textura de \n\u00edndices ........................................................................................................... 52 \n\nFIGURA 4.11 - Esquema b\u00e1scio do texture shader para o m\u00e9todo de compress\u00e3o............. 52 \nFIGURA 4.12 - C\u00e1lculo para recupera\u00e7\u00e3o dos refinamentos ............................................... 53 \nFIGURA 4.13 - Processo geral de visualiza\u00e7\u00e3o para um instante de tempo tn..................... 54 \nFIGURA 4.14 - C\u00f3digo em CG para visualiza\u00e7\u00e3o (descompress\u00e3o) ................................... 56 \nFIGURA 5.1 - Fases do descarregamento ........................................................................... 57 \nFIGURA 5.2 - Estrutura da grade e seq\u00fc\u00eancia de planos de dados gerados pelo \n\nsimulador ...................................................................................................... 58 \nFIGURA 5.3 - Visualiza\u00e7\u00e3o acumula\u00e7\u00e3o total, representada por uma textura 2D............... 59 \nFIGURA 5.4 - Visualiza\u00e7\u00e3o individualizada de quatro instantes de tempo, com texturas \n\n3D ................................................................................................................. 60 \nFIGURA 5.5 - Compara\u00e7\u00e3o entre visualiza\u00e7\u00f5es usando texturas 3D simples e usando a \n\nt\u00e9cnica Gritex: s\u00e3o ilustrados os instantes de tempo 5 , 21 e 35, com as \nimagens \u00e0 esquerda sendo geradas com texturas 3D simples e as da \ndireita  usando o m\u00e9todo Gritex ................................................................... 62 \n\nFIGURA 5.6 - Texturas 3D de \u00edndice e refinamento produzidas por Gritex com n\u00edvel 4 \nde parada....................................................................................................... 63 \n\nFIGURA 5.7 - Texturas 3D de \u00edndice e refinamento produzidas por Gritex com n\u00edvel 5 \nde parada....................................................................................................... 63 \n\n \n \n \n \n\n \n\n\n\n 10\n\nLista de Tabelas \nTABELA 5.1 - Compara\u00e7\u00e3o dos resultados do m\u00e9todo de compress\u00e3o .............................. 64 \nTABELA 5.2 - An\u00e1lise de desempenho de visualiza\u00e7\u00e3o em frames por segundo ............... 64 \n \n \n \n\n \n\n\n\n 11\n\nResumo \nDados volum\u00e9tricos temporais s\u00e3o usados na representa\u00e7\u00e3o de fen\u00f4menos f\u00edsicos \n\nem v\u00e1rias aplica\u00e7\u00f5es de visualiza\u00e7\u00e3o cient\u00edfica, pois tais fen\u00f4menos s\u00e3o complexos, \nalteram-se com o tempo e n\u00e3o possuem uma forma de representa\u00e7\u00e3o definida. Uma \nsolu\u00e7\u00e3o \u00e9 usar amostragens sobre um espa\u00e7o de forma geom\u00e9trica simples que cont\u00e9m o \nfen\u00f4meno (um cubo, por exemplo), discretizado ao longo de uma grade em c\u00e9lulas de \nmesmo formato e usualmente chamado de volume de amostragem. Este volume de \namostragem representa um instante da representa\u00e7\u00e3o do fen\u00f4meno e, para representar \ndados temporais, simplesmente enumera-se tantos volumes quanto forem as diferentes \ninst\u00e2ncias de tempo. Esta abordagem faz com que a representa\u00e7\u00e3o seja extremamente \ncustosa, necessitando de t\u00e9cnicas de representa\u00e7\u00e3o de dados para comprimir e \ndescomprimir os mesmos. \n\nEste trabalho apresenta uma nova abordagem para compress\u00e3o de volumes de \ndados temporais que permite a visualiza\u00e7\u00e3o em tempo real destes dados usando \nhardware gr\u00e1fico. O m\u00e9todo de compress\u00e3o usa uma representa\u00e7\u00e3o hier\u00e1rquica dos \nv\u00e1rios volumes de dados dentro da mem\u00f3ria do hardware gr\u00e1fico, referenciados pelo \nhardware como texturas 3D. O m\u00e9todo de compress\u00e3o tem melhor desempenho para \ndados volum\u00e9tricos esparsos e com alto grau de coer\u00eancia (espacial e temporal). A \ndescompress\u00e3o destes dados \u00e9 feita por programas especiais que s\u00e3o executados no \npr\u00f3prio hardware gr\u00e1fico.  \n\nUm estudo de caso usando o m\u00e9todo de compress\u00e3o/descompress\u00e3o proposto \u00e9 \napresentado com dados provenientes do Projeto MAPEM (Monitoramento Ambiental \nem Atividades de Perfura\u00e7\u00e3o Explorat\u00f3ria Mar\u00edtima). O objetivo do projeto \u00e9 propor \numa metodologia para o monitoramento dos efeitos das descargas de materiais no \necossistema marinho durante a perfura\u00e7\u00e3o de um po\u00e7o de petr\u00f3leo. Para estimar certos \ndescarregamentos de fluidos, o projeto usa um simulador CFD que permite mostrar tais \ndescarregamentos, gerando grades planares e uniformes 2D ou 3D em qualquer instante \nde tempo durante a simula\u00e7\u00e3o.  \n \nPalavras-Chaves: visualiza\u00e7\u00e3o volum\u00e9trica, compress\u00e3o de dados, hardware gr\u00e1fico, \ntexturas 3D, visualiza\u00e7\u00e3o cient\u00edfica. \n \n\n \n\n\n\n 12\n\nTITLE: \u201cREAL-TIME VISUALIZATION OF DYNAMIC VOLUMETRIC DATA \nUSING GRAPHICS HARDWARE\u201d \n\n \nAbstract \n\nTemporal volumetric data are used in many scientific visualization applications for \nrepresenting physical phenomena, which may have complex shapes, change with time \nand do not have a closed representation form. Sampling is one solution that can be used \nin these cases, using a simple spatial shape that contains the phenomena (e. g. cube), \ndiscretized along an uniform grid. This sampling volume represents one instance of the \nphenomena, and to represent temporal data, one approach is to enumerate as many \nvolumes as time instances. This approach leads to a costly representation, demanding \ndata representation techniques to compress and decompress these data. \n\nThis work presents a novel approach to compress temporal volumetric data \nsuitable for real-time volume rendering using graphics hardware. The compression \ntechnique uses an hierarchical representation of data inside the graphics board memory \n(referenced as 3D textures). The compression method has better performance in sparse \nand highly coherent (spatial or temporal) data sets. The decompression is done by \nspecial programs that run inside the graphics board. \n\nA case study using the compression/decompression scheme is presented using data \nfrom the MAPEM Project (Environment Monitoring of Off-Shore Oil Prospecting \nActivities and Exploration). The project goal is to evaluate the impact in the marine \necosystem of cuttings discharged during oil well drilling activities. In order to estimate a \ndrilling behavior, the project uses a CFD simulator that samples the dispersion of \ndischarged fluids and materials, producing uniform 2D or 3D grid planar sections at any \ntime instance of  the simulation. \n\n \nKeywords: volume rendering, data compression, graphics hardware, 3D textures, \nscientific visualization. \n \n \n \n \n \n \n \n \n \n\n \n\n\n\n 13\n\n1 Introdu\u00e7\u00e3o \nO estudo de fen\u00f4menos f\u00edsicos \u00e9 de grande import\u00e2ncia em v\u00e1rias \u00e1reas da ci\u00eancia. \n\nModelos computacionais matem\u00e1ticos s\u00e3o desenvolvidos com base em equa\u00e7\u00f5es que \ntentam aproximar da realidade, na melhor forma poss\u00edvel, cada fen\u00f4meno. A \nrepresenta\u00e7\u00e3o de escoamento de fluidos, em particular, \u00e9 feita por v\u00e1rios grupos de \npesquisa da \u00e1rea de modelagem de fluidos computacionais (CFD - Computational Fluid \nDynamics). O comportamento dos fluidos \u00e9 usualmente governado por um conjunto de \nequa\u00e7\u00f5es diferenciais denominadas equa\u00e7\u00f5es de Navier-Stokes, mas a representa\u00e7\u00e3o \ngeom\u00e9trica destes dados \u00e9 complexa, n\u00e3o possuem uma forma definida e, sobretudo, \nalteram-se com o tempo. \n\nT\u00e9cnicas de amostragem de dados s\u00e3o usadas freq\u00fcentemente em casos onde a \nfun\u00e7\u00e3o de modelagem \u00e9 complexa. Um espa\u00e7o de forma geom\u00e9trica simples, que \ncontenha o fen\u00f4meno, \u00e9 escolhido (um cubo, por exemplo) e discretizado ao longo de \numa grade contendo c\u00e9lulas de mesmo formato. Cada um desses volumes de \namostragem, como s\u00e3o usualmente chamados, corresponde a um instante da \nrepresenta\u00e7\u00e3o do fen\u00f4meno. Para representar dados temporais, s\u00e3o enumerados tantos \nvolumes quantas forem as diferentes inst\u00e2ncias de tempo. Assim, o objetivo deste \ntrabalho \u00e9 desenvolver uma forma de representar esses dados eficientemente, para um \nprocesso de visualiza\u00e7\u00e3o interativa. \n\nUm exemplo da modelagem de escoamento de fluidos encontra-se no Projeto \nMAPEM (Monitoramento Ambiental em Atividades de Perfura\u00e7\u00e3o Explorat\u00f3ria \nMar\u00edtima)1. Neste projeto, que ser\u00e1 o estudo de caso deste trabalho, analisa-se o \ncomportamento e o impacto do descarregamento de res\u00edduos da perfura\u00e7\u00e3o de po\u00e7os de \npetr\u00f3leo em um ecossistema marinho. Em uma de suas fases, as perfura\u00e7\u00f5es envolvem o \nuso de um fluido n\u00e3o-aquoso (prejudicial ao meio ambiente) e os cascalhos \ndescarregados, apesar de lavados previamente, est\u00e3o impregnados com certa quantidade \ndesse fluido. Tendo em vista a import\u00e2ncia da preserva\u00e7\u00e3o do meio ambiente, as \nempresas de extra\u00e7\u00e3o de petr\u00f3leo em alto mar devem se preocupar com o \nmonitoramento das subst\u00e2ncias e materiais descarregados durante os processos de \nperfura\u00e7\u00e3o explorat\u00f3ria para extra\u00e7\u00e3o de petr\u00f3leo. As altas multas decorrentes de \ncontamina\u00e7\u00e3o aumentam consideravelmente a import\u00e2ncia desse monitoramento. \n\nNesse projeto, um simulador denominado OOC (Offshore Operators Commitee \nMud and Produced Water Discharge Model) \u00e9 usado para prever a dispers\u00e3o e a \ndeposi\u00e7\u00e3o no fundo do mar dos materiais descarregados durante as perfura\u00e7\u00f5es de \npetr\u00f3leo (Brandsma e Smith, 1999). Os dados gerados por este simulador s\u00e3o escalares e \nrepresentam concentra\u00e7\u00f5es de material por unidade de \u00e1rea em grades 2D (se\u00e7\u00f5es \nplanares), 3D (espaciais) ou 4D (espa\u00e7o-temporais). Para um melhor entendimento \ndestes resultados, uma apresenta\u00e7\u00e3o visual de tais dados \u00e9 feita (Comba et al., 2002) \nusando t\u00e9cnicas de Visualiza\u00e7\u00e3o Cient\u00edfica (Brodlie et al., 1992) ou, mais \nespecificamente, Visualiza\u00e7\u00e3o Volum\u00e9trica  (Kaufman, 1991 e Brodlie e Wood, 2001).  \n\nA representa\u00e7\u00e3o eficiente de tais dados torna-se crucial quando aplicada em \nconjunto com uma t\u00e9cnica de visualiza\u00e7\u00e3o volum\u00e9trica. Obviamente, a visualiza\u00e7\u00e3o de \ngrades 4D \u00e9 mais complexa que grades 2D ou 3D, sendo alvo de pesquisas recentes \n(Shen et al., 1999, Ellsworth et al., 2000 e Kraus e Ertl, 2002). O foco do presente \n\n                                                 \n1 MAPEM \u00e9 um projeto financiado pelo programa FINEP/CTPetro e ser\u00e1 abordado em maior detalhe no \ncap\u00edtulo 5. \n\n \n\n\n\n 14\n\ntrabalho consiste em apresentar uma nova abordagem para a representa\u00e7\u00e3o comprimida \ndestes dados, visualizando-os em tempo real usando hardware gr\u00e1fico.  \n\nO desenvolvimento de hardware gr\u00e1fico nos \u00faltimos anos tem resultado em \nmelhorias de performance e em novas ou mais gen\u00e9ricas caracter\u00edsticas em rela\u00e7\u00e3o \u00e0s \ngera\u00e7\u00f5es de hardware anteriores. Recentemente, a \u00eanfase no projeto de hardware \ngr\u00e1fico tem focado o desenvolvimento de novas funcionalidades, dado que os n\u00edveis de \nperformance t\u00eam atingido patamares extremamente satisfat\u00f3rios. Como resultado, \nefeitos especiais mais complexos podem ser obtidos, aumentado o realismo das imagens \ngeradas.  \n\nA gera\u00e7\u00e3o da cor final associada a cada pixel de tela \u00e9 a tarefa crucial dos \nalgoritmos de visualiza\u00e7\u00e3o. Isto n\u00e3o \u00e9 simples de ser realizado, pois a cor final \nrepresenta a contribui\u00e7\u00e3o de diferentes componentes como, por exemplo, as \ncomponentes difusa, especular e ambiente no modelo de ilumina\u00e7\u00e3o de Phong (Foley e \nDam, 1992). Dentre as funcionalidades adicionadas \u00e0s placas (hardware) gr\u00e1ficas, o \nmapeamento de texturas permitiu a especifica\u00e7\u00e3o de novos componentes para a gera\u00e7\u00e3o \nda cor final do pixel. A id\u00e9ia \u00e9 usar a mem\u00f3ria da placa gr\u00e1fica para armazenar os \nvalores da fun\u00e7\u00e3o correspondente aos dados, chamada de textura, e usar uma outra \nfun\u00e7\u00e3o que permite mapear um dado pixel a esta representa\u00e7\u00e3o. Inicialmente, uma \u00fanica \ntextura, usualmente bi-dimensional, gerada proceduralmente ou obtida diretamente a \npartir de uma imagem 2D estava disponibilizada por pixel. Mais recentemente, t\u00eam sido \nusadas texturas tri-dimensionais, bem como a exist\u00eancia de m\u00faltiplas texturas por pixel.  \n\nEsta nova abordagem tamb\u00e9m se mostrou \u00fatil na visualiza\u00e7\u00e3o de determinados \nvolumes.  O m\u00e9todo descrito por Engel et al. (2001) consiste em representar os dados \nvolum\u00e9tricos em uma textura 3D e visualiz\u00e1-la por uma seq\u00fc\u00eancia de planos paralelos \nentre si e ortogonais a dire\u00e7\u00e3o de visualiza\u00e7\u00e3o. Desta forma, cada pixel gerado a partir \nde cada um destes planos ser\u00e1 mapeado para a textura 3D, obtendo o valor do dado \nvolum\u00e9trico amostrado. O uso de transpar\u00eancia e o desenho dos planos ordenados pela \ndist\u00e2ncia do observador permitem a visualiza\u00e7\u00e3o volum\u00e9trica em tempo real de um dado \nvolume (Engel et al., 2001). \n\nA extens\u00e3o desta t\u00e9cnica para mais de um volume pode ser feita atrav\u00e9s da cria\u00e7\u00e3o \nde uma textura 3D para cada inst\u00e2ncia de tempo. Entretanto, a capacidade de mem\u00f3ria \ndo hardware gr\u00e1fico e de mem\u00f3ria do computador s\u00e3o limita\u00e7\u00f5es para esta solu\u00e7\u00e3o. \nComo volumes pequenos usam uma quantidade consider\u00e1vel de mem\u00f3ria (1283 com 4 \nbytes por entrada resulta em 8MB), o n\u00famero de inst\u00e2ncias a ser usado nesta abordagem \n\u00e9 reduzido. \n\nUma outra caracter\u00edstica recente da t\u00e9cnica de mapeamento de texturas \u00e9 usar o \nresultado de um mapeamento de textura para definir o acesso a uma textura \nsubseq\u00fcente. Esta t\u00e9cnica, denominada de \u201ctexturas dependentes\u201d, tem mostrado um \npotencial enorme para estender ainda mais os efeitos especiais a serem aplicados.  \n\nEste trabalho apresenta uma nova forma de compactar as informa\u00e7\u00f5es \nvolum\u00e9tricas temporais a qual supera as limita\u00e7\u00f5es de mem\u00f3ria existentes, com melhor \ndesempenho quando os dados s\u00e3o esparsos e possuem alto grau de coer\u00eancia (tanto \nespacial quanto temporal). Para descomprimir tal representa\u00e7\u00e3o, utiliza-se a \nfuncionalidade de texturas dependentes para recuperar a informa\u00e7\u00e3o original. A Figura \n1.1 ilustra, em uma vis\u00e3o geral, os processos envolvidos na t\u00e9cnica, desde os dados a \nserem comprimidos at\u00e9 sua visualiza\u00e7\u00e3o. \n\n \n\n \n\n\n\n 15\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nVisualiza\u00e7\u00e3o Descompress\u00e3o \nDados 4D \n\nrepresentados \nem texturas 3D \n\nCompress\u00e3o \nDados 4D \n\nSimuladores ou \nqualquer gerador \n\nde dados \ndin\u00e2micos \n\nHardware \n\nPr\u00e9-processamento \n\nFIGURA 1.1 - Processos envolvidos na compress\u00e3o e visualiza\u00e7\u00e3o de dados 4D \n\nO m\u00e9todo de compress\u00e3o proposto torna poss\u00edvel a visualiza\u00e7\u00e3o em tempo real de \nsimula\u00e7\u00f5es que apresentam comportamento din\u00e2mico e cujos resultados s\u00e3o \nrepresentados por v\u00e1rios volumes de dados, correspondendo a inst\u00e2ncias de tempo. Ao \nfim deste trabalho, o m\u00e9todo de compress\u00e3o / visualiza\u00e7\u00e3o ser\u00e1 aplicado e validado com \nos dados provenientes do Projeto MAPEM. Entretanto, a aplicabilidade do m\u00e9todo e sua \nvisualiza\u00e7\u00e3o n\u00e3o s\u00e3o espec\u00edficas para os dados desse projeto, mas para qualquer \naplica\u00e7\u00e3o cujos dados sejam esparsos e apresentem coer\u00eancia espa\u00e7o-temporal. \n\nFormando a base para o entendimento do problema, o cap\u00edtulo 2 apresentar\u00e1 os \nconceitos e t\u00e9cnicas de visualiza\u00e7\u00e3o volum\u00e9trica e compress\u00e3o de dados volum\u00e9tricos \nou de grandes dimens\u00f5es. \n\nO cap\u00edtulo 3 revisa a arquitetura do hardware gr\u00e1fico atual. Neste cap\u00edtulo, s\u00e3o \napresentadas as caracter\u00edsticas do hardware e suas propriedades. Ser\u00e1 dada tamb\u00e9m uma \n\u00eanfase maior \u00e0s peculiaridades da estrutura que engloba as opera\u00e7\u00f5es com unidades de \ntextura, as quais ser\u00e3o base para o m\u00e9todo de compress\u00e3o / visualiza\u00e7\u00e3o proposto. \n\nFormada a base das t\u00e9cnicas de visualiza\u00e7\u00e3o volum\u00e9trica, compress\u00e3o e das \npropriedades do hardware, o cap\u00edtulo 4 detalha o mecanismo de compress\u00e3o de dados \nvolum\u00e9tricos din\u00e2micos proposto. Ser\u00e1 explorada n\u00e3o s\u00f3 sua id\u00e9ia estrutural, mas \ntamb\u00e9m sua viabilidade, ou seja, a implementa\u00e7\u00e3o. \n\nO cap\u00edtulo 5 apresenta os resultados obtidos, atrav\u00e9s de um estudo de caso com \ndados oriundos do Projeto MAPEM. S\u00e3o analisados resultados obtidos com a t\u00e9cnica de \nvisualiza\u00e7\u00e3o que se tem hoje em dia e com a aplica\u00e7\u00e3o deste m\u00e9todo de \ncompress\u00e3o/descompress\u00e3o. S\u00e3o elaboradas, tamb\u00e9m, an\u00e1lises de efici\u00eancia do m\u00e9todo, \no qual atingiu uma visualiza\u00e7\u00e3o din\u00e2mica (anima\u00e7\u00e3o) e interativa de mais de 30 frames \npor segundo, caracterizando tempo real.  \n\nFinalmente, o cap\u00edtulo 6 conclui o trabalho proposto. Trabalhos futuros tamb\u00e9m \nser\u00e3o abordados neste cap\u00edtulo como sugest\u00e3o para continua\u00e7\u00e3o e amplia\u00e7\u00e3o deste \nm\u00e9todo de representa\u00e7\u00e3o e visualiza\u00e7\u00e3o. \n \n\n \n\n\n\n 16\n\n2 Visualiza\u00e7\u00e3o Volum\u00e9trica e Compress\u00e3o \nEste cap\u00edtulo aborda os conceitos fundamentais sobre visualiza\u00e7\u00e3o volum\u00e9trica e \n\ncompress\u00e3o de dados volum\u00e9tricos. Para os algoritmos de visualiza\u00e7\u00e3o, s\u00e3o descritos os \ntrabalhos b\u00e1sicos na \u00e1rea, sendo um artigo recente (Brodlie e Wood, 2001), que faz uma \nan\u00e1lise cr\u00edtica das diferentes t\u00e9cnicas e suas extens\u00f5es, a principal fonte bibliogr\u00e1fica \ndesta parte. Na se\u00e7\u00e3o de compress\u00e3o de dados volum\u00e9tricos, s\u00e3o apresentadas t\u00e9cnicas \nrecentes de compress\u00e3o para dados est\u00e1ticos e din\u00e2micos, utilizando algumas das \nt\u00e9cnicas de visualiza\u00e7\u00e3o apresentadas. Esta revis\u00e3o \u00e9 importante, pois o \u00faltimo tipo de \ncompress\u00e3o ser\u00e1 o alvo deste trabalho. \n\n2.1 Introdu\u00e7\u00e3o \n\nA visualiza\u00e7\u00e3o de dados visa fornecer aos usu\u00e1rios ferramentas para a \nidentifica\u00e7\u00e3o de caracter\u00edsticas significativas nos dados ali representados, usando \ndiversas t\u00e9cnicas de an\u00e1lise, exibi\u00e7\u00e3o e explora\u00e7\u00e3o. Os dados s\u00e3o de naturezas diversas. \nPor exemplo, uma forma de obter diretamente dados referentes a fen\u00f4menos f\u00edsicos \u00e9 \natrav\u00e9s de instrumentos de aquisi\u00e7\u00e3o, como sensores, scanners ou at\u00e9 mesmo sat\u00e9lites. \nPor outro lado, representa\u00e7\u00f5es podem ser criadas atrav\u00e9s da modelagem matem\u00e1tica de \num fen\u00f4meno f\u00edsico, estando tal abordagem presente em \u00e1reas como medicina, geologia, \nmeteorologia, bioqu\u00edmica, etc. Em todas estas \u00e1reas e aplica\u00e7\u00f5es, a visualiza\u00e7\u00e3o de \ndados tem papel importante. \n\nUma classe espec\u00edfica de dados interessante a este trabalho refere-se a \nenumera\u00e7\u00f5es regulares do espa\u00e7o. No caso tri-dimensional, tais dados s\u00e3o ditos \nvolum\u00e9tricos, definidos em grades que cont\u00e9m valores escalares ou vetoriais associados. \nEstes dados volum\u00e9tricos s\u00e3o representados por uma matriz de elementos de volume, \nonde cada elemento b\u00e1sico \u00e9 chamado de voxel (volume element) (Figura 2.1). A \nexist\u00eancia de um ou mais valores associados a uma posi\u00e7\u00e3o de amostragem depende das \npropriedades dos dados que o volume representa. Este tipo de representa\u00e7\u00e3o \u00e9 usado \nvastamente para dados provenientes de fen\u00f4menos f\u00edsicos ou para modelagens \ngeom\u00e9tricas complexas de problemas. Por exemplo, a an\u00e1lise por elementos finitos ou \npor din\u00e2mica de fluidos \u00e9 utilizada vastamente para simular eventos da natureza, \nconstituindo uma fonte geradora de dados volum\u00e9tricos. No caso de din\u00e2mica de fluidos \n\u00e9 comum haver mais de um valor escalar associado \u00e0 mesma posi\u00e7\u00e3o, tais como \ntemperatura, press\u00e3o e densidade, bem como dados vetoriais. \n\n \n\n \n\n \n\n \n\n  \n\nVoxel ou \nElemento \nda Matriz \n3D\n\nFIGURA 2.1 - Grade ou matriz tridimensional representando um volume \n\n \n\n\n\n 17\n\nUma forma de analisar estes dados \u00e9 usar a t\u00e9cnica de Computa\u00e7\u00e3o Gr\u00e1fica \nchamada Visualiza\u00e7\u00e3o Volum\u00e9trica, de modo a comparar os dados oriundos de \nsimula\u00e7\u00f5es com resultados num\u00e9ricos derivados de experimentos ou coletados da \nnatureza.  \n\nUm dos principais problemas desta \u00e1rea est\u00e1 relacionado ao tamanho dos \nconjuntos de dados volum\u00e9tricos, em geral da ordem de v\u00e1rios megabytes, os quais \nnecessita, de compress\u00e3o. Estes volumes de dados s\u00e3o ditos multidimensionais, onde \ncada ponto do conjunto de dados \u00e9 representado por uma n-upla, onde cada elemento \ndesta n-upla representa uma coordenada em um espa\u00e7o n-dimensional, com n maior ou \nigual a tr\u00eas. Entretanto, o presente trabalho destina-se apenas a dados que variam ao \nlongo do tempo e, conseq\u00fcentemente, uma destas dimens\u00f5es ser\u00e1 o tempo. \n\nA Figura 2.2 mostra um exemplo de visualiza\u00e7\u00e3o volum\u00e9trica com dados do \nprojeto MAPEM, correspondendo ao resultado da simula\u00e7\u00e3o do descarregamento de \ncascalhos em alto mar ao longo de tr\u00eas instantes de tempo. Este exemplo ser\u00e1 explorado \nposteriormente, no cap\u00edtulo 5. \n \n\n \n\n \n\n \n\n \n \n\n \n\n \n\nFIGURA 2.2 - Visualiza\u00e7\u00e3o de tr\u00eas instantes de tempo de dados volum\u00e9tricos \n\n2.2 T\u00e9cnicas de Visualiza\u00e7\u00e3o Volum\u00e9trica \n\nNa literatura, v\u00e1rios termos s\u00e3o utilizados para caracterizar as diferentes classes de \nt\u00e9cnicas de visualiza\u00e7\u00e3o de volumes. Neste trabalho s\u00e3o utilizados os termos definidos \npor Kaufman (1991), que considera duas abordagens b\u00e1sicas para a solu\u00e7\u00e3o do \nproblema de visualiza\u00e7\u00e3o volum\u00e9trica: extra\u00e7\u00e3o de superf\u00edcies (surface rendering) e \nvisualiza\u00e7\u00e3o direta de volumes (volume rendering).  \n\nEstas classes diferem basicamente pela utiliza\u00e7\u00e3o ou n\u00e3o de representa\u00e7\u00f5es \nintermedi\u00e1rias dos dados volum\u00e9tricos para a gera\u00e7\u00e3o da visualiza\u00e7\u00e3o adequada \u00e0 \naplica\u00e7\u00e3o. Enquanto na visualiza\u00e7\u00e3o direta de volumes a proje\u00e7\u00e3o para formar a imagem \n\u00e9 realizada diretamente a partir dos dados volum\u00e9tricos, na extra\u00e7\u00e3o de superf\u00edcies os \ndados volum\u00e9tricos s\u00e3o convertidos para uma representa\u00e7\u00e3o geom\u00e9trica (pol\u00edgonos), a \npartir da qual s\u00e3o usados os m\u00e9todos tradicionais de visualiza\u00e7\u00e3o de malhas de \npol\u00edgonos. A Figura 2.3 apresenta o esquema b\u00e1sico da poss\u00edvel conex\u00e3o entre estas \nduas classes de t\u00e9cnicas. \n\n \n\n \n\n \n\n\n\n 18\n\n \n\n \n\n \n\n \n\n \n\nrep o \no objeto \n\nReconstru\u00e7\u00e3o 3D\n\nDado Geom\u00e9trico Dado Amostrado \n\nVisualiza\u00e7\u00e3o \nde Superf\u00edcie \n\nVisualiza\u00e7\u00e3o \nde Direta de \nVolumes \n\nPlano de imagem \n\nAmostragem\n\nExtra\u00e7\u00e3o de superf\u00edcie  \nPol\u00edgonos \n\ndescrevendo o \nobjeto \n\nFatias de \ndados \n\namostrados \nresentand\n\n \n  \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nFIGURA 2.3 - Representa\u00e7\u00e3o esquem\u00e1tica das t\u00e9cnicas de visualiza\u00e7\u00e3o volum\u00e9trica \n(Kaufman, 1991) \n\nAs t\u00e9cnicas envolvidas no processo de visualiza\u00e7\u00e3o volum\u00e9trica (Figura 2.3) \npodem ser resumidas, segundo Kaufman (1991) na execu\u00e7\u00e3o de cinco passos b\u00e1sicos, \ndefinidos na Figura 2.4. No entanto, a visualiza\u00e7\u00e3o \u00e9 realizada atrav\u00e9s da \nimplementa\u00e7\u00e3o apenas dos tr\u00eas \u00faltimos passos, pois \u00e9 considerada somente a \nvisualiza\u00e7\u00e3o de volumes j\u00e1 pr\u00e9-processados. \n\nNo final do processo de aquisi\u00e7\u00e3o do volume, os dados s\u00e3o reconstru\u00eddos, gerando \num volume com dimens\u00f5es proporcionais. Uma vez fornecido um volume j\u00e1 \ndeterminado, pode-se dar in\u00edcio ao processo de visualiza\u00e7\u00e3o. Para isto, inicia-se a etapa \nde classifica\u00e7\u00e3o, que est\u00e1 relacionada \u00e0 identifica\u00e7\u00e3o do material representado em cada \nvoxel. Esta etapa possibilita a sele\u00e7\u00e3o de caracter\u00edsticas dos dados, segundo um crit\u00e9rio \nquantitativo, definindo a regi\u00e3o do volume que se deseja explorar. Em t\u00e9cnicas de \nextra\u00e7\u00e3o de superf\u00edcies, classificar significa definir o valor de limiariza\u00e7\u00e3o (threshold) \nutilizado para identificar a superf\u00edcie que deve ser poligonalizada, para posterior \nvisualiza\u00e7\u00e3o. J\u00e1 para t\u00e9cnicas de visualiza\u00e7\u00e3o direta de volumes, a etapa de classifica\u00e7\u00e3o \nenvolve a defini\u00e7\u00e3o da rela\u00e7\u00e3o entre os valores dos dados do volume e os valores de cor \ne opacidade que ser\u00e3o utilizados no algoritmo de exibi\u00e7\u00e3o, ou seja, a defini\u00e7\u00e3o das \nfun\u00e7\u00f5es de transfer\u00eancia. \n\nEm seguida, para visualiza\u00e7\u00e3o direta de volumes, \u00e9 aplicado um modelo de \nilumina\u00e7\u00e3o (etapa de mapeamento) que, com base nas propriedades do material e de \ncada voxel e nas condi\u00e7\u00f5es de ilumina\u00e7\u00e3o externas, calcula a tonalidade de cor em cada \nponto do volume. Nas t\u00e9cnicas de extra\u00e7\u00e3o de superf\u00edcies, esta etapa realiza a remo\u00e7\u00e3o \nde \u00e1reas ou faces ocultas, introduzindo um modelo de ilumina\u00e7\u00e3o para o c\u00e1lculo da cor \nfinal dos pol\u00edgonos. \n\n \n\n \n\n \n\n \n\n\n\n 19\n\n \n\n \n\nReconstru\u00e7\u00e3o do volume\n\nProje\u00e7\u00e3o \n\nMapeamento \n\nClassifica\u00e7\u00e3o \n\nForma\u00e7\u00e3o do volume \n\nVisualiza\u00e7\u00e3o \n\nAquisi\u00e7\u00e3o \n\nPr\u00e9-processamento \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n \n \n\nFIGURA 2.4 - Processo para visualiza\u00e7\u00e3o volum\u00e9trica \n\nA \u00faltima etapa do processo de visualiza\u00e7\u00e3o envolve a proje\u00e7\u00e3o dos voxels ou \npol\u00edgonos mapeados na superf\u00edcie de visualiza\u00e7\u00e3o e a conseq\u00fcente composi\u00e7\u00e3o para \ndeterminar a imagem a ser visualizada. Nos algoritmos de visualiza\u00e7\u00e3o direta de \nvolumes \u00e9 realizada a proje\u00e7\u00e3o dos voxels e o c\u00e1lculo da composi\u00e7\u00e3o dos mesmos sobre \no plano da imagem. \n\nA seguir, encontra-se a descri\u00e7\u00e3o das t\u00e9cnicas mais conhecidas destas duas \nabordagens. Entretanto, o escopo deste trabalho encontra-se em uma t\u00e9cnica espec\u00edfica \nda visualiza\u00e7\u00e3o direta de volumes, o Mapeamento de Textura 3D, \u00e0 qual ser\u00e1 dada uma \n\u00eanfase maior. \n\n2.2.1 Extra\u00e7\u00e3o de Superf\u00edcies \n\nEsses m\u00e9todos produzem a visualiza\u00e7\u00e3o atrav\u00e9s da gera\u00e7\u00e3o de representa\u00e7\u00f5es \ngeom\u00e9tricas dos dados de modo a isolar um determinado objeto que est\u00e1 representado \nnos dados volum\u00e9tricos. Em raz\u00e3o disto, a quantidade de dados manipulados \u00e9 reduzida \nquando da forma\u00e7\u00e3o da imagem. Esta classe de algoritmos utiliza t\u00e9cnicas \nconvencionais de Computa\u00e7\u00e3o Gr\u00e1fica para a visualiza\u00e7\u00e3o de pol\u00edgonos e do re-\nprocessamento do volume para se extrair novamente o objeto toda vez que uma \naltera\u00e7\u00e3o da caracter\u00edstica do volume a ser visualizada for solicitada. \n\nResumidamente, estes algoritmos tipicamente ajustam uma superf\u00edcie constru\u00edda \npor pol\u00edgonos a pontos de isovalor dentro dos dados volum\u00e9tricos. As grandes \nvantagens destas t\u00e9cnicas s\u00e3o a velocidade para a gera\u00e7\u00e3o e exibi\u00e7\u00e3o da imagem final e \no pequeno espa\u00e7o de armazenamento requerido. No entanto, n\u00e3o s\u00e3o apropriadas \nquando existem isosuperf\u00edcies complexas nos dados. \n\n \n\n\n\n 20\n\nEntre os algoritmos de extra\u00e7\u00e3o de superf\u00edcies, destacam-se dois que s\u00e3o descritos \na seguir: conex\u00e3o de contornos, proposto por Keppel (1975) e adaptado por Fuchs et al. \n(1977), e cubos marchantes (marching cubes), idealizado por Lorensen e Cline (1987).  \n\n2.2.1.1 Conex\u00e3o de Contornos (Contour-Connecting) \n\nA id\u00e9ia b\u00e1sica deste algoritmo \u00e9 determinar uma isolinha em cada fatia de dados e, \nposteriormente, conectar as fatias adjacentes. O m\u00e9todo opera inicialmente em cada \nfatia de dados individualmente, seguindo uma determinada ordem dos objetos. \n\nAp\u00f3s o valor de limiariza\u00e7\u00e3o ser especificado, uma curva fechada conecta estes \nvalores para cada fatia de dados (linha de isovalores). Uma vez determinado o contorno \nde cada fatia, o problema volta-se para encontrar a conex\u00e3o \u00f3tima, geralmente atrav\u00e9s \nde tri\u00e2ngulos, interligando as curvas de fatias adjacentes (Figura 2.5). \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nFIGURA 2.5 - Algoritmo de conex\u00e3o de contornos (Keppel, 1975) \n\nQuando uma fatia cont\u00e9m mais de um contorno que pode ser conectado a um dos \ncontornos da fatia seguinte, \u00e9 usado, em geral, um crit\u00e9rio de proximidade para definir \nos pares de contornos a serem conectados, sendo este o problema central da t\u00e9cnica. A \nFigura 2.6 ilustra esta dificuldade. \n\n \n\n \n\n \n\n \n\nFIGURA 2.6 - Modelos que podem ser gerados para um mesmo par de fatias (Fuchs et \nal., 1977) \n\nSem entrar em detalhes no problema apresentado na Figura 2.6, trata-se da \nconex\u00e3o dos contornos definidos em duas fatias adjacentes, onde o objetivo \u00e9 encontrar \na conex\u00e3o \u00f3tima. Considera-se um contorno como um ciclo fechado de segmentos de \nreta ligando pontos de mesma propriedade em um plano particular, sendo todos os \nplanos paralelos entre si. Considera-se tamb\u00e9m dois contornos situados em planos \nadjacentes, definidos como, por exemplo, (P0, P1, P2 ... Pm-1, P0) e (Q0, Q1, Q2 ... Qn-\n1, Q0). \n\n \n\n\n\n 21\n\nExistem dois problemas b\u00e1sicos para a constru\u00e7\u00e3o de uma superf\u00edcie a partir de \nconjuntos estruturados de contornos planos: correspond\u00eancia e acoplamento. O \nproblema de correspond\u00eancia ocorre quando um segmento de um contorno no plano \u00e9 \ncriado e existem dois ou mais contornos pr\u00f3ximos no mesmo plano. Algumas solu\u00e7\u00f5es \npara este problema foram sugeridas por Meyers (1992). Uma solu\u00e7\u00e3o emprega cilindros \nel\u00edpticos que produzem contornos ajustados por elipses; outra solu\u00e7\u00e3o usa \u00e1rvores \ngeradoras de grafos que ligam os contornos em se\u00e7\u00f5es adjacentes, sendo que o grafo \ngerado \u00e9 usado para encontrar a melhor conex\u00e3o de contornos.  \n\nO problema de acoplamento est\u00e1 relacionado \u00e0 maneira como os contornos ser\u00e3o \nunidos em duas fatias adjacentes para formar os tri\u00e2ngulos que geram a superf\u00edcie. Cada \ntri\u00e2ngulo \u00e9 formado por dois pontos do contorno P e um do contorno Q, ou vice versa. \nIsto pode ser escrito como: (Pi,Pj,Qk) ou (Qi,Qj,Pk). O problema \u00e9 decidir a orienta\u00e7\u00e3o \ndo pr\u00f3ximo tri\u00e2ngulo. Fuchs et al. (1977) determinam o tri\u00e2ngulo seguinte utilizando as \nseguintes regras: \n\n\u2022 cada segmento de contorno ser\u00e1 usado por um \u00fanico tri\u00e2ngulo; \n\n\u2022 o lado esquerdo de um determinado tri\u00e2ngulo ser\u00e1 usado como lado direito \ndo seguinte. \n\nA decis\u00e3o do pr\u00f3ximo tri\u00e2ngulo a ser conectado \u00e9 feita com base na teoria dos \ngrafos, usando a seguinte hip\u00f3tese: \u201ctoda superf\u00edcie aceit\u00e1vel definida entre dois \ncontornos pode ser associada com certos ciclos em um grafo toroidal direcionado\u201d \n(Meyers, 1992). A superf\u00edcie \u00f3tima corresponde ao caminho m\u00ednimo no grafo toroidal. \nO custo \u00e9 a soma dos arcos percorridos, sendo que v\u00e1rias heur\u00edsticas s\u00e3o propostas para \ncalcular este caminho m\u00ednimo. \n\n2.2.1.2 Cubos Marchantes (Marching Cubes) \n\nO algoritmo de cubos marchantes foi introduzido por Lorensen e Cline (1987) \ncom uma vers\u00e3o similar de Wyvill et al. (1986) e consiste em uma t\u00e9cnica cl\u00e1ssica, \nsendo uma das mais utilizadas para a extra\u00e7\u00e3o de superf\u00edcies e visualiza\u00e7\u00e3o de dados \namostrados.  \n\nO algoritmo assume que os dados est\u00e3o armazenados em uma grade estruturada e \ncada c\u00e9lula \u00e9 processada individualmente. As c\u00e9lulas na grade estruturada s\u00e3o \ntopologicamente equivalentes a cubos e o m\u00e9todo foca na extra\u00e7\u00e3o de superf\u00edcie ao \nlongo de um \u00fanico cubo. O processo completo de extra\u00e7\u00e3o \u00e9 realizado percorrendo \ntodos os cubos, um ap\u00f3s o outro, derivando o nome de cubos marchantes. \n\nCada v\u00e9rtice de um cubo pode ser maior ou menor que um determinado limiar k. \nAssim, 256 (28, pois um cubo possui 8 v\u00e9rtices) cen\u00e1rios diferentes s\u00e3o poss\u00edveis. Uma \nfun\u00e7\u00e3o f(x,y,z) pode ser constru\u00edda como uma interpola\u00e7\u00e3o tri-linear dos valores de cada \nv\u00e9rtice de um cubo, gerando uma isosuperf\u00edcie. As interse\u00e7\u00f5es da isosuperf\u00edcie f(x,y,z) = \nk com as arestas do cubo s\u00e3o f\u00e1cil e corretamente calculadas por interpola\u00e7\u00e3o linear \ninversa. A Figura 2.7 ilustra esta fun\u00e7\u00e3o f(x,y,z) = k, onde os v\u00e9rtices do cubo que est\u00e3o \nabaixo do plano apresentam valores menores que o limiar k e os que est\u00e3o acima \napresentam valores maiores que k. \n\nComo o comportamento de f(x,y,z) = k dentro do cubo \u00e9 o de uma superf\u00edcie \nc\u00fabica, uma simples estimativa de f  ao longo do cubo pode ser realizada unindo os \npontos de intersec\u00e7\u00e3o em um conjunto de tri\u00e2ngulos. \n\n \n\n\n\n 22\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \nf(x,y,z) &lt;k \n\nf(x,y,z) > k \n\nf(x,y,z) = k \n\nFIGURA 2.7 - Fun\u00e7\u00e3o de interpola\u00e7\u00e3o para cada v\u00e9rtice \n\nEncerrado o processamento de um cubo, o algoritmo prossegue (\u201cmarcha\u201d) para a \npr\u00f3xima c\u00e9lula ou cubo. Depois que todas as c\u00e9lulas forem \u201cvisitadas\u201d, a isosuperf\u00edcie, \ndefinida em termos de uma malha poligonal, est\u00e1 pronta para ser visualizada. \n\nUm ponto central do algoritmo \u00e9 a defini\u00e7\u00e3o de uma tabela que determina a \ntopologia da superf\u00edcie dentro do cubo para cada caso poss\u00edvel.  No trabalho de \nLorensen e Cline (1987), os 256 casos dessa tabela s\u00e3o reduzidos a 15 casos b\u00e1sicos, \ndescritos na Figura 2.8, atrav\u00e9s de considera\u00e7\u00f5es de simetria e complementaridade, onde \na topologia da superf\u00edcie \u00e9 invariante a rota\u00e7\u00f5es do cubo e a invers\u00e3o dos valores dos \nv\u00e9rtices \u00e9 equivalente ao caso original. \n\n\u00c9 importante ressaltar que recentemente, Cignoni et al. (2000) mostraram que os \ncasos de ambig\u00fcidade se estendem de 256 casos para 798 casos, mas apenas 88 s\u00e3o de \nconfigura\u00e7\u00f5es distintas. Outro trabalho anterior (Chernayev, 1995) tamb\u00e9m identificou \noutros 33 casos b\u00e1sicos. \n\nUm problema do marching cubes \u00e9 que existem casos amb\u00edguos na tabela de \ncasos. Uma an\u00e1lise cuidadosa dos casos 7, 10, 12 e 13, na Figura 2.8, como casos \nsubseq\u00fcentes, mostra que existem estados nos quais uma c\u00e9lula pode ser \u201ccortada\u201d de \nmais de uma maneira. Essa ambig\u00fcidade ocorre na face de um voxel quando v\u00e9rtices em \narestas adjacentes est\u00e3o em estados diferentes, mas v\u00e9rtices diagonais est\u00e3o no mesmo \nestado (todos dentro ou todos fora da superf\u00edcie). A escolha de um dos dois casos \nprecisa ser consistente ao longo do processamento. Por exemplo, vejamos o caso 3 e o \ncomplementar do caso 6 (casos complementares s\u00e3o obtidos substituindo-se os v\u00e9rtices \nque est\u00e3o dentro pelos que est\u00e3o fora ou vice-versa). Se dois casos amb\u00edguos s\u00e3o \nimplementados de forma independente um do outro, ocorre a forma\u00e7\u00e3o de um buraco na \nsuperf\u00edcie. \n\nNo marching cubes, a solu\u00e7\u00e3o adotada consiste em estender os 15 casos originais \npara incluir os casos complementares, sendo que estes casos s\u00e3o projetados para serem \ncompat\u00edveis com os casos vizinhos e evitam a cria\u00e7\u00e3o de buracos. \n\n \n\n \n\n \n\n \n\n\n\n 23\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nFIGURA 2.8\n\nPosterio\ntri\u00e2ngulos ge\ndivis\u00e3o de cu\nobserva\u00e7\u00e3o. O\naquelas em q\nsub-c\u00e9lulas, \nvisualizada co\n\n2.2.2 Visual\n\nA visua\nvisualiza\u00e7\u00e3o d\numa pequena\nconsiderado \nEntretanto, \ndesenvolvime\n\nEste m\u00e9\ndiretamente e\nintermedi\u00e1ria\ntransfer\u00eancia \nvisuais, tais c\nutilizar-se de\n\n \n\n - Os 15 casos b\u00e1sicos do algoritmo de marching cubes (Lorensen e Cline, \n1987) \n\nrmente, Cline et al. (1998) descobriram tamb\u00e9m que o tamanho de alguns \nrados era menor que o tamanho de um pixel. O algoritmo denominado \nbos (dividing cubes) foi, ent\u00e3o, desenvolvido para tirar vantagem desta \n algoritmo efetua a proje\u00e7\u00e3o das c\u00e9lulas na tela, verificando somente \n\nue a proje\u00e7\u00e3o \u00e9 maior que um pixel. Se isto ocorrer, a c\u00e9lula \u00e9 dividida em \ncada uma das quais determinando um ponto. Se n\u00e3o, a c\u00e9lula toda \u00e9 \nmo um ponto. \n\niza\u00e7\u00e3o Direta de Volumes \n\nliza\u00e7\u00e3o direta de volumes oferece uma solu\u00e7\u00e3o mais completa para a \ne volumes, a qual tem o objetivo de retratar o volume inteiro ao inv\u00e9s de \n\n amostra do mesmo. Este conjunto de t\u00e9cnicas tem sido, tradicionalmente, \nmais custoso computacionalmente do que a extra\u00e7\u00e3o de superf\u00edcies. \nessa situa\u00e7\u00e3o tem sido recentemente minimizada por novos \nntos em hardware. \n\ntodo consiste em tomar o volume constitu\u00eddo por voxels e projet\u00e1-los \nm pixels, dispensando o uso de primitivas geom\u00e9tricas ou representa\u00e7\u00e3o \n. Neste caso, numa etapa de classifica\u00e7\u00e3o, \u00e9 utilizada uma fun\u00e7\u00e3o de \nque corresponde ao mapeamento dos valores dos voxels para propriedades \nomo cor e opacidade. Estas fun\u00e7\u00f5es de transfer\u00eancia podem, por exemplo, \n estimativas de gradiente, onde se pode combinar a diminui\u00e7\u00e3o da cor e \n\n\n\n 24\n\nopacidade nas \u00e1reas de baixo gradiente com o aumento destas caracter\u00edsticas nas \u00e1reas \nde alto gradiente. \n\nA visualiza\u00e7\u00e3o das estruturas de interesse dentro do volume \u00e9 realizada a partir da \n\u201cvisita\u201d, em uma certa ordem, a todos os voxels (ou quase todos, dependendo do \nalgoritmo) e da aplica\u00e7\u00e3o da fun\u00e7\u00e3o de transfer\u00eancia para a constru\u00e7\u00e3o da imagem. Esta \nordem pode ser classificada, segundo Kaufman (1991), em ordem dos objetos (object-\norder ou forward projection), quando os voxels s\u00e3o projetados diretamente no plano de \nimagem, e ordem da imagem (image-order ou backward projection), que determina \npara cada pixel do plano da imagem quais s\u00e3o as amostras que contribuem no c\u00e1lculo da \nsua intensidade. \n\nEstas t\u00e9cnicas possuem um alto custo computacional, pois normalmente envolvem \numa interpola\u00e7\u00e3o de valores nos pontos ao longo da dire\u00e7\u00e3o de visualiza\u00e7\u00e3o. Por outro \nlado, produzem imagens de excelente qualidade, uma vez que todos os voxels podem ser \nusados na s\u00edntese das imagens, possibilitando a visualiza\u00e7\u00e3o interior dos objetos. \n\nOs principais algoritmos que se destacam neste grupo s\u00e3o: ray casting, splatting e \nshear-warp. Essas t\u00e9cnicas s\u00e3o descritas a seguir juntamente com a t\u00e9cnica de \nmapeamento de textura, considerada tamb\u00e9m muito importante na visualiza\u00e7\u00e3o direta de \nvolumes e usada no m\u00e9todo proposto neste trabalho. \n\n2.2.2.1 Algoritmo de Ray Casting \n\nResumidamente, o algoritmo de ray casting (Levoy, 1988 e Levoy, 1990) baseia-\nse em raios lan\u00e7ados do ponto de vista do observador, passando atrav\u00e9s de cada pixel da \ntela e interceptando o volume. Se o raio intercept\u00e1-lo, o conte\u00fado do volume ao longo \ndo raio \u00e9 amostrado, transformando-se o valor acumulado em cor e opacidade, \natribu\u00eddos ao pixel. Este algoritmo \u00e9 o mais usado para a visualiza\u00e7\u00e3o de volumes \nquando se necessita de imagens de alta qualidade (Elvins, 1992). \n\nOs par\u00e2metros de visualiza\u00e7\u00e3o tradicionalmente especificam a posi\u00e7\u00e3o do \nobservador, o tipo, a dire\u00e7\u00e3o e o plano de proje\u00e7\u00e3o e os planos de corte 3D. No contexto \nda visualiza\u00e7\u00e3o direta de volumes, a dire\u00e7\u00e3o de proje\u00e7\u00e3o DOP determina a orienta\u00e7\u00e3o \ndos raios lan\u00e7ados no volume. O plano de proje\u00e7\u00e3o \u00e9 mapeado para uma janela de \nvisualiza\u00e7\u00e3o I no plano da imagem, que se refere aos valores de intensidade associados \n\u00e0s posi\u00e7\u00f5es dos pixels (Figura 2.9). \n\nA intensidade para cada pixel da imagem \u00e9 determinada pelo lan\u00e7amento de um \nraio Rp deste pixel ao seguindo a dire\u00e7\u00e3o de visualiza\u00e7\u00e3o. Ao longo de cada raio s\u00e3o \nprocessadas s amostras, em geral com um espa\u00e7amento constante. O processamento de \numa amostra corresponde ao c\u00e1lculo de um valor de cor e um valor de opacidade \ndependentes das posi\u00e7\u00f5es de amostragem. Caso a posi\u00e7\u00e3o da amostra n\u00e3o coincida com \nas posi\u00e7\u00f5es discretas de amostragem do volume, o c\u00e1lculo \u00e9 feito a partir da cor e \nopacidade dos voxels vizinhos. \n\nNa Figura 2.9, considerou-se que o processamento do algoritmo de ray casting \u00e9 \nrealizado na ordem de frente para tr\u00e1s (front-to-back), ou seja, as amostras s\u00e3o \nprocessadas a partir do primeiro ponto de intersec\u00e7\u00e3o a do raio com o volume at\u00e9 o \nsegundo ponto de intersec\u00e7\u00e3o b. Entretanto, tamb\u00e9m \u00e9 poss\u00edvel realizar o processamento \nna ordem de tr\u00e1s para frente (back-to-front), ou seja, de b para a. \n\n \n\n \n\n\n\n 25\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n  \n\nFIGURA 2.9 - Esquema gen\u00e9rico do algoritmo de ray casting front-to-back (extra\u00edda de \nManssour e Freitas, 2002) \n\n2.2.2.2 Algoritmo de Splatting \n\nSplatting (Westover, 1989 e Westover, 1990) \u00e9 um algoritmo de visualiza\u00e7\u00e3o do \ntipo image-order usado com volumes de dados regulares, mas que podem n\u00e3o possuir o \nmesmo espa\u00e7amento nas tr\u00eas dimens\u00f5es da grade. \u00c9 inspirado na estrutura do pipeline \nde visualiza\u00e7\u00e3o de pol\u00edgonos, onde cada primitiva passa ao longo de v\u00e1rios est\u00e1gios por \nvez. \n\nCada elemento \u00e9 mapeado no plano da tela e, em seguida, atrav\u00e9s de um processo \nde acumula\u00e7\u00e3o, tem sua contribui\u00e7\u00e3o \u00e0 forma\u00e7\u00e3o da imagem calculada. A contribui\u00e7\u00e3o \nde um voxel \u00e9 maior perto do centro de sua proje\u00e7\u00e3o e menor quando mais distante do \ncentro. Pode-se fazer uma analogia como atirar (splat) uma bola de neve contra um \nmuro. A contribui\u00e7\u00e3o da neve no centro do impacto ser\u00e1 maior e decai \u00e0 medida que se \ndistancia do centro. O algoritmo termina quando todas as primitivas tiverem sido \nmapeadas na tela. \n\nO algoritmo \u00e9 definido por quatro etapas principais: transforma\u00e7\u00e3o, tonalidade, \nreconstru\u00e7\u00e3o e visibilidade. Inicialmente, a amostra \u00e9 processada atrav\u00e9s de sua \ntransforma\u00e7\u00e3o de coordenadas do volume para o espa\u00e7o da tela. Em seguida \u00e9 feita a \ntonaliza\u00e7\u00e3o da amostra, que engloba classifica\u00e7\u00e3o e ilumina\u00e7\u00e3o, usando apenas a \ninforma\u00e7\u00e3o local. \n\nA reconstru\u00e7\u00e3o \u00e9 realizada para todas as amostras em um plano do volume de \ndados, definido como um plano paralelo ao plano da imagem. Ap\u00f3s a determina\u00e7\u00e3o da \npor\u00e7\u00e3o da imagem que a amostra influencia, atrav\u00e9s da fun\u00e7\u00e3o footprint, sua \ncontribui\u00e7\u00e3o \u00e9 adicionada em um acumulador do plano. Quando todas as amostras de \num plano do volume de dados s\u00e3o processadas, o conte\u00fado do acumulador do plano \u00e9 \ncombinado na imagem atrav\u00e9s de um operador de composi\u00e7\u00e3o. Depois que todas as \namostras forem processadas, \u00e9, ent\u00e3o, obtida a imagem final. \n\n \n\n\n\n 26\n\nA fun\u00e7\u00e3o footprint \u00e9 calculada para cada posi\u00e7\u00e3o de observa\u00e7\u00e3o do volume de \ndados. Como cada voxel projetado (splat) \u00e9 representado por um n\u00facleo (kernel) de \ninterpola\u00e7\u00e3o sim\u00e9trico, primeiro \u00e9 calculada a extens\u00e3o do espa\u00e7o de tela onde o kernel \nser\u00e1 projetado. Essa proje\u00e7\u00e3o \u00e9 chamada de um footprint. Para uma proje\u00e7\u00e3o ortogr\u00e1fica, \no n\u00facleo mais comum \u00e9 um Gaussiano esf\u00e9rico, ilustrado na Figura 2.10. \n\n \n\n \n\n \n \n\n \n\n \n\n \n\n FIGURA 2.10 - Footprint, onde \u00e1reas escuras indicam maior intensidade \n\nTodos os pixels cujos centros se encontram na regi\u00e3o onde o kernel \u00e9 projetado \npodem ser afetados pela amostra. A partir do kernel, s\u00e3o ponderados os valores dos \nvoxels. A tabela que representa a fun\u00e7\u00e3o footprint \u00e9 determinada em uma etapa de pr\u00e9-\nprocessamento, acelerando o m\u00e9todo (Westover, 1990). \n\nUm algoritmo semelhante, denominado v-buffer, foi apresentado por Upson e \nKeeler (1998). Este algoritmo apresenta como diferen\u00e7a o fato de se basear em c\u00e9lulas \n2D e n\u00e3o em c\u00e9lulas 3D (voxels). O algoritmo v-buffer percorre o interior da c\u00e9lula \ninterpolando os valores dos v\u00e9rtices e projetando cada valor interpolado no plano de \nvisualiza\u00e7\u00e3o. Tanto o m\u00e9todo de splatting como o v-buffer, s\u00e3o facilmente \nparaleliz\u00e1veis. \n\n2.2.2.3 Algoritmo de Shear-Warp \n\nA id\u00e9ia do algoritmo de shear-warp, desenvolvido por Lacroute e Levoy (1994) \ncom base, entre outros, no trabalho de Cameron e Undrill (1992), \u00e9 pr\u00e9-transformar os \ndados em uma orienta\u00e7\u00e3o de maneira que a visualiza\u00e7\u00e3o seja r\u00e1pida.  \n\nA base desta t\u00e9cnica est\u00e1 na fatora\u00e7\u00e3o da matriz de visualiza\u00e7\u00e3o, onde h\u00e1 a \ndecomposi\u00e7\u00e3o da transforma\u00e7\u00e3o de proje\u00e7\u00e3o em duas etapas. Esta decomposi\u00e7\u00e3o gera \numa transforma\u00e7\u00e3o de cisalhamento (shear) e uma de corre\u00e7\u00e3o (warping). \n\nInicialmente, o volume \u00e9 transformado para um sistema de coordenadas \nintermedi\u00e1rio de modo que cada fatia fique paralela ao plano da imagem e perpendicular \naos raios. Assim, com este cisalhamento, os raios de vis\u00e3o percorrem de maneira trivial \nas fatias do volume, gerando uma imagem intermedi\u00e1ria distorcida. A outra parcela \nresultante da decomposi\u00e7\u00e3o \u00e9 uma transforma\u00e7\u00e3o de corre\u00e7\u00e3o da deforma\u00e7\u00e3o da imagem \nintermedi\u00e1ria, que gera a imagem final do objeto tridimensional. Estas fases podem ser \nvisualizadas na Figura 2.11. \n\nResumidamente, ent\u00e3o, o algoritmo \u00e9 composto das seguintes etapas: (i) \ntransforma\u00e7\u00e3o do volume de dados para o espa\u00e7o de cisalhamento, transladando e \nreamostrando cada fatia de acordo com a transla\u00e7\u00e3o; (ii) composi\u00e7\u00e3o das fatias \nreamostradas, projetando o volume em uma imagem 2D intermedi\u00e1ria; (iii) \n\n \n\n\n\n 27\n\ntransforma\u00e7\u00e3o da imagem intermedi\u00e1ria para o espa\u00e7o da imagem final, corrigindo a \ndeforma\u00e7\u00e3o. \n \n\nPlano da Imagem \n\nFatias do volume \n\nRaios \nShear \n\nProje\u00e7\u00e3o \n\nWarp \n\n \n\n \n\n \n\n \n\n \n\n \n\nFIGURA 2.11 - Esquema do algoritmo shear-warp (Lacroute e Levoy, 1994) \n\nO algoritmo explora a coer\u00eancia do volume de dados usando o m\u00e9todo de \ncompacta\u00e7\u00e3o Run-Lenght Encoding para os voxels, de tal forma que n\u00e3o ocorre o \nprocessamento dos voxels transparentes. \n\nO m\u00e9todo tamb\u00e9m pode ser paraleliz\u00e1vel e sua performance \u00e9 apresentada em \nLacroute (1996). \n\n2.2.2.4 Mapeamento de Textura \n\nO desenvolvimento de hardware espec\u00edfico para computa\u00e7\u00e3o gr\u00e1fica motivou o \ntrabalho de Akeley (1993) em apresentar a visualiza\u00e7\u00e3o de uma textura s\u00f3lida usando o \nprimeiro hardware da s\u00e9rie SGI Reality Engine. Esse trabalho foi o precursor dentre as \nabordagens baseadas em texturas usando hardware para PCs. Posteriormente, Cabral et \nal. (1994) apresentou uma representa\u00e7\u00e3o do volume de dados utilizando mapeamento de \ntexturas com opacidade, tanto 2D como 3D. Esta abordagem foi significativamente \nexpandida por Westermann e Ertl (1998), que introduziram um algoritmo para \nvisualiza\u00e7\u00e3o de isosuperf\u00edcies sombreadas. Em seguida, Mei?ner et al. (1999) \ndesenvolveu um m\u00e9todo de ilumina\u00e7\u00e3o difusa para visualiza\u00e7\u00e3o direta de volumes semi-\ntransparentes. \n\nA seguir, s\u00e3o apresentadas duas abordagens baseadas em mapeamento de texturas \npara visualiza\u00e7\u00e3o direta de volumes. A primeira explora uma abordagem simplificada \n(bidimensional) e a outra aplica realmente o conceito em tr\u00eas dimens\u00f5es. \n\n2.2.2.4.1 Textura 2D \n\nEspecificamente, as texturas 2D podem ser usadas para a visualiza\u00e7\u00e3o volum\u00e9trica \nde dados regulares estruturados. Para isso, uma cole\u00e7\u00e3o de pol\u00edgonos paralelos entre si \u00e9 \nespecificada ortogonal a cada eixo principal do sistema de coordenadas (object-aligned), \ncomo mostrado na Figura 2.12. Estes planos poder\u00e3o ser desenhados tanto na ordem de \nfrente para tr\u00e1s (front-to-back) como de tr\u00e1s para frente (back-to-front) e a especifica\u00e7\u00e3o \ndestas tr\u00eas cole\u00e7\u00f5es de planos se deve completamente \u00e0 dire\u00e7\u00e3o de visualiza\u00e7\u00e3o.  \n\nDada uma dire\u00e7\u00e3o de visualiza\u00e7\u00e3o que segue a mesma dire\u00e7\u00e3o de qualquer um dos \neixos, seria suficiente especificar apenas a cole\u00e7\u00e3o de planos que estivesse ortogonal a \nesta dire\u00e7\u00e3o. Entretanto, a especifica\u00e7\u00e3o de apenas um destes conjuntos de planos n\u00e3o \u00e9 \ninteressante quando se utiliza diferentes c\u00e2meras para visualiza\u00e7\u00e3o. Por exemplo, \nquando uma cole\u00e7\u00e3o \u00e9 desenhada no plano XY e a dire\u00e7\u00e3o de visualiza\u00e7\u00e3o se move para \n\n \n\n\n\n 28\n\no plano YZ, o usu\u00e1rio estar\u00e1 visualizando diretamente ao longo das fatias e, \nconseq\u00fcentemente, a imagem desaparecer\u00e1. Outro problema que poderia ocorrer com a \nvisualiza\u00e7\u00e3o de uma \u00fanica seq\u00fc\u00eancia de planos \u00e9 que o usu\u00e1rio tamb\u00e9m perceberia que o \nvolume \u00e9 realmente constitu\u00eddo de fatias, se os intervalos entre as mesmas forem \nconsider\u00e1veis, j\u00e1 que a interpola\u00e7\u00e3o \u00e9 bi-linear. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nX \n\nZ \n\n \n \n\n \n \n\nX \n\nZ \n\nY \n\nZ \n\nX \n\nY \n\nY \n\nFIGURA 2.12 - Fatias ortogonais a cada eixo \n\nUsando os tr\u00eas conjuntos de fatias, este problema seria evitado, pois, seguindo o \nexemplo, o plano YZ estaria na dire\u00e7\u00e3o de visualiza\u00e7\u00e3o. Entretanto, a visualiza\u00e7\u00e3o \ndestas tr\u00eas pilhas de fatias ao mesmo tempo seria muito custosa e causaria uma \nvisualiza\u00e7\u00e3o err\u00f4nea do objeto, j\u00e1 que, na realidade, tr\u00eas objetos seriam visualizados ao \nmesmo tempo. Para prevenir este poss\u00edvel problema, caso os objetos n\u00e3o sejam \nsim\u00e9tricos, apenas o conjunto de pol\u00edgonos mais alinhado \u00e0 dire\u00e7\u00e3o de visualiza\u00e7\u00e3o \u00e9 \ndesenhado, tornando-se invis\u00edveis os outros dois conjuntos. \u00c0 medida que o ponto de \nvisualiza\u00e7\u00e3o se movimenta, o sistema seleciona o conjunto de fatias apropriado, ou seja, \no mais perpendicular ao observador \u00e9 desenhado. \n\nSolucionados tais problemas, o mapeamento de textura e da fun\u00e7\u00e3o de \ntransfer\u00eancia de cor e opacidade \u00e9 simples e pode ser abstra\u00eddo no esquema da Figura \n2.13. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n(x4,y4) \n\n(x4,y4,z4) (x3,y3,z3)\n\n(s,t) \n\n(s4,t4) (s3,t3) (x,y,z) \n\n(x,y) \n\n(x2,y2,z2)\n(s2,t2) Texel \n\nFragmento\n\nPixel \n\n(x3,y3) \n\n(x2,y2) \n\nTextura 2D \n\nPol\u00edgono no \nespa\u00e7o 3D \n\n(x1,y1,z1)\n(s1,t1) \n\nPol\u00edgono no \nespa\u00e7o de tela \n\n(x1,y1) \n \n\nFIGURA 2.13 - Mapeamento de textura 2D \n\n \n\n\n\n 29\n\nApesar destas solu\u00e7\u00f5es propostas, o usu\u00e1rio ainda perceber\u00e1 claramente as fatias \nquando estiver se aproximando de um \u00e2ngulo de 90 graus em rela\u00e7\u00e3o a qualquer um dos \nplanos, necessitando de uma corre\u00e7\u00e3o baseada no algoritmo de shear-warp. \n\n2.2.2.4.2 Textura 3D \n\nEste m\u00e9todo surgiu basicamente com o avan\u00e7o recente do hardware para a \nacelera\u00e7\u00e3o do processo de visualiza\u00e7\u00e3o, tornando-se r\u00e1pido o bastante e sendo uma \nalternativa ao mapeamento de textura 2D para dados volum\u00e9tricos. Com o avan\u00e7o da \ntecnologia, o hardware gr\u00e1fico acelerou todas as etapas do pipeline 3D. \n\nA id\u00e9ia desta t\u00e9cnica parte do princ\u00edpio de uma pr\u00e9-convers\u00e3o do volume de dados \npara um mapa 3D de texturas, usando um m\u00e9todo de classifica\u00e7\u00e3o baseado em tabelas \nque representam a fun\u00e7\u00e3o de transfer\u00eancia de cor e opacidade dos voxels, onde cada \nfatia do volume de dados ser\u00e1 representada em uma fatia do mapa de textura. A \nconvers\u00e3o dos mapas de textura \u00e9 realizada apenas uma vez, sendo uma etapa de pr\u00e9-\nprocessamento. \n\nUma vez criada a textura 3D, \u00e9 necess\u00e1rio aplic\u00e1-la a uma cole\u00e7\u00e3o de pol\u00edgonos \n(Yagel et al., 1996) localizados em planos paralelos ao plano da imagem, como \nexemplificado na Figura 2.14. A interpola\u00e7\u00e3o agora ser\u00e1 trilinear, fazendo com que o \nvolume seja considerado na composi\u00e7\u00e3o da cor de cada pixel. Na realidade, o volume \u00e9 \napresentado usando um artif\u00edcio que \u00e9 criar pol\u00edgonos que s\u00e3o exibidos e recebem fatias \nda textura.  \n\n \n\n \n\nDire\u00e7\u00e3o de visualiza\u00e7\u00e3o \n\nMapeamento \n\nTextura 3D \n\nPlano da imagem \n\nPol\u00edgonos \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nFIGURA 2.14 - Aplica\u00e7\u00e3o da textura 3D em uma seq\u00fc\u00eancia de pol\u00edgonos \n\nOs planos podem ser desenhados de tr\u00e1s para frente (back-to-front) ou de frente \npara tr\u00e1s (front-to-back) e, de acordo com Engel et al. (2001), se a c\u00e2mera se \nmovimentar, os planos devem acompanh\u00e1-la de forma que fiquem sempre ortogonais \u00e0 \ndire\u00e7\u00e3o de visualiza\u00e7\u00e3o (view-aligned), como na Figura 2.15. Esta abordagem soluciona \no problema apresentado pelo mapeamento de texturas 2D em dados volum\u00e9tricos. \n\n \n\n \n\n \n\n\n\n 30\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n                    (a)   (b) \n\nFatias Plano da imagem\n\nObservador \nO \n\n \n\n \nFIGURA 2.15 - Visualiza\u00e7\u00e3o usando textura 3D: (a) planos ortogonais ao olhar do leitor \n\n(paralelos \u00e0 folha) e (b) planos ortogonais a dire\u00e7\u00e3o de observa\u00e7\u00e3o de O (Kraus e Ertl, \n2002) \n\nO n\u00famero de planos utilizados \u00e9 determinado levando em considera\u00e7\u00e3o o \ncompromisso entre qualidade e velocidade. Quanto mais planos s\u00e3o utilizados, mais \nprecisos os resultados e maior o tempo gasto pelo algoritmo. O n\u00famero de planos \nexigidos para apresentar os dados adequadamente em uma dada dire\u00e7\u00e3o \u00e9 fun\u00e7\u00e3o da \namostragem dos dados, podendo ser at\u00e9 uma rela\u00e7\u00e3o de um para um. \n\nEnt\u00e3o, basicamente, o m\u00e9todo de mapeamento de textura 3D resume-se a uma \nsimples correspond\u00eancia entre as coordenadas (x,y) de cada plano e uma unidade da \ntextura 3D (texel) a ser interpolada (s,t,r). A Figura 2.16 apresenta de modo geral o \nmapeamento de um \u00fanico pol\u00edgono. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n(s,t,r) \n\n(x,y) \n\n(x3,y3,z3)\n(s3,t3,r3) \n\n(x4,y4,z4)\n(s4,t4,r4) (x,y,z)\n\nTexel \n\nFragmento\n\nPixel \n\n(x4,y4) \n\n(x3,y3) \n\n(x2,y2) \n\nTextura 3D \n\nPol\u00edgono no \nespa\u00e7o 3D \n\n(x1,y1,z1) (x2,y2,z2)\n(s2,t2,r2) (s1,t1,r1) \n\nPol\u00edgono no \nespa\u00e7o de tela \n\n(x1,y1) \n \n\nFIGURA 2.16 - Mapeamento de um \u00fanico pol\u00edgono a textura 3D \n\n \n\n\n\n 31\n\n2.3 Compress\u00e3o de Dados Volum\u00e9tricos  \n\nDiversos trabalhos recentes em visualiza\u00e7\u00e3o volum\u00e9trica abordam t\u00e9cnicas de \ncompress\u00e3o de dados volum\u00e9tricos de grandes dimens\u00f5es para diminuir o volume a ser \ntransmitido e, conseq\u00fcentemente, o tempo de visualiza\u00e7\u00e3o destes dados. V\u00e1rias destas \nt\u00e9cnicas utilizam abordagens hier\u00e1rquicas na visualiza\u00e7\u00e3o, enquanto outras focam em \narmazenar e transmitir eficientemente os dados volum\u00e9tricos.  \n\nPor exemplo, Benson e Davis (2002) e DeBry et al. (2002) desenvolveram, \nindependentemente, abordagens semelhantes para representa\u00e7\u00e3o de texturas em octrees, \nonde apenas a parte do volume (nodos) que intercepta uma superf\u00edcie do modelo \ngeom\u00e9trico \u00e9 armazenada.  \n\nTodas estas t\u00e9cnicas de compress\u00e3o de dados volum\u00e9tricos est\u00e1ticos s\u00e3o baseadas \nem uma propriedade denominada \u201ccoer\u00eancia espacial\u201d, ou seja, no fato de que voxels \nadjacentes t\u00eam valores semelhantes de intensidade de cor ou outra propriedade \nqualquer. Para dados din\u00e2micos, a coer\u00eancia temporal \u00e9 levada em considera\u00e7\u00e3o. As \nprincipais e mais recentes t\u00e9cnicas de compress\u00e3o de dados volum\u00e9tricos s\u00e3o descritas a \nseguir. \n\n2.3.1 Visualiza\u00e7\u00e3o Volum\u00e9trica com Multiresolu\u00e7\u00e3o Baseada em Octrees \ncomo Representa\u00e7\u00e3o de Texturas \n\nPara grandes volumes de dados, isto \u00e9, volumes maiores que a capacidade de \narmazenamento de textura em mem\u00f3ria, uma decomposi\u00e7\u00e3o em sub-volumes, a qual \npode implicar em um esquema de compress\u00e3o, \u00e9 aplicada por Boada et al. (2001). Estes \nautores desenvolveram uma t\u00e9cnica de visualiza\u00e7\u00e3o direta de volumes usando texturas \n3D, onde a textura \u00e9 obtida atrav\u00e9s de uma representa\u00e7\u00e3o hier\u00e1rquica, do tipo octree, do \nvolume de dados usando dois crit\u00e9rios: homogeneidade e import\u00e2ncia dos dados.  \n\nA Figura 2.17 apresenta a id\u00e9ia b\u00e1sica desta t\u00e9cnica, onde a constru\u00e7\u00e3o da octree \u00e9 \nrealizada numa etapa de pr\u00e9-processamento do volume de dados, e seu caminhamento \nna etapa de visualiza\u00e7\u00e3o leva em conta algumas defini\u00e7\u00f5es do usu\u00e1rio. Um conjunto de \nnodos desta octree, chamado de corte, tamb\u00e9m pode ser selecionado pelo usu\u00e1rio \ndurante o caminhamento da \u00e1rvore, determinando um sub-volume a ser visualizado. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \nTextura \n\nvisualizada\n\noctree \n\nCorte (sele\u00e7\u00e3o de \num sub-volume) \n\nRepresenta\u00e7\u00e3o \nem octree \n\ncorte \n\nVolume de \ndados \n\n \n\nFIGURA 2.17 - Esquema geral do m\u00e9todo de visualiza\u00e7\u00e3o volum\u00e9trica com \nmultiresolu\u00e7\u00e3o baseada em octree (extra\u00eddo de Boada et al., 2001) \n\n \n\n\n\n 32\n\nPara a constru\u00e7\u00e3o da octree, \u00e9 necess\u00e1rio um crit\u00e9rio para determinar quando uma \nregi\u00e3o do volume (sub-volume) \u00e9 importante. O crit\u00e9rio considerado por Boada et al. \n(2001) foi a homogeneidade (coer\u00eancia espacial) dos dados, com uma sele\u00e7\u00e3o on-line de \nregi\u00f5es de grande interesse, as quais ser\u00e3o representadas em m\u00e1xima resolu\u00e7\u00e3o. \n\nDurante a constru\u00e7\u00e3o da estrutura, a homogeneidade dos dados refere-se aos \nvalores de intensidade das amostras do volume que est\u00e3o associadas aos nodos da \nestrutura e que satisfazem um dado intervalo de valores. Para cada nodo, um erro \u00e9 \ncalculado, representando o grau de homogeneidade das amostras, ou seja, as diferen\u00e7as \nentre os valores reais dos voxels de uma regi\u00e3o representada por um nodo na octree e o \nvalor obtido por uma interpola\u00e7\u00e3o trilinear dos mesmos. Este erro representa o grau de \nhomogeneidade de um sub-volume coberto pelo nodo. \n\nO caminhamento na octree \u00e9 de cima para baixo (top-down) para selecionar os \nnodos que comp\u00f5em o corte. Um corte ser\u00e1 v\u00e1lido quando o sub-volume resultante \ngarantir que todas as regi\u00f5es do conjunto de dados correspondentes aos nodos \nparticipantes do corte tenham uma representa\u00e7\u00e3o no volume total, satisfazendo um erro \ndeterminado pelo usu\u00e1rio. Em contrapartida, o grau de compress\u00e3o pode ser baixo \nconsiderando apenas a homogeneidade dos sub-volumes e, por essa raz\u00e3o, o usu\u00e1rio tem \nde definir, al\u00e9m de um limiar de erro aceit\u00e1vel, um valor de import\u00e2ncia ao nodo. A \nimport\u00e2ncia do nodo apenas determina se est\u00e1 dentro ou fora da regi\u00e3o de interesse e \npode ser definida pelo usu\u00e1rio atrav\u00e9s da sele\u00e7\u00e3o de uma sub-regi\u00e3o 3D do volume de \ndados.  \n\nFinalmente, a visualiza\u00e7\u00e3o do sub-conjunto de nodos (textura 3D) \u00e9 realizada na \nordem de tr\u00e1s para frente, onde um cubo, envolt\u00f3rio do objeto e centrado no nodo \ncentral da estrutura, \u00e9 formado por um conjunto de pol\u00edgonos paralelos ao plano de \nproje\u00e7\u00e3o. \n\n2.3.2 Mapeamento de Texturas Adaptativas \n\nEsta t\u00e9cnica \u00e9 fruto do recente trabalho de Kraus e Ertl (2002) e apresenta um \nm\u00e9todo de compress\u00e3o de dados (2D, 3D e campos de ilumina\u00e7\u00e3o 4D) para representar \nmapeamento de texturas adaptativas (adaptive texture maps), isto \u00e9, mapeamento de \ntexturas com resolu\u00e7\u00f5es locais adaptativas e com fronteiras adaptativas. O m\u00e9todo \ntrabalha em duas etapas, onde uma decomposi\u00e7\u00e3o do volume de dados \u00e9 realizada e o \nresultado \u00e9 armazenado em duas texturas. Na primeira etapa, uma textura armazena um \nfator de escala (resolu\u00e7\u00e3o) e \u00edndices para os dados que s\u00e3o realmente armazenados em \noutra textura, caracterizando a segunda etapa. \n\nA Figura 2.18 apresenta um exemplo, em duas dimens\u00f5es, do m\u00e9todo. A Figura \n2.18(a) representa a primeira etapa, onde os dados s\u00e3o subdivididos em c\u00e9lulas, as quais \narmazenam uma coordenada de origem e um fator de escala dos dados  que s\u00e3o \narmazenados em outra textura (Figura 2.18(b)). \n\nEste fator de escala \u00e9 calculado a partir da c\u00e9lula resultante da decomposi\u00e7\u00e3o e \nrepresenta o qu\u00e3o semelhante esta c\u00e9lula \u00e9 em rela\u00e7\u00e3o a uma c\u00e9lula vazia. A c\u00e9lula ser\u00e1 \narmazenada na segunda textura seguindo a resolu\u00e7\u00e3o ou escala calculada. O processo de \ndescompress\u00e3o \u00e9 realizado em hardware, acessando a textura da primeira etapa que \nresultar\u00e1 em um outro acesso (dependente) \u00e0 textura da segunda etapa. Os acessos a \ntexturas, principalmente os acessos dependentes, utilizando hardware ficar\u00e3o mais \nclaros a partir do pr\u00f3ximo cap\u00edtulo. \n\n \n\n\n\n 33\n\n \n\n \n\n \n(b)(a) \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nFIGURA 2.18 - Ilustra\u00e7\u00e3o em 2D do mapeamento de texturas adaptativas. (a) \u00cdndice: \nfator de escala e coordenadas para os dados comprimidos. (b) Dados comprimidos \n\n(Kraus e Ertl, 2002). \n\nNo processo de visualiza\u00e7\u00e3o do mapeamento de texturas adaptativas, o acesso \u00e0 \ntextura atrav\u00e9s de coordenadas (s, t) \u00e9 efetivado realizando os seguintes passos (Figura \n2.19): \n\n\u2022 determina\u00e7\u00e3o da c\u00e9lula na textura de \u00edndices que contem o ponto (s ,t); \n\n\u2022 c\u00e1lculo das coordenadas (s0 ,t0) que correspondem a origem desta c\u00e9lula; \n\n\u2022 acesso \u00e0 textura de \u00edndices que corresponde a esta c\u00e9lula para recuperar o \nfator de escala m e a origem (s0\u2019,t0\u2019) correspondente a esta c\u00e9lula na textura \nde dados comprimidos; \n\n\u2022 c\u00e1lculo das coordenadas (s\u2019,t\u2019) na textura de dados comprimidos \ncorrespondente a (s,t) na textura de \u00edndices, levando em conta o fator de \nescala m; \n\n\u2022 acesso \u00e0 textura de dados comprimidos atrav\u00e9s de (s\u2019, t\u2019) e interpola\u00e7\u00e3o. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nFIGURA 2.19 - Visualiza\u00e7\u00e3o de texturas na t\u00e9cnica de mapeamento adaptativo de \ntexturas (Kraus e Ertl, 2002) \n\n \n\n \n\n\n\n 34\n\nA Figura 2.20 mostra um exemplo para este m\u00e9todo com dados volum\u00e9tricos, \nonde (a) ilustra a textura de \u00edndices e (b) a textura contendo os dados comprimidos. \n\n \n(b)(a) \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nFIGURA 2.20 - Textura 3D de \u00edndices (a) e textura 3D com dados comprimidos (b) \n(Kraus e Ertl, 2002) \n\nO m\u00e9todo tamb\u00e9m apresentou, em abordagem semelhante aos dados 3D, um \nexemplo de campos de luz (light fields), representados por dados de quatro dimens\u00f5es \n(Levoy e Hanrahan, 1996). Para tal, utilizou-se duas texturas 3D para armazenamento \ndos dados. \n\n\u00c9 importante ressaltar que este trabalho de Kraus e Ertl (2002) \u00e9 semelhante \u00e0 \nt\u00e9cnica a ser apresentada nesta disserta\u00e7\u00e3o, mesmo tendo sido desenvolvidos totalmente \nindependentes. Entretanto, embora este m\u00e9todo seja eficiente na visualiza\u00e7\u00e3o de grandes \nvolumes de dados, assim como outros m\u00e9todos descritos em Cabral et al. (1994) e \nLaMar et al. (1999), n\u00e3o aborda a visualiza\u00e7\u00e3o de v\u00e1rios volumes que representam \ninstantes de tempo, ou seja, n\u00e3o aborda visualiza\u00e7\u00e3o volum\u00e9trica de dados din\u00e2micos. \n\n2.3.3 \u00c1rvores TSP \n\nEnquanto um volume de dados est\u00e1tico normalmente \u00e9 caracterizado pela \npropriedade da coer\u00eancia espacial, volumes que variam com o tempo apresentam \ntamb\u00e9m coer\u00eancia temporal, ou seja, os valores de intensidade dos voxels tendem a n\u00e3o \nmudar drasticamente de um instante de tempo para o pr\u00f3ximo. Embora estas \ncaracter\u00edsticas de coer\u00eancia sejam um ponto crucial para a explora\u00e7\u00e3o de t\u00e9cnicas de \ncompress\u00e3o de dados, somente recentemente est\u00e3o sendo exploradas por um pequeno \nn\u00famero de pesquisas. \n\nA t\u00e9cnica proposta por Shen et al. (1999) apresenta uma estrutura hier\u00e1rquica \nchamada \u00e1rvore TSP (Time-Space Partitioning) para visualiza\u00e7\u00e3o de uma s\u00e9rie temporal \nde dados volum\u00e9tricos, representando-os tanto no dom\u00ednio espacial quanto temporal. A \nbase desta estrutura \u00e9 praticamente uma octree, mas com o adicional de conter n\u00e3o s\u00f3 \ninforma\u00e7\u00f5es espaciais, mas tamb\u00e9m temporais. Para armazenar a informa\u00e7\u00e3o temporal, \ncada nodo da \u00e1rvore TSP \u00e9 uma \u00e1rvore bin\u00e1ria que divide tamb\u00e9m, recursivamente, o \ntempo representado no conjunto volum\u00e9trico de dados (Figura 2.21). As informa\u00e7\u00f5es \narmazenadas nos nodos da \u00e1rvore bin\u00e1ria s\u00e3o o valor m\u00e9dio dos voxels componentes do \nsub-volume e um erro espacial e temporal referentes a um dado per\u00edodo de tempo. \n\n \n\n\n\n 35\n\n \n\nt=0 t=1 t=2 t=3 \n\n[0,1] \n\n[0,3]  \n\n \n\n \n\n \n\n \n\n \n\nFIGURA 2.21 - Exemplo de \u00e1rvore TSP para dados 2D, representado 4 instantes de \ntempo (Shen et al., 1999) \n\nA visualiza\u00e7\u00e3o desta estrutura, utilizando a t\u00e9cnica de Ray Casting, \u00e9 realizada \npercorrendo apenas os nodos contidos no instante de tempo atual, onde os sub-volumes \ns\u00e3o visualizados em imagens independentes que s\u00e3o armazenadas em mem\u00f3ria cache. \n\nNa continua\u00e7\u00e3o do trabalho envolvendo \u00e1rvores TSP (Ellsworth et al., 2000), foi \ndesenvolvida a visualiza\u00e7\u00e3o utilizando texturas 3D em hardware, mas com duas \naltera\u00e7\u00f5es em rela\u00e7\u00e3o \u00e0 abordagem de mapeamento de texturas 3D padr\u00e3o (se\u00e7\u00e3o \n2.2.2.4.2). Uma vez gerados os sub-volumes pr\u00f3prios \u00e0 visualiza\u00e7\u00e3o, tais sub-volumes \nser\u00e3o visualizados seguindo um fator de toler\u00e2ncia de erro espacial: os sub-volumes que \nestiverem dentro da faixa de erro s\u00e3o visualizados usando uma cor constante enquanto \nque os outros s\u00e3o visualizados usando uma textura. Neste \u00faltimo caso, os sub-volumes \nque estiverem na faixa de toler\u00e2ncia temporal e representem um per\u00edodo de tempo s\u00e3o \nvisualizados usando a textura que representa o determinado instante de tempo. Com \nisso, a t\u00e9cnica permite o compartilhamento de texturas entre os instantes de tempo. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n\n\n 36\n\n3 Hardware Gr\u00e1fico \nUma das grandes dificuldades da visualiza\u00e7\u00e3o interativa de dados volum\u00e9tricos \u00e9 a \n\nquantidade de dados envolvida em rela\u00e7\u00e3o \u00e0s limita\u00e7\u00f5es de capacidade de \narmazenamento e processamento dos computadores. Apesar do desenvolvimento de \nalgoritmos otimizados, apenas o avan\u00e7o recente da tecnologia de hardware, \nprincipalmente em placas gr\u00e1ficas aceleradoras, possibilitou uma grande expans\u00e3o e \nutiliza\u00e7\u00e3o destas aplica\u00e7\u00f5es. \n\nAs placas gr\u00e1ficas aceleradoras v\u00eam incorporando muitos aspectos que antes eram \nrealizados por software e que permitem in\u00fameros efeitos gr\u00e1ficos complexos, al\u00e9m de \nconseguir processar cenas compostas por milh\u00f5es de tri\u00e2ngulos em tempo real. Al\u00e9m \ndisto, uma caracter\u00edstica importante e inovadora \u00e9 a possibilidade de programa\u00e7\u00e3o das \nfuncionalidades existentes na arquitetura do pipeline gr\u00e1fico da placa.  \n\nDeterminados processos do pipeline gr\u00e1fico s\u00e3o mais suscet\u00edveis ao aspecto de \nprograma\u00e7\u00e3o do que outros. A unidade ou processo do pipeline que trata os v\u00e9rtices dos \nobjetos gr\u00e1ficos, por exemplo, \u00e9 flex\u00edvel a opera\u00e7\u00f5es de programa\u00e7\u00e3o. A unidade de \nprograma\u00e7\u00e3o de v\u00e9rtices (vertex shaders) poder\u00e1 realizar v\u00e1rias opera\u00e7\u00f5es e c\u00e1lculos \ncom os atributos dos v\u00e9rtices (posi\u00e7\u00e3o, cor e normal, por exemplo) para produzir efeitos, \ndentre outros, de ilumina\u00e7\u00e3o, skinning, morphing e bump mapping. \n\nOutro processo importante do pipeline que pode ser programado \u00e9 aquele que gera \na cor final de um pixel na tela. A unidade de programa\u00e7\u00e3o de pixels ou fragmentos (pixel \nou fragment shader) opera com os atributos de cada pixel para a composi\u00e7\u00e3o final da cor \nde cada fragmento. Esta unidade de programa\u00e7\u00e3o produz efeitos muito interessantes, j\u00e1 \nque se pode fazer acessos a v\u00e1rias texturas pr\u00f3prias do hardware para combinar o \nresultado destes acessos aos pr\u00f3prios atributos dos pixels. Estes acessos a texturas v\u00eam \nsendo explorados por pesquisas utilizando texturas 3D na visualiza\u00e7\u00e0o de dados \nvolum\u00e9tricos. \n\nA Figura 3.1 apresenta um fluxo de dados geral da GPU (Unidade Gr\u00e1fica de \nProcessamento) do hardware, contendo os processos program\u00e1veis e os n\u00e3o-\nprogram\u00e1veis. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nAPI: \nOpenGL \n\nou DirectX \n\nFrame buffer\n\nTestes de frame-buffer \ne blending \n\nTexturas \n\n\u00cdndices dos v\u00e9rtices \n\nMatrizes, posi\u00e7\u00e3o da luz e outros par\u00e2metros \n\nProcessador \nProgram\u00e1vel \n\nde Fragmentos \n\nRasteriza\u00e7\u00e3o \ne Interpola\u00e7\u00e3o \n\nPrimitive \nProcessador \nProgram\u00e1vel \nde V\u00e9rtices \n\nCPU / \nAplica\u00e7\u00e3o \n\n \n\nFIGURA 3.1 - Fluxo de dados e unidades program\u00e1veis do hardware (NVIDIA, 2003) \n\n \n\n\n\n 37\n\nPara programar estas unidades do pipeline gr\u00e1fico do hardware, uma API \n(Application Program Interface) foi desenvolvida pela empresa NVIDIA Coorporation, \ndenominada C for Graphics (Cg). A linguagem Cg permite um alto n\u00edvel de abstra\u00e7\u00e3o \ndo hardware gr\u00e1fico semelhante \u00e0 linguagem C, tanto em sua sintaxe quanto no pr\u00f3prio \nn\u00edvel de abstra\u00e7\u00e3o, podendo ser compilada para gerar c\u00f3digo em aplica\u00e7\u00f5es que utilizam \nDirectX ou OpenGL. Ao longo deste cap\u00edtulo, exemplos de c\u00f3digos de vertex ou \nfragment shaders ser\u00e3o apresentados em Cg admitindo que o leitor tenha um pr\u00e9vio \nconhecimento da linguagem, que pode ser obtido atrav\u00e9s de um tutorial apropriado \n(NVIDIA, 2003). \n\nA seguir, estas duas unidades principais de programa\u00e7\u00e3o em hardware s\u00e3o \napresentadas juntamente com exemplos descritos na linguagem de programa\u00e7\u00e3o Cg. \nEntretanto, uma \u00eanfase maior ser\u00e1 abordada para as caracter\u00edsticas da unidade fragment \nshader, pois este trabalho utilizar\u00e1 fundamentalmente as propriedades das texturas 3D \npresentes no hardware. \n\n3.1 Unidade de Programa\u00e7\u00e3o de V\u00e9rtices (vertex shader) \n\nPrimitivas simples, como tri\u00e2ngulos, s\u00e3o usadas para representar diversas formas \nou objetos. As principais informa\u00e7\u00f5es destas primitivas est\u00e3o relacionadas com seus \nv\u00e9rtices. Tais informa\u00e7\u00f5es dos v\u00e9rtices s\u00e3o enviadas a GPU e representam, por exemplo, \nposi\u00e7\u00f5es (x,y,z,w), normais (x,y,z), cores (r,g,b,a) ou coordenadas de textura (s,q,r,t). \nEm seguida, transforma\u00e7\u00f5es geom\u00e9tricas, c\u00e1lculo de ilumina\u00e7\u00e3o e gera\u00e7\u00e3o de \ncoordenadas de textura s\u00e3o executadas pela unidade de vertex shaders. \n\nDesta forma, para esta unidade program\u00e1vel do pipeline gr\u00e1fico do hardware, um \nprograma \u00e9 composto por uma seq\u00fc\u00eancia de instru\u00e7\u00f5es que executa opera\u00e7\u00f5es a partir de \npar\u00e2metros compostos por caracter\u00edsticas dos v\u00e9rtices dos dados e resulta em outros \npar\u00e2metros de sa\u00edda referentes a cada v\u00e9rtice. Uma representa\u00e7\u00e3o esquem\u00e1tica do \nmodelo de vertex shader est\u00e1 descrita na Figura 3.2. Estes programas acessam quatro \ntipos de unidades de mem\u00f3ria: atributos dos v\u00e9rtices (apenas leitura), par\u00e2metros de \nentrada para o programa (apenas leitura), registradores tempor\u00e1rios (leitura e grava\u00e7\u00e3o) \ne registradores de sa\u00edda (apenas grava\u00e7\u00e3o). \n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nprograma \n\nRegistradores \nde sa\u00edda \n\nRegistradores \ntempor\u00e1rios \n\nPar\u00e2metros do \n\nAtributos dos v\u00e9rtices \n\n \nUnidade de programa\u00e7\u00e3o \n\nde v\u00e9rtices \n\nFIGURA 3.2 - Modelo do vertex shader \n\nOs dados referentes a cada v\u00e9rtice de entrada s\u00e3o armazenados nos registradores \nde atributos dos v\u00e9rtices. Estes dados representam, entre outros par\u00e2metros, posi\u00e7\u00e3o, \n\n \n\nCarla Freitas\n\u00c9 em mai\u00fasculas??\n\n\n\n 38\n\ncor, normal e coordenadas de textura. A aplica\u00e7\u00e3o tamb\u00e9m pode enviar par\u00e2metros que \nn\u00e3o t\u00eam liga\u00e7\u00e3o direta com os v\u00e9rtices, proporcionando a cria\u00e7\u00e3o de efeitos especiais. \nEstes par\u00e2metros s\u00e3o, usualmente, matrizes de transforma\u00e7\u00e3o, par\u00e2metros de \nilumina\u00e7\u00e3o, valores pr\u00e9-computados, etc. \n\nA partir destes dados fornecidos pela aplica\u00e7\u00e3o, a unidade de programa\u00e7\u00e3o executa \nas opera\u00e7\u00f5es especificadas e pode armazenar nos registradores tempor\u00e1rios resultados \nintermedi\u00e1rios durante a execu\u00e7\u00e3o do programa para uma opera\u00e7\u00e3o posterior. Ap\u00f3s a \nexecu\u00e7\u00e3o completa do programa, os resultados s\u00e3o armazenados nos registradores de \nsa\u00edda. \n\n3.1.1 Efeitos Especiais \n\nMuitos efeitos especiais podem ser obtidos usando a programa\u00e7\u00e3o em hardware \nde v\u00e9rtices. Abaixo, est\u00e3o descritos alguns efeitos publicados (NVIDIA, 2001): \n\n\u2022 Skinning: a anima\u00e7\u00e3o de esqueletos requer a aplica\u00e7\u00e3o de pesos aos \nv\u00e9rtices do modelo, proporcionais ao impacto de cada osso. Esta t\u00e9cnica \ntamb\u00e9m requer a aplica\u00e7\u00e3o de in\u00fameras matrizes de transforma\u00e7\u00e3o \n(movimenta\u00e7\u00e3o) para cada v\u00e9rtice; \n\n\u2022 Deforma\u00e7\u00e3o din\u00e2mica de superf\u00edcies: a mudan\u00e7a de posi\u00e7\u00e3o dos v\u00e9rtices \npermite com que os vertex shaders executem deforma\u00e7\u00f5es no formato de \num objeto. Esse movimento dos v\u00e9rtices pode ser regido por uma simples \nfun\u00e7\u00e3o ao longo do tempo; \n\n\u2022 Modelagem procedural: semelhante a deforma\u00e7\u00f5es, a modelagem \nprocedural pode ser usada para descrever o formato de um objeto \nutilizando a programa\u00e7\u00e3o em hardware de v\u00e9rtices. Sistemas de part\u00edculas \ntamb\u00e9m podem ser criados usando o mesmo conceito; \n\n\u2022 Morphing: determinados valores de intensidade representando pesos s\u00e3o \ndefinidos para cada v\u00e9rtice e utilizados para transformar um objeto em \noutro; \n\n\u2022 Distor\u00e7\u00e3o: a cria\u00e7\u00e3o de matrizes de transforma\u00e7\u00e3o permite um efeito de \ndistor\u00e7\u00e3o diferente dos efeitos criados por um pipeline fixo de v\u00e9rtices. Um \nexemplo desta t\u00e9cnica s\u00e3o os efeitos do tipo \u201colho de peixe\u201d; \n\n\u2022 Ambiente: efeitos de neblina podem ser obtidos mudando em tempo real \nas coordenadas da neblina, que depender\u00e3o de sua altura ou eleva\u00e7\u00e3o. \n\n3.1.2 Exemplo em Cg \n\nUm exemplo muito interessante utilizando vertex shaders foi desenvolvido no \ngrupo de Computa\u00e7\u00e3o Gr\u00e1fica da UFRGS (Dietrich e Comba, 2003), denominado \noriginalmente Repulsive Potencial Fields. Este trabalho implementa os conceitos de \nmodelagem procedural e sistemas de part\u00edculas para representar o movimento de neve \ncaindo em um ambiente composto pelo fluxo de um rio e alguns obst\u00e1culos. Todas as \npart\u00edculas (neve e \u00e1gua do rio) desviar\u00e3o destes obst\u00e1culos a partir de c\u00e1lculos de \nrepuls\u00e3o realizados com os v\u00e9rtices dos elementos que formam tais part\u00edculas. A Figura \n3.3(a) mostra uma imagem resultante deste exemplo e (b) ilustra o c\u00f3digo em Cg para o \nvertex shader. \n\n \n\n\n\n 39\n\n \n (a)\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n  \n\n \n\n \n \n \n \n \n \n \n \n\n \n\n \n\nFIGURA 3.3 - Exemplo do efeito especial (a) e seu respectivo c\u00f3digo em Cg (b) para \nvertex shader: Repulsive Potential Fields (Dietrich e Comba, 2003) \n\nstruct app2vert : application2vertex { \nfloat4 position : POSITION; \nfloat3 normal   : NORMAL; \n\n   float4 color    : DIFFUSE; \n   float4 disloc   : SPECULAR; \n}; \nstruct vert2frag : vertex2fragment { \n\nfloat4 HPOS : POSITION; \nfloat4 COL0 : COLOR0; \n\n}; \nvert2frag main( app2vert IN, \n                uniform float4x4 ModelViewProj, uniform float4x4 control, \n                uniform float4x4 obstacle     , uniform float4   clock ) { \n\nvert2frag OUT; float t, it; float4 P, O; \n \n //> FLUXO DO RIO \n t   = IN.disloc.w + clock.x / 6000.0f; // flow \n t   = (t > 1.0f) ? t - 1.0f : t; \n it  = 1.0f - t; \n P.x = it * it * it;      // P0 \n P.y = 3.0f * t * it * it; // P1 \n P.z = 3.0f * t * t * it;  // P2 \n P.w = t * t * t;      // P3 \n\nOUT.HPOS.x = dot( P, float4(control[0][0], control[1][0], control[2][0], \ncontrol[3][0]) ); \n\nOUT.HPOS.y = dot( P, float4(control[0][1], control[1][1], control[2][1], \ncontrol[3][1]) ); \n\nOUT.HPOS.z = dot( P, float4(control[0][2], control[1][2], control[2][2], \ncontrol[3][2]) ); \n\n OUT.HPOS   = OUT.HPOS + IN.disloc; \n OUT.HPOS.w = 1.0f; \n //&lt;FLUXO DO RIO \n //> REPULSIVIDADE DO RIO E DA NEVE AO LONGO DO OBSTACULO \n float g, d, s;  float4 N; \n \n N   = OUT.HPOS - obstacle[0]; N.w = 0.0f; \n d   = length( N ); \n N   = normalize( N ); \n s   = 1.0f / (obstacle[0].w * obstacle[0].w); \n g   = exp(-d * d * s) * obstacle[0].w; // obstacle power \n N   = N * g; \n O   = OUT.HPOS + N + IN.position; \n //&lt;REPULSIVIDADE DO RIO E DA NEVE AO LONGO DO OBSTACULO \n \n O.w      = 1.0f; \n OUT.HPOS = mul( ModelViewProj, O ); \n OUT.COL0 = IN.color; \n return OUT; \n} \n\n(b)\n\n \n\n\n\n 40\n\nEmbora o exemplo da Figura 3.3 n\u00e3o seja aqui detalhado minuciosamente, j\u00e1 que \nn\u00e3o \u00e9 o objetivo principal deste trabalho, vale ressaltar que cada v\u00e9rtice cont\u00e9m quatro \npropriedades: posi\u00e7\u00e3o, normal, cor e um valor de deslocamento. Al\u00e9m destes par\u00e2metros \noriundos das caracter\u00edsticas dos v\u00e9rtices (IN), mais quatro par\u00e2metros de entrada ao \nprograma foram definidos: matriz de proje\u00e7\u00e3o (ModelViewProj), matriz com pontos \ncontrole de uma curva B\u00e8zier (control) que representa a trajet\u00f3ria do rio, matriz \nrepresentando a posi\u00e7\u00e3o e o raio do obst\u00e1culo (obstacle) e um valor que representa o \ntempo (clock). A partir destes dados, c\u00e1lculos s\u00e3o realizados no procedimento principal \ne os resultados produzidos (posi\u00e7\u00e3o e cor), referentes a cada v\u00e9rtice, s\u00e3o gravados nos \nregistradores de sa\u00edda.  Este procedimento principal, por sua vez, divide-se em duas \netapas: execu\u00e7\u00e3o do c\u00e1lculo do fluxo das part\u00edculas do rio na trajet\u00f3ria da curva \nestipulada e c\u00e1lculo da repuls\u00e3o das part\u00edculas de \u00e1gua e neve pelo obst\u00e1culo. \n\n3.2 Unidade de Programa\u00e7\u00e3o de Fragmentos (pixel ou fragment \nshader) \n\nEmbora a programa\u00e7\u00e3o em hardware com v\u00e9rtices ofere\u00e7a grande flexibilidade \npara c\u00e1lculos e interpola\u00e7\u00e3o de dados em baixa freq\u00fc\u00eancia (por v\u00e9rtices), a programa\u00e7\u00e3o \npor fragmento ou por pixel \u00e9 necess\u00e1ria para informa\u00e7\u00f5es de alta freq\u00fc\u00eancia, isto \u00e9, \ninforma\u00e7\u00f5es que mudam muito mais rapidamente e que n\u00e3o conseguem ser capturadas \npelos v\u00e9rtices.  \n\nEste controle de dados no n\u00edvel de pixel evoluiu n\u00e3o s\u00f3 com o desenvolvimento do \nhardware, mas tamb\u00e9m com a evolu\u00e7\u00e3o do pipeline gr\u00e1fico. Enquanto algumas placas \ngr\u00e1ficas ainda disponibilizam apenas uma textura (1D, 2D ou 3D) para mapeamento, os \navan\u00e7os recentes introduziram m\u00faltiplas texturas. Atrav\u00e9s da unidade de programa\u00e7\u00e3o \npor fragmento, efeitos especiais interessantes podem ser obtidos atrav\u00e9s de m\u00faltiplas \ntexturas. A cor final de um pixel, por exemplo, pode ser determinada atrav\u00e9s da \ncombina\u00e7\u00e3o de v\u00e1rios acessos \u00e0s diferentes texturas dispon\u00edveis com outros atributos, \ncomo valores de ilumina\u00e7\u00e3o difusa e especular.  \n\nPara aumentar ainda mais o poder de combina\u00e7\u00e3o dos dados, o pipeline gr\u00e1fico \npode ainda manipular os valores de acesso \u00e0s texturas. Conectando acessos seq\u00fcenciais \n\u00e0s texturas dispon\u00edveis, coordenadas de acesso a uma determinada textura podem \ndepender diretamente do resultado de um acesso pr\u00e9vio a outra textura. Isto quer dizer \nque o resultado do acesso a uma textura, com coordenadas de textura (s,t,r,q), pode n\u00e3o \nrepresentar uma cor no sistema RGBA (r,g,b,a) e sim novas coordenadas de textura \n(s\u2019,t\u2019,r\u2019,q\u2019) para um pr\u00f3ximo acesso. A este processo deu-se o nome de \u201ctexturas \ndependentes\u201d e para a unidade program\u00e1vel que envolve os acessos a texturas e c\u00e1lculos \ncom seus resultados, chamou-se texture shader ou unidade de programa\u00e7\u00e3o de texturas. \nEsta unidade do hardware desempenha papel importante neste trabalho. \n\n3.2.1 Unidade de Programa\u00e7\u00e3o de Texturas (texture shader) \n\nA funcionalidade das texturas dependentes permite uma grande flexibilidade e um \nalto poder computacional em n\u00edvel de pixel, j\u00e1 que as texturas poder\u00e3o conter n\u00e3o \napenas cor e sim informa\u00e7\u00f5es codificadas que podem ser trabalhadas na execu\u00e7\u00e3o de \numa fun\u00e7\u00e3o, gerando a cor final do pixel. A Figura 3.4 exemplifica o pipeline referente \nao hardware da GeForce4, que permite a implementa\u00e7\u00e3o do conceito de texturas \ndependentes.  \n\n \n\n\n\n 41\n\nNa Figura 3.4, os pixels oriundos da unidade rasteriza\u00e7\u00e3o passam por uma \nseq\u00fc\u00eancia de at\u00e9 tr\u00eas acessos a texturas dependentes e as cores resultantes s\u00e3o \narmazenadas nos registradores de sa\u00edda, que podem ser combinadas a outros atributos \nou cores armazenadas em um buffer (frame buffer) para gera\u00e7\u00e3o da cor final do pixel.  \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nTexture shader \n\nAtributos \n\nAtributos \n\nAtributos \n\nAtributos \n\n(r\u2019\u2019,g\u2019\u2019,b\u2019\u2019,a\u2019\u2019)\n\n(r,g,b,a) \n\nFrame buffer\ne \n\nBlending \n\n(r\u2019,g\u2019,b\u2019,a\u2019) \n\nAtributos dos v\u00e9rtices \n\nRegistra-\ndores  \n\nde Sa\u00edda (s\u2019\u2019,t\u2019\u2019,r\u2019\u2019,q\u2019\u2019)\n\n(s\u2019,t\u2019,r\u2019,q\u2019) \n\n(s,t,r,q) \n\nTextura 3 \n\n(s\u2019\u2019\u2019,t\u2019\u2019\u2019,r\u2019\u2019\u2019,q\u2019\u2019\u2019) \n(r\u2019\u2019\u2019,g\u2019\u2019\u2019,b\u2019\u2019\u2019,a\u2019\u2019\u2019) \n\nTextura 2 \n\nTextura 1 \n\nTextura 0 \n\nRasteri- \nzador \n\nFIGURA 3.4 - Fragment shader do hardware GeForce4 \n\nAssim, a unidade de programa\u00e7\u00e3o de texturas ou simplesmente texture shader \nconsiste, no hardware da GeForce4, em at\u00e9 quatro est\u00e1gios de manipula\u00e7\u00e3o de acessos a \ntexturas (Figura 3.4). Cada est\u00e1gio executa determinadas opera\u00e7\u00f5es nas coordenadas de \ntextura em quest\u00e3o para produzir tanto um novo conjunto de coordenadas de textura \npara o pr\u00f3ximo est\u00e1gio (texturas dependentes) quanto a cor final do pixel no est\u00e1gio \natual. O programa da unidade texture shader determina, ent\u00e3o, o comportamento do \nacesso \u00e0 textura seguindo uma poss\u00edvel depend\u00eancia impl\u00edcita em rela\u00e7\u00e3o aos est\u00e1gios \nanteriores e uma poss\u00edvel combina\u00e7\u00e3o ou manipula\u00e7\u00e3o dos valores de cor obtidos. \n\nUm exemplo da aplicabilidade das texturas dependentes encontra-se no trabalho \nde Engel et al. (2001). Este trabalho apresenta dois algoritmos de visualiza\u00e7\u00e3o \nvolum\u00e9trica baseados em textura, um para textura 2D e outro para textura 3D, ambos \nutilizando o conceito de textura dependente presente no hardware GeForce3. Uma \ndeterminada textura (a ser utilizada como dependente), em ambos algoritmos, cont\u00e9m \nvalores escalares obtidos a partir de uma p\u00f3s-classifica\u00e7\u00e3o (aplica\u00e7\u00e3o de uma fun\u00e7\u00e3o de \ntransfer\u00eancia ap\u00f3s interpola\u00e7\u00e3o) do conjunto de volumes de dados. Durante a \nvisualiza\u00e7\u00e3o dos pol\u00edgonos a serem mapeados pela textura principal, dois pares de \nvalores escalares s\u00e3o amostrados de dois planos (pol\u00edgonos) adjacentes (Figura 3.5), \nonde cada pixel de um plano corresponde \u00e0 contribui\u00e7\u00e3o de cor e opacidade ao longo de \num segmento de raio. Como cada pixel destes dois pol\u00edgonos adjacentes corresponde ao \nmesmo raio, uma composi\u00e7\u00e3o destes planos em um \u00fanico valor \u00e9 realizada. Assim, estes \ndois pares de valores escalares s\u00e3o usados para realizar um acesso dependente \u00e0 textura \ncriada pela p\u00f3s-classifica\u00e7\u00e3o, a qual cont\u00e9m os valores de cor e opacidade pr\u00e9-\ncalculados. \n\n \n\n \n\n \n\n\n\n 42\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nFIGURA 3.5 - Par de planos adjacentes (Engel et al., 2001) \n\n3.2.2 Efeitos Especiais \n\nV\u00e1rios efeitos especiais podem ser obtidos usando fragment shaders. Abaixo, \nest\u00e3o descritos alguns efeitos publicados (NVIDIA, 2001): \n\n Depth sprites: visualiza\u00e7\u00e3o de objetos tridimensionais atrav\u00e9s de uma \nopera\u00e7\u00e3o de mapeamento de textura em uma superf\u00edcie plana. O valor de \nprofundidade dos pixels componentes da superf\u00edcie s\u00e3o trocados por \nvalores provenientes de um acesso a textura que cont\u00e9m um mapa de \nalturas. O texture shader \u00e9 usado na troca destes valores de profundidade e \noutras unidades do fragment shader s\u00e3o usados na composi\u00e7\u00e3o da \nilumina\u00e7\u00e3o da geometria resultante destes pixels; \n\n Bump mapping especular e difuso usando a ilumina\u00e7\u00e3o de Phong: \nutiliza texture shader para o c\u00e1lculo dos par\u00e2metros que comp\u00f5em a \nequa\u00e7\u00e3o de ilumina\u00e7\u00e3o especular e difusa; \n\n Ilumina\u00e7\u00e3o para shadow mapping: combina o uso de vertex shader e \ntexture shader para calcular ilumina\u00e7\u00e3o difusa e especular de cada pixel \ncom utiliza\u00e7\u00e3o de texturas contendo informa\u00e7\u00f5es de sombras; \n\n Reflex\u00e3o e refra\u00e7\u00e3o: utiliza o texture shader para visualiza\u00e7\u00e3o de reflex\u00e3o \ne refra\u00e7\u00e3o de superf\u00edcies em bump mapping; \n\n Visualiza\u00e7\u00e3o de superf\u00edcies transparentes: a visualiza\u00e7\u00e3o da \nsobreposi\u00e7\u00e3o de superf\u00edcies transparentes \u00e9 realizada na ordem \ncaracterizada de tr\u00e1s para frente (back to front). O uso de shadow mapping \nem hardware combinado com texture shader (manipula\u00e7\u00e3o com valores \nalpha) propicia a correta visualiza\u00e7\u00e3o destas superf\u00edcies. \n\n3.2.3 Exemplo em Cg \n\nUm exemplo simples de um programa em Cg para texture shader foi extra\u00eddo de \nNVIDIA (2003) e \u00e9 apresentado na Figura 3.6. Este exemplo combina a t\u00e9cnica de \nmapeamento de ambiente (environment mapping) com reflex\u00e3o, transformando a \nnormal, extra\u00edda do mapa de normais, no espa\u00e7o que representa os dados de ambiente \n(textura do ambiente), refletindo esta normal a partir do vetor de visualiza\u00e7\u00e3o. \nFinalmente, se extrai os dados da textura de ambiente para obter a cor final do pixel, \ngerando um efeito de reflex\u00e3o do ambiente em que se encontra o objeto em quest\u00e3o. \n\n \n\n\n\n 43\n\nOs atributos de entrada do programa s\u00e3o: coordenadas de textura pr\u00e9-calculadas \n(IN) para acesso a textura de ambiente, textura 2D contendo as normais (normalMap), \ntextura contendo os dados do ambiente externo (environmentMap) e o vetor de \nvisualiza\u00e7\u00e3o (eyeVector). Na primeira etapa, um acesso \u00e0 textura de normais \u00e9 realizado \npara recuperar, obviamente, o vetor normal do pixel. A segunda etapa utiliza a seguinte \ninstru\u00e7\u00e3o: texCUBE_reflect_eye_dp3x3. Esta instru\u00e7\u00e3o utiliza a normal calculada, j\u00e1 \nrecuperada no espa\u00e7o da textura de ambiente, juntamente com o vetor de visualiza\u00e7\u00e3o e \nas coordenadas de textura, para calcular o vetor de reflex\u00e3o. A mesma instru\u00e7\u00e3o utiliza \neste vetor de reflex\u00e3o para, automaticamente, acessar a textura contendo os dados de \nambiente e retornar cor de pixel. \n\n \n (a)\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\n \n\n \n\n \n\n \n\n \n\nstruct vert2frag  \n{ \n // Coordenadas de textura transformadas no espa\u00e7o da textura cube map \n\nfloat4 tangentToCubeSpace0: TEXCOORD1; \n float4 tangentToCubeSpace1: TEXCOORD2; \n}; \nstruct frag2frame \n{ \n float4 color : COLOR0; \n}; \n  \nfrag2frame main ( vert2frag IN, \n\nuniform sampler2D normalMap, \nuniform samplerCUBE environmentMap, \nuniform float3 eyeVector \n\n  ) : COLOR \n{ \n frag2frame OUT; \n  \n // Acesso a textura que cont\u00e9m os valores de normais \n\nfloat4 normal = tex2D(normalMap); \n// Acesso a textura de CUBE MAP \n\n OUT.color = texCUBE_reflect_eye_dp3x3(environmentMap, \n       IN.tangentToCubeSpace0, \n       IN.tangentToCubeSpace1, \n       normal, \n       eyeVector); \n  \n return OUT; \n} \n\n (b)\n\nFIGURA 3.6 - Exemplo do efeito especial (a) e seu respectivo c\u00f3digo em Cg para \nfragment shader: environment mapping, extra\u00eddo de NVIDIA (2003) \n\n\n\n 44\n\n4 Compress\u00e3o e Visualiza\u00e7\u00e3o de Dados Volum\u00e9tricos \nDin\u00e2micos Usando Texturas 3D \nEste cap\u00edtulo apresenta a contribui\u00e7\u00e3o essencial deste trabalho mostrando o \n\ndesenvolvimento de um mecanismo de compress\u00e3o e descompress\u00e3o (para visualiza\u00e7\u00e3o) \nde dados volum\u00e9tricos din\u00e2micos. O m\u00e9todo \u00e9 dividido em duas etapas: \n\n decomposi\u00e7\u00e3o dos dados volum\u00e9tricos din\u00e2micos e armazenamento dos sub-\nvolumes, resultantes da decomposi\u00e7\u00e3o, em texturas 3D (etapa de \ncompress\u00e3o); \n\n visualiza\u00e7\u00e3o das texturas 3D geradas usando caracter\u00edsticas do hardware \ngr\u00e1fico (etapa de descompress\u00e3o). \n\n4.1 Compress\u00e3o  \n\nA etapa de compress\u00e3o de informa\u00e7\u00e3o codifica os m\u00faltiplos volumes de dados e os \narmazena para visualiza\u00e7\u00e3o posterior. O m\u00e9todo de compress\u00e3o proposto no presente \ntrabalho \u00e9 baseado em alguns pressupostos ou propriedades fundamentais dos dados, \ndescritos a seguir.  \n\n4.1.1 Propriedades B\u00e1sicas dos Dados \n\nDados volum\u00e9tricos din\u00e2micos podem apresentar in\u00fameras informa\u00e7\u00f5es \nassociadas a cada ponto amostrado, dependendo da aplica\u00e7\u00e3o (velocidade, vorticidade, \ntemperatura, salinidade, viscosidade, entre outros). Tamb\u00e9m podem apresentar outras \ncaracter\u00edsticas mais abstratas que n\u00e3o est\u00e3o associadas diretamente a um determinado \nponto amostrado e sim ao conjunto completo dos dados.  \n\nUma destas caracter\u00edsticas, que \u00e9 de grande import\u00e2ncia para um m\u00e9todo de \ncompress\u00e3o, \u00e9 o fato dos dados serem esparsos e, al\u00e9m disso, se concentrarem em \napenas algumas regi\u00f5es da \u00e1rea total amostrada, com um comportamento semelhante ao \nde uma matriz esparsa. Para estas matrizes, existem v\u00e1rios m\u00e9todos de compress\u00e3o \ndescritos na literatura, que variam de acordo com o qu\u00e3o esparso \u00e9 o conjunto de dados \ne sua localiza\u00e7\u00e3o ou concentra\u00e7\u00e3o na matriz. Por\u00e9m, os m\u00e9todos de compress\u00e3o de \nmatrizes esparsas s\u00e3o usados na solu\u00e7\u00e3o de sistemas lineares que possuam propriedades \nespec\u00edficas (matrizes diagonais, triangulares, etc). Portanto, tais m\u00e9todos n\u00e3o se aplicam \ndiretamente para dados volum\u00e9tricos esparsos que n\u00e3o possuem tais propriedades.  \n\n Outra caracter\u00edstica fundamental \u00e9 a coer\u00eancia, muito explorada por Shen et al. \n(1999) e Ellsworth et al. (2000), conforme j\u00e1 mencionado na se\u00e7\u00e3o 2.3 do cap\u00edtulo 2. Os \ndados din\u00e2micos possuem um alto grau de coer\u00eancia, tanto espacial como temporal. A \nFigura 4.1 representa uma id\u00e9ia desta propriedade, em duas dimens\u00f5es, para instantes de \ntempo a partir de tn. \n\n \n\n \n\n \n\n \n\n \n\n \n\n\n\n 45\n\n \n\ntn+1 tn+2tn \n\n \n\n \n\n \n\nFIGURA 4.1 - Exemplo de coer\u00eancia espacial e temporal \n\nA coer\u00eancia espacial est\u00e1 bastante presente em dados de din\u00e2mica de fluidos \n(CFD), por exemplo, onde a velocidade e dire\u00e7\u00e3o regem a posi\u00e7\u00e3o do material ao longo \ndo volume de dados, sendo que os valores das c\u00e9lulas vizinhas em rela\u00e7\u00e3o ao valor de \numa determinada c\u00e9lula da grade n\u00e3o mudam abruptamente. J\u00e1 o outro tipo de \ncoer\u00eancia, a temporal, \u00e9 freq\u00fcentemente encontrada em uma s\u00e9rie qualquer de volumes \nde dados, cada volume representando um instante de tempo, onde o valor de uma \ndeterminada c\u00e9lula tamb\u00e9m n\u00e3o muda abruptamente de um instante (portanto, um \nvolume) para outro.  \n\nUsada apropriadamente, a coer\u00eancia pode ser explorada para acelerar \nconsideravelmente o desempenho da visualiza\u00e7\u00e3o, que ainda \u00e9 muito dif\u00edcil de ser \nexecutada em tempo real para visualiza\u00e7\u00e3o direta de volumes. Outra possibilidade de \nacelera\u00e7\u00e3o atrav\u00e9s desta propriedade \u00e9 reduzir o excesso de I/O (input/output), pois \nvolumes iguais ou muito semelhantes podem ser armazenados uma \u00fanica vez e \nreutilizados. \n\nEstas duas propriedades (dados esparsos e coer\u00eancia) permitem compactar a \ninforma\u00e7\u00e3o, o que \u00e9 extremamente interessante, pois tais dados tendem a ser volumosos. \nEste cap\u00edtulo apresenta um novo mecanismo de compacta\u00e7\u00e3o que se beneficia das \ncaracter\u00edsticas do hardware gr\u00e1fico descrito no cap\u00edtulo 3, utilizando as propriedades \ndas texturas 3D dependentes para acelerar o processo de visualiza\u00e7\u00e3o.  \n\nFeito isso, ser\u00e1 poss\u00edvel realizar a visualiza\u00e7\u00e3o volum\u00e9trica em tempo real de \ndados din\u00e2micos, resultantes de simula\u00e7\u00f5es geradas por modelos em CFD ou por \nqualquer outra \u00e1rea que contenha dados variantes ao longo do tempo. \n\n4.1.2 Dados de Entrada para o Mecanismo \n\nAssume-se, ent\u00e3o, que os dados de entrada consistam de diferentes inst\u00e2ncias de \ntempo, cada qual representada por um volume de dados esparsos. A dimens\u00e3o de cada \nvolume n\u00e3o \u00e9 limitada, mas por restri\u00e7\u00f5es de mem\u00f3ria do hardware gr\u00e1fico atual ser\u00e3o \nutilizados volumes com 1283 c\u00e9lulas.  \n\nCada volume passa por uma etapa de classifica\u00e7\u00e3o de valores, onde cada c\u00e9lula \ncorresponde a um valor escalar de intensidade que pode variar de 0 a 255 no sistema \nRGBA, como ilustrado na Figura 4.2. \n\nTodos os voxels de cada volume de dados ser\u00e3o submetidos, ent\u00e3o, ao m\u00e9todo de \ncompress\u00e3o denominado Gritex, descrito a seguir. \n\n \n\n \n\n \n\n \n\n \n\n\n\n 46\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \nFIGURA 4.2 - Volume de dados \n\n128 \n\n(r,g,b,a) \n\n128 \n\n128 \n\ntn \n\n4.1.3 O M\u00e9todo de Compress\u00e3o Gritex  \n\nA abordagem usada para este m\u00e9todo consiste em um mecanismo de indexa\u00e7\u00e3o \ndividido em duas etapas dependentes, pois \u00e9 baseado nas texturas dependentes descritas \nno cap\u00edtulo 3. \n\nResumindo o m\u00e9todo, para um entendimento preliminar (ver Figura 4.3), a \nprimeira etapa consiste em uma decomposi\u00e7\u00e3o regular de cada volume de entrada em \nv\u00e1rios sub-volumes, at\u00e9 um determinado n\u00edvel estipulado, correspondendo a uma \nsubdivis\u00e3o hier\u00e1rquica dos dados. Neste passo, o objetivo \u00e9 separar claramente as \nregi\u00f5es que necessitam de um maior detalhamento daquelas que n\u00e3o precisam de \nrefinamento. A primeira etapa resulta no armazenamento em uma primeira textura 3D, \nde valores correspondentes aos sub-volumes plenamente \u201cresolvidos\u201d, pois s\u00e3o \nhomog\u00eaneos, ou refer\u00eancias para uma segunda textura 3D, onde ser\u00e3o armazenados os \nsub-volumes heterog\u00eaneos que precisam ser refinados. \n\nNa segunda etapa, para cada sub-volume onde o refinamento \u00e9 necess\u00e1rio, tais \nrefinamentos s\u00e3o criados, ou seja, prossegue a subdivis\u00e3o at\u00e9 a unidade de voxel. Todos \nestes sub-volumes refinados ser\u00e3o armazenados na segunda ou em outras unidades de \ntextura 3D, conforme necess\u00e1rio. \n\n \n\n \nEtapa 1 Etapa 2 \n\nCompress\u00e3o \n\nSub-volumes heterog\u00eaneos \nrefinados armazenados em \noutra textura 3D \nrepresentando cor \n\nSub-volumes armazenados numa\ntextura 3D representando cor\n(homog\u00eaneos) ou \u00edndices para\nrefinamentos (heterog\u00eaneos) \n\n \n\n \n\n \n\n \n\n \n\nFIGURA 4.3 - Esquema geral do m\u00e9todo de compress\u00e3o \n\n4.1.3.1 Primeira Etapa: \u00cdndice \n\nEm geral, estruturas de dados hier\u00e1rquicas convencionais s\u00e3o apropriadamente \nusadas para caracterizar a homogeneidade dos dados no dom\u00ednio espacial. Com isso, \nnesta primeira etapa, cada volume de dados \u00e9 decomposto atrav\u00e9s de um processo \n\n \n\n\n\n 47\n\nhier\u00e1rquico um pouco similar \u00e0 t\u00e9cnica octree (M\u00e4ntyl\u00e4, 1988). Em octrees, um volume \n\u00e9 dividido em 8 sub-volumes (cubos) de igual tamanho chamados de nodos, que \npoder\u00e3o conter valores constantes ou vari\u00e1veis. Os cubos que contiverem valores \nconstantes s\u00e3o denominados cheios (valores maiores que zero) ou vazios (valor igual a \nzero), e s\u00e3o considerados homog\u00eaneos. Caso contr\u00e1rio, s\u00e3o chamados de mistos ou \nheterog\u00eaneos, requerendo subdivis\u00f5es adicionais at\u00e9 que seja alcan\u00e7ada a \nhomogeneidade. A Figura 4.4 mostra esta decomposi\u00e7\u00e3o, onde os nodos homog\u00eaneos \ns\u00e3o caracterizados pelas cores branca (vazio) e preta (cheio) e os heterog\u00eaneos pela cor \ncinza. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nFIGURA 4.4 - Estrutura de uma octree \n\nEntretanto, a natureza adaptativa da octree n\u00e3o \u00e9 diretamente aproveitada pelas \ntexturas 3D em hardware, tanto por sua irregularidade como tamb\u00e9m pelo fato de n\u00e3o \nser preciso armazenar informa\u00e7\u00f5es relacionadas \u00e0 hierarquia em cada nodo. Para for\u00e7ar \nesta regularidade indispens\u00e1vel ao uso das texturas 3D em hardware e para facilitar o \nprocesso de visualiza\u00e7\u00e3o, constr\u00f3i-se uma estrutura semelhante \u00e0 octree completa (com \ntodos os nodos filhos) at\u00e9 uma certa profundidade ou n\u00edvel, ou seja, um grid. Este n\u00edvel, \nobviamente, tem de ser menor que a profundidade m\u00e1xima e \u00e9 definido de acordo com \nas caracter\u00edsticas dos volumes de dados.  \n\nA diferen\u00e7a clara entre esta estrutura e uma octree \u00e9 verificada quando a octree \nencontra um nodo homog\u00eaneo, finalizando a subdivis\u00e3o. Num grid, existem subdivis\u00f5es \nsucessivas at\u00e9 o n\u00edvel pr\u00e9-determinado, independente da homogeneidade do nodo em \nquest\u00e3o. Outra diferen\u00e7a presente \u00e9 que um grid n\u00e3o guarda as informa\u00e7\u00f5es hier\u00e1rquicas \nda estrutura de dados. \n\nA Figura 4.5 ilustra a estrutura do grid, apresentando a divis\u00e3o do volume em sub-\nvolumes at\u00e9 o segundo n\u00edvel da octree. \n\n \n\n...\nEtapa 2 \n\nEtapa 1 \n\nN\u00edvel de voxel \n\n...... Parada no n\u00edvel 2 \nda subdivis\u00e3o  \n\n \n\n \n\n \n\n \n\n \n \n\nFIGURA 4.5 - Estrutura de um grid para o n\u00edvel 2 \n\n \n\n\n\n 48\n\n\u00c9 muito importante frisar que, dependendo das caracter\u00edsticas dos dados de \nentrada (mais ou menos esparsos e concentrados em apenas algumas regi\u00f5es da \namostra), \u00e9 poss\u00edvel estimar o melhor ponto de parada do processo de subdivis\u00e3o na \nprimeira etapa. Isto significa dizer que este ponto de parada n\u00e3o \u00e9 fixo e pode ser \nalterado adequadamente. \n\nNa segunda etapa, como ser\u00e1 visto, apenas os sub-volumes heterog\u00eaneos ser\u00e3o \nnovamente subdivididos at\u00e9 o n\u00edvel de voxel, independente da homogeneidade dos \nnodos. \n\nPara os dados atuais de entrada (volumes de dimens\u00e3o 1283) e os exemplos ao \nlongo de todo este trabalho, a subdivis\u00e3o ser\u00e1 processada at\u00e9 o n\u00edvel quatro da \u00e1rvore, \num n\u00edvel considerado intermedi\u00e1rio. A Figura 4.6 apresenta esta estrutura, sendo \nmostrado, do lado esquerdo a dimens\u00e3o de cada cubo ou c\u00e9lula e do lado direito, o n\u00edvel \nda subdivis\u00e3o, juntamente com o n\u00famero total de cubos resultantes. Na figura, para \nfacilitar a visualiza\u00e7\u00e3o, as oito subdivis\u00f5es para cada nodo est\u00e3o representadas apenas \npor duas e todos os valores est\u00e3o descritos em pot\u00eancia de dois.  \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nEtapa 2 \n\nEtapa 1 \n\n13  \n\n23  \n\n43 = 26 \n\n83 = 29 \n\n163 = 212 \n\n323 = 215 \n\n643 = 218 \n\n1283 = 221\n\n7: 2097152 = 221 \n\n6: 262144 = 218 \n\n5: 32768 = 215 \n\n4: 4096 = 212 \n\n3: 512 = 29 \n\n2: 64 = 26\n\n1: 8 = 23 \n\n0 \n\n...\n\n...\n\n...\n\n... \n\n...\n\n... \n\n...\n\n \n\nInstante de tempo\ntn \n\n \nFIGURA 4.6 - Grid para um volume de 1283. No lado esquerdo da \u00e1rvore tem-se o \ntamanho de cada c\u00e9lula e no lado direito o n\u00edvel da subdivis\u00e3o juntamente com a \n\nquantidade m\u00e1xima comport\u00e1vel de sub-volumes \n\nAo final da primeira etapa, o grid \u00e9 armazenado na primeira textura 3D da \nseguinte forma: \n\n\u2022 sub-volumes homog\u00eaneos: os valores armazenados na textura s\u00e3o os \npr\u00f3prios valores de intensidade de cor e opacidade no sistema RGBA, onde \na componente alpha varia de 0 a 0,9; \n\n\u2022 sub-volumes heterog\u00eaneos: um \u00edndice de acesso ao refinamento \u00e9 \ncalculado e armazenado nessa textura, iniciando a segunda etapa do \nprocesso de compress\u00e3o. Os valores armazenados correspondem a (ox, oy, \noz, T), onde esse \u00edndice corresponder\u00e1 \u00e0 origem (ox, oy, oz) do sub-volume \ne a identifica\u00e7\u00e3o da textura (T), dita \u201ctextura de refinamento\u201d, que \n\n \n\n\n\n 49\n\narmazenar\u00e1 o sub-volume. Neste caso, a componente alpha representa a \nidentifica\u00e7\u00e3o da textura e assume um valor maior ou igual a 1. \n\nOs valores da origem no caso de sub-volumes heterog\u00eaneos s\u00e3o determinados \nsimplesmente como a primeira posi\u00e7\u00e3o (x,y,z) livre na textura de refinamento e todos os \nvalores referentes a este refinamento ser\u00e3o armazenados a partir desta origem. A \ninforma\u00e7\u00e3o da origem na textura de \u00edndices, representando uma posi\u00e7\u00e3o inicial do sub-\nvolume na textura de refinamento, \u00e9 armazenada como valores r, g e b, e a informa\u00e7\u00e3o \nde identifica\u00e7\u00e3o da textura \u00e9 armazenada como canal alfa na representa\u00e7\u00e3o RGBA. \n\nExemplificando, o n\u00edvel quatro do grid apresenta 4096 nodos, que correspondem \nao primeiro \u00edndice de um dado instante de tempo. Esta informa\u00e7\u00e3o \u00e9 armazenada em \numa das texturas 3D dispon\u00edveis no hardware. Como estas texturas tamb\u00e9m apresentam \ndimens\u00e3o 1283, ser\u00e1 poss\u00edvel armazenar 512 (1283/4096) destes grids, que representam \n512 inst\u00e2ncias de tempo. Cada grid neste n\u00edvel ter\u00e1 dimens\u00f5es 163, o que corresponde a \nter 16 sub-volumes de 83, considerando a dimens\u00e3o de 1283 (128/8)3. Este \narmazenamento caracteriza a primeira etapa da indexa\u00e7\u00e3o do m\u00e9todo de compress\u00e3o. A \nFigura 4.7 ilustra esta primeira etapa da compress\u00e3o. Nota-se tamb\u00e9m que este \narmazenamento de grids em texturas origina o nome do m\u00e9todo, gritex. \n\n \n\n \n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n32 \n\n16 \n\n8 \n\nEtapa 1 (n\u00edvel 4)\n\nInstante de tempo tn \n(128x128x128) \n\nTextura de \u00cdndices \n(128x128x128) \n\n16 \n\n16 \n\n16 \n\n(0,15,0)\n\n(15,0,0)(0,0,0)\n\n8x16\n\n511 \n\n63 56\n\n0\n...\n\n7\n8x16 \n\n8x16\n\nFIGURA 4.7 - Esquema de armazenamento da primeira etapa de compress\u00e3o \n\n4.1.3.2 Segunda Etapa: Refinamento \n\nNa segunda etapa do m\u00e9todo Gritex, desenvolve-se a subdivis\u00e3o dos sub-volumes \nheterog\u00eaneos, isto \u00e9, um refinamento ou subdivis\u00e3o completa dos cubos \u00e9 criado. O \nresultado deste refinamento ser\u00e1 armazenado em outra textura 3D, caracterizando a \nsegunda etapa do m\u00e9todo de compress\u00e3o, de acordo com a Figura 4.8. Esta textura, por \nsua vez, ser\u00e1 acessada a partir da primeira textura (textura de \u00edndices), atrav\u00e9s do \nconceito de depend\u00eancia de texturas. \n \n \n \n \n \n\n \n\n\n\n 50\n\n \n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n \n \n\n16x8\n\nAcesso ao \nrefinamento \n\n4095 \n\n...\n\nTextura de Refinamentos \n(128x128x128) \n\n(0,7,0)\n\n(7,0,0)(0,0,0)\n\n16x8\n\n16x8\n\n15 0\n\nEtapa 2 \n\nRefinamento \n\n8 \n\n8 \n\n8 \n\nEtapa 1 (n\u00edvel 4)\n\nInstante de tempo tn \n(128x128x128) \n\nTextura de \u00cdndices \n(128x128x128) \n\n16 \n\n16 \n\n16 \n\n(0,15,0)\n\n(15,0,0)(0,0,0)\n\n8x16 \n\n8x16\n\n511 \n\n6356\n\n0\n...\n\n7\n8x16 \n\nFIGURA 4.8 - Esquema geral de armazenamento da compress\u00e3o \n\nO hardware gr\u00e1fico atual disponibiliza quatro texturas 3D e o m\u00e9todo de \ncompress\u00e3o est\u00e1 utilizando, at\u00e9 o momento, apenas duas, restando outras duas. Com \nisso, estas outras duas texturas 3D poder\u00e3o comportar mais refinamentos, caso o espa\u00e7o \nde armazenamento da segunda textura se esgote. \n\nDe forma a explorar os conceitos de coer\u00eancia espacial e temporal vistos \nanteriormente, tenta-se re-usar ao m\u00e1ximo a informa\u00e7\u00e3o de refinamento, armazenando \nos valores j\u00e1 alocados em uma tabela de hash. Esta abordagem aumenta a capacidade de \narmazenamento dos refinamentos, comparando cada refinamento novo com \nrefinamentos criados previamente e apenas armazena-se os refinamentos distintos.  \n\nCaso haja um refinamento igual a um j\u00e1 armazenado (duplicado), ou seja, caso \nocorra uma \u201ccolis\u00e3o\u201d, haver\u00e1 o re-uso dos \u00edndices (origem e identificador da textura) \nrelativos a este refinamento na textura de \u00edndices. A fun\u00e7\u00e3o hash utilizada neste trabalho \n\u00e9 extremamente simples e corresponde \u00e0 soma dos valores escalares RGBA de todas as \nc\u00e9lulas que comp\u00f5em um sub-volume. Todavia, outras fun\u00e7\u00f5es mais elaboradas tamb\u00e9m \npodem ser utilizadas e testadas. \n\n \n\n\n\n 51\n\nA Figura 4.9 apresenta este esquema de hash implementado atrav\u00e9s de uma lista \nencadeada. Cada voxel do refinamento apresenta valores escalares para cada canal de \nintensidade de cor RGBA que s\u00e3o somados entre si e tamb\u00e9m aos valores RGBA de \ntodos os outros voxels componentes do refinamento. Este valor obtido \u00e9 dividido pelo \nescalar 4195, estipulado como um bom n\u00famero para uma fun\u00e7\u00e3o hash utilizando o \nm\u00e9todo da divis\u00e3o, e o resto da divis\u00e3o representa o \u00edndice na tabela hash. Em seguida, \no sub-volume \u00e9 armazenado na lista encadeada referente ao resultado da fun\u00e7\u00e3o hash. \n\n \n\n \n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n4195\n\n...\n\n5\n\n4\n\n3\n\n2\n\n1\n\n0\nFun\u00e7\u00e3o hash \n\n i=Dim-1; j=Dim-1; k=Dim-1; \n(r,g,b,a) = ? (Voxel [i] [j] [k]) \n \nHash = (r + g + b + a) MOD 4195 \n\ni=ox; j=oy; k=oz; \n\nDim (2)\n\nDim (2)\n\nRefinamento \n\n/Ref 2 Ref 3\n\n/Ref 1\n\n(ox,oy,oz) Dim (2)  \n\nFIGURA 4.9 - Esquema hash utilizado \n\nNota-se, neste caso, que uma colis\u00e3o n\u00e3o \u00e9 definida apenas pelo valor de retorno \nda fun\u00e7\u00e3o hash, pois sub-volumes diferentes podem apresentar o mesmo valor de soma \nde suas c\u00e9lulas. A colis\u00e3o \u00e9 definida apenas para aqueles sub-volumes que realmente \ns\u00e3o id\u00eanticos. Assim, uma compara\u00e7\u00e3o volume a volume, envolvendo voxel a voxel, \u00e9 \nrealizada entre o sub-volume em quest\u00e3o e os sub-volumes j\u00e1 armazenados na lista \nencadeada referente ao valor da fun\u00e7\u00e3o hash obtido. \n\nCompletado o processo de compress\u00e3o, \u00e9 necess\u00e1rio realizar o caminho inverso, \nou seja, a descompress\u00e3o. A descompress\u00e3o \u00e9 utilizada para visualiza\u00e7\u00e3o dos volumes e \nest\u00e1 detalhada na se\u00e7\u00e3o a seguir. \n\n4.2 Descompress\u00e3o e Visualiza\u00e7\u00e3o \n\nA visualiza\u00e7\u00e3o volum\u00e9trica baseada em texturas, neste trabalho, se baseia no uso \nde texturas mapeadas para uma seq\u00fc\u00eancia de pol\u00edgonos ou planos alinhados de acordo \ncom a dire\u00e7\u00e3o de visualiza\u00e7\u00e3o. Isto pode ser observado re-visitando a se\u00e7\u00e3o 2.2.2.4.1 do \ncap\u00edtulo 2. Entretanto, o m\u00e9todo de compress\u00e3o Gritex requer uma etapa de \ndescompress\u00e3o, usando o hardware gr\u00e1fico, com opera\u00e7\u00f5es que v\u00e3o al\u00e9m de um simples \nmapeamento de textura 3D, pois os dados amostrados est\u00e3o armazenados em mais de \numa textura 3D. O acesso as diferentes texturas, como j\u00e1 mencionado, ser\u00e1 realizado \nutilizando a caracter\u00edstica de texturas dependentes em hardware.  \n\nSendo assim, a visualiza\u00e7\u00e3o de um determinado tempo t \u00e9 realizada mapeando a \n\u201cpor\u00e7\u00e3o\u201d referente a este tempo na textura 3D que cont\u00e9m os dados obtidos na primeira \n\n \n\n\n\n 52\n\netapa do processo de compress\u00e3o, mas com um adicional: um conjunto de instru\u00e7\u00f5es \nser\u00e1 informado \u00e0 unidade texture shader do hardware para verificar se os valores de cor \ne opacidade (RGBA) a serem visualizados s\u00e3o os pr\u00f3prios armazenados nesta textura de \n\u00edndices ou se estes valores servir\u00e3o de \u00edndice a valores armazenados na(s) textura(s) de \nrefinamento, os quais dever\u00e3o ser buscados.  \n\nA Figura 4.10 mostra a equa\u00e7\u00e3o que resulta nas origens de um tempo t contido na \ntextura 3D de \u00edndices, onde refinamentoDim \u00e9 a dimens\u00e3o do volume que representa o \nrefinamento (no caso do n\u00edvel de parada ser 4, refinamentoDim \u00e9 igual a 8), tempoDim \u00e9 \na dimens\u00e3o do volume que representa cada tempo (para n\u00edvel de parada 4, tempoDim \u00e9 \nigual a 16), MOD retorna o resto da divis\u00e3o de dois valores inteiros e DIV retorna o \nquociente da divis\u00e3o. Nota-se uma ressalva para n\u00e3o confundir a origem (ox,oy,oz) de \num refinamento com esta origem (Ox,Oy,Oz) de um tempo na textura de \u00edndice. \n\n \nOx = (t MOD refinamentoDim) * tempoDim\nOy = (t DIV refinamentoDim) * tempoDim \nOz = (t DIV refinamentoDim2) * tempoDim \n\n \n\n \n\n \n\nFIGURA 4.10 - C\u00e1lculo para a recupera\u00e7\u00e3o da origem de um tempo na textura de \n\u00edndices \n\nEm seguida, a Figura 4.11 ilustra o papel da unidade texture shader na \nvisualiza\u00e7\u00e3o dos dados comprimidos pela t\u00e9cnica Gritex. A unidade de rasteriza\u00e7\u00e3o gera \ntodos os fragmentos pertencentes \u00e0 \u00e1rea delimitada pelos v\u00e9rtices estabelecidos dos \npol\u00edgonos ou planos e os envia (fragmentos ou pixels), um por um, \u00e0 unidade de \nfragment shader. As texturas de \u00edndice e refinamento tamb\u00e9m s\u00e3o informadas ao \nfragment shader. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n \n\n(s\u2019,t\u2019,r\u2019,T)\n\n(s,t,r,q)\n\nRefinamento 3\n\nRefinamento 2\n\n \nInstru\u00e7\u00f5es\n\n\u00cdndice \n\nRefinamento 1\nRasterizador \n\nTexturas de \n\u00cdndice e \n\nRefinamento \n\nBlen-\nding\n\n Texture Shader \n\nFragment Shader \n\nFIGURA 4.11 - Esquema b\u00e1scio do texture shader para o m\u00e9todo de compress\u00e3o \n\nO conjunto de instru\u00e7\u00f5es definidos na unidade de texture shader executar\u00e1 um \nacesso \u00e0 textura de \u00edndices, atrav\u00e9s das coordenadas (s,t,r,q) dos pol\u00edgonos, e analisar\u00e1 \n\n \n\n\n\n 53\n\nos valores RGBA obtidos. Caso estes valores signifiquem uma intensidade de cor e \nopacidade (este teste \u00e9 detalhado na pr\u00f3xima se\u00e7\u00e3o), s\u00e3o exibidos (Blending). Caso \ncontr\u00e1rio, estes valores assumir\u00e3o o papel de novas coordenadas (s\u2019,t\u2019,r\u2019, T) para acesso \n(dependente) ao refinamento, onde s\u2019, t\u2019 e r\u2019 definem a origem do sub-volume que \ncont\u00e9m o fragmento em quest\u00e3o dentro da textura de refinamento e T caracteriza essa \ntextura. \u00c9 importante ressaltar que estes valores recuperados pelo acesso \u00e0 primeira \ntextura podem n\u00e3o ser utilizados diretamente para um acesso dependente (como \u00e9 o caso \ndeste m\u00e9todo), mas tamb\u00e9m manipulados para a gera\u00e7\u00e3o de um novo \u00edndice. \n\nA partir desta origem e da dimens\u00e3o do sub-volume, todos os voxels contidos \nneste sub-volume s\u00e3o mapeados \u00e0s suas referentes coordenadas de textura, obtendo-se, \nassim, a cor e opacidade de cada fragmento ou voxel do sub-volume. Para tal, um \ndeslocamento a partir desta origem \u00e9 calculado de acordo com a Figura 4.12. Na figura, \no c\u00e1lculo do deslocamento utiliza as coordenadas de textura X, Y e Z referentes a cada \nfragmento para realizar uma opera\u00e7\u00e3o de MOD (fun\u00e7\u00e3o que retorna o resto de uma \ndivis\u00e3o de inteiros) com as dimens\u00f5es dos sub-volumes. A cor final do pixel \u00e9, ent\u00e3o, \ncalculada atrav\u00e9s de um acesso \u00e0 textura de refinamento utilizando, como novas \ncoordenadas, o deslocamento somado \u00e0 sua origem. Em seguida, esta cor \u00e9 enviada para \no processo de composi\u00e7\u00e3o de cores para posterior visualiza\u00e7\u00e3o (blending). \n\n \n\n \ndx = Coordenada X da textura MOD dimens\u00e3o X do sub-volume \ndy = Coordenada Y da textura MOD dimens\u00e3o Y do sub-volume \ndz = Coordenada Z da textura MOD dimens\u00e3o Z do sub-volume \n \nCor = Refinamento [ox + dx] [oy + dy] [oz + dz] \n\n \n\n \n\n \n\n \n \n\nFIGURA 4.12 - C\u00e1lculo para recupera\u00e7\u00e3o dos refinamentos \n\nResumindo, a Figura 4.13 apresenta o processo geral de visualiza\u00e7\u00e3o do m\u00e9todo \nGritex para um instante de tempo tn. Nota-se que as coordenadas de textura (s,t,r) s\u00e3o \ndivididas pela dimens\u00e3o do sub-volume (8, no caso) no acesso \u00e0 textura de \u00edndices, pois \ncada unidade dessa textura representa um sub-volume de 83. \n\nA pr\u00f3xima se\u00e7\u00e3o apresenta os detalhes de implementa\u00e7\u00e3o da descompress\u00e3o. Esta \ndescompress\u00e3o baseia-se no conjunto de instru\u00e7\u00f5es, apresentado na Figura 4.11, \nimplementado na unidade texture shader e executado pelo hardware gr\u00e1fico. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n\n\n 54\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nDire\u00e7\u00e3o de visualiza\u00e7\u00e3o \n\nOx + s/8\nOy + t/8\nOz + r/8\n\n(s,t,r) \n(x,y,z) \n\nFragmento\n\n(x4,y4,z4) \n(s4,t4,r4) \n\n(x3,y3,z3)\n(s3,t3,r3) \n\n(x2,y2,z2)\n(s2,t2,r2) \n\nPol\u00edgonos \n\n(x1,y1,z1) \n(s1,t1,r1) \n\ntn \n\nTextura de \u00cdndices  \n \n\nox + s MOD 8\noy + t  MOD 8\noz + r  MOD 8\n\nTextura de  \nRefinamentos  \n\n \n\nFIGURA 4.13 - Processo geral de visualiza\u00e7\u00e3o para um instante de tempo tn \n\n4.2.1 Detalhes de implementa\u00e7\u00e3o \n\nAs instru\u00e7\u00f5es foram codificadas na linguagem Cg, abordada no cap\u00edtulo 3, e \ncompiladas para gerar c\u00f3digo geral assembler de forma a ser aproveitado integralmente \npor um hardware de outro fabricante, Radeon 9700 da empresa ATI. \u00c9 importante \nressaltar que n\u00e3o foi utilizada outra placa gr\u00e1fica com caracter\u00edsticas semelhantes ou \ncom maior poder de armazenamento e processamento, como o hardware GeForce FX \nda empresa NVIDIA, pois este ainda n\u00e3o se encontra dispon\u00edvel no mercado.  \n\nUma vez armazenadas todas as unidades de textura (\u00edndice e refinamento), um \nmapeamento simples, referente a um instante de tempo em quest\u00e3o, da textura 3D de \n\u00edndices \u00e9 realizado. Nesta etapa de acesso \u00e0 textura, entra em a\u00e7\u00e3o a unidade fragment \nshader e, por sua vez, sua sub-unidade texture shader. Esta unidade executa o conjunto \nde instru\u00e7\u00f5es, previamente compilado, para atribui\u00e7\u00e3o de cor e opacidade a cada pixel. \nA Figura 4.14 ilustra o conjunto de instru\u00e7\u00f5es adotadas para descompress\u00e3o e \nvisualiza\u00e7\u00e3o com apenas uma textura 3D representando os refinamentos. Esta \nsimplifica\u00e7\u00e3o se deve ao fato do hardware ATI Radeon 9700 trabalhar com no m\u00e1ximo \n64 instru\u00e7\u00f5es em assembler para um fragment shader e o c\u00f3digo em Cg da Figura 4.14 \nresulta, em sua compila\u00e7\u00e3o, 60 instru\u00e7\u00f5es, ou seja, quase o n\u00famero m\u00e1ximo poss\u00edvel de \ninstru\u00e7\u00f5es. \n\nAs etapas para a visualiza\u00e7\u00e3o/descompress\u00e3o presentes no programa da Figura \n4.14 est\u00e3o numeradas a seguir: \n\n \n\n \n\n\n\n 55\n\n1. os valores Ox, Oy e Oz s\u00e3o pr\u00e9-calculados atrav\u00e9s da equa\u00e7\u00e3o da Figura \n4.10, os quais determinam o instante de tempo a ser acessado na textura de \n\u00edndices; \n\n2. os seguintes par\u00e2metros de entrada ao programa s\u00e3o, ent\u00e3o, informados: \ncoordenadas de textura (IN), origem do sub-volume (Ox, Oy e Oz) que \nrepresenta um tempo na textura de \u00edndices, dimens\u00e3o do sub-volume de \nrefinamento (nodeSide) estabelecido na Figura 4.12, textura 3D com os \n\u00edndices armazenados (texIndex) e textura 3D contendo os refinamentos \n(texRefinement); \n\n3. calcula-se as novas coordenadas de textura (index) referente ao instante de \ntempo desejado para acesso na textura de \u00edndices. Estas novas coordenadas \nde textura s\u00e3o obtidas atrav\u00e9s da divis\u00e3o das coordenadas de texturas \npassadas como par\u00e2metro (IN) pela dimens\u00e3o do refinamento (nodeSide) e \nseu resultado somado a origem (Ox, Oy, Oz). Assim, \u00e9 realizado o \nmapeamento correto da \u201cpor\u00e7\u00e3o\u201d de textura que representa o tempo em \nquest\u00e3o; \n\n4. acesso \u00e0 textura de \u00edndices com as coordenadas armazenadas em index; \n\n5. um teste \u00e9 realizado com a informa\u00e7\u00e3o retornada do acesso a textura de \n\u00edndices para verificar se a mesma representa uma cor, relativa a um sub-\nvolume homog\u00eaneo, ou uma origem na textura de refinamento. O teste \u00e9 \nrealizado levando em considera\u00e7\u00e3o a componente alfa do valor retornado \n(r,g,b,a), j\u00e1 que a implementa\u00e7\u00e3o da compress\u00e3o foi realizada adotando \nvalor igual a 1 para um sub-volume que necessite de refinamento e valores \nmenores que 1 para sub-volumes homog\u00eaneos. Este teste \u00e9 realizado \natrav\u00e9s de uma instru\u00e7\u00e3o if-else. Deve-se observar que, no c\u00f3digo, os \nvalores RGBA recuperados da textura est\u00e3o sendo representados por \n(x,y,z,w); \n\n6. caso a seja igual a 1, um  acesso dependente \u00e9 realizado na textura de \nrefinamento, mas com novas coordenadas de textura calculadas em \nrefIndex. Estas novas coordenadas (ox+dx, oy+dy, oz+dz) s\u00e3o calculadas \nseguindo a f\u00f3rmula apresentada na Figura 4.12, com algumas \nmodifica\u00e7\u00f5es: \n\na. as origens s\u00e3o multiplicadas por 2, pois a estrutura RGBA utilizada \nassume valores entre 0 e 255, mas quando se representa uma \norigem nesta estrutura, armazena-se valores referentes \u00e0 dimens\u00e3o \nda textura 3D usada, ou seja, entre 0 e 127. O hardware gr\u00e1fico faz \num mapeamento dos valores de RGBA para valores entre 0 e 1 e, \nassim, o valor 127 seria mapeado para 0,5 e n\u00e3o para 1 (dimens\u00e3o \nm\u00e1xima da textura) como se deseja; \n\nb. a segunda modifica\u00e7\u00e3o tamb\u00e9m leva em conta este mapeamento \npara valores entre 0 e 1. Como a fun\u00e7\u00e3o MOD retorna o resto da \ndivis\u00e3o entre dois valores inteiros e os valores de coordenadas de \ntextura tamb\u00e9m s\u00e3o mapeados para valores entre 0 e 1, estes valores \nde coordenadas de textura devem ser transformados para inteiros. A \nsolu\u00e7\u00e3o \u00e9 multiplicar estes valores pela dimens\u00e3o da textura (1283), \nrealizar o c\u00e1lculo da fun\u00e7\u00e3o MOD e, finalmente, dividir o resultado \npela dimens\u00e3o da textura. Deve-se observar que o mapeamento das \n\n \n\n\n\n 56\n\ncoordenadas de textura n\u00e3o \u00e9 realizado com valores entre 0 a 255 e \nsim com valores entre 0 a 127, para valores entre 0 a 1; \n\n7. a cor final do pixel \u00e9, finalmente, definida como sendo o resultado do \nacesso \u00e0 textura de \u00edndices, caso a (alfa) seja diferente de 1 ou como sendo \no resultado do acesso \u00e0 textura de refinamento, caso a seja igual a 1.  \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nstruct vert2frag \n{ \n float4 texCoord : TEX0; \n}; \n \nstruct frag2frame \n{ \n float4 color : COLOR0; \n}; \n \nfrag2frame \nmain( vert2frag IN,     // Coordenada de textura \n uniform float Ox,    // Origens na textura de \u00edndices \n uniform float Oy,    // \n uniform float Oz,    // \n uniform float nodeSide, // Dimens\u00e3o do refinamento \n uniform sampler3D texIndex : texUnit0,     // Textura de \u00edndices \n uniform sampler3D texRefinement : texUnit1 // Textura de refinamentos \n ) : COLOR \n{ \n // Cor de sa\u00edda do pixel \n\nfrag2frame OUT;  \n \n //> Origem de um tempo t na textura de \u00edndices + deslocamento \n\nfloat3 index; \n index.x = Ox + IN.texCoord.x / nodeSide; \n index.y = Oy + IN.texCoord.y / nodeSide; \n index.z = Oz + IN.texCoord.z / nodeSide; \n //&lt;Origem de um tempo t na textura de \u00edndices + deslocamento \n \n // Acesso a textura de \u00edndices. Origin = (ox,oy,oz) \n\nfloat4 origin = f4tex3D(texIndex, index); \n \n //> Origem de um refinamento na textura de refinamentos + deslocamento \n float3 refIndex; \n refIndex.x = origin.x*2 + fmod(IN.texCoord.x*128, nodeSide)/128; \n refIndex.y = origin.y*2 + fmod(IN.texCoord.y*128, nodeSide)/128; \n refIndex.z = origin.z*2 + fmod(IN.texCoord.z*128, nodeSide)/128; \n //&lt;Origem de um refinamento na textura de refinamentos + deslocamento \n  \n // Teste para saber se h\u00e1 refinamentos \n if (origin.w == 1.0) { \n  // Acesso a textura de refinamento \n  float4 ref = f4tex3D(texRefinement, refIndex); \n  // Cor final do pixel \u00e9 a cor recuperada de um refinamento \n\nOUT.color = ref; \n } \n else { \n  // Cor final do pixel \u00e9 a cor recuperada no \u00edndice \n\nOUT.color = origin; \n } \n \n // Retorno da cor final do pixel \n\nreturn OUT; \n} \n\n \n \n\nFIGURA 4.14 - C\u00f3digo em Cg para visualiza\u00e7\u00e3o (descompress\u00e3o) \n\n \n\n \n\n\n\n 57\n\n5 Resultados \nEste cap\u00edtulo apresenta os resultados da aplica\u00e7\u00e3o do m\u00e9todo proposto a um \n\nestudo de caso, o Projeto MAPEM. O estudo de caso corresponde \u00e0 visualiza\u00e7\u00e3o dos \ndados provenientes da simula\u00e7\u00e3o do descarregamento de material produzido na \nperfura\u00e7\u00e3o prospectiva de um po\u00e7o de petr\u00f3leo. \n\n5.1 Gera\u00e7\u00e3o dos Dados Volum\u00e9tricos Din\u00e2micos \n\nO Modelo OOC foi desenvolvido pela empresa Exxon Mobil Production Research \n(Brandsma e Smith, 1999) para simular o comportamento do descarregamento no mar \nde materiais (cascalhos impregnados de fluidos de perfura\u00e7\u00e3o, entre outros) gerados \npela perfura\u00e7\u00e3o de po\u00e7os de petr\u00f3leo (Figura 5.1). O objetivo final da simula\u00e7\u00e3o \u00e9 \nprever a acumula\u00e7\u00e3o destes cascalhos no fundo do mar. Um estudo desse modelo foi \nrealizado (Binotto, 2001) e ser\u00e3o abordados aqui apenas os aspectos necess\u00e1rios para o \nentendimento geral do processo. \n\n \n \n \n \n\n \n\n \n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nJato inicial, formando a pluma de \ndescarregamento\n\nGot\u00edculas de \n\u00f3leo \nsuspendendo \npara a \nsuperf\u00edcie\n\nPart\u00edculas \ns\u00f3lidas se \ndepositando \nno fundo\n\nMovimenta\u00e7\u00e3o de acordo \ncom a corrente mar\u00edtima\n\nDispers\u00e3o \nturbulenta\n\nPlataforma \nde petr\u00f3leo Jato inicial, formando a pluma de \n\ndescarregamento\n\nGot\u00edculas de \n\u00f3leo \nsuspendendo \npara a \nsuperf\u00edcie\n\nPart\u00edculas \ns\u00f3lidas se \ndepositando \nno fundo\n\nMovimenta\u00e7\u00e3o de acordo \ncom a corrente mar\u00edtima\n\nDispers\u00e3o \nturbulenta\n\nPlataforma \nde petr\u00f3leo\n\nFIGURA 5.1 - Fases do descarregamento (Brandsma e Smith, 1999) \n\nOs dados de entrada para o simulador descrevem: \n\n\u2022 Grade \u2013 regi\u00e3o a ser estudada na simula\u00e7\u00e3o (Figura 5.2). Esta \u00e1rea \u00e9 \ndecomposta de c\u00e9lulas, formando uma malha; \u00e0 cada c\u00e9lula ser\u00e3o \nassociados valores de concentra\u00e7\u00e3o de material descarregado. \n\n\u2022 Ambiente \u2013 vari\u00e1veis do ambiente, entre as quais, os perfis de correntes \nmar\u00edtimas em diversas profundidades. \n\n\u2022 Descarregamento \u2013 par\u00e2metros referentes \u00e0 taxa de descarga, dimens\u00e3o \ndo tubo de descarga, orienta\u00e7\u00e3o do tubo, entre outros. \n\n \n\n\n\n 58\n\n\u2022 Sa\u00edda \u2013 descri\u00e7\u00e3o da organiza\u00e7\u00e3o esperada do resultado da simula\u00e7\u00e3o, \nsendo os mais importantes itens: a defini\u00e7\u00e3o de profundidades ao longo da \ncoluna de \u00e1gua em que se deseja obter uma grade com a concentra\u00e7\u00e3o do \nmaterial e defini\u00e7\u00e3o de instantes de tempo em que se deseja obter tais \ninforma\u00e7\u00f5es.  \n\nO modelo produz, basicamente, resultados num\u00e9ricos para an\u00e1lise, sem nenhuma \nsa\u00edda gr\u00e1fica. Estes resultados representam concentra\u00e7\u00f5es do material descarregado por \nc\u00e9lula da grade. Pode-se gerar apenas um \u00fanico plano representando o ac\u00famulo total no \nfundo do mar de cada classe de part\u00edculas s\u00f3lidas individuais ou do conjunto de todos os \nconstituintes s\u00f3lidos, como tamb\u00e9m uma s\u00e9rie de planos ou camadas ao longo da coluna \nde \u00e1gua, representando fatias de um volume de dados (Figura 5.2).  \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n \n\nx\ny\n\nz\n\nx\ny\n\nz\n\n \n\nTubo de descarga \n\nFIGURA 5.2 - Estrutura da grade e seq\u00fc\u00eancia de planos de dados gerados pelo \nsimulador \n\nAp\u00f3s a obten\u00e7\u00e3o dos dados de simula\u00e7\u00e3o, estes passam por uma etapa de p\u00f3s-\nprocessamento para a obten\u00e7\u00e3o de valores de espessura da camada (virtual) de cascalho \nque seria acumulada no fundo do mar. Assim, o resultado desse p\u00f3s-processamento \npode ser tanto as grades originais de concentra\u00e7\u00e3o como grades contendo \u201cespessuras\u201d \nem diferentes profundidades, para o c\u00f4mputo da acumula\u00e7\u00e3o de fundo. \n\n5.2 Visualiza\u00e7\u00e3o dos Dados Volum\u00e9tricos \n\nObtidos os dados de espessura, a visualiza\u00e7\u00e3o dos dados resultantes com o Modelo \nOOC foi desenvolvida em duas etapas.  \n\nA primeira etapa \u00e9 um processo de mapeamento de cores. Para isso, tais dados \nser\u00e3o normalizados em valores escalares de cor no sistema RGBA, variando de 0 a 255. \nO resultado desta etapa consistir\u00e1 em uma textura a ser visualizada na etapa seguinte. \nPor exemplo, para uma grade que representa a acumula\u00e7\u00e3o do fundo do mar, uma \ntextura 2D ser\u00e1 criada. Entretanto, reunindo as v\u00e1rias grades que representam camadas \ndos dados p\u00f3s-processados, uma textura 3D pode ser criada. Como o simulador gera, \n\n \n\n\n\n 59\n\npara cada instante de tempo, um conjunto de camadas como as da Figura 5.2, v\u00e1rias \ntexturas 3D podem ser criadas. \n\nPassando pela etapa de mapeamento de cores, os dados j\u00e1 podem ser visualizados \ncomo texturas. Para o caso da visualiza\u00e7\u00e3o de um \u00fanico instante de tempo, ou apenas da \nacumula\u00e7\u00e3o no fundo, um programa interativo para visualiza\u00e7\u00e3o 3D simples de texturas \n2D e 3D, baseado numa c\u00e2mera OpenGL, \u00e9 utilizado. Para a visualiza\u00e7\u00e3o de uma s\u00e9rie \ntemporal de dados volum\u00e9tricos, \u00e9 utilizada a t\u00e9cnica de compress\u00e3o/visualiza\u00e7\u00e3o \ndesenvolvida neste trabalho. A utiliza\u00e7\u00e3o de ambos permitir\u00e1 uma avalia\u00e7\u00e3o do m\u00e9todo \nproposto atrav\u00e9s da visualiza\u00e7\u00e3o de instantes de tempo espec\u00edficos.  \n\n5.2.1 Visualiza\u00e7\u00e3o Usando Texturas 2D e 3D Simples \n\nNa Figura 5.3, \u00e9 apresentada a visualiza\u00e7\u00e3o da acumula\u00e7\u00e3o total de materiais \ndecorrente da simula\u00e7\u00e3o de uma perfura\u00e7\u00e3o2. Foram gerados os dados volum\u00e9tricos de \ndiferentes camadas e apenas a espessura acumulada na camada de fundo \u00e9 exibida. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nFIGURA 5.3 - Visualiza\u00e7\u00e3o acumula\u00e7\u00e3o total, representada por uma textura 2D \n\nNa Figura 5.3, o cubo (volume de amostragem) representa a coluna de \u00e1gua do \nmar correspondente \u00e0 grade modelada e a linha vertical, no centro do cubo, o local da \nperfura\u00e7\u00e3o. A batimetria do fundo do mar \u00e9 exibida em aramado e a textura 2D, nela \nmapeada, representa a espessura de acumula\u00e7\u00e3o do material; os pontos demarcados \ncorrespondem \u00e0s esta\u00e7\u00f5es de coleta de material in loco pelos diferentes grupos do \nProjeto MAPEM. \n\nA utiliza\u00e7\u00e3o dos dados volum\u00e9tricos diretamente como texturas 3D permite \nvisualizar o comportamento do fluxo de descarga do material ao longo do tempo, desde \na superf\u00edcie at\u00e9 o fundo do oceano. Para isso, \u00e9 necess\u00e1rio utilizar um hardware gr\u00e1fico \n\n \n\n                                                 \n2 Perfura\u00e7\u00e3o do po\u00e7o Eagle, localizado na Bacia de Campos, de 2 a 12 de Junho de 2002. \n\n\n\n 60\n\ncomo GeForce3 ou superior. Al\u00e9m disso, \u00e9 necess\u00e1rio trocar a textura 3D, para cada \ninstante de tempo a ser visualizado, e processar a visualiza\u00e7\u00e3o com a t\u00e9cnica de \nmapeamento de texturas 3D (se\u00e7\u00e3o 2.2.2.4.2 do cap\u00edtulo 2). A Figura 5.4 ilustra a \nvisualiza\u00e7\u00e3o de quatro tempos (dois iniciais e dois intermedi\u00e1rios) da mesma simula\u00e7\u00e3o \nexibida na Figura 5.3. Cada tempo, ou seja, cada volume de dados correspondente a um \ntempo, \u00e9 representado numa textura 3D. \n\n \n\n  \n\n  \n\nFIGURA 5.4 - Visualiza\u00e7\u00e3o individualizada de quatro instantes de tempo, com texturas \n3D \n\nMesmo com o uso do harwdare gr\u00e1fico, esta visualiza\u00e7\u00e3o torna-se lenta quando se \ndeseja exibir seq\u00fcencialmente diferentes volumes (de 2 a 3 segundos para atualizar a \nimagem, usando um computador com a configura\u00e7\u00e3o descrita na pr\u00f3xima se\u00e7\u00e3o). Desta \nforma, a solu\u00e7\u00e3o para visualizar o descarregamento em tempo real \u00e9 aplicar ao conjunto \nde dados volum\u00e9tricos a t\u00e9cnica de compress\u00e3o e visualiza\u00e7\u00e3o de dados Gritex e utilizar \nas texturas 3D resultantes da t\u00e9cnica e as propriedades (depend\u00eancia de texturas) em \nhardware para visualiza\u00e7\u00e3o dos v\u00e1rios volumes. \n\n \n\n\n\n 61\n\n5.2.2 Visualiza\u00e7\u00e3o Usando a T\u00e9cnica de Compress\u00e3o Gritex \n\nA t\u00e9cnica Gritex, proposta no cap\u00edtulo anterior, obteve um \u00f3timo desempenho de \ncompress\u00e3o com os volumes resultantes do estudo de caso. Conseguiu-se realizar em \ntempo real a visualiza\u00e7\u00e3o dos 36 instantes de tempo que representam uma das \nsimula\u00e7\u00f5es da perfura\u00e7\u00e3o do po\u00e7o Eagle.  \n\nO n\u00edvel quatro foi escolhido como ponto de parada da primeira etapa de \ncompress\u00e3o, podendo comportar ainda mais 476 (512-36) instantes de tempo. O m\u00e9todo \nde compress\u00e3o resultou em 143.894 sub-volumes ou nodos homog\u00eaneos de dimens\u00e3o 83 \ne 3.562 sub-volumes de 83, que necessitaram de refinamento (Tabela 5.1). A fun\u00e7\u00e3o \nhash identificou 126 colis\u00f5es, ou seja, 3.436 (3.562-126) sub-volumes de 83 foram \narmazenados na textura de refinamento, restando ainda 660 (4.096-3.436) posi\u00e7\u00f5es \nlivres.  \n\nO computador utilizado para o pr\u00e9-processamento de compress\u00e3o foi um PC \nPentium IV com 1.6 GHz e 256 MB de mem\u00f3ria RAM. O tempo de compress\u00e3o destes \n36 instantes de tempo foi em torno de 6 minutos, ou seja, m\u00e9dia de 10 segundos para \ncada volume (instante de tempo) de 1283. \n\nA Figura 5.5 ilustra a compara\u00e7\u00e3o da visualiza\u00e7\u00e3o de tr\u00eas instantes de tempo \n(instantes 5, 21 e 35) usando o m\u00e9todo de mapeamento de texturas 3D simples (visto na \nse\u00e7\u00e3o 2.2.2.4.2) \u00e0 esquerda e o m\u00e9todo de compress\u00e3o e descompress\u00e3o (visualiza\u00e7\u00e3o) \nGritex \u00e0 direita. Ressalta-se que na Figura 5.5 s\u00e3o visualizados apenas os dados do \ndescarregamento, sem dados de acumula\u00e7\u00e3o no fundo do mar. Pode-se observar a \nsimilaridade entre as imagens a2, b2 e c2 e a1, b1 e c1, respectivamente.  \n\nUm aspecto interessante para ter id\u00e9ia do volume armazenado \u00e9 visualizar a \ntextura 3D de \u00edndices e de refinamentos, resultantes da compress\u00e3o Gritex. A Figura \n5.6(a) e 5.6(b) exibem, respectivamente, a textura de \u00edndices e de refinamentos. A \nvisualiza\u00e7\u00e3o da textura de \u00edndices \u00e9 um pouco curiosa, pois os \u00edndices que referenciam \nos refinamentos tamb\u00e9m s\u00e3o mapeados para cores. Como a implementa\u00e7\u00e3o do processo \nde armazenamento est\u00e1 no formato (z,y,x) e n\u00e3o (x,y,z), os valores mapeados para cores \nestar\u00e3o no formato (b,g,r) e n\u00e3o (r,g,b). Isso explica a cor azul predominante \ninicialmente, seguindo o tom de verde e, finalmente, o vermelho. As cores na textura de \nrefinamento s\u00e3o as pr\u00f3prias cores dos sub-volumes refinados. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n\n\n 62\n\n \n(a1) \n\n \n(a2) \n\n \n(b1) \n\n \n(b2) \n\n \n(c1) \n\n \n(c2) \n\nFIGURA 5.5 - Compara\u00e7\u00e3o entre visualiza\u00e7\u00f5es usando texturas 3D simples e usando a \nt\u00e9cnica Gritex: s\u00e3o ilustrados os instantes de tempo 5 , 21 e 35, com as imagens \u00e0 \nesquerda sendo geradas com texturas 3D simples e as da direita  usando o m\u00e9todo \n\nGritex \n\n \n\n \n\n \n\n\n\n 63\n\n \n\n \n(a) \n\n \n(b) \n\nFIGURA 5.6 - Texturas 3D de \u00edndice e refinamento produzidas por Gritex com n\u00edvel 4 \nde parada \n\nUm outro n\u00edvel de parada da primeira etapa do m\u00e9todo de compress\u00e3o Gritex, \nn\u00edvel 5, foi utilizado com o mesmo conjunto de dados. Neste n\u00edvel, os sub-volumes \nresultantes obt\u00e9m dimens\u00e3o de 43 e ocupam um espa\u00e7o na textura de \u00edndices \ncorrespondente a 323 ((128/4)3). A textura de \u00edndices poder\u00e1, ent\u00e3o, conter at\u00e9 64 \n((128/32)3) instantes de tempo. \n\nA compress\u00e3o dos 36 instantes de tempo ocorreu, tamb\u00e9m, em torno de 6 minutos, \ne resultou em 1.165.507 sub-volumes ou nodos homog\u00eaneos de dimens\u00e3o 43, e 14.141 \nsub-volumes de 43, que necessitaram de refinamento (Tabela 5.1). A fun\u00e7\u00e3o hash \nidentificou 1.385 colis\u00f5es, ou seja, 12.756 (14.141-1.385) sub-volumes de 43 foram \narmazenados na textura de refinamento, restando ainda 20.012 (32.768-12.756) posi\u00e7\u00f5es \nlivres.  \n\nA descompress\u00e3o produziu os mesmos resultados da Figura 5.5 mas, obviamente, \nas texturas 3D de \u00edndices e refinamentos (Figura 5.7) s\u00e3o diferentes das da Figura 5.6.  \n\n \n\n \n(a) \n\n \n(b) \n\nFIGURA 5.7 - Texturas 3D de \u00edndice e refinamento produzidas por Gritex com n\u00edvel 5 \nde parada \n\n \n\n\n\n 64\n\nResumidamente, a Tabela 5.1 mostra a compara\u00e7\u00e3o dos resultados da t\u00e9cnica de \ncompress\u00e3o para tr\u00eas n\u00edveis de parada (relacionados a este estudo de caso), apresentando \na capacidade m\u00e1xima de inst\u00e2ncias de tempo e refinamentos armazenados, o n\u00famero \nresultante de sub-volumes homog\u00eaneos, heterog\u00eaneos e id\u00eanticos (duplicados). Tamb\u00e9m \n\u00e9 apresentado o n\u00famero de texturas 3D (1283) utilizadas para armazenar as 36 inst\u00e2ncias \nde tempo e seus respectivos refinamentos. \n\nTABELA 5.1 - Compara\u00e7\u00e3o dos resultados do m\u00e9todo de compress\u00e3o \n\nN\u00edvel \n\nM\u00e1x. \nInst\u00e2ncias \nde tempo \n(\u00cdndices) \n\nM\u00e1x. \nRefina-\nmentos \n\nSub-\nvolumes \nhomog\u00ea-\n\nneos \n\nSub-\nvolumes \nheterog\u00ea-\n\nneos \n\nSub-\nvolumes \n\nduplicados\n\n\u00cdndices \nutilizados \n\nRefina-\nmentos \n\nutilizados\n\n3 4.096 512 17.355 1.077 0 0,009 2,104 \n\n4 512 4.096 143.894 3.562 126 0,070 0,839 \n\n5 64 32.768 1.165.507 14.141 1.385 0,562 0,390 \n \n\nOutra an\u00e1lise de grande import\u00e2ncia \u00e9 apresentada na Tabela 5.2 para compara\u00e7\u00e3o \ndo desempenho da visualiza\u00e7\u00e3o. Esta tabela mostra a m\u00e9dia da varia\u00e7\u00e3o da taxa de \nframes por segundo (FPS) em rela\u00e7\u00e3o \u00e0 janela de visualiza\u00e7\u00e3o e ao n\u00famero de pol\u00edgonos \ndesenhados para obter a imagem do volume. \n\nTABELA 5.2 - An\u00e1lise de desempenho de visualiza\u00e7\u00e3o em quadros por segundo \n\nPol\u00edgonos Dimens\u00e3o da janela de visualiza\u00e7\u00e3o FPS \n\n200 1282 33,76 \n\n200 2562 8,65 \n\n200 5122 4,23 \n\n500 1282 14,66 \n\n500 2562 4,00 \n\n500 5122 1,30 \n\n \n \n\n \n\n \n\n\n\n 65\n\n6 Conclus\u00e3o \nEste trabalho apresentou um novo m\u00e9todo para visualiza\u00e7\u00e3o direta de volumes \n\ndin\u00e2micos (representados por uma fun\u00e7\u00e3o 4D) em tempo real usando texturas 3D e \ncaracter\u00edsticas de hardware gr\u00e1fico. O m\u00e9todo Gritex seguiu uma abordagem em duas \netapas, sendo a primeira para compress\u00e3o (em pr\u00e9-processamento) de v\u00e1rios volumes de \ndados, representando inst\u00e2ncias de tempo, para grids armazenados em texturas 3D, e a \nsegunda, para descompress\u00e3o e visualiza\u00e7\u00e3o dos dados usando o conceito de texturas \ndependentes presente no hardware gr\u00e1fico. \n\nO m\u00e9todo apresentou, em alguns casos, uma rela\u00e7\u00e3o de quadros por segundo \nmaior que 30, o que torna a visualiza\u00e7\u00e3o n\u00e3o apenas interativa e sim em tempo real. \nVale ressaltar que esta rela\u00e7\u00e3o tamb\u00e9m leva em conta o n\u00famero de planos utilizados \npara mapear a textura 3D e a dimens\u00e3o da janela de visualiza\u00e7\u00e3o. \n\nO grande custo computacional do m\u00e9todo se concentra na etapa de compress\u00e3o \ndos volumes de dados. Mas este custo n\u00e3o chega a ser considerado desvantagem, j\u00e1 que \n\u00e9 parte de um pr\u00e9-processamento dos dados e n\u00e3o do processo de visualiza\u00e7\u00e3o \npropriamente dito. \n\nAnalisando o m\u00e9todo Gritex em rela\u00e7\u00e3o aos demais trabalhos descritos na \nliteratura, apenas o trabalho de Kraus e Ertl (2002) se assemelha a este m\u00e9todo. Al\u00e9m de \napresentar uma abordagem 2D e 3D, Kraus e Ertl (2002) tamb\u00e9m apresentaram, como \nvisto no cap\u00edtulo 2, uma abordagem de compress\u00e3o de dados 4D referentes a uma \nfun\u00e7\u00e3o de campos de ilumina\u00e7\u00e3o (Levoy e Hanrahan, 1996), utilizando um esquema em \ndois n\u00edveis de \u00edndices, armazenados em texturas 3D, e baseado no conceito de \ndepend\u00eancia de texturas em hardware. O m\u00e9todo tamb\u00e9m n\u00e3o apresenta uma \nabordagem hier\u00e1rquica flex\u00edvel para a determina\u00e7\u00e3o de sub-volumes homog\u00eaneos e \nheterog\u00eaneos e n\u00e3o h\u00e1 detalhes sobre um poss\u00edvel re-uso de dados de sub-volumes \nhomog\u00eaneos, como desenvolvido em Gritex. \n\nO m\u00e9todo Gritex \u00e9 gen\u00e9rico para a utiliza\u00e7\u00e3o de quantas texturas forem \nnecess\u00e1rias para o armazenamento dos dados. A limita\u00e7\u00e3o do n\u00famero de instru\u00e7\u00f5es para \na unidade texture shader (64 instru\u00e7\u00f5es com o hardware utilizado) foi o \u00fanico fator \ndeterminante para o uso de apenas duas texturas na atual implementa\u00e7\u00e3o. O relaxamento \ndessa limita\u00e7\u00e3o propicia a utiliza\u00e7\u00e3o de mais de duas texturas para o armazenamento dos \ndados volum\u00e9tricos din\u00e2micos. Isto quer dizer que mais de uma textura 3D poder\u00e1 \narmazenar tanto os \u00edndices da primeira etapa quanto seus refinamentos.  \n\nPoss\u00edveis trabalhos diretamente derivados deste podem surgir aplicando o m\u00e9todo \ncom outros volumes de diferentes simula\u00e7\u00f5es ou oriundos de outros dom\u00ednios, para uma \nan\u00e1lise do impacto de diferentes taxas de coer\u00eancia espacial e temporal, assim como de \ndiferentes n\u00edveis de esparsidade. \n\n \n\n \n\n\n\n66 \n\n \nAnexo \n\n(Artigo publicado no I Workshop de Teses e Disserta\u00e7\u00f5es do XV Simp\u00f3sio Brasileiro de \nComputa\u00e7\u00e3o Gr\u00e1fica e Processamento de Imagens e na Revista Scientia da Unisinos) \n\nReal-Time Volume Rendering of Dynamic Data Using Graphics Hardware \n         \n\nAL\u00c9CIO P. D. BINOTTO, JO\u00c3O L. D. COMBA, CARLA M. D. S. FREITAS \n\n \nII/UFRGS \u2013 Instituto de Inform\u00e1tica da Universidade Federal do Rio Grande do Sul, Caixa Postal \n\n15.064, 91501-970 Porto Alegre, RS, Brasil  \n{abinotto, comba, carla}@inf.ufrgs.br \n\n \nAbstract. Many applications in computational fluid dynamics work with time-varying volumetric \ndata (4D). Although high-dimensional, it is possible to compress these data when they are sparse \nor have coherence (spatial or temporal). In this work we are developing a new compression \nscheme that benefits from 3D textures of recent graphics hardware, and we antecede it will be \npossible to render it in real time. Tests will be performed using the data produced in MAPEM \nproject. \n \n\n1 Introduction \nThe visualization and representation of physical \nphenomena is very important to many scientific \nareas. For example, the MAPEM project \n(Environment Monitoring of Off-Shore Activities \nand Exploration) evaluates the impact in the \nmarine ecosystem of the discharge of drilling cuts \nproduced during oil perforation. Seabed samples \nare collected before and after drilling, and pass \nthrough a complete analysis by several groups \n(chemistry, statistics, geosciences, etc). The \nvisualization of the discharge process is very \nuseful to help understand the results obtained in \nthis analysis, and this is the main goal of this \nwork. \n\nThe representation of the discharge \nphenomenon can become very complex (see \nBrodlie et al. [5]). Solutions to this type of \nproblems are studied in the Computational Fluid \nDynamics (CFD) field, where it is common to \ndecompose the domain in uniform cells (grids), \nwith each cell containing an approximation of the \nfunction. This approach produces volumetric \ndatasets (3D) for each instance of time, which \nrepresents a 4D dataset if we consider all time \ninstances.  \n\nIn the MAPEM project, approximations to \nthe discharge process are obtained using a \nsimulator developed by the Exxon Mobil \n\nCorporation called OOC (The Offshore Operators \nComittee Mud and Produced Water Discharge \nModel, Brandsma and Smith [7]). The simulator \nallows the user to specify the parameters that \ndescribe the discharge process (location, pipe \norientation, salinity, fluid concentration, currents, \netc). The discharge process is approximated using \na mathematical model, which produces an \nestimated dispersion of discharged fluids and \nmaterials during oil drilling. These data is \nrepresented in a uniform 3D grid or 2D planar \nsections, and can be sampled at any instance of \ntime during the simulation. In order to interpret \nthe generated results, scientific visualization \ntechniques are used. \n\nVolume Rendering is the classic Computer \nGraphics technique to render volumetric data as \ndescribed. Traditionally, it is computationally \nvery expensive, requires faster computers and \neven special hardware, which limited the \nwidespread use of the technique. Recently, the \nadvance of graphics hardware is changing this \nscenario. Several new features, such as support to \nmulti-texturing and 3D textures, can be used by \nvolumetric rendering algorithms to speed-up \ncomputations and make it real-time.   \n\nIn this paper we present a novel approach to \nperform volume rendering using recent graphics \nhardware. The paper is organized as follows. First, \nwe review past and related work. Next, we present \nthe new features of graphics hardware, specially \n\n \n\n\n\n67 \n\nthe 3D and dependent textures, which are \nimportant to understand the technique proposed in \nSection 4. The description of the visualization \nmodel used for the proposed technique is \npresented in Section 5. Section 6 presents the \ncurrent stage of the work, followed by conclusions \nand future directions. \n\n2 Related Work \nFour-dimensional data composed of several \ninstances of volumetric data have been widely \nused in flow visualization. In Shen et al. [2], an \nefficient structure called the TSP-tree (Time-\nSpace Partitioning) was created to visualize \ntemporal series of volumetric data.  Ellsworth et \nal. [1] followed extended this work with a way to \nrepresent TSP trees in hardware, using 3D \ntextures of a SGI Infinite Reality 2. \n\nEngel et al. [4] proposed an approach that \nexplores the 3D textures of the GeForce3 graphics \nboard (NVIDIA  Corporation). Volume rendering \nusing 3D textures is done by rendering a stack of \n3D textured slices (polygons) orthogonal to the \nviewing direction position. Each slice is processed \naccording to its distance to the viewer, starting \nwith the nearest slice. Each pixel of a slice \ncorresponds to the contribution of one ray \nsegment that is emitted by the viewer and the \naccumulation is computed considering the impact \nof the correspondent pixel in the previous slice \nprocessed. The access to each pixel value, as well \nas the combination of several pixel colors, is \ncomputed using the GeForce3 pixel shader, which \nwe will review in the next section. \n\n3 Review of the GeForce3 Pixel Shader \nNowadays, graphic cards have been incorporating \nmany interesting features that were previously \nonly implemented by software. Besides allowing \ninnumerous complex effects, these features also \nmake it possible to render scenes composed by \nmillions of triangles at very high fill-rates. \n\nOne of the features that can produce \nincredible effects is the use of textures. In the \nGeForce3 card (64MB of memory), it is possible \nto process simultaneously for each fragment a \nmaximum of four textures (1D, 2D or 3D). \nTextures can be seen as tables that are indexed by \ntexture coordinates, producing a 32-bit integer and \nrepresented as rgba colors.  \n\nThe first attempts to allow more than one \ntexture access to each pixel (called multi-\ntexturing) were implemented by individual \n\naccesses to each one of the textures. In the \nOpenGl 1.2 specification [10], some level of \ndependency between texture accesses was \nintroduced by allowing the result of a texture \naccess to be passed on to the following texture \nunit. In the GeForce3, a more elaborate \ndependency between texture units was proposed, \nallowing other ways to re-use the result of a \ntexture unit (rgba). This approach is called \ndependent textures. The available operations to \ncombine these results with the next input texture \ncoordinates were still limited, but even so they are \nable to obtain innumerous effects. For example, \nComba and Bastos [3] mentioned that a pixel \ncolor could be an input parameter for the \nfollowing texture, by changing the depth texture \ncoordinate value (z) of a fragment for the color \nvalue obtained. \n\nOnce all texture accesses were performed, \nthe final task of the pixel shader is to produce the \nfinal color of the pixel. A single pixel can be \nassociated with different colors, coming from \neither the interpolated colors generated during \nrasterization or colors obtained by accesses to \ntexture units. In the GeForce3, a dedicated \nhardware called the Register Combiners allows \nthe different colors of a pixel to be combined and \nproduce its final color. \n\nThe next section discusses the proposed \nstructure to visualize in real time the fluid \ndynamic data using these hardware features. \n\n4 Data Storage using 3D Textures \nSome CFD data are extremely sparse, such as in \nliquid and gaseous fluids simulation. In addition, \ndynamic data usually possess high degrees of \ncoherence, either spatial or temporal. Using the \nabove properties, we designed a compression \nmechanism that can be implemented using the \ngraphics hardware, specially the properties of 3D \ntextures. Our solution is initially target to the \nGeForce3, which has four 3D textures and a \ndefined set of dependent operations, but can be \napplied to future boards with more general \ndesigns and more resources. Once this is done, our \nintention is to make it possible the real-time \nvisualization of the CFD simulations. \n\nWe assume that the input data consists of \ndifferent time instances, each represented by a \nsparse volumetric data. Due to the graphics card \nlimitations, the dimension of each volume is at \nmost 1283, which is a reasonable value in volume \n\n \n\n\n\n68 \n\nrendering. Each cell corresponds to an intensity \nscalar value varying from 0 to 255. \n\nThe approach consists in creating a two-step \nindexed dependent mechanism, like the \ndependent textures. In the first step, a regular \ndecomposition of each volume in sub-volumes is \nperformed, corresponding to an initial hierarchical \nsubdivision of the data. In this step, our goal is to \nseparate the regions that need to be detailed from \nthe ones that are homogeneous. A hierarchical \nsubdivision in few levels usually suffices for this. \nIn the second step, we add refinements to each \nnon-homogeneous sub-volumes obtained in the \nfirst step. All of these values are storage in \ndifferent textures units (the first phase uses a 3D \ntexture and the second another one). \n\nIn the first step, a hierarchically process \ndecomposes the volumetric data in a structure \nsimilar to an octree (M\u00e4ntyl\u00e4 [6]), where the \noriginal volume is divided in eight sub-volumes \n(cubes). In octrees, when a cube contains a \nconstant value it is called black (if the value is \nhigher than zero) or white (if the value is zero). In \ncontrast, if the value is not constant it is called \ngray and requires additional subdivisions. \nHowever, the adaptive nature of octrees creates \nirregular structures most of the time not suited to \nbe stored directly in 3D textures. To force the \nindispensable regularity, we build a complete \noctree (with all nodes) until a certain depth, which \nmust be less than the maximum depth (seven for a \n128x128x128 volume). Note that a complete \noctree is an uniform partition of a volume, or in \nother words, a grid. Note that the octree nature of \nthe structure remains in the fact that we only \nrefine the sub-volumes that are not homogeneous.  \n\nDepending on the data properties (coherence \nand sparcity), it is possible to estimate the best \nbreakpoint of the subdivision process, allowing it \nto be changed according to the data. In our current \nexperiments, we are using four levels of \nsubdivision, as illustrated in Figure 1.  \n\n \n\n \n\n \n\n \n\n \n\nFigure 1 Subdivision until the fourth level. \nIn the left we have the size of the sub-volume, and \n\nin the right the number of cubes in the \ncorresponding level. \n\nThere are 4096 nodes at the fourth level of \nthe grid corresponding to the first index of a given \ntime instance. This information is stored in one of \nthe 3D textures available, defined at the current \ntests due to the graphics memory limitations at \n1283, which has room to 512 (1283/4096) of these \nfourth level grids.  \n\nOnly gray nodes need to be refined, and will \nbe stored in an additional index. We chose to use \na two-level indexing scheme, therefore the entire \nsub-volume corresponding to a gray node needs to \nbe represented elsewhere in other textures. \nBecause we have three more 3D textures \navailable, we could store in the first index the \nnecessary information to locate the sub-volume in \nother textures, such as the texture identification \n(2, 3, or 4), and the origin of the sub-volume \ninside the texture (ox, oy, oz), and use dependent \noperations to retrieve this data. Due to limitations \non the dependent texture operations available \ntoday (specific dot products), only one 3D texture \ncan be used. This limitation is soon going to be \nremoved as NVIDIA antecedes a fully \nprogrammable fragment shader with more \npowerful dependent operations [9]. \n\nThe second texture will contain all \nrefinements of gray nodes obtained from the grids \nstored in the first texture. In order to explore \nspatial and temporal coherence, we look to re-use \nrefinement information as much as possible using \na hashing scheme that speeds-up comparisons of \neach newly created refinement to the ones \npreviously created. Collision cases allow us to re-\nuse indexes, increasing the compression of the \ndata. More elaborate hash functions can be \nproposed and we are using a very simple strategy \nthat takes the remainder to the table size of the \nsums of the scalar values of each cell in the sub-\nvolume, and so far the results are satisfactory. \n\nFigure 2 shows the two-index model scheme \nproposed. Each volume, representing a time \ninstance, is divided until a user-defined level (four \nin this case). For these parameters, the initial \nvolume contains 163 volumes of size 83, for a total \nof 512 different time instances. All  stored in the \nfirst 3D texture. Each gray sub-volume has size \n83, refined and stored in the second texture.  \n\n0 \n\n1: 8=23 \n2: 64=26 \n3: 512=29\n\n4: 4096=212 83=29 \n\n1283=221 \n\n643=218 \n\n323=215 \n\n163=212 \n\n\u2026 \n\n\u2026 \n\n\u2026 \n\n\u2026 \n\n \n\n \n\n \n\n\n\n69 \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n \n\n \n\n \n\n \nFigure 2 Two-indexed storage technique graphic \n\nscheme. \n\n5 Data Visualization \nThe visualization of the dynamic data stored in the \ntwo-level index structure will follow the approach \nproposed by Engel et al. [4]. The visualization \nworks by rendering a sequence of parallel slices \northogonal to the viewing direction, indexed to the \n3D texture. Here, we will have a different way to \nretrieve information from the textures, using the \nmethod proposed in the previous section. \n\nDuring rendering, each slice is processed \naccording to its distance in relation to the viewer, \nfrom the nearest to the farthest (front-to-back). \nPixel accumulation uses two adjacent slices (slab), \nwhich takes into account the impact of the \ncorrespondent pixel in the already processed front \nslice (sf). The accumulation is mapped onto one \nslice (either the front or the back slice) as depicted \nin Figure 3. Color and opacity will be linearly \ninterpolated for each pixel by the GeForce3 \nrasterization engine.  \n\n \n \n \n\n \n \n\nFigure 3 Pair of polygons (slab). \n\nTemporal coherence can also be explored if \nthe volume data do not change in a certain period \nof time. In this case, volume visualization will be \nexecuted just once, allowing images to be re-used \nfor further frames in an animation sequence. Shen \net al. [2] describes good results using this \n\napproach, decreasing volume rendering time and \nI/O time. 4th Grid Level 511 8 (128) \n\n1st Phase 6 Current Stage \nThe implementation is under way. The \nconstruction of the two-index structure is already \nconcluded for a general case. The volume \nrendering of a single instance of a 3D structure is \ndone, remaining to integrate both parts using the \ndependent operations of the GeForce3 board. We \nare also experimenting with the new NVIDIA \nshading language CG (C for Graphics, [8]), which \nwill be probably be the standard for graphics \nhardware programming.  \n\n16 56 63 \n\nTextures16 \n16 8 (128) 7 0  (0,15,0) \n\nPreliminary results obtained by the two-index \nimplementation illustrate the potential of our \napproach to CFD data, specially the ones in the \nMAPEM project.  For three time instances of \ndynamic data (1283x3) produced by the OOC \nsimulator using the two-index approach until with \nbreakpoint at the fourth level, we reached a well \ndistributed hash table (at most with two nodes in \neach linked list of the hash table) with a total of \n1459 homogeneous nodes and 77 nodes that need \nto be refined. \n\nThe implementation reads 3D textures as a \ncollection of 2D slices, corresponding grids of a \ngiven time instance. For the MAPEM project, we \nwrote a visualization tool that allows other types \nof visualization of the discharge process \n(visualization of bathymetry data and \naccumulations at the bottom of sea, pipe position \nand orientation, etc), and we will be integrating \ninto this program the visualization using the two-\nindex approach. The visualization of the discharge \nprocess as described by the simulation data will \nhelp the analysts of the MAPEM project to better \nunderstand the effects of the discharge in the \nmarine ecosystem, as well as serve as a tool to \ndebug the simulator itself.   \n\n7 Conclusions and Future Work \nThe main contribution of this research is to define \na new approach for real-time volume rendering of \ndynamic data that are sparse and presents high \nlevels of spatial and temporal coherence. The \nexistence of 3D textures in hardware, together \nwith powerful ways to combine values stored in \ntextures, allowed to design a new way to \ncompress and access volumetric data, in such way \nthat it can be rendered in real time.  \n\nThe new indexed model will be widely tested \nin many general CFD functions, including the \n\nsf s\n\n (15,0,0) \n 7 \n\n (0,0,0) \n8 (128) \n\n1288 2nd Phase \n\n8 \n\n (1,0,0) \n \n\n (0,0,0) \n (0,1,0)  \n\n127\nRefinement \n\n8 0 128\n\n128\n\n \n\n\n\n70 \n\nspecific generated by the MAPEM project. Other \nvolumetric functions or high-dimensional \nfunctions, such as light-fields may be considered.  \n\nAlso, as graphics hardware is changing so \nmuch recently, we antecede that we will need to \nfollow the new boards released by NVIDIA. We \nbelieve that the appearance of a new shading \nlanguage as CG will make our task of \nprogramming the hardware a lot easier.  \n\nAcknowledgements \nWe would like to thank Cnpq for the support to \nthe MAPEM project (Finep/CTPETRO), which \nhas been motivating this work. \n\nReferences \n[1] D. Ellsworth, L. J. Chiang and H. W. Shen, \n\n\u201cAccelerating Time-Varying Hardware \nVolume Rendering Using TSP Trees and \nColor-Based Error Metrics\u201d, In Volume \nVisualization, 2000. \n\n[2] H. W. Shen, L. J. Chiang and L. K. Ma,  \u201cA \nFast Volume Rendering Algorithm for Time-\nVarying Fields Using a Time-Space (TSP) \nTree\u201d, In Volume Visualization, 1999. \n\n[3] J. L. D. Comba and R. Bastos, \u201cSpecial \nEffects with Current Graphics Hardware\u201d. \nRevista de Inform\u00e1tica Te\u00f3rica e Aplicada 8 \n(2001), n\u00ba 2, 69--88. \n\n[4] K. Engel, M. Kraus and T. Ertl, \u201cHigh-\nQuality Pre-Integrated Volume Rendering \nUsing Hardware-Accelerated Pixel \n\nShading\u201d, In Graphics Hardware \nSymposium, 2001. \n\n[5] K. W. Brodlie et al., \u201cScientific \nVisualization Techniques and Applications\u201d, \nSpringer-Verlag, 1992. \n\n[6] M. M\u00e4ntyl\u00e4, \u201cAn Introduction to Solid \nModeling\u201d, Computer Science Press, 1988. \n\n[7] M. G. Brandsma and J. P. Smith, \u201cOffshore \nOperators Committee Mud and Produced \nWater Discharge Model \u2013 Report and User \nGuide\u201d, ExxonMobil Upstream Research \nCompany, 1999. \n\n[8] NVIDIA Corporation, nVidia CG \nspecifications, \nhttp://developer.nvidia.com/cg. \n\n[9] NVIDIA Corporation, nVidia CineFx \nspecifications, http://developer.nvidia.com. \n\n[10] Silicon Graphics Inc., OpenGl 1.2 \nspecifications, \nhttp://www.opengl.org/developers/document\nation/OpenGL12.html. \n\n[11] D. Benson and J. Davis, \u201cOctree Textures\u201d, \nProceedings of SIGGRAPH 02, 2002. \n\n[12] D. DeBry, J. Gibbs, D. D. Petty and N. \nRobins, \u201cPainting and Rendering Textures \non Unparameterized Models\u201d, Proceedings \nof SIGGRAPH 02, 2002. \n\n[13] I. Boada, I. Navazo and R. Scopigno, \n\u201cMultiresolution Volume Visualization with \na Texture-Based Octree\u201d, The Visual \nComputer 17 (2001), n\u00ba 3, 185\u2014197. \n\n \n \n\n \n\nhttp://developer.nvidia.com/cg\nhttp://developer.nvidia.com/\nhttp://www.opengl.org/developers/documentation/OpenGL12.html\nhttp://www.opengl.org/developers/documentation/OpenGL12.html\n\n\n71 \n\nBibliografia \nAKELEY, K. RealityEngine Graphics. Computer Graphics, New York, p. 109-116, Aug. \n1993. Trabalho apresentado na SIGGRAPH Conference, 1993. \n\nBENSON, D.; DAVIS, J. Octree Textures. ACM Transactions on Graphics, New York, \nv.21, n.3, July 2002. Trabalho apresentado na SIGGRAPH, 2002. \n\nBINOTTO, A. P. D. Visualiza\u00e7\u00e3o da Simula\u00e7\u00e3o de Escoamentos. 2001. Trabalho \nIndividual (Mestrado em Ci\u00eancia da Computa\u00e7\u00e3o) \u2013 Instituto de Inform\u00e1tica, UFRGS, \nPorto Alegre. \n\nBOADA, I.; NAVAZO, I.; SCOPIGNO, R. Multiresolution Volume Visualization with a \nTexture-Base Octree. The Visual Computer, New York, v.17, 2001. \n\nBRANDSMA, M.; SMITH, J. Offshore Operators Committee Mud and Produced \nWater Discharge Model: report and user guide. Houston: ExxonMobil Upstream Research \nCompany, 1999. \n\nBRODLIE, K. et al. Scientific Visualization: techniques and applications. Berlim: \nSpringer-Verlag, 1992. \n\nBRODLIE, K. ; WOOD, J. Recent Advances in Volume Visualization. Computer \nGraphics Forum, Amsterdam, v.20, n.2, p. 125-148, 2001. \n\nCABRAL, B.; CAM, N.; FORAN, J. Accelerated Volume Rendering and Tomographic \nReconstruction Using Texture Mapping Hardware. In: ACM/IEEE SYMPOSIUM ON \nVOLUME VISUALIZATION, 1994. Proceedings\u2026 New York: IEEE Press, 1994. p. 91-\n98. \n\nCAMERON, G.; UNDRILL, P. Rendering Volumetric Medical Image Data on a SIMD-\nArchitecture Computer. In: SIGGRAPH,  1994. Proceedings\u2026 Orlando: [s.n.], 1994. p. \n451-458. \n\nCHERNAYEV, E.  Marching Cubes 33: construction of topologically correct and \nadaptive trilinear surfaces. Cidade: CERN, 1995. (Relato t\u00e9cnico CN/95-17). Dispon\u00edvel \nem:&lt;http://wwwinfo.cern.ch/asdoc/psdir/mc.ps.gz>. Acesso em:18 dez. 2002. \n\nCIGNONI, P. et al. Reconstruction of Topologically Correct and Adaptive Trilinear \nSurfaces. Computer Graphics Forum, Amsterdam, v.24, n.3, p. 399-418, 2000. \n\nCLINE, H. et al. Two Algorithms for Three-Dimensional Reconstruction of Tomograms. \nMedical Physics, [S.l.], v.15, n.3, p. 320-327, 1988. \n\nCOMBA, J.L.D.; BINOTTO, A.P.D.; FREITAS, C.M.D.S. Visualiza\u00e7\u00e3o tridimensional \ninterativa dos resultados da simula\u00e7\u00e3o da perfura\u00e7\u00e3o do po\u00e7o Eagle. In: RELAT\u00d3RIO do \nProjeto MAPEM. Porto Alegre: Instituto de Geoci\u00eancias, 2003.   \n\nDEBRY, D. et al. Painting and Rendering Textures on Unparameterized Models. ACM \nTransactions on Graphics, New York, v.21, n.3, July 2002. Trabalho apresentado na \nSIGGRAPH, 2002. \n\nDIETRICH, C.; COMBA, J. Repulsive Potential Fields. Dispon\u00edvel em: \n<http://www.cgshaders.org/contest/contest-results-03.php>. Acesso em: 19 fev. 2003. \n\n \n\nhttp://wwwinfo.cern.ch/asdoc/psdir/mc.ps.gz\nhttp://www.cgshaders.org/contest/contest-results-03.php\n\n\n72 \n\nDOI, A.; KOIDE, A. An Efficient Method of Triangulating Equi-valued Surfaces by Using \nTetrahedral Cells. IEICE Trans. Commun. Elec. Inf. Syst., [S.l.], v.74, n.1, p. 214-224, \n1991. \n\nELLSWORTH, D.; CHIANG, L.; SHEN, H. Accelerating Time-Varying Hardware \nVolume Rendering Using TSP Trees and Color-Based Error Metrics. In: ACM/IEEE \nSYMPOSIUM ON VOLUME VISUALIZATION, 2000. Proceedings\u2026 New York: IEEE \nPress, 2000. p. 119-128. \n\nELVINS, T. T. A Survey of Algorithms for Volume Visualization. Computer Graphics \nForum, [S.l.], v.26, n.3, p. 194-201, 1992. \n\nENGEL, K.; KRAUS, M.; ERTL, T. High-Quality Pre-Integrated Volume Rendering Using \nHardware-Accelerated Pixel Shading. In: EUROGRAPHICS/SIGGRAPH WORKSHOP \nON GRAPHICS HARDWARE, 2001. Proceedings\u2026 Los Angeles: Addison-Wesley \nPublishing Company Inc, 2001. p. 9. \n\nFOLEY, J. D. et al. Computer Graphics: Principles and Practice. Washington: Addison-\nWesley, 1992. \n\nFUCHS, H.; ZEDEM, Z. M.,; USELTON, S. P. Optimal Surface Reconstruction from \nPlanar Contours. Communications of the ACM, New York, v. 20, n. 10, p. 693-702, \n1977. \n\nKAUFMAN, A. E. Volume Visualization. Los Alamitos, CA: IEEE Computer Society \nPress, 1991. \n\nKEPPEL, E. Approximating Complex Surfaces by Triangulation of Contour Lines. IBM \nJournal of Research and Development, [S.l.], v. 19, n. 1, p. 2-11, 1975. \n\nKRAUS, M.; ERTL, T. Adaptive Texture Maps. In: EUROGRAPHICS/SIGGRAPH \nWORKSHOP ON GRAPHICS HARDWARE, 2002. Proceedings\u2026 San Antonio: IEEE \nPress, 2002. p. 1-10. \n\nLACROUTE, P. Analysis of a Parallel Volume Rendering System Based on the Shear-\nWarp Factorization. IEEE Transactions on Visualization and Computer Graphics, \n[S.l.], v. 2, n. 3, p. 218-231, 1996. \n\nLACROUTE, P.; LEVOY, M. Fast Volume Rendering Using a Shear-Warp \nTransformation of the Viewing Transformation. In: SIGGRAPH, 1994. Proceedings\u2026 \nOrlando: [s.n.], 1994. p. 451-458. \n\nLAMAR, E.; HAMANN, B.; JOY, K. Multiresolution techniques for Interactive Texture-\nBased Volume Visualization. In: IEEE CONFERENCE ON VISUALIZATION, 10., 1999, \nSan Francisco, CA. Visualization\u201999: proceedings. New York: ACM, 1999. p. 355-361. \n\nLEVOY, M. Volume Rendering \u2013 Display of Surfaces from Volume Data. Computer \nGraphics and Applications, Los Alamitos,  v. 8, n. 3, p. 29-37, 1988. \n\nLEVOY, M. Efficient Ray Tracing of Volume Data. ACM Transaction on Graphics, \nNew York, v. 9, n. 3, p. 245-261, 1990. \n\nLEVOY, M.; HANRAHAN, P. Light Field Rendering. In: SIGGRAPH, 1996. \nProceedings\u2026 New York: ACM Press, 1996. p.31-42. \n\n \n\n\n\n73 \n\nLORENSEN, W. E.; CLINE, H. E. Marching Cubes: A High Resolution 3D Surface \nConstruction Algorithm. In: SIGGRAPH, 1987. Proceedings\u2026 New York: ACM Press, \n1987. p. 163-169. \n\nMANSSOUR, I. H.; FREITAS, C. M. D. S. Visualiza\u00e7\u00e3o Volum\u00e9trica. Revista de \nInform\u00e1tica Te\u00f3rica e Aplicada, Porto Alegre, v. 9, n. 2, p. 97-126, 2002. \n\nM\u00c4NTYL\u00c4, M. An Introduction to Solid Modeling. New York: Computer Science \nPress, 1988. \n\nMEI?NER, M.; HOFFMANN, U.; STRA?ER, W. Enabling Classification and Shading for \n3D Texture Based Volume Rendering Using OpenGL and Extensions. In: IEEE \nCONFERENCE ON VISUALIZATION, 10., 1999, San Francisco, CA. Visualization\u201999: \nproceedings. Los Alamitos: IEEE Press, 1999. p. 207-214. \n\nMEYERS, D.; SKINNER, S.; SLOAN, K. Surfaces from Contours. ACM Transactions \non Graphics, New York, v. 11, n. 3, p. 228-258, 1992. \n\nNVIDIA COORPORATION. CG Toolkit: a developer\u2019s guide to programmable graphics. \nDispon\u00edvel em:&lt;http://developer.nvidia.com/Cg>. Acesso em: 19 fev. 2003. \n\nNVIDIA COORPORATION. Dispon\u00edvel em:&lt;http://www.nvidia.com/developer>. Acesso \nem: 01 ago. 2001. \n\nSHEN, H.; CHIANG, L.; MA, K. A Fast Volume Rendering Algorithm for Time-Varying \nFields Using a Time-Space Partitioning (TSP) Tree. In: ACM/IEEE SYMPOSIUM ON \nVOLUME VISUALIZATION, 1999. Proceedings\u2026 New York: IEEE Press, 1999. p. 371-\n377. \n\nUPSON, C.; KEELER, M. V-Buffer: Visible Volume Rendering. In: SIGGRAPH, 1988. \nProceedings\u2026 New York: ACM Press, 1988. p. 59-64. \n\nWESTERMANN, R.; ERTL, T. Efficiently Using Graphics Hardware in Volume \nRendering Applications. In: SIGGRAPH, 1998. Proceedings\u2026 New York: ACM Press, \n1998. p. 169-177. \n\nWESTOVER, L. Interactive Volume Rendering. In: WORKSHOP ON VOLUME \nVISUALIZATION, 1989. Proceedings\u2026 North Carolina: University of North Carolina \nPress, 1989. p. 9-16. \n\nWESTOVER, L. Footprint Evaluation for Volume Rendering. In: SIGGRAPH, 1990. \nProceedings\u2026 New York: ACM Press, 1990. p. 367-376. \n\nWYVILL, G.; MCPHEETERS, C.; WYVILL, B. Data Structure for Soft Objects. The \nVisual Computer, [S.l.], v. 2, p. 227-234, 1986. \n\nYAGEL, R. et al. Hardware Assisted Volume Rendering of Unstructured Grids by \nIncremental Slicing. In: ACM/IEEE SYMPOSIUM ON VOLUME VISUALIZATION, \n1996. Proceedings\u2026 New York: IEEE Press, 1996. p. 55-62. \n \n\n \n\n \n\nhttp://developer.nvidia.com/Cg\nhttp://www.nvidia.com/developer\n\n\tIntrodu\u00e7\u00e3o\n\tVisualiza\u00e7\u00e3o Volum\u00e9trica e Compress\u00e3o\n\tIntrodu\u00e7\u00e3o\n\tT\u00e9cnicas de Visualiza\u00e7\u00e3o Volum\u00e9trica\n\tExtra\u00e7\u00e3o de Superf\u00edcies\n\tConex\u00e3o de Contornos \\(Contour-Connecting\\)\n\tCubos Marchantes (Marching Cubes)\n\n\tVisualiza\u00e7\u00e3o Direta de Volumes\n\tAlgoritmo de Ray Casting\n\tAlgoritmo de Splatting\n\tAlgoritmo de Shear-Warp\n\tMapeamento de Textura\n\tTextura 2D\n\tTextura 3D\n\n\n\n\tCompress\u00e3o de Dados Volum\u00e9tricos\n\tVisualiza\u00e7\u00e3o Volum\u00e9trica com Multiresolu\u00e7\u00e3o Ba\n\tMapeamento de Texturas Adaptativas\n\t\u00c1rvores TSP\n\n\n\tHardware Gr\u00e1fico\n\tUnidade de Programa\u00e7\u00e3o de V\u00e9rtices \\(vertex sh\n\tEfeitos Especiais\n\tExemplo em Cg\n\n\tUnidade de Programa\u00e7\u00e3o de Fragmentos \\(pixel o?\n\tUnidade de Programa\u00e7\u00e3o de Texturas \\(texture s?\n\tEfeitos Especiais\n\tExemplo em Cg\n\n\n\tCompress\u00e3o e Visualiza\u00e7\u00e3o de Dados Volum\u00e9trico?\n\tCompress\u00e3o\n\tPropriedades B\u00e1sicas dos Dados\n\tDados de Entrada para o Mecanismo\n\tO M\u00e9todo de Compress\u00e3o Gritex\n\tPrimeira Etapa: \u00cdndice\n\tSegunda Etapa: Refinamento\n\n\n\tDescompress\u00e3o e Visualiza\u00e7\u00e3o\n\tDetalhes de implementa\u00e7\u00e3o\n\n\n\tResultados\n\tGera\u00e7\u00e3o dos Dados Volum\u00e9tricos Din\u00e2micos\n\tVisualiza\u00e7\u00e3o dos Dados Volum\u00e9tricos\n\tVisualiza\u00e7\u00e3o Usando Texturas 2D e 3D Simples\n\tVisualiza\u00e7\u00e3o Usando a T\u00e9cnica de Compress\u00e3o Gr?\n\n\n\tConclus\u00e3o"}]}}}