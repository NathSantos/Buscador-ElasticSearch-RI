{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.25022"}, {"@name": "filename", "#text": "9567_DM_DiogoPedrosa_2018_MEEC.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "Control-law for Oil Spill Mitigation with a\nteam of Heterogeneous Autonomous\nVehicles\n\nDIOGO COELHO PEDROSA\njulho de 2018\n\n\n\nControl-law for Oil Spill Mitigation with a\nteam of Heterogeneous Autonomous\n\nVehicles\n\nDiogo Coelho Pedrosa,\nN\u00ba 1120331\n\nMaster in Electrical and Computer Engineering\nBranch of Autonomous Systems\n\nJuly 26, 2018\n\n\n\n\n\nDissertation for partial satisfaction of the requirements of the Master\n\nin Electrical and Computer Engineering\n\nCandidate: Diogo Coelho Pedrosa,\n\nN\u00ba 1120331\n\nSupervisor: Dr. Andre? Miguel Pinheiro Dias\n\napd@isep.ipp.pt\n\nMaster in Electrical and Computer Engineering\n\nBranch of Autonomous Systems\n\n\n\n\n\nAgradecimentos\n\nGostaria de utilizar esta secc?a?o para, em primeiro lugar, agradecer ao meu orienta-\n\ndor Eng.\u00ba Andre? Dias, por me ter proporcionado a oportunidade de realizar a minha\n\ndissertac?a?o num tema interessante e com tanto impacto como este e pela ajuda disponi-\n\nbilizada ao longo da mesma.\n\nA toda a \u201dfam??lia\u201d do laborato?rio de sistemas auto?nomos (LSA) que me acompanhou e\n\nforneceu ajuda, sempre que necessa?ria, durante este percurso.\n\nA todos os meus amigos e colegas de curso que participaram nesta caminhada comigo e\n\nme ofereceram apoio na realizac?a?o desta dissertac?a?o, sem os quais na?o chegaria a? sua con-\n\nclusa?o, Alexandre Amaral, Andre? Filipe, Caio Lomba, Denys Sytnyk, Eduardo Soares,\n\nFa?bio Azevedo, Henrique Silva, Ricardo Pereira, Tiago Miranda, Tiago Pereira. Um\n\nenorme agradecimento ao meu amigo de longa data Pedro Meireles por toda a amizade\n\ne apoio ao longo destes a?rduos ultimos anos.\n\nA toda a minha fam??lia, pela educac?a?o que me proporcionou, pelos esforc?os efetuados\n\nna minha formac?a?o acade?mica e por estarem presentes sempre que necessitei.\n\nPor fim, um agradecimento muito especial a? minha namorada, Le?nia Carmo, pela\n\npacie?ncia, carinho, apoio e dedicac?a?o demnstrados durante a elaborac?a?o desta dis-\n\nsertac?a?o.\n\nDiogo Coelho Pedrosa\n\ni\n\n\n\nThis page was intentionally left blank.\n\n\n\nAbstract\n\nOil spill incidents in the sea or harbours occur with some regularity during explo-\n\nration, production, and transport of petroleum products. In order to mitigate the impact\n\nof the oil spill in the marine life, immediate, safety, effective and eco-friendly actions must\n\nbe taken. Autonomous vehicles can assume an important contribution by establishing a\n\ncooperative and coordinated intervention.\n\nThis dissertation presents the development of two path planning control-laws, the\n\nfirst one an autonomous surface vehicle (ASV) being able to contour the oil spill while\n\nis deploying microorganisms and nutrients (bioremediation) capable of mitigate and\n\ncontain the oil spill spread, and the second one for a unmanned aerial vehicle (UAV) in\n\norder to perform the coverage of the entire spillage area with the same microorganisms\n\nand nutrients deployment capabilities.\n\nIn order to validate both methods, a simulation environment was developed in Gazebo\n\nwith a oil spill scenario, an ASV and an UAV.\n\nField tests have been conducted in the Leixo?es Harbour in Porto, Portugal.\n\nKeywords:\n\nPath planning, oil spill, detection, mitigation, simulation, Gazebo, PX4, UAV, STORK\n\nI, ASV, ROAZ II, Artificial Potential Field, Normal Vectors.\n\niii\n\n\n\nThis page was intentionally left blank.\n\n\n\nResumo\n\nIncidentes relacionados com derrames de petro?leo no oceano ou em portos ocorrem\n\ncom alguma regularidade, durante a explorac?a?o, produc?a?o e transporte de petro?leo e seus\n\nderivados. Para mitigar o impacto desses derramamentos na fauna e flora marinha de\n\numa forma imediata, segura, efectiva e amiga do ambiente novas ac?o?es sa?o necessa?rias.\n\nVe??culos autonomos podem providenciar uma importante contribuic?a?o establecendo uma\n\nintervenc?a?o cooperativa e coordenada.\n\nEsta dissertac?a?o apresenta o desenvolvimento de dois algoritmos de controlo para o\n\nplaneamento de trajecto?rias, a primeira para um ve??culo de superf??cie auto?nomo (ASV)\n\nser capaz de contornar o per??metro do derrame enquanto distribui microorganismos e\n\nnutrientes (bio-remediac?a?o), capazes de mitigar e conter a propagac?a?o do derramamento\n\nde petro?leo e a segunda para um ve??culo ae?reo na?o-tripulado (UAV) ser capaz de cobrir\n\ntodo a a?rea de derrame enquanto distribui os mesmos microorganismos e nutrientes.\n\nDe forma a validar ambos os me?todos, um ambiente de simulac?a?o foi desenvolvido\n\nem Gazebo com cena?rio do derrame de petro?leo, um ASV e um UAV.\n\nTestes de campo foram realizados no porto de Leixo?es, no Porto, Portugal.\n\nPalavras-Chave:\n\nPath planning, derrame de petro?leo, detec?a?o, mitigac?a?o, simulac?a?o, Gazebo, PX4, UAV,\n\nSTORK I, ASV, ROAZ II, Artificial Potential Field, Normal Vectors.\n\nv\n\n\n\nThis page was intentionally left blank.\n\n\n\nContents\n\nAgradecimentos i\n\nAbstract iii\n\nResumo v\n\nList of Figures xi\n\nList of Tables xv\n\nList of Acronyms xviii\n\n1 Introduction 1\n\n1.1 Dissertation Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n\n1.2 Background and motivation . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n\n1.3 Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n\n1.4 Dissertation Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n\n2 State of the Art 7\n\n2.1 Path planning for autonomous vehicles . . . . . . . . . . . . . . . . . . . . 7\n\n2.1.1 UAVs Path Planning Methods . . . . . . . . . . . . . . . . . . . . 7\n\n2.1.2 ASVs Path Planning Methods . . . . . . . . . . . . . . . . . . . . 10\n\n2.2 Oil Spill Detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n\n2.2.1 Visible Spectrum Camera . . . . . . . . . . . . . . . . . . . . . . . 12\n\n2.2.2 Infrared Camera . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n\n2.2.3 Fluorosensor Laser . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n\n2.2.4 Radar . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n\nvii\n\n\n\nviii CONTENTS\n\n2.3 Oil Spill Mitigation strategies . . . . . . . . . . . . . . . . . . . . . . . . . 16\n\n3 Fundamentals 19\n\n3.1 Path planning techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n\n3.1.1 Potential Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n\n3.1.2 Probabilistic Roadmap . . . . . . . . . . . . . . . . . . . . . . . . . 24\n\n3.1.3 Voronoi . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n\n3.2 ROS - Robot Operating System . . . . . . . . . . . . . . . . . . . . . . . . 28\n\n3.3 Robotic Simulators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n\n3.3.1 UWSim . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n\n3.3.2 Gazebo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n\n3.3.3 MORSE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n\n4 Conceptual approach 39\n\n4.1 Proposed Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n\n4.2 UAV\u2019s trajectory computation . . . . . . . . . . . . . . . . . . . . . . . . 41\n\n4.3 ASV\u2019s trajectory computation . . . . . . . . . . . . . . . . . . . . . . . . . 44\n\n4.3.1 Method I: Artificial Potential Fields with 8 interchangeable goals 45\n\n4.3.2 Method II: Artificial Potential Fields with an extra Tangential\n\nForce . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n\n4.3.3 Method III: Control Points through Normal Vectors with Arti-\n\nficial Potential Fields . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n\n5 Implementation 49\n\n5.1 Autonomous Vehicles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n\n5.1.1 Unmanned Aerial Vehicle (UAV): STORK I . . . . . . . . . . . . . 49\n\n5.1.2 Autonomous Surface Vehicle (ASV): ROAZ II . . . . . . . . . . . . 51\n\n5.2 Scenario creation and simulation . . . . . . . . . . . . . . . . . . . . . . . 54\n\n5.3 Spill identification and real world position computation . . . . . . . . . . 59\n\n5.4 UAV\u2019s trajectory computation in the simulation scenario . . . . . . . . . . 62\n\n5.5 ASV\u2019s trajectory computation in the simulation scenario . . . . . . . . . . 63\n\n5.5.1 Method I: Artificial Potential Fields with 8 interchangeable goals 63\n\n5.5.2 Method II: Artificial Potential Fields with an extra Tangential\n\nForce . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n\n\n\nCONTENTS ix\n\n5.5.3 Method III: Control Points through Normal Vectors with Arti-\n\nficial Potential Fields . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n\n6 Results 71\n\n6.1 UAV\u2019s trajectory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n\n6.2 ASV\u2019s trajectory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n\n7 Conclusion and Future Work 81\n\nBibliography 83\n\n\n\nThis page was intentionally left blank.\n\n\n\nList of Figures\n\n1.1 Deepwater Horizon platform explosion on April 20, 2010. . . . . . . . . . 1\n\n1.2 Oil spill simulation scenario. Cooperative ASV/UAV oils spill perception\n\nand mitigation(bioremediation). . . . . . . . . . . . . . . . . . . . . . . . 3\n\n3.1 Representation of the attractive forces towards the goal.[1] . . . . . . . . . 21\n\n3.2 Representation of the repulsive forces imposed by each obstacle. . . . . . . 22\n\n3.3 Representation of the overall potential field. . . . . . . . . . . . . . . . . . 22\n\n3.4 Representation of the most favourable trajectory for the vehicle to reach\n\nthe goal position. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n\n3.5 Representation of a scenario that contains a Local Minima. . . . . . . . . 23\n\n3.6 Comparison between the probabilistic roadmaps (in blue) and resulting\n\ntrajectories (in orange) in the same map with different number of random\n\nsamples, 50 (left) and 250 (right).1 . . . . . . . . . . . . . . . . . . . . . . 25\n\n3.7 Terms used in Voronoi Diagrams. . . . . . . . . . . . . . . . . . . . . . . . 26\n\n3.8 Perpendicular bisector representation. . . . . . . . . . . . . . . . . . . . . 26\n\n3.9 Circumcenter representation. . . . . . . . . . . . . . . . . . . . . . . . . . 27\n\n3.10 Graphical representation of a Voronoi Diagram. . . . . . . . . . . . . . . . 27\n\n3.11 Example of the publish/subscribe messaging model.[2] . . . . . . . . . . . 29\n\n3.12 ROS components[3] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n\n4.1 Proposed Architecture for Oil Spill Mitigation. . . . . . . . . . . . . . . . 39\n\n4.2 Angle of dispersion of the powder spreader nozzle.2 . . . . . . . . . . . . . 41\n\n4.3 Coverage area of the powder spreader nozzle. . . . . . . . . . . . . . . . . 42\n\n4.4 Waypoints computation through the minimum and maximum contour\n\npoints along the X axis on each horizontal layer. . . . . . . . . . . . . . . 43\n\nxi\n\n\n\nxii LIST OF FIGURES\n\n4.5 Repulsive forces applied to the ASV for oil spill avoidance. . . . . . . . . . 44\n\n4.6 Resultant force from repulsive and attractive forces. . . . . . . . . . . . . 44\n\n4.7 Representation of the behaviour of the orientation component of the Tan-\n\ngential Force. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n\n4.8 New point based on three consecutive contour points. . . . . . . . . . . . 48\n\n5.1 Hexarotor AUV STORK I. . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n\n5.2 UAV\u2019s spraying system for the Lyophilized powder. . . . . . . . . . . . . . 50\n\n5.3 Autonomous Surface Vehicle ROAZ II. . . . . . . . . . . . . . . . . . . . . 51\n\n5.4 ASV\u2019s spraying system for the Lyophilized powder. . . . . . . . . . . . . . 52\n\n5.5 Implementation of the spraying system in the ASV being the water pump\n\nsystem noticeable in blue and the motorised sprinkler in red. . . . . . . . 53\n\n5.6 Oil spill and vehicles simulation in Gazebo. . . . . . . . . . . . . . . . . . 54\n\n5.7 Oil spill from the ASV perspective. . . . . . . . . . . . . . . . . . . . . . . 55\n\n5.8 Oil spill from the UAV perspective. . . . . . . . . . . . . . . . . . . . . . . 55\n\n5.9 Model of the ocean surface (left) and oil spill (right). . . . . . . . . . . . . 56\n\n5.10 ROS/Gazebo integration with PX4. . . . . . . . . . . . . . . . . . . . . . 57\n\n5.11 Model of the Iris UAV. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n\n5.12 Model of the ROAZ II ASV. . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n\n5.13 Input (left) and output (right) through OpenCV \u201dfindContours\u201d function. 59\n\n5.14 UAV trajectory computation. . . . . . . . . . . . . . . . . . . . . . . . . . 62\n\n5.15 Control-law performance of Method I in a simulated oil spill scenario. . . 63\n\n5.16 Control-law performance of Method I for a simulated scenario with dif-\n\nferent geometric forms. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n\n5.17 Control-law performance of Method II with Utangential=3.2 in a simulated\n\noil spill scenario. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n\n5.18 Control-law performance of Method II, with Utangential=3.2, for a simu-\n\nlated scenario with different geometric forms. . . . . . . . . . . . . . . . . 65\n\n5.19 Control-law performance of Method II, with Utangential=16.2 in a simu-\n\nlated oil spill scenario. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n\n5.20 Control-law performance of Method II, with Utangential=30, for a simu-\n\nlated scenario with different geometric forms. . . . . . . . . . . . . . . . . 66\n\n5.21 Control-law performance of Method III in a simulated oil spill scenario. . 67\n\n\n\nLIST OF FIGURES xiii\n\n5.22 Control-law performance of Method III, for a simulated scenario with\n\ndifferent geometric forms. . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n\n5.23 Trajectories overlap comparison in a simulated oil spill scenario. . . . . . 68\n\n5.24 Trajectories overlap comparison, for a simulated scenario with different\n\ngeometric forms. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n\n6.1 Experimental Field Tests at Leixo?es Harbour. . . . . . . . . . . . . . . . . 71\n\n6.2 RViz representation of the scenario and vehicles position. . . . . . . . . . 72\n\n6.3 Powder loading into the UAV\u2019s container. . . . . . . . . . . . . . . . . . . 73\n\n6.4 UAV\u2019s powder releasing system in action. . . . . . . . . . . . . . . . . . . 73\n\n6.5 UAV\u2019s estimated trajectory representation. . . . . . . . . . . . . . . . . . 74\n\n6.6 Representation of the data obtained from the UAV\u2019s PX4 autopilot. . . . 75\n\n6.7 UAV trajectory representation from the PX4 global position logs. . . . . . 75\n\n6.8 ASV sprinkler in action. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n\n6.9 ASV ROAZ II field base station. . . . . . . . . . . . . . . . . . . . . . . . 77\n\n6.10 ASV trajectory representation in the basestation. . . . . . . . . . . . . . . 77\n\n6.11 ASV trajectory on April 23. . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n\n6.12 ASV trajectory on April 24. . . . . . . . . . . . . . . . . . . . . . . . . . 79\n\n\n\nThis page was intentionally left blank.\n\n\n\nList of Tables\n\n3.1 Simulator Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n\n5.1 Travelled distance performed by each method. . . . . . . . . . . . . . . . . 69\n\nxv\n\n\n\nThis page was intentionally left blank.\n\n\n\nList of Acronyms\n\nASV Autonomous Surface Vehicle\n\nAUV Autonomous Underwater Vehicle\n\nAPF Artificial Potential Field\n\nCCD Charge-Coupled Device\n\nCo3-AUVs Cooperative Cognitive Control for Autonomous Underwater Vehicles\n\nDARPA Defense Advanced Research Projects Agency\n\nDART Dynamic Animation and Robotics Toolkit\n\nDRC DARPA Robotics Challenge\n\nDVL Doppler Velocity Log\n\nGNSS Global Navigation Satellite System\n\nGPS Global Positioning System\n\nICRA International Conference on Robotics and Automation\n\nIMU Inertial Measurement Unit\n\nISEP Instituto Superior de Engenharia do Porto\n\nLSA Laborato?rio de Sistemas Auto?nomos\n\nMORSE Modular OpenRobots Simulation Engine\n\nNASA National Aeronautics and Space Administration\n\nxvii\n\n\n\nxviii LIST OF TABLES\n\nODE Open Dynamics Engine\n\nOSG OpenSceneGraph\n\nOSRF Open Source Robotics Foundation\n\nPRM Probabilistic RoadMap\n\nRAUVI Reconfigurable AUV for Intervention Missions\n\nROCK Robot Construction Kit\n\nROS Robot Operating System\n\nROSM Robotic Oil Spill Mitigation\n\nSAR Synthetic Aperture Radar\n\nSDF Simulation Description Format\n\nSLAR Side-Looking Airborne Radar\n\nSRC Space Robotics Challenge\n\nUAV Unmanned Aerial Vehicle\n\nURDF Unified Robot Description Format\n\nUSARSim Unified System for Automation and Robot Simulation\n\nUUV Unmanned Underwater Vehicle\n\nUWSim UnderWater Simulator\n\nV-REP Virtual Robot Experimentation Platform\n\nXML eXtensible Markup Language\n\nYARP Yet Another Robot Platform\n\n\n\nChapter 1\n\nIntroduction\n\nMarine oil spills have a large economic and ecologic impact in the world community,\n\nwith high losses in the marine life in the ecosystems. Oil spill incidents occur with some\n\nregularity during the exploration, production, and transport of petroleum products[4][5].\n\nRecently, in 2010, the Deepwater Horizon oil spill in the Gulf of Mexico, depicted in\n\nFigure 1.1, has been considered one of the largest accidental marine oil spill in the history\n\nof the petroleum industry with more than 210 million gallons of crude oil released in the\n\nocean surface over 180.000 km2 with the oil spill cleaning process involving over 39.000\n\npersonnel, 5000 vessels and 110 aircrafts[6]. In 2002 at coast of Galicia (North of Spain),\n\nthe tanker Prestige sank at 250km from the coast and spilled more than 60.000 tons of\n\noil crude over thousands of kilometres causing great harm to the local fishing industry.\n\nFigure 1.1: Deepwater Horizon platform explosion on April 20, 2010.\n\n1\n\n\n\n1.1. Dissertation Scope Chapter 1\n\nThe current oil spill cleaning technology includes physical (e.g. controlled burning;\n\nabsorbing) and chemical (e.g. dispersing) actions, which is largely constrained by mar-\n\nitime conditions. Though these treatments are important to rapidly control the diffusion\n\nand drift of the oil, they are not suitable for ecological restoration. Recently, bioremedi-\n\nation using microorganisms to degrade the remaining spilled oil has been proposed as a\n\ncost-effective alternative to the use of chemical additives[7]. In order to improve the oil\n\nspill mitigation, in situ operational technologies must be developed to ensure immedi-\n\nate, safety, effective and eco-friendly actions to minimise the environmental damages[8].\n\nFollowing these requirements, several autonomous vehicles have been developed, such as\n\nthe Seaswarm (MIT Senseable City Lab)[9] and Protei: Open Source Sailing Drone[10].\n\nCommon to both autonomous vehicles is the oil spill mitigation being based in a system\n\nfor ocean-skimming and oil removal, which is a limitation in future interventions due to\n\nthe impact of the oil in the mechanical parts.\n\nThis dissertation proposes to address the development of two path planning control-\n\nlaws, the first for an autonomous surface vehicle (ASV) being able to contour the oil\n\nspill while is deploying microorganisms and nutrients (bioremediation) capable of miti-\n\ngate and contain the oil spill spread and the second for a unmanned aerial vehicle (UAV)\n\nallowing it to perform the coverage of the entire spillage area with the same microor-\n\nganisms and nutrients deployment capabilities. In order to evaluate the path-planning\n\ndeveloped algorithms, a simulation was also addressed during the dissertation with the\n\ngoal of creating an oil spill scenario and the subsequent mitigation actions in a robotic\n\nsimulator.\n\n1.1 Dissertation Scope\n\nThis dissertation developed in the context of the master in Electrical and Computer\n\nEngineering in the branch of Autonomous Systems of the School of Engineering of the\n\nPolytechnic Institute of Porto (ISEP). It is also based in the FCT - Portuguese Founda-\n\ntion for Science and Technology as part of project ROSM \u2013 Robotic Oil Spill Mitigation\n\n(POCI-01-0145-FEDER-24055) and by the EU SpilLess project: First-line response to\n\noil spills based on native microorganism cooperation1, through Blue Labs: innovative so-\n\nlutions for maritime challenges program. (EASME/EMFF/2016/1.2.1.4/02/SI2.749374\n\n-SpilLess). In both projects, the goal is the development of an autonomous and coordi-\n\nnated action able to increase the efficiency of the bioremediation process, by deploying\n\n1https://ec.europa.eu/easme/en/first-line-response-oil-spills-based-native-microorganisms-\ncooperation\n\n2\n\n\n\nChapter 1 1.2. Background and motivation\n\nmicroorganisms and nutrients on identified targets, with the required amounts, and by\n\nmaking oil spill combat from air (UAV) and water surface (ASV), as depicted in Figure\n\n1.2. The UAV is responsible for detecting the oil spill area through a thermographic\n\ncamera and combat the leakage inner areas by spreading lyophilized native microbial\n\nconsortium dust over the oil spill, while the ASV release the product mixed with water\n\non the stroke border areas.\n\nFigure 1.2: Oil spill simulation scenario. Cooperative ASV/UAV oils spill perception\n\nand mitigation(bioremediation).\n\n1.2 Background and motivation\n\nDuring the last years, the LSA from ISEP, has played a fundamental role in the\n\ndevelopment of autonomous robotic systems to operate in distinct scenarios, aerial, ter-\n\nrestrial or aquatic (surface or underwater), with applications ranging from monitoring\n\nand mapping to search and rescue. In this environment and within the scope of SpilLess\n\nand ROSM projects, the need to perform perception and navigation algorithms in a\n\nsimulation environment is a challenging requirement, and therefore a motivation for this\n\nwork.\n\nThis dissertation will try to reduce the impacts of oil spillage incidents on the en-\n\n3\n\n\n\n1.3. Objectives Chapter 1\n\nvironment with an attempt to develop a mitigation strategy more efficient and robust\n\nthan the physical and chemical like controlled burning, ocean-skimming, absorbing and\n\ndispersion, that will be achieved through an action of bioremediation. The problem of\n\nsimulating a complex manoeuvre for an ASV robot and for an UAV and a comparative\n\nanalysis of simulators for marine robotics are presented.\n\n1.3 Objectives\n\nHaving in mind the requirements of the SpilLess and ROSM projects described above\n\nand the challenges imposed by an oil spill, the main objectives of this dissertation are:\n\n\u2022 Integrate the first line responses to oil spill incidents with the support of hetero-\ngeneous autonomous vehicles;\n\n\u2022 Cooperative perception, combine information from different sensors with different\nlevels of oil spill detection accuracy;\n\n\u2022 Cooperative and coordinated manoeuvres in order to maximise the efficiency (max-\nimum overlap of the bacteria-oil area);\n\n\u2022 UAV: Oil spill area detection, through the thermographic camera and combat the\nleakage inner areas by spreading lyophilized native microbial consortium dust over\n\nthe oil spill, while ensuring optimal coverage;\n\n\u2022 ASV: Contour the oil spill area while releasing the powder mixed with water on\nthe stroke border areas;\n\n\u2022 Increase the overall efficiency of the oil spill combat missions;\n\n\u2022 Decrease the overall time of reaction and mission costs;\n\n\u2022 Development of a realistic simulation scenario able to identify and represent the\nmitigation manoeuvres;\n\n\u2022 Solution validation through field tests and proof-of-concept through demonstration\nat a \u201cquasi-real\u201d scenario.\n\n1.4 Dissertation Structure\n\nThis dissertation is organised in seven chapters. In Chapter 1 a brief introduction of\n\nthis dissertation, its scope and objectives, the background and motivation are presented.\n\n4\n\n\n\nChapter 1 1.4. Dissertation Structure\n\nIn Chapter 2, a study of methods and approaches already developed by the scientific\n\ncommunity for autonomous aerial and surface vehicles path planning methods, oil spill\n\ndetection and mitigation strategies are described.\n\nIn Chapter 3, the fundamentals that support this dissertation focusing mainly on\n\nthe trajectory planning techniques and robotic simulators that could be the support to\n\ndevelop and study a novel method for oils spill mitigation are presented.\n\nIn Chapter 4, the proposed architecture and control-law manoeuvres for the ASV\n\nand UAV are present and detailed.\n\nIn Chapter 5, the system implementation with a description of the vehicles used for\n\nthe trials are presented. In this chapter the author addresses also the creation of an oil\n\nspill scenario in the simulator and the mitigation manoeuvres representation.\n\nIn Chapter 6, the simulation results for each vehicle in the presence of different\n\nobstacles and also the field tests performed in Leixo?es harbour with the developed path\n\nplanning in the presence of a simulated oil spill.\n\nFinally, in the Chapter 7 the conclusions taken from the development of this disser-\n\ntation are presented as well as some lines of future work.\n\n5\n\n\n\nThis page was intentionally left blank.\n\n\n\nChapter 2\n\nState of the Art\n\nIn this chapter an analysis of the methods and algorithms already developed and used\n\nby the community for path-planning and obstacle avoidance, in autonomous vehicles, are\n\naddressed.\n\nAn analysis of the current strategies applied to oil spillage detection and mitigation\n\nis also presented in this chapter.\n\n2.1 Path planning for autonomous vehicles\n\nThe applications of the autonomous mobile robot in many fields such as industry,\n\nspace, defence and transportation, and other social sectors are growing day by day[11].\n\nTo achieve those complex operations, path planning algorithms capable of handling static\n\nand dynamic environments are necessary.\n\nA standard path planning algorithm will simply try to find the optimal path, clear\n\nof obstacles, from the initial position to the goal, minimising the distance and therefore\n\nenergy and time spent. For some specific applications, a coverage path planning is\n\nnecessary, in that case, the algorithm computes an optimal path that ensures a complete\n\ncoverage of the interest area, while avoiding the obstacles present in the environment.\n\nLiterature surveys of standard and coverage path planning techniques, used for mobile\n\nrobot navigation, can be found in [11] and [12], respectively.\n\n2.1.1 UAVs Path Planning Methods\n\nThe specific path planning algorithm for an UAV attempts to compute an optimal\n\nand collision free path, while having the physical and temporal constraints into account.\n\n7\n\n\n\n2.1. Path planning for autonomous vehicles Chapter 2\n\nA large portion of the studied implementations can be included into one of the following\n\ncategories[13][14]:\n\n\u2022 Sampling-based methods: These approaches require the previous knowledge\nof the environment for its sampling into nodes. They can be divided into two\n\nsubcategories, passive methods like Probabilistic Roadmaps (PRM), K-PRM, S-\n\nPRM, 3D Voronoi, Visibility Graphs, etc., that generate road-maps from the initial\n\nnode to the target node but are not capable of determine the optimal path having\n\nto resort to an additional algorithm and active methods like Rapidly-exploring\n\nRandom Trees (RRT), Dynamic Domain RRT, RRT-Star, Artificial Potential Field\n\n(APF), etc., that are capable of both processes.\n\nThese algorithms are of easy implementation and appropriate for static and dy-\n\nnamic path planning conditions, being suitable for real-time implementation.\n\nAn implementation of Probabilistic Roadmaps by Kavraki[15] demonstrates the\n\ndivision of the algorithm into two phases, the learning phase where the collision-\n\nfree roadmap is created and the query phase where the best path is chosen.\n\nAn example of a Rapidly-exploring Random Tree method from 2011 by Shen[16]\n\ndetails the incremental construction of a tree through samples spread in the space.\n\n\u2022 Node-based methods: Similarly to the Sampling-based methods, the Node-\nbased methods generate a path through several nodes, however, this nodes are\n\ncreated through the previous obtainment of sensory data. The list of created algo-\n\nrithms based upon this approach is fairly extensive with examples as A*, Lifelong\n\nPlanning A* (LPA), Theta*, Lazy Theta*, Dynamic A* (D*), D* Lite and Har-\n\nmony Search, most of which can also be applied to the output of Sampling-based\n\nmethods.\n\nThe A* algorithm, first described by Dijkstra[17], is responsible for computing the\n\nfastest path, with the lowest cost, to the target node, through the node graph in\n\nthe implementation of Musliman[18].\n\nAn implementation of the Theta* algorithm by Filippis[19] takes into account the\n\nvehicle attitude to plan its trajectory in a 3D environment.\n\nA simpler implementation by Grzonka[20] generates a 2D trajectory for the vehi-\n\ncle, using the D* Lite algorithm. This implementation allow the generation of a\n\nposterior 2.5D trajectory with the inclusion of the Yaw component.\n\n8\n\n\n\nChapter 2 2.1. Path planning for autonomous vehicles\n\n\u2022 Mathematical model methods: This approach uses the models of the vehicle\nand environment, with the kinematic and dynamic limitations, to compute the\n\ncost function that will identify the optimal path for the vehicle. This approach\n\nis commonly used offline due to its high demand for computational power. Some\n\nclasses of problems included into this category are Mixed-Integer Linear Program-\n\nming (MILP), Binary Linear Programming, Nonlinear Programming and Extended\n\nKalman Filter (EKF).\n\nAn example of an EKF implementation combined with Simultaneous Localisation\n\nand Mapping (SLAM), by Huh[21], demonstrates how the 3D point cloud is gen-\n\nerated from the sensory data and the how the EKF filter estimates the vehicle and\n\nlandmarks states.\n\n\u2022 Bio-inspired methods: These methods replicate the biological behaviour with-\nout the construction of complex environment models and try to converge to the\n\nsolution, this procedure however, requires a high computational power.\n\nThe bio-inspired methods can be divided into two subcategories, Neural Networks\n\nthat generate a dynamic landscape for the neural activities and Evolutionary Algo-\n\nrithms (EA) that select randomly feasible solutions as the first generation, the en-\n\nvironment, robot\u2019s capacity, goal and other constraints are taken into consideration\n\nwhen planning the next step, the process stops when a pre-set value is achieved.\n\nSome examples of Evolutionary Algorithms are generic algorithm, memethic al-\n\ngorithm, particle swarm optimisation, ant colony optimisation and shuffled frog\n\nleaping algorithm.\n\nThe memethic algorithm is used in [22] by Shahidi to obtain a optimal path free\n\nof collisions, using a small population and in a few generations.\n\n\u2022 Multi-fusion based methods: To plan an optimal trajectory in a 3D environ-\nment, these methods combine several different simpler algorithms. These methods\n\nare also divided into two subcategories, Integration of Algorithms that integrate\n\nseveral path planning algorithms to achieve an optimal trajectory and Algorithms\n\nRanking that also use several path planning algorithms to achieve an optimal tra-\n\njectory but in a consecutive way.\n\nAn interesting implementation by Masehian[23] integrates a visibility graph with\n\na Voronoi diagram and a potential field to achieve the shortest and safest path.\n\nThere is two specific implementations of area coverage that are worth mentioning.\n\nThe first by Maza et al.[24], tackles the adversities of a cooperative action between\n\n9\n\n\n\n2.1. Path planning for autonomous vehicles Chapter 2\n\nmultiple UAVs for exploration of an area, this goal is achieved with the polygon area\n\ndecomposition and with efficient coverage algorithms that rely on zigzag patterns. The\n\nsecond implementation by Schwager et al.[25], presents a decentralised control strategy\n\nfor positioning and orienting multiple robotic cameras to collectively monitor an envi-\n\nronment, this approach is capable of handling adjustments on the number of vehicles\n\nand vehicles with different degrees of mobility.\n\n2.1.2 ASVs Path Planning Methods\n\nAfter the aerial and underwater vehicles contribution to the scientific world, the\n\ninterest in Autonomous Surface Vehicles (ASVs) has grown considerably. Although\n\nASVs present a high potential in maritime applications, their ability to detect and avoid\n\nobstacles still lacks development, being typically focused on above-surface obstacles while\n\nneglecting the need for the detection of sub-surface obstacles such as waters with reefs\n\nor lakes with shallow banks[26].\n\nAlthough most of the 2D path planning techniques described before could be adapted\n\nto ASVs, the most noticeable development in this field was the integration of the Inter-\n\nnational Regulations for Avoiding Collisions at Sea (COLREGs)[27], within the obstacle\n\navoidance algorithms, reducing the ocean navigation conflicts and maritime accidents at-\n\ntributed to human error, while simultaneously, establishing legal policies for unmanned\n\nvessels[28].\n\nThe modern COLREGs were delineated in 1972 by the International Maritime Or-\n\nganisation as a set of rules for potential collision scenarios, as crossing paths, head-on\n\nand overtaking, in a maritime environment. Although these rules describe possible ma-\n\nnoeuvres to avoid collisions, their creation was designed for human navigators usage,\n\nbeing dependent of the operator experience and interpretation. It is estimated that the\n\nsubjective nature of COLREGs and human error are related to 89% to 96% of marine\n\ncollisions. Therefore, if autonomous surface vehicles can operate in accordance with\n\nthese rules, maritime collisions can be vastly reduced.\n\nIn 2012, Naeem et al.[29] proposed an approach that relies on a simple waypoint\n\nby line-of-sight guidance strategy, coupled with a manual biasing scheme. The vehicle\n\nfollows the direct route through the multiple waypoints defined between the initial and\n\ngoal positions, when no obstacles are found on its path. When an obstacle is detected\n\nby the onboard vision-based detection system, a bias is added to the current reference\n\nheading angle, in order to avoid an obstacle. The added bias is compliant with the\n\nCOLREGs regulations. After the obstacle is overpassed, the heading angle, between the\n\n10\n\n\n\nChapter 2 2.1. Path planning for autonomous vehicles\n\nvehicle current position and the next waypoint, is computed once more.\n\nAnother implementation by Campbell et al.[30], uses an obstacle detection system\n\nbased on vision-LIDAR (light detection and radar), accesses the risk for the vehicle and\n\nwith an heuristic path planner, avoids obstacles in a COLREGs regulations compliant\n\nway.\n\nA worth mentioning implementation of COLREGs compliant path planning for ASVs\n\nwas recently developed by Hu et al.[31], this approach, in addition to the COLREGs\n\ncompliant obstacle avoidance algorithm and the risk assessment, enforces a multiobjec-\n\ntive optimisation based on particle swarm optimisation re-planning the original path.\n\nOther examples of navigation and obstacle avoidance in accordance with the Coast\n\nGuard Collision Regulations, for Autonomous Surface Vehicles, by Benjamin et al in\n\n2006 and by Pinto et. al in 2013, can be found in [32] and [33], respectively.\n\n11\n\n\n\n2.2. Oil Spill Detection Chapter 2\n\n2.2 Oil Spill Detection\n\nThe detection of an oil spill and its simultaneous mapping has been subject of mul-\n\ntiple distinct implementations in the past years and can occur through several different\n\nsensors. The interest in this field [34] comes from the urgency in reducing the impact of\n\nsuch incidents in the environment. Data relative to the spill such as the precise location\n\nand movement, support an effective action in order to reduce the impact of the pollution\n\nin the environment.\n\nAs stated before, several sensors can be used to achieve oil spill surveillance and map-\n\nping, varying from visible spectrum, infrared and thermographic cameras to fluorosensor\n\nlasers and radars, carried by aircrafts, UAVs or on satellites. In this section, techniques\n\nwith each sensor will be presented and analysed not with goal of being implemented\n\nduring the dissertation but in order to understand the vehicle behaviour during the oil\n\nspill intervention.\n\n2.2.1 Visible Spectrum Camera\n\nThe oil has an interesting aspect, it shows higher reflectance than water while not\n\npresenting a specific light absorption/reflection behaviour, this means that for oil identi-\n\nfication, one has rely on contrast differences from the oil to the enclosing waters within\n\nthe visible region of the electromagnetic spectrum (400 to 700nm approximately).\n\nAn example for a visible spectrum camera application can be found in [35], where\n\na push-broom scanner method is used. This method is described as the use of a CCD\n\n(Charge-Coupled Device) detector and an optical system to direct ground elements to\n\ndifferent parts of the CCD detector.\n\nOil spill detection with visible spectrum cameras has however several disadvantages,\n\nbeing the most noticeable the harsh weather conditions and the action of the light or\n\nits absence in the environment. The effect of this last can however be reduced since\n\nits known that the light, when it its the water surface at 53 degrees (Brewster angle)\n\nbecomes polarised in parallel with the water surface, so a detector can be set for this\n\nspecific angle and polarised lens can be used.\n\nIn the last years different approaches have been developed, one of them is the ex-\n\nploration of hyperspectral imaging in this scenario, that like other spectral imaging,\n\ncollects and processes information from across the electromagnetic spectrum. Although\n\nhyperspectral imaging requires the computation of extensive data, not ideal for a real-\n\ntime propose, a technique called spectral un-mixing is commonly used for characterising\n\nindividual pixels, that can be used for oil monitoring[34].\n\n12\n\n\n\nChapter 2 2.2. Oil Spill Detection\n\nEven if visible spectrum cameras present worse results on oil spill detection than\n\ntermographic cameras for example, due to the sun glint in the ocean surface that can\n\nbe falsely identified as an oil spill, they will continue to be widely used for support\n\noperations due to its economic aspect.\n\n2.2.2 Infrared Camera\n\nThe oil spill, when exposed to a heat source, as the sun, will emit infrared radiation\n\nand since the emissivity from the oil is distinct from the water is possible to detect\n\na distinct substance in the water. This behaviour of emission of radiation as thermal\n\nenergy is not completely understood since thick oil spills appear hot and intermediate oil\n\nthickness appears cool. While not completely understood, this transition seems to occur\n\nbetween the thickness of 50 and 150 \u00b5m, furthermore the minimum detectable layer for\nan oil slick is between 10 and 70 \u00b5m, making thin oil spills undetectable with infrared\ncameras.\n\nThe largest portion of infrared sensing of oil spills occur in the thermal infrared, at\n\nwavelenghts of 8-14 \u00b5m. During daylight, thick spills appear warmer than the surround-\ning water since they absorb solar radiation faster, while thin films tend to appear cooler\n\nthan oil-free water. This lower temperature can be correlated with the electromagnetic\n\ninterference on the oil layer. During the night-time the behaviour is completely inverted\n\nwith thin spills appearing warmer than the surrounding water and thicker spills acting as\n\nthermal insulators thus appearing cooler[36]. This contrast is supposedly higher during\n\ndaylight as stated by Dickins[37].\n\nHover and Plourde[38] evaluated the day and night imaging capabilities of ship-\n\nmounted thermographic sensors operating in 8 to 15 \u00b5m range, as well as hand-held\nsensors exploiting the 3 to 5 \u00b5m interval and found both types of systems useful in the\nidentification of oil slicks, although the performance of individual sensors depended on\n\nenvironmental conditions and sensor tuning.\n\nEven though infrared cameras present several disadvantages as not being capable of\n\nproviding thickness measurements and the possibility of false detections from seaweeds,\n\nsediment, organic matter, shoreline, and oceanic fronts, they are still widely used for oil\n\ndetection due its the availability of the market at a reduced cost.\n\n2.2.3 Fluorosensor Laser\n\nFluorosensor lasers take advantage of the presence of aromatic compounds in petroleum\n\nproducts, these compounds absorb ultraviolet light and become electronically excited,\n\n13\n\n\n\n2.2. Oil Spill Detection Chapter 2\n\nthis excitation is transformed into a fluorescence emission, primarily in the visible region\n\nof the spectrum, ranging from 400 to 650 nm, with peak centres in the 480 nm region.\n\nSince other natural fluorescing substances emit at sufficiently different wavelengths than\n\noil (e. g. chlorophyll yields a sharp peak at 685 nm), in most cases is easy to identify,\n\nwith high certainty, if oil is present in the environment.\n\nSome lasers increase even further its sensitivity and selectivity using a technique\n\ncalled \u201dgating\u201d, opening their detectors at the precise time that the signals return from\n\nthe surface. This feature can be taken even further to target specific regions below the\n\nsurface on the water column as deep as 2 meters[39]. As a sampling instrument, the\n\nlaser repetition rate and the velocity of the vehicle carrying the sensor are important\n\nin the sampling rate of the surface where the oil contamination is being observed. At\n\nground speeds of 100\u2013140 knots, at a laser repetition rate of 100 Hz, a fluorescence\n\nspectrum is collected approximately every 60 cm along the flight path. This decreases\n\nif the instrument is scanning.\n\nThe capability to identify oil presence in water, shoreline, soil, plants, ice and snow[40]\n\nis proving the enormous potential of fluorosensor lasers in an oil spill identification\n\nscenario.\n\n2.2.4 Radar\n\nRadar sensors became the standard sensor for mapping oil offshore, either carried by\n\naircrafts or as a satellite sensor. Its oil detecting capability comes from the attenuation of\n\nthe capillary waves, resulting in a \u201ddark\u201d region within the \u201dsea clutter\u201d, formed by the\n\nmicrowaves reflection in the oil-free water[41]. For a correct perception, low to moderate\n\nwave/wind conditions are necessary, bellow 1.5 m/s wind speeds the \u201dsea clutter\u201d formed\n\nis insufficient for oil spill detection and wind speeds stronger than 10 m/s difficult the\n\nvisibility of wave troughs.\n\nTwo distinct types of radar can be employed, Synthetic Aperture Radar (SAR) that\n\nuses the forward motion of the vehicle to simulate a long antenna, trying to replicate\n\nthe other type of radar, the Side-Looking Airborne Radar (SLAR), to obtain satisfac-\n\ntory spatial resolution, independent of the range but requiring sophisticated electronic\n\nprocessing, making this solution more expensive than SLAR. Even though studies show\n\na far superior performance by SAR[42], SLAR is widely used on oil spill remote sensing,\n\nmainly due to its lower price.\n\nApart from the wind/waves speed limitations, this sensor presents still another im-\n\nportant disadvantage, the possibility of false positives from fresh water slicks, calm areas,\n\n14\n\n\n\nChapter 2 2.2. Oil Spill Detection\n\nwave shadows behind structures or topographical features, shallow seaweed beds, bio-\n\ngenic oils and sea-life sperm. However, radars provide a very good solution for large-area,\n\nnight-time, and foul weather detection work.\n\n15\n\n\n\n2.3. Oil Spill Mitigation strategies Chapter 2\n\n2.3 Oil Spill Mitigation strategies\n\nImmediate and efficient responses to oil spills are of extreme importance to reduce\n\nthe economic and ecological impacts of such incidents. The quality of the response\n\nis dependent on several factors such as, the water temperature, the locale and most\n\nimportantly, on the specific type of oil spilled.\n\nIn the last years a wide range of oil spill countermeasures were developed, most of\n\nthem can be inserted into one of the following categories[43]:\n\n\u2022 Mechanical methods have the simplest concept, the use of booms (floating bar-\nriers) to contain the oil spreading, enclosing the spill into a well defined area, while\n\nusing oil skimmers to remove the oil floating on the water surface. Mechanical\n\nmethods are still widely used due to their simplicity, however they can only be\n\nenforced on calm waters;\n\n\u2022 Chemical methods though more efficient than mechanical methods when prop-\nerly applied, could endanger countless species. These methods transform the\n\nphysico-chemical properties of the oil mainly through dispersants, mixture of emul-\n\nsifiers and solvents that improves the separation of the particles, breaking the oil\n\nslick into small droplets. These small droplets however, can be dispersed into the\n\nwater column and when in high concentration have an acute lethal toxicity for\n\nmany species, especially on fish eggs and coral;\n\n\u2022 Bioremediation demonstrates enormous potential for oil spill cleanups with the\nuse of microorganisms such as Fusobacteria species or biological agents to colonise\n\nand degrade hydrocarbons present in the oil, though its practical use is still re-\n\nstricted;\n\n\u2022 Controlled oil burning effectively reduces the amount of oil in the water in situ,\nat a low cost, however the viscous and dense residue may sink and extends air\n\npollution;\n\n\u2022 Solidifying the oil could be an option in oil spills. With the use of dry ice pellets\nand hydrophobic polymers the liquid oil is solidified into a floatable rubber-like\n\nmaterial, that can be more conveniently collected and recycled.\n\n\u2022 Vacuum and centrifuge the mixture of oil and water is another approach that\nobtains near pure oil as an end result. There is a debate either the resulting water\n\nshould be returned to the sea or not, improving the efficiency of the process, this\n\nis not entirely accepted due to the amount of oil present in the resulting water.\n\n16\n\n\n\nChapter 2 2.3. Oil Spill Mitigation strategies\n\nTechnologies that allow a safe, immediate, effective and eco-friendly operation of\n\noil spill removal, in situ, have been under development in the recent years. A specific\n\narea that grow from that development was the application of autonomous vehicles for\n\nocean exploration and conservation, with two important projects being developed in\n\n2010, Seaswarm[9] and Protei[10]. The autonomous vehicles designed within the scope\n\nof these projects, reduce the operational time and protect the health and safety of the\n\ncleaning crew by working as an organised fleet or \u201dswarm\u201d of vehicles, that rely on\n\nocean-skimming and oil removal techniques, this can be viewed as a limitation of both\n\napproaches since there is a considerable impact of oil in the mechanical parts.\n\nThis evolution on oil spill mitigation techniques has primarily occurred in the form of\n\nhardware development. The research on advanced software-based navigation algorithms\n\nstill lacks sufficient attention and support, however some cases are worth mentioning,\n\nlike the approach developed by Jin and Ray[6], that uses a multi-resolution navigation\n\nalgorithm that, seamlessly, integrates the concepts of local navigation and global navi-\n\ngation, based on the sensory information for oil spill cleaning in dynamic and uncertain\n\nenvironments, using autonomous vehicles as a single agent. The developed algorithm\n\nprovides a complete coverage of the search area for clean-up of the oil spills and does not\n\nsuffer from the problem of having \u201dlocal minima\u201d, which is commonly encountered in\n\npotential-field-based methods through adaptive decision making and online re-planning\n\nof vehicle paths.\n\n17\n\n\n\nThis page was intentionally left blank.\n\n\n\nChapter 3\n\nFundamentals\n\n3.1 Path planning techniques\n\nConsidering the requirement of the ASV being able to navigate on the stroke border\n\nareas of the oil spill, the path planning methods explored for this vehicle were focused on\n\nthe ability to have a cost function capable of cover all area but at the same time avoid, in\n\na robust manner, the oil spill. Therefore, one of the methods presented in this chapter is\n\nthe Potential Functions (or Potential Fields), applied in [44][45] and [46], where several\n\ngradient vector fields are created, attracting the vehicle towards the target or repelling\n\nit from the obstacles. The method generates repelling vectors once the vehicle is within\n\na range of a new obstacle, and the sum of all vectors provides the direction for the\n\nmovement of the vehicle. This method is computationally efficient although in some\n\nscenarios it has a limitation, the existence of a critical point called \u201dLocal Minima\u201d,\n\nwhere the vehicle can be attracted to it and will not be able to generate an escape safe\n\nposition. In [47], obstacle avoidance using potential fields is applied into a non-holonomic\n\nvehicle, with two independently driven wheels and is not capable of sideways movement,\n\nresulting in the attractive and repulsive forces being applied on the front and on the\n\nrear body of the vehicle, being the repulsive forces computed by the distance between\n\nobstacle points and the contour of the vehicle\u2019s body, those repulsive and attractive\n\nforces constitute the resultant force that determines the motion of the vehicle.\n\nAnother approach proposed by Lumelsky and Stepanov [48], is based on curvature\n\nestimation. This real-time path-planning algorithms rely on sensor-based exploration\n\n[49], the boundary curvature of the obstacles are followed by the vehicle until a condition\n\nis reached, through this boundary curve following, the vehicle is able to reach the target.\n\n19\n\n\n\n3.1. Path planning techniques Chapter 3\n\nSimilar approaches were presented in [50], [51] and [52]. Zhang and et.al[53] propose\n\na novel curvature-based steering control law able to produce the obstacle avoidance\n\nbehaviour for unicycle type robots travelling at a constant speed.\n\nTo obtain a efficient and complete coverage manoeuvre of the oil spill, Voronoi algo-\n\nrithms were studied to be applied into the UAV path planning algorithm. An interesting\n\napproach by Corte?s et al.[54] relies on Voronoi partition of the environment to control\n\nand coordinate a sensor coverage action between a group of autonomous vehicles, where\n\neach autonomous vehicle implements a control law designed based on the gradient de-\n\nscent method that minimises the coverage cost in space and time, leading to an optimal\n\npartitioning. The implementation of Abbasi et al.[55] also presents the control algo-\n\nrithm of an heterogeneous group of robots to achieve coverage over an area resorting\n\nto Voronoi diagrams, while ensuring an ideal allocation of robots to distinct regions of\n\ninterest. Similar Voronoi approaches were presented in [56] and [57].\n\nThe path planning algorithm for the UAV was also inspired on the approach by\n\nSchwager et al.[25] that presents a decentralised control strategy capable of achieving\n\narea coverage (environment monitoring), with the fields of view of multiple cameras on\n\ndistinct aerial platforms, resorting to a cost function that, unlike most approaches, does\n\nnot involve a Voronoi partition.\n\n3.1.1 Potential Fields\n\nThe Artificial Potential Field (APF) method was first proposed by Khatib [58] and\n\ncan be simply described as \u201dmagnetic fields\u201d, that are simulated for the goal position and\n\nfor any obstacle present in the scenario. The goal position attracts the the robot, while,\n\nsimultaneously, the robot is repelled from any obstacles in its path. In theory then, with\n\ncorrectly designed potential fields, the robot will follow the shortest trajectory to the\n\ngoal position while avoiding getting too close to an obstacle.\n\nThe overall potential field, at any moment, in the robot q, U(q), in the Equation 3.1,\n\ncan be described as a sum of the attraction force towards the goal Ugoal and the sum of\n\nevery repulsive force of obstacles in the vicinity\n?\nUobstacle.\n\nU(q) = Ugoal(q) +\n?\n\nUobstacle(q) (3.1)\n\nThe attractive force towards the goal, represented in the Figure 3.1, is given by\n\nthe Equation 3.2, where ?d(q,goal) represents the euclidean distance between the goal\n\nposition and the robot q.\n\n20\n\n\n\nChapter 3 3.1. Path planning techniques\n\nFigure 3.1: Representation of the attractive forces towards the goal.[1]\n\nUgoal(q) = ?d(q,goal)\n2 (3.2)\n\nThe potential barrier imposed by each individual obstacle, represented in the Figure\n\n3.2, is given by the Equation 3.3, where ?d(q,obstacle) represents the euclidean distance\n\nbetween a specific obstacle and the robot q. This potential barrier rises to infinity when\n\nthe robot approaches the obstacle.\n\nUobstacle(q) = ?d(q,obstacle)\n?1 (3.3)\n\nIf all the potential fields from the goal and from the obstacles are combined, it\u2019s\n\npossible to obtain the overall potential field represented in the Figure 3.3. From here is\n\npossible to compute the most favourable path for the robot to reach the goal position,\n\nFigure 3.4.\n\nThis approach presents, however a disadvantage, in certain scenarios, as in a \u201dU\u201d\n\nshaped obstacle in the vehicle path, represented in the Figure 3.5, if the vehicle is\n\nattracted to the \u201dinner\u201d area of the obstacle, it will never be able to get out of it and\n\nreach the goal position, this places are called \u201dLocal Minima\u201d.\n\n21\n\n\n\n3.1. Path planning techniques Chapter 3\n\nFigure 3.2: Representation of the repulsive forces imposed by each obstacle.\n\nFigure 3.3: Representation of the overall potential field.\n\n22\n\n\n\nChapter 3 3.1. Path planning techniques\n\nFigure 3.4: Representation of the most favourable trajectory for the vehicle to reach the\ngoal position.\n\nFigure 3.5: Representation of a scenario that contains a Local Minima.\n\n23\n\n\n\n3.1. Path planning techniques Chapter 3\n\n3.1.2 Probabilistic Roadmap\n\nProbabilistic Roadmap (PRM)[15][59] is a path planning algorithm that computes a\n\ncollision-free trajectory, from the starting configuration of the robot to a goal configu-\n\nration. It receives as inputs the initial and goal position for the robot and the position\n\nof every obstacle in the map. A defined maximum number of random samples are dis-\n\ntributed within the map, only in the space free of obstacles. To those samples is added\n\nalso the initial and target positions. From there, each sample tries to \u201dconnect itself\u201d to\n\na defined maximum number of closest neighbour samples, by straight segments that do\n\nnot escape the configuration space, creating the roadmap, if any sample is not connected\n\nin this roadmap, the number maximum of closest neighbours is increased until they\u2019re\n\nall connected.\n\nAfter the roadmap is built, the shortest way from the initial position to the goal\n\nposition, through the samples, is computed. For this demanding computational step\n\nseveral algorithms can be used, being the A* (A star) algorithm[60], first described\n\nDijkstra[17], the most frequent. This approach uses all the possible paths to the target,\n\nto determine which one has the smallest cost (smallest distance).\n\nThe number of random samples added to the configuration space of the robot in the\n\nbeginning, is directly linked to the resultant trajectory from the initial position to the\n\ngoal position, when the number of samples tends to infinite it\u2019s possible to obtain the\n\nshortest resulting trajectory. In the Figure 3.6 it\u2019s possible to see the difference in the\n\nresulting trajectory, within the same map in having increased the number of random\n\nsamples.\n\nPRM has been applied with excellent results to free flying and articulated robots\n\nmoving in the plane or in space, as well as to non-holonomic robots.\n\n2https://www.mathworks.com/help/robotics/ug/probabilistic-roadmaps-prm.html\n\n24\n\n\n\nChapter 3 3.1. Path planning techniques\n\nFigure 3.6: Comparison between the probabilistic roadmaps (in blue) and resulting\ntrajectories (in orange) in the same map with different number of random samples, 50\n(left) and 250 (right).2\n\n3.1.3 Voronoi\n\nVoronoi Diagrams are one of the most fundamental data structures in computational\n\ngeometry. In [61], [62] and [63] a better description of the algorithm, its application and\n\nimportance in a wide variety of fields inside and outside of outside computer science, are\n\npresented. Given a set P , of points, called sites in this specific algorithm to differentiate\n\nthem from arbitrary points, a Voronoi diagram is simply the subdivision of a space into\n\ncells, with one cell per each site p ? P.\n\nV or(p,P) = {x : |px| ? |qx|, ?q ? P} (3.4)\n\nA point q lies in the cell corresponding to a site pi ? P if:\n\nEuclidean Distance(q,pi)&lt;Euclidean distance(q,pj), for each pi ? P, j 6= i.\nIn the Figure 3.7, we can see the terms used to describe Voronoi diagrams.\n\nThe division between two cells, in a Voronoi diagram, is made by a line segment,\n\nof infinite length, unless other conditions are imposed. This line segment is Euclid\u2019s\n\ncompass and straight-edge construction of the perpendicular bisector, Figure 3.8.\n\nA point q lies on a Voronoi edge between sites pi and pj if the largest empty circle\n\ncentred at q touches only pi and pj \u2013 A Voronoi edge is a subset of locus of points\n\nequidistant from pi and pj.\n\n25\n\n\n\n3.1. Path planning techniques Chapter 3\n\nFigure 3.7: Terms used in Voronoi Diagrams.\n\nFigure 3.8: Perpendicular bisector representation.\n\n26\n\n\n\nChapter 3 3.1. Path planning techniques\n\nFigure 3.9: Circumcenter representation.\n\nFigure 3.10: Graphical representation of a Voronoi Diagram.\n\nMultiple collinear sites form a series of parallel lines while three non-collinear sites\n\nform Voronoi half lines that coincide in a Voronoi vertex. This vertex is the circumcenter\n\nof the triangle formed by the three sites, the only point that is at an equal distance from\n\nall vertices of the triangle, Figure 3.9.\n\nA point q is a vertex if the largest empty circle centred at q touches at least 3 sites\n\n\u2013 A Voronoi vertex is an intersection of 3 more segments, each equidistant from a pair\n\nof sites.\n\nIn the figure 3.10, it\u2019s presented an example of a Voronoi diagram, with a set of points\n\nP, and the cell division computed using Euclidean distances.\n\n27\n\n\n\n3.2. ROS - Robot Operating System Chapter 3\n\n3.2 ROS - Robot Operating System\n\nDeveloped in 2007 by the U.S. robot company Willow Garage, ROS[64] stands for\n\nRobot Operating System but, in fact, ROS is not a real operating system. It can be\n\ndescribed as a middleware since it stands between the aplication and the operating\n\nsystem on each individual machine it is capable of message-passing between processes,\n\nand package management with various ROS libraries open-source with implementations\n\nof common robotics functionality and algorithms, focused on maximising code reuse in\n\nthe robotics research and development. Several implementations are distributed as ROS\n\npackages with each ROS distribution or through code sharing sites such as GitHub3.\n\nThe representation of the processes of this middleware can be done in a graph ar-\n\nchitecture with several independent processes, called nodes, these nodes communicate\n\nbetween themselves through a publisher-subscriber mechanism sending data streams,\n\nknown as topics. This peer-to-peer communication is controlled by a master node, cre-\n\nated obligatorily using the roscore command when starting. The various existent nodes\n\ncould be running on the same or on a different machine, being responsible for subscribe,\n\nprocess and publish data, control actuators between other operations.\n\nTo clarify the publish/subscribe messaging mechanism, depicted in Figure 3.11 an\n\nexample of a possible communication is presented. In this example on the robot, the\n\nCamera Node takes care of the communication with the camera, another node on the\n\nrobot, the Image Processing Node processes the image data and a Image Display Node,\n\non a external laptop, displays images on a screen. To start every nodes registers itself\n\nwith the ROS Master. In registering with the ROS Master, the Camera Node states\n\nthat it will publish a topic called \u201d/image data\u201d. Both of the other nodes register that\n\nthey wish to subscribe to the topic \u201d/image data\u201d thus, once the Camera Node receives\n\nsome data from the Camera, it sends the topic directly to the other two nodes. It is also\n\npossible for a node to request a message at a specific time, registering a service with the\n\nROS Master.\n\nIt\u2019s possible to integrate ROS with real-time code to mitigate the flaw in this mid-\n\ndleware of not being an real-time system. This capability is of major importance in a\n\nlarge number of applications were low latency in robot control is a critical aspect.\n\nROS provides a platform to develop a distributed and highly independent modular\n\nsystem to control a robot. The constituent modules i.e. nodes have limited knowledge\n\nof other nodes in system and communicate over TCP (or UDP) via standard messages\n\ni.e. topics. This is a great strength and enables rapid and clean development and high\n\n3www.github.com\n\n28\n\n\n\nChapter 3 3.2. ROS - Robot Operating System\n\nFigure 3.11: Example of the publish/subscribe messaging model.[2]\n\nreusability. This does come, however, with a performance drawback as communication\n\nmust be done over network infrastructure which can slow down things considerably\n\nespecially if the message consists of huge sized data like video streams or lidar scan, to\n\novercome this efficiency issue and still provide the same benefits of standardised message\n\npassing infrastructure, ROS presents the concept of nodelets. Nodelets can use the same\n\ninterface of subscribing and publishing to topics, however, when a nodelet subscribes or\n\npublishes to a topic in the same nodelet manager, instead of message being passed over\n\nTCP/IP, only a C++ boost pointer to message is passed.\n\nThe software is open-source and free for both commercial and research use. Its open-\n\nsource packages vary from hardware drivers, robot models, data-types, planning, per-\n\nception, simultaneous localisation and mapping, simulation tools, and other algorithms\n\nthat can be built with different programming languages like C++, Python, Octave and\n\nLISP.\n\nAs shown in Figure 3.12, ROS consists of a client library to support various program-\n\nming languages, a hardware interface for hardware control, communication for data\n\ntransmission and reception, the Robotics Application Framework to help create various\n\nRobotics Applications, the Robotics Application which is a service application based on\n\nthe Robotics Application Framework, Simulation tools which can control the robot in a\n\nvirtual space, and Software Development Tools.\n\n29\n\n\n\n3.3. Robotic Simulators Chapter 3\n\nFigure 3.12: ROS components[3]\n\n3.3 Robotic Simulators\n\nExperiments with unmanned vehicles are complex, costly, time-consuming and in\n\nsome circumstances potentially dangerous, involving the risk of losing or damaging the\n\nrobots, so in most cases, the most promising course of action is the simulation of the\n\nsituation. Simulators are useful tools for the development of unmanned vehicle software,\n\nalgorithm benchmarking and system preliminary validation, that may later, improve the\n\nperformance of the robots, in real life experiments.\n\nMany simulation tools[65][66][67][68][69] have been used and specifically developed\n\nfor robotics development purposes. The inclusion of proper dynamics, visual realism,\n\nwide variety of sensors, interfaces, modelling tools and real-time sensor-based control are\n\nmajor factors in a simulator.\n\nFrom 2D low fidelity simulators such as Player/Stage[70] to 3D dynamic simulators\n\nsuch Gazebo[69], MORSE[65], USARSim[71], UWSim[72] or V-REP[73], these systems\n\nallow for simulation of mobile robots and their interactions with the environments. Some\n\nsimulators, such as Gazebo for instance, have hardware in loop capabilities allowing for\n\nmultiple stages of subsystem validation with real hardware.\n\nMarine robotics[74][75][76][77], focused simulators have been developed either for\n\nspecific simulation scenario requirements or as more or less generic tools under multiple\n\nEuropean research projects such as Co3-AUVs[78], RAUVI[79] or TRIDENT[80] with\n\n30\n\n\n\nChapter 3 3.3. Robotic Simulators\n\nUWSim[72].\n\nNowadays, numerous simulators are available in the market, this research will be fo-\n\ncused on simulators compatible with ROS such as Gazebo, UWSim and MORSE. Apart\n\nfrom the ROS compatibility, the software\u2019s are built on modern rendering and physics en-\n\ngines and have large support communities. All of the listed simulators are open source.\n\nAs described previously, ROS is a distributed system where different nodes can run\n\non different computers and mainly communicate through \u201dtopics\u201d, via publishing/sub-\n\nscribing mechanisms. For instance, the ROS interface of UWSim, allows running the\n\nsimulator as another ROS node that can communicate with the rest of the architecture\n\nwith the standard ROS communication facilities.\n\nRobotics simulations have been presented in many projects and conferences, some of\n\nthe most relevant are DARPA Robotics Challenge (DRC), ICRA, RoboCup and more\n\nrecently in Space Robotics Challenge (SRC), a NASA Centennial Challenge. Earlier\n\nin 2007, during the International Conference on Robotics and Automation (ICRA\u201907)\n\nRobin Murphy, presented a survey[66], were the state of the art on robotic simulators,\n\na subject under an early development, was analysed. In that survey a set of available\n\nand open source simulators capable of handling a wide spectrum of vehicles, such as\n\nunmanned terrestrial, aerial, surface and subsurface vehicles, were explored under the\n\nmost diverse scenarios and situations such as urban search and rescue, bomb disposal,\n\nsurveillance and military purposes. This study ended up with the conclusion that there\n\nwas no need to build a robotic simulator from the ground since there was already avail-\n\nable, in the market, multiple solutions with reasonable physical and functional fidelity.\n\nNowadays, robotic simulation has evolved and numerous simulators are available in the\n\nmarket, this softwares are built upon modern rendering and physics engines and have\n\nlarge support communities. In 2014, Cook, Vardy and Lewis et al. [81] reviewed and\n\ncompared multiple robot simulators for multi-vehicle operations.\n\nIn order to obtain a better comparison between them, different criteria were defined:\n\n\u2022 Physical Fidelity: As the name suggests, this field allow a deeper comparison\nbetween the softwares, on their physical fidelity, being this, the capability for a\n\ncorrect interaction between the robot and the environment/objects, between the\n\nrobot and its arms/actuators or between those actuators and the environment/ob-\n\njects. Simple actions such as pushing, picking or grasping objects involve a complex\n\ncalculation of simulated forces and collisions.\n\n\u2022 Sensor Modelling: This criteria defines the capability of the software in the\nprecise simulation of multiple sensors.\n\n31\n\n\n\n3.3. Robotic Simulators Chapter 3\n\n\u2022 Required Knowledge/Experience: The amount of knowledge/experience re-\nquired to work with the simulator software in a proficient way.\n\n\u2022 Visual Fidelity: Quantifies the fidelity of the visualisation on the simulator,\nwhere details such as water reflection, water refraction, sediments flotation, waves\n\nmovement and clouds representation are taken into account.\n\nThis and other criteria are summarised in Table 3.1.\n\nTable 3.1: Simulator Comparison\nSimulator Gazebo UWSim MORSE\n\n3D Rendering Engine ogre3D OSG Blender\n\nPhysics Engine ODE/Bullet/Simbody/DART Bullet Bullet\n\nProgramming Language C++ C++ Python\n\nMiddleware\n\nSupport\nROS/Player/Sockets ROS\n\nROS/YARP/Pocolibs/\n\nMOOS/Sockets\n\nOperating System Linux/MacOS X/Windows Linux Linux/MacOS X\n\nFormats Support SDF/URDF URDF URDF\n\nOpen Source Yes Yes Yes\n\nAdequate Documentation High Low Medium\n\nPhysical Fidelity High Medium Medium\n\nSensor Modelling High High Medium\n\nRequired Knowledge Medium Medium High\n\nVisual Fidelity Medium High High\n\n3.3.1 UWSim\n\nIn order to have a simulator for marine robotics research and development, UWSim[72][82]\n\nwas developed in the scope of the RAUVI and TRIDENT research projects. UWSim is\n\ncurrently used in different ongoing projects funded by European Commission (MORPH\n\n[83] and PANDORA [84]) in order to perform hardware in the loop experiments and to\n\nreproduce real missions from the captured logs. UWSim is not only useful for software\n\nvalidation, but also for benchmarking mechanisms inside the simulator, so that control\n\nand vision algorithms can be easily compared in common scenarios.\n\nThis underwater and surface robotic simulator renders realistic images through Open-\n\nSceneGraph (OSG)4 rendering engine, Bullet5 physics engine and osgOcean6 plugin.\n\nOSG is an open source 3D graphics application, while the plugin osgOcean was devel-\n\noped to enhance the reality of the underwater simulation in OSG, it adds visual improve-\n\n4http://trac.openscenegraph.org/\n5http://bulletphysics.org/\n6https://github.com/kbale/osgocean/\n\n32\n\n\n\nChapter 3 3.3. Robotic Simulators\n\nments such as waves, water coloration, reflection/refraction, flotation of sediments, etc.\n\nThe toolkit is written in standard C++ using OpenGL7 and runs on various operating\n\nsystems including Microsoft Windows, Mac OS X, Linux, IRIX, Solaris, FreeBSD and re-\n\ncently also Android. The Bullet physics engine adds the physical reliability, by detecting\n\nany kind of collisions or even with physical interactions between multiple robots/objects\n\nsuch as push or grab.\n\nThe physics engine is used only to handle contact forces and the implementation\n\nof the vehicle dynamics, including the simulation of thrust forces. It is located in one\n\nmonolithic ROS node, but it could be modified to adhere to a more modular structure.\n\nUWSim possess also an interface to communicate with external software such as Matlab,\n\nusing ROS nodes.\n\nA vehicle in UWSim is composed of a 3D model, created by user, that can be posi-\n\ntioned in the scene by setting 6 degrees of freedom. Support for kinematic chains are\n\nincluded. The robots are described with an XML file, according to the URDF format,\n\nthat can include kinematic, dynamic and visual information. Interfacing with Matlab is\n\nalso possible, through the ipc bridge ROS package.\n\nThe model can be complemented with other dynamic models like those corresponding\n\nto the marine environment (hydro-dynamics, waves, wind, underwater currents, etc.),\n\nto the actuators (thrusters and control surfaces as rudders or fins), and to the sensors\n\n(sonar, DVL, etc.).\n\nUWSim allows the dynamic simulation of rigid body motion, by using a state-space\n\ndynamic model in terms of state variables representing body linear and angular velocities\n\nand positions. It takes as inputs the forces and torques that act on the body and\n\ntheir current state vector value. The output is a future estimation of the state vector.\n\nCustomizable widgets can be added to the main window that show specific data to the\n\nuser. The data acquired during a survey mission, with a real robot, can be logged and\n\nthen reproduced in UWSim in order to analyse the vehicle trajectory. Vehicle dynamics\n\ncan also be simulated with Matlab.\n\nIn this simulator it is also possible to visualise different underwater virtual scenarios\n\nthat can be configured using standard 3D modelling software (ex: Blender8, 3D Stu-\n\ndio Max, etc). Controllable underwater vehicles, as well as simulated sensors can be\n\nadded to the scene and accessed externally through network interfaces. This allows to\n\neasily integrate the visualisation tool with existing control architectures. The scenes in\n\nUWSim are XML-formatted documents that describes the general scenario, and simula-\n\n7https://www.opengl.org/\n8https://www.blender.org/\n\n33\n\n\n\n3.3. Robotic Simulators Chapter 3\n\ntion parameters. On the other and, robots are described with an URDF (Unified Robotic\n\nDescription File) file. However, a scene XML file may make a reference to an URDF file\n\nfor including a robot into the scene. The UWSim scene XML file is divided in blocks,\n\nwhich define the different aspects of the scene. The available blocks are the oceanState\n\nblock that allows configuring ocean parameters, simParams block, that makes possible\n\nto modify the settings of the simulator, the camera block for set the main camera pa-\n\nrameters, the vehicle tag that is used to create and configure underwater robots and\n\nthe sensors available on them, the object block that allows inclusion of other 3D models\n\nto interact with the robots and the ROS interfaces block that allows the attachment\n\nof ROS interfaces to certain objects, robots or sensors, specifying the communication\n\npossibilities. The supported 3D models formats are all that are supported by OSG, like\n\n.osg, .obj, .ive, .stl, .3ds and others. So, it is possible to use a 3D modelling program\n\nsuch as Blender to simply export the 3D model with one of the formats above.\n\nAll the different robots sensors and actuators can be interfaced with external software\n\nthrough the network. UWSim includes an interface for its integration with ROS, that is\n\na set of libraries and tools that assist software developers create robotic applications.\n\nThis allows to seamlessly validate control methods developed in ROS either on\n\nUWSim or on the real robots, as long as they provide the same interface. Through\n\nthe ROS interfaces, it is possible to access/update any vehicle position or velocity, to\n\nmove arm joints, and to access the data generated by virtual sensors. This provides to\n\nthe software the capability to detect collisions and forces and automatically updating\n\nthe scene accordingly. The different bodies collision shapes can be automatically gener-\n\nated from the 3D models. In addition, it is possible to set the position and attitude of\n\ncollision shapes automatically from the scene graph, which is necessary, for instance, for\n\nupdating the collision shapes transforms of kinematic chains like manipulators.\n\nThe output variables (position and attitude of vehicles) are published on the ROS\n\nnetwork and captured by the UWSim core for updating the visualisation.\n\nIt is also possible to use UWSim for mission playback. For instance, the navigation\n\ndata acquired during a survey mission with a real robot can be logged and then repro-\n\nduced in UWSim in order to analyse the vehicle trajectory. If bathymetry and images\n\nof the seafloor are gathered during the survey, it would be possible to build a textured\n\nterrain from them and visualise it in UWSim.\n\nThere are twelve sensors available for vehicles in the current version of UWSim such\n\nas camera, range sensor, pressure sensor, DVL, IMU, Global Positioning System (GPS),\n\nMultibeam, force sensor and structured light projector.\n\nUWSim is not a difficult software to work with, though it requires some level of\n\n34\n\n\n\nChapter 3 3.3. Robotic Simulators\n\nprevious experience using ROS. The UWSim wiki page contains articles on installing\n\nthe software and on the configuration and creation of simulation scenes.\n\nThe major drawbacks in UWSim are that is only a kinematic simulator and even with\n\nits external dynamic module coded in Matlab it is only capable of handling single-body\n\nvehicles, excluding most of the situations, where a AUV carry a robotic arm and the\n\naspect that there is no convenient way of extending the software, any modifications, e.\n\ng. adding a new type of sensor must be written in the core source code.\n\n3.3.2 Gazebo\n\nOne of the most used softwares, is Gazebo, a primary tool used by ROS for simula-\n\ntions, which is very common among robotics professionals and academics. It was built\n\nwith ROS compatibility since the beginning, and is easy to work with, however, it is also\n\npossible the use of another middleware wrapper for Gazebo, such as YARP plugin (Yet\n\nAnother Robot Platform)[85]. This simulator uses Bullet for physics simulation.\n\nGazebo features high fidelity models and a enormous user base, a recent example of\n\nuse is shown in [86]. Gazebo supports plugins, allowing users to embed custom C++\n\ncode into simulations. Communication method used by Gazebo, are topics that export\n\nsimulated data to third party applications. Gazebo topics are flexible but, there is no\n\ndata transfer control.\n\nThis simulation software uses the Ogre3D9 rendering engine and, in opposition to\n\nUWSim, supports multiple physics engines, being the first to support four different\n\nphysics engines such as ODE10, Bullet, Simbody11 and DART12, being its default physics\n\nengine ODE. Having this in mind, its clear that, the physical fidelity of this simulator\n\nwill be dependent on the physics engine chosen for the compilation. The simulation\n\nsystem is also able to simulate multi-robot collaboration.\n\nGazebo overcomes the drawbacks of UWSim, since it handles better the dynamics,\n\ncontact physics and is very versatile through its plugin-based design.\n\nAs UWSim is only a kinematic simulator, the URDF used to describe the robots\n\nare usually simpler that the Gazebo ones, that contains all the inertial and collision-\n\nrelated data. On the opposite, the scene file, used to describe the whole world setup in\n\nUWSim, contains all information about the considered simulation while the same data\n\nis separated in several files when using Gazebo. The considered modelling is focused\n\n9http://www.ogre3d.org/\n10http://www.ode.org/\n11https://github.com/simbody/simbody/\n12https://dartsim.github.io/\n\n35\n\n\n\n3.3. Robotic Simulators Chapter 3\n\non the main effects due to hydrodynamic forces, that are drag and buoyancy that are\n\nalready available through plugins. A possible improvement is to take into account the\n\nadded inertia and Coriolis, but these effects are even harder to quantify precisely.\n\nGazebo uses Simulation Description Format (SDF) and Universal Robot Description\n\nFormat (URDF), to describe the simulation, the robot and its sensors, this data can\n\nbe used in any other software that supports this format. A robot model in SDF is\n\nmainly a set of links and joints. The links represent the rigid parts of the robot, and the\n\njoints represent connections between two links and therefore define the kinematic and\n\ndynamic properties of the robot. In a world file, the simulation world is described, which\n\nare lighting, simulation step size, simulation frequency and other simulation properties.\n\nRobot, sensor or world models are described in their respective SDF file, an XML format\n\ndesigned for Gazebo. The URDF file format used by ROS is automatically converted to\n\nSDF format when used by Gazebo. Visual geometries used by the rendering engine are\n\nprovided in COLLADA format and the collision geometries in .stl format. In Gazebo 8,\n\n.obj format was added as alternative input option for COLLADA (.dae format).\n\nGazebo\u2019s rendering system is not optimised for underwater scenario, where underwa-\n\nter characteristics are not taken into account. However, Gazebo simulator gives the user\n\nthe possibility to extend the simulation with plugins. It can be extended for new dynam-\n\nics, rendering, sensors and world models. Graphical user interface is included to visualise\n\nthe scenario with extended capabilities. Regarding future work within this project, one\n\nof the most noticeable features missing in this underwater robotics simulator for the\n\nGazebo environment is the lack of characteristic visual effects as floating particles and\n\nproper light damping as a function of water depth, along with the generation of waves\n\non the sea surface.\n\nAs a drawback, Gazebo\u2019s rendering system has a far worse performance, where un-\n\nderwater characteristics such as water colour, visibility and floating particles are not\n\nrepresented. Since Gazebo 6, the software already includes a hydrodynamics package\n\nwhere the buoyancy and drag forces is already taken into account.\n\nIn 2014[74], Olivier Kermorgant developed freefloating gazebo13, a plug-in for the\n\nintegration between Gazebo and UWSim, achieving a realistic simulation, where the\n\ndynamics from Gazebo and the appropriate visualisation from UWSim are combined.\n\nIn 2016, within the scope of the SWARMs project, a open-source package for Gazebo\n\nsimulator was created, named UUV (Unmanned Underwater Vehicle) simulator[77] for\n\nunderwater intervention and multi-robot simulation where a realistic ocean environment\n\nrepresentation was achieved.\n\n13https://github.com/freefloating-gazebo/freefloating gazebo/\n\n36\n\n\n\nChapter 3 3.3. Robotic Simulators\n\nAnother example of the integration between Gazebo and other softwares, is mentioned\n\nin [87]. This work consists in the integration between Rock-Gazebo, which provides a\n\nsolution to simulate ROCK (Robot Construction Kit)14 based systems in Gazebo. This\n\nsolution synchronises framework components in the simulation. All components states\n\nare updated within the simulation step, thus synchronising the simulation. The syn-\n\nchronisation is important to define robots states and control the data transfer. It also\n\nincludes Vizkit3d15 visualisation plugins that make the simulator more flexible, allowing\n\nthe user to include features, such as, an underwater environment or even a spatial envi-\n\nronment.The underwater environment was released in the simulation-gazebo underwater\n\npackage. This package is parsed by a Gazebo world file and reads the simulation param-\n\neters like the model centre of buoyancy, water level, fluid density and drag coefficient.\n\nVarious sensors are already available in Gazebo such as camera, multi-camera (stereo),\n\nlaser scanner, IMU, GPS, sonar, etc. There is also a provided application programming\n\ninterface, for the creation of new sensors as plugins for Gazebo.\n\nFor an inexperienced user, Gazebo can be fairly easy understood and used, with the\n\nhelp of the large number of tutorials available in Gazebo\u2019s web-page and with a big\n\ncommunity, though it also requires some previous experience with ROS for a deeper\n\nunderstanding. Gazebo has a regularly updated and well-defined road-map for new\n\nreleases. The integration with ROS, also developed by OSRF16, is already guaranteed\n\nthrough Gazebo/ROS packages. Contributions from the Gazebo user community allow\n\nit to be regularly improved with new features.\n\n3.3.3 MORSE\n\nMORSE[88] uses Blender Game Engine and the Bullet physics engine. Physical fi-\n\ndelity is completely dependent of the fidelity provided by the Bullet engine. Attached\n\ncomponents such as arms and grippers, can interact with the world up until some de-\n\ngree, fine grasping of objects is generally not possible. MORSE can be entirely controlled\n\nfrom the command-line. Two configuration are provided by MORSE for time handling:\n\nbest effort, that tries to keep a real-time simulation and fixed step that ensures accu-\n\nracy of simulation. Multiple middlewares are compatible with MORSE, including ROS,\n\nYARP, Pocolibs17, Mavlink18 and MOOS19. In addition to those, MORSE also supports\n\n14http://rock-robotics.org/\n15http://rock-robotics.org/stable/documentation/graphical user interface/450 vizkit3d.html/\n16https://www.openrobotics.org/\n17https://github.com/openrobots/pocolibs/\n18http://qgroundcontrol.org/mavlink/\n19http://oceanai.mit.edu/moos-ivp/pmwiki/pmwiki.php/\n\n37\n\n\n\n3.3. Robotic Simulators Chapter 3\n\na socket-based protocol that allows the integration of unsupported middlewares or tools.\n\nThe most stable and extensible method of communicating data between the MORSE\n\nsimulator and an external process, is with the use of ROS.\n\nLike UWSim and Gazebo, MORSE already includes multiple sensors including ac-\n\ncelerometer, battery sensor, contact sensor, depth camera, GPS, odometry sensor, laser\n\nscanner, etc. It\u2019s also provided a convenient facility for the creation of nonexistent\n\nsensors and actuators.\n\nMORSE provides multiple tutorials divided by levels of proficiency, making the gen-\n\neral use of the simulator by inexperienced users easier. The programmer can choose to\n\neither use Blender\u2019s internal integration engine for basic physics models, such as the dif-\n\nferential drive robot, or the programmer can integrate complex models with the use of an\n\nexternal C++ program. One additional property of MORSE are modifiers. Those can\n\nmodify data produced by sonar (\u201dperfect data\u201d), by adding additional noise functions,\n\nsimilarly to the Gazebo and UWSim simulators.\n\nMORSE is designed to allow simulations of multiple robots systems. The biggest\n\nadvantage of using Blender is the high customisation and the high level of graphical\n\ndetail that can be achieved, thanks to the advanced modelling of meshes, and effects such\n\nas texturing, lighting and shades. Blender also offers the capability of using multiple\n\ncamera views, displaying a global view of the scenario, as well as views from each of the\n\ncameras on\u2013board the various robots. MORSE component consists of a Python and a\n\nBlender file. The Python file defines an object class for the component type, with its\n\nstate variables, data and logical behaviour. The Blender file specifies the visual and\n\nphysical properties of the object in the simulated world. Sensors and actuators have a\n\nreference to the robot they are attached to, and the relative position/orientation with\n\nrespect to it.\n\nMORSE have many advantages like high detail world, ability to create new sensor\n\nand cameras view, but at the same time, presents the drawback of having to understand\n\nits interface, as well as the additional computational overhead.\n\n38\n\n\n\nChapter 4\n\nConceptual approach\n\nThis chapter will describe the conceptual approach formalised in this dissertation,\n\nstarting with a brief description of the proposed architecture, followed by a detailed\n\nexplanation on the UAV and ASV trajectory computation proposed methods.\n\n4.1 Proposed Architecture\n\nFigure 4.1: Proposed Architecture for Oil Spill Mitigation.\n\n39\n\n\n\n4.1. Proposed Architecture Chapter 4\n\nIn this section the oil spill mitigation proposed architecture, for a cooperative action\n\nbetween the ASV and the UAV, is described. The figure 4.1 depicts the data flow\n\nbetween both vehicles through a middleware, a middleware is used to allow the increase\n\nof the number of vehicles used in the manoeuvre. The oil spill is either detected through\n\na monocular camera on the UAV or through a simulation of that camera within the\n\nGazebo simulator scenario. The frame containing the oil spill is processed to extract the\n\ncoordinates of the points that form the oil contour, this contour points image coordinates\n\nare then transformed into real-world coordinates, W CT , and sent through the middleware\n\nto the ASV. The aerial vehicle is also responsible for using those contour points positions,\n\nthat describe the oil spill, to plan its oil spill mitigation waypoints position in the world\n\nreferential, depicted in the Figure as W ?UAV .\n\nThe ASV subscribes to the contour points world coordinates, W CT , and uses the\n\ndeveloped control-law path planning algorithm, to plan its oil mitigation waypoints,\nW ?ASV . Furthermore, both vehicles share their positions,\n\nW PASV and\nW PUAV , through\n\nthe middleware, to plan efficiently the cooperative manoeuvre.\n\nIn order to evaluate the performance of the control-law algorithms, a simulation en-\n\nvironment was developed in Gazebo under the framework ROS. This approach provides\n\na straightforward integration between the simulation environment and the real robots.\n\nConsidering the careful analysis of simulators presented in section 3.3, the decision\n\nfor the Oil Spill Simulator fell in the Gazebo Simulator due to its better performance\n\nin sensor modelling and physical fidelity. This simulator granted the author the capa-\n\nbility to recreate a environment with high visual and physical fidelity, with behaviours\n\nas buoyancy or drag and with a vast number of already developed sensors. Different\n\nperspectives of this simulation environment are depicted in the Figures 5.6, 5.7 and 5.8.\n\n40\n\n\n\nChapter 4 4.2. UAV\u2019s trajectory computation\n\n4.2 UAV\u2019s trajectory computation\n\nTo compute the UAV trajectory, in a efficient manner, is necessary to know in advance\n\nthe optimal manoeuvre height for the UAV, represented in the Figure 4.2 as the distance\n\nbetween the spreader nozzle and the surface, and the angle of dispersion of the powder\n\nspreader nozzle.\n\nFigure 4.2: Angle of dispersion of the powder spreader nozzle.1\n\nAssuming that the dispersion of the nozzle forms the cone depicted in Figure 4.3\n\nand to simplify the algorithm computation, its action area on the water surface can be\n\nroughly estimated as the largest square to fit in the base of said cone, represented in blue\n\nin the Figure. The length of said square, L, can be obtained if the manoeuvre height for\n\nthe UAV, H, and the angle of dispersion of the powder spreader nozzle, ? are known.\n\nFirst, the diagonal of the cone base, D, is computed using the equation 4.1. The next\n\nstep is to use the equation 4.2, to obtain the length of the action square.\n\nD = 2 ? (H ? tan ?) (4.1)\n\nD2 = L2 + L2 ? L =\n?\n\n(D2)/2 (4.2)\n\nAfter the determination of the dimensions of the action area, is possible to start\n\nthe computation of the UAV\u2019s trajectory. This trajectory should ensure a complete\n\n1https://www.lorric.com/en/WhyLORRIC/Nozzle/Cone-spray-coverage-by-distance\n\n41\n\n\n\n4.2. UAV\u2019s trajectory computation Chapter 4\n\nFigure 4.3: Coverage area of the powder spreader nozzle.\n\ncoverage of the surface of the spill, for a distribution of the lyophilized powder over its\n\nentire surface.\n\nTo achieve the trajectory depicted in red in the Figure 5.14, the UAV path planning\n\nalgorithm starts by dividing the points that define the spill into several horizontal layers,\n\nrepresented in the same figure in green, with the corresponding width from the action\n\narea square, at the previously determined flight altitude.\n\nThe computed UAV\u2019s waypoints, represented in the Figure 4.4, correspond to the\n\nminimum and maximum contour points, along the X axis on each horizontal layer. These\n\nwaypoints, depicted as red asterisks, when reached in the correct order and maintaining\n\nthe flight altitude between them, ensure complete coverage of the oil spill area with\n\nminimal overlap and consequently, minimal waste of resources.\n\n42\n\n\n\nChapter 4 4.2. UAV\u2019s trajectory computation\n\nFigure 4.4: Waypoints computation through the minimum and maximum contour points\nalong the X axis on each horizontal layer.\n\n43\n\n\n\n4.3. ASV\u2019s trajectory computation Chapter 4\n\n4.3 ASV\u2019s trajectory computation\n\nThe computation of the trajectory for the ASV, is obtained through potential fields\n\napplied to the surface vehicle. This non-holonomic vehicle is incapable of sideways\n\nmovement since it only has two independently driven thrusters, resulting in distinct\n\nattractive and repulsive forces, Ugoal(q) and Uobstacle(q), respectively, being applied on\n\nthe front and on the rear body of the vehicle, being the repulsive forces, represented in\n\nFigure 4.5, computed by the distance between obstacle points and the contour of the\n\nvehicle\u2019s body, those repulsive and attractive forces constitute the resultant force, U(q),\n\nrepresented in Figure 4.6, that determines the motion of the vehicle.\n\nFigure 4.5: Repulsive forces applied to the ASV for oil spill avoidance.\n\nFigure 4.6: Resultant force from repulsive and attractive forces.\n\n44\n\n\n\nChapter 4 4.3. ASV\u2019s trajectory computation\n\nFor the scenario described on this dissertation, the used algorithm can\u2019t be the stan-\n\ndard Potential Fields algorithm, since there is no real goal defined and the objective\n\nis not simply to avoid getting to close to obstacles, but to follow the contour bound-\n\naries of an obstacle, the oil spill, while maintaining a safety distance from it. From the\n\nstandard Potential Field approach two new algorithms were created to better suit the\n\nneeds of this scenario, in addition to those, a third algorithm based on a new curvature-\n\nbased approach, formulated in this dissertation and denominated \u201dNormal Vectors\u201d, this\n\napproach computes a new and enlarged contour.\n\n4.3.1 Method I: Artificial Potential Fields with 8 interchangeable goals\n\nTo obtain the obstacle contour behaviour, for each individual contour detected, 8\n\ninterchangeable goals were created on the extremes of the contour. One at a time, each\n\nof these goals attract the robot, in a successive clockwise way, granting the vehicle a\n\nalmost circular motion centred in the centroid of the oil spill (obstacle). Apart from the\n\nattractive force exerted by a predetermined goal at any moment, Ugoal(q), the sum of\n\nthe repulsive forces exerted by each of the near contours of the oil spill,\n?\nUobstacle(q), is\n\nstill exerted over the robot. This algorithm follows the standard potential field equation,\n\npresented in the equation 4.3, to compute the resulting force at any moment, U(q).\n\nU(q) = Ugoal(q) +\n?\n\nUobstacle(q) (4.3)\n\nThis algorithm, will move the robot towards the next goal, avoiding to get to close to\n\nthe obstacle boundary, granting it then, in theory, a contour trajectory distanced from\n\nthe obstacle\u2019s boundaries. This distance can be increased if the ratio between attractive\n\nand repulsive forces is increased and vice versa.\n\n4.3.2 Method II: Artificial Potential Fields with an extra Tangential\n\nForce\n\nThe second approach is also an adaptation of the Potential Fields algorithm, this\n\ntime the robot is simultaneously attracted to the goal, positioned in the centre of the\n\nobstacle and repelled by each point in its contour. This set of forces keep the robot at\n\na determined distance from the obstacle\u2019s boundaries. This distance can be adjusted by\n\nbalancing the ratio of attracting and repulsive forces.\n\nNow to grant a contour motion to the robot, a third force is applied to it, the resultant\n\nforce from a new Tangential Field, described in [89] and depicted in Figure 4.7. This\n\n45\n\n\n\n4.3. ASV\u2019s trajectory computation Chapter 4\n\nFigure 4.7: Representation of the behaviour of the orientation component of the Tan-\ngential Force.\n\nclockwise circular motion, by itself, forces the robot to move in a circular motion, with\n\nthe motion centre aligned with the oil spill centre. Now, instead of simply following\n\nthe equation 4.3, a Tangential force, Utangential is combined with the attractive and\n\nthe repulsive forces, as represented in the equation 4.4, moving the robot on a contour\n\ntrajectory, distanced from the obstacle\u2019s boundaries.\n\nU(q) = Ugoal(q) +\n?\n\nUobstacle(q) + Utangential(q) (4.4)\n\nWhile Utangential represents a constant force during the entire path planning, that can\n\nbe adjusted to surpass the \u201dlocal minimas \u201d on each scenario, its orientation component,\n\n?, varies during the manoeuvre depending on the ASV position relatively to the obstacle\n\ncentroid, as depicted in Figure 4.7. That orientation can be obtained with the equation\n\n4.5, where PWASV x and P\nW\nASV y represent the position of the ASV and P\n\nW\nobstacle x and\n\nPWobstacle y represent the position of the obstacle (oil spill) centroid.\n\n? = arctan2(PWASV y ?P\nW\nobstacle y,P\n\nW\nASV x?P\n\nW\nobstacle x) ??/2 (4.5)\n\n4.3.3 Method III: Control Points through Normal Vectors with Arti-\n\nficial Potential Fields\n\nThis algorithm computes a new enlarged contour, resorting to normal vectors at\n\npoints from the original contour. After obtained the new control points from the enlarged\n\ncontour, they are put through a standard potential field algorithm as goals, following\n\nthe equation 4.3 to compute the resulting force. The algorithm moves the surface vehicle\n\nthrough all of the points, while avoiding getting too close to the original contour.\n\nThe control points previously described are computed using a method that resorts\n\nto Normal Vectors. This method uses three successive oil spill contour points at a\n\n46\n\n\n\nChapter 4 4.3. ASV\u2019s trajectory computation\n\ntime (N ? 1, N and N + 1) to form a new set of points, distanced from the original\ncontour points, that describe a new, enlarged contour. This newly generated list of\n\npoints represents then, the intended ASV trajectory.\n\nThe algorithm starts by taking three consecutive points from the contour, N-1(xN?1,\n\nyN?1), N(xN , yN ) and N+1(xN+1, yN+1) and computing the Euclidean distance d(N ?\n1,N + 1) between N-1 and N+1, equation 4.6.\n\nd(N ? 1,N + 1) =\n?\n\n(xN?1 ?xN+1)2 + (yN?1 ?yN+1)2 (4.6)\n\nThe variables Dx and Dy are obtained by simply taking the positions differences in\n\nx and y, respectively, and divide them by the Euclidean distance calculated previously,\n\nas represented in equations 4.7 and 4.8.\n\nDx =\n(xN?1 ?xN+1)\nd(N ? 1,N + 1)\n\n(4.7)\n\nDy =\n(yN?1 ?yN+1)\nd(N ? 1,N + 1)\n\n(4.8)\n\nNow, with Dx and Dy computed, is relatively easy to obtain a new point (x,y),\n\ndistanced ? from N(xN , yN ), as represented in equations 4.9 and 4.10.\n\nx = xN + ??Dy (4.9)\n\ny = yN ???Dx (4.10)\n\nBy repeating this procedure through every successive combination of three points in\n\nthe contour (N ? 1, N and N + 1), a new set of points is obtained, distanced from the\noriginal contour points, that describe a new, enlarged contour, representing then, the\n\nintended ASV trajectory.\n\nThese equations describe the simple procedure of taking three consecutive points from\n\nthe original contour, N ?1, N and N + 1, grey points at the figure 4.8, compute the line\nsegment that passes through N ? 1 and N + 1, represented in black. Next, the normal\nvector to that line segment at N is obtained, represented in red in the figure. The last\n\nstep is the computation of a new point, represented in green, on that normal, distanced\n\n? from the original point N.\n\n47\n\n\n\n4.3. ASV\u2019s trajectory computation Chapter 4\n\nFigure 4.8: New point based on three consecutive contour points.\n\n48\n\n\n\nChapter 5\n\nImplementation\n\nIn this chapter, a brief description of the UAV and ASV used for the field tests,\n\ndescribed later on this dissertation, is presented, followed by an explanation on how\n\nthe oil spill scenario was created and simulated on the Gazebo simulator. The process\n\nof identifying the oil spill in the camera frame, the extraction of its contour borders,\n\nthe computation of its real world position and the computation of the UAV and ASV\n\ntrajectories from the simulated scenario are also addressed in this chapter.\n\n5.1 Autonomous Vehicles\n\n5.1.1 Unmanned Aerial Vehicle (UAV): STORK I\n\nSTORK I, depicted in Figure 5.1, is an hexarotor UAV, built in 2015 by a Portuguese\n\nresearch institution, INESC TEC and by the Autonomous Systems Lab of the School of\n\nEngineering of the Polytechnic Institute of Porto (ISEP), capable of autonomous take-off\n\nand landing, real time sensor data acquisition with on-board processing and autonomous\n\nmissions with obstacle avoidance.\n\nThe vehicle was developed by INESC TEC for this project, built from carbon fiber\n\nand plastic, with 90 cm of total diameter and with a height of 70 cm, a payload capacity\n\nof 4.9 kg and with an autonomy reaching the 25 minutes of flight. The UAV makes use\n\nof the open-source autopilot from Pixhawk project, running PX4 firmware.\n\nThe navigation sensors, IMU and Ublox Neo M8N Global Navigation Satellite System\n\n(GNSS) and the interchangeable sensorial payload, 0.3 MP PointGrey Firefly FMVU-\n\n03MTC-CS visible camera, 2.3 MP Pointgrey Grasshoper GS3-U3-23S6C-C, termo-\n\ngraphic camera and a LIDAR allow the vehicle to be suitable for a wide range of distinct\n\n49\n\n\n\n5.1. Autonomous Vehicles Chapter 5\n\nFigure 5.1: Hexarotor AUV STORK I.\n\napplications such as search and rescue, aerial surveillance and inspection, 3D mapping\n\nand target identification, localisation and tracking.\n\nFor the SpilLess and ROSM projects a sprinkler like, spraying system for the Lyophilized\n\npowder, described in the Figure 5.2, was designed and linked to the UAV bellow its frame,\n\nvisible in the Figure 6.3.\n\nFigure 5.2: UAV\u2019s spraying system for the Lyophilized powder.\n\nOther vehicle specifications:\n\n\u2022 On-board computation: Odroid XU3 running Ubuntu 14.04 with ROS Indigo;\n\n\u2022 Weight: 3 kg;\n\n\u2022 Power: rechargeable batteries (LiPo, 22000 mAh);\n\n\u2022 Payload interfaces/ports: USB (2.0 and 3.0);\n\n\u2022 Maximum height: 300 m;\n\n50\n\n\n\nChapter 5 5.1. Autonomous Vehicles\n\n\u2022 Range: 300 m;\n\n\u2022 Propulsion: six brushless rotors;\n\n\u2022 Horizontal speed: 0-10 m/s;\n\n\u2022 Vertical speed: 0-6 m/s (ascent and descent);\n\n\u2022 Degrees of freedom: throttle, roll, pitch, yaw;\n\n\u2022 Communications: Wi-Fi (5 GHz), telemetry (433 MHz), emergency stop (2.4 GHz);\n\n\u2022 Navigation system: GPS, Flight Control Unit (with accelerometer, barometer,\ngyroscope, magnetometer) and IMU.\n\n5.1.2 Autonomous Surface Vehicle (ASV): ROAZ II\n\nThe vehicle ROAZ II, depicted in Figure 5.3, is a ASV with the shape of a catamaran,\n\nbuilt in 2008 by a Portuguese research company, INESC TEC and by the Autonomous\n\nSystems Lab of the School of Engineering of the Polytechnic Institute of Porto (ISEP),\n\ncapable of autonomous operation as a result of on-board sensor processing and high\n\nprecision navigation.\n\nFigure 5.3: Autonomous Surface Vehicle ROAZ II.\n\n51\n\n\n\n5.1. Autonomous Vehicles Chapter 5\n\nFigure 5.4: ASV\u2019s spraying system for the Lyophilized powder.\n\nThe developed vehicle with a length of 4.5 m, width of 2.2 m and weight of 400kg\n\nwith the capability to handle 300 kg more of payload, is built from Polyethylene and\n\nAluminium and it\u2019s continuously being adapted to different projects and missions.\n\nWith several interchangeable sensors: Side-scan Sonar, Multibeam Echosounder, Sub-\n\nBottom Profiler, Video cameras (visible and thermographic), Sound velocity probe, DVL\n\nwith ADCP option, GPS with RTK and INS, Radar, Infra-red, and CTD (conductivity,\n\ntemperature, and depth) instrument, is suitable for a wide range of applications such\n\nas aquatic environment monitoring, data collection and oceanography, environmental\n\nmodelling (oceanographic, 3D sea floor modelling), bathymetry, security, area patrol,\n\nautomated intrusion detection, target identification and tracking, search and rescue and\n\ncmmunications relay in multi-vehicle scenarios and surface support to underwater assets.\n\nFor the SpilLess and ROSM projects a sprinkler like, spraying system for the Lyophilized\n\npowder, described in the Figure 5.4, was designed and linked to the side of the ASV,\n\nvisible in the Figure 5.5. This system is composed by a water pump that obtains wa-\n\nter from the ocean and mixes the Lyophilized powder in that water before releasing it\n\nthrough its sprinkler.\n\nOther vehicle specifications:\n\n\u2022 Deployment: boat trailer or crane;\n\n\u2022 Power: rechargeable batteries (LiFePO4, 4800 Wh);\n\n\u2022 Autonomy: 10 h;\n\n\u2022 Range: 60-100 km;\n\n\u2022 Payload interfaces/ports: ethernet, serial RS232/485, CAN bus (IP68 or underwa-\nter connectors plugs);\n\n52\n\n\n\nChapter 5 5.1. Autonomous Vehicles\n\nFigure 5.5: Implementation of the spraying system in the ASV being the water pump\nsystem noticeable in blue and the motorised sprinkler in red.\n\n\u2022 Wireless communication (data/video);\n\n\u2022 Propulsion: two electric thrusters (independent);\n\n\u2022 Propulsion power: 10 HP;\n\n\u2022 Maximum speed: 5 m/s (10 knots);\n\n\u2022 Degrees of freedom: 3DOF;\n\n\u2022 Communications: Wi-Fi, RF, Iridium, underwater acoustic communications;\n\n\u2022 Modes of operation: teleoperation, autonomous waypoint following, station keep-\ning and adaptive autonomous mission.\n\n\u2022 Landing system for UAVs;\n\n53\n\n\n\n5.2. Scenario creation and simulation Chapter 5\n\n5.2 Scenario creation and simulation\n\nTo obtain a realistic simulation of the mitigation of an oil spill incident, the recre-\n\nation of this scenario was implemented within the Gazebo simulator. The main features\n\nof this scenario are the oil spill in open waters, the existence of two vehicles, an ASV\n\nROAZ II and an UAV STORK I with the capability for a cooperative and coordinate\n\nmanoeuvre between them for the oil spill mitigation. That manoeuvre consists on a\n\ncontour trajectory by the ASV, while deploying microorganisms and nutrients (biore-\n\nmediation), capable of mitigating and containing the spillage and, simultaneously, on a\n\ncoverage trajectory of the affected area by the UAV.\n\nTo achieve the level of realism depicted in the Figures 5.6, 5.7 and 5.8, several different\n\nparts had to be combined:\n\nFigure 5.6: Oil spill and vehicles simulation in Gazebo.\n\nThe usage of Ubuntu 14.04 LTS;\n\nThe installation of the chosen robotic simulator, Gazebo 7.0;\n\nThe installation of ROS Indigo;\n\nThe integration of the package \u201duuv simulator \u201d (Unmanned Underwater Vehicle sim-\n\nulator) from 2016, under constant development by Manha?es et Al. [77]. This package\n\nprovided the simulation with an realistic ocean environment representation;\n\nModification of the squared mesh without thickness used by the \u201duuv simulator \u201d\n\n54\n\n\n\nChapter 5 5.2. Scenario creation and simulation\n\nFigure 5.7: Oil spill from the ASV perspective.\n\nFigure 5.8: Oil spill from the UAV perspective.\n\n55\n\n\n\n5.2. Scenario creation and simulation Chapter 5\n\nFigure 5.9: Model of the ocean surface (left) and oil spill (right).\n\npackage to represent the ocean surface and exportation as two different meshes, ocean\n\nsurface mesh without the oil spill and the oil spill mesh itself, as depicted in Figure 5.9\n\nand inclusion of both into the simulation world. If a new mesh was created for the oil spill\n\narea and overlapped over the previously existent ocean mesh, the distinct wave motion\n\non both surfaces would be noticeable, therefore, the oil spill area must be removed from\n\nthe ocean surface mesh. For the oil spill mesh a darker colour is used;\n\nThe integration of the MAVROS ROS package, that supports the bridge between ROS\n\nand the MAVLink protocol. This bridge allows the communication between computers\n\nrunning ROS and MAVLink enabled autopilots, like the PX4 flight stack. Based on the\n\ncommunication protocol between the PX4 and the application in ROS, we are able to\n\ncommunicate between the low level UAV control and the high level.\n\nThe usage of Iris UAV model, depicted in Figure 5.11, from the SITL Gazebo simu-\n\nlation, provided by the PX4 Developer Guide[90] that uses MAVROS MAVLink node to\n\ncommunicate with PX4 Autopilot Firmware. This UAV model is used to simulate the\n\nSTORK I vehicle;\n\nIntegration of a undistorted camera model into the UAV with a plugin that publishes\n\nthe camera feed into a ROS topic, to obtain a aerial perspective of an oil spill scenario.\n\nIntegration of an realistic model of the ASV ROAZ II, depicted in Figure 5.12, into\n\nthe simulation world as a mesh in a Collada file (.dae format);\n\nThe author suggests the usage of the referred software, though later versions should\n\nwork correctly, with some minor adjustments if required.\n\n56\n\n\n\nChapter 5 5.2. Scenario creation and simulation\n\nFigure 5.10: ROS/Gazebo integration with PX4.\n\nFigure 5.11: Model of the Iris UAV.\n\n57\n\n\n\n5.2. Scenario creation and simulation Chapter 5\n\nFigure 5.12: Model of the ROAZ II ASV.\n\n58\n\n\n\nChapter 5 5.3. Spill identification and real world position computation\n\n5.3 Spill identification and real world position computa-\n\ntion\n\nIn order to identify and obtain the position of the oil spill, in the real world, a node\n\n\u201dmove drone\u201d was created that forces the UAV model to perform an ascending trajectory\n\nto a higher position within the oil spill area. Ensuring that the entire affected area is\n\ncaptured by the field of view of the camera. Once it reaches that position, waits for the\n\nwaypoint publication in the rostopic \u201d/drone waypoints \u201d, to initiate the trajectory.\n\nOnce the entire spill it\u2019s contained within its camera frame, a ROS node, named\n\n\u201dspillage detection node\u201d, subscribes to the UAV camera feed, being published as a\n\nrostopic, \u201dcamera/image raw \u201d. Based on that image, a findContours function from the\n\nOpen Source Computer Vision Library (OpenCV)1, with the correct threshold, obtained\n\nthrough several tests for this specific scenario, is applied in order to obtain the position\n\nof each point of the contour from the oil spill, in pixels from that frame, as depicted in\n\nFigure 5.13.\n\nFigure 5.13: Input (left) and output (right) through OpenCV \u201dfindContours\u201d function.\n\nTo obtain the projection of the contour points in the real world is necessary to go\n\nthrough a series of transformations. The first matrix necessary to obtain that projection\n\nis described in the equation 5.1 with K and corresponds to the camera Intrinsic Matrix,\n\na 3 by 3 matrix where fx and fy stand for the focal length, in pixels, x0 and y0 for the\n\nprincipal point offset of the camera and s for the axis skew of the camera.\n\n1https://docs.opencv.org/2.4/\n\n59\n\n\n\n5.3. Spill identification and real world position computation Chapter 5\n\nK =\n\n?\n??fx s x0 00 fy y0 0\n\n0 0 1 0\n\n?\n?? =\n\n?\n??568.238 0 644 00 568.238 482 0\n\n0 0 1 0\n\n?\n?? (5.1)\n\nThe rotation matrix between the camera and UAV body reference frames, Rbc, is\n\npresented in the equation 5.2. This 3 by 3 matrix is constant throughout the entire\n\nmanoeuvre, since the camera orientation does not change within the UAV body refer-\n\nence frame, and represent a Roll, Pitch and Y aw rotations of ?, 0 and ??/2 radians,\nrespectively.\n\nRbc = Y aw\nb\nc(??/2) ?Pitch\n\nb\nc(0) ?Roll\n\nb\nc(?) =\n\n?\n?? 0 ?1 0?1 0 0\n\n0 0 ?1\n\n?\n?? (5.2)\n\nThe transformation matrix between the camera and UAV body reference frames, Pbc ,\n\nis presented in the equation 5.3. This 4 by 4 matrix contains the rotation matrix between\n\nthe camera and UAV body reference frames, Rbc, and the displacement between the\n\ncamera and UAV body reference frames, Tbc , this translation is also constant throughout\n\nthe entire manoeuvre.\n\nPbc =\n\n?\n?????\n\nTbc x\n\nRbc T\nb\nc y\n\nTbc z\n\n0 0 0 1\n\n?\n????? =\n\n?\n?????\n\n0 ?1 0 0\n?1 0 0 0\n0 0 ?1 0\n0 0 0 1\n\n?\n????? (5.3)\n\nThe rotation matrix between the UAV body and world reference frames, Rwb , is pre-\n\nsented in the equation 5.4. This 3 by 3 matrix represents the Roll, Pitch and Y aw\n\nrotations of the UAV in relation to the world referential. This rotations and the trans-\n\nlation matrix Twb are obtained through the subscription to the rostopic \u201d/mavros/lo-\n\ncal position/pose\u201d, that estimates the UAV pose (through GPS + IMU), being published\n\nby the MAVROS node.\n\nRwb = Y aw\nw\nb (?) ?Pitch\n\nw\nb (?) ?Roll\n\nw\nb (?) (5.4)\n\nThe transformation matrix between the UAV body and world reference frames, Pwb ,\n\nis presented in the equation 5.5. This 4 by 4 matrix contains the rotation matrix between\n\nthe UAV body and world reference frames, Rwb , and the displacement between the UAV\n\nbody and world reference frames, Tbc .\n\n60\n\n\n\nChapter 5 5.3. Spill identification and real world position computation\n\nPwb =\n\n?\n?????\n\nTwb x\n\nRwb T\nw\nb y\n\nTwb z\n\n0 0 0 1\n\n?\n????? (5.5)\n\nConsidering the matrices previously defined it\u2019s possible to compute an auxiliary\n\nmatrix, ?, that represents the position and attitude transformation matrix of the camera\n\nto the world referential. This matrix is formed by the multiplication of K by the inverse\n\nof Pbc and by the inverse of P\nw\nb , and its represented in the equation 5.6. In this matrix\n\nthe third column is removed to allow the multiplication in 5.8, this could only be done\n\nsince the author is assuming that the ocean surface is a plan with Z = 0 and the contour\n\npoints will be always on that plan.\n\n? = K ? [Pbc ]\n?1 ? [Pwb ]\n\n?1 =\n\n?\n???1 ?2 ?3 ?4?5 ?6 ?7 ?8\n\n?9 ?10 ?11 ?12\n\n?\n?? =\n\n?\n???1 ?2 ?4?5 ?6 ?8\n\n?9 ?10 ?12\n\n?\n?? (5.6)\n\nThe matrix with each contour x and y positions, in pixels, from the image frame,\n\nImage pos, is represented in the equation 5.7.\n\nImage pos =\n[\nPixelx Pixely 1\n\n]\n(5.7)\n\nLastly World pos corresponds to a vector with the x and y positions of that contour\n\npoint in real world coordinates. This operation, represented in the equation 5.8, must\n\nbe applied for each contour point.\n\nWorld pos = Image pos? [K ? [Pbc ]\n?1 ? [Pwb ]\n\n?1]?1 = Image pos? ??1 (5.8)\n\n61\n\n\n\n5.4. UAV\u2019s trajectory computation in the simulation scenario Chapter 5\n\n5.4 UAV\u2019s trajectory computation in the simulation sce-\n\nnario\n\nThe same ROS node, \u201dspillage detection node\u201d is responsible for the computation of\n\nthe optimal oil spill mitigation trajectory for the UAV. This trajectory is depicted, in\n\nred, in the Figure 5.14 and is obtained through an orderly following of the waypoints,\n\ndepicted as red asterisks, by the UAV.\n\n-50 0 50\n\nX (pixels)\n\n-50\n\n-40\n\n-30\n\n-20\n\n-10\n\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\nY\n (\n\np\nix\n\ne\nls\n\n)\n\nUAV Trajectory\n\nFigure 5.14: UAV trajectory computation.\n\nFor the simulation of the UAV manoeuvre, within the Gazebo Simulator, a node\n\nwas created, \u201dmove drone\u201d, this plugin, described before is not only responsible for\n\nsending the UAV to a higher position within the oil spill area for wider aerial perspec-\n\ntive, but also for moving the UAV through the waypoints published into the rostopic\n\n\u201d/drone waypoints \u201d once determined the trajectory.\n\n62\n\n\n\nChapter 5 5.5. ASV\u2019s trajectory computation in the simulation scenario\n\n5.5 ASV\u2019s trajectory computation in the simulation sce-\n\nnario\n\nTo achieve the control-law for the ASV manoeuvre, the previously described ROS\n\nnode \u201dspillage detection node\u201d, starts by subscribing to the ASV GPS position, through\n\nthe rostopic \u201droaz gps \u201d, to obtain a trajectory from the vehicle current position and\n\nby receiving the vehicle behavior (waypoint/maneuover) to maintain from the oil spill\n\nborders. With these values and the contour points real world positions, the node is\n\ncapable of computing a mitigation trajectory for the ASV based on the three methods\n\ndescribed bellow.\n\n5.5.1 Method I: Artificial Potential Fields with 8 interchangeable goals\n\nIn the figure 5.15, the result of this first algorithm is presented. When the surface\n\nvehicle is in the area A1, is attracted towards the top central goal, but once it enters\n\nthe area A2, is attracted towards the top right goal and so on, interchanging goals in a\n\nclockwise direction. The same algorithm is applied to a scenario with multiple different\n\ngeometrical forms, in the figure 5.16.\n\nFigure 5.15: Control-law performance of Method I in a simulated oil spill scenario.\n\nThis algorithm provides a good trajectory, though it is highly dependable on the\n\nshape of the spill, as it is demonstrated on the figures 5.15 and 5.16, where the robot\n\nfound a \u201dlocal minima\u201d, from which it is unable to leave.\n\n63\n\n\n\n5.5. ASV\u2019s trajectory computation in the simulation scenario Chapter 5\n\nFigure 5.16: Control-law performance of Method I for a simulated scenario with different\ngeometric forms.\n\n5.5.2 Method II: Artificial Potential Fields with an extra Tangential\n\nForce\n\nIn the figures 5.17 and 5.18, the results of this second algorithm are presented and\n\nthough it looked promising, in theory, is also affected by a \u201dlocal minima\u201d.\n\nFigure 5.17: Control-law performance of Method II with Utangential=3.2 in a simulated\n\noil spill scenario.\n\n64\n\n\n\nChapter 5 5.5. ASV\u2019s trajectory computation in the simulation scenario\n\nFigure 5.18: Control-law performance of Method II, with Utangential=3.2, for a simulated\nscenario with different geometric forms.\n\nThe presence of \u201dlocal minimas \u201d on this algorithm, can be surpassed, in the oil spill\n\nscenario, by increasing the value of the tangential force. In the figure 5.17 that value\n\nwas 3.2, if increased up to 16.2, the robot is already capable of contour the entire spill,\n\nas demonstrated in the figure 5.19. This raises another problem, with the increase of the\n\ntangential force, the trajectory tends to a circular motion, not respecting then, the main\n\nobjective of this project, to follow closely the contour of an oil spill. Furthermore, there\n\nis no way to define the ideal tangential force value, without the previous knowledge of\n\nthe entire shape of the obstacle.\n\nIf the tangential force is increased up to 30, in the scenario with multiple different\n\ngeometric forms, the algorithm fails, since the tangential force surpasses the repulsion\n\nforce created by the spill, moving the robot to the interior of the spill, as represented in\n\nthe figure 5.20.\n\n65\n\n\n\n5.5. ASV\u2019s trajectory computation in the simulation scenario Chapter 5\n\nFigure 5.19: Control-law performance of Method II, with Utangential=16.2 in a simulated\noil spill scenario.\n\nFigure 5.20: Control-law performance of Method II, with Utangential=30, for a simulated\n\nscenario with different geometric forms.\n\n5.5.3 Method III: Control Points through Normal Vectors with Arti-\n\nficial Potential Fields\n\nThe oil spill contour and the trajectory obtained with this algorithm are represented\n\nin the figures 5.21 and 5.22.\n\n66\n\n\n\nChapter 5 5.5. ASV\u2019s trajectory computation in the simulation scenario\n\nFigure 5.21: Control-law performance of Method III in a simulated oil spill scenario.\n\nFigure 5.22: Control-law performance of Method III, for a simulated scenario with dif-\n\nferent geometric forms.\n\nAn overlap of the result trajectories for each method, at the oil spill scenario and at\n\nthe scenario with the multiple geometrical forms, are represented in the figures 5.23 and\n\n5.24, respectively.\n\n67\n\n\n\n5.5. ASV\u2019s trajectory computation in the simulation scenario Chapter 5\n\nFigure 5.23: Trajectories overlap comparison in a simulated oil spill scenario.\n\nFigure 5.24: Trajectories overlap comparison, for a simulated scenario with different\n\ngeometric forms.\n\nSince two methods were able to complete the contour, in the oil spill scenario, figures\n\n5.19 and 5.21, the table 5.1 was elaborated to compare the travelled distance performed\n\nby each method. In this table, the method III has a shorter travelled distance than the\n\nmethod II with the Utangential = 16.2, which indicates a much closer contour following\n\ntrajectory of the oil spill.\n\n68\n\n\n\nChapter 5 5.5. ASV\u2019s trajectory computation in the simulation scenario\n\nTable 5.1: Travelled distance performed by each method.\n\nMethod Travelled distance (m)\n\nI Incomplete mission\n\nII, Utangential = 3.2 Incomplete mission\n\nII, Utangential = 16.2 1536\n\nIII 1238\n\nFor the scenario described in this dissertation, from the approaches tested, it became\n\nclear that, the one that produced the best trajectory, for the oil spill mitigation, was the\n\nMethod III, that uses normal vectors to compute a list of control points that describe a\n\nnew and enlarged contour, this list of control points is then passed through a Potential\n\nField algorithm that uses them as successive goals. It is the easiest method to define a\n\nexact distance, to be maintained in relation to the oil spill boundaries, along the entire\n\ntrajectory and does not present trajectory stops unlike the other algorithms that suffer\n\nfrom \u201dlocal minimas \u201d.\n\nFor the simulation of the ASV manoeuvre within the Gazebo Simulator the node\n\n\u201dmove roaz \u201d was created, this node is responsible for moving the surface vehicle model\n\nthrough the waypoints published into the rostopic \u201d/surf waypoints \u201d once determined\n\nthe trajectory.\n\n69\n\n\n\nThis page was intentionally left blank.\n\n\n\nChapter 6\n\nResults\n\nThe results for this dissertation were obtained on April 23 and 24, in the preliminary\n\ntests of the project SpilLess that occurred in the Leixo?es Harbour in Porto, Portugal,\n\ndepicted in Figure 6.1, where the oil spill was simulated on the Gazebo simulator scenario,\n\non a known position from the real world and the algorithms for the cooperative and\n\nsimultaneous manoeuvre between the UAV and the ASV were put to test. In this test\n\nfor the generation of the surface vehicle trajectory, the method III, generation of control\n\npoints through normal vectors and artificial potential field, was applied, since it provided\n\nthe best simulated results.\n\nFigure 6.1: Experimental Field Tests at Leixo?es Harbour.\n\n71\n\n\n\nChapter 6\n\nThe position of both vehicles was represented in real time in a ROS tool for 3D\n\nvisualisation, RViz, with a precise model of the oil spill included into the scenario for\n\nmanoeuvre monitoring from land. This representation is depicted in Figure 6.2, where\n\nthe ASV is represented in red, the UAV in green and the oil spill in black. In the figure is\n\nalso possible to observe, in real time, the orientation of the ASV\u2019s sprinkler, represented\n\nas a three dimensional white arrow and the ASV waypoints generated using the Method\n\nIII, represented as a two dimensional blue arrows.\n\nFigure 6.2: RViz representation of the scenario and vehicles position.\n\n72\n\n\n\nChapter 6 6.1. UAV\u2019s trajectory\n\n6.1 UAV\u2019s trajectory\n\nPrior to the UAV\u2019s trajectory start, the container for the Lyophilized powder was\n\nloaded with a pink powder, as depicted in Figure 6.3, in order to visualise the release\n\nsystem in operation, this pink powder has a similar consistency to the Lyophilized pow-\n\nder. The powder releasing is noticeable in Figure 6.4.\n\nFigure 6.3: Powder loading into the UAV\u2019s container.\n\nFigure 6.4: UAV\u2019s powder releasing system in action.\n\n73\n\n\n\n6.1. UAV\u2019s trajectory Chapter 6\n\nAfter the powder was loaded into the UAV, the trajectory waypoints were generated\n\nthrough the simulation environment and loaded into the UAV\u2019s mission planner. The\n\ncomputed trajectory was formed by 18 waypoints that describe an efficient \u201dzigzag\u201d\n\nmanoeuvre for the oil spill mitigation. At that moment, the vehicle took of for an\n\nautonomous waypoint following flight.\n\nFrom the data obtained from the PX4 autopilot logs, from the performed trajectory,\n\nit was possible to obtain the global estimated position from the UAV\u2019s on board GPS\n\nand IMU. The representation of that estimated trajectory is depicted in Figure 6.5.\n\nIn the Figure 6.6 is possible to perceive in addition, other information like the intended\n\ntrajectory, the estimated trajectory based only on the GPS and the trajectory waypoints.\n\nBoth representations were obtained using the online software PX4 Flight Review1.\n\nFigure 6.5: UAV\u2019s estimated trajectory representation.\n\nDepicted in the Figure 6.7 is an overlap of the UAV\u2019s waypoints (intended trajec-\n\ntory), in green, and UAV\u2019s performed trajectory, in blue. For a more comprehensible\n\nrepresentation, the detected oil spill contour was also included in the figure, in red. The\n\nrepresentation was obtained using the online software GPS Visualizer2.\n\n1https://review.px4.io/\n2http://www.gpsvisualizer.com/\n\n74\n\n\n\nChapter 6 6.1. UAV\u2019s trajectory\n\nFigure 6.6: Representation of the data obtained from the UAV\u2019s PX4 autopilot.\n\nFigure 6.7: UAV trajectory representation from the PX4 global position logs.\n\n75\n\n\n\n6.2. ASV\u2019s trajectory Chapter 6\n\n6.2 ASV\u2019s trajectory\n\nThe sprinkler implemented into the ASV is visible in action in the Figure 6.8. A\n\nDynamixel servo motor was fixed to the ASV\u2019s sprinkler, to allow the sprinkler to to\n\nvary its angle of attack to the oil spill in a constant motion.\n\nFigure 6.8: ASV sprinkler in action.\n\nThe ASV used for the experimental field tests, ROAZ II, has its own control base-\n\nstation, depicted in Figure 6.9, from where is possible to manually control it, define and\n\nsend waypoints for an autonomous waypoint following behaviour and the capability of\n\nmonitor all the data provided by ROAZ II such as sensor data, vehicle position and\n\ntrajectory, waypoints reached and next waypoint to be reached.\n\nIn the Figure 6.10 from a base station screenshot, is possible to identify the vehicle\u2019s\n\ncurrent position by the red arrow, its performed trajectory by the red dots, the reached\n\nwaypoints, from 1 to 8, as green triangles and the waypoint 9 still to be reached, in yellow.\n\nAll these positions are presented on a realistic map. These 9 waypoints, represent the oil\n\nspill contour manoeuvre. The manoeuvre is represented by this low number of waypoints\n\ndue too the minimal distance of 30 meters between each waypoint, this condition is\n\nimposed by the reduced turning angle of this specific surface vehicle. This distance\n\nbetween the waypoints can be easily altered in a parameter of the algorithm.\n\nFrom the GPS attached to the ASV it was possible to represent the trajectories\n\n76\n\n\n\nChapter 6 6.2. ASV\u2019s trajectory\n\nFigure 6.9: ASV ROAZ II field base station.\n\nFigure 6.10: ASV trajectory representation in the basestation.\n\n77\n\n\n\n6.2. ASV\u2019s trajectory Chapter 6\n\nperformed by ROAZ II. In the Figures 6.11 and 6.12, those trajectories are represented\n\nin blue. This manoeuvres were performed on two distinct days, 23 and 24 of April\n\nof 2018, respectively, with a constant acceptance radius of 10 meters. It is noticeable\n\na larger drift from the intended trajectory in the Figure 6.12, this was due to harsh\n\nweather conditions, strong wind and current. Both representations were obtained using\n\nthe online software GPS Visualizer.\n\nFigure 6.11: ASV trajectory on April 23.\n\n78\n\n\n\nChapter 6 6.2. ASV\u2019s trajectory\n\nFigure 6.12: ASV trajectory on April 24.\n\nIt is noticeable that the intended trajectory does not follow closely the oil spill bor-\n\nders during the entire manoeuvre, as explained before, this reduction of the number\n\nof trajectory waypoints was necessary due to the reduced turning angle of this specific\n\nsurface vehicle.\n\n79\n\n\n\nThis page was intentionally left blank.\n\n\n\nChapter 7\n\nConclusion and Future Work\n\nIn this dissertation the simulation and experimental results for the control-laws for\n\nthe oil spill mitigation resorting to an UAV and an ASV are presented.\n\nFor the scenario previously described, from the approaches tested for the surface\n\nvehicle, it became clear that, the method able of obtain the best trajectory, for the oil\n\nspill mitigation, was the Method III, that uses normal vectors to compute a new and\n\nenlarged contour, the control points from that new contour are then passed through an\n\nArtificial Potential Field algorithm that uses them as successive goals. This method\n\ndemonstrated to be the easiest to define a precise distance, to be maintained in relation\n\nto the oil spill boundaries, along the entire trajectory and did not present trajectory\n\nstops unlike the other algorithms that suffer from \u201dlocal minimas \u201d.\n\nHowever, in the real-world applications, the autonomous vehicles must carry out the\n\nclean-up tasks in more complicated scenarios, such as obstacle-rich environments that\n\ncontain islands and other cleaning vessels. To mitigate these and other adversities, the\n\nfollowing tasks are proposed as future work:\n\n\u2022 Further improve the oil spill detection, discarding false positives from obstacles,\npersonnel rescue teams or oil spill mitigation vessels;\n\n\u2022 Control the displacement or the spread of the oil spill by the action of the wind/cur-\nrents and its degradation from the mitigation process, either by realistic weathering\n\nmodels or through an aerial view of the environment during the entire process;\n\n\u2022 Convert the UAV and ASV path planning methods into adaptive algorithms, ca-\npable of handling the displacement, spread or degradation of the oil spill;\n\n\u2022 Modify the UAV path planning algorithm to ensure a mitigation action prioriti-\nsation over the areas where the ASV has already taken action, thereby ensuring a\n\n81\n\n\n\nChapter 7\n\nmore effective action.\n\n\u2022 Continue improving the performance of the control law defined in this dissertation\nas Method III.\n\n\u2022 Replace the 8 interchangeable goals defined in the Method I for N interchangeable\ngoals, this N value keeps increasing while \u201dlocal minimas \u201d still exist in the planned\n\ntrajectory.\n\n\u2022 Increasing the ASV sprinkler\u2019s reach so that the vehicle do not need to follow the\nspill boundaries so closely.\n\nA part of the work developed in this dissertation resulted in the publication of the\n\npaper \u201dControl-law for Oil Spill Mitigation with an Autonomous Surface Vehicle\u201d on\n\nthe conference OCEANS\u201918 MTS/IEEE Kobe / Techno-Ocean 2018.\n\n82\n\n\n\nBibliography\n\n[1] Hani Safadi. Local path planning using virtual potential field. McGill University\n\nSchool of Computer Science, Tech. Rep, 2007.\n\n[2] Clearpath Robotics et al. Ros 101: Intro to the robot operating system\u2014 robohub.\n\nRobohub. org. Np, 2017.\n\n[3] RyuWoon Jung TaeHoon Lim YoonSeok Pyo, HanCheol Cho. ROS Robot Program-\n\nming. ROBOTIS Co.,Ltd, 2017.\n\n[4] Peter Burgherr. In-depth analysis of accidental oil spills from tankers in the context\n\nof global spill trends from all sources. Journal of hazardous materials, 140(1-2):245\u2013\n\n256, 2007.\n\n[5] Keisha Huijer. Trends in oil spills from tanker ships 1995-2004. International Tanker\n\nOwners Pollution Federation (ITOPF), London, 30, 2005.\n\n[6] Xin Jin and Asok Ray. Navigation of autonomous vehicles for oil spill cleaning in\n\ndynamic and uncertain environments. International Journal of Control, 87(4):787\u2013\n\n801, 2014.\n\n[7] James G Speight and Karuna K Arjoon. Bioremediation of petroleum and petroleum\n\nproducts. John Wiley &amp; Sons, 2012.\n\n[8] Mark F Kirby and Robin J Law. Accidental spills at sea\u2013risk, impact, mitigation\n\nand the need for co-ordinated post-incident monitoring. Marine pollution bulletin,\n\n60(6):797\u2013803, 2010.\n\n[9] Sharon Gaudin. MIT builds swimming, oil-eating robots. Computerworld, August,\n\n26, 2010.\n\n[10] E. Gernez, C. M. Harada, R. Bootsman, Z. Chaczko, G. Levine, and P. Keen.\n\nProtei open source sailing drones: A platform for education in ocean exploration\n\n83\n\n\n\nBIBLIOGRAPHY BIBLIOGRAPHY\n\nand conservation. In 2012 International Conference on Information Technology\n\nBased Higher Education and Training (ITHET), pages 1\u20137, June 2012.\n\n[11] A Pandey, S Pandey, and DR Parhi. Mobile robot navigation and obstacle avoidance\n\ntechniques: A review. Int Rob Auto J, 2(3):00022, 2017.\n\n[12] Enric Galceran and Marc Carreras. A survey on coverage path planning for robotics.\n\nRobotics and Autonomous systems, 61(12):1258\u20131276, 2013.\n\n[13] Liang Yang, Juntong Qi, Jizhong Xiao, and Xia Yong. A literature review of uav 3d\n\npath planning. In Intelligent Control and Automation (WCICA), 2014 11th World\n\nCongress on, pages 2376\u20132381. IEEE, 2014.\n\n[14] Tiago Fernandes. Planeamento de Trajeto?ria para Operac?o?es de Busca e Salvamento\n\ncom UAVs. ISEP, 2016.\n\n[15] Lydia E Kavraki, Petr Svestka, J-C Latombe, and Mark H Overmars. Probabilis-\n\ntic roadmaps for path planning in high-dimensional configuration spaces. IEEE\n\ntransactions on Robotics and Automation, 12(4):566\u2013580, 1996.\n\n[16] Shaojie Shen, Nathan Michael, and Vijay Kumar. Autonomous multi-floor indoor\n\nnavigation with a computationally constrained mav. In Robotics and automation\n\n(ICRA), 2011 IEEE international conference on, pages 20\u201325. IEEE, 2011.\n\n[17] Edsger W Dijkstra. A note on two problems in connexion with graphs. Numerische\n\nmathematik, 1(1):269\u2013271, 1959.\n\n[18] Ivin Amri Musliman, Alias Abdul Rahman, Volker Coors, et al. Implementing 3d\n\nnetwork analysis in 3d gis. International archives of ISPRS, 37(part B), 2008.\n\n[19] Luca De Filippis, Giorgio Guglieri, and Fulvia Quagliotti. Path planning strategies\n\nfor uavs in 3d environments. Journal of Intelligent &amp; Robotic Systems, 65(1-4):247\u2013\n\n264, 2012.\n\n[20] Slawomir Grzonka, Giorgio Grisetti, and Wolfram Burgard. A fully autonomous\n\nindoor quadrotor. IEEE Transactions on Robotics, 28(1):90\u2013100, 2012.\n\n[21] Sungsik Huh, David Hyunchul Shim, and Jonghyuk Kim. Integrated navigation sys-\n\ntem using camera and gimbaled laser scanner for indoor and outdoor autonomous\n\nflight of uavs. In Intelligent Robots and Systems (IROS), 2013 IEEE/RSJ Interna-\n\ntional Conference on, pages 3158\u20133163. IEEE, 2013.\n\n84\n\n\n\nBIBLIOGRAPHY BIBLIOGRAPHY\n\n[22] Neda Shahidi, Hadi Esmaeilzadeh, Marziye Abdollahi, and Caro Lucas. Memetic\n\nalgorithm based path planning for a mobile robot. In International Conference on\n\nComputational Intelligence. Citeseer, 2004.\n\n[23] Ellips Masehian and MR Amin-Naseri. A voronoi diagram-visibility graph-potential\n\nfield compound algorithm for robot path planning. Journal of Field Robotics,\n\n21(6):275\u2013300, 2004.\n\n[24] Ivan Maza and Anibal Ollero. Multiple uav cooperative searching operation us-\n\ning polygon area decomposition and efficient coverage algorithms. In Distributed\n\nAutonomous Robotic Systems 6, pages 221\u2013230. Springer, 2007.\n\n[25] M. Schwager, B. J. Julian, M. Angermann, and D. Rus. Eyes in the sky: Decen-\n\ntralized control for the deployment of robotic camera networks. Proceedings of the\n\nIEEE, 99(9):1541\u20131561, Sept 2011.\n\n[26] H. K. Heidarsson and G. S. Sukhatme. Obstacle detection and avoidance for an\n\nautonomous surface vehicle using a profiling sonar. In 2011 IEEE International\n\nConference on Robotics and Automation, pages 731\u2013736, May 2011.\n\n[27] UCG Commandant. International regulations for prevention of collisions at sea,\n\n1972 (72 colregs). US Department of Transportation, US Coast Guard, COMMAN-\n\nDANT INSTRUCTION M, 16672, 1999.\n\n[28] S Campbell, Wasif Naeem, and George W Irwin. A review on improving the auton-\n\nomy of unmanned surface vehicles through intelligent collision avoidance manoeu-\n\nvres. Annual Reviews in Control, 36(2):267\u2013283, 2012.\n\n[29] Wasif Naeem, George W Irwin, and Aolei Yang. Colregs-based collision avoidance\n\nstrategies for unmanned surface vehicles. Mechatronics, 22(6):669\u2013678, 2012.\n\n[30] Sable Campbell, Mamun Abu-Tair, and Wasif Naeem. An automatic colregs-\n\ncompliant obstacle avoidance system for an unmanned surface vehicle. Proceedings\n\nof the Institution of Mechanical Engineers, Part M: Journal of Engineering for the\n\nMaritime Environment, 228(2):108\u2013121, 2014.\n\n[31] Liang Hu, Wasif Naeem, Eshan Rajabally, Graham Watson, Terry Mills, Za-\n\nkirul Bhuiyan, and Ivor Salter. Colregs-compliant path planning for autonomous\n\nsurface vehicles: A multiobjective optimization approach. IFAC-PapersOnLine,\n\n50(1):13662\u201313667, 2017.\n\n85\n\n\n\nBIBLIOGRAPHY BIBLIOGRAPHY\n\n[32] Michael Benjamin, Joseph Curcio, and John Leonard. Navigation of unmanned\n\nmarine vehicles in accordance with the rules of the road. Technical report, NAVAL\n\nSEA SYSTEMS COMMAND NEWPORT DIV RI, 2006.\n\n[33] M. Pinto, B. Ferreira, H. Sobreira, A. Matos, and N. Cruz. Spline navigation and\n\nreactive collision avoidance with colregs for asvs. In 2013 OCEANS - San Diego,\n\npages 1\u20139, Sept 2013.\n\n[34] Merv Fingas and Carl Brown. Review of oil spill remote sensing. Marine pollution\n\nbulletin, 83(1):9\u201323, 2014.\n\n[35] Difeng Wang, Fang Gong, Delu Pan, Zengzhou Hao, and Qiankun Zhu. Introduction\n\nto the airborne marine surveillance platform and its application to water quality\n\nmonitoring in china. Acta Oceanologica Sinica, 29(2):33\u201339, 2010.\n\n[36] T Puestow, L Parsons, I Zakharov, N Cater, P Bobby, M Fuglem, G Parr, A Jayasiri,\n\nS Warren, and G Warbanski. Oil spill detection and mapping in low visibility and\n\nice: Surface remote sensing. Arctic Oil Spill Response Technology Joint Industry\n\nProgramme (JIP), 2013.\n\n[37] DF Dickins and JH Andersen. Evaluation of airborne remote sensing systems for\n\noil in ice detection. SINTEF Oil-in-Ice final report, Trondheim, (28), 2010.\n\n[38] GL Hover and JV Plourde. Evaluation of night capable sensors for the detection of\n\noil on water. Technical report, COAST GUARD WASHINGTON DC OFFICE OF\n\nRESEARCH AND DEVELOPMENT, 1994.\n\n[39] Carl E Brown, Richard Marois, Gregory E Myslicki, Mervin F Fingas, and Ron C\n\nMackay. Remote detection of submerged orimulsion with a range-gated laser fluo-\n\nrosensor. In International Oil Spill Conference, volume 2003, pages 779\u2013784. Amer-\n\nican Petroleum Institute, 2003.\n\n[40] Deqing Liu, Xiaoning Luan, Feng Zhang, Jiucai Jin, Jinjia Guo, and Ronger Zheng.\n\nAn usv-based laser fluorosensor for oil spill detection. In Sensing Technology (ICST),\n\n2016 10th International Conference on, pages 1\u20134. IEEE, 2016.\n\n[41] Pablo Marzialetti and Giovanni Laneve. Oil spill monitoring on water surfaces by\n\nradar l, c and x band sar imagery: A comparison of relevant characteristics. In\n\nGeoscience and Remote Sensing Symposium (IGARSS), 2016 IEEE International,\n\npages 7715\u20137717. IEEE, 2016.\n\n86\n\n\n\nBIBLIOGRAPHY BIBLIOGRAPHY\n\n[42] G Aalet Mastin, JJ Manson, JD Bradley, RM Axline, and GL Hover. A comparative\n\nevaluation of sar and slar. Technical report, Sandia National Labs., Albuquerque,\n\nNM (United States), 1993.\n\n[43] Nikolaos P Ventikos, Emmanouil Vergetis, Harilaos N Psaraftis, and George Tri-\n\nantafyllou. A high-level synthesis of oil spill response equipment and countermea-\n\nsures. Journal of hazardous materials, 107(1-2):51\u201358, 2004.\n\n[44] Elon Rimon and Daniel E Koditschek. Exact robot navigation using artificial po-\n\ntential functions. IEEE Transactions on robotics and automation, 8(5):501\u2013518,\n\n1992.\n\n[45] Yoram Koren and Johann Borenstein. Potential field methods and their inherent\n\nlimitations for mobile robot navigation. In Robotics and Automation, 1991. Pro-\n\nceedings., 1991 IEEE International Conference on, pages 1398\u20131404. IEEE, 1991.\n\n[46] J-O Kim and Pradeep K Khosla. Real-time obstacle avoidance using harmonic\n\npotential functions. IEEE Transactions on Robotics and Automation, 8(3):338\u2013349,\n\n1992.\n\n[47] Hiroaki Seki, Yoshitsugu Kamiya, and Masatoshi Hikizu. Real-time obstacle avoid-\n\nance using potential field for a nonholonomic vehicle. In Factory Automation. In-\n\nTech, 2010.\n\n[48] Vladimir J Lumelsky and Alexander A Stepanov. Path-planning strategies for a\n\npoint mobile automaton moving amidst unknown obstacles of arbitrary shape. Al-\n\ngorithmica, 2(1):403\u2013430, 1987.\n\n[49] Ji Yeong Lee and Howie Choset. Sensor-based exploration for convex bodies: A new\n\nroadmap for a convex-shaped robot. IEEE Transactions on Robotics, 21(2):240\u2013247,\n\n2005.\n\n[50] Zvi Shiller. Online suboptimal obstacle avoidance. The International Journal of\n\nRobotics Research, 19(5):480\u2013497, 2000.\n\n[51] Stefan Escaida Navarro, Stefan Koch, and Bjo?rn Hein. 3d contour following for\n\na cylindrical end-effector using capacitive proximity sensors. In Intelligent Robots\n\nand Systems (IROS), 2016 IEEE/RSJ International Conference on, pages 82\u201389.\n\nIEEE, 2016.\n\n87\n\n\n\nBIBLIOGRAPHY BIBLIOGRAPHY\n\n[52] Urbano Nunes, Pedro Faia, and Anibal T de Almeida. Sensor-based 3-d autonomous\n\ncontour-following control. In Intelligent Robots and Systems\u2019 94.\u2019Advanced Robotic\n\nSystems and the Real World\u2019, IROS\u201994. Proceedings of the IEEE/RSJ/GI Interna-\n\ntional Conference on, volume 1, pages 172\u2013179. IEEE, 1994.\n\n[53] Fumin Zhang, Alan O\u2019Connor, Derek Luebke, and PS Krishnaprasad. Experimen-\n\ntal study of curvature-based control laws for obstacle avoidance. In Robotics and\n\nAutomation, 2004. Proceedings. ICRA\u201904. 2004 IEEE International Conference on,\n\nvolume 4, pages 3849\u20133854. IEEE, 2004.\n\n[54] J. Cortes, S. Martinez, T. Karatas, and F. Bullo. Coverage control for mobile\n\nsensing networks. IEEE Transactions on Robotics and Automation, 20(2):243\u2013255,\n\nApril 2004.\n\n[55] F. Abbasi, A. Mesbahi, and J. M. Velni. Coverage control of moving sensor networks\n\nwith multiple regions of interest. In 2017 American Control Conference (ACC),\n\npages 3587\u20133592, May 2017.\n\n[56] S. Chen, C. Li, and S. Zhuo. A distributed coverage algorithm for multi-uav with\n\naverage voronoi partition. In 2017 17th International Conference on Control, Au-\n\ntomation and Systems (ICCAS), pages 1083\u20131086, Oct 2017.\n\n[57] Mac Schwager, Daniela Rus, and Jean-Jacques Slotine. Unifying geometric, proba-\n\nbilistic, and potential field approaches to multi-robot deployment. The International\n\nJournal of Robotics Research, 30(3):371\u2013383, 2011.\n\n[58] Oussama Khatib. Real-time obstacle avoidance for manipulators and mobile robots.\n\nIn Robotics and Automation. Proceedings. 1985 IEEE International Conference on,\n\nvolume 2, pages 500\u2013505. IEEE, 1985.\n\n[59] Lydia E Kavraki, Mihail N Kolountzakis, and J-C Latombe. Analysis of probabilistic\n\nroadmaps for path planning. IEEE Transactions on Robotics and Automation,\n\n14(1):166\u2013171, 1998.\n\n[60] Peter E Hart, Nils J Nilsson, and Bertram Raphael. A formal basis for the heuristic\n\ndetermination of minimum cost paths. IEEE transactions on Systems Science and\n\nCybernetics, 4(2):100\u2013107, 1968.\n\n[61] Franz Aurenhammer. Voronoi diagrams\u2014a survey of a fundamental geometric data\n\nstructure. ACM Computing Surveys (CSUR), 23(3):345\u2013405, 1991.\n\n88\n\n\n\nBIBLIOGRAPHY BIBLIOGRAPHY\n\n[62] Allen Miu. Lecture 7: Voronoi diagrams in computational geometry, September\n\n2001.\n\n[63] Csaba D Toth, Joseph O\u2019Rourke, and Jacob E Goodman. Handbook of discrete and\n\ncomputational geometry. Chapman and Hall/CRC, 2017.\n\n[64] Morgan Quigley, Ken Conley, Brian Gerkey, Josh Faust, Tully Foote, Jeremy Leibs,\n\nRob Wheeler, and Andrew Y Ng. Ros: an open-source robot operating system. In\n\nICRA workshop on open source software, volume 3, page 5. Kobe, Japan, 2009.\n\n[65] Gilberto Echeverria, Nicolas Lassabe, Arnaud Degroote, and Se?verin Lemaignan.\n\nModular open robots simulation engine: Morse. In Robotics and Automation\n\n(ICRA), 2011 IEEE International Conference on, pages 46\u201351. IEEE, 2011.\n\n[66] Jeff Craighead, Robin Murphy, Jenny Burke, and Brian Goldiez. A survey of com-\n\nmercial &amp; open source unmanned vehicle simulators. In Proceedings 2007 IEEE\n\nInternational Conference on Robotics and Automation, pages 852\u2013857. IEEE, 2007.\n\n[67] Adam Harris and James M Conrad. Survey of popular robotics simulators, frame-\n\nworks, and toolkits. In Southeastcon, 2011 Proceedings of IEEE, pages 243\u2013249.\n\nIEEE, 2011.\n\n[68] Patricio Castillo-Pizarro, Toma?s V Arredondo, and Miguel Torres-Torriti. Introduc-\n\ntory survey to open-source mobile robot simulation software. In Robotics Sympo-\n\nsium and Intelligent Robotic Meeting (LARS), 2010 Latin American, pages 150\u2013155.\n\nIEEE, 2010.\n\n[69] Nathan Koenig and Andrew Howard. Design and use paradigms for gazebo, an\n\nopen-source multi-robot simulator. In Intelligent Robots and Systems, 2004.(IROS\n\n2004). Proceedings. 2004 IEEE/RSJ International Conference on, volume 3, pages\n\n2149\u20132154. IEEE, 2004.\n\n[70] Brian Gerkey, Richard T Vaughan, and Andrew Howard. The player/stage project:\n\nTools for multi-robot and distributed sensor systems. In Proceedings of the 11th\n\ninternational conference on advanced robotics, volume 1, pages 317\u2013323, 2003.\n\n[71] Stefano Carpin, Mike Lewis, Jijun Wang, Stephen Balakirsky, and Chris Scrapper.\n\nUsarsim: a robot simulator for research and education. In Robotics and Automation,\n\n2007 IEEE International Conference on, pages 1400\u20131405. IEEE, 2007.\n\n89\n\n\n\nBIBLIOGRAPHY BIBLIOGRAPHY\n\n[72] Mario Prats, Javier Pe?rez, J Javier Ferna?ndez, and Pedro J Sanz. An open source\n\ntool for simulation and supervision of underwater intervention missions. In 2012\n\nIEEE/RSJ International Conference on Intelligent Robots and Systems, pages 2577\u2013\n\n2582. IEEE, 2012.\n\n[73] E. Rohmer, S. P. N. Singh, and M. Freese. V-rep: A versatile and scalable robot\n\nsimulation framework. In 2013 IEEE/RSJ International Conference on Intelligent\n\nRobots and Systems, pages 1321\u20131326, Nov 2013.\n\n[74] Olivier Kermorgant. A dynamic simulator for underwater vehicle-manipulators.\n\nIn International Conference on Simulation, Modeling, and Programming for Au-\n\ntonomous Robots, pages 25\u201336. Springer, 2014.\n\n[75] Kevin J DeMarco, Michael E West, and Ayanna M Howard. A simulator for un-\n\nderwater human-robot interaction scenarios. In 2013 OCEANS-San Diego, pages\n\n1\u201310. IEEE, 2013.\n\n[76] Thomas Tosik and Erik Maehle. Mars: A simulation environment for marine\n\nrobotics. In Oceans-St. John\u2019s, 2014, pages 1\u20137. IEEE, 2014.\n\n[77] Musa Morena Marcusso Manha?es, Sebastian A. Scherer, Martin Voss, Luiz Ricardo\n\nDouat, and Thomas Rauschenbach. UUV simulator: A gazebo-based package for\n\nunderwater intervention and multi-robot simulation. In OCEANS 2016 MTS/IEEE\n\nMonterey. IEEE, sep 2016.\n\n[78] Andreas Birk, Gianluca Antonelli, Andrea Caiti, Giuseppe Casalino, Giovanni In-\n\ndiveri, Antonio Pascoal, and Andrea Caffaz. The co 3 auvs (cooperative cognitive\n\ncontrol for autonomous underwater vehicles) project: overview and current pro-\n\ngresses. In OCEANS 2011 IEEE-Spain, pages 1\u201310. IEEE, 2011.\n\n[79] Pedro J Sanz, Mario Prats, Pere Ridao, David Ribas, Gabriel Oliver, and Alberto\n\nOrtiz. Recent progress in the rauvi project: A reconfigurable autonomous under-\n\nwater vehicle for intervention. In Elmar, 2010 Proceedings, pages 471\u2013474. IEEE,\n\n2010.\n\n[80] Pedro J Sanz, Pere Ridao, Gabriel Oliver, Giuseppe Casalino, Yvan Petillot, Carlos\n\nSilvestre, Claudio Melchiorri, and Alessio Turetta. Trident an european project\n\ntargeted to increase the autonomy levels for underwater intervention missions. In\n\nOceans-San Diego, 2013, pages 1\u201310. IEEE, 2013.\n\n90\n\n\n\nBIBLIOGRAPHY BIBLIOGRAPHY\n\n[81] Daniel Cook, Andrew Vardy, and Ron Lewis. A survey of auv and robot simulators\n\nfor multi-vehicle operations. In Autonomous Underwater Vehicles (AUV), 2014\n\nIEEE/OES, pages 1\u20138. IEEE, 2014.\n\n[82] J. J. Fernandez, J. Perez, A. Penalver, J. Sales, D. Fornas, and P. J. Sanz. Bench-\n\nmarking using UWSim, Simurv and ROS: An autonomous free floating dredging\n\nintervention case study. MTS/IEEE OCEANS 2015 - Genova: Discovering Sus-\n\ntainable Ocean Energy for a New World, 2015.\n\n[83] Jo?rg Kalwa, A Pascoal, Pere Ridao, A Birk, M Eichhorn, L Brignone, M Caccia,\n\nJ Alvez, and RS Santos. The european r&amp;d-project morph: Marine robotic sys-\n\ntems of self-organizing, logically linked physical nodes. IFAC Proceedings Volumes,\n\n45(5):349\u2013354, 2012.\n\n[84] David M Lane, Francesco Maurelli, Tom Larkworthy, Darwin Caldwell, Joaquim\n\nSalvi, Maria Fox, and Konstantinos Kyriakopoulos. Pandora: Persistent auton-\n\nomy through learning, adaptation, observation and re-planning. IFAC Proceedings\n\nVolumes, 45(5):367\u2013372, 2012.\n\n[85] Giorgio Metta, Paul Fitzpatrick, and Lorenzo Natale. Yarp: yet another robot\n\nplatform. International Journal of Advanced Robotic Systems, 3(1):8, 2006.\n\n[86] Weijia Yao, Wei Dai, Junhao Xiao, Huimin Lu, and Zhiqiang Zheng. A simula-\n\ntion system based on ros and gazebo for robocup middle size league. In Robotics\n\nand Biomimetics (ROBIO), 2015 IEEE International Conference on, pages 54\u201359.\n\nIEEE, 2015.\n\n[87] Thomio Watanabe, Gustavo Neves, Ro?mulo Cerqueira, Tiago Trocoli, Marco Reis,\n\nSylvain Joyeux, and Jan Albiez. The rock-gazebo integration and a real-time auv\n\nsimulation. In Robotics Symposium (LARS) and 2015 3rd Brazilian Symposium on\n\nRobotics (LARS-SBR), 2015 12th Latin American, pages 132\u2013138. IEEE, 2015.\n\n[88] Gilberto Echeverria, Nicolas Lassabe, Arnaud Degroote, and Se?verin Lemaignan.\n\nModular open robots simulation engine: MORSE. Proceedings - IEEE International\n\nConference on Robotics and Automation, pages 46\u201351, 2011.\n\n[89] Haris Balta, Silvia Rossi, Salvatore Iengo, Bruno Siciliano, Alberto Finzi, and Geert\n\nDe Cubber. Adaptive behavior-based control for robot navigation: A multi-robot\n\ncase study. In Information, Communication and Automation Technologies (ICAT),\n\n2013 XXIV International Symposium on, pages 1\u20137. IEEE, 2013.\n\n91\n\n\n\nBIBLIOGRAPHY BIBLIOGRAPHY\n\n[90] MAVROS (MAVLink on ROS) - PX4 Developer Guide. https://dev.px4.io/en/\n\nros/mavros_installation.html. Accessed: 2018-06-16.\n\n92"}]}}}