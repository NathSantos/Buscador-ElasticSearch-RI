{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.14168"}, {"@name": "filename", "#text": "20439_ICIP2011.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "SYNTHETIC OCT DATA FOR IMAGE PROCESSING PERFORMANCE TESTING\n\nP. Serranho\n\nIBILI, Faculty of Medicine,\nUniversity of Coimbra,\n\nAzinhaga de Santa Comba, Celas,\n3000-548 Coimbra, Portugal\n\nC. Maduro, T. Santos, J. Cunha-Vaz, R. Bernardes\n\nIBILI, Faculty of Medicine,\nUniversity of Coimbra,\n\nand\nAIBILI, Coimbra, Portugal\n\nABSTRACT\nThe use of synthetic images is needed for testing the perfor-\nmance of image processing methods in order to establish a\nground truth to test performance metrics. However, these syn-\nthetic images do not represent real applications. The aim of\nthis paper is to build a mathematical model to obtain a syn-\nthetic noise-free image mimicking a real Optical Coherence\nTomography (OCT) B-scan or volume from the human retina,\nin order to establish a ground truth for filtering performance\nmetrics in this context. Moreover we also suggest a method\nto add speckle noise to this image based on the speckle noise\nof the given OCT volume. In this way we establish a repli-\ncable method to obtain a ground truth for image processing\nperformance metrics that actually mimics a real case.\n\nIndex Terms\u2014 Optical Coherence Tomography, Retina,\nImage Processing, Synthetic Image, Synthetic Noise.\n\n1. INTRODUCTION\n\nCurrent image processing techniques (eg. despeckling filter-\ning methods) with application to optical coherence tomogra-\nphy (OCT) rely on the respective qualitative evaluation of its\nresults. Qualitative evaluation is usually subjective, since it\ndepends strongly on the expert evaluating the results. On the\nother hand, quantitative approaches are reduced to using syn-\nthetic images which consists of an homogeneous background\nand a set of abstract geometric objects as concentric rings,\nsquares or triangles with smooth or abrupt edges [1, 2] or\nare accepted by the image processing community as Lena or\nthe photographer [3, 4, 5]. These solutions are therefore far\nfrom optimal, since these synthetic images do not represent\nthe features of real medical image data. Approaches for op-\ntical testing using phantoms mimicking tissue have already\nbeen developed [6], however to the best of our knowledge no\napproach has been made in order to obtain a noise-free syn-\nthetic image of the retinal tissue as a ground truth to test the\nperformance of image processing tools nor a noise model for\nOCT speckle.\n\nThis work was partially funded by PTDC/SAU-BEB/103151/2008 and\nprogram COMPETE (FCOMP-01-0124 FEDER-010930).\n\nThe purpose of the paper at hand is to establish a noise-\nfree synthetic image that mimics real OCT data. In this way,\nwe suggest a method to establish a ground truth for the com-\nputation of performance metrics in the context of OCT im-\nage processing tools. We stress that it only makes sense that\na feature as fundamental as the mean square error is com-\nputed if a noise-free ground truth is known. Moreover we\nsuggest a method to mimic the speckle noise present in the\nreal OCT data (as in most optic based mechanisms [7, 8]),\nso that noise can be added to the created synthetic image. In\nthis way we have a complete model for OCT image process-\ning performance metrics, since we establish a realistic ground\ntruth and noise pattern model.\n\nThe computation of the synthetic image relies on features\nof the real OCT data. Each of the considered eye scans was\nprocessed in order to extract required parameters. For healthy\nsubjects, only the segmentation of the inner limiting mem-\nbrane (ILM), the outer segment layer (OSL) and the retinal\npigment epithelium (RPE) is required. We note that for patho-\nlogic eyes, the segmentation of additional structures (cyst,\nepiretinal membrane, macular hole, etc...) to be preserved\nmight also be needed. In each segmented region, OCT data\nis surface fitted using appropriate basis functions. As for the\ncomputation of the noise distribution, we do not aim at mim-\nicking the physical process of speckle formation but to mimic\nthe speckle noise grainy aspect of the given OCT scan. To\nachieve this, we study the intensity distribution in the vitre-\nous. In this area, all the variability is due to noise, and there-\nfore the model for the noise distribution is fitted accordingly,\nhaving in mind the grainy appearance of speckle noise.\n\nThe paper is organized as follows. In section 2 we present\nin detail the method to obtain the synthetic retina and the syn-\nthetic noise. In section 3, we illustrate the results obtained,\nas well as results for the performed statistical tests to support\nthe good performance of the proposed methods. Finally, in\nsection 4 we summarize the results with some conclusions.\n\n2011 18th IEEE International Conference on Image Processing\n\n978-1-4577-1302-6/11/$26.00 \u00a92011 IEEE 409\n\n\n\n2. METHODS\n\nEye scans of 10 healthy volunteers were used following Cir-\nrus OCT (Carl Zeiss Meditec, Dublin, CA, USA) scans using\nboth the 200x200x1024 and the 512x128x1024 Macular Cube\nProtocols.\n\n2.1. Synthetic image\n\nFor each B-scan we consider the segmentation of the ILM, the\ninterface of the upper OSL and the interface between the RPE\nand the choroid, which in our case was performed manually.\nIn this way, the image is divided in four different areas as il-\nlustrated in figure 1 (red contour in the left image). Each area\nis then mapped to the unitary square [0,1]2 such that the left,\nright, upper and lower boundary of each segmented region\nare mapped to the correspondent subsets within the unitary\nsquare of x = 0,x = 1,y = 0 and y = 1, respectively. Ac-\ncording to the variability of the signal in each region, a set of\nbasis functions is chosen in the unitary square in order to fit\nthe given data. For the stability of the solution, we considered\nTikhonov regularization. For instance, as the vitreous is sup-\nposed to be almost constant and this region should vary only\nin depth, we considered a linear approximation\n\nfvitreous(x,y) = a0 + a1x + a2y, x,y ? [0,1],\n\nwhere x is the horizontal direction, y is the depth (vertical)\none and a0,a1,a2 are the coefficients that best fit the given\nOCT data in a least squares sense. The following two regions\n(upper retina and OSL/RPE) present a much higher variabil-\nity, so one needs a higher degree basis. In order to cope with\nhigh oscillations we considered a trigonometric series in each\nof the two regions considered of the form\n\nfretina(x,y) =\n\nK?\nk=0\n\nN?\nn=0\n\nak,n cos(k?x) cos(n?y)\n\n+\n\nK?\nk=0\n\nN?\nn=1\n\nbk,n cos(k?x) sin(n?y)\n\n+\n\nK?\nk=1\n\nN?\nn=0\n\nck,n sin(k?x) cos(n?y)\n\n+\n\nK?\nk=1\n\nN?\nn=1\n\ndk,n sin(k?x) sin(n?y), (1)\n\nfor x,y ? [0,1] with appropriate choices of K and N,\nwhere ak,n,bk,n,ck,n,dk,n are again the coefficients that best\nfit to the given OCT data in each of these regions in a least\nsquares sense. Finally, for the last region (choroid), it is clear\nthat the signal is decreasing in depth y (due to absorption)\nand may vary in the horizontal coordinate x. Hence we chose\n\nan approximation of the form\n\nfchoroid(x,y) =\n\nK?\nk=0\n\nN?\nn=0\n\nak,ne\n??x(x?xk)2??y(2n?1)y, (2)\n\nfor x,y ? [0,1], with appropriate choices of K,N,?x and ?y,\nand xk = k/K, for k = 0,1, . . . ,K, with ak,n being the co-\nefficients that best fit the data for this region in a least square\nsense.\n\n(a) (b) (c)\n\nFig. 1. (a) Original B-scan with given segmented areas; (b)\nobtained synthetic image; (c) Comparison over the retina of\nboth A-scan profiles (green dashed line on (a)).\n\n2.2. Noise model\n\nFor each B-scan we consider a 100\u00d7100 pixel matrix Avitreous\nwithin the vitreous, in which we consider the distribution of\nintensities. We note that in the vitreous no oscillation in the\nsignal intensities is expected, being therefore all the variabil-\nity due to speckle noise. We consider\n\nAnoise = Avitreous ?\u00b5Avitreous,\n\nwhere \u00b5 holds for the mean. It is clear that \u00b5Anoise = 0 and\nthat the standard deviations coincide (?Anoise = ?Avitreous ).\nWe stress that the statistical properties of the OCT speckle\nnoise are represented in Anoise and one can easily determine\nits probability density function.\n\nAs a starting point we create a random matrix B(0) with\nthe same dimensions of the original image and the same den-\nsity probability function of Anoise . In order to get the usual\ngrainy appearance of OCT speckle noise in the synthetic noise\nmatrix, we considered three different scales, namely the orig-\ninal matrix B(0) and the matrices obtained by taking the mean\nin m1 \u00d7n1 (denoted by B(1)) and m2 \u00d7n2 blocks (denoted\nby B(2)). We also considered an outlier matrix in each scale,\ngiven by\n\nO\n(k)\ni,j =\n\n??\n? B\n\n(k)\ni,j ,\n\n???B(k)i,j ??? > 3?B(k)\n0 otherwise,\n\n, k = 0,1,2,\n\n2011 18th IEEE International Conference on Image Processing\n\n410\n\n\n\nwhere ?B(k) is the standard deviation of the entries of B\n(k).\n\nFor each of these scale matrices we considered two low-pass\nGaussian filters h1 and h2 with different standard variation ?1\nand ?2, respectively. Finally, we computed a weighted com-\nbination of these matrices\n\nC(k) = ?1O\n(k) + ?2\n\n(\nB(k) ?h1\n\n)\n+ ?3\n\n(\nB(k) ?h2\n\n)\n, (3)\n\nfor k = 0,1,2, where ? holds for the discrete convolution,\nconsider\n\nM = ?1C\n(0) + ?2C\n\n(1) + ?3C\n(2). (4)\n\nWe note that the sum of both the triplets of the coeffi-\ncients ?i and ?i, i = 1,2,3, should be equal to one. We\nconsider M? = M ?\u00b5M and make\n\nAsynthetic?noise =\n?Anoise\n?M?\n\nM?,\n\nin order to the synthetic noise matrix Asynthetic?noise to have\nthe same global statistics as the real noise matrix Anoise from\nthe OCT data. The results are illustrated in figure 2, show-\ning that both the statistics and the visual appearance of the\noriginal and synthetic noise are similar.\n\n(a) (b) (c)\n\n(d) (e) (f)\n\n(g) (h) (i)\n\nFig. 2. Original noise (top), synthetic noise (middle) and\ncomparison of both probability density functions (bottom)\nwith several signal-to-noise ratios, namely SNR=3 dB (left),\nSNR=7 dB (center) and SNR=10 dB (right).\n\n3. RESULTS\n\nA total of 10 B-scans from 10 healthy eyes were processed\nresulting in the synthetic data representing the major charac-\nteristics of the respective real OCT scans.\n\nHaving in mind the characteristic of the OCT signal in\neach region, we considered K = N = 8 for both regions re-\nferring to fretina in (1) and K = 8,N = 3,?x = 8,?y = 36\nfor fchoroid in (2).\n\nMoreover, for the construction of the matrices B(1)\n\nand B(2) we considered block of size 1 \u00d7 2 and 1 \u00d7 5,\n\nrespectively. We also considered two low-pass Gaussian fil-\nters h1 and h2 such that the first is anisotropic with standard\nvariation ?1 = [0.15,1.5] and the second is isotropic with\nstandard variation ?2 = [0.5,0.5].\n\nFinally, in equations (3) and (4) we considered\n\n?1 = 0.2, ?2 = 0.2, ?3 = 0.6,\n\n?1 = 0.6, ?2 = 0.3, ?3 = 0.1.\n\nIn figure 3 we present the sum of the synthetic B-scan and\nthe synthetic noise in order to compare with the original scan.\nThe main visible difference between the synthetic and orig-\ninal data is at the beginning of the choroid, which is not a\nproblem for the intended application, since the region of in-\nterest is the retina.\n\n(a) (b) (c)\n\nFig. 3. (a) Original OCT B-scan; (b) Synthetic OCT B-scan\nwith synthetic noise added; (c) Comparison of the probability\ndensity function of the intensities of the original (red dashed)\nand synthetic (blue) B-scan.\n\nWe note that the standard variation for the difference\nbetween the original and the noise-free synthetic image\nis 14.29 \u00b1 0.34 (mean \u00b1 std. dev.) while the noise level\nin the vitreous is 10.88 \u00b1 0.27. This shows that the error of\nour approximation is of the same order of magnitude as the\nnoise level.\n\nWe have also compared the probability density functions\nof the intensities of both the original and noisy synthetic im-\nages, which are illustrated in figure 3(c). A Rank-sum test for\nthe comparison of both probability functions for the sample of\ndimension 10 gave p-values 0.37\u00b10.28, which shows that the\ndistribution of intensities is similar in the synthetic and orig-\ninal images. A comparison within each segmented layer is\nalso presented in figure 4. As expected, the main differences\nare presented within the retina, since we force the synthetic\nretina to be smoother than the original signal in order to have\na smooth ground truth.\n\nIn order to validate the synthetic noise model alone, we\nconsidered 100 \u00d7 100 pixel regions of the vitreous of the\noriginal and the correspondent synthetic data. A Rank-sum\nTest for the comparison of the two distribution gave p-values\nof 0.83 \u00b1 0.12 in our 10-dimensional sample, showing that\nthe speckle synthetic model mimics the real one with high ac-\ncuracy. Moreover, the same 20 images were shown to 3 OCT\n\n2011 18th IEEE International Conference on Image Processing\n\n411\n\n\n\n(a) (b)\n\n(c) (d)\n\nFig. 4. Comparison of the probability density function of the\nintensities of the original (red dashed) and synthetic (blue) B-\nscan in each region ((a) Vitreous, (b) Upper Retina, (c) OSL\nand RPE, (d) choroid) for the example shown in figure 3.\n\ntechnicians in order for them to classify them into original or\nsynthetic noise. Results demonstrate the difficulty in correct\nclassification, with 52 misclassifications and only 8 correct\nclassifications out of 60, that is, 86.6% and 13.3%, respec-\ntively. Additionally, out of the 30 classifications of synthetic\nnoise images, 22 were classified as original (73.3%) and only\n8 were classified as synthetic (26.7%). No original noise im-\nage was classified as such, illustrating that the synthetic noise\nimages were very close to the original ones.\n\n4. DISCUSSIONS AND CONCLUSIONS\n\nWe propose a method to generate synthetic OCT data that\nmimics real one. The approach is two-folded. We obtain a\nnoise-free synthetic B-scan that mimics the main features of\na given original one with an appropriate segmentation, in or-\nder to establish a ground truth for processing methods. The\nmethod is designed so that for healthy eyes one only needs\nthe segmentation of 4 areas (that is, 3 interfaces), which can\nbe easily accomplished.\n\nMoreover, we showed the statistic validation of an OCT\nspeckle noise model, based on the characteristics of the given\nreal OCT data. If one adds the synthetic noise and the syn-\nthetic noise-free B-scan generated by our methods, one has\nan adequate synthetic image in the context of OCT processing\nmethods. In this way, this process makes it possible to have a\nquantitative evaluation of the performance of any image pro-\ncessing procedure (eg. filtering) by providing adequate syn-\nthetic data as ground truth.\n\nThese results have been used for testing the performance\nof an improved complex diffusion despeckling method [1]\nsubsequently to its publication. We also intend to apply this\nmethod to pathologic eyes. This extension is straighforward,\n\ngiven that the segmentation of additional structures (eg. cysts,\nepiretinal membranes, macular holes, etc...) is provided. The\npossibility of using less smooth approximation spaces in each\nsegmented region will also be considered.\n\nAcknowledgments\nThe authors would like to thank Dr. Melissa Horne and Carl\nZeiss Meditec (Dublin, CA, USA) for their support on get-\nting access to OCT data, and AIBILI Clinical Trial Center\ntechnicians for their support in managing data, working with\npatients and performing scans.\n\n5. REFERENCES\n\n[1] R. Bernardes, C. Maduro, P. Serranho, A. Arau?jo, S. Bar-\nbeiro, and J. Cunha-Vaz, \u201cImproved adaptive complex\ndiffusion despeckling filter,\u201d Opt. Express, vol. 18, no.\n23, pp. 24048\u201324059, 2010.\n\n[2] H. Salinas and D. Ferna?ndez, \u201cComparison of pde-based\nnonlinear diffusion approaches for image enhancement\nand denoising in optical coherence tomography,\u201d IEEE\nTrans Med Imaging, vol. 26 (6), pp. 761\u2013771, 2007.\n\n[3] G. Gilboa, N. Sochen, and Y. Zeeni, \u201cImage enhancement\nand denoising by complex diffusion processes,\u201d IEEE\nTrans Pattern Anal Mach Intell, vol. 26, no. 8, pp. 1020\n\u20131036, 2004.\n\n[4] P. Perona and J. Malik, \u201cScale-space and edge detection\nusing anisotropic diffusion,\u201d Pattern Analysis and Ma-\nchine Intelligence, IEEE Transactions on, vol. 12, no. 7,\npp. 629 \u2013639, July 1990.\n\n[5] J. Rajan and M.R. Kaimal, \u201cImage denoising using\nwavelet embedded anisotropic diffusion (wead),\u201d IET\nConference Publications, vol. 2006, no. CP522, pp. 589\u2013\n593, 2006.\n\n[6] D.C. Fernandez and H.M. Salinas, \u201cA tissue phantom\nfor investigating volume quantification on retinal images\nobtained with the stratus oct system,\u201d in Engineer-\ning in Medicine and Biology Society, 2004. IEMBS \u201904.\n26th Annual International Conference of the IEEE, 2004,\nvol. 1, pp. 1225 \u20131228.\n\n[7] J. Dainty, A. Ennos, M. Franc?on, J. Goodman, T. McK-\nechnie, G. Parry, and J. Goodman, \u201cStatistical prop-\nerties of laser speckle patterns,\u201d in Laser Speckle\nand Related Phenomena, vol. 9 of Topics in Applied\nPhysics, pp. 9\u201375. Springer Berlin / Heidelberg, 1975,\n10.1007/BFb0111436.\n\n[8] J. W. Goodman, \u201cSome fundamental properties of\nspeckle,\u201d J. Opt. Soc. Am., vol. 66, no. 11, pp. 1145\u2013\n1150, Nov 1976.\n\n2011 18th IEEE International Conference on Image Processing\n\n412"}]}}}