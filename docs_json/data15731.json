{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.19756"}, {"@name": "filename", "#text": "3170_001091559.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNIVERSIDADE FEDERAL DO RIO GRANDE DO SUL \n\nESCOLA DE ENGENHARIA \n\nDEPARTAMENTO DE ENGENHARIA QU\u00cdMICA \n\nENG07053 - TRABALHO DE DIPLOMA\u00c7\u00c3O EM ENGENHARIA \nQU\u00cdMICA  \n\n \n\n \n\n  \n\n \n\n \n\n \n\nD e s e n v o l v i m e n t o  d e  \nA n a l i s a d o r  V i r t u a l  p a r a  \n\nP r e d i \u00e7 \u00e3 o  d a  P r e s s \u00e3 o  d e  F u n d o  \ne m  P o \u00e7 o s  d e  P e t r \u00f3 l e o  \n\nU t i l i z a n d o  R e d e  N e u r a l  \n \n\n \n\n \n\n \n\n \n\n \n\nAutor: Norton Fait\u00e3o Farias \n\nOrientador: Marcelo Farenzena \n\nCoorientador: J\u00f4nathan Dambros \n\n \n\n \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\nii \n\n \n\nPorto Alegre, dezembro de 18 \n\nSu m\u00e1 r i o  \n\nSum\u00e1rio ii \n\nAgradecimentos iii \n\nResumo iv \n\nLista de Figuras v \n\nLista de Tabelas vi \n\n1 Introdu\u00e7\u00e3o 1 \n\n2 Revis\u00e3o Bibliogr\u00e1fica 3 \n\n2.1 Extra\u00e7\u00e3o e produ\u00e7\u00e3o de petr\u00f3leo 3 \n\n2.1.1 Sistema de extra\u00e7\u00e3o offshore 3 \n2.1.2 Escoamento multif\u00e1sico e golfadas 3 \n2.1.3 Sensores para controle 5 \n\n2.2 Analisadores Virtuais 5 \n\n2.3 Modelo de rede neural 9 \n\n2.3.1 Hiperpar\u00e2metros 2 \n\n2.4 M\u00e9todo de regress\u00e3o linear 5 \n\n2.5 Estruturas de redes neurais aplicadas \u00e0 predi\u00e7\u00e3o da Ppdg em sistemas offshore\n 6 \n\n3 Materiais e M\u00e9todos 7 \n\n3.1 Desenvolvimento do Soft Sensor 7 \n\n3.1.1 Primeira inspe\u00e7\u00e3o de dados sele\u00e7\u00e3o de dados hist\u00f3ricos 7 \n3.1.2 Pr\u00e9-tratamento dos dados 8 \n3.1.3 Sele\u00e7\u00e3o, treinamento e valida\u00e7\u00e3o do modelo 9 \n\n4 Resultados 10 \n\n5 Conclus\u00f5es e Trabalhos Futuros 15 \n\n6 Refer\u00eancias 16 \n\n \n\n \n\n \n\n \n\n  \n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias iii \n\nAg ra dec i me nto s  \n\n\u00c0 universidade UFRGS e seu corpo docente que me oportunizaram a estrutura base \npara meu aprendizado. \n\nAo meu orientador, pelos ensinamentos, sugest\u00f5es e empenho dedicado \u00e0 elabora\u00e7\u00e3o \ndeste trabalho. \n\nAo meu co-orientador, que mesmo a dist\u00e2ncia e com fuso hor\u00e1rio diferente pode me \nauxiliar, dar suporte e incentivar muito. \n\nObrigado a minha namorada, que mesmo com momentos em que eu estava ausente \ndevido aos estudos, sempre me apoiou e me animou muito nas situa\u00e7\u00f5es de dificuldade. \n\nAos meus pais, pelo amor, incentivo, suporte nos momentos de cansa\u00e7o e apoio \nincondicional. \n\nMeus agradecimentos aos amigos Daniela, Gabriele e Felipe, companheiros de \ntrabalhos, irm\u00e3os na amizade, que fizeram toda a diferen\u00e7a na minha forma\u00e7\u00e3o ? que ir\u00e3o \ncontinuar sempre presentes em minha vida. \n \n\n \n\n \n\n \n\n \n\n  \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\niv \n\nRes um o  \n\nNa explora\u00e7\u00e3o de petr\u00f3leo a melhor vari\u00e1vel para estabiliza\u00e7\u00e3o do fluxo via golfadas \u00e9 \na Press\u00e3o no chamado de Downhole Pressure Gauge (Ppdg). Por\u00e9m este instrumento \u00e9 \ninstalado em ambiente agressivo e, portanto tende a estragar facilmente. Al\u00e9m disso, \ndevido sua localiza\u00e7\u00e3o a manuten\u00e7\u00e3o/substitui\u00e7\u00e3o \u00e9 normalmente invi\u00e1vel \neconomicamente. Sendo assim, uma solu\u00e7\u00e3o para garantir esta medida \u00e9 utilizar como \nsensor um analisador virtual. Nesse contexto, utilizando de um modelo de rede neural \nfeedforward do tipo caixa preta com dados do modelo din\u00e2mico semi-emp\u00edrico \nsimplificado FOWM (Fast Offshore Wells Model), o objetivo do presente trabalho \u00e9 \ndesenvolver um analisador virtual capaz de predizer a Ppdg com o m\u00ednimo erro associado. \nObteve-se como resultado otimizado o modelo com os hiperpar\u00e2metros: otimizador = \nAdadelta, inicializa\u00e7\u00e3o = glorot_normal, ativa\u00e7\u00e3o = relu, N\u00b0 neur\u00f4nios na 1\u00b0 camada = 256 \ne N\u00b0 neur\u00f4nios na 2\u00b0 camada = 0, sendo o coeficiente de determina\u00e7\u00e3o (R\n\n2\n) igual a \n\n0.9998969 e um MSE de 5,02 X 10\n-6\n\n. Indicando assim, que o mesmo \u00e9 capaz de substituir \nem uma planta real o sensor f\u00edsico. Al\u00e9m disso, pode-se observar que um modelo do tipo \ncaixa preta exige que a base de dados contemple a maioria dos cen\u00e1rios que a planta est\u00e1 \nsujeita a operar, tendo em vista que a capacidade preditiva extrapolava do modelo foi \nmuito inferior a capacidade interpolativa, sendo o coeficiente de determina\u00e7\u00e3o da \nextrapola\u00e7\u00e3o inicial igual a 0,659041 e final igual a 0,699827. Por fim, quando testada a \nmesma base de dados no m\u00e9todo cl\u00e1ssico de predi\u00e7\u00e3o, a regress\u00e3o linear, obteve-se \ncomo R\n\n2\n = 0,995022 e o MSE = 2X10\n\n-4\n. Indicando assim, que o m\u00e9todo de rede neural \u00e9 \n\nmais acurado para modelagem preditiva. \n\n \n\n \n\n \n\n \n\n  \n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias v \n\nL ista  de  F ig ura s  \n\nFigura 1: Desenho esquem\u00e1tico de uma plataforma de petr\u00f3leo offshore. Fonte: \nadaptado de Di Meglio et al. (2012). ..................................................................................3 \n\nFigura 2: Representa\u00e7\u00e3o de fluxo multif\u00e1sico horizontal. Fonte: adaptado de Smart e \nSmith (1997). .....................................................................................................................4 \n\nFigura 3: Representa\u00e7\u00e3o esquem\u00e1tica de uma regi\u00e3o suscet\u00edvel ao fen\u00f4meno da golfada \nsevera. Fonte: Ashikawa (2017)..........................................................................................4 \n\nFigura 4: Fluxo de cria\u00e7\u00e3o de um soft sensor. Fonte: adaptado de Kadlec et al. (2009). .....7 \n\nFigura 5: Representa\u00e7\u00e3o a da t\u00e9cnica de valida\u00e7\u00e3o cruzada k-fold cross-validation, com K = \n4. Fonte: adaptado de Bishop (2006)..................................................................................8 \n\nFigura 6: Representa\u00e7\u00e3o de um neur\u00f4nio artificial. Fonte: adaptado de Agatonovic-kustrin \ne Beresford (2000). ............................................................................................................9 \n\nFigura 7: Representa\u00e7\u00e3o de uma rede neural t\u00edpica. Fonte: Adaptado de Deka et. al (2015) \n. .........................................................................................................................................2 \n\nFigura 8: Representa\u00e7\u00e3o da t\u00e9cnica de parada antecipada. Fonte: adaptado de G\u00e9ron \n(2017). ...............................................................................................................................3 \n\nFigura 9: Representa\u00e7\u00e3o da fun\u00e7\u00e3o Sigmoid. Fonte: Autoria pr\u00f3pria. .................................3 \n\nFigura 10: Representa\u00e7\u00e3o da fun\u00e7\u00e3o Tanh. Fonte: Autoria pr\u00f3pria. ....................................3 \n\nFigura 11: Representa\u00e7\u00e3o da fun\u00e7\u00e3o ReLU. Fonte: Autoria pr\u00f3pria. ...................................4 \n\nFigura 12: Representa\u00e7\u00e3o m\u00e9todo de otimiza\u00e7\u00e3o chamado de Gradiente Descendente, \nFonte: adaptado de G\u00c9RON, 2017. .....................................................................................5 \n\nFigura 13:  Varia\u00e7\u00e3o da Ppdg pelo tempo. ..........................................................................8 \n\nFigura 14: Normaliza\u00e7\u00e3o da PPDG. .....................................................................................8 \n\nFigura 15: Avalia\u00e7\u00e3o dos algoritmos de otimiza\u00e7\u00e3o. .........................................................11 \n\nFigura 16: Avalia\u00e7\u00e3o dos m\u00e9todos de inicializa\u00e7\u00e3o. ..........................................................11 \n\nFigura 17: Avalia\u00e7\u00e3o das Fun\u00e7\u00f5es de ativa\u00e7\u00e3o. .................................................................11 \n\nFigura 18: Avalia\u00e7\u00e3o do n\u00famero de neur\u00f4nios totais no modelo, onde no eixo X \u00e9 a soma \ndos numero de neur\u00f4nios na 1\u00aa camada e numero de neur\u00f4nios na 2\u00aa camada al\u00e9m da \nrepresenta\u00e7\u00e3o dos mesmos (numero de neur\u00f4nios na 1\u00aa camada/ numero de neur\u00f4nios \nna 2\u00aa camada). .................................................................................................................12 \n\nFigura 19: Capacidade do modelo em predizer a Ppdg frente aos valores reais. ...............13 \n\nFigura 20: Reta que representa a precis\u00e3o do modelo frente aos valores reais. ...............13 \n\nFigura 21: Precis\u00e3o preditiva extrapolativa do modelo. ....................................................14 \n\n \n\n \n\n \n\n  \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\nvi \n\nL ista  de  Ta be la s  \n\nTabela 1: Dados de entrada do simulador FOWM. .............................................................7 \n\nTabela 2: Hiperpar\u00e2metros utilizados no estudo. ...............................................................9 \n\nTabela 3: Melhores combina\u00e7\u00f5es de hiperpar\u00e2metros do modelo. ..................................10 \n\n \n\n \n\n \n\n \n \n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias 1 \n\n1  I ntr od u\u00e7\u00e3 o  \n\nNos dias atuais o petr\u00f3leo e o g\u00e1s ainda continuam sendo as mais importantes fontes \nde energia em todo o mundo. Mesmo com o aumento dos investimentos no \ndesenvolvimento de novas tecnologias que utilizem de novas fontes de energia, incluindo \nas renov\u00e1veis, ainda assim o mundo ainda ser\u00e1 dependente de petr\u00f3leo e g\u00e1s por muitos \nanos (BRAGA e CAMPOS, 2012). No Brasil, essa import\u00e2ncia ficou ainda mais evidente com \na descoberta de potenciais reservas de grande escala localizadas no Pr\u00e9-Sal. Segundo \nregistro da Petrobr\u00e1s (2014) o segmento de petr\u00f3leo e g\u00e1s natural representam cerca de \n13% no PIB nacional e tem perspectivas de dobrar a atual produ\u00e7\u00e3o petr\u00f3leo at\u00e9 2020. \n\nNo inicio da explora\u00e7\u00e3o de um novo po\u00e7o de petr\u00f3leo, a pr\u00f3pria press\u00e3o do \nreservat\u00f3rio \u00e9 capaz de fazer com que a mistura multif\u00e1sica de \u00f3leo, g\u00e1s e \u00e1gua flua at\u00e9 a \nsuperf\u00edcie. Entretanto com o passar do tempo com o esgotamento das reservas se faz \nnecess\u00e1ria a inje\u00e7\u00e3o de g\u00e1s com o objetivo de reduzir a massa espec\u00edfica da mistura para \nque seja mantido o mesmo fluxo de produ\u00e7\u00e3o (AGUIRRE et. al, 2017). \n\nCom isso, surgem as golfadas severas ou slugging. Esse fen\u00f4meno \u00e9 caracterizado por \nirregularidades do fluxo multif\u00e1sico durante o transporte do reservat\u00f3rio para as \ninstala\u00e7\u00f5es de superf\u00edcie. \u00c9 de forte interesse econ\u00f4mico prever e preveni-lo, j\u00e1 que sua \npresen\u00e7a aumenta o risco operacional, reduz a produtividade e a vida \u00fatil das instala\u00e7\u00f5es  \n(JAHANSHAHI, 2013). \n\nO monitoramento e o controle efetivo do processo s\u00e3o solu\u00e7\u00f5es vi\u00e1veis para atingir \nesse objetivo. Para isso, existem diversos sensores dispon\u00edveis em plataformas, \nentretanto a press\u00e3o mensurada no chamado Permanent Downhole Gauge (Ppdg) \u00e9 a \nmedida que melhor representa a din\u00e2mica dos po\u00e7os de extra\u00e7\u00e3o, principalmente por sua \nlocaliza\u00e7\u00e3o e por estar diretamente ligada \u00e0 estabilidade da produ\u00e7\u00e3o. Todavia essa se \nencontra em local de intenso desgaste e, portanto, tem vida \u00fatil curta (FROTA e DESTRO, \n2006). Al\u00e9m disso, quando \u00e9 poss\u00edvel realizar manuten\u00e7\u00e3o, essa n\u00e3o s\u00f3 \u00e9 de dif\u00edcil acesso, \nexigindo uma log\u00edstica muito onerosa, mas tamb\u00e9m exige que seja parada a produ\u00e7\u00e3o \npara troca do instrumento. \n\nNesse contexto, o objetivo principal do presente trabalho \u00e9 desenvolver um \nanalisador virtual capaz de predizer a Ppdg utilizando redes neurais artificiais. Uma \nvantagem deste tipo de modelagem \u00e9 que ela frequentemente pode ser desenvolvida em \npouco tempo e utilizando dados dispon\u00edveis com um custo muito baixo quando \ncomparado com o desenvolvimento de conventional expert systems. A economia de \ntempo e custo \u00e9 obtida por se substituir o processo de aquisi\u00e7\u00e3o de conhecimento do \nprocesso por treinamento de redes (HERTZ et al., 1991; ZURADA, 1992). Outra vantagem, \n\u00e9 que as redes neurais podem se ajustar com dados hist\u00f3ricos e predizer novas situa\u00e7\u00f5es. \nPortanto, podem ser treinadas para resolver um problema mesmo antes que os \nespecialistas no processo sejam capazes de formular seus conhecimentos de forma \norganizada, completa e consistente (HERTZ et al., 1991; ZURADA, 1992). \n\nOs objetivos espec\u00edficos desse trabalho contemplam: \n\ni) A compara\u00e7\u00e3o de diferentes hiperpar\u00e2metros da rede a fim de estimar o modelo \notimizado. J\u00e1 que estes par\u00e2metros definem a capacidade da rede neural e, por meio \ndeles, podem-se minimizar os erros associados \u00e0s predi\u00e7\u00f5es. Uma boa compreens\u00e3o dos \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\n2 \n\nefeitos que cada um deles tem sobre o treino de uma rede neural auxilia muito na \nelabora\u00e7\u00e3o de um modelo eficaz (G\u00c9RON, 2017). \n\nii) Estimar a capacidade preditiva interpolativa e extrapolativa do mesmo para que se \ntenha conhecimento da necessidade de dados que a base deve conter. \n\niii) A compara\u00e7\u00e3o do m\u00e9todo de predi\u00e7\u00e3o baseado em rede neural com o m\u00e9todo \ncl\u00e1ssico de regress\u00e3o linear, tendo em vista sua simplicidade, baixo custo operacional e \ntempo para seu desenvolvimento e execu\u00e7\u00e3o. \n\nEste trabalho est\u00e1 estruturado em 5 cap\u00edtulos: o Cap\u00edtulo 1 traz motiva\u00e7\u00f5es e os \nobjetivos do trabalho; o Cap\u00edtulo 2, evidencia aspectos que ser\u00e3o importantes para o \nentendimento do trabalho, desde o funcionamento de um po\u00e7o de extra\u00e7\u00e3o de petr\u00f3leo \nat\u00e9 o desenvolvimento de um analisador virtual; o cap\u00edtulo 3, exp\u00f5e como foi \ndesenvolvido o softsensor e o como ser\u00e3o atingidos os objetivos; o cap\u00edtulo 4, apresenta o \nmelhor conjunto de hiperpar\u00e2metros do modelo, o comparativo entre estes, al\u00e9m de \ngr\u00e1ficos explicativos referentes a capacidade preditiva do resultado mais otimizado; e o \ncap\u00edtulo 5 com as principais conclus\u00f5es do trabalho. \n\n \n\n \n\n  \n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias 3 \n\n2  Rev is\u00e3 o B i bl iog r\u00e1 fi ca  \n\nNeste cap\u00edtulo, ser\u00e3o apresentados os conceitos necess\u00e1rios para uma melhor \ncompreens\u00e3o do trabalho. \n\n2.1 Extra\u00e7\u00e3o e produ\u00e7\u00e3o de petr\u00f3leo  \n\n2.1.1 Sistema de extra\u00e7\u00e3o offshore \n\nUm processo tradicional de extra\u00e7\u00e3o de petr\u00f3leo offshore, como ilustrado na Figura 1, \ninicia-se com a eleva\u00e7\u00e3o, atrav\u00e9s dos tubos de transporte, de uma mistura multif\u00e1sica \ncomposta de petr\u00f3leo, g\u00e1s e \u00e1gua desde os reservat\u00f3rios at\u00e9 as instala\u00e7\u00f5es do fundo do \nmar, pelos po\u00e7os. A pr\u00f3xima etapa, na chamada \u201ccabe\u00e7a do po\u00e7o\u201d encontra-se a \u00e1rvore \nde natal molhada (ANM), onde est\u00e3o presentes os instrumentos de medida e as v\u00e1lvulas \noperadas remotamente, que controlam o fluxo dos fluidos produzidos ou injetados no \npo\u00e7o visando a seguran\u00e7a do processo. Al\u00e9m disso, as ANM re\u00fanem as produ\u00e7\u00f5es de \ndiversos po\u00e7os e realizam o transporte das mesmas por v\u00e1rios quil\u00f4metros, atrav\u00e9s das \nlinhas de produ\u00e7\u00e3o (flowlines) na superf\u00edcie do solo marinho. A eleva\u00e7\u00e3o dos produtos at\u00e9 \na plataforma \u00e9 realizada por meio de dutos verticais denominados risers (DI MEGLIO et \nal., 2012). Por fim, na plataforma est\u00e1 presente a v\u00e1lvula choke que \u00e9 respons\u00e1vel pelo \ncontrole do fluxo de produ\u00e7\u00e3o visando proteger os equipamentos da superf\u00edcie que \ntenham restri\u00e7\u00e3o de press\u00e3o e/ou vaz\u00e3o.  \n\n \n\nFigura 1: Desenho esquem\u00e1tico de uma plataforma de petr\u00f3leo offshore. Fonte: \nadaptado de Di Meglio et al. (2012). \n\n2.1.2 Escoamento multif\u00e1sico e golfadas \n\nUma caracter\u00edstica comum na produ\u00e7\u00e3o de petr\u00f3leo s\u00e3o as irregularidades de fluxo \ndurante o transporte do reservat\u00f3rio para as instala\u00e7\u00f5es de superf\u00edcie. Os principais \nproblemas causados por essas instabilidades de fluxo est\u00e3o ligados ao aumento do risco \noperacional, redu\u00e7\u00e3o do sistema de produ\u00e7\u00e3o, e dificuldades na condu\u00e7\u00e3o dos po\u00e7os para \no funcionamento em condi\u00e7\u00f5es ideais. Quando a produ\u00e7\u00e3o ocorre em um ambiente do \ntipo offshore, os problemas de fluxo tornam-se ainda mais cr\u00edticos (DIEHL et al. 2017). \n\nNa produ\u00e7\u00e3o em \u00e1guas profundas e ultraprofundas, o flowline e o riser s\u00e3o compostos \nde tubos longos distribu\u00eddos em diferentes angula\u00e7\u00f5es. Essa distribui\u00e7\u00e3o, combinada \u00e0 \ndiferen\u00e7a de velocidade, viscosidade e densidade entre as fases gasosa e l\u00edquida pode \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\n4 \n\ncriar instabilidades no fluxo multif\u00e1sico, denominadas golfadas (slug flow), resultando em \nriscos operacionais e redu\u00e7\u00e3o da produ\u00e7\u00e3o (SCHMIDT et al., 1979; FABRE et al., 1990; \nMEGLIO, 2011). Ainda, Di Maglio (2012) afirma que o regime de fluxo multif\u00e1sico \nintermitente/oscilat\u00f3rio ocorre com maior frequ\u00eancia em po\u00e7os de petr\u00f3leo com maior \ntempo de explora\u00e7\u00e3o.   \n\nAs golfadas s\u00e3o caracterizadas por bols\u00f5es de l\u00edquido (slugs) seguidos de bols\u00f5es de \ng\u00e1s. Nos dutos horizontais (flowline) esse fen\u00f4meno, ilustrado na Figura 2, pode ocorrer \ndevido \u00e0 diferen\u00e7a de velocidade entre a fase l\u00edquida e a fase gasosa, e \u00e9 denominado de \ngolfada hidrodin\u00e2mica. Ainda, pela superf\u00edcie irregular do leito marinho, denominado de \ngolfada induzida pelo terreno, onde o l\u00edquido se acumula nas posi\u00e7\u00f5es do duto com \nmenor eleva\u00e7\u00e3o e bloqueia a passagem de g\u00e1s. \n\nJ\u00e1 nos dutos verticais, os risers, quando associados a trechos horizontais \nsubsequentes de inclina\u00e7\u00e3o descendente, situa\u00e7\u00e3o representada na Figura 3, ou \ncondi\u00e7\u00f5es de baixa vaz\u00e3o de produ\u00e7\u00e3o, ocorre \u00e0 chamada golfada severa. Nesta, o l\u00edquido \nimpede a passagem do g\u00e1s que est\u00e1 no trecho inferior, at\u00e9 que este tenha press\u00e3o \nsuficiente para vencer a coluna hidrost\u00e1tica (JAHANSHAHI, 2013). \n\n  \n\nFigura 2: Representa\u00e7\u00e3o de fluxo multif\u00e1sico horizontal. Fonte: adaptado de Smart e \nSmith (1997). \n\n \n\nFigura 3: Representa\u00e7\u00e3o esquem\u00e1tica de uma regi\u00e3o suscet\u00edvel ao fen\u00f4meno da golfada \nsevera. Fonte: Ashikawa (2017). \n\nPara reduzir tal problema, uma das solu\u00e7\u00f5es convencionais \u00e9 reduzir a abertura da \nv\u00e1lvula choke de produ\u00e7\u00e3o, por\u00e9m essa atitude resulta na redu\u00e7\u00e3o da taxa de produ\u00e7\u00e3o \ndo po\u00e7o de petr\u00f3leo. Outra possibilidade \u00e9 aumentar a quantidade do g\u00e1s injetado, \nentretanto isso acarreta em custos mais elevados (JAHANSHAHI, 2012). \n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias 5 \n\nMelhorar essa opera\u00e7\u00e3o \u00e9 um ponto chave para otimizar o lucro do sistema de \nprodu\u00e7\u00e3o. Para alcan\u00e7ar este objetivo, os esfor\u00e7os devem ser concentrados em fornecer \nmelhor opera\u00e7\u00e3o do sistema de produ\u00e7\u00e3o, aumentando o monitoramento, controle e \nconhecimento em tempo real para apoiar decis\u00f5es r\u00e1pidas sobre a opera\u00e7\u00e3o. (DIEHL et \nal., 2017) \n\n2.1.3 Sensores para controle \n\nO primeiro a utilizar t\u00e9cnicas de controle foi Jansen et al. (1999), que fez uso de \nmedi\u00e7\u00f5es de press\u00e3o, vaz\u00e3o ou densidade do fluido como vari\u00e1veis de controle, sendo a \npress\u00e3o do po\u00e7o, denominada de permanent downhole gauge (PDG), a vari\u00e1vel de \ncontrole mais importante. Por\u00e9m, essa medi\u00e7\u00e3o \u00e9 de baixa confiabilidade e n\u00e3o est\u00e1 \ndispon\u00edvel em boa parte dos casos. Portanto, para solucionar esse infort\u00fanio e otimizar o \nprocesso muitos estudos prop\u00f5em sistemas predi\u00e7\u00e3o baseados em analisadores virtuais \n(EIKREM et al., 2004; AAMO et al., 2005).  \n\nPara monitorar e controlar o sistema, dentre muitos sensores dispon\u00edveis em uma \nt\u00edpica plataforma, um dos mais importantes \u00e9 o sensor PDG, pois este tem uma \nlocaliza\u00e7\u00e3o que torna poss\u00edvel a obten\u00e7\u00e3o de valiosos dados para a estabiliza\u00e7\u00e3o do fluxo \nvia golfadas. Todavia, sua localiza\u00e7\u00e3o tamb\u00e9m resulta em muitos inconvenientes, como \ndesgaste intenso, que ocasiona em uma curta vida \u00fatil. Frota e Destro (2006) afirmam que \naproximadamente 30% dos sensores falham em at\u00e9 5 anos ap\u00f3s a instala\u00e7\u00e3o. Outro \nproblema \u00e9 a dificuldade, ou at\u00e9 mesmo a impossibilidade, de substitui\u00e7\u00e3o ou \nmanuten\u00e7\u00e3o dos instrumentos devido \u00e0 sua localiza\u00e7\u00e3o. Al\u00e9m disso, ainda \u00e9 necess\u00e1rio \ninterromper a produ\u00e7\u00e3o para executar essas tarefas, ocasionando grandes perdas \nmonet\u00e1rias. Nesse contexto, analisadores virtuais tornam-se boas alternativas para \naumentar a confiabilidade dos dados e at\u00e9 mesmo, atuar como um substituto em casos \nde falha do sensor (BARBOSA et al., 2015). \n\n \n\n2.2 Analisadores Virtuais  \n\nEm muitas situa\u00e7\u00f5es de controle de processos, devido a limita\u00e7\u00f5es de amostragem e \naus\u00eancia ou perda do sensor desejado, impede-se a detec\u00e7\u00e3o antecipada de dist\u00farbios de \ncarga, como na composi\u00e7\u00e3o do produto de colunas de destila\u00e7\u00e3o e reatores qu\u00edmicos. Isso \npode resultar em grandes desvios dos setpoints e tempos longos de recupera\u00e7\u00e3o de \ndist\u00farbios. Uma das maneiras de solucionar este problema \u00e9 a inser\u00e7\u00e3o das informa\u00e7\u00f5es \nfornecidas por outras vari\u00e1veis facilmente mensur\u00e1veis em analisadores virtuais, a fim de \nfornecer uma estimativa da sa\u00edda controlada. Os resultados estimados podem ser \nutilizados, ent\u00e3o, para o controle total da planta (THAM et al., 1991).  \n\nOs analisadores virtuais tamb\u00e9m s\u00e3o chamados de soft sensor, ou seja, a combina\u00e7\u00e3o \ndas palavras \u201csoftware\u201d, uma vez que os modelos s\u00e3o geralmente programas de \ncomputador e da palavra \u201csensores\u201d, porque os modelos est\u00e3o fornecendo informa\u00e7\u00f5es \nsemelhantes \u00e0s suas contrapartes de hardware (KADLEC et al., 2009). \n\nDentre muitas aplica\u00e7\u00f5es este tipo de sensor pode utilizado como: um modelo de \nprocesso que fornece uma estimativa da vari\u00e1vel desejada a partir das medi\u00e7\u00f5es de \noutras vari\u00e1veis; um modelo de observa\u00e7\u00e3o que explica outra vari\u00e1vel a partir da \nestima\u00e7\u00e3o desejada da vari\u00e1vel anterior e, ent\u00e3o, usada para corrigir a sa\u00edda do tipo de \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\n6 \n\nprocesso; pode, ainda, ser utilizado como um estimador sequencial respons\u00e1vel por \nalimentar as entradas do modelo, ler a sa\u00edda do modelo e calcular os finais ou estimar a \nvari\u00e1vel desejada em cada itera\u00e7\u00e3o (TEIXEIRA et al., 2014). \n\nPodem-se distinguir dois tipos de Soft Sensors de acordo com os princ\u00edpios do modelo \nutilizado, sendo um deles baseado em modelos fenomenol\u00f3gicos e outro baseado em \ndados. Os primeiros s\u00e3o tamb\u00e9m chamados de modelo white-box, pois t\u00eam \nconhecimento fenomenol\u00f3gico sobre o processo, como por exemplo, uso de princ\u00edpios de \npreserva\u00e7\u00e3o de massa, balan\u00e7os energ\u00e9ticos e cin\u00e9ticas de rea\u00e7\u00f5es. Entretanto, este \nmodelo tem muitas desvantagens, s\u00e3o elas:  \n\ni) Requer conhecimento avan\u00e7ado do processo;  \n\nii) Por vezes n\u00e3o h\u00e1 defini\u00e7\u00f5es fenomenol\u00f3gicas suficientes;  \n\niii) Descreve uma base te\u00f3rica do processo, ao inv\u00e9s de condi\u00e7\u00f5es reais; \n\niv) Geralmente centra-se na descri\u00e7\u00e3o do estado estacion\u00e1rio \u00f3timo do processo, \no que nem sempre \u00e9 atingido (KADLEC et al., 2009). \n\nTendo em vista estas desvantagens, os modelos baseados em dados, chamados de \nmodelo black-box, baseiam-se em observa\u00e7\u00f5es do processo, ou seja, medi\u00e7\u00f5es do \nprocesso real da planta que s\u00e3o gravados, armazenados e fornecidos como dados \nhist\u00f3ricos. Este modelo normalmente est\u00e1 dispon\u00edvel para operadores de plantas e \nincorporados em sistemas de controle automatizados. Al\u00e9m disso, \u00e9 muito utilizado para \nm\u00e9todos de diagn\u00f3stico, progn\u00f3stico e apoio \u00e0s decis\u00f5es (KADLEC et al., 2009). Dentre os \nmodelos que utilizam soft sensor do tipo black-box, Kadlec (2009) destaca os m\u00e9todos \npreditivos emp\u00edricos como o Princ\u00edpio de Regress\u00e3o de Componentes Principais e o Multi-\nlayer Perceptron (MLP). \n\nKadlec et al. (2009) descreve, de maneira geral, as etapas e os problemas t\u00edpicos do \nprocedimento de desenvolvimento de Soft Sensor. Esse procedimento segue o fluxo \nconforme a Figura 4. \n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias 7 \n\n \n\nFigura 4: Fluxo de cria\u00e7\u00e3o de um soft sensor. Fonte: adaptado de Kadlec et al. (2009). \n \n\n? Primeira inspe\u00e7\u00e3o de dados \nAo gerar a base de dados podem ocorrer problemas, tanto na estrutura dos dados, \n\nquanto nas vari\u00e1veis. Portanto, neste passo \u00e9 realizada uma an\u00e1lise geral da base \nobjetivando reconhecer os erros prim\u00e1rios, como por exemplo, vari\u00e1veis bloqueadas com \nvalor constante. Assim como compreender a complexidade dos dados para escolha do \nmelhor tipo e especifica\u00e7\u00f5es do modelo (KADLEC et al., 2009). \n\n? Sele\u00e7\u00e3o de dados hist\u00f3ricos \nAqui, ser\u00e3o selecionados os dados que ser\u00e3o treinados, assim como, identificados e \n\nmarcados os dados referentes aos estados estacion\u00e1rios para que sejam utilizados em \numa modelagem adicional. Para modelos din\u00e2micos utiliza-se de lotes representativos ao \ninv\u00e9s da identifica\u00e7\u00e3o dos estacion\u00e1rios (KADLEC et al., 2009). \n\n? Pr\u00e9-processamento de dados \nNo pr\u00e9-processamento, o objetivo \u00e9 transformar a base de dados a fim de que a rede \n\nseja treinada da forma mais eficaz poss\u00edvel, s\u00e3o exemplos desta etapa:  \n\ni) A normaliza\u00e7\u00e3o dos dados para a m\u00e9dia zero e vari\u00e2ncia unit\u00e1ria; \n\nii) A manipula\u00e7\u00e3o de dados perdidos; \n\niii) Detec\u00e7\u00e3o e substitui\u00e7\u00e3o outliers; \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\n8 \n\niv) Sele\u00e7\u00e3o de vari\u00e1veis relevantes. \n\nComo apresentado na Figura 4, o pr\u00e9-processamento \u00e9 iterativo, sendo assim, mesmo \nap\u00f3s as pr\u00f3ximas etapas do modelo, deve-se revisar os dados e atentar aos pontos \nabordados acima (KADLEC et al., 2009). \n\n? Sele\u00e7\u00e3o, treinamento e valida\u00e7\u00e3o do modelo \nEsta \u00e9 a etapa crucial para o desenvolvimento de um soft sensor que atenda os fins \n\nque se destina, pois \u00e9 nela que ser\u00e3o selecionados o tipo de modelo, a divis\u00e3o da base de \ndados, a m\u00e9trica de avalia\u00e7\u00e3o da efici\u00eancia do modelo e os par\u00e2metros utilizados (KADLEC \net al., 2009).  \n\nExistem diversos tipos de modelos, desde os mais cl\u00e1ssicos como o m\u00e9todo de \nregress\u00e3o linear, at\u00e9 m\u00e9todos mais sofisticados como redes neurais. A sua escolha deve \nlevar em considera\u00e7\u00e3o a complexidade do problema, o tempo de desenvolvimento \nrequerido, al\u00e9m da robustez e precis\u00e3o desejadas. \n\nPara se estimar a capacidade preditiva do modelo, dentre v\u00e1rios m\u00e9todos existentes \ndois s\u00e3o mais comumente utilizados. No modelo mais b\u00e1sico basta se dividir a base de \ndados em tr\u00eas grupos: treino, valida\u00e7\u00e3o e teste. Sendo a base de treino utilizada para \ntreinar o modelo, a de valida\u00e7\u00e3o para minimizar o erro de bias e de vari\u00e2ncia, por fim, a \nde teste, para que seja analisado o resultado da predi\u00e7\u00e3o (HASTIE et al., 2008). Essa \nmetodologia \u00e9 bastante simples, contudo utiliza informa\u00e7\u00e3o da base de maneira ineficaz, \nj\u00e1 que parte da base \u00e9 exclusiva para valida\u00e7\u00e3o, al\u00e9m de variar seu resultado de acordo \ncom a parte escolhida para treino e valida\u00e7\u00e3o (JAMES et al., 2013). \n\nOutro m\u00e9todo, bastante utilizado \u00e9 o K-fold cross-validation, representado na Figura \n5, que surge como uma maneira de otimizar o uso das informa\u00e7\u00f5es. Esse consiste em \ndividir a base de maneira aleat\u00f3ria em K partes. K-1 partes s\u00e3o utilizadas para \ntreinamento e a parte remanescente \u00e9 tratada na valida\u00e7\u00e3o, sendo esse processo, ent\u00e3o, \nrepetido para todas K partes (James et al., 2013). Por\u00e9m, \u00e9 necess\u00e1rio escolher com \ncautela o valor de K parcelas, pois com K = N a estimativa \u00e9 aproximadamente imparcial \nem rela\u00e7\u00e3o ao erro de previs\u00e3o, mas pode ter alta vari\u00e2ncia, tendo em vista que os N \n\"conjuntos de treinamento\" s\u00e3o muito semelhantes, al\u00e9m de ser exigida uma carga \ncomputacional elevada para seu processamento. Com isso, Kohavi (1995) ao dividir a base \nem 10 partes obteve o melhor resultado nas estimativas do modelo. \n\n \n\nFigura 5: Representa\u00e7\u00e3o a da t\u00e9cnica de valida\u00e7\u00e3o cruzada k-fold cross-validation, com K = \n4. Fonte: adaptado de Bishop (2006).   \n\nAp\u00f3s decididos os par\u00e2metros, o modelo \u00e9 treinado e validado. A seguir \u00e9 importante \nque se avalie o desempenho do modelo com suas especifica\u00e7\u00f5es. Para avalia\u00e7\u00e3o do \ndesempenho estat\u00edstico, o mais comum \u00e9 empregar o erro quadr\u00e1tico m\u00e9dio (Mean \n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias 9 \n\nSquared Error - MSE), o qual mede a dist\u00e2ncia quadr\u00e1tica entre o valor estimado ( ) e o \nvalor correto ( ) ponderado pelo n\u00famero de termos (n), conforme a Equa\u00e7\u00e3o 1: \n\n                                                       \n \n\n \n?           \n\n \n                                               Equa\u00e7\u00e3o (1) \n\n? Manuten\u00e7\u00e3o \nPor fim, ap\u00f3s o desenvolvimento e implanta\u00e7\u00e3o do Soft Sensor, ele deve ser mantido \n\nem observa\u00e7\u00e3o e ajustado regularmente, por meio de compensa\u00e7\u00e3o num\u00e9rica. E caso o \ndesempenho do Soft Sensor se deteriore com o passar do tempo o modelo ter\u00e1 que ser \nadaptado ou, at\u00e9 mesmo, redesenvolvido (KADLEC et al., 2009). \n\n \n\n2.3 Modelo de rede neural  \n\nAs redes neurais artificiais originalmente surgiram com o objetivo de construir \nmodelos computacionais motivados pela opera\u00e7\u00e3o similar a de neur\u00f4nios biol\u00f3gicos, ou \nseja, as unidades b\u00e1sicas de processamento de informa\u00e7\u00e3o em sistemas nervosos. \n(KADLEC et al., 2009). \n\nO neur\u00f4nio artificial \u00e9 um importante componente de constru\u00e7\u00e3o da rede neural. \nNele, os sinais que chegam (entradas), associados aos pesos de conex\u00e3o (ajustados no \ntreinamento do modelo) s\u00e3o somados/combinados e transformados por uma fun\u00e7\u00e3o de \ntransfer\u00eancia, ou fun\u00e7\u00e3o de ativa\u00e7\u00e3o, para produzir a sa\u00edda do neur\u00f4nio, conforme \nilustrado na Figura 6 (AGATONOVIC-KUSTRIN e BERESFORD, 2000). \n\n \n\nFigura 6: Representa\u00e7\u00e3o de um neur\u00f4nio artificial. Fonte: adaptado de Agatonovic-kustrin \ne Beresford (2000).   \n\nArquiteturas de redes neurais s\u00e3o tipicamente organizadas por camadas. Geralmente \nas camadas s\u00e3o divididas em tr\u00eas grupos, como representado na Figura 7: \n\n? Camada de Entrada: onde os dados s\u00e3o inseridos \u00e0 rede; \n\n? Camadas Ocultas ou Intermedi\u00e1rias: onde \u00e9 realizada a maior parte do \nprocessamento da rede neural; \n\n? Camada de Sa\u00edda: onde o resultado final \u00e9 conclu\u00eddo e apresentado. \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\n2 \n\n \n\nFigura 7: Representa\u00e7\u00e3o de uma rede neural t\u00edpica. Fonte: Adaptado de Deka et. al (2015) \n. \n\n \n\n2.3.1 Hiperpar\u00e2metros \n\nOs hiperpar\u00e2metros s\u00e3o par\u00e2metros que ser\u00e3o incorporados apenas pelo algoritmo de \naprendizado e n\u00e3o pelo modelo. Com isso, devem ser definidos anteriormente ao \ntreinamento e permanecem constantes durante o mesmo. A defini\u00e7\u00e3o dos \nhiperpar\u00e2metros \u00e9 uma etapa decisiva na constru\u00e7\u00e3o de uma rede neural, e pode ser a \ndiferen\u00e7a entre a constru\u00e7\u00e3o de uma rede com boa capacidade de predi\u00e7\u00e3o ou n\u00e3o \n(G\u00c9RON, 2017).  \n\nOs principais par\u00e2metros s\u00e3o: \n\n i) N\u00famero de epochs:  \n\n\u00c9 cada rodada de ciclos de itera\u00e7\u00e3o que o algoritmo de aprendizado realiza. Este \nhiperpar\u00e2metro \u00e9 muito importante para determinar o fim do treino, pois enquanto \npassam as epochs o algoritmo aprende e seu erro de previs\u00e3o (RMSE) no conjunto de \ntreinamento naturalmente diminui, assim como o erro de previs\u00e3o no conjunto de \nvalida\u00e7\u00e3o. Entretanto, ap\u00f3s certo tempo, o erro de valida\u00e7\u00e3o para de diminuir e passa a \naumentar. Isso indica que o modelo come\u00e7ou a sobrecarregar os dados de treinamento, \neste fen\u00f4meno \u00e9 chamado de overfitting. Com t\u00e9cnica de parada antecipada basta \ninterromper o treinamento na epoch em que o erro de valida\u00e7\u00e3o atingir o m\u00ednimo ou \nainda, quando alcan\u00e7a um valor limite, suficientemente pequeno que indique \nconverg\u00eancia, como ilustrado na Figura 8 (G\u00c9RON, 2017). \n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias 3 \n\n \n\nFigura 8: Representa\u00e7\u00e3o da t\u00e9cnica de parada antecipada. Fonte: adaptado de G\u00e9ron \n(2017).   \n\nii) Fun\u00e7\u00e3o de ativa\u00e7\u00e3o: \n\nRealiza uma transforma\u00e7\u00e3o n\u00e3o-linear nos dados de entrada, tornando-o modelo \ncapaz de aprender e executar tarefas mais complexas. Al\u00e9m disso, diferencia informa\u00e7\u00f5es \nrecebidas pelo neur\u00f4nio que ser\u00e3o utilizadas/ativadas ou rejeitadas. S\u00e3o utilizados para \nconverter grandes sa\u00eddas das unidades em um valor menor, al\u00e9m de promover a n\u00e3o \nlinearidade na rede (G\u00c9RON, 2017). Segundo G\u00e9ron (2017) ReLu \u00e9 a fun\u00e7\u00e3o que \ngeralmente apresenta melhores resultados e Agatonovic-kustrin  e Beresford (2000) \nafirmam que a mais comumente utilizada \u00e9 a fun\u00e7\u00e3o Sigmoid. Os principais tipos s\u00e3o \n(G\u00c9RON, 2017):  \n\n? Fun\u00e7\u00e3o Sigmoid: \n\n \n\nFigura 9: Representa\u00e7\u00e3o da fun\u00e7\u00e3o Sigmoid. Fonte: Autoria pr\u00f3pria. \n\n? Fun\u00e7\u00e3o Tanh: \n\n \n\nFigura 10: Representa\u00e7\u00e3o da fun\u00e7\u00e3o Tanh. Fonte: Autoria pr\u00f3pria. \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\n4 \n\n? Fun\u00e7\u00e3o ReLU (Rectified Linear Unit): \n\n \n\nFigura 11: Representa\u00e7\u00e3o da fun\u00e7\u00e3o ReLU. Fonte: Autoria pr\u00f3pria. \n\niii) N\u00famero de camadas ocultas: \n\nAs chamadas camadas ocultas (layers) s\u00e3o as estruturas que cont\u00e9m os neur\u00f4nios \nartificiais. Elas s\u00e3o todas as camadas intermedi\u00e1rias entre a camada de entrada e a \ncamada de sa\u00edda. Segundo G\u00e9ron (2017) para muitos problemas apenas uma ou duas \ncamadas ocultas far\u00e1 com que o modelo apresente capacidade preditiva adequada. \nAfirma, tamb\u00e9m, que com apenas uma camada oculta com algumas centenas de \nneur\u00f4nios alcan\u00e7am-se acuracidades superiores a 97%. E ainda, que \u00e9 poss\u00edvel obter \nacuracidades acima de 98% utilizando 2 camadas ocultas com a mesma quantidade total \nde neur\u00f4nios, em aproximadamente mesma quantidade de tempo de treinamento. \nEntretanto, para problemas mais complexos, deve-se gradualmente aumentar o n\u00famero \nde camadas ocultas, sendo o valor limite onde ocorra o overffiting (G\u00c9RON, 2017). \n\niV) N\u00famero de neur\u00f4nios: \n\nO n\u00famero de neur\u00f4nios nas camadas de entrada e sa\u00edda \u00e9 determinado pelo tipo de \nentrada e sa\u00edda que a tarefa requer. Quanto \u00e0s camadas ocultas, uma pr\u00e1tica \u00e9 \ndimension\u00e1-los na forma de um funil, com menos e menos neur\u00f4nios em cada camada \nsucessiva. Essa estrutura tem como base a l\u00f3gica de unir muitos recursos de baixo n\u00edvel \nem menos recursos do alto n\u00edvel. Outra op\u00e7\u00e3o \u00e9 estabelecer um n\u00famero constante de \nneur\u00f4nios por camada oculta (G\u00c9RON, 2017). \n\nPortanto, encontrar a quantidade perfeita de neur\u00f4nios \u00e9 uma tarefa que pode variar \nmuito. Uma abordagem simples para auxiliar na escolha \u00e9 a utiliza\u00e7\u00e3o de um modelo com \nmais camadas e neur\u00f4nios do que o necess\u00e1rio, e a seguir fazer uso da parada \nantecipada, evitando o overfitting (G\u00c9RON, 2017). Para G\u00e9ron (2017), em geral obt\u00e9m-se \nresultados mais efetivos aumentando o n\u00famero de camadas do que o n\u00famero de \nneur\u00f4nios por camada. \n\n \n\nV) M\u00e9todo de otimiza\u00e7\u00e3o:  \n\nEste algoritmo gradualmente reduz uma fun\u00e7\u00e3o erro (por exemplo, MSE) at\u00e9 que est\u00e1 \nconvirja a um m\u00ednimo. O algoritmo mais tradicional, representado na Figura 12 \u00e9 o \nGradiente Descendente, este mede o gradiente local da fun\u00e7\u00e3o de erro em rela\u00e7\u00e3o ao \n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias 5 \n\nvetor de par\u00e2metro ?, e vai na dire\u00e7\u00e3o do gradiente descendente, at\u00e9 que o valor nulo \nseja atingido (neste caso o m\u00ednimo da fun\u00e7\u00e3o). Pode-se destacar tamb\u00e9m outros \nalgoritmos eficientes de otimiza\u00e7\u00e3o, como: AdaGrad, Adam Optimization e Adadelta. \nG\u00e9ron (2017) afirma que na maioria das vezes o otimizador Adam ser\u00e1 a melhor op\u00e7\u00e3o.  \n\n \n\n \n\nFigura 12: Representa\u00e7\u00e3o m\u00e9todo de otimiza\u00e7\u00e3o chamado de Gradiente Descendente, \nFonte: adaptado de G\u00c9RON, 2017.   \n\nVI) M\u00e9todo de inicializa\u00e7\u00e3o:  \n\n\u00c9 o m\u00e9todo que ser\u00e1 utilizado para determinar os pesos (bias) iniciais. Esta etapa \nafeta diretamente a converg\u00eancia do algoritmo de otimiza\u00e7\u00e3o. Podem ocorrer 2 cen\u00e1rios: \ninicializa\u00e7\u00e3o com pesos com valor igual a zero, o que faz com que o modelo seja \nequivalente a um modelo linear, tornando as unidades ocultas sim\u00e9tricas em todas as \nitera\u00e7\u00f5es. Ou ent\u00e3o, para evitar este problema, \u00e9 comumente utilizado inicializa\u00e7\u00f5es \naleat\u00f3rias. Estas podem seguir a distribui\u00e7\u00e3o normal ou m\u00e9todos mais otimizados, como \npor exemplo a inicializa\u00e7\u00e3o proposta por Xavier &amp; Yoshua (2010), onde, os pesos s\u00e3o \ninicializados levando em considera\u00e7\u00e3o o tamanho da camada anterior. Isso auxilia na \nbusca do m\u00ednimo global da fun\u00e7\u00e3o erro com mais rapidez e efici\u00eancia. Os pesos ainda s\u00e3o \naleat\u00f3rios, mas dependem do tamanho da camada anterior de neur\u00f4nios. Isso fornece \numa inicializa\u00e7\u00e3o controlada, e, portanto um gradiente de descida mais r\u00e1pido e eficiente. \n(G\u00c9RON, 2017). \n\nOutro m\u00e9todo otimizado \u00e9 proposto por He et al. (2015), o qual \u00e9 muito semelhante \nao de Xavier &amp; Yoshua (2010), apenas se diferencia pelo acr\u00e9scimo de um fator de \nmultiplicador de valor dois (G\u00c9RON, 2017).. \n\n2.4 M\u00e9todo de regress\u00e3o linear  \n\nModelos lineares foram amplamente desenvolvidos nos prim\u00f3rdios da estat\u00edstica \ncomputadorizada, mas mesmo nos tempos atuais ainda existem boas raz\u00f5es para estud\u00e1-\nlos e us\u00e1-los. Eles s\u00e3o simples e, muitas vezes, fornecem uma descri\u00e7\u00e3o adequada e \ninterpret\u00e1vel de como as entradas afetam a sa\u00eddas. Para fins de predi\u00e7\u00e3o eles, as vezes, \npodem superar alguns dos modelos n\u00e3o-lineares, especialmente em situa\u00e7\u00f5es que \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\n6 \n\ncontenham baixa rela\u00e7\u00e3o sinal-ru\u00eddo ou dados esparsos (HASTIE, TIBSHIRANI &amp; \nFRIEDMAN, 2009).  \n\nA an\u00e1lise de regress\u00e3o \u00e9 um m\u00e9todo que objetiva encontrar uma rela\u00e7\u00e3o funcional \nentre vari\u00e1veis dependentes (resposta) e vari\u00e1veis independentes (preditoras) (FUMO &amp; \nBISWAS, 2015). Neste modelo a fun\u00e7\u00e3o \u00e9 uma equa\u00e7\u00e3o linear e a vari\u00e1vel dependente \npode ser expressa como uma fun\u00e7\u00e3o de vari\u00e1veis independentes segundo a Equa\u00e7\u00e3o 2 \n(BILGILI &amp; SAHIN, 2010): \n\n                                                                                         Equa\u00e7\u00e3o (2) \n\nonde Y \u00e9 vari\u00e1vel dependente, B0 at\u00e9 Bn s\u00e3o par\u00e2metros da equa\u00e7\u00e3o e X1 at\u00e9 Xn s\u00e3o as \nvari\u00e1veis independentes. \n\n2.5 Estruturas de redes neurais aplicadas \u00e0 predi\u00e7\u00e3o da Ppdg em sistemas \noffshore \n\nAtualmente h\u00e1 alguns estudos (EIKREM et al., 2004; AAMO et al. 2005; AGUIRRE et al., \n2017) direcionados a predizer de maneira eficiente a press\u00e3o do po\u00e7o visando o controle \nde processos de extra\u00e7\u00e3o de petr\u00f3leo, dentre estes \u00e9 interessante evidenciar os estudos \nque se utilizam de modelos baseados em redes neurais e quais par\u00e2metros s\u00e3o \nespecificados para prover bons resultados. \n\nNesse contexto, Motke (2017) fez uso de modelo de predi\u00e7\u00e3o baseado em rede neural \ndo tipo feed-foward com duas camadas contendo 200 neur\u00f4nios cada e obteve seu \nmelhor resultado com um coeficiente de determina\u00e7\u00e3o (R\u00b2) igual a 0,98. \n\nPor outro lado, Barbosa et al. (2015), objetivando estudar a din\u00e2mica da PDG, a partir \nde uma estrutura de treinamento da rede composta por multilayers perceptrons com \numa camada contendo dez neur\u00f4nios, fun\u00e7\u00e3o de ativa\u00e7\u00e3o sendo a tangente hiperb\u00f3lica e \numa sa\u00edda de dados linear, p\u00f4de concluir que o modelo \u00e9 suficiente para os fins que se \ndestina.  \n\nPor fim, com o mesmo objetivo, Antonelo et al. (2017) utilizou dados reais de uma \nplataforma oriundos de instrumentos dispostos apenas na parte superior do leito \nmarinho. Como par\u00e2metros de treinamento fez uso do m\u00e9todo de valida\u00e7\u00e3o cross-\nvalidation com 9 parti\u00e7\u00f5es, arbitrariamente 400 neur\u00f4nios, e Echo State Neural como tipo \nde modelo. A partir disso, p\u00f4de, ent\u00e3o, afirmar que mesmo um \u00fanico modelo com tais \nespecifica\u00e7\u00f5es j\u00e1 \u00e9 suficiente para desenvolver um sensor eficiente e robusto para tal \npredi\u00e7\u00e3o. \n\n \n\n \n\n \n\n \n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias 7 \n\n3  M ater ia is e M \u00e9tod os  \n\nEste cap\u00edtulo descreve as etapas do desenvolvimento do Soft Sensor, a escolha da \nplataforma computacional, do tipo de rede neural, do tipo de modelo utilizado e os \nprincipais hiperpar\u00e2metros utilizados. \n\n3.1 Desenvolvimento do Soft Sensor  \n\nA plataforma computacional utilizada para o desenvolvimento do modelo e avalia\u00e7\u00e3o \nda Rede Neural \u00e9 o Python 3.5 juntamente com a biblioteca Keras (CHOLLET, 2015) e o \nbackend TensorFlow (ABADI et al., 2015). \n\nA base de dados utilizada como refer\u00eancia \u00e0s informa\u00e7\u00f5es de um po\u00e7o de petr\u00f3leo, \nforam extra\u00eddas de um modelo din\u00e2mico semi-emp\u00edrico simplificado chamado de FOWM \n(Fast Offshore Wells Model). Este modelo \u00e9 capaz de simular comportamentos din\u00e2micos \ncomplexos como as golfadas e fora baseado em dados dos sistemas de produ\u00e7\u00e3o da \nPetrobras em ambiente offshore de \u00e1guas profundas e ultra profundas (DIEHL et al., \n2017) \n\n3.1.1 Primeira inspe\u00e7\u00e3o de dados sele\u00e7\u00e3o de dados hist\u00f3ricos \n\nPrimeiramente, a base de dados foi extra\u00edda contendo as entradas do modelo FOWM, \nque s\u00e3o: a press\u00e3o do separador (Ps), a abertura da v\u00e1lvula choke (% choke) e a vaz\u00e3o do \ng\u00e1s lift (Gl), e as vari\u00e1veis de sa\u00edda, sendo elas: a press\u00e3o de topo Ryser (Prt) a press\u00e3o na \nbase do Ryser (Prb), a press\u00e3o do topo do Tubing (Ptt) e a press\u00e3o medida no \u201colho\u201d do \npo\u00e7o, a Ppdg.   \n\nForam simulados no Matlab 7.160.001 pontos do FOWM, resultado da combina\u00e7\u00e3o de \n13 varia\u00e7\u00f5es de vaz\u00e3o de g\u00e1s lift, com 11 varia\u00e7\u00f5es de abertura da v\u00e1lvula choke e 5 \nvaria\u00e7\u00f5es da press\u00e3o no separador, como representado na Tabela 1. \n\nTabela 1: Dados de entrada do simulador FOWM. \n\nVaz\u00e3o de g\u00e1s lift (m\n3\n/ dia) Abertura da v\u00e1lvula choke (%) Press\u00e3o do separador (Pa) \n\n145000 1 613250 \n\n150000 3 713250 \n\n155000 5 813250 \n\n160000 7 913250 \n\n165000 9 1013300 \n\n170000 11 \n \n\n175000 13 \n \n\n180000 15 \n \n\n185000 17 \n \n\n190000 19 \n \n\n195000 21 \n \n\n200000 \n  \n\n205000 \n  \n\n \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\n8 \n\nPara ter conhecimento do comportamento da Ppdg com o tempo segue a Figura 13. \nPode-se verificar que se trata de um modelo din\u00e2mico com comportamento semelhante \nat\u00e9 tempo &lt;5860000 s , onde tem-se uma varia\u00e7\u00e3o, seguida de uma estabiliza\u00e7\u00e3o em um \n\u201cpatamar\u201d e assim sucessivamente. Somente ap\u00f3s tempo > 5860000 s, onde a vaz\u00e3o de \ng\u00e1s lift = 145000 m\u00b3/dia, abertura da v\u00e1lvula choke = 19% e Press\u00e3o do separador = \n613250 Pa h\u00e1 mudan\u00e7a do comportamento para uma oscila\u00e7\u00e3o constante (ciclo-limite), \nrepresentando o fen\u00f4meno chamado de golfada. \n\n \n\nFigura 13:  Varia\u00e7\u00e3o da Ppdg pelo tempo. \n\n3.1.2 Pr\u00e9-tratamento dos dados \n\nTendo em vista a dimens\u00e3o da base de dados, o pr\u00e9-tratamento foi realizado no \nsoftware Python. Visando, ent\u00e3o, otimizar o funcionamento do algoritmo de aprendizado \ne, portanto, obter valores mais confi\u00e1veis do modelo optou-se por escalonar as var\u00e1veis \nde tal maneira que estas contivessem grandezas semelhantes. Essa metodologia fora \nempregada, pois \u00e9 prejudicial para o algoritmo de aprendizado multiplicar pesos de \nvari\u00e1veis t\u00e3o distintas como, por exemplo, abertura da v\u00e1lvula choke que varia de 1 a 21 e \nvaz\u00e3o de g\u00e1s lift que est\u00e1 entre 145000 Pa e 205000 Pa.  \n\nEsta padroniza\u00e7\u00e3o foi realizada segundo a Equa\u00e7\u00e3o 3, e a representa\u00e7\u00e3o de tal efeito \npode ser observado na Figura 14, onde a varia\u00e7\u00e3o m\u00e1xima da Ppdg agora \u00e9 de -0,6 at\u00e9 \n0,4. \n\n \n\nFigura 14: Normaliza\u00e7\u00e3o da PPDG. \n\n \n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias 9 \n\n                                                          \n          \n\n              \n                                             Equa\u00e7\u00e3o (3) \n\nonde, V \u00e9 a vari\u00e1vel que ser\u00e1 normalizada. \n\n3.1.3 Sele\u00e7\u00e3o, treinamento e valida\u00e7\u00e3o do modelo \n\nPara o desenvolvimento do modelo foi utilizada a rede neural do tipo feedforward, \ntendo em vista sua recorr\u00eancia em pesquisas (ANTONELO, CAMPONOGARA, &amp; FOSS, \n2017) e sua simplicidade. Al\u00e9m disso, outro recurso usado foi a biblioteca Keras, a qual \ntraz grandes recursos que auxiliam no desenvolvimento do modelo, como fun\u00e7\u00f5es de \nativa\u00e7\u00e3o, m\u00e9tricas e otimizadores. Os dados de entrada utilizados foram todas as \nvari\u00e1veis da base de dados exceto a Ppdg, j\u00e1 que esta \u00e9 a vari\u00e1vel de interesse. \n\nNo presente trabalho 20% da base foi previamente reservada para os testes. Testes \nesses que indicar\u00e3o se o modelo \u00e9 capaz de realizar predi\u00e7\u00f5es mesmo com dados de \nentrada que n\u00e3o foram treinados, ou seja que o modelo nunca \u201cviu\u201d. O restante da base \u00e9 \no conjunto de dados que ser\u00e1 utilizado para o treino e valida\u00e7\u00e3o do modelo. Para o treino \ne valida\u00e7\u00e3o da rede neural, objetivando utilizar a base de maneira otimizada \nimplementou-se o recurso crossvalidation com N = 3. Al\u00e9m disso, visando reduzir o \nconsumo de dados, o tempo e evitar o overffiting, foi utilizada a parada antecipada (early \nstopping). Ou seja, no momento em que a fun\u00e7\u00e3o erro da valida\u00e7\u00e3o come\u00e7ar a aumentar \nnovamente o modelo para, mesmo antes de terminar o n\u00famero total de epochs. \n\nOs hiperpar\u00e2metros testados no estudo s\u00e3o apresentados na Tabela 2, s\u00e3o eles: o \nn\u00famero de neur\u00f4nios da primeira camada, o n\u00famero de neur\u00f4nios da segunda camada, o \nalgoritmo de otimiza\u00e7\u00e3o e o algoritmo de inicializa\u00e7\u00e3o. Como m\u00e9trica da fun\u00e7\u00e3o erro foi \nutilizada a m\u00e9dia do erro ao quadrado (MSE), representada na Equa\u00e7\u00e3o 1. \n\nTabela 2: Hiperpar\u00e2metros utilizados no estudo. \n\n  \nObjetivando obter o conjunto de hiperpar\u00e2metros com o menor erro associado e um \n\nresultado que contemplasse todas as combina\u00e7\u00f5es poss\u00edveis optou-se por utilizar a busca \nchamada de grid search. \n\nAp\u00f3s treinadas e validadas todas a combina\u00e7\u00f5es de hiperpar\u00e2metros, fora realizada \numa an\u00e1lise de qual resultava em menor erro e est\u00e1 combina\u00e7\u00e3o, ent\u00e3o, utilizada para \nimplementa\u00e7\u00e3o no modelo que utilizar\u00e1 como dados de entrada a base de teste \nreservada anteriormente.  \n\nAinda, em uma nova an\u00e1lise, selecionaram-se os 60% intermedi\u00e1rios dados da base \npara treinar, validar e testar novamente o modelo e os demais 20% iniciais e 20% finais da \nbase para testar a precis\u00e3o preditiva extrapolativa do modelo. Ou seja, o quanto o \nmodelo \u00e9 capaz de predizer dados com comportamentos distintos do que o modelo fora \nantes treinado. \n\nHiperpar\u00e2metro\n\nAlgoritmo de otmiza\u00e7\u00e3o SGD, Adagrad, Adadelta, Adam\n\nM\u00e9todo de inicializa\u00e7\u00e3o glorot_normal, he_normal\n\nFun\u00e7\u00e3o ativa\u00e7\u00e3o Relu, tanh, sigmoid, elu\n\nN\u00famero de neur\u00f4nios 1\u00b0 camada 16, 64, 256\n\nN\u00famero de neur\u00f4nios 2\u00b0 camada 0, 16, 64, 256\n\nValor/fun\u00e7\u00f5es\n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\n10 \n\nPor fim, 80% dos dados foram utilizados, aleatoriamente, para constituir a equa\u00e7\u00e3o de \nregress\u00e3o. Ent\u00e3o, permanecendo aleatoriamente selecionados 20% dos dados que foram \ntestados com o uso da equa\u00e7\u00e3o formada. \n\n4  Res ul ta d os  \n\nTreinaram-se 385 modelos e obtiveram-se os valores de MSE de valida\u00e7\u00e3o, conforme \na Tabela 3.  \n\nTabela 3: Melhores combina\u00e7\u00f5es de hiperpar\u00e2metros do modelo. \n\n \nPode-se observar que foram atingidos resultados com erros muito baixos na ordem de \n\n10\n-6\n\n; que os hiperpar\u00e2metros exercem grande influ\u00eancia no resultado do modelo; ainda, \nque os par\u00e2metros estejam correlacionados, ou seja, n\u00e3o basta encontrar a melhor \notimiza\u00e7\u00e3o de um deles e deixa-lo constante para as demais otimiza\u00e7\u00f5es, \u00e9 necess\u00e1rio \ntestar todas a combina\u00e7\u00f5es para posterior compara\u00e7\u00e3o de resultados. \n\nA fim de avaliar impacto individual de cada um dos hiperpar\u00e2metros, selecionaram-se \nos 100 melhores resultados e avaliou-se a frequ\u00eancia em que os par\u00e2metros estavam \npresentes nos mesmos. Evitou-se realizar a m\u00e9dia dos erros, pois algumas combina\u00e7\u00f5es \nn\u00e3o convergiram e, ainda, haveria muitos outliers que comprometeriam a m\u00e9dia. \n\nPara verificar a probabilidade estat\u00edstica de obter bons resultados com: os algoritmos \nde otimiza\u00e7\u00e3o construiu-se o gr\u00e1fico da Figura 15, para os m\u00e9todos de inicializa\u00e7\u00e3o a \nFigura 16 e para as fun\u00e7\u00f5es ativa\u00e7\u00e3o a Figura 17.  \n\nOtmizador Inicializa\u00e7\u00e3o Ativa\u00e7\u00e3o N\u00b0 neur\u00f4nios 1\u00b0 camada N\u00b0 neur\u00f4nios 2\u00b0 camada MSE valida\u00e7\u00e3o\n\n1 Adadelta glorot_normal relu 256 0 4,01E-06\n\n2 SGD glorot_normal relu 256 0 4,60E-06\n\n3 Adagrad he_normal tanh 16 0 5,20E-06\n\n4 Adagrad he_normal sigmoid 64 0 6,61E-06\n\n5 Adagrad glorot_normal sigmoid 16 0 7,63E-06\n\n6 Adagrad glorot_normal tanh 16 0 7,88E-06\n\n7 Adadelta glorot_normal relu 64 0 8,19E-06\n\n8 Adagrad he_normal sigmoid 16 0 8,37E-06\n\n9 Adagrad glorot_normal tanh 256 0 8,65E-06\n\n10 Adagrad he_normal sigmoid 16 64 9,04E-06\n\n11 Adagrad he_normal elu 16 0 9,51E-06\n\n12 Adagrad he_normal relu 64 0 9,57E-06\n\n13 Adagrad glorot_normal elu 16 0 9,79E-06\n\n14 Adagrad he_normal tanh 64 0 1,06E-05\n\n15 Adagrad he_normal sigmoid 256 0 1,09E-05\n\n16 SGD glorot_normal relu 256 256 1,12E-05\n\n17 SGD glorot_normal relu 64 16 1,15E-05\n\n18 Adagrad glorot_normal relu 16 0 1,17E-05\n\n19 Adagrad he_normal sigmoid 64 64 1,17E-05\n\n20 Adagrad glorot_normal sigmoid 64 0 1,29E-05\n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias 11 \n\n \n\nFigura 15: Avalia\u00e7\u00e3o dos algoritmos de otimiza\u00e7\u00e3o. \n\nPode-se observar que a maioria dos melhores resultados obtidos utilizaram como \nalgoritmo de otimiza\u00e7\u00e3o o Adadelta (46%), e ainda que o Adam n\u00e3o \u00e9 efetivo (0%) para \nesta modelagem. Isso est\u00e1 em desacordo com o que \u00e9 proposto por G\u00e9ron (2017), que \nrelata que na maioria dos casos o algoritmo Adam ser\u00e1 a melhor escolha. \n\n  \n\nFigura 16: Avalia\u00e7\u00e3o dos m\u00e9todos de inicializa\u00e7\u00e3o. \n\nNos m\u00e9todos de inicializa\u00e7\u00e3o, pode-se verificar que a varia\u00e7\u00e3o do par\u00e2metro n\u00e3o tem \ngrande impacto sobre a frequ\u00eancia em que est\u00e3o presentes nos melhores resultados \nobtidos. Isso pode ser explicado tendo em vista que o m\u00e9todo he_normal \u00e9 apenas o \nm\u00e9todo glorot_normal multiplicado por um fator igual a 2. \n\n \n\nFigura 17: Avalia\u00e7\u00e3o das Fun\u00e7\u00f5es de ativa\u00e7\u00e3o. \n\nNa avalia\u00e7\u00e3o das fun\u00e7\u00f5es ativa\u00e7\u00e3o a ReLu se mostrou a melhor op\u00e7\u00e3o sendo a melhor \nescolha em 42% dos casos, ou seja, estatisticamente duas vezes mais efetiva do que a \nsegunda colocada Tanh (22%). Assim como sugerido na literatura, em que G\u00e9ron (2017) \ndeclara que ReLu em grande parte dos casos ser\u00e1 a melhor escolha. \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\n12 \n\nCom o objetivo de utilizar-se da menor quantidade de dados poss\u00edveis e realizar o \nestudo no menor tempo, analisou-se o desempenho dos modelos em fun\u00e7\u00e3o do n\u00famero \nde par\u00e2metros, ou seja a soma total dos neur\u00f4nios e obteve-se a Figura 18. \n\n \n\nFigura 18: Avalia\u00e7\u00e3o do n\u00famero de neur\u00f4nios totais no modelo, onde no eixo X \u00e9 a soma \ndos n\u00famero de neur\u00f4nios na 1\u00aa camada e numero de neur\u00f4nios na 2\u00aa camada al\u00e9m da \nrepresenta\u00e7\u00e3o dos mesmos (n\u00famero de neur\u00f4nios na 1\u00aa camada/ n\u00famero de neur\u00f4nios \n\nna 2\u00aa camada). \n\nPode-se constatar que para a complexidade desta base de dados o uso de poucos \npar\u00e2metros \u00e9 mais relevante, tendo em vista que 19% das melhores respostas utilizaram \napenas o m\u00ednimo de 16 neur\u00f4nios na primeira camada e nenhum neur\u00f4nio na segunda, e \nainda que o aumento de par\u00e2metros representa uma redu\u00e7\u00e3o na probabilidade de ser um \nmodelo com erros baixos. Al\u00e9m disso, quando acrescentou-se par\u00e2metros na segunda \ncamada obteve-se redu\u00e7\u00e3o da efic\u00e1cia do modelo, como no ponto 32 (16/16), o qual tem \num total de neur\u00f4nios reduzido e ainda assim \u00e9 menos representativo (12%) em \ncompara\u00e7\u00e3o ao ponto 64 (64/0), 15%, o qual n\u00e3o tem neur\u00f4nios na segunda camada \n\nA seguir, com o resultado otimizado da Tabela 3, utilizando os hiperpar\u00e2metros \notimizador = Adadelta, inicializa\u00e7\u00e3o = glorot_normal, ativa\u00e7\u00e3o = relu, N\u00b0 neur\u00f4nios na 1\u00b0 \ncamada = 256 e N\u00b0 neur\u00f4nios na 2\u00b0 camada = 0 realizou-se a etapa de teste, utilizando a \nbase que estava previamente reservada. Com isso obteve-se as Figura 19 e Figura 20, que \nilustram a capacidade do modelo em predizer a Ppdg frente os dados de teste. Pode-se \nobservar que o modelo \u00e9 capaz de predizer a Ppdg com erro muito baixo, sendo o MSE = \n5,02 X 10\n\n-6\n e o R\u00b2=0,9998969. \n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias 13 \n\n \n\nFigura 19: Capacidade do modelo em predizer a Ppdg frente aos valores de teste. \n\n \n\nFigura 20: Reta que representa a precis\u00e3o do modelo frente aos valores reais. \n\nAinda, pode-se constatar que o modelo ao ser extrapolado perde muito sua \ncapacidade preditiva, como mostrado na Figura 21, pois na parte central da base (onde o \nmodelo foi treinado e validado) o R\u00b2 de teste foi de 0,999891. J\u00e1 na extremidade inicial o \nR\u00b2i = 0,66 e na final R\u00b2f = 0,70. Este fen\u00f4meno pode ser explicado devido ao modelo ser \ndo tipo caixa preta, ou seja, est\u00e1 baseado em dados anteriormente treinados para \npredizer, e neste caso as extrapola\u00e7\u00f5es tem comportamentos distintos dos quais este fora \npreparado para operar. \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\n14 \n\n \n\nFigura 21: Precis\u00e3o preditiva extrapolativa do modelo. \n\nPor fim, foi treinado o modelo baseado no m\u00e9todo de regress\u00e3o linear (RL) e a \nequa\u00e7\u00e3o de predi\u00e7\u00e3o obtida foi a Equa\u00e7\u00e3o 4. O R\n\n2\n obtido foi de 0,995022 e o MSE igual a \n\n2X10\n-4\n\n. Quando comparados os resultados de regress\u00e3o linear e rede neural, pode-se \nverificar que a modelagem de RL oferece resultados menos acurados, tendo em vista seu \nMSE ser 50 vezes maior que o obtido na otimiza\u00e7\u00e3o da rede neural.  \n\nEntretanto, quando comparado o tempo de desenvolvimento e a capacidade \ncomputacional do modelo a RL se mostra mais eficiente. Tendo em vista que o \ndesenvolvimento e otimiza\u00e7\u00e3o da rede neural foi realizado em 7 dias utilizando 3 \ncomputadores com bons processadores, enquanto a RL foi desenvolvida e testada em 20 \nminutos.  \n\n               \n  \n\n                                           \n\n                                            \n                                                                                                                                            Equa\u00e7\u00e3o (4) \n \n\nonde Gl a vaz\u00e3o do g\u00e1s lift, choke \u00e9 % de abertura da v\u00e1lvula choke, Ps  \u00e9 a press\u00e3o do \nseparador, Prt \u00e9 a press\u00e3o de topo Ryser, Prb \u00e9 a press\u00e3o na base do Ryser, Ptt \u00e9 a \npress\u00e3o do topo do Tubing e Ppdg \u00e9 a press\u00e3o medida no \u201colho\u201d do po\u00e7o.   \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias 15 \n\n5  C on cl us \u00f5es  e  Tra ba l ho s F u tur os  \n\nNo presente trabalho, foi desenvolvido e otimizado um modelo de rede neural do tipo \nfeedforward, baseado em vari\u00e1veis facilmente medidas (Vaz\u00e3o de g\u00e1s lift, Ps, Prt, Prb, Ptt, \nabertura da Choke) em uma planta de extra\u00e7\u00e3o de petr\u00f3leo e este se mostrou capaz de \npredizer a Ppdg com erro muito baixo, sendo o MSE observado na valida\u00e7\u00e3o de 4,01 X 10\n\n-\n\n6\n. O melhor resultado foi obtido com a seguinte combina\u00e7\u00e3o de hiperpar\u00e2metros: \n\notimizador = Adadelta, inicializa\u00e7\u00e3o = glorot_normal, ativa\u00e7\u00e3o = relu, N\u00b0 neur\u00f4nios na 1\u00b0 \ncamada = 256 e N\u00b0 neur\u00f4nios na 2\u00b0 camada = 0. \n\nAl\u00e9m disso, foi realizada a verifica\u00e7\u00e3o da efici\u00eancia do modelo frente \u00e0 base de teste, e \no mesmo se mostrou capaz de se adaptar a dados n\u00e3o apresentados anteriormente. \nComprovando ser uma ferramenta muito \u00fatil no caso de uma substitui\u00e7\u00e3o do sensor f\u00edsico \nda Ppdg por um analisador virtual. O coeficiente de determina\u00e7\u00e3o (R\u00b2) da base de testes \nfoi de 0.9998969. \n\nTamb\u00e9m, foram verificados os hiperpar\u00e2metros com a melhor probabilidade de \napresentarem bons resultados para este modelo e conclui-se que para fun\u00e7\u00e3o ativa\u00e7\u00e3o a \nmelhor escolha seria a fun\u00e7\u00e3o ReLu, para o algoritmo de otimiza\u00e7\u00e3o o Adadelta e para o \nm\u00e9todo de inicializa\u00e7\u00e3o o Glorot_normal. Pode-se, ainda, verificar que o aumento do \nn\u00famero total de par\u00e2metros/neur\u00f4nios diminui a efici\u00eancia do modelo. \n\nPara mais, tendo em vista a utiliza\u00e7\u00e3o de um modelo do tipo caixa preta foi observado \numa baixa precis\u00e3o preditiva extrapolativa com R\u00b2i = 0,659041 e R\u00b2f = 0,699827. \nEvidenciando que para operar com este tipo de modelo \u00e9 necess\u00e1rio que se tenha uma \nbase de dados que contemple a maioria dos cen\u00e1rios poss\u00edveis de opera\u00e7\u00e3o. \n\nPor fim, ao testar o modelo de regress\u00e3o linear obteve-se um R\n2\n = 0,995022 e o MSE = \n\n2X10\n-4\n\n. Pode-se constatar que esta modelagem oferece resultados menos precisos, sendo \nseu MSE ser 50 vezes maior que o obtido na otimiza\u00e7\u00e3o da rede neural. Representando, \nassim, que o modelo escolhido para o estudo fornece uma acuracidade muito melhor \nque, at\u00e9 mesmo, os m\u00e9todos cl\u00e1ssicos. Entretanto a RL requer um tempo e uma \ncapacidade computacional muito menor e, dependendo da acuracidade exigida pelo \nprocesso pode ser uma metodologia eficaz. \n\n Sugere-se para trabalhos futuros a modelagem e teste de outros tipos de modelos \ncomo o Filtro de Kalman estendido (EKF) e modelos de \u00e1rvores de decis\u00e3o; al\u00e9m do uso \nde outras estruturas de redes neurais que n\u00e3o foram abordadas no trabalho, como Echo \nState Neural. Ainda, trabalhar com modelagem do tipo caixa cinza ou branca. \n\n \n\n \n\n \n\n \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\n16 \n\n6  Refe r\u00ea nc ia s  \n\nAAMO, O.; EIKREM, G.; SIAHAAN, H.; FOSS, B. Observer design for multiphase flow in \nvertical pipes with gas-lift - theory and experiments. Journal of Process Control, v. 15, p. \n247-257, 2005. \n\nABADI, M.; BARHAM, P.; CHEN, J.; CHEN, Z.; DAVIS, A.; DEAN, J. TensorFlow: Large-\nScale Machine Learning on Heterogeneous Systems, 2015. \n\nAGATONOVIC-KUSTRIN, S. e BERESFORD, R. Review: Basic concepts of artificial neural \nnetwork (ANN) modeling and its application in pharmaceutical research. Journal of \nPharmaceutical and Biomedical Analysis, v. 22, p. 717\u2013727, 2000. \n\nAGUIRRE, L.; TEIXEIRA, B.; BARBOSA, B.; TEIXEIRA, A.; CAMPOS, M.; MENDES, E. \nDevelopment of soft sensors for permanent downhole Gauges in deepwater oil wells. \nControl Engineering Practice, v. 65, p. 83\u201399, 2017. \n\nANTONELO, E. A.; CAMPONOGARA, E.; FOSS, B. Echo State Networks for data-driven \ndownhole pressure estimation in gas-lift oil wells. Neural Networks, v. 85, p. 106-117, \n2017. \n\nASHIKAWA, F. H. Mitiga\u00e7\u00e3o de golfadas em sistemas offshore utilizando modelo \ndin\u00e2mico simplificado. Disserta\u00e7\u00e3o para Escola Polit\u00e9cnica da Universidade de S\u00e3o Paulo, \n2017. \n\nBARBOSA, B. H. G.; GOMES, L. P.; TEIXEIRA, A. F.; AGUIRRE, L. A. Downhole pressure \nestimation using committee machines and neural networks. IFAC-PapersOnLine, v.48, p. \n286\u2013291, 2015. \n\nBARBOSA, B.H.G.; GOMES, L. P.; Teixeira, A. F.; Aguirre, L. A. Downhole Pressure \nEstimation Using Committee Machines and Neural Networks. IFAC Workshop on \nAutomatic Control in Offshore Oil and Gas Production, 2015. \n\nBISHOP, C. M. Pattern Recognition and Machine Learning. New York. 2006. \n\nBRAGA, L. P.; CAMPOS, T. N. A Comparative Study Of Bid Models Adopted By Brazil, Peru, \nColombia And Uruguay To Granting Petroleum Exploration And Production Rights. 5 Journal \nof World Energy Law &amp; Business, v. 99, p. 1-19, 2012. \n\nCHOLLET, F., &amp; others. Keras, 2015. \n\nDEKA, A.; HAMTA, N.; ESMAEILIAN, B.; BEHDAD, S. Predictive Modeling Techniques to \nForecast Energy Demand in the United States: A Focus on Economic and Demographic \nFactors. Journal of Energy Resources Technology, p. 138, 2015. \n\nDI MEGLIO, F. et al. Stabilization of slugging in oil production facilities with or without \nupstream pressure sensors. Journal of Process Control, v. 22, p. 809-822, 2012. \n\nDIEHL, F.; ANZAI, K. T.; ALMEIDA, S. C.; MEIEN, F. V. O.; NETO, S. S.; ROSA, R. V.; \nCAMPOS, C. M. M. M.; REOLON, F.; GEREVINI, G.; RANZAN, C.; FARENZENA, M.; \nTRIERWEILER, J. Fast Offshore Wells Model (FOWM): A practical dynamic model for \n\n\n\nDEQUI / UFRGS \u2013 Norton Fait\u00e3o Farias 17 \n\nmultiphase oil production systems in deepwater and ultra-deepwater scenarios. \nComputers &amp; Chemical Engineering, v. 99, p. 304-313, 2017. \n\nEIKREM, G.O.; IMSLAND, L.; FOSS, B. Stabilization of gas lifted wells based on state \nestimation. In IFAC International Symposium on Advanced Control of Chemical \nProcesses. Hong Kong, China, 2004. \n\nFABRE, J.; PERESSON, L.L.; CORTEVILLE, J.; ODELLO, R.; BOURGEOIS, T. Severe \nsluggingin pipeline/riser systems. SPE Prod. Eng. v. 5, p. 299\u2013305, 1990. \n\nFROTA, H.M.; DESTRO, W. Reliability evolution of permanent downhole gauges for \ncampos basin sub sea wells: A 10-years case study. In 2006 SPE Annual Technical \nConference and Exhibition. Santo Antonio: Society of Petroleum Engineers, 2006. \n\nG\u00c9RON, A. Hands-On Machine Learning with Scikit-Learn and TensorFlow Concepts, \nTools, and Techniques to Build Intelligent Systems. O\u2019 Reilly Media. v.1, 2017. \n\nHASTIE, T.; TIBSHIRANI, R.; FRIEDMAN, J. H. The elements of statistical learning: data \nmining, inference, and prediction. New York: Springer, v.2, 2009. \n\nHASTIE, T.; TIBSHIRANI, R.; FRIEDMAN, J. The elements of statistical learning: Data \nMining, Inference, and Prediction. New York: Springer series in statistics, v.2, 2008. \n\nHE, K. \u201cDelving Deep into Rectifiers: Surpassing Human-Level Performance on \nImageNet Classification.\u201d 2015 IEEE International Conference on Computer Vision (ICCV). \np. 1026-1034, 2015. \n\nHERTZ, J.; KROGH, A.; PALMER, R.G. Introduction to the Theory of Neural \nComputation. Redwood City: Addison-Wesley, 1991. \n\nJAHANSHAHI, E.; SKOGESTAD, S. E.; HANSEN, H. Control structure design forstabilizing \nunstable gas-lift oil wells. 8th IFAC Symposium on AdvancedControl of Chemical \nProcesses, SI \u2013 Furama Riverfront, 2012. \n\nJAHANSHAHI, E. Control Soluctions for Multiphase Flow Linear and nonlinear \napproaches to anti-slug control. Tese de doutorado. Trondheim, 2013. \n\nJAMES, Gareth; WITTEN, Daniela; HASTIE, Trevor; TIBSHIRANI, Robert. An introduction \nto statistical learning. New York: springer, 2013. \n\nJansen, B., Dalsmo, M., Nokleberg, L., Havre, K., Kristiansen, V., and Lemetayer, P. \nAutomatic control of unstable gas lifted wells. In SPE Annual Techni-cal Conference and \nExhibition. Houston, Texas, 1999. \n\nKADLEC, P.; GABRYS, B.; STRANDT, S. Data-driven soft sensors in the process industry. \nv. 33, p. 795\u2013814, 2009. \n\nKOHAVI, Ron. A study of cross-validation and bootstrap for accuracy estimation and \nmodel selection. In: Ijcai. p. 1137-1145, 1995. \n\nMEGLIO, F. Dynamics and Control of Slugging in Oil Production, DoctorateThesis. Paris \nInstitute of Technology, 2011. \n\n\n\n   Desenvolvimento de Analisador Virtual para Predi\u00e7\u00e3o da Press\u00e3o de Fundo em Po\u00e7os de \nPetr\u00f3leo Utilizando Rede Neural \n\n18 \n\nMOTKE M. B. Predi\u00e7\u00e3o de press\u00e3o de fundo em po\u00e7os de petr\u00f3leo via redes neurais. \nURFGS, 2017. \n\nPETROBRAS. Participa\u00e7\u00e3o do setor de petr\u00f3leo e g\u00e1s chega a 13% do PIB brasileiro. \nDispon\u00edvel em:&lt;http://www.petrobras.com.br/fatos-e-dados/participacao-do-setor-de-\npetroleo-e-gas-chega-a-13-do-pib-brasileiro.htm> Acesso em: 16/11/2018 \n\nSCHMIDT, Z.; BRILL, J.P.; BEGGS, D.H. Choking can eliminate severe pipelineslugging. \nOil Gas J. 12, 230\u2013238,  1979. \n\nSMART, J. S.; SMITH, G.S. Pigging and Chemical Treatment for Oil and Gas Pipelines. \nRichardson: Society of Petroleum Engineers, 1997. \n\nTEIXEIRA, B. O.; CASTRO, W. S.; TEIXEIRA, A. F.; AGUIRRE, L. A. Data-driven soft sensor \nof downhole pressure for a gas-lift oil well. Control Engineering Practice, v. 22, p. 34\u201343, \n2014. \n\nTHAM, M. T.; MONTAGUE, C. A.; MORRIS, A. J.; LANT, P. A. Soft sensors for process \nestimation and inferential control. J. Process Control., v.1, p 3-14, 1991. \n\nWILLINGS, M. J.; MONTAGUE, G. A.; DI MASSIMO, C.; THAM, M. T.; MORRIS, A. J. \nArtificial neural networks in process estimation and control. Automatica, v. 28, p. 1181\u2013\n1187, 1992. \n\nXAVIER G., YOSHUA B. Understanding the difficulty of training deep feedforward \nneural networks, p. 249-256, 2010. \n\nZURADA, J. M. Introduction to Artificial Neural Systems. St. Paul, MINN: West \nPublishing Company, 1992."}]}}}