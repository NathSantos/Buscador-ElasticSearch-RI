{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.15803"}, {"@name": "filename", "#text": "22299_Gregio_AndreRicardoAbed_D.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "Andre? Ricardo Abed Gre?gio\n\nMalware Behavior\n\nComportamento de Programas Maliciosos\n\nCampinas\n2012\n\ni\n\n\n\nii\n\n\n\nUniversidade Estadual de Campinas\nFaculdade de Engenharia Ele?trica e de Computac?a?o\n\nAndre? Ricardo Abed Gre?gio\n\nMalware Behavior\n\nComportamento de Programas Maliciosos\n\nDoctorate thesis presented to the School of Electrical and Computer Engineering in partial\nfulfillment of the requirements for the degree of Doctor in Electrical Engineering.\n\nConcentration area: Computer Engineering.\n\nTese de doutorado apresentada a? Faculdade de Engenharia Ele?trica e de Computac?a?o como\nparte dos requisitos exigidos para a obtenc?a?o do t??tulo de Doutor em Engenharia Ele?trica.\n\nA?rea de concentrac?a?o: Engenharia de Computac?a?o.\n\nOrientador (Tutor): Prof. Dr. Mario Jino\nCo-orientador (Co-Tutor): Prof. Dr. Paulo Licio de Geus\n\nEste exemplar corresponde a? versa?o final\nda tese defendida pelo aluno, e orientada\npelo Prof. Dr. Mario Jino.\n\nCampinas\n2012\n\niii\n\n\n\n \n \n \n \n \n \n \n\nFICHA  CATALOGR\u00c1FICA  ELABORADA  PELA  \n  BIBLIOTECA  DA  \u00c1REA  DE  ENGENHARIA  E  ARQUITETURA  -  BAE  -  UNICAMP \n\n \n \n\n \n \n    G861c \n\n \nGr\u00e9gio, Andr\u00e9 Ricardo Abed \n     Comportamento de programas maliciosos / Andr\u00e9 \nRicardo Abed Gr\u00e9gio. --Campinas, SP: [s.n.], 2012. \n \n     Orientador: Mario Jino. \n     Coorientador: Paulo Licio de Geus. \n     Tese de Doutorado - Universidade Estadual de \nCampinas, Faculdade de Engenharia El\u00e9trica e de \nComputa\u00e7\u00e3o. \n \n     1. Redes de computadores - Medidas de seguran\u00e7a.  \n2. Tecnologia da informa\u00e7\u00e3o - Seguran\u00e7a.  3. Software \n- Seguran\u00e7a.  4. Virus de computador.  5. Taxonomia.  \nI. Jino, Mario, 1943-.  II. Geus, Paulo Licio de, 1956-.  \nIII. Universidade Estadual de Campinas. Faculdade de \nEngenharia El\u00e9trica e de Computa\u00e7\u00e3o.  IV. T\u00edtulo. \n \n\n \nT\u00edtulo em Ingl\u00eas: Malware behavior \nPalavras-chave em Ingl\u00eas: Computer networks - Security measures, Information \n\ntechnology - Security, Software - Security, Computer virus, \nTaxonomy \n\n\u00c1rea de concentra\u00e7\u00e3o: Engenharia de Computa\u00e7\u00e3o \nTitula\u00e7\u00e3o: Doutor em Engenharia El\u00e9trica \nBanca examinadora: Mario Jino, Eleri Cardozo, Ricardo Dahab, Adriano Mauro \n\nCansian, Luiz Fernando Rust da Costa Carmo \nData da defesa: 28-11-2012 \nPrograma de P\u00f3s Gradua\u00e7\u00e3o: Engenharia El\u00e9trica \n\niv\n\n\n\nv\n\n\n\nvi\n\n\n\nTo my Family.\n\nvii\n\n\n\nviii\n\n\n\nAcknowledgments\n\nI would like to thank my advisors, Professors Paulo L??cio de Geus and Mario Jino, for support-\ning me during the past years, listening to my frequent complaints and giving me freedom to\npursue my goals. Their advice and ideas were essential not only to glue the pieces of this thesis\ntogether, but to allow me to grow as a scientist and as a better person.\n\nI thank the Brazilian Government, my employer, for investing in me as a researcher.\n\nI thank my former Bachelor and Masters research advisors, Professor Adriano Mauro Can-\nsian and Dr. Rafael Duarte Coelho dos Santos, for their friendship and for always standing by\nmy side since I met them. I also thank Otavio Carlos Cunha da Silva for the very same reasons.\nThey prevented me from \u201croundhouse kicking\u201d people on the road. =]\n\nI also thank my friends, students and research colleagues for all the support, chit-chatting,\nlaughs, coding, paper writing, hamburger eating and the late night coffee time, mainly Vitor\nMonte Afonso, Dario Simo?es Fernandes Filho, Victor Furuse Martins, Isabela Liane de Oliveira,\nRoberto Alves Gallo Filho, Henrique Kawakami, Eduardo Ellery and Alexandre Or Cansian\nBaruque. If I forgot anyone, I am sorry, it is just because my cache is volatile...\n\nI finally thank my family, especially my wife Fabiana, my brother (Ne?), my dad (Bastian) and\nmy mom (Jamile). Their support, patience, love and friendship make my life more meaningful.\n\nix\n\n\n\nx\n\n\n\nOh, so they have Internet on computers now!\n\nHomer Simpson\n\nxi\n\n\n\nxii\n\n\n\nResumo\n\nAtaques envolvendo programas maliciosos (malware) sa?o a grande ameac?a atual\n\na? seguranc?a de sistemas. Assim, a motivac?a?o desta tese e? estudar o comporta-\n\nmento de malware e como este pode ser utilizado para fins de defesa. O principal\n\nmecanismo utilizado para defesa contra malware e? o antiv??rus (AV). Embora seu\n\npropo?sito seja detectar (e remover) programas maliciosos de ma?quinas infectadas,\n\nos resultados desta detecc?a?o prove?em, para usua?rios e analistas, informac?o?es insufi-\n\ncientes sobre o processo de infecc?a?o realizado pelo malware. Ale?m disso, na?o ha? um\n\npadra?o de esquema de nomenclatura para atribuir, de maneira consistente, nomes\n\nde identificac?a?o para exemplares de malware detectados, tornando dif??cil a sua clas-\n\nsificac?a?o. De modo a prover um esquema de nomenclatura para malware e melhorar\n\na qualidade dos resultados produzidos por sistemas de ana?lise dina?mica de malware,\n\npropo?e-se, nesta tese, uma taxonomia de malware com base nos comportamentos\n\npotencialmente perigosos observados durante va?rios anos de ana?lise de exemplares\n\nencontrados em campo. A meta principal desta taxonomia e? ser clara, de simples\n\nmanutenc?a?o e extensa?o, e englobar tipos gerais de malware (worms, bots, spyware).\n\nA taxonomia proposta introduz quatro classes e seus respectivos comportamentos de\n\nalto n??vel, os quais representam atividades potencialmente perigosas. Para avalia?-la,\n\nforam utilizados mais de 12 mil exemplares u?nicos de malware pertencentes a difer-\n\nentes classes (atribu??das por antiv??rus). Outras contribuic?o?es provenientes desta tese\n\nincluem um breve histo?rico dos programas maliciosos e um levantamento das taxono-\n\nmias que tratam de tipos espec??ficos de malware; o desenvolvimento de um sistema\n\nde ana?lise dina?mica para extrair perfis comportamentais de malware; a especializa-\n\nc?a?o da taxonomia para lidar com exemplares de malware que roubam informac?o?es\n\n(stealers), conhecidos como bankers, a implementac?a?o de ferramentas de visualiza-\n\nc?a?o para interagir com trac?os de execuc?a?o de malware e, finalmente, a introduc?a?o de\n\numa te?cnica de agrupamento baseada nos valores escritos por malware na memo?ria\n\ne nos registradores.\n\nPalavras-chave: Seguranc?a de Redes e Computadores. Comportamento de Progra-\n\nmas Maliciosos. Ana?lise Dina?mica de Malware. Taxonomia de Malware. Classifi-\n\ncac?a?o de Malware. Visualizac?a?o de Dados de Seguranc?a.\n\nxiii\n\n\n\nxiv\n\n\n\nAbstract\n\nAttacks involving malicious software (malware) are the major current threats to\n\nsystems security. The motivation behind this thesis is to study malware behavior\n\nwith that purpose. The main mechanism used for defending against malware is the\n\nantivirus (AV) tool. Although the purpose of an AV is to detect (and remove) ma-\n\nlicious programs from infected machines, this detection usually provides insufficient\n\ninformation for users and analysts regarding the malware infection process. Further-\n\nmore, there is no standard naming scheme for consistently labeling detected malware,\n\nmaking the malware classification process harder. To provide a meaningful naming\n\nscheme, as well as to improve the quality of results produced by dynamic analysis\n\nsystems, we propose a malware taxonomy based on potentially dangerous behav-\n\niors observed during several years of analysis of malware found in the wild. The\n\nmain goal of the taxonomy is, in addition to being simple to understand, extend\n\nand maintain, to embrace general types of malware (e.g., worms, bots, spyware).\n\nOur behavior-centric malware taxonomy introduces four classes and their respective\n\nhigh-level behaviors that represent potentially dangerous activities. We applied our\n\ntaxonomy to more than 12 thousand unique malware samples from different classes\n\n(assigned by AV scanners) to show that it is useful to better understand malware\n\ninfections and to aid in malware-related incident response procedures. Other con-\n\ntributions of our work are: a brief history of malware and a survey of taxonomies\n\nthat address specific malware types; a dynamic analysis system to extract behavioral\n\nprofiles from malware; specialization of our taxonomy to handle information stealers\n\nknown as bankers; proposal of visualization tools to interact with malware execution\n\ntraces and, finally, a clustering technique based on values that malware writes into\n\nmemory or registers.\n\nKeywords: Network and Computer Security. Malicious Programs Behavior. Mal-\n\nware Dynamic Analysis. Malware Taxonomy. Malware Classification. Security Data\n\nVisualization.\n\nxv\n\n\n\nxvi\n\n\n\nList of Figures\n\n3.1 Behavioral matrix based on our taxonomy. . . . . . . . . . . . . . . . . . . . . . 32\n\n3.2 Behavioral matrix for M[DU,BI].S[CS]. . . . . . . . . . . . . . . . . . . . . . . . . 33\n\n3.3 Mapping sets of behaviors to their classes and the security principles they violate. 34\n\n4.1 Framework\u2019s overall architecture. . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n\n4.2 Steps to pinpoint suspicious behavior. . . . . . . . . . . . . . . . . . . . . . . . . 40\n\n4.3 Overview of the samples distribution over the classes plus \u201cNone\u201d. . . . . . . . . 45\n\n4.4 Distribution of samples among the possible combinations of classes. . . . . . . . 45\n\n4.5 Amount of samples distributed over multiple classes (percentages rounded up). . 46\n\n4.6 Percentage of samples that presented each of the compiled behaviors. . . . . . . 46\n\n4.7 Discriminant behavior\u2019s matrix for Allaple. . . . . . . . . . . . . . . . . . . . . . 48\n\n4.8 Discriminant behavior\u2019s matrix for Swizzor. . . . . . . . . . . . . . . . . . . . . 49\n\n4.9 Discriminant behavior\u2019s matrix for Atraps. . . . . . . . . . . . . . . . . . . . . . 49\n\n4.10 Discriminant behavior\u2019s matrix for Crypt. . . . . . . . . . . . . . . . . . . . . . 49\n\n4.11 Discriminant behavior\u2019s matrix for Virut. . . . . . . . . . . . . . . . . . . . . . . 51\n\n4.12 Discriminant behavior\u2019s matrix for Hupigon. . . . . . . . . . . . . . . . . . . . . 52\n\n4.13 Screenshot of a Porndialer sample execution. . . . . . . . . . . . . . . . . . . . . 53\n\n4.14 Discriminant behavior\u2019s matrix for Expiro. . . . . . . . . . . . . . . . . . . . . . 53\n\n4.15 Behaviors exhibited by AV-\u201cUNDECIDED\u201d samples. . . . . . . . . . . . . . . . 54\n\n4.16 Behaviors exhibited by AV-\u201cCLEAN\u201d samples. . . . . . . . . . . . . . . . . . . . 55\n\n5.1 Additional Internet banking authentication factors . . . . . . . . . . . . . . . . . 59\n\n5.2 A successful phishing message. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n\n5.3 Banker screen to steal token value. . . . . . . . . . . . . . . . . . . . . . . . . . 62\n\n5.4 Distraction screens to allow an attacker to steal online banks while the user waits. 62\n\n5.5 Banker screen to steal all values from the user\u2019s password table. . . . . . . . . . 63\n\n5.6 Overview of BanDIT. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\n\n5.7 Percentage of banker samples per presented behavior. . . . . . . . . . . . . . . . 68\n\n5.8 BanDIT\u2019s identification results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n\n5.9 Screenshot of BanDIT\u2019s Web site. . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n\n6.1 Timeline and Magnifier tool representing malicious events. . . . . . . . . . . . . 80\n\n6.2 Sequence of selected events (user and automatic). . . . . . . . . . . . . . . . . . 80\n\nxvii\n\n\n\n6.3 Behavioral spirals for \u2018Pincav\u2019 (a) and \u2018Zbot\u2019 (b). . . . . . . . . . . . . . . . . . 82\n\n6.4 Three \u2018Allaple\u2019 worm variants. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\n\n6.5 Visual behavior extracted from four malware families. . . . . . . . . . . . . . . . 83\n\n6.6 Unidentified malware (right) sample visually classified as a known threat (left). . 84\n\n7.1 Steps to produce a data value trace from a sequence of instructions. . . . . . . . 91\n\n7.2 Quick comparison technique in action: forming a new cluster. . . . . . . . . . . 93\n\n7.3 Election of a new leader based on trace length. . . . . . . . . . . . . . . . . . . . 94\n\n7.4 Sample clustered with a previously unclustered sample. . . . . . . . . . . . . . . 95\n\n7.5 Inter-cluster merging being applied to an initial set of clusters. . . . . . . . . . . 96\n\n7.6 Code reuse identification process. . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n\n7.7 Precision and recall of a reduced dataset of 1,000 samples (static clustering). . . 100\n\n7.8 Precision and recall of a reduced dataset of 1,000 samples (dynamic clustering). 101\n\nxviii\n\n\n\nList of Tables\n\n2.1 AV scanner and respective identification label. . . . . . . . . . . . . . . . . . . . 14\n\n2.2 The taxonomy of computer worms proposed by Weaver et al., 2003. . . . . . . . 18\n\n2.3 Summary of the discussed malware taxonomies. . . . . . . . . . . . . . . . . . . 22\n\n3.1 Proposed malware classes, suspicious behaviors and associated labels. . . . . . . 32\n\n4.1 Distribution of malware samples in categories. . . . . . . . . . . . . . . . . . . . 41\n\n4.2 Top 15 unique \u201cUNDECIDED\u201d labels assigned to 1,488 samples. . . . . . . . . . 42\n\n4.3 Top 15 unique \u201cUNDECIDED\u201d individual labels. . . . . . . . . . . . . . . . . . . 42\n\n4.4 Top 15 labeled malware families and their corresponding amount of samples. . . 43\n\n4.5 Remaining labeled malware families and their amount. . . . . . . . . . . . . . . 44\n\n4.6 Allaple: AV-assigned family vs. behavior-centric taxonomy. . . . . . . . . . . . . 48\n\n4.7 Top 15 Behavioral-Centric Taxonomy labels for AV-\u201cUNDECIDED\u201d samples. . . 54\n\n4.8 Top 15 Behavioral-Centric Taxonomy labels for AV-\u201cCLEAN\u201d samples. . . . . . 55\n\n5.1 Distribution of malware samples among Avira-assigned families. . . . . . . . . . 68\n\n5.2 Behaviors presented (columns) by malware families (rows) under manual inspection. 69\n\n6.1 Icons for monitored operations and types. . . . . . . . . . . . . . . . . . . . . . 81\n\n7.1 Quality (Q) and amount (#) of our produced clustering (1,000 samples). . . . . 101\n\n7.2 Precision, Recall and Quality for the three reference clustering sets (T = 70%). . 101\n\n7.3 Blocks of code shared among samples. . . . . . . . . . . . . . . . . . . . . . . . 103\n\n7.4 Similarity scores (S) for static malware code. . . . . . . . . . . . . . . . . . . . . 103\n\n7.5 Shared code rate (%) of malware samples\u2019 pairs and respective AV labels. . . . . 103\n\nxix\n\n\n\nxx\n\n\n\nGlossary\n\nAntivirus A software to protect computers, either by scanning the\nfilesystem in the search for malicious programs or by\nmonitoring system\u2019s activities.\n\nAPI Application Programming Interface, an interface to al-\nlow the communication between software objects.\n\nBackdoor The goal of a backdoor is to allow the remote access\nand/or control of a system. It can be deployed as a stan-\ndalone malicious program that opens a network port,\ncan be a \u201cfeature\u201d embedded (or compiled) into another\nprogram, or it can be a software security flaw.\n\nBanker A type of malicious program whose main intent is to\nsteal Internet Banking information.\n\nBHO Browser Helper Object, a module, or plug-in, to add new\nfunctionalities for an Internet Explorer web browser. A\nmalware sample can load a specially crafted BHO to\nchange its victim\u2019s browser behavior, usually aiming to\nsteal sensitive information.\n\nBotnet A network composed of infected machines and remotely\ncontrolled by an attacker. The intent may vary from\nstealing sensitive data (such as credit card numbers) to\nperforming distributed attacks.\n\nC&amp;C Command and Controller. The \u201cmanager\u201d of a botnet;\nusually a server that launches commands and receives\ninformation from bots.\n\nDownloader A program whose intent is to fetch and install another\npiece of software. In the context of this thesis, download-\ners are small programs that obtain and install malware\nfrom the Internet.\n\nxxi\n\n\n\nDrive-by Download A downloaded performed automatically and stealthily,\nusually without the user\u2019s consent or awareness.\n\nDropper A program that carries malicious code inside itself to\ninstall it on an infected machine.\n\nDynamic Analysis The process of runnning a program under a controlled\nenvironment to monitor its interaction with the operat-\ning system.\n\nHoneyclient A tool that acts as a client (usually a Web browser) and\ninteracts with servers to verify the occurence of attacks.\n\nHooking A technique used to intercept events, calls and/or mes-\nsages aiming to alter or monitor the operating system\u2019s\nbehavior.\n\nLCS Longest Common Subsequence, the longest set of string\nsequences (not consecutive) common to a set of se-\nquences being compared.\n\nMalware Malicious software. A program that perform harmful\nactions or behaves maliciously without the user\u2019s aware-\nness or consent.\n\nPAC Proxy Auto-Config, a file that defines a list of proxy\nservers in browsers so they can choose specific ones ac-\ncording to a certain URL. This type of file may be used\nby attackers to redirect users from legitimate domains\nto compromised servers in order to steal information.\n\nPacker A program used to encrypt or obfuscate another pro-\ngram in a way to make its analysis (or reverse engineer-\ning) difficult.\n\nPhishing A technique used by attackers to lure users into provid-\ning sensitive information, such as credit card numbers\nand credentials.\n\nRegistry A Microsoft Windows database that stores information\nabout settings, configurations and components of the\noperating system.\n\nRootkit A special type of malware that usually operates at the\nkernel level. Rootkits may hide malicious programs, files\nand directories, and network communications. They\nmay also disable security mechanisms and modify the\ninfected system\u2019s behavior.\n\nxxii\n\n\n\nSandbox A controlled environment used to run malicious code\nwithout spreading the infection to other systems or\nthrough the network. In general, malware sandboxes\nare deployed using virtual machines or emulators.\n\nSpyware A type of malware specialized in collecting users\u2019 infor-\nmation (e.g., keystrokes, browsing profiles).\n\nSSDT System Service Dispatch Table, a Microsoft Windows\nkernel structure that contains the addresses of native\nfunctions, or system calls.\n\nStatic Analysis The process of extracting information of a binary file\nwithout running it.\n\nTrojan A computer program that can present legitimate fea-\ntures, but that also has hidden functions whose intent is\nmalicious.\n\nVirus One of the first popular types of malware. A computer\nvirus is a code that appends itself to another program\nand spreads when this infected program is executed.\n\nVMI Virtual Machine Introspection, a tecnique to monitor\ninternal states and events of a virtual machines with-\nout inserting a component inside the virtualized system.\nThus, VMI allows one to \u201cobserve\u201d a VM\u2019s inside infor-\nmation from outside.\n\nVMM Virtual Machine Monitor, a \u201cprobe\u201d inserted in a layer\nlocated between the host and the guest in a virtualiza-\ntion system.\n\nWorm Another popular type of malware, a worm is a program\ncapable of spreading itself autonomously. Worms usu-\nally scan for vulnerable services, exploit them and copy\nthemselves to the compromised machine.\n\nZombie A compromised system that can be remotely controlled\nby an attacker, the owner of a botnet or a C&amp;C. Zombies\nare also known as \u201cbotclients\u201d or simply \u201cbots\u201d.\n\nxxiii\n\n\n\n\n\nContents\n\n1 Introduction 1\n\n1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n\n1.2 Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n\n1.3 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n\n1.4 Thesis Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n\n2 Background and Related Work 9\n\n2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n\n2.2 A Brief History on Malicious Software . . . . . . . . . . . . . . . . . . . . . . . 9\n\n2.3 Confusion in the Battlefield . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n\n2.4 Systematics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n\n2.5 Security-related Taxonomies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n\n2.6 Malware Taxonomies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n\n2.6.1 Viruses, Worms, Trojans . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n\n2.6.2 Botnets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n\n2.6.3 Spyware . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n\n2.6.4 Rootkits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n\n2.6.5 Malware Taxonomies Panorama . . . . . . . . . . . . . . . . . . . . . . . 21\n\n2.7 Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n\n3 A Behavior-Centric Malware Taxonomy 23\n\n3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n\n3.2 Behavioral Aspects of Malware . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n\n3.2.1 Recent Work on Malware Behavior . . . . . . . . . . . . . . . . . . . . . 23\n\n3.3 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n\n3.3.1 Potentially Malicious Behaviors . . . . . . . . . . . . . . . . . . . . . . . 25\n\n3.4 The Proposed Taxonomy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n\n3.4.1 Malware Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n\n3.4.2 Observed Suspicious Behaviors and Related Classes . . . . . . . . . . . . 31\n\n3.5 Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n\nxxv\n\n\n\n4 Evaluation of the Taxonomy 35\n\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n\n4.2 Behavioral Profiling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n\n4.2.1 Malware Analysis Systems . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\n4.2.2 System Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n\n4.2.3 Considerations about the Framework . . . . . . . . . . . . . . . . . . . . 40\n\n4.3 Taxonomy Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n\n4.3.1 Samples Distribution regarding AV Labels . . . . . . . . . . . . . . . . . 41\n\n4.3.2 Types of Behavior and Classes Found . . . . . . . . . . . . . . . . . . . . 43\n\n4.4 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n\n4.4.1 Top AV Labeled Samples vs. Behavior-Centric Taxonomy . . . . . . . . 47\n\n4.4.2 Behavior of Unknown Malware . . . . . . . . . . . . . . . . . . . . . . . 53\n\n4.5 Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n\n5 Malware Detection 57\n\n5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n\n5.2 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n\n5.3 Background: Internet Banking and Bankers . . . . . . . . . . . . . . . . . . . . 59\n\n5.3.1 Hardware Tokens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n\n5.3.2 Password Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n\n5.3.3 Anatomy of a Banker Infection . . . . . . . . . . . . . . . . . . . . . . . 60\n\n5.3.4 Other Works about Bankers . . . . . . . . . . . . . . . . . . . . . . . . . 63\n\n5.4 System Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n\n5.4.1 Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n\n5.4.2 Data Extraction and Dynamic Execution . . . . . . . . . . . . . . . . . . 67\n\n5.5 Empirical Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n\n5.5.1 Observed Behavior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n\n5.5.2 BanDIT Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n\n5.5.3 Infection Tracking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n\n5.5.4 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n\n5.6 Limitations and Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\n\n5.7 Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n\n6 Malware Visualization 75\n\n6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n\n6.2 Interactive, Visual-Aided Tools to Analyze Malware Behavior . . . . . . . . . . . 75\n\n6.2.1 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n\n6.2.2 Data Gathering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n\n6.2.3 Interactive Visualization Tools for Behavioral Analysis . . . . . . . . . . 78\n\n6.2.4 Tests and Analysis of Results . . . . . . . . . . . . . . . . . . . . . . . . 81\n\n6.3 Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\n\nxxvi\n\n\n\n7 Malware Classification 85\n\n7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\n\n7.2 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\n\n7.3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\n\n7.3.1 Static Analysis Approaches . . . . . . . . . . . . . . . . . . . . . . . . . 88\n\n7.3.2 Dynamic Analysis Approaches . . . . . . . . . . . . . . . . . . . . . . . . 88\n\n7.4 Data Value Traces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\n\n7.5 Comparing Traces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91\n\n7.5.1 Step 1: Quick Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n\n7.5.2 Step 2: Full Similarity Computation . . . . . . . . . . . . . . . . . . . . 92\n\n7.6 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n\n7.6.1 Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n\n7.6.2 Code Reuse Identification . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n\n7.7 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n\n7.7.1 Malware Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\n\n7.7.2 Code Reuse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\n\n7.8 Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n\n8 Conclusion 105\n\nA Example of BehEMOT Report 111\n\nBibliography 114\n\nxxvii\n\n\n\nxxviii\n\n\n\nChapter 1\nIntroduction\n\nIn this thesis, we cover several applications regarding malware behavior, such as classification,\n\ndetection, visualization, clustering and so on. Due to this diversity and to the fact that the\n\n\u201cconverging factor\u201d of all applications presented in this text relies on malware behavior, we\n\nchose this thesis\u2019 current short title. However, it does not mean that we cover all aspects of\n\nmalware behavior nor that this thesis is a final word on the subject.\n\n1.1 Motivation\n\nThe dissemination of malicious programs through computer networks, mainly the Internet,\n\nhas been a major threat to the security of interconnected systems. Malicious programs, com-\n\nmonly referred to as malware, can be understood as applications whose development\u2019s intent\n\nis to compromise a system. Those applications are also commonly named as viruses, worms,\n\nTrojans, backdoors, keyloggers, and so on.\n\nThe increasingly growing interaction among several types of devices\u2014notebooks, desktops,\n\nservers, tablets, cell phones, television sets, video game consoles\u2014allied to the wide offer of\n\n(vulnerable) services creates an ideal scenario for attackers. In addition, careless, naive or\n\nunaware users that are continuously online, eager to obtain and to provide information on the\n\nInternet, contribute to the success of malware attacks.\n\nOne of the greatest motivations for malware attacks is the underground economy that is cur-\n\nrently established [53] [68] [145], based on compromised infrastructures renting (e.g., network-\n\nconnected systems that are invaded and remote controlled by attackers, such as botnets), sen-\n\nsitive information stealing (e.g., Internet Banking credentials, usernames and passwords of e-\n\nmail accounts, credit card numbers) [148], unsolicited messages (e.g., spam, fake product of-\n\nfers) [91] [144] and advertisement clicking [146] [90].\n\nMalware threats have been reaching alarming levels so high that even simple activities, such\n\nas Web browsing [29] [40], social networking [149] [170] and the use of cell phones to access the\n\nInternet and run the so-called apps [18] [46] became risky. An article from the IBM Systems\n\nMagazine [70] evaluates the cost of data breaches in several countries to be of millions of dollars\n\nand blames the losses mainly to malware activity.\n\nAs time goes by, it is possible to notice a greater incidence of attacks performed by specific\n\n1\n\n\n\n2 Chapter 1. Introduction\n\ngroups (or \u201cfamilies\u201d) of malware during certain intervals. For instance, in the last few years there\n\nhas been an increase of botnet-related perceived activity, encouraging researchers to perform\n\nattempts (sometimes frustrated) to shut those malicious networks off [147] [171] [136] [32].\n\nThe particular incidence of certain malware families usually causes serious security incidents\n\nwith global proportions, such as the StuxNet [52]. More examples of notorious past incidents\n\ninvolving malware are discussed in Chapter 2.\n\nAlthough malware families tend to exploit the vulnerabilities that are \u201cpopular\u201d at a deter-\n\nmined time frame, it is common that they revisit older attack techniques through the sharing of\n\ncode, and consequently functionalities, which perform those malicious activities, such as scan-\n\nning engines, mutation of code excerpts, hiding mechanisms, etc. This code sharing leads to\n\n\u201cmutations\u201d that can cause the bypass of security barriers and incur in less effective detection\n\nrates for samples belonging to an already known family. However, the mutant sample keeps the\n\nmalicious behavior \u201cinherited\u201d by the malware ancestors.\n\nThus, the mere identification of a program as being a known malware (already collected and\n\nanalyzed, maybe defeated) allows for efficient and effective incident response. The countermea-\n\nsures taken, for its part, can facilitate the damage containment process, decrease losses and\n\nmitigate side infections through security blocking rules and patch application.\n\nCurrently, one of the most popular defense mechanism against malware is still the antivirus\n\n(AV). Basically, an AV is a program that scans files or monitors predefined actions to search\n\nfor evidences of malicious activities occurring in a system. Usually, AV engines rely on two\n\ntechniques to identify malicious programs: pattern matching of signatures against a database\n\nof known malware and heuristics related to certain behaviors observed in malicious programs\n\nwhile compromising a system. In signature-based malware detection, a binary file is usually\n\nbroken into small chunks of code, which are then scanned for patterns within the AV signature\n\ndatabase. Hence, if one or more chunks of the scanned file are found in the signature database as\n\npertaining to a specific malware family, the AV assigns a label identifying the file. In heuristic-\n\nbased detection, a monitored file is executed in a minimal emulator and its behavior is evaluated\n\nto check for known suspicious activities. If an evidence of malicious behavior is found, the AV\n\nlaunches an alert and takes a measure (block, remove, quarantine the suspicious file or leave the\n\ndecision to the user).\n\nThe major issue regarding AV engines is the frequent and increasing rise of malware variants.\n\nMalware variants correspond to previously identified malware families modified until they do\n\nnot match a known signature or until they are able to evade, to compromise or to subvert\n\nthe protection mechanisms in order to remain stealthy. To corroborate this assertive, a US\n\nDHS (Department of Homeland Security) report alleges that \u201cA/V and IDS/IPS approaches\n\nare becoming less effective because malware is becoming increasingly sophisticated (...) Malware\n\npolymorphism is outpacing signature generation and distribution in A/V and IDS/IPS [159].\u201d\n\nVariants usually need to be addressed individually and manually by AV analysts so that they are\n\nable to produce a new detection signature and update their products. In addition to this fact,\n\ndetection heuristics may need modifications to encompass a new variant of a known family; these\n\nchanges should be carefully handled to avoid false-positives or, even worse, false negatives of\n\npreviously known malware. False positives and negatives are another great difficulty regarding\n\n\n\n1.1. Motivation 3\n\nsignature/heuristics generation: the erroneous identification of an inoffensive user application\n\nas malicious may lead to its deletion, blocking or quarantine, causing a \u201cdenial of service\u201d, as\n\nthe decrease of usability is not a desirable feature for AV vendors.\n\nAnother issue that must be taken into account is that malware developers are embedding\n\nself-defense mechanisms to their products, i.e. current malware can disable operating system\n\nnative protection (e.g., firewall, AV, security plugins, updates), can verify if it is under some\n\nkind of analysis and do not present its malicious behavior (e.g., by modifying its execution on-\n\nthe-fly), can be packed in a way that avoids analysis and detection (e.g., checking its integrity\n\nin memory), can disguise itself as a system application, a legitimate software or a fake antivirus,\n\nand so on. Therefore, the tasks of avoiding the disabling of security mechanisms, identifying\n\nmalware in an efficient and accurate way without interfering with users experience, and ex-\n\ntending detection capabilities without causing overheads are becoming harder and harder. The\n\nscenario is not the most favorable either: the malware variants, the social networking exposition\n\nand the variety of potentially malicious applications, the cell phones and tablets becoming closer\n\nto traditional computer system (in processing power and functionality), and the establishment\n\nof cloud computing-based systems contribute to the abundance of \u201cattack points\u201d that lead to\n\nmalware compromise, dissemination and persistence.\n\nApart from those aforementioned issues, the AV developers\u2019 community is still not tied to a\n\ncommon standard to classify detected malware samples. This slows the malware-related incident\n\nresponse procedures, turning them ineffective in certain cases. To illustrate this comment, lets\n\nthink of AV engines that identify a program as being malicious based solely on their packer1.\n\nPacking features or even the identification of one specific facet of the evaluated binary may\n\nlead to wrong assumptions about the extent of its damages or about its attacking behavior.\n\nFor instance, malware samples may be infected by another malware, and the AV will probably\n\ndetect the \u201cinfector\u201d, launching an alert and assigning a misleading label whereas the behavior of\n\nthe \u201cinfected\u201d file, i.e. the actual malware sample, can be missed [163]. Furthermore, diverging\n\nnaming assignments can also confuse classification schemes, as the lack of a common standard\n\nmakes each vendor to assign its own label in its own format. Latter in this thesis we are able\n\nto verify that the same malware sample can be identified as being from distinct classes, families\n\nand versions depending on the AV vendor, all of them formatted in a peculiar manner.\n\nThus, to guarantee that a countermeasure is effective, i.e. to remove the malicious code and\n\nits associated artifacts (objects and changes in the system), we need in most cases a manual\n\nintervention. This is required due to the fact that not all AV engines are able to undo the\n\nperformed actions, as there is not a general procedure that embraces all malware samples in\n\nactivity, and compromised systems are usually not trustworthy anymore. Aside from this,\n\nsome more epidemic malware infections may have removal applications or automated routines\n\navailable, which can be innocuous in face of variants. However, the success of achieving a correct\n\nand functional removal procedure (manual or automated) is unrelated to the label assigned by\n\nan AV engine, which can be the wrong one.\n\nAlthough the usual method of operation of AV engines rely principally on signature-based\n\n1In the scope of this thesis, a packer is a program used to encrypt or compress a malicious file to produce\nan obstacle to detection and analysis techniques. For more information about packers, we point to the work of\nJacob et al. [73].\n\n\n\n4 Chapter 1. Introduction\n\ndetection, there has been an increasing of interest in heuristics. A well-crafted heuristic may\n\nresult in the substitution of dozens of signatures, taking some burden off the AV updating\n\nprocess. However, the generation of an adequate heuristic to identify a malware sample or class\n\nrequires knowledge about the related behavior. This behavior consists of the actions performed\n\non the target operating system, mainly those that denote abnormal, suspicious or dangerous\n\nactivities. Thus, there are dynamic analysis systems that serve as a complementary option to\n\nthe limited emulators present in AV engines. Those systems have been improved and refined in\n\na constant basis, making them a viable option to extract malware behavior. Dynamic malware\n\nanalysis systems leverage several advanced techniques to monitor system by running samples in a\n\ncontrolled environment so as to observe the infection while it is being performed. These systems\n\nare based on several monitoring methods, from the instrumentation of complex emulators to\n\nthe capture of kernel system calls within the target operating system [49].\n\nIt is not unusual that AV vendors develop their own dynamic malware analysis systems to\n\nsell and to make internal use of them\u2014a.k.a sandboxes\u2014or provide financial support to third-\n\nparty developers, but there are also publicly available solutions that can be accessed through\n\nthe Internet, such as Anubis2, ThreatExpert 3 and CWSandbox 4. A sandbox is, within the scope\n\nof this thesis, a restrict and controlled environment that serves to the purpose of malware\n\nexecution, and whose aim is to avoid damage to external systems through the use of network\n\ntraffic filtering and blocking, and limiting the running time. In general, malware samples run\n\nfor about four or five minutes inside the sandbox and then they are terminated. During the\n\nexecution, the actions related to the sample under analysis are monitored, as well as the side\n\neffects of these actions. After the timeout, this kind of system provides an activity report that\n\ncan be analyzed.\n\nThough a malware activity report may provide insights about the infection process and\n\nthe sample behavior, the analysis of this report is left in charge of the user who submitted\n\nthe malware sample. Therefore, even in the presence of a summary of the relevant activities,\n\naverage users can get lost easily in the analysis process, which is more a log of activities than\n\nan analysis report. In addition, dynamic malware analysis systems can be used to classify\n\nsamples, but they do not do it, to the best of our knowledge. In addition, due to limitations\n\nregarding the monitoring techniques that are used internally in sandboxes, modern malware\n\ncan easily evade the analysis by stalling [92], exhibiting unsuspicious behavior [13] or detecting\n\nthe execution environment [31]. This can be worsened if a sample mutates its behavior during\n\nadditional executions (context or environment-sensitive), misleading the efforts of an analyst\n\nthat compares outputs from distinct analysis systems. Thus, without a proper classification\n\nscheme, an analyst or user may become confused at the point of a security decision taking\n\n(e.g., disinfection procedures, defensive applications), turning the analysis reports into useless\n\ninformation.\n\nThere are other worthy points regarding malware classification, in addition to the previously\n\ndiscussed lack of a general taxonomy: the available research works address very specific tax-\n\nonomies (see Chapter 2), the classification algorithms are applied to already known families and\n\n2http://anubis.iseclab.org\n3http://www.threatexpert.com\n4http://mwanalysis.org\n\n\n\n1.2. Objectives 5\n\non a limited amount of classes (usually based on AV labels with the only purpose to cluster\n\nsamples and verify the precision of the clusters), the proposed previous taxonomies and malware\n\nnaming schemes are meaningless when dealing with modern malware, as these were attempts to\n\ndescribe distinct classes tied to specific behaviors in a strict scope. Nowadays, the boundaries\n\nthat divide a malware class from another do not exist anymore, as modern malware samples are\n\nusually built on functional modules, presenting thus, at the same time, the behavior expected\n\nfrom rootkits, Trojan horses, worms, viruses, flooders, spammers and botclients.\n\nThence, on the one hand, we depend on malware detection and classification to build defen-\n\nsive solutions or perform better incident response. On the other hand, there is neither an official\n\n\u201cmandatory\u201d standard nor a document widely adopted by the majority of the security commu-\n\nnity to handle the malware menace. This causes confusing identification (naming) schemes that\n\nbecome obstacles when addressing malware-related incidents. Since the lack of an objective\n\nstandard is disrupting to users and organizations that rely on security products output to carry\n\non their daily activities, handling incidents caused by malware attacks is an imperative task.\n\nHowever, the adequate handling of this type of incident requires a systematic process, divided\n\ninto well defined steps that address (i) the collection of malware samples, (ii) the extraction of\n\nthe behavior that these samples present, (iii) the mining of suspicious features contained within\n\na behavior and the characterization of the prevalent ones, (iv) the categorization of samples into\n\nfamilies that represent their prevalent behavior and (v) the generation of detection procedures\n\nto identify malware according to the perceived behavioral profile.\n\n1.2 Objectives\n\nAccordingly to the afore discussed points, the main goal of this thesis is to study malware\n\nbehavior (using a practical approach) and how to use the information acquired from the ob-\n\nserved behaviors to develop detection techniques and a more meaningful classification scheme\n\nthat handle the damage that a malware can cause to an infected system. To this end, forward-\n\ning this point, we present the research work done for this thesis as a proposal of addressing\n\nthe aforementioned needs, aiming to respond to malware incidents in a useful, organized and\n\nunderstandable manner. This is accomplished through the extraction of malicious behavior us-\n\ning a dynamic analysis system that we have been developing, the proposal of a behavior-based\n\ntaxonomy for classification, the addition of modules for the detection of specialized malware\n\n(bankers) and for the visualization of the malware execution trace, and, finally, the introduction\n\nof a clustering algorithm to address malware behavior at a lower level.\n\n1.3 Contributions\n\nThe field of malware research is very broad and plenty of effort has been spent by the\n\nsecurity community to address the several types of threats that malicious code poses to Internet-\n\nconnected systems.\n\nIn this thesis, the focus is on malware behaviors and in what can be done with them concern-\n\ning computer systems defense. Thus, in addition to defining dangerous behaviors and malware\n\n\n\n6 Chapter 1. Introduction\n\nclasses based on them, we also apply the behavioral profiling on other topics, such as detection,\n\nclassification, clustering, code reuse identification, visualization and incident response. The\n\nmain contributions of this thesis are:\n\n\u2022 A brief review of the history of malicious programs, since their beginning up to date.\n\n\u2022 A discussion about the current malware naming scheme issues and antivirus labeling.\n\n\u2022 A survey on the diversity of malware taxonomies according to their types (e.g., worms,\nspyware, bots).\n\n\u2022 A definition of the different types of behavior that a malicious program can present, the\ndescription of a set of dangerous activities gathered from actually analyzed samples and\n\nthe proposal of a behavior-centric malware taxonomy.\n\n\u2022 An approach to detect information stealing malware that leverages a subset of the defined\nbehaviors and image processing techniques.\n\n\u2022 Interactive visualization tools to help in identifying similar behavioral patterns.\n\n\u2022 A heuristic to cluster malware based on their memory and registers writing values, as well\nas an application of this technique to identify code reuse among malware samples from\n\ndifferent families.\n\nFurthermore, the work concerning this thesis is not limited to the contents of this document:\n\nthe Ph.D. candidate has co-advised three Master students in Computer Science and two Un-\n\ndergraduate Students in Computer Engineering. As a result of this effort, articles and technical\n\nproduction have been generated, and skills in advising people were gained.\n\n1.4 Thesis Outline\n\nThe remainder of this thesis is organized as follows.\n\nIn Chapter 2, there is a brief review of the history of malicious programs, from before\n\ntheir formal conception (as automata or science fiction subjects) to their use in disrupting\n\ncritical infrastructures. Issues regarding the current malware naming schemes used by antivirus\n\ncompanies are discussed with practical examples. Finally, the chapter contains a survey on\n\navailable malware taxonomies, all of them based on the current concept of a malicious program\n\ntied to a specific behavior (e.g., a virus attaches its code to another program, a worm propagates\n\nautonomously, a Trojan horse lures the user into thinking he/she is installing a legitimate\n\nprogram, and so on).\n\nIn Chapter 3, we provide the notion of different types of execution behavior, such as active,\n\npassive, suspicious and neutral. Regarding those behavioral facets, we have chosen to analyze\n\nmalware according to behaviors that allow information stealing, malicious communications and\n\nactivities that cause changes on the compromised system. Hence, we select and describe a set\n\nof suspicious or dangerous activities that compose the behavior commonly observed on actual\n\n\n\n1.4. Thesis Outline 7\n\nmalware. Next, we define malware classes whose main behavior can be defined in terms of\n\nthose activities and, based on this, we propose a new taxonomic scheme centered on malware\n\nbehavior.\n\nIn Chapter 4, we evaluate and validate the proposed taxonomy on a large set of malware\n\nsamples collected from honeypots, spam crawling, colleagues and public databases. We also\n\ndescribe the architecture designed to analyze malware samples in order to obtain the behavioral\n\nprofiles used along this thesis.\n\nIn Chapter 5, we present a novel approach to detect bankers, i.e. malware samples whose\n\nmain purpose is to steal online banking credentials from infected users, often using social en-\n\ngineering tricks. We present BanDIT, a prototype system developed to detect bankers using\n\nimage processing techniques, network traffic patterns and file system modifications related to\n\nInternet browsing.\n\nIn Chapter 6, we introduce the visualization of behavioral profiles to help in the analysis of\n\nmalware infection. To this end, we developed two tools that allow the visual-aided analysis of\n\nmalware samples and the observation of similar behavior among samples from the same family.\n\nThis work is the first step towards the perception that although malware families overlap their\n\nbehavioral features, their (combination of) classes can be linearly separable.\n\nIn Chapter 7, we propose a heuristic to cluster malware based on the values that are written\n\ninto addresses in memory and into registers during the execution. To this end, we developed\n\na prototype system that tracks these memory/registers values and produces execution traces\n\nthat characterize the analyzed samples. We leverage an algorithm to approximate the LCS\n\n(longest common subsequence) computation and to group malware into clusters that represent\n\ntheir family. Moreover, the proposed concepts are also applied in a code reuse identification\n\nproblem, allowing us to pinpoint excerpts of shared code among different malware families.\n\nIn Chapter 8, we conclude by discussing limitations of the previously presented approaches\n\nand future work that can be explored to advance the research in the field, taking advantage of\n\nthe topics we have addressed. Finally, we briefly summarize the results obtained in this thesis.\n\nIt is worth to note that, since the chapters are based on published papers, the analyzed set\n\nof samples may be different (regarding the set\u2019s size and variety).\n\n\n\n8 Chapter 1. Introduction\n\n\n\nChapter 2\nBackground and Related Work\n\n2.1 Introduction\n\nA malicious software, or malware, is a set of instructions that runs on a system to make it do\n\narbitrary activities on behalf of an attacker [140]. Malware evolved from the harmless concept\n\nof self-replicating automata to multipurpose stealthy code that can destroy physical assets.\n\nHowever, despite all orientation changes, the research field of malware analysis suffers from\n\ninconsistent naming schemes and lack of a useful taxonomy. In this chapter we summarize the\n\nhistory of malware, discuss issues related to malware naming schemes, briefly present concepts\n\nand requirements regarding the field and present work related to security-oriented taxonomies,\n\nmore specifically those regarding malware.\n\n2.2 A Brief History on Malicious Software\n\nComputer virus. It is still possible to hear (or read) this term associated to a malicious\n\nprogram attack. However, a computer virus is one among several other existing malware classes.\n\nFred Cohen formally coined the term \u201ccomputer virus\u201d in 1983, defining it as a program\n\nthat can infect other programs, changing them to include a possibly evolved copy of itself [35].\n\nThis contagion method allows a computer virus to propagate to other systems through other\n\nprograms or the network. In his Ph.D. thesis, Cohen wrote and demonstrated the execution of\n\na computer virus aimed at Unix systems [34].\n\nYears before the viruses appeared, another \u201cmalware\u201d class was already being discussed:\n\nworm, a kind of program that resembles the self-replicant automata described by John von\n\nNeumann in 1949 [108]. John F. Shoch and Jon A. Hupp, from Xerox Palo Alto Research\n\nCenter, are given the credit for the term being used in the computer field. They debate about\n\nthe development of worm programs for use in distributed computing in their 1982 paper [137].\n\nShochs and Hupp\u2019s worms were inspired by the first noticed worm in activity, the Creeper,\n\nwritten by Bob Thomas in 1971 and spread through ARPANET [30].\n\nShoch and Hupp describe their worms as applications that perform inoffensive tasks, such as\n\nthe dissemination of messages through the network or the splitting of tasks to accomplish real-\n\ntime animation. Despite this benign intent, they raise some concerns about the propagation\n\n9\n\n\n\n10 Chapter 2. Background and Related Work\n\ncontrol and the maintenance of a stable execution along the time. Those worries were not\n\nin vain: in 1988 Robert Morris Jr. launched the \u201cInternet Worm\u201d, a malicious program that\n\nexplored a vulnerability in the Unix\u2019s Sendmail application [113]. This worm contained itself a\n\nprogramming bug that escaped from the control of its developer, causing quick spurts of local\n\nand remote propagations. The result was the denial of service of the majority of the Internet-\n\nconnected systems of that time [81]. The \u201cInternet Worm\u201d established the genesis of the massive\n\nmalware attacks and led us to the current situation of pervasive threat.\n\nTrojan horses, or Trojans, are the elements of another major malware class. The first use of\n\nthe term in the security scope is credited to Daniel Edwards, a NSA researcher, on the second\n\nvolume of a U.S. Air Force report from 1972 [7]. Edwards describes a Trojan horse as a\n\ncomputer program that is useful to a system, i.e. attractive enough to be executed, but that\n\nalso has hidden functions that disguise its actual motivation. Edwards exemplify this kind of\n\nbehavior as a text editor whose hidden function copies a file being edited to an attacker, partially\n\nor totally. The mathematical foundations for Trojan horses date from the work of Leonard\n\nAdleman in 1990 [4]. Adleman characterizes Trojan horses as programs that are incapable of\n\ninfecting other programs, but able to imitate or injure them, the latter occurring only if certain\n\nconditions are met.\n\nWhile the 80\u2019s brought us a new paradigm on computer security, the 90\u2019s can be considered\n\nthe rise of malware attacks. In 1995, a macro virus (a virus written using a macro programming\n\nlanguage) started to receive public attention due to its potential to spread rapidly: Concept,\n\nwhich executed as soon as an MS Word application with enabled macros opened a document.\n\nSince then, a user could be infected through a simple e-mail reading [62]. Back to 1989, there\n\nalready were reports related to macro viruses that attacked Lotus123 spreadsheets, as well\n\nas detection procedures [66]. In 1996, several macro attacks and prevention possibilities were\n\ndiscussed, including polymorphic macro viruses [24].\n\nThe polymorphism feature in malware, i.e. the ability to mutate their code to evade signature\n\ndetection, forced the antivirus companies to develop a new technique, the detection by code\n\nemulation. This technique implies that a malware sample runs in a controlled environment,\n\nusually an instructions emulator, on a predefined amount of cycles [17]. The first virus that\n\nwas considered to be polymorphic was \u201cChameleon\u201d, from 1990. Its main functionality was to\n\nmutate its signature every time it infected another file [138].\n\nIn 1998, the first virus to abuse Java applets and applications, called \u201cStrangeBrew\u201d, was\n\ndeveloped as a proof-of-concept. It was written using the Java programming language [107].\n\nThis year is also remarkable due to the dissemination of the \u201cBack Orifice\u201d tool, which was\n\ncommonly installed as some Trojan payload and acted as a backdoor, allowing for the complete\n\nremote control of the target machine [41]. In 1999, the \u201cMelissa\u201d virus caused denial of service on\n\ne-mail servers and large financial losses due to disinfection procedures. This macro virus/worm\n\nhad a massive spreading, infecting a user\u2019s address book and sending itself (on behalf of the\n\ninfected user) to the e-mail contacts found [59].\n\nFollowing the \u201cMelissa\u201d infection scheme, the \u201cILOVEYOU\u201d worm attacked 45 million com-\n\nputers and caused 80 million dollar losses in 2000 [162]. From this time on, malware became\n\nmore dangerous, complex and ubiquitous. In 2001, the \u201cCode Red\u201d worm scanned the Internet\n\n\n\n2.2. A Brief History on Malicious Software 11\n\nsearching for vulnerable Windows IIS Web servers and exploiting them as they were found [174].\n\nAccording to Moore et al. [102], \u201cCode Red\u201d infected more than 359 thousand Internet-connected\n\nmachines in less than 14 hours, causing losses of approximately 2.6 billions of dollars. Another\n\ncritical worm from 2001 was \u201cNimda\u201d, which also exploited vulnerable Microsoft IIS Web servers.\n\nThis worm\u2019s attack was based on a multi-vector approach to assure a high rate of success in its\n\ninfection process. Among other methods, \u201cNimda\u201d e-mailed itself as an attachment based on\n\ncontacts found in the compromised machine, copied itself through open network shares and used\n\nbackdoors opened by \u201cCode Red\u201d [143]. In 2002, \u201cSdbot\u201d and its variants combined scanning,\n\nexploiting, hiding, system\u2019s information obtaining and peer-to-peer spreading capabilities in a\n\nsingle malware sample [105], beginning the Instant Relay Chat bots age.\n\nOther malware samples that caused impact on the Internet stability, security and economy\n\nare described next. The \u201cBlaster\u201d worm of 2003, which exploited a buffer overrun vulnera-\n\nbility in the Windows RPC (Remote Procedure Call) interface\u2014allowing for the execution of\n\narbitrary code\u2014launched denial of service attacks against the Windows Update site [11]; The\n\n\u201cSlammer\u201d worm, also in 2003, spread fast (it infected 90% of vulnerable systems in 10 min-\n\nutes) by exploiting a buffer overflow vulnerability in Microsoft SQL Server [101]. In addition\n\nto causing denial of service attacks by disabling database servers, its massive scanning capa-\n\nbilities overloaded networks by consuming all their bandwidth. \u201cSasser\u201d, of 2004, scanned for\n\nbuffer overflow-vulnerable Windows LSASS (Local Security Authority Subsystem Service) com-\n\nponents and exploited them through TCP port 445 [88]. The worm usually crashed the LSASS\n\ncomponent, leading the infected system to frequent shutdowns.\n\nThe war of the worms had its outbreak in 2004, bringing attention not only to the massive\n\nmalware infection rate, but to malware interactions, i.e. a malicious program terminating an-\n\nother type of malicious program [151]. The main threats of 2004 were \u201cBagle\u201d, \u201cMyDoom\u201d and\n\n\u201cNetsky\u201d. The three of them were mass-mailer worms and installed their own SMTP engines\n\nto propagate through spam; the first two also operated as backdoors whereas \u201cNetsky\u201d tried to\n\ndeactivate \u201cMydoom\u201d and \u201cBagle\u201d [139]. 2005 was the year of the \u201cZotob\u201d worm\u2014which spread\n\nby exploiting a Microsoft Windows Plug and Play buffer overflow vulnerability [129]\u2014and the\n\n\u201cZlob\u201d trojan\u2014which disguised itself as an ActiveX Codec [156]. In 2007, the \u201cStorm\u201d worm\n\nstruck, infecting about 10 million computers and gathering them into a botnet [116]. Also in\n\nthis year, the \u201cZeus\u201d crimeware became popular, due to its toolkit approach that allowed crim-\n\ninals to generate variants using a user-friendly interface, to its low price in the underground\n\nand to its Internet banking credentials and sensitive information (such as credit cards) stealing\n\ncapabilities [20].\n\nMalicious botnets and attacks from multipurpose malware continued to grow and, in 2008,\n\nmore sophisticated pieces of malware began to be observed. \u201cTorpig\u201d not only stole online\n\nbanking credentials and credit card data, but also user\u2019s personal information. This malware is\n\ninstalled in the victim\u2019s machine as part of the \u201cMebroot\u201d rootkit, which replaces the system\u2019s\n\nMaster Boot Record (MBR) and launches a drive-by download attack to turn the infected\n\nmachine into a bot. An estimative about the size of a \u201cTorpig\u201d botnet counted more than 182\n\nthousand machines in a 10 days monitoring study [147]. Another interesting botnet that arose\n\nin 2008 was the \u201cKoobface\u201d. It had a massive reach by infecting users mainly through Facebook,\n\n\n\n12 Chapter 2. Background and Related Work\n\nspreading to a victim\u2019s social network friends [154]. The \u201cConficker\u201d worm/bot appeared in late\n\n2008 and spread very fast by exploiting the port TCP 445 through a remote procedure call\n\n(RPC), allowing the execution of arbitrary code [117]. Its features include a domain generation\n\nalgorithm and self-updates via Web and P2P, resulting in an estimative of about 25 millions of\n\ninfected victims [135].\n\nThe situation got worse in 2010 with the rise of \u201cStuxnet\u201d. This complex malware tar-\n\ngeted industrial control systems (its aim was to reprogram them to take their control in a\n\nstealthy way) and the pack included zero-day exploits, a Windows and a programmable logic\n\ncontroller (PLC) rootkit, antivirus evasion, process injection and hooking techniques, network-\n\nbased spreading, updates using P2P and a command and control interface [52]. \u201cStuxnet\u201d\n\ncaused a global proportion crisis as it compromised real-world infrastructure, specifically com-\n\nputers from an Iranian nuclear power station [16]. In 2011 Hungarian researches discovered\n\n\u201cDuQu\u201d, a malware whose features (modular structure, injection mechanisms and fake-signed\n\ndriver) refers to \u201cStuxnet\u201d [19]. However, the main purpose of \u201cDuQu\u201d, at least initially, was\n\nto gather information from the compromised system through a keylogger module. Moreover,\n\n\u201cDuQu\u201d has an execution delay of 15 minutes, avoiding the dynamic analysis process of most\n\navailable systems. As of this writing (1Q/2012), malware trends include attacks using man-in-\n\nthe-browser techniques, smartphones targeting samples and open-source kits for banking trojans\n\ndevelopment. Also, the threat of the moment is known by the name of \u201cCitadel\u201d, an open-source\n\nmalware project based on the \u201cZeus\u201d Trojan that alluded to the Software-as-a-Service model\n\n(SaaS) [84]. \u201cCitadel\u201d evolves based on its customers additions, which includes the use of AES\n\ncryptography, trackers detection avoidance mechanism, security vendors websites blacklist and\n\neven a video recording module [130].\n\nDespite the fact that most of the \u201cpress-famous\u201d malware are referred as virus, worms,\n\nTrojans or bots, other malware classes do exist. For instance, Bishop describes in [22] \u201drabbits\n\nand bacteria\u201d and \u201dlogic bombs\u201d as other forms of malware. He defines a logic bomb as\n\na program that attacks when externally triggered, giving as example a Trojan horse that is\n\nactivated when an employee identification is removed from the payment database. In this case,\n\nthe trigger to the logic bomb is the removal and its effect is the execution of a malware. Rabbits\n\nor bacteria are programs that reproduce themselves in a rapid fashion to exhaust some system\u2019s\n\nresource (e.g., disk space, memory, processor). This kind of behavior can be also observed in\n\nworms; thus, instead of a new class, rabbits can be considered a worm\u2019s subclass, which is indeed\n\ndone in Peter Szor\u2019s terminology [150]. Szor also describes, among other classes:\n\n\u2022 Spyware, which inadvertently collects system\u2019s or user\u2019s information and sends it through\nthe network.\n\n\u2022 Rootkit, a set of tools to attack and maintain access to an infected machine in a long\nlasting, stealthy way.\n\n\u2022 Keylogger, a program that captures keystrokes and is usually installed stealthily.\n\n\u2022 Flooder, a kind of tool that generates plenty of network traffic directed to a target in\norder to cause a denial of service.\n\n\n\n2.3. Confusion in the Battlefield 13\n\n\u2022 Exploit, code that aims to automatically gain privileged access or run arbitrary code in\na target machine.\n\n\u2022 Auto-Rooter, whose goal is to remotely break into a target and to gain access to admin-\nistrative privileges.\n\n\u2022 Downloader, a piece of code whose intent is to install itself in an infected system to\ndownload and extract malicious content, while avoiding security mechanisms.\n\n\u2022 Dropper, an installer-like program that \u201ccarries\u201d hidden viral code inside of itself. A\ndropper \u201cmutates\u201d to install (or generate) its carried payload and then to replicate without\n\nthe need of its original code.\n\n\u2022 Injector, a special kind of dropper that injects/installs malware code in the target\u2019s\nmemory.\n\nViruses, worms, Trojan horses and the other aforementioned categories form the basis for a\n\nsimplistic taxonomy that can be used to classify malware according to their expected behavior.\n\nHowever, this is not so simple as it seems to be, as we discuss in the next sections.\n\n2.3 Confusion in the Battlefield\n\nThe analysis of the malware definitions from Section 2.2 lead us to notice that some classes\n\nintersect whereas others are variations of a common behavior. For instance, auto-rooters, ex-\n\nploits and flooders can be grouped into one bigger class, as they are usually considered to be set\n\nof tools with different intents. Regarding exploits and auto-rooters, even the intent is almost\n\nthe same. If we take notice to the classes downloader, dropper and injector, it is clear that the\n\nmain behavior is shared and that they differ by the way they install the attacking piece of code.\n\nSzor himself defines an injector as a slightly different dropper.\n\nThere are also minor variations that specialize a class; for example, we can consider that a\n\nrabbit is a specialized worm and that a keylogger is a form of spyware. Back to the 1980\u2019s, Spaf-\n\nford discussed the misuse of malware terminology in his report about the Internet Worm [142].\n\nHe mentions the press using the term \u201cvirus\u201d instead of \u201cworm\u201d, misleading the readers about\n\nthe behavior observed during the attack. His justification on denoting the Morris program as\n\na worm is quoted below, as the \u201cbehavior\u201d factor in classifying malware attacks is the stepping\n\nstone of this thesis.\n\n\u201cA worm is a program that can run by itself and can propagate a fully working\n\nversion of itself to other machines. It is derived from the word tapeworm, a parasitic\n\norganism that lives inside a host and saps its resources to maintain itself. A virus\n\nis a piece of code that adds itself to other programs, including operating systems. It\n\ncannot run independently-it requires that its \u201chost\u201d program be run to activate it. As\n\nsuch, it has a clear analog to biological viruses - those viruses are not considered alive\n\nin the usual sense; instead, they invade host cells and corrupt them, causing them\n\n\n\n14 Chapter 2. Background and Related Work\n\nto produce new viruses. The program that was loosed on the Internet was clearly a\n\nworm.\u201d\n\nSince then, there have been a plethora of efforts towards the standardization of procedures to\n\nname malicious programs, such as the CARO (Computer Antivirus Researchers Organization)\n\nMalware Naming Scheme [141], created in the beginning of the 1990\u2019s. Their website, which\n\nis unfinished up to the date of this writing, states that CARO Naming Scheme accepts as\n\nmalware types \u201cvirus\u201d, \u201ctrojan\u201d, \u201cdropper\u201d, \u201cintended\u201d, \u201ckit\u201d and \u201cgarbage\u201d. Bontchev, one of\n\nthe proposer of the original CARO Naming Scheme, presents some updates to the scheme [25]\n\nby adding \u201cpws\u201d, \u201cdialer\u201d, \u201cbackdoor\u201d, \u201cexploit\u201d and \u201ctool\u201d to the previously accepted malware\n\ntypes; the last replaces the \u201ckit\u201d definition. According to CARO, kit/tool is a program designed\n\nto generate variants from a malware family; intended is a buggy program whose initial intention\n\nwas to be a virus, but its execution fails (or crashes); garbage is attributed to meaningless or\n\nbuggy programs that are not intended to be malware; pws stands for password stealer programs;\n\na dialer tries to force the establishment of a dial-up connection; backdoors are programs that\n\nallow unauthorized or illegitimate access to compromised systems. The other types have already\n\nbeen defined previously.\n\nAlthough Bontchev discusses important issues, such as the lack of a naming standard and of\n\nreliability in the naming process, the difficulty to enforce its use and the current messy naming\n\nschemes, we can notice that even CARO\u2019s proposed scheme is confusing: they can group viruses\n\nand worms in the same type whereas they consider backdoors and Trojans distinct enough to\n\nbe in separate classes. However, Bontchev poses an interesting discussion topic: if some user\u2019s\n\nantivirus (AV) scanner detects a program as MyDoom.D, the user is unaware about its malicious\n\nbehavior at the same time he is helpless, as the AV analysts are unable to determine the actual\n\nmalware\u2019s behavior without analyzing the sample. Another problem arises when more than one\n\nAV scanner is used to improve the detection of malware. The use of multiple AV scanners can\n\nmake worse the understanding of an infection regarding a malware successfully detected, as the\n\nidentifications are meaningless and not uniform. To illustrate this, we sent a malware sample\n\nto VirusTotal [67], a service that scans a user-submitted file with several AV engines and shows\n\nthe identified detection labels, if any. Table 2.1 shows this submission\u2019s results. It is possible to\n\nnotice the confusing naming scheme provided by each AV as well as the questionable utility of\n\nthe label to the extent of the user\u2019s comprehension.\n\nTable 2.1: AV scanner and respective identification label.\nAV scanner Detection label\nMcAfee PWS-OnlineGames.bu\nSymantec Infostealer.Gampass\nNorman W32/Packedi_Upack.h\nKaspersky Trojan-GameThief.Win32.OnlineGames.akyb\nMcAfee-GW-Ed. Heuristic.BehavesLike.Win32.Packed.A\nPCTools Rootkit.Order\nIkarus Virus.Win32.Virut\nPanda Trj/Lineage.ISP\n\n\n\n2.4. Systematics 15\n\nThe naming issue is also discussed in the work of Raiu [123]. Raiu, from the Kaspersky\n\nAntivirus Laboratories in Romania, claims that when the VBS/VBSWG.J malware appeared, the\n\nmedia called it Kournikova due to its disguise under a so-claimed picture of the named tennis\n\nplayer while most of the AV engines detected it as malicious program under a mysterious label:\n\nSST. The AV vendors disagreed on this malware sample name, some claiming that SST was\n\nshorter and easier to remember and others that VBSWG was not too hard to remember and\n\npronounce for the average AV user.\n\nThus, considering the \u201cAnnaKournikova\u201d malware case and taking the AV labels and the\n\nnames assigned to the threats along the years into account, there is still a major question,\n\nwhich is the subject of this thesis: What does this malware sample do?\n\nTo try to start answering this question, let\u2019s evoke Leonard Adleman again. In his seminal\n\nwork about a theory for characterizing computer viruses [4], Adleman formally defines certain\n\ntypes of viruses, such as the \u201ccarrier\u201d, which is defined as unable to cause injury but able to\n\ninfect other programs under the right conditions, and the previously mentioned \u201cTrojan horse\u201d.\n\nThose formalisms have their basis on the behavior observed from malware execution, e.g., if a\n\nsample is \u201cpathogenic\u201d, \u201ccontagious\u201d, \u201cbenignant\u201d, if it \u201cinjures\u201d, \u201cinfects\u201d or \u201cimitates\u201d another\n\nprogram, and so on.\n\nAdleman\u2019s behavioral models allow to distinguish among possible malware infection strate-\n\ngies and elegantly encompass several classes of the malware fauna. For instance, the \u201ccarrier\u201d\n\ndefinition can be used to denote the behavior of droppers, downloaders and injectors. This\n\nperception contributes to stress out the importance of a taxonomy that clearly indicates the\n\nrisk posed by a malicious program, i.e. its behavior on a compromised system, and emphasizes\n\nthe obsolescence, contradiction and incompleteness of the current naming schemes, which have\n\nbeen defective since their inception.\n\n2.4 Systematics\n\nSystematics, in the biological scope, can be defined as the study of the living organisms\n\ndiversity and their relationships through time. Those relationships are depicted as phylogenies\n\nor evolutionary trees [167].\n\nSystematics is a field that encompasses several responsibilities, such as providing scientific\n\nnames to organisms and their related descriptions, maintaining sample collections, their classifi-\n\ncation, identification and distribution [99]. These responsibilities can be used to define the terms\n\n\u201ctaxonomy\u201d and \u201cscientific classification\u201d. Taxonomy is more specific to the naming scheme, the\n\nidentification and the description of organisms whereas scientific classification is focused on their\n\nseparation into hierarchically-related groups.\n\nAt first in this thesis, we discuss features of taxonomies and how they can be used to help\n\nin the malware analysis process. The objective is to create a ruleset to identify malware, to\n\nunderstand their behavior during an attack, as well as to improve the counter measures to\n\nperform effective incident response. We leave the discussion about classification to Chapter 7.\n\nThus, taxonomy can be defined as the science of species identification and naming, as well\n\nas their organization into classification systems [110]. Although the history of taxonomy refers\n\n\n\n16 Chapter 2. Background and Related Work\n\nback to ancient China (3000 B.C) [96], an organized and widely adopted standard only arose\n\nafter Linnaeus published his work, Systema Naturae [94].\n\nHowever, as taxonomy is a set of rules to identify, describe and organize elements, their basic\n\nconcepts can be applied to several knowledge fields. In the following sections, we discuss: the\n\nuse of taxonomies in the field of computer security, their scope and requirements; a brief survey\n\nof taxonomies that are focused on malware classes; a proposal for a new taxonomic scheme that\n\nis extensible, flexible, understandable and more generic than the current ones, at the same time\n\nthat it takes advantage of their strengths.\n\n2.5 Security-related Taxonomies\n\nA number of taxonomies have been proposed to cover diverse computer security topics.\n\nFor example, the works of Aslam [8], Krsul [85] and Landwehr address system\u2019s vulnerabilities\n\nand attacks [89]. The Neumann-Parker taxonomy addresses intrusions [109], whereas other\n\ntaxonomies related to intrusion or threats to computer security are summarized by Lindqvist\n\nand Jonsson [93]. Taxonomies related specifically to malware are discussed in Section 2.6, as\n\nthey pertain to the scope of this thesis.\n\nMany are the requirements [65] that a taxonomy has to meet in order to accomplish its goal,\n\ni.e. to be clear, adaptive and applicable. Howard and Longstaff [69] and Amoroso [6] mention\n\nimportant properties of good taxonomies, which are listed as follows:\n\n\u2022 Mutually exclusive, to assure that a sample fits into only one category.\n\n\u2022 Exhaustive (or completeness), so that the predefined categories include all possibilities\nof the subject under analysis.\n\n\u2022 Unambiguous, to eliminate uncertainty and to allow the taxonomy application to be a\nclear process.\n\n\u2022 Repeatable, so that others can repeat the taxonomic process and get the same results.\n\n\u2022 Acceptable and useful, to allow it to be used by the community, serving as a reference\nand source of knowledge in the field.\n\nIn addition, Bishop states that a taxonomy requires well defined terms, so that there is\n\nno confusion about the meaning of a term [21]. Another interesting property of a taxonomy is\n\nthat it should be comprehensible, i.e. either a field\u2019s expert or a merely interested person are\n\nable to understand it [93]. Therefore, a taxonomy should provide the discernment ability to\n\nits \u201cusers\u201d. Thus, it is possible to clearly discern which features segregate the analyzed samples\n\ninto distinguished classes and which are the features that make given classes to be closer to each\n\nother.\n\nHowever, when dealing with malware, we may not fulfill all of the aforementioned require-\n\nments. This happens due to the complexity of malware behavior and we return to this issue.\n\n\n\n2.6. Malware Taxonomies 17\n\n2.6 Malware Taxonomies\n\nThere are several attempts reported in the literature concerning the creation of malware\n\ntaxonomies. However, those taxonomies either address only one type of the existing malware\n\nset, e.g., a taxonomy specific for worms, or are closely tied to the standard classes and the current\n\nnaming schemes. Although these efforts are valid and useful, we believe that there is still the\n\nlack of a generic and more comprehensible taxonomy obeying the requirements presented in\n\nSection 2.5. In this section, we present important research works that are focused on malware\n\ntaxonomies and whose contributions led to the development of our proposal.\n\n2.6.1 Viruses, Worms, Trojans\n\nFiliol discusses the misuse of the term computer virus and the user\u2019s incomplete knowledge in\n\nthe subject [54]. He defines malware as \u201ccomputer infection programs\u201d and proposes a taxonomy\n\nthat divides them into two classes, simple, which encompasses logical bombs and Trojans, and\n\nself-reproducing, which embraces viruses and worms. Filiol shows that worms are particular\n\nviruses from an algorithmic point of view and that it is difficult to classify malware using the\n\nstandard definitions (virus, worm, Trojan) due to the overlap of behaviors that characterize\n\neach class.\n\nWeaver et al. state that \u201cto understand the worm threat, it is necessary to understand the\n\nvarious types of worms, payloads, and attackers\u201d [161]. They propose a taxonomy of computer\n\nworms whose attributes are the target discovery technique, the propagation mechanism,\n\nthe activation method, the payloads and the attackers\u2019 motivation. As mentioned in\n\ntheir paper, the proposed taxonomy is incomplete, as new attacks and malware variants arise\n\nconstantly. Table 2.2 summarizes this taxonomy of worms, which uses the carrier, the activation\n\nand the payload to describe a certain worm, as they are independent attributes.\n\nKarresand proposes a taxonomy to separate viruses, worms and Trojans [79]. He discusses\n\nthe fact that the malware developers started to combine different functions into a single sample,\n\nmaking harder the naming task. Also, he shows examples of malware that are categorized into\n\nmultiple or different classes by antivirus vendors. He proposes TEBIT, a taxonomy of software\n\nweapons with 15 independent categories and one to four possible values for each category:\n\n\u2022 Type: atomic or combined.\n\n\u2022 Violates: confidentiality, integrity/parasitic, integrity/non-parasitic or availability.\n\n\u2022 Duration of effect: temporary or permanent.\n\n\u2022 Targeting: manual or autonomous.\n\n\u2022 Attack: immediate or conditional.\n\n\u2022 Functional area: local or remote.\n\n\u2022 Affected data: stationary or in transfer.\n\n\n\n18 Chapter 2. Background and Related Work\n\nTable 2.2: The taxonomy of computer worms proposed by Weaver et al., 2003.\nAttribute Possible values\n\nTarget Discovery\n\nScanning\nPre-generated target lists\nExternally generated target lists\nInternal target lists\nPassive\n\nPropagation Carrier\nSelf-carried\nSecond channel\nEmbedded\n\nActivation\n\nHuman activation\nHuman activity-based activation\nScheduled process activation\nSelf activation\n\nPayloads\n\nNone/nonfunctional\nInternet remote control\nSpam-relays\nHTML-proxies\nInternet DoS\nData collection\nAccess for sale\nData damage\nPhysical-world remote control\nPhysical-world DoS\nPhysical-world reconnaissance\nPhysical-world damage\nWorm maintenance\n\nMotivations\n\nExperimental curiosity\nPride and power\nCommercial advantage\nExtortion and criminal gain\nRandom protest\nPolitical protest\nTerrorism\nCyber warfare\n\n\u2022 Used vulnerability: CVE/CAN, other or none.\n\n\u2022 Topology of source: single or distributed.\n\n\u2022 Target of attack: single or multiple.\n\n\u2022 Platform dependency: dependent or independent.\n\n\u2022 Signature of replicated code: monomorphic, polymorphic or not replicating.\n\n\u2022 Signature of attack: monomorphic or polymorphic.\n\n\n\n2.6. Malware Taxonomies 19\n\n\u2022 Signature when passive: visible or stealthy.\n\n\u2022 Signature when active: visible or stealthy.\n\nAlthough interesting in the sense of stressing once more the current malware naming schemes\n\nproblems, TEBIT suffers from two major issues: it does not explain clearly the results of an\n\nattack to the victim\u2019s system and its categories heavily rely on technical descriptions provided\n\nby antivirus vendors (the same ones that still apply the criticized naming scheme). Moreover,\n\nTEBIT\u2019s categorization results show that it uses very few categories to separate viruses, worms\n\nand trojans, whereas the values of the remaining ones are unclear. This led to the conclusion\n\nthat almost any malware is a Trojan horse; thus, there is no need for a classification process.\n\nAlso, the few categories that clearly distinguish the classes fit the standard definitions, i.e. a\n\nvirus is parasitic and performs local attacks, a worm is non-parasitic and propagates remotely.\n\n2.6.2 Botnets\n\nBots are very remarkable species of malware as they present features that could include them\n\nin a large variety of classes. Bots can spread like worms, open ports or setup servers to act as\n\nbackdoors, use rootkits to hide their presence, download other pieces of malware or components\n\nfor self-updating, monitor keystrokes to steal information as keyloggers do and so on.\n\nTo evade detection and to accomplish their malicious intents, botnets are generated byus-\n\ning different structures. Cooke et al. [38] identify three topologies related to the communi-\n\ncation methods used by a botnet\u2019s infected machines\u2014zombies or bots\u2014and its controller\u2014\n\nmothership, botmaster, botherder or C&amp;C server: centralized, in which there is a central\n\nlocation to allow the exchange of messages among clients; peer-to-peer (P2P), which are\n\nstructurally more complex and harder to take down due to the inexistence of a central point of\n\nfailure; random, in which each bot knows only one other bot, passing encrypted messages after\n\nrandomly scanning the Internet to find it.\n\nDagon et al. propose a taxonomy of botnet topologies to discuss their organization and utility\n\nfor malicious activities [42]. They propose the effectiveness, the efficiency and the robustness\n\nas discriminators (or attributes) to measure botnets. The authors consider different types of\n\ngraphs from complex networks to model the possible topologies of their taxonomy:\n\n\u2022 Erdo?s-Re?nyi random graph models: denote randomly organized structures.\n\n\u2022 Watts-Strogatz small world models: there are regional networks grouping local con-\nnections in a ring whose distant nodes are accessed through shortcuts, e.g., victim\u2019s lists.\n\n\u2022 Barba?si-Albert scale free models: usually organized in a hub architecture with a\nsmall amount of highly connected central nodes and a larger amount of less connected leaf\n\nnodes;\n\n\u2022 P2P models: can be organized in structured or unstructured topologies.\n\n\n\n20 Chapter 2. Background and Related Work\n\nAnother way to develop a taxonomy of botnets is to consider their behavior once a bot\n\ncompromises a victim\u2019s system. Rajab et al. [1] discuss the execution features that they have\n\nobserved in IRC-based botclients, which they divided into the following classes: AV/FW killer,\n\nmeaning that the bot tried to disable possible defense mechanisms running on the target; Identd\n\nserver, when a bot run identd so that the IRC server can verify that this bot is allowed to join\n\na specific channel; System security monitor, which indicates a bot\u2019s self-defense behavior to\n\n\u201csecure\u201d the compromised target against other malware attacks; Registry monitor, denoting\n\nthe behavior of a bot that verifies for system\u2019s registry changes that may point to disabling\n\nattempts.\n\n2.6.3 Spyware\n\nSpyware is a malware class that aims to monitor the behavior of users and steal their data\n\nin a covert manner [48]. Saroiu et al. [128] refine the class into the following subclasses1:\n\n\u2022 Cookies and Web bugs: can track the Web behavior of users in a passive way.\n\n\u2022 Browser hijackers: attempt to change the browser settings usually by installing browser\nextensions to steal user data.\n\n\u2022 Keyloggers: capture sensitive information, logs of visited sites, instant messaging sessions\nand so on.\n\n\u2022 Tracks: the recorded information about the actions of a user that can be used by a\nmalicious program.\n\n\u2022 Malware: any malicious software.\n\n\u2022 Spybots: a kind of spyware that monitors the user\u2019s behavior and transmit the collected\ninformation to a third party.\n\n\u2022 Adware: software that displays advertisements based on the captured behavior of a\nmonitored user.\n\nWe notice that the above classes can be somewhat confusing if we try to apply them to\n\nactual samples, i.e. most malware whose behavior is different from \u201cspying and stealing\u201d fit\n\ninto the Malware class. Moreover, there are overlaps among some descriptions (mainly those\n\nrelated to user data monitoring). It is also worth to notice that all of the classes target the\n\nuser\u2019s privacy.\n\nSome harmful effects attributed to spyware are presented by Boldt et al. [23]. The authors\n\nmention four main categories of risks posed by spyware: consumption of system capac-\n\nity (processing) and consumption of bandwidth can cause availability problems; Security\n\nissues and privacy issues, such as user\u2019s information (credentials, e-mail addresses) leakage\n\nthrough covert communications violate the principle of confidentiality.\n\n1We can notice that Tracks and Malware are more a terminology than a spyware class.\n\n\n\n2.6. Malware Taxonomies 21\n\n2.6.4 Rootkits\n\nRootkits are often seen as stealth malware, as they aim to operate in an unsuspicious and\n\nhidden way. Rutkowska proposes a taxonomy to classify stealthy malware samples according\n\nto their interactions with the operating system [127]. For this purpose, she redefines the term\n\nthat describes the general concept of malware to a new one that considers malware as a piece\n\nof code that modifies the behavior of the operating system kernel or some security application\n\nin an non-consenting, undetectable and undocumented way.\n\nTo embrace even the \u201cordinary\u201d malware, i.e. those that are not stealthy in the sense she\n\ndefined, her taxonomy describes four classes of malware, explained below:\n\n\u2022 Type 0 malware: does not compromise the operating system nor the behavior of other\napplications of processes using undocumented methods. A type 0 malware can still com-\n\npromise the integrity and the availability of user data (by modifying or deleting it) or\n\nthe user\u2019s information confidentiality (by stealing sensitive documents or credentials and\n\nevading them through network connections), but this is done using valid APIs. This type\n\nof malware embraces the traditional classes already described in the previous sections.\n\n\u2022 Type I malware: modifies operating system\u2019s constant resources, such as executable\nfiles and in-memory code sections of running processes or the kernel. This type describes\n\nrootkits that usually \u201ctrojanize\u201d resources to turn communications stealthy or to hide\n\nprocesses, files and directories, for example.\n\n\u2022 Type II malware: operates on dynamic resources that are designed to be modified,\ne.g., configuration files, registry keys and data sections of processes or the operating sys-\n\ntem kernel. Type II malware are those rootkits that apply dynamic hooking in kernel\n\nstructures,\n\n\u2022 Type III malware: a dangerous malware that can take the complete control of the\noperating systems without modifying the memory or any visible registers. Those rootk-\n\nits leverage hardware virtualization techniques to run with greater privileges than the\n\noperating system.\n\n2.6.5 Malware Taxonomies Panorama\n\nAs we can observe in the previous subsections, each of the presented taxonomies tries to\n\nclassify specific malware types. Such classification schemes may be precise to describe those\n\nknown malware types, as some of them delve into details such as the attacker\u2019s motivation,\n\nthe vulnerability used during the infection, the propagation model and so on. However, this\n\nkind of approach may not be useful to users or to automated incident response procedures,\n\nsince the analyst has to potentially analyze the sample manually to gather all the taxonomy\u2019s\n\nrequired information. Due to this fact, we propose a more general approach on the next chapter.\n\nTable 2.3 provides an overview of the taxonomies discussed in this chapter.\n\n\n\n22 Chapter 2. Background and Related Work\n\nTable 2.3: Summary of the discussed malware taxonomies.\nMalware Type Approach Section\n\nViruses, Worms\nand Trojans\n\nFiliol [54] divides computer infection programs into\nsimple\u2014logical bombs, Trojans\u2014and self-reproducing\u2014\nviruses and worms\u2014mentioning the malware behaviors\npotential overlap. Karresand et al. [79] also discusses\nthe combination of different behaviors and proposes a\ntaxonomy that is heavily dependent on AV descriptions.\nWeaver et al. [161] proposes a worms taxonomy that\nconsiders the attacker\u2019s motivation.\n\nSection 2.6.1\n\nBotnets\n\nCooke et al. [38] adresses the communication structures\nused between bots and their motherships. Dagon et\nal. [42] uses graphs to model botnets topologic organiza-\ntions. Rajab et al. [1] considers the behaviors performed\nby bots during the infection procedure.\n\nSection 2.6.2\n\nSpyware\n\nSaroiu et al. [128] defines (sometimes overlapping) sub-\nclasses to spyware that are based on their expected be-\nhavior. Boldt et al. [23] classifies spyware according to\nthe risk they pose to the security principles of availabil-\nity and confidentiality.\n\nSection 2.6.3\n\nRootkits\n\nRutkowska [127] proposes a taxonomy based on the\nmodifications that a malware sample performs on the\ninfected operating system. It considers mainly stealth\nmalware and the violation they can cause to the integrity\nof the target.\n\nSection 2.6.4\n\n2.7 Concluding Remarks\n\nThe lack of a consistent taxonomy that embraces most of the malware species is a clear\n\nconclusion of this chapter and the main motivation for this thesis. Furthermore, a more useful\n\ntaxonomy to classify malware should include the ability to automate the classification process\n\nso as to help the security analyst responsible for handling a malware infection incident. Due to\n\nthe level of detail and dependence upon external entities or specific knowledge about the inner\n\nworkings and/or organization of some types of malware, we reasoned that automation can be\n\nhard for most of the presented taxonomies. We also presented in this chapter a brief history of\n\nmalware, from just intelectual concepts to full-blown weapons of an ongoing cyberwar. In addi-\n\ntion, we discussed the unaddressed issues of current malware naming schemes, introduced basic\n\nconcepts on the field and finally summarized recent research available on malware taxonomies.\n\n\n\nChapter 3\nA Behavior-Centric Malware Taxonomy\n\n3.1 Introduction\n\nAvailable malware taxonomies try to explain the behavior of a certain malware class by\n\nmeans of the attacks they launch, the kind of damage they cause or the way they are structurally\n\norganized to perform malicious activities. However, they are tied to a naming scheme that\n\nconsiders \u201cviruses\u201d, \u201cworms\u201d, \u201cTrojans\u201d and other identifiers as classes and attributes to them a\n\nstatic behavior, such as \u201cappends itself to a file\u201d or \u201cautonomously propagates\u201d.\n\nIn this chapter, we define the different aspects of \u201cbehavior\u201d that a program can present,\n\nbriefly discuss other research about malware behavior and, finally, propose a novel taxonomic\n\nscheme based solely on the malicious behavior of a program as it compromises a victim\u2019s system.\n\nThis way, we intend to effectively help incident response efforts as well as to provide a better\n\nunderstanding of a malware sample under analysis, fulfilling important requirements of a good\n\ntaxonomic scheme.\n\n3.2 Behavioral Aspects of Malware\n\nMalicious programs behave most of the time similarly to benign programs. Therefore, to\n\n\u201canalyze\u201d a piece of software, we need to pinpoint aspects of its behavior that serve the purpose\n\nof characterizing malignity in it. We mention previous works on malware behavioral aspects\n\nand redefine \u201cmalware behavior\u201d in the scope of this thesis.\n\n3.2.1 Recent Work on Malware Behavior\n\nFiliol et al. propose a theoretical model to perform behavior-based detection of infectious\n\nactions [56]. Their work presents a strong mathematical basis to define different types of be-\n\nhavior and is an extension to a previous work that was capable only of handling sequences of\n\nbytes [55]. The limiting factor is that their approach requires the malware\u2019s source code, which\n\nis sometimes difficult to obtain.\n\nJacob et al. describe a malicious behavior model that is based on attribute grammars [74].\n\nThey propose an abstraction layer to bridge the semantic gap between the behavior-based\n\n23\n\n\n\n24 Chapter 3. A Behavior-Centric Malware Taxonomy\n\ndetection of malware and subtleties of platforms and systems. They trace a malware sample\n\nbehavior through its execution in a virtualized enviroment in order to monitor the sample\u2019s\n\nsystem calls. These system calls are then translated to their malicious behavior language. They\n\nexamine and formally define four types of malware behavior.\n\nMartignoni et al. propose to bridge the semantic gap using behavioral graphs that are\n\nmanually built to correlate common actions found in malicious bots, such as e-mail sending and\n\ndata leaking [97]. They evaluate seven kinds of behaviors related to bots; thus, their coverage\n\nis mostly based on network actions.\n\nBayer et al. provide a view on different behaviors presented by almost one million malware\n\nsamples that were analyzed by Anubis over 2007 and 2008 [87]. They produced statistics and\n\nanalyzed trends, showing the percentage of observed samples that performed a variety of actions,\n\nfrom a simple file creation to the installation of a Windows kernel driver. We took some of their\n\nobserved behavior to compose our suspicious activity definitions but, instead of analyzing the\n\noverall scene, we tried to delve into behaviors we believe to pose risk to target systems.\n\n3.3 Definitions\n\nGeneral Behavior. We consider the general behavior of a program as the set of actions\n\nperformed during its execution by an operating system. We define \u201caction\u201d based on some\n\nattributes: source of action (usually the malware process), operation (create, delete, write, ter-\n\nminate and so on), object (file, process, network, registry, mutex, memory), target of action\n\n(the name or path to the object that is subject to one of the available operations), and argu-\n\nments (additional parameters). Thus, an action \u201c?i\u201d is a tuple composed by the values of the\n\naforementioned attributes and, therefore, we define the general behavior as follows:\n\nDefinition 1 Let B be the general behavior of a malware sample Mk, composed by the set of\n\nN actions ?1,?2, ...,?N performed during its execution, so that B(Mk) = {?1,?2, ...,?N}.\n\nThe set of actions that compose a behavior can be divided into groups according to their\n\nnature: if an action interferes with the environment, i.e. changes the state of the system, it is\n\npart of an active subset of the behavior. This is the case of actions that involve a file write,\n\ndelete or creation, for instance. Otherwise, the action is passive, meaning that it gathered a\n\npiece of information without modifying anything, for example, read, open or query something.\n\nHowever, there is a subset of the general behavior that is neutral, i.e. the actions can\n\nbe either active or passive, but they do not lead to a malign outcome. The neutral behavior\n\ncontains common actions that are performed during a normal execution of any program, such as\n\nto load standard system libraries, to read or to configure registry keys and to create temporary\n\nfiles.\n\nSuspicious Behavior. When a malicious program is executed, each of its actions can be\n\nconsidered suspicious. These actions constitute a suspicious behavior that, when analyzed, may\n\nreveal important details related to the attack. For instance, a malware sample that downloads\n\nanother piece of malicious code and use it to spread itself has to perform a network connection,\n\n\n\n3.3. Definitions 25\n\nto write the file containing the malicious code in the compromised system and to launch the\n\nprocess of the downloaded file that will handle the spreading process.\n\nTherefore, we are interested only in actions that modify the state of the compromised system\n\n(the active subset of the general behavior) at the same time that we want to ignore the actions\n\nthat are considered normal to a program\u2019s execution (the neutral behavior). Hence, we define\n\nthe suspicious behavior as follows:\n\nDefinition 2 Let Mk be a malware sample whose general behavior B(Mk) is divided into the\n\nactive behavior BA(Mk) and the passive behavior BP (Mk). Then, B(Mk) = BA(Mk)?BP (Mk).\nLet BN (Mk) be the malware sample\u2019s neutral behavior so that BN (Mk) ? BA(Mk) ? BP (Mk).\nThus, the suspicious behavior BS(Mk) is equal to BA(Mk) ?BN (Mk).\n\nThe collection of suspicious behaviors and a few exceptions pertaining to passive behaviors\n\nallows us to identify the potentially dangerous behaviors discussed next.\n\n3.3.1 Potentially Malicious Behaviors\n\nDuring execution, a program interacts actively and passively with the operating system.\n\nThus, benign software presents active behavior such as creating new registries, writing values\n\nto registry keys, creating other processes, accessing the network to send debug information or\n\nto search for updates, downloading and writing new files etc., which modify the system state in\n\nan authorized manner.\n\nTherefore, as any piece of software does, malware interact with the operating system in\n\nthe same way. However, malware interactions cause undesired or unauthorized changes in the\n\noperating system settings. The discovery of suspicious behaviors to categorize malware is a\n\ndifficult task, as a legitimate or benign application may also present one or more of these\n\nbehaviors, as mentioned above.\n\nDespite this fact, as it is not expected that a malware sample performs only one of the\n\n(network and operating system) listed behaviors, we also consider in the categorization process\n\nthose that do not pose a severe risk to the compromised system. Hence, less risky behaviors\n\nare included as we believe that they provide a better understanding about an analyzed mal-\n\nware sample, thus allowing better decisions related to incident responses or counter-measures\n\nprocedures.\n\nTo the extent of this thesis, we gathered 24 suspicious behaviors that are listed below. They\n\nare initially grouped based on their venue (network or operating system features). On the one\n\nhand, we have tried to be as complete as our malware collection allowed us to be. On the other\n\nhand, the taxonomy proposed in this thesis has as a main objective to be extensible, so it should\n\nbe easy to add new behaviors to our knowledge base.\n\nNetwork Patterns\n\nNetwork activity patterns that may point to suspicious behaviors are:\n\n\n\n26 Chapter 3. A Behavior-Centric Malware Taxonomy\n\nInformation Stealing. Information related to the operating system or the user can be stolen\n\nthrough the network, such as the hostname, hardware data, network interface data, OS version\n\nand credentials. An adversary may use this information to choose targets for an attack, or to\n\nmap her compromised machines (e.g., zombie computers that are part of a botnet). In a directed\n\nattack, sensitive documents may be stolen and transferred to an FTP server, for instance. Also,\n\ninformation can be stolen through a POST (HTTP method) performed on a compromised\n\nserver, a FTP transfer, an SQL update query to a remote database, an IRC (Instant Relay\n\nChat) communication or an e-mail message sent through an open SMTP server. We choose the\n\nfollowing information as interesting ones to define this behavior:\n\n1. Stealing of system/user data.\n\n2. Stealing of user credentials or financial information.\n\nScanning. Malicious programs often perform scans to search for local or remote targets.\n\nThese scans aim to discover information about the targeted systems to allow malware to dis-\n\nseminate, e.g., operating system and applications version, opened network ports, vulnerable\n\nservices. Worm-like malware need to perform scans over the network to find possible targets for\n\nspreading. This involves the search for known vulnerable services or unprotected/open network\n\napplications. Apart from spreading, a malware sample may also perform scans to map a network\n\ntopology or to find trampoline systems that could be used to launch attacks anonymously.\n\nDownloading. Some types of malware consist of several pieces that execute specialized tasks.\n\nThus, the first piece\u2014the downloader\u2014is responsible for downloading other components, such\n\nas libraries, configuration files, drivers or infected executable files. This compartmentalization\n\nis also used by malware developers to try to avoid antiviruses or other security mechanisms.\n\nThis activity can also indicate a drive-by download, which is a download commonly performed\n\nduring a user\u2019s Web browsing without his/her knowledge. We will consider executable files or\n\nlibraries to specialize this behavior into:\n\n1. Download of known malware.\n\n2. Download of unknown file.\n\nE-mail sending. A malicious program can communicate with its owner through e-mail to\n\nannounce the success of an attack or to send out sensitive data from the compromised machine\n\n(see evasion of information). Also, a compromised machine can be used as an unsolicited e-mail\n\nserver, sending thousands of spam on behalf of an attacker that is being paid for the service.\n\nThe victim\u2019s machine is \u201crented\u201d and acts as a provider of spam or phishing, aiming to distribute\n\ncommercial messages or even malicious links or attached infected files [28]. Thus, it is interesting\n\nto \u201cflag\u201d when a program sends an e-mail message, as it may happen without the user\u2019s consent.\n\n\n\n3.3. Definitions 27\n\nIRC/IM connection. If an attacked system becomes part of a botnet, it needs to \u201cphone\n\nhome\u201d, i.e. to contact a C&amp;C1 server to receive commands, updates etc. Botclients commonly\n\nconnect to an Instant Relay Chat (IRC) server that acts as a C&amp;C. To define this behavior,\n\nwe consider connections to IRC or Instant Messaging (IM) servers as well as IRC commands\n\npassing as clear text within the network traffic:\n\n1. Connection to known IRC/IM port.\n\n2. IRC/IM unencrypted commands.\n\nOS Patterns\n\nActivity patterns related to operating system settings, services or applications that may\n\npoint to suspicious behaviors are:\n\nShutdown defense mechanisms. Malware authors usually try to identify and disable security-\n\nrelated processes in order to evade detection when compromising a victim\u2019s system. This activity\n\ncan be accomplished by turning off the system firewall or known antivirus engines, through the\n\ntermination of their processes and/or removal of the associated registry keys. In addition, there\n\nare registry keys that are critical to the normal operation of a system, e.g., the one that allows\n\ninitialization in secure mode. The removal of this kind of key can cause instability in the sys-\n\ntem and inconvenient obstacles during a disinfection procedure. We consider the following as\n\nsuspicious activities when referring to this behavior:\n\n1. Disable system firewall.\n\n2. Disable system update notification.\n\n3. Terminate known antivirus engine.\n\n4. Removal of critical registry key.\n\nAdd object in sensitive area. This behavior is tied to the objects that a malware sample\n\nmay create on a system to perform malicious tasks. These objects can be new libraries (DLLs\n\nin our case) or executable files, overwritten library/executable files so as to subvert their use,\n\nmutex elements to lock resources and avoid accesses (mutex names may be used either as part of\n\ndetection signatures or by malware samples to avoid the reinfection of a system already compro-\n\nmised by a \u201cmember\u201d from the same family), protecting malicious resources from termination\n\nor crashing. Thus, we identify the following suspicious activities:\n\n1. Creation of new DLL or EXE.\n\n2. Modification of existing (system) DLL or EXE.\n\n3. Creation of unusual mutex.\n\n1Command and Control server that manages the bots that belong to a botnet.\n\n\n\n28 Chapter 3. A Behavior-Centric Malware Taxonomy\n\nSubversion of Internet browsing. The subversion of Internet browsing is very dangerous\n\nas users are, in most cases, unaware of the changes that occurred in their systems. A Trojan-like\n\nmalware sample can modify the network name resolution file to forward users to a compromised\n\nserver and lure them into supplying their data. These can be credentials (e-mail, online banking,\n\nWeb applications such as Facebook and Twitter) or financial information (credit card numbers).\n\nThis kind of modification tricks users to access fake online banking sites as a direct cause of\n\nmalware known as \u201cbankers\u201d. Another activity that is similar to the aforementioned one occurs\n\nwhen a malware sample loads a configuration file in the browser\u2019s memory (when it is running)\n\nthat changes the proxy on the fly, resulting in an automatic redirection of the user to a malicious\n\nsite. Malware usually do it using PAC (proxy auto-config) files, which are effective on different\n\noperating systems and browsers. Moreover, it is possible to silently load a plugin such as a\n\nBHO (browser helper object) that modifies the browser behavior. We address three ways to\n\naccomplish this:\n\n1. Modification of the name resolution file.\n\n2. Modification of the browser proxy through PAC files.\n\n3. Modification of the browser behavior via BHO loading.\n\nRemoval of evidence. Some malware disguise themselves as system processes to deceive\n\nsecurity mechanisms or forensic analysis: they can \u201cdrop\u201d a file that was embedded in a packed\n\nway inside their main file or download the actual malicious program from the Internet. In some\n\ncases, these droppers/downloaders remove the evidence of compromise, deleting the installation\n\nfiles after the attack. In addition, a malware sample that is able to identify it is under analysis\n\nmay also remove itself from the system.\n\nDriver loading. Drivers are kernel modules that access the most privileged level of a system.\n\nA driver makes the interface between the operating system and the hardware, such as network\n\ninterfaces, graphic cards and other devices. However, drivers are also used by rootkits, a kernel-\n\nlevel kind of malware that can hide their processes, files and network connections in order to\n\nremain undetected.\n\nProcess hijacking. To disguise its presence and avoid monitoring, malware samples can write\n\ninto the memory of another process (a benign one) and take control of it. Thus, the \u201chijacked\u201d\n\nprocess can create a thread and perform malicious actions even if the original malware process\n\nis terminated.\n\nPersistence. Once a system is infected, the motivation behind the malware sample may lead\n\nto the need of \u201csurvivability\u201d, i.e. this sample should be able to survive a reboot and execute on\n\na permanent basis. There are many reasons to this type of behavior, such as to keep a network\n\nport in an open state to allow the communication with an attacker (working as a backdoor), to\n\nperform a daily routine (collect files, credentials, logs), to connect to a remote system so as to\n\nreceive commands (botnets) or even to wait for a specific date or event to occur.\n\n\n\n3.4. The Proposed Taxonomy 29\n\nSuspicious-Passive Patterns\n\nPassive behaviors, which can be part of previous step leading to a malicious activity (e.g.,\n\nsome information related to the target that may cause a change of the expected behavior or a\n\nfurther exposure), should also be considered:\n\nLanguage checks. Malware that have well-defined targets usually verify the system\u2019s in-\n\nstalled language. This is a behavior common to Internet banking malware, as they are specially\n\ncrafted to attack a specific type of user or application. In this case, the language checking\n\nserves two main purposes: to identify if the system has the appropriate language to run (if not,\n\nexit) and to avoid publicly available malware analysis systems (e.g., a malware sample targeting\n\nBrazilian banks that checks for the Portuguese language will terminate its execution if analyzed\n\nin an English or German analysis system).\n\nSystem/user information reading. To perform the evasion of information related to the\n\nsystem or its users, malware samples need to obtain that information, usually from the registry.\n\nThis type of information may also serve as management data to an attacker, i.e. a table of\n\ncompromised machines and their peculiarities, such as username, hard disk identifier, operating\n\nsystem version, patching level etc.\n\nAlthough finding these patterns does not indicate malignity, their combination with another\n\nbehavioral feature can bring light to an analysis. For instance, if there is a language check in\n\na behavioral trace that ends abruptly or that terminates without presenting other behaviors,\n\nit may be possible that a malware sample is targeted to a language different from the ones\n\ninstalled on our system.\n\n3.4 The Proposed Taxonomy\n\nBased on interesting attributes from other malware taxonomies (Section 2.6), the suspicious\n\nbehaviors extracted from our malware collection and from the recent literature (Section 3.2.1),\n\nand aiming to meet the taxonomy requirements that make sense regarding our scope, we propose\n\na novel taxonomic scheme with three dimensions, which is detailed below. The dimensions of\n\nthe proposed taxonomy are:\n\n\u2022 Class, an attribute that describes the type of behavior observed in a malware sample\n(Section 3.4.1).\n\n\u2022 Suspicious activity, which specifies the potentially malicious (or at least dangerous)\nactivity performed by a malware sample and that caused its assignment to a certain class\n\n(Section 3.4.2).\n\n\u2022 Violated security principle, to make it better and simpler to understand the damage\nand risks that a malware sample poses to its victim.\n\n\n\n30 Chapter 3. A Behavior-Centric Malware Taxonomy\n\nThe resulting scheme assigns a label to a malware sample that allows us to map it back to\n\nthe taxonomic descriptions. Thus, a sample may be in several classes if it presents multiple\n\nbehaviors.\n\n3.4.1 Malware Classes\n\nWe mentioned in the previous chapter that it is very difficult to stick to some requirements for\n\na taxonomy regarding malware. The main issue in our case is to meet the mutual exclusivity\n\nwhen assigning a class to a sample. Although a malicious program might exhibit only one\n\nbehavior that predominantly characterizes it as pertaining to a certain class, there may be\n\nother behaviors that allow us to assign the sample to other classes also. Thus, we propose in\n\nthis section a non exhaustive set of possible classes and state that a malware sample may be\n\ntied to more than one of them at the same time.\n\nStealer. A stealer is a piece of software that captures data (sensitive or not) from the com-\n\npromised machine, potentially causing information exposure or identity theft. Stealers can\n\ndisclosure confidential information from a system as well as from users, credentials (usernames,\n\npasswords, credit cards, Internet banking account and login information etc.), documents, keys\n\npressed, opened windows and mouse clicks. Malware known as keyloggers, spyware, bankers\n\nand some botclients fit in this class.\n\nEvader. Evasive malware samples try to bypass system security features or computer foren-\n\nsics procedures through the use of techniques that range from removing their own file after\n\ninfections to stopping antiviruses engines and firewalls executing on the compromised system.\n\nThere are malware samples that use packers to obfuscate themselves or leverage anti-analysis\n\ntechniques to identify if they are being executed under a debugger, an emulated or a virtualized\n\nenvironment. Additionally, modern malware may launch several shadow processes to distribute\n\ntheir malicious actions [95] while evading detection mechanisms. Evasive malware can also be\n\nseen as deceptive programs. A deceptive program lure users by making them believe that it has\n\na legitimate functionality or by trying to disguise itself as a system \u201cresource\u201d. For instance,\n\nrecently a malware started to execute as an antivirus engine to make users to provide their credit\n\ncard numbers (so that users buy the fake antivirus to clean their infected machines) [144]. Other\n\ntype of malware can disguise itself in the form of Internet bank protection mechanisms updates,\n\ntricking users to input their one-time password (OTP) tables and all online banking credentials.\n\nMore common malware samples install and launch themselves using the same name (sometimes\n\nwith minor modifications or typos) of known system\u2019s processes, or inject themselves to an-\n\nother processes. This type of malware may also need to operate stealthily. To operate in a\n\nstealthy manner, a program must run with administrative privileges or even greater, as in case\n\nof hardware-assisted virtual machine (HVM) rootkits [43]. Moreover, to get access to kernel\n\nresources, such as device drivers, userland2 malware need to escalate privileges to assure the\n\ntotal control of the compromised system. Rootkits are a common type of privileged malware,\n\n2Userland malware executes with limited access privileges, such as an ordinary user, i.e. non administrator.\n\n\n\n3.4. The Proposed Taxonomy 31\n\nas they usually load new drivers, modify system drivers and applications or change the system\u2019s\n\nflow of data while trying to remain unnoticed in the system. This class enables impersonation\n\nand process hijacking attacks.\n\nDisrupter. Malicious programs can be used in directed attacks to disrupt computational\n\nresources to make them unavailable. Disrupters may be as simple as flooders that consume\n\nbandwidth or malware that self replicate until the exhaustion of processing power or memory,\n\nor they may launch massive and distributed denial of service attacks against major Internet sites\n\nwith several motivations, e.g., protesting, politics, competition, etc. Even worse, this type of\n\nmalware could inflict physical damages to infrastructures, e.g., Iran nuclear plant [16], or attempt\n\nagainst human lives, e.g., the shutdown of a hospital near Atlanta, Georgia, US [169]. However,\n\ntheir detection or their behavioral profiling can be difficult, as they are usually stealthy and/or\n\ndependent on specific frameworks, programs or devices to run properly. On the other hand,\n\nmalware samples can connect to remote systems to wait for commands (e.g., scan a network,\n\ndisseminate, attack a system). Although this type of behavior is not necessarily malicious while\n\nthe sample is waiting the command, the result after an order is usually a scan, an exploit\n\nattempt, a flooding, a spam sending and so on. This way, we conclude that this type of malware\n\ncan receive orders or act autonomously, disrupting their target environment functioning locally\n\nand/or remotely.\n\nModifier. To perform its malicious activity, a program may need to modify objects of the\n\ncompromised system. These changes include the overwriting of processes, the removal of files,\n\nthe modification of system settings (e.g., proxy, name resolution files, configuration directives to\n\nexecute after a reboot), the substitution of a system library or binary, etc. Botclients, bankers,\n\ndownloaders, droppers and Trojans pertain to the modifier class.\n\n3.4.2 Observed Suspicious Behaviors and Related Classes\n\nThe set of behaviors described in Section 3.3.1 represents some of the possible suspicious\n\nactivities that may compose a malware class. For instance, a sample whose type is \u201cstealer\u201d can\n\naccomplish its information stealing task in several manners, such as sending system data through\n\nHTTP methods, credentials through e-mail and so on. Table 3.1 presents the correspondence\n\nbetween previously defined suspicious behaviors and their related classes. Table 3.1 also contains\n\na set of labels to identify each behavior within the malware class in a shorter manner. This\n\nled us to produce a reduced naming scheme that is based on the combination of the classes for\n\nwhich a malware sample pertains (C = {D,E,M,S}), associated with the specific subset of\nbehaviors (BC ={[VS, ES, IP, IC], [RE, RR, TA, TF, TU, LC], [NB, CB, UM, HC, PL, BI, Pe,\nDK, DU, DL], [IS, CS, IR, PH]}). Therefore, a malware sample can be classified based on the\nperformed infection behavior and its label will be \u201cassembled\u201d according to it. Thus, the format\n\nof a general label is:\n\nC1BC1.C2BC2.C3BC3.C4BC4\n\n\n\n32 Chapter 3. A Behavior-Centric Malware Taxonomy\n\nThis way, a credential stealer that downloads an unknown file and injects a BHO to subvert\n\nthe victim\u2019s browser would be represented as \u201cM[DU,BI].S[CS]\u201d.\n\nTable 3.1: Proposed malware classes, suspicious behaviors and associated labels.\nClass Behavior Label\n\nEvader Removal of Evidence RemEvd [RE]\nRemoval of Registries RemReg [RR]\n\nAV Engine Termination TerAVe [TA]\nFirewall Termination TerFwl [TF]\n\nNotification of Updates Termination TerUpd [TU]\nLanguage Checking LngChk (Suspicious) [LC]\n\nDisrupter Scanning of Known-Vulnerable Service VulScn [VS]\nE-mail Sending (Spam) EmlSpm [ES]\n\nIRC/IM Known Port Connection IrcPrt [IP]\nIRC/IM Unencrypted Commands IrcCom [IC]\n\nModifier Creation of New Binary NewBin [NB]\nModification of Existing System Binary ChgBin [CB]\n\nCreation of Unusual Mutex UnkMut [UM]\nModification of the Name Resolution File HstChg [HC]\n\nModification of the Browser Proxy Settings PacLdn [PL]\nModification of the Browser Behavior BhoInj [BI]\n\nPersistence Persis [Pe]\nDownload of Known Malware DldKmw [DK]\nDownload of Unknown File DldUnk [DU]\n\nDriver Loading DrvLdn [DL]\n\nStealer Stealing of System/User Data InfStl [IS]\nStealing of Credentials or Financial Data CrdStl [CS]\n\nSystem/user Information Reading InfRdn (Suspicious) [IR]\nProcess Hijacking PrcHjk [PH]\n\nWe also propose a depictive matrix (to be included in a dynamic analysis report) that is\n\nbased on our defined behaviors. This matrix is extensible, since new lines and/or columns can\n\nbe easily inserted to reflect future additions to our taxonomy, and it aims to provide a quick\n\nguide to the report\u2019s reader. This matrix also allows for the visual identification of a sample\n\nas being similar (or not) to another previously analyzed sample in a fast and intuitive way.\n\nFigure 3.1 shows the overall current matrix disposition whereas Figure 3.2 shows the matrix for\n\nthe previously mentioned example of malware sample (M[DU,BI].S[CS]).\n\nFigure 3.1: Behavioral matrix based on our taxonomy.\n\n\n\n3.5. Concluding Remarks 33\n\nFigure 3.2: Behavioral matrix for M[DU,BI].S[CS].\n\nFurthermore, a behavior exhibited by a malware class may violate one or more security prin-\n\nciples that affect users and the adequate functioning of the system. Quoting Matt Bishop [22],\n\n\u201ccomputer security rests on confidentiality, integrity, and availability.\u201d Thus, to the extent\n\nof this work, we consider these security principles when regarding the damage that a certain\n\nmalicious behavior can cause. Briefly, they can be described as follows:\n\n\u2022 Integrity: refers to the \u201ccredibility\u201d of a subject content, i.e. the assurance that this\nsubject\u2014a file, an information, a piece of data\u2014is not changed in an improper or unau-\n\nthorized manner.\n\n\u2022 Confidentiality: refers to the \u201cneed to know\u201d principle, meaning that only those that\nallowed to do so should access an information or resource. The principle of confidentiality\n\nserves to the purpose of keeping the privacy and/or secrecy of a subject.\n\n\u2022 Availability: refers to the possibility of access for use at any time that a resource or\ninformation is required, i.e. the subject must be available, providing its intended service.\n\nTo illustrate our proposed behavioral-centric taxonomy, we depict a mapping among the\n\nsecurity principles that can be violated and the malware classes and their related behaviors in\n\nFigure 3.3.\n\n3.5 Concluding Remarks\n\nIn this chapter we discussed malware behavior. We defined types of behaviors, focusing our\n\nresearch mainly on the active set of behaviors, i.e. activities that can cause changes to a com-\n\npromised system. Moreover, we described some suspicious and dangerous activities that may\n\nbe performed during the execution of a program. These activities are commonly observed in\n\nmalware infections; thus, any sign of them should be observed carefully. Furthermore, we pro-\n\nposed a new taxonomic scheme that separates observed behaviors in classes (disruptor, evader,\n\nmodifier, stealer), whose main goal is to be clear, understandable, easy to maintain and to up-\n\ndate, and to overcome some of the inconsistencies seen on currently available naming schemes.\n\nAlthough the proposed taxonomy is not complete, as it is based on the authors observations\n\nabout malware behavior along the last decade and their expertise related to malware analysis,\n\nit reflects most of the common malicious behaviors seen in the wild. Therefore, this taxonomy\n\ncan be used for malware classification, detection and incident response procedures, generalizing\n\nthe potentially dangerous behaviors that a malware sample can present, while at the same time\n\nclarifying the impact of the infection without cryptic naming schemes.\n\n\n\n34 Chapter 3. A Behavior-Centric Malware Taxonomy\n\nFigure 3.3: Mapping sets of behaviors to their classes and the security principles they violate.\n\n\n\nChapter 4\nEvaluation of the Taxonomy\n\n4.1 Introduction\n\nIn this chapter, we aim to evaluate and validate the taxonomy by collecting and dynamically\n\nanalyzing malware samples in order to generate behavioral profiles for each one of them. These\n\nbehavioral profiles will then be used to allow for the assignment of a sample into one or more of\n\nthe taxonomic classes, consequently describing the malicious behaviors that it exhibits. To this\n\nend, we show the architecture proposed and developed that produces the behavioral profiles and\n\nanalyze a large and diverse set of actual malware samples, providing a view on their malicious\n\nbehaviors based on this taxonomic scheme and a discussion about the results.\n\n4.2 Behavioral Profiling\n\nTo extract information about the behavior of a malware sample, we need to execute it in\n\na controlled environment and observe its actions. We gather the behavioral profile of malware\n\naccording to the defined set of behaviors and activities defined in Chapter 3.\n\nAlthough the focus of this thesis relies on extracting malware behavior by running the ex-\n\necutable, we prototyped a framework that is also able to analyze Web-related malware that\n\nperform attacks at the client-side of a system. To this end, we provide some additional informa-\n\ntion that is directly related to this thesis theme but that is not fully addressed on it to keep the\n\nscope tight. Therefore, we detail the framework from which we obtain the behavioral profiles,\n\nwhile at the same time emphasizing that not all Web malware detection techniques explained\n\nin the text were used in the present work.\n\nThus, we initially motivate the development of this framework by briefly discussing Web\n\nmalware. Currently, the Web is the main vector to install malware in attacked systems. Web\n\nmalware, i.e. malicious code inside Web pages, exploit the browser or some of its components\n\nand perform drive-by downloads that install malicious programs in the compromised system.\n\nThey can also be used to steal personal cached information and even to control the browser.\n\nTwo methods are often used to make the victims\u2019 browser load malicious content, either\n\nby injecting malicious codes into benign pages and waiting for casual users to access it, or by\n\nsending phishing messages containing malicious files or links. The infection of benign sites is\n\n35\n\n\n\n36 Chapter 4. Evaluation of the Taxonomy\n\nperformed through the exploitation of some vulnerability in the Web application (server-side),\n\nfollowed by the insertion of the malicious content onto that server. The phishing messages are\n\nused to lure the victims to execute files or to access links (client-side) that lead them to the\n\nmalicious content.\n\nTo develop and improve protection mechanisms deployed on the client-side, it is necessary\n\nto study and deeply understand these malicious pages and programs. There are several systems\n\nthat perform this kind of analysis, but they are focused either on Web or operating system (OS)\n\nmalware.\n\nOne of the major problems that makes the malware analysis process hard is the use of\n\nobfuscation techniques via packers. These packers change the code in a way that still keeps the\n\nmain functionality, but turn the manual or static analysis into a very hard task. Moreover, some\n\npackers insert blocks of code inside the obfuscated file to verify whether it is being executed on\n\nan emulated or virtual environment, hiding its malicious behavior in such cases.\n\nTo analyze malware, we developed a framework that obtains URLs and files from a spam\n\ncrawler and from malware collectors, and transparently performs their analysis. This framework\n\nis capable of analyzing both Web and OS-based malware and its modular design makes it possible\n\nto extend it to other file types or languages. We deployed a prototype and tested it against actual\n\nmalware from our collected dataset, presenting results that show that our framework has some\n\nadvantages over the existing systems that perform Web and OS-based malware analysis. The\n\nevaluation performed using Web malware shows that our detection rate is much better than that\n\nof other existing systems. Also, due to the way we capture the behavior of OS malware, we can\n\ndeploy the monitoring system in emulated, virtual or real environments, providing an advantage\n\nover some of the existing malware analysis systems that are tied to specific virtualized [168],\n\nbare-metal [83] or emulated environments [86].\n\nBefore showing the proposed architecture, we present some related work related to Web and\n\nOS malware analysis.\n\n4.2.1 Malware Analysis Systems\n\nThere are several analysis systems designed to monitor the behavior of Web or OS malware,\n\nas described in the following sections. However, each of them focuses solely on one of the\n\nmentioned malware types. Below, we present the main systems and techniques that are used to\n\nanalyze malware, to produce informative reports about them and, in the case of Web malware\n\nanalyzers, to tell whether the analyzed sample is malicious or benign.\n\nOS Malware analysis\n\nA malware behavior can be defined by the set of activities performed on the operating\n\nsystem. These activities include modifying files, writing registry values, establishing network\n\nconnections, creating processes etc. Malware analysis is the procedure applied to a malicious\n\nprogram in order to extract features that can characterize it.\n\nMalware analysis can be performed in a static way, i.e. without executing the sample, or\n\ndynamically, by monitoring its execution. The use of packers make the static analysis a very\n\n\n\n4.2. Behavioral Profiling 37\n\ndifficult and slow [103] process. Therefore, the most frequently used systems for malware analysis\n\nuse the dynamic approach. Common techniques to dynamically extract malware behavior are:\n\nVirtual Machine Introspection (VMI), System Service Dispatch Table (SSDT) Hooking, and\n\nApplication Programming Interface (API) Hooking.\n\nIn the case of VMI, a virtual environment is used to execute the malware and restore the\n\nsystem after the analysis. Monitoring is performed in an intermediary layer, called Virtual\n\nMachine Monitor (VMM), which is interposed between the virtual system and the real one. This\n\napproach allows for the extraction of low-level information, such as system calls and memory\n\nstate. The down side is that this kind of analysis always needs a virtual environment. Moreover,\n\nsome types of malware try to realize whether they are under analysis through the detection of\n\na virtual environment. Thus, the malicious actions may not be executed [121] if the virtual\n\nenvironment is detected. VMI is used by the Anubis [72] system.\n\nSSDT is a Windows kernel structure that contains the addresses of native functions. The\n\nSSDT hooking is performed at kernel level by a specially crafted driver that modifies some\n\naddresses of the SSDT to point to functions inside this driver. These functions can change the\n\nexecution flow and the values returned to programs. This technique can be used in virtual,\n\nemulated or real environments as its flexibility is linked to the driver\u2019s mobility. However, there\n\nmay be some issues related to rootkits\u2019 analysis, as they also operate at the kernel level and\n\npossess the same privileges of the monitoring driver. The framework presented in this text uses\n\nthis technique to capture the malware behavior at the OS level.\n\nAnother technique to monitor malware execution behavior is the API hooking. It modifies\n\nthe binary under analysis to force the execution of certain functions that are in the monitoring\n\nprogram, before calling the selected system APIs. On the one hand, this technique is deployed\n\nat a level that is closer to the analyzed sample, so it is possible to easily obtain higher-level\n\ninformation. On the other hand, this also makes it easy for a malware sample to detect the\n\nmonitoring action through integrity checking. Furthermore, malware can issue system calls\n\ndirectly from memory-mapped addresses, evading this kind of monitoring. This approach is\n\nused by the CWSandbox [168].\n\nWeb malware analysis\n\nWeb malware analysis is usually performed through a component located at the operat-\n\ning system or at the browser. In both cases, the monitoring system verifies whether the an-\n\nalyzed Web page contains malicious codes or not and provides some information about the\n\ncaptured behavior. The three most used (and publicly available) systems are JSand, PhoneyC\n\nand Capture-HPC, which are described below.\n\nJSand [40] is a low-interaction honeyclient that uses a browser emulator to obtain the be-\n\nhavior of the JavaScript code present in the Web page. Then, the system extracts some features\n\nfrom the obtained behavior and applies machine learning techniques to classify the analyzed\n\npage as benign, suspicious or malicious. The main problems related to this approach are its\n\nlimitation to JavaScript-only analysis and the inability to detect attacks that steal information\n\nfrom the browser.\n\nPhoneyC [106] is another low-interaction honeyclient that uses a browser emulator to process\n\n\n\n38 Chapter 4. Evaluation of the Taxonomy\n\nthe analyzed Web page and is able to analyze JavaScript and VBScript codes. To detect exploits\n\nin those types of codes, it emulates certain vulnerable components. The limitations are the same\n\nas JSand\u2019s, except for the VBScript analysis.\n\nCapture-HPC [132] is a high-interaction honeyclient that uses a full-featured browser and a\n\nkernel driver inside a virtual environment to extract the system calls performed by the browser\n\nas it accesses the analyzed page. Then, it performs a classification based on these system calls,\n\nin order to obtain a benign or malicious result. Regardless of the aforementioned systems,\n\nCapture-HPC can detect attacks independently of the script language used, but only those that\n\ngenerate anomalous system calls.\n\n4.2.2 System Architecture\n\nThe architecture of our proposed framework can be seen in Figure 4.1, where the dark lines\n\nindicate the analysis from Web related files and URLs, and the dotted lines indicate the analysis\n\nof OS executable files. A spam crawler, malware collectors and manual input are the source\n\nof the samples, which are then forwarded to the Selector module. The Selector is responsible\n\nfor the identification of the sample type and its sending to the appropriate module. Windows\n\nexecutable files\u2014PE32 and DLL file formats\u2014are sent to the OS module, whereas Web-related\n\ncontent, such as URLs, HTML and JavaScript files, are sent to the Web module. The OS\n\nmodule extracts the sample behavior and send it to the Parser, which processes it, extracts\n\nthe high-level information and produces a report containing the analysis results. In contrast,\n\nthe behavior extracted by the Web module serves as input to four different processors, each\n\nof them being responsible for one type of malicious behavior detection. The General classifier\n\ncollects the results of these four processors and produces a summarized information report.\n\nWhen the Web module detects an executable file, for example, due to a drive-by download, this\n\nis forwarded to the OS module, which returns the sample\u2019s observed behavior.\n\nSelector\n\nWeb module\n\nOS module Parser\n\nYes\n\nShellcode verification\n\nJS signature verification\n\nAnomaly detection\n\nSyscall signature verification\n\nGeneral\nclassifier\n\nExecutable\nfiles\n\nURLs and\nWeb-related\nfiles\n\nWeb\nReport\n\nOS\nReport\n\nDrive-by \ndownload?\n\nSPAM crawler Files and \nURLs\n\nManual insertion\n\nMalware collector\n\nFigure 4.1: Framework\u2019s overall architecture.\n\nCollection. Apart from manual insertion, malicious content is obtained by a spam crawler\n\nand by malware collectors. The spam crawler periodically fetches emails from an account created\n\nespecially to receive spam. When the crawler finds a link or an attached file, that object is sent\n\nto the Selector. Malware collectors are low-interaction honeypots (systems that emulate some\n\nvulnerable services) that collect samples by downloading them after attempted exploits.\n\n\n\n4.2. Behavioral Profiling 39\n\nWeb module. The Web module performs its monitoring process through a Windows library\n\n(DLL - Dynamic Link Library) that hooks some functions from libraries that are required by\n\nthe Internet Explorer browser. When one of the monitored functions is called, the execution\n\nflow is changed to a function inside the monitoring DLL. It then logs all the needed information\n\nand redirects the execution flow back to the original function. We monitor actions that are\n\nexecuted by JavaScript code due to its wide usage in attacks as a client-side script language [47].\n\nThe monitored actions are related to string, ActiveX, decoding and array operations, DOM\n\n(Document Object Model) modifications, dynamic code execution and manipulation of personal\n\ninformation, such as cookies. The actions that the Web module captures are then sent to the\n\nfour available detection modules, each one responsible for one type of detection. The windows\n\nexecutable files obtained during the monitoring process by the Web module are sent to the OS\n\none, which in turn forwards the returned system calls to the detector that processes system call\n\nsignatures. The detection results are used to classify the analyzed sample.\n\nOS Module. The OS module is based on a Windows kernel driver and contains a pool of\n\nemulated and real environments. The SSDT hooking technique is used to monitor system calls\n\nperformed by the analyzed sample and its children-processes. The captured actions are related\n\nto file, registry, sync (mutex), process, memory, driver loading and network operations. When\n\nit detects the use of some packer that is known to cause problems in emulated environments or\n\nwhen the analysis in the emulated environment finishes with error, the sample is then sent to\n\nbe analyzed in a real system, i.e. neither emulated nor virtual.\n\nParser. The Parser processes the behavior extracted by the OS module and selects only the\n\nrelevant actions to insert into the analysis report. An action is considered relevant if it causes a\n\nmodification in the state of the system or if it incurs in sensitive data leakage. The parser not\n\nonly screens out the passive and neutral activities that are not interesting within the scope of\n\nthis thesis, but also applies the behavioral filters to the profile.\n\nBehEMOT (OS Module)\n\nThe \u201cOS module\u201d described above consists of a dynamic analysis system designed and de-\n\nployed to meet the requirements of malware behavior extraction. This system, BehEMOT (Be-\n\nhavioral Evaluation of Malicious Objects Tool), is able to monitor a running malware sample\n\nand to capture its operating system actions and network traffic, as well as the actions performed\n\nby launched child or hijacked processes. To obtain a malware sample\u2019s profile, the behavioral\n\nfilters described previously are applied to the BehEMOT output data1. An overview of these\n\nsteps can be seen on Figure 4.2, which shows the data flow from binary files to class assignment\n\n(report).\n\n1Appendix A shows an example of a BehEMOT analysis report.\n\n\n\n40 Chapter 4. Evaluation of the Taxonomy\n\nFigure 4.2: Steps to pinpoint suspicious behavior.\n\n4.2.3 Considerations about the Framework\n\nIn this thesis, we used the OS module of the aforementioned described framework to dy-\n\nnamically analyze a set of samples and to apply the behavioral filters defined in the previous\n\nchapter to the extracted profiles. With these profiles, we were able to evaluate the proposed\n\ntaxonomy. It is worth noting that the framework yielded promising results either in analyzing\n\nmalware that may crash other approaches\u2019 systems or in detecting Web malware with better\n\nresults than the most popular approaches. For a more detailed description and the complete\n\nresults, we point the reader to the work of Afonso et al. [5].\n\n4.3 Taxonomy Evaluation\n\nTo validate our proposed taxonomy, we obtained thousands of samples from different sources:\n\nspam and phishing e-mail messages, honeypots specially designed to collect malware [152],[153],\n\nprivate and public collections (specifically VxHeavens [160]). We extracted the general behavior\n\nof 12,579 unique2 malware samples. We scanned these samples using three antivirus tools that\n\nuse distinct engines: F-Prot3, Avira4 and AVG5. These AV tools provide identification labels in\n\ndifferent formats, which then required normalization. For instance, for the well-known malware\n\nfamily dubbed \u201cAllaple\u201d, we scanned one sample using the three AVs and obtained labels such\n\nas Worm/Allaple.D, WORM/Allaple.Gen and W32/Allaple.A.gen!Eldorado, which were then\n\nnormalized to simply \u201callaple\u201d. The normalization process aims to provide the family name\n\ngiven to a certain sample and, in case no family name is assigned, we obtain at least its generic\n\nclass (e.g., backdoor, worm), if available. The goal here is to obtain the distribution of the\n\nanalyzed samples, as well as to further compare the AV family groups with the behavioral\n\n2the uniqueness of the malware samples is based on the binary file\u2019s MD5 hash.\n3http://www.f-prot.com\n4http://www.avira.com\n5http://www.avg.com\n\n\n\n4.3. Taxonomy Evaluation 41\n\nclasses produced by our taxonomy.\n\n4.3.1 Samples Distribution regarding AV Labels\n\nThe main objective of using three distinct AV engines is to assign a label to a malware\n\nsample, so that disagreements can potentially be solved. If at least two of them agree that a\n\nsample is from the same family, or in the case when only one AV detect the sample as malware,\n\nthen this family label is assigned to that sample. Moreover, it is possible to observe (and\n\nanalyze) situations in which the three AV engines disagree or they do not detect the sample as\n\na known malware. We add an \u201cUNDECIDED\u201d tag to those samples that the three AV engines\n\nassigned distinct labels, and a \u201cCLEAN\u201d tag to those that are not detected by the three AV\n\nengines. Table 4.1 shows the distribution of the 12,579 samples in three categories: Undecided\n\n(each of the three AV engines providing a distinct label), Clean (the three having not detected\n\nthe sample) and Labeled (at least two engines having agreed upon the same label or only one\n\nengine detected the sample).\n\nTable 4.1: Distribution of malware samples in categories.\nUndecided Clean Labeled\n\n% 44.2 21.0 34.8\nAmount 5,559 2,640 4,378\n\nInterestingly, the \u201cUNDECIDED\u201d samples correspond to almost half of the total samples,\n\nthus illustrating the confusion that AV engines may cause to a user. Further to that, the 5,559\n\nsamples tagged as \u201cUNDECIDED\u201d are distributed among 2,018 unique label combinations. The\n\ndiversity of the top 15 combinations can be observed in Table 4.2. The samples assigned to\n\nthese labels amount to just over a quarter of the total 5,559 \u201cUNDECIDED\u201d samples. In this\n\ntable, we can verify that there are two occurrences of \u201callaple\u201d, \u201crahack\u201d and \u201cvirut\u201d in a different\n\nordering. It is worth to notice that \u201crahack\u201d is another name used for \u201callaple\u201d. Thus, if the AV\n\nvendors agreed to rely on a standard scheme to name their detected samples, those 217 (176\n\n+ 41) samples would not fall into the \u201cUNDECIDED\u201d group. Moreover, since the behavior of\n\nan \u201callaple\u201d sample is the same of that presented by an \u201crahack\u201d sample, the assigned labels\n\nare useless to explain the infection extension for a user. This corroborates our hypothesis that\n\ncurrent AV labels are, in general, meaningless and confusing.\n\nThe analysis of the individual AV labels revealed that there are 648 unique identifiers. We\n\nshow the 15 most frequent ones in Table 4.3, in which it is possible to notice that the three\n\nmost frequent identifiers are related to the generic labels \u201cgen\u201d, \u201ccrypt\u201d and \u201cclean\u201d. The first\n\none means \u201cgeneric\u201d, a term that is usually assigned when the AV engine is not able to identify\n\na proper family but detects the file as malicious. The second one refers to the type of packer\n\nused to obfuscate the malware sample, usually meaning that the file is encrypted. The last label\n\nmeans that the AV engine did not detect the file as malicious. Among the other identifiers, we\n\ncan observe other generic type terms to describe malware, such as \u201cbackdoor\u201d, \u201cTrojan\u201d, \u201cworm\u201d\n\nand \u201cdownloader\u201d.\n\nThe samples tagged as \u201cCLEAN\u201d were not detected by any of the three AV engines used at\n\n\n\n42 Chapter 4. Evaluation of the Taxonomy\n\nTable 4.2: Top 15 unique \u201cUNDECIDED\u201d labels assigned to 1,488 samples.\nLabel Amount of Samples\n\nautoit,gen,worm 306\ngen,udr,backdoorx 282\nallaple,virut,rahack 176\neesbin,gen,skintrim 112\nallaple,crypt,rahack 102\n\ngen,vb,worm 91\nsheur,-,skintrim 66\nclean,crypt,zbot 57\nzlob,agent,socks 52\n\ndialer,gen,skintrim 46\ngen,crypt,downloader 42\nsheur,crypt,fakealert 42\nvirut,allaple,rahack 41\n\nbifrose,vb,downloader 41\nsheur,crypt,downloader 32\n\nTable 4.3: Top 15 unique \u201cUNDECIDED\u201d individual labels.\nIndividual Label Amount of Samples\n\ngen 2,831\ncrypt 1,231\nclean 794\nagent 709\n\ndownloader 680\nTrojan 477\nworm 436\n\nbackdoor 397\nallaple 376\nrahack 354\n\nspy 334\nautoit 322\nsheur 317\n\nbackdoorx 304\nvirut 293\n\nthe time of the scanning. These 2,640 \u201cCLEAN\u201d samples represent over 20% of the entire sample\n\nset. The amount of undetected samples serves to show that it is hard to AV vendors to keep\n\ntheir products up to date, considering their collection and analysis process. Though they have\n\nteams to create the new signatures, each AV vendor has its own workflow, which invariably is\n\nsupervised by humans to avoid the occurrence of false-positives when the update is deployed in\n\na client\u2019s system. We will return to the \u201cCLEAN\u201d subset later in this chapter, when discussing\n\ntheir behavioral classes according to our proposed taxonomy.\n\nAs for the \u201cLabeled\u201d set of 4,378 samples, we observed that they are divided into 160 distinct\n\n\n\n4.3. Taxonomy Evaluation 43\n\nfamilies. Table 4.4 shows the 15 most populated labeled families. Table 4.5 shows the remaining\n\nfamilies and the amount of samples within each of them.\n\nTable 4.4: Top 15 labeled malware families and their corresponding amount of samples.\nFamily Amount of Samples (%)\nallaple 1922 (43.9)\nswizzor 281 (6.4)\nagent 248 (5.7)\nspy 140 (3.2)\n\natraps 139 (3.2)\ncrypt 124 (2.8)\n\ndownloader 121 (2.8)\nparite 110 (2.5)\nvirut 105 (2.4)\n\ngeneric 96 (2.2)\nvb 92 (2.1)\n\nhupigon 88 (2.0)\nporndialer 59 (1.3)\n\nexpiro 58 (1.3)\nbanker 50 (1.1)\n\nWe notice that the \u201callaple\u201d family is by far the most prevalent one, at over 40% of the entire\n\ndataset. This happens due to the fact that \u201callaple\u201d samples are very common in the wild, as\n\nthey scan vulnerable services in large network ranges in order to propagate, thus being more\n\nprone to be collected by a honeypot or to be present in malware databases.\n\n4.3.2 Types of Behavior and Classes Found\n\nPreviously, we defined four basic malware classes based on a set of types of behavior they\n\ncan present: \u201cDisrupter\u201d, \u201cEvader\u201d, \u201cModifier\u201d and \u201cStealer\u201d. Now, we define some \u201csuspicious\u201d\n\nbehaviors that, although not malicious, can be indicative of something harmful about to happen\n\n(mainly in cases in which a suspicious behavior is followed by a dangerous activity). We include\n\nthese suspicious (within our scope) behavior in our predefined classes: Language Checking is\n\npart of the Evader class and Information Reading of the Stealer one.\n\nHence, we applied the behavioral filters to the same dataset composed of 12,579 samples\n\nin order to classify them according to our taxonomy. First of all, we present an overview of\n\nthe classes by showing the amount of samples that fell into each one of them. This overview\n\nis illustrated in Figure 4.3, in which we can notice that plenty of samples fall on more than\n\none class. We also observe that the majority of malware samples from our dataset are Stealers,\n\nclosely followed by the Modifiers. Also, 4.58% of samples did not present any of our predefined\n\nbehaviors. The manual analysis of these samples, labeled as \u201cNone\u201d (i.e. those samples that do\n\nnot presented any of the defined network and filesystem behaviors), revealed that either they\n\ncrashed during the dynamic analysis, or they performed only passive operations, or even tried\n\nto access an unavailable resource and exited. Possibly the main motives for these samples not\n\n\n\n44 Chapter 4. Evaluation of the Taxonomy\n\nTable 4.5: Remaining labeled malware families and their amount.\nFamilies # of Samples\nzperm, zorin, zapchast, yabinder, webhancer, vimes, viking, vesic,\nudef, tibick, threat-hllsi, suspiciouspe, startpage, sober, skintrim,\nsinowal, sheur, servu, ranky, radmin, qhost, pws, proxy, powerspy,\npopmon, poisonivy, pexvi, perfloger, pepbot, offend, obfuscate, nuj,\nnewdotnet, netsky, mydoom, messen, mdh, maran, mantis, malum,\nmabezat, lookme, livetv, lineage, kolab, klone, killwin, istbar, im,\nhipak, happy, fc, etap, dyfuca, dudu, dsnx, dnschanger, deadcode,\ncmjspy, ciadoor, cdlmedia, buzy, buzus, bravesent, boxed, ardamax,\napdoor, alemod, activitylog\n\n1\n\nclicker, oqa, mostofate, bladi, black, magania, adspy, admedia,\ncasino, dropper, tool, genome, tibs, stration, sasser, nuclear, keen-\nval, beastdoor, bancos, antinny\n\n2\n\nflooder, agobot, ircbot, vundo, packed, prorat, jevafus, zenosearch,\npassviewer, horse, toolbar, virtool, chir, banload, autorun\n\n3\n\nzhelatin, spybot, polip, gendal 4\nkorgo, induc, fiha, trojan, adrotator 5\npolycrypt, koobface 6\nfraudload, bobax, heuristic, malware 7\nturkojan, socks, small, file 8\nrbot, gobot, bagle 9\nlegendmir 10\ndialer 11\npcclient 12\ndelphi, cinmus 13\nbifrose 14\nbho 15\ndelf 17\nldpinch 18\nbackdoor, sdbot, adware 20\nfakealert 24\nsalite 25\naliser 27\nautoit 29\nzlob 35\nluder 39\ndh 42\nonlinegames 45\n\npresenting any suspicious behavior may be due to: i) a corrupted malware file; ii) the detection\n\nof the analysis environment by the malware; or iii) a malware that shows split personalities [13].\n\nThe distribution of samples among the possible combinations related to our defined malware\n\n\n\n4.3. Taxonomy Evaluation 45\n\nFigure 4.3: Overview of the samples distribution over the classes plus \u201cNone\u201d.\n\nclasses can be seen on the Venn diagram presented in Figure 4.46. This diagram is useful to\n\nenrich our perception of how multifaceted current malware is, showing us that nowadays malware\n\nperform several malicious operations to accomplish their intent. Based on this Venn diagram,\n\nwe produced the full multi-class distribution with the respective percentages (Figure 4.5), where\n\n\u201cD\u201d stands for \u201cDisrupter\u201d, \u201cE\u201d for \u201cEvader\u201d, \u201cM\u201d for \u201cModifier\u201d and \u201cS\u201d for \u201cStealer\u201d. In this\n\nfigure, it is possible to observe that the majority of our samples are Stealers and Modifiers (46%\n\nalone, 17% associated with Evader\u2019s behavior, 12% with Disrupter\u2019s).\n\nFigure 4.4: Distribution of samples among the possible combinations of classes.\n\nIf we go one step deeper within the classes, we can analyze the specific behaviors related\n\nto O.S. and network dangerous activities, and the amount of samples that performed each of\n\nthem. Figure 4.6 illustrates the percentage of samples that presented an O.S. or network-related\n\n6This diagram was generated using Olivero\u2019s tool [112].\n\n\n\n46 Chapter 4. Evaluation of the Taxonomy\n\nFigure 4.5: Amount of samples distributed over multiple classes (percentages rounded up).\n\nbehavior, with the respective class. In this case, the percentage is calculated over the 12,003\n\nsamples that presented any behavior, i.e. we excluded those labeled as \u201cNone\u201d.\n\nFigure 4.6: Percentage of samples that presented each of the compiled behaviors.\n\n\n\n4.4. Discussion 47\n\nIf we carefully analyze Figure 4.6, we notice that the most frequent behaviors (defined in Sec-\n\ntion 3.4.2) are the less dangerous ones, if found alone. For instance, 83.36% of samples performed\n\n\u201cInformation Reading (IR)\u201d\u2014a suspicious, passive action, yet very common even to legitimate\n\nprograms. The same can be said about \u201cProcess Hijacking\u201d (PH, 60.08%), \u201cNew Binary\u201d (NB,\n\n59.94%), and \u201cUnknown Mutex\u201d (UM, 50.90%). Though these activities may indicate behaviors\n\nthat are often present in benign programs7, the knowledge about their association with other\n\nmore dangerous behaviors can shed a light on a malware-related security incident.\n\nTherefore, an analyst or incident responder may envision the chain of events related to an\n\ninfection (given a technical report), even in cases where actions that are only apparently not so\n\nsuspicious are found. For instance, if a malware sample reads some information and, based on\n\nthis, downloads or drops an unknown file, registers itself through the creation of an unknown\n\nmutex to avoid reinfections and, at the end, hijacks a process, we can track down the infection\n\nprocess using our proposed taxonomy (e.g., attributing the label \u201cM[DU,UM].S[IR,PH]\u201d to the\n\nreferred sample). Moreover, the provision of this behavioral aspects to a user depending on the\n\nanalysis of an unknown file is very informative, since it is possible to know beforehand what\n\nthat file is supposed to do.\n\n4.4 Discussion\n\nThe most valuable contribution of a behavior-centric taxonomy is\u2014besides the high-level\n\ninformation about the malicious intent of an executable file\u2014the possibility of obtaining knowl-\n\nedge about unknown malware. Moreover, the use of our taxonomy allows analysts to be free of\n\nantivirus ambiguity. This advantage can be better acknowledged if illustrated with comparisons\n\nbetween samples classified by our taxonomy and by AV assignment.\n\n4.4.1 Top AV Labeled Samples vs. Behavior-Centric Taxonomy\n\nTo find out which behaviors are performed by the most frequently detected malware sam-\n\nples, we analyzed them under the lens of our taxonomy. In this section, we will discuss the\n\ndistinguishing behavior of the ten most populated AV-labeled families from Table 4.4, i.e. the\n\nbehavior that characterizes most of the samples from those families. Since AV names are mean-\n\ningless for us, we will not try to explain all of the families\u2019 expected behaviors using common\n\nAV technical descriptions. Actually, we are going to use the AV labels only to show that the\n\nassigned names may have little to no bearing on the samples\u2019 behaviors, which can be better\n\ndescribed using our behavior-centric taxonomy.\n\nAllaple. First of all, let us analyze the most popular family (according to the AV assignment\n\nstep) of our samples dataset, the Allaple worm. Allaple\u2019s basic behavior includes copying itself\n\nto the system, launching its newly \u201cdropped\u201d file as a process and attempting to exploit other\n\n7The definition of process hijacking encompasses the same legitimate activity of a program/process \u201ccalling\u201d\nanother program or a system process; a benign installer often downloads or drops a new binary; all mutex\nnames that we did not include in our \u201cwhite-list\u201d are considered unknown. Despite the inconveniences that our\ndefinitions may cause in certain cases, these activities are important to enrich the understanding of complex\nmalicious programs.\n\n\n\n48 Chapter 4. Evaluation of the Taxonomy\n\nvulnerable systems across the network [100][131]. Dynamic analysis system\u2019s reports includes\n\nthe creation of random mutexes, so as to guarantee that only one copy is running on the infected\n\nmachine. According to our taxonomy, the discriminant set of behaviors of our Allaple samples\n\nis to write a new binary (NB), to launch its process (PH), to create an unknown mutex (UM),\n\nto start a scan of vulnerable network systems (VS), and to read system\u2019s information (IR).\n\nDifferent behaviors are also present in a few samples, as we can see in Table 4.6, but 37% of\n\nour Allaple samples exhibited the mentioned behavior, falling into the \u201cM[NB,UM].D[V S].S[PH,IR]\u201d\n\nclass. Thus, this may be the discriminant behavior for this family (Figure 4.7).\n\nFigure 4.7: Discriminant behavior\u2019s matrix for Allaple.\n\nTherefore, our result not only agrees with the family description, but also tells the user\n\nwhat the observed behavior is without those weird or peculiar names commonly found on AV\n\nanalyses. Furthermore, we are able to search for other unknown samples/families embraced\n\nby the same behavior-centric produced class and group them together. While we have chosen\n\nto provide, with our taxonomy, higher-level information about the malware classes and their\n\nassociated behaviors, there is additional, specific data (e.g., mutex and process names, scanned\n\nIP addresses or port numbers) that can be found in the report related to the analyzed malware\n\nsample. The information contained in this report serves as input to the step that classifies\n\nmalware according to the proposed taxonomy. An extra 7% of Allaple-labeled samples presented\n\nthe same previous behavior and, additionally, downloaded an unknown file from the Internet\n\n(DU), falling into the \u201cM[NB,UM].D[DU,V S].S[PH,IR]\u201d class; 15.3% of them are \u201cM[UM].D[V S]\u201d,\n\n10.6% are \u201cM[NB,UM].S[PH,IR]\u201d, and 10.0% are \u201cM[NB].S[PH,IR]\u201d.\n\nTable 4.6: Allaple: AV-assigned family vs. behavior-centric taxonomy.\nAV Family PH IR NB UM IP VS ES IC DU\n\nallaple 73.2% 73.3% 73.2% 87.8% 0.1% 70.1% 7.8% 0.3% 15.9%\n\nSwizzor. Swizzor samples are divided into ten classes, 75.8% of them distributed over\n\n\u201cS[IR,PH]\u201d (35.6%), \u201cM[UM,NB].S[IR,PH]\u201d (26%), \u201cM[UM].S[IR,PH]\u201d (10.3%) and \u201cM[DU]. S[IR,PH]\u201d\n\n(3.9%). The remaining samples are in classes that are variations of the same five behaviors\n\npresent in those four more populated classes. Since IR and PH correspond to behaviors that,\n\nalone, are not too much informative about the malignity of a certain sample, we chose the\n\ndiscriminant behavior to be \u201cM[UM,NB].S[IR,PH]\u201d (Figure 4.8). Notice that the discriminant\n\nbehavior of Parite and Allaple differs only by the vulnerability scan exhibited in the latter.\n\nSpy. We expect that samples whose assigned label is \u201cSpy\u201d present spyware behavior,\n\ntrying to steal information if possible. When we applied our taxonomy to the available Spy\n\nsamples, we obtained 54 distinct classes. The most populated classes are \u201cE[RE].M[Pe]\u201d (10.9%),\n\n\u201cE[RE].M[DU,Pe].S[IS,CS]\u201d (5.5%), \u201cS[IS,CS]\u201d (5.5%), S[IR] (5.5%), \u201cM[Pe]\u201d (4.7%), \u201cE[RE].M[Pe].S[IS,CS]\u201d\n\n\n\n4.4. Discussion 49\n\nFigure 4.8: Discriminant behavior\u2019s matrix for Swizzor.\n\n(3.9%), \u201cE[RE].M[Pe].S[IR]\u201d (3.9%) and \u201cS[IS,CS,PH]\u201d (3.9%). Most of one-element classes exhib-\n\nited behaviors related to information and credential stealing, as well as PAC loading and known\n\nmalware downloading. We confirmed our hypothesis about the behavior of Spy samples by ver-\n\nifying that 57.0% of them performed information stealing wehereas 50.9% performed credential\n\nstealing.\n\nAtraps. These samples produced 58 classes. 11.9% of Atraps samples fell in the \u201cM[DU].S[IS,CS]\u201d\n\nclass, which we chose as the discriminant behavior. In addition, 19.8% of Atraps samples ex-\n\nhibited the discrimant behavior along with other behaviors. Another 11.9% of samples fell in\n\nthe \u201cS[IS,CS]\u201d class, 5.5% in \u201cM[DU].S[IR]\u201d, 4.0% in \u201cM[DU].S[IS,CS,IR]\u201d, 4.0% in \u201cS[IR]\u201d, and so on.\n\nFigure 4.9 illustrates Atraps\u2019 discriminant behavior.\n\nFigure 4.9: Discriminant behavior\u2019s matrix for Atraps.\n\nCrypt. The discriminant behavior for Crypt samples is \u201cE[RE].M[NB,Pe].S[IS,CS,PH]\u201d (Fig-\n\nure 4.10), which is observed in 8.6% of them. Other most populated classes include \u201cE[RE].M[Pe].S[IR]\u201d\n\n(7.7%) and \u201cE[RE].M[NB,Pe].S[PH]\u201d (6.9%). Crypt samples produced 63 classes, 44 of them with\n\none element. The behaviors found in these one-element classes vary from loading PAC files\n\n(PL) and drivers (DL) to changing the \u201chosts\u201d file (HC) and sending e-mail (ES).\n\nFigure 4.10: Discriminant behavior\u2019s matrix for Crypt.\n\nDownloader. We identified that 33.9% of these samples performed downloads of known\n\nmalware or unknown files. However, 49.6% of them created new files on the system, indicating\n\nthat some of these samples effectively \u201cdropped\u201d these files instead of downloading them. The\n\nmost populated of the 51 produced classes are \u201cE[RE].M[NB].S[IR,PH]\u201d (9.6%), \u201cS[IS,CS,IR]\u201d (7.8%),\n\n\u201cE[RE].M[NB].S[IS,CS,IR,PH]\u201d (6.9%) and \u201cS[IR]\u201d (6.9%). Downloader samples produced 32 one-\n\nelement classes that exhibited, among other behaviors, vulnerability scanning (VS), known IRC\n\nports communication (IP), persistence to survive to reboots (Pe) and e-mail sending (ES).\n\nParite. These samples produced 24 distinct classes, 16 of them with only one element.\n\n35.4% of Parite samples fell in the \u201cS[IR]\u201d class, 9.1% in \u201cM[UM].S[IR]\u201d, 7.3% in \u201cM[NB].S[IR,PH]\u201d,\n\n\n\n50 Chapter 4. Evaluation of the Taxonomy\n\nand so on. More interesting are those classes that contain only one sample, since they are a\n\nclear example of the nonsense regarding AV labeling. To properly name the Parite samples\n\nwhile still showing the richness of their behavioral diversity, the items below show each of their\n\none-element class:\n\n\u2022 D[ES].E[RE].M[UM,NB,Pe].S[IR,PH]\n\n\u2022 D[IP,IC].S[IR,PH]\n\n\u2022 M[DU]\n\n\u2022 M[DU,UM]\n\n\u2022 E[RE].M[DL,DU,UM,NB,Pe].S[IR,PH]\n\n\u2022 M[DL,DU,UM,NB,Pe].S[IR,PH]\n\n\u2022 M[DU,UM].S[IR]\n\n\u2022 M[NB,HC,Pe].S[IR]\n\n\u2022 E[RE].M[NB,Pe].S[IR,PH]\n\n\u2022 M[NB,Pe].S[IR,PH]\n\n\u2022 M[Pe]\n\n\u2022 M[Pe].S[PH]\n\n\u2022 E[RE].M[UM,NB].S[IR,PH]\n\n\u2022 E[RE].M[NB].S[IS,IR,PH]\n\n\u2022 E[RE].M[NB,Pe].S[CS,IS,IR,PH]\n\n\u2022 S[PH]\n\nThis behavioral diversity makes it difficult to define a discriminant behavior for Parite sam-\n\nples without a deeper analysis of the samples.\n\nVirut. Virut samples produced 43 classes, 24 of them with one element. Again, the one-\n\nelement classes exhibit a more diverse set of behaviors, such as IRC communication and known\n\nport access, e-mail sending, \u201chosts\u201d file modification, vulnerability scanning and download of\n\nalready known malware. However, the most populated classes are \u201cM[DU,UM,NB,HC].S[IR,PH]\u201d\n\n(14.5%), \u201cD[V S].M[UM]\u201d (10.0%), \u201cD[V S].M[UM,NB].S[IR,PH]\u201d (4.5%), \u201cM[UM,NB,HC].S[IR,PH]\u201d (4.5%),\n\nand \u201cD[V S].M[DU,UM]\u201d (4.5%). We consider the first one as the discriminant behavior of Virut\n\n(Figure 4.11).\n\nAgent. These samples were distributed among 37 classes of our behavior-centric taxonomy,\n\n21 of them with a single element. Similarly to Parite and Virut, the most varied Agent samples\n\n(regarding the behavior\u2019s diversity) are not associated with the most populated classes. Class\n\n\u201cS[IR,PH]\u201d encompasses 17.0% of the total Agent samples and class \u201cS[IR]\u201d, 15.9%. One-element\n\nclasses include:\n\n\n\n4.4. Discussion 51\n\nFigure 4.11: Discriminant behavior\u2019s matrix for Virut.\n\n\u2022 M[DU,NB,Pe].S[PH]\n\n\u2022 M[DU,NB].S[IR]\n\n\u2022 M[DU,NB].S[IR,PH]\n\n\u2022 M[DU,NB,CB].S[IR,PH]\n\n\u2022 M[DU,UM,NB,BI]\n\n\u2022 M[DU,UM,NB].S[PH]\n\n\u2022 M[DU,UM].S[IR]\n\n\u2022 E[RE].M[NB]\n\n\u2022 M[NB,Pe,BI].S[IR,PH]\n\n\u2022 M[UM,CB].S[IR,PH]\n\n\u2022 E[RE].M[UM,NB].S[PH]\n\n\u2022 M[UM,NB,BI]\n\n\u2022 M[UM,NB].S[IR]\n\n\u2022 D[V S].M[UM,NB].S[IR]\n\n\u2022 M[UM,NB,Pe].S[IR]\n\n\u2022 M[UM,DL].S[IR]\n\n\u2022 M[UM,DL].S[IR,PH]\n\n\u2022 M[UM,Pe].S[IR]\n\n\u2022 M[Pe].S[IR]\n\n\u2022 E[RE].M[UM,Pe].S[IS,IR]\n\n\u2022 S[IS,IR,PH]\n\n\n\n52 Chapter 4. Evaluation of the Taxonomy\n\nGeneric. Generic samples produced 41 distinct classes, 25 of them with one element. 10%\n\nof the total samples were classified as \u201cS[IR]\u201d, 8.9% as \u201cM[NB].S[IR,PH]\u201d, 7.8% as\n\n\u201cD[ES].E[RE].M[PL].S[IS,CS,IR,PH]\u201d, and so on. From the 24 defined behaviors, only 10 did not\n\nshow up in Generic samples (TA, TU, TF, CB, HC, DK, VS, IP, IC, LC).\n\nVB. Similarly to the Generic samples, the two most populated VB classes are \u201cS[IR]\u201d (8.6%)\n\nand \u201cM[NB].S[IR,PH]\u201d (8.6%). These samples produced 47 classes, 33 of them with one element.\n\nThe diversity of behaviors exhibited by the observed classes includes a sample that tried to ter-\n\nminate security mechanisms\u2014assigned to the \u201cE[TA,TF,TU]\u201d class\u2014and a sample that presented\n\nhalf of the possible behaviors\u2014assigned to the \u201cE[TA,TF,RE].D[ES]. M[PL,UM,NB,Pe].S[IS,CS,IR,PH]\u201d\n\nclass.\n\nHupigon. 41.3% of Hupigon samples were classified as \u201cM[UM,NB].S[IR,PH]\u201d, 18.4% as\n\n\u201cM[UM].S[IR,PH]\u201d, 6.9% as \u201cE[RE].M[UM,NB].S[IR,PH]\u201d, 5.7% as \u201cM[NB].S[IR,PH]\u201d, and 4.6% as\n\n\u201cM[DU,UM,NB].S[IR,PH]\u201d. On the group of the single-element classes, we observed the odd be-\n\nhavior of loading a driver in one sample, and the stealing of system or user information through\n\nthe network in another one. Considering only the high-level exhibited behavior, we can notice\n\nthat the discriminant behavior of Hupigon samples (Figure 4.12) is the same as Swizzor samples\u2019\n\n(Figure 4.8).\n\nFigure 4.12: Discriminant behavior\u2019s matrix for Hupigon.\n\nPorndialer. These samples were grouped into only two classes: 83% in \u201cM[UM,NB].S[IR]\u201d\n\nand 17% in \u201cM[DU,UM,NB].S[IR]\u201d, behaving like droppers and downloaders, respectively. It makes\n\nsense, since this type of malware is a program that executes (or downloads and executes) a soft-\n\nware that intends to dial telephone numbers whose call will be charged to the victim. Figure 4.13\n\nshows an image captured during BehEMOT\u2019s dynamic analysis step.\n\nExpiro. Expiro samples\u2019 discriminant behavior is \u201cM[UM,CB,NB].S[IR]\u201d (Figure 4.14), which is\n\npresent in 24.1% of the samples. This warns us about the fact that some of these samples modify\n\nsystem programs. 22.4% of samples are \u201cM[UM].S[IR]\u201d, 10.3% of them are \u201cD[V S].M[UM,NB].S[IR,PH]\u201d,\n\nanother 10.3% are \u201cM[UM,DU,CB,NB].S[IR]\u201d, 8.6% are \u201cM[UM,NB].S[IR,PH]\u201d, 5.2% are\n\n\u201cM[UM,CB,NB].S[IR,PH]\u201d, one sample tried to send e-mail from the victim\u2019s machine and to per-\n\nform a vulnerability scanning (among other behaviors), and another one tried to download an\n\nunknown file and to perform a scan for vulnerable services. The remaining samples performed\n\na combination of the behaviors already exhibited by this family.\n\nBanker. The name \u201cbanker\u201d is usually assigned to a special type of malware whose main pur-\n\npose is to steal Internet banking credentials from infected victims. Samples labeled as bankers,\n\nhowever, behaved in 25 distinct ways. 10.9% exhibited the behaviors from the \u201cM[NB,Pe].S[IR,PH]\u201d\n\nclass, 8.7% from \u201cE[RE].M[UM,NB,Pe,BI].S[IR,PH]\u201d, 6.5% from \u201cM[NB,Pe].S[IR]\u201d, and another 6.5%\n\nfrom \u201cD[ES].M[NB,P e].S[IR,P H] \u201d. Interestingly, we were able to pinpoint the credential stealing be-\n\nhavior in only one of those AV-labeled bankers, and over 80% of them tried to persist in the\n\ninfected system after a reboot. We address bankers in more detail in Chapter 5.\n\n\n\n4.4. Discussion 53\n\nFigure 4.13: Screenshot of a Porndialer sample execution.\n\nFigure 4.14: Discriminant behavior\u2019s matrix for Expiro.\n\n4.4.2 Behavior of Unknown Malware\n\nAnother useful feature of a behavior-centric taxonomy is to group samples that the AV\n\nengines did not detect as malicious together with samples that exhibits the same behavior.\n\nTherefore, those \u201cundecided\u201d samples can also be associated to their rightful pairs. For instance,\n\nthe class M[UM,Pe,NB].S[IR,PH] is composed of 358 \u201cundecided\u201d, 2 \u201cclean\u201d, and 34 samples with\n\nvariable labels (e.g., agent, backdoor, bagle, banker, bifrose, chir, fakealert, koobface, legendmir,\n\nnuclear, sdbot, skintrin, vb). This turns the AV label unnecessary, since we know that, among\n\nother behaviors, those samples try to persist on the infected system and they create a new\n\nbinary file (apparently a \u201cdrop\u201d behavior).\n\nWe found 463 unique combinations of classes and behaviors for the 5,559 \u201cundecided\u201d (re-\n\ngarding AV labels) samples. Table 4.7 shows the 15 most frequent labels for the samples in\n\nwhich the AVs did not agree, according to our behavior-centric taxonomy. Figure 4.15 shows\n\nthe distribution of behaviors among those \u201cundecided\u201d samples.\n\nThe undetected samples (\u201cclean\u201d) are even more important, since they pose a major threat\n\nto AV-powered users. We were able to extract the behavior of 91.7% of the samples labeled\n\nas \u201cclean\u201d. Then, we found 332 unique combinations of classes and behaviors for these 2,422\n\n\u201cclean\u201d samples. We show the 15 most frequent labels in Table 4.8, and the overall distribution\n\nof behaviors in Figure 4.16. It is worth noting the type and frequency of behaviors exhibited\n\nby those \u201cclean\u201d samples. For instance, about a quarter of them performed information and\n\ncredential stealing; over 40.0% of them downloaded unknown files; over 10.0% of them loaded\n\na PAC file to change the browser\u2019s proxy. Therefore, the knowledge about these potentially\n\n\n\n54 Chapter 4. Evaluation of the Taxonomy\n\nTable 4.7: Top 15 Behavioral-Centric Taxonomy labels for AV-\u201cUNDECIDED\u201d samples.\nBehavioral Label % of Samples\nM[UM,NB,Pe].S[IR,PH] 6.4\nM[NB].S[IR,PH] 6.2\n\nS[IR] 5.2\nM[UM,NB].S[IR,PH] 5.0\n\nD[V S].M[UM,NB].S[IR,PH] 3.3\nM[UM,NB].S[IR] 3.1\nM[NB].S[IR] 3.1\nM[UM].S[IR] 2.6\nS[IR,PH] 2.5\n\nM[NB,Pe].S[IR] 2.2\nM[NB,Pe].S[IR,PH] 2.1\n\nE[TA,TF,TU,RR].M[NB,Pe].S[IR,PH] 2.1\nE[RE].M[NB].S[IR,PH] 1.8\n\nE[RE].M[UM,NB,Pe].S[IR,PH] 1.6\nE[RE].M[UM,NB].S[IR,PH] 1.6\n\nFigure 4.15: Behaviors exhibited by AV-\u201cUNDECIDED\u201d samples.\n\ndangerous behaviors show that our proposed taxonomy can effectively help users to decide\n\nwhether a program that their AV considered as clean will run or not.\n\n\n\n4.5. Concluding Remarks 55\n\nTable 4.8: Top 15 Behavioral-Centric Taxonomy labels for AV-\u201cCLEAN\u201d samples.\nBehavioral Label % of Samples\nM[DU,UM,Pe].S[IR] 16.4\nM[NB].S[IR,PH] 8.4\n\nS[IR] 8.3\nM[DU,UM,Pe].S[IR,PH] 5.8\n\nE[RE].M[DU,UM,NB,Pe].S[IR,PH] 4.2\nM[DU,NB].S[IR,PH] 2.5\nM[UM].S[IR] 1.9\n\nM[UM,Pe].S[IR,PH] 1.7\nM[UM].S[IR,PH] 1.6\n\nE[RE].M[UM,NB].S[IR,PH] 1.5\nM[DU].S[CS,IS] 1.4\nM[DU].S[IR] 1.4\nS[CS,IS] 1.4\n\nD[ES].M[PL].S[CS,IS] 1.2\nM[DU].S[CS,IS,IR] 1.2\n\nFigure 4.16: Behaviors exhibited by AV-\u201cCLEAN\u201d samples.\n\n4.5 Concluding Remarks\n\nIn this Chapter, we presented an evaluation of our proposed behavior-centric taxonomy.\n\nInitially, we discussed dynamic malware analysis and introduced our framework that extracts\n\nbehavioral profiles. We also presented the distribution of our samples regarding AV labels,\n\n\n\n56 Chapter 4. Evaluation of the Taxonomy\n\nobtaining the amount of samples for which the AV engines did not agree while assigning a label,\n\nthe undetected ones and those that were assigned to a family. Then, we presented the results of\n\nour taxonomy\u2019s application to our sample dataset, grouping those samples (not exclusively) in\n\nfour classes: Disrupter, Evader, Modifier and Stealer. This evaluation corroborates the fact that\n\ncurrent malware are very complex and multi-purposeful. Finally, we discussed our results and\n\nshowed that our taxonomy can guide users and professionals due to its informative orientation.\n\nThe discussion showed us, on one hand, that our taxonomy describes these samples accord-\n\ning to their dangerous activities, such as persistence on the victim\u2019s system, as well as qualifies\n\nthem as capable of data stealing and modificaton during an infection. On the other hand, we\n\nare limited to describe only samples that fit into our scheme, that is, those that exhibit behav-\n\niors that belong to our taxonomy, and even so, only if the behavior extraction is successfully\n\naccomplished, that is, the dynamic analyzer that was used being able to capture the monitored\n\nmalware behavior. Nonetheless, these problems can be technically solved, either by adding\n\nmore behaviors to the taxonomy, or by changing the monitoring techniques used in the dynamic\n\nanalysis system.\n\n\n\nChapter 5\nMalware Detection\n\n5.1 Introduction\n\nSince one of the main objectives of this thesis is to provide a taxonomy that may be easily\n\nextended and to show that our taxonomy can also be used in restricted scopes to, for instance,\n\nidentify specific types of malware, we introduce BanDIT (the Banker Detection and Infection\n\nTracking system), a specialization of our system that intends to address malicious Internet Bank-\n\ning software (a.k.a bankers). In this chapter, we motivate the study of bankers\u2019 behavior, briefly\n\npresent an Internet Banking background, describe BanDIT\u2019s architecture and leverage bankers\u2019\n\nidentification results using an extended, yet specialized, version of our taxonomy. Therefore,\n\nthis chapter can be considered a case-study about bankers.\n\n5.2 Motivation\n\nCrimeware, phishing Trojan or banking Trojan are terms used to refer to a special type\n\nof malware whose main objective is to obtain online banking credentials in order to steal\n\nmoney [51]. These malware samples, commonly known as \u201cbankers\u201d, make use of social en-\n\ngineering techniques and phishing e-mail messages to trick users into providing their Internet\n\nbanking credentials, credit or debit card numbers, and security token values to take over the\n\nvictim\u2019s online bank account or to resell these pieces of information in underground markets.\n\nThe high success rate of such attacks results in billions of dollars in losses worldwide [158][71].\n\nRecent examples of widespread bankers are ZeuS [20] and Spyeye [37], which infect users by\n\nmodifying files and system libraries, and by injecting their code into system processes. Con-\n\nversely, Brazilian bankers usually infect users\u2019 machines by falsely warning them that they need\n\nto update their Internet banking defense mechanisms or to confirm their authentication data.\n\nThis type of banker has been seen in the Brazilian Internet space for at least ten years: in\n\nlate 2006, they amounted to 30.7% of the observed bankers in [51] (the remaining ones tar-\n\ngeted mainly European, Australian and North American banks). More recently, a report from\n\nKaspersky [80] pointed Brazil as the country most frequently targeted by bankers.\n\nWe believe that this happens due to two main reasons: Brazil has about 28 million on-\n\nline bank users and there are no specific laws (until very recently) regarding computer-based\n\n57\n\n\n\n58 Chapter 5. Malware Detection\n\ncrimes, turning the scenario into a favorable one for cyber criminals. This situation created an\n\nunderground commerce in which attackers sell not only valid credit card numbers, but do-it-\n\nyourself kits\u2014to compile Delphi or Visual Basic source codes offered at social networks, such as\n\nOrkut\u2014that allows for a quick production of customized variants. In spite of the focus of this\n\nchapter lying on Brazilian bankers, mainly because our samples were obtained from phishing or\n\ncollectors in Brazilian cyberspace, the detection techniques proposed here are applicable to any\n\nother banker that acts in the same way, only requiring updates to the bankers detection pattern\n\nlists and images database.\n\nDespite previous works [57][27][51] regarding the detection of bankers, there is a lack of\n\ninitiatives to automatically identify this type of malware during the dynamic analysis in publicly\n\navailable systems (e.g., Anubis [86], CWSandbox [168], ThreatExpert [155]). However, these\n\nsystems are largely used by incident response teams around the world as a first step to provide\n\ninformation about a malware incident during the response procedures. Hence, the identification\n\nof a banker right on the dynamic analysis step should yield a more efficient development of\n\nprotective measures, such as sending alerts to ISPs, deeper investigation of the banker\u2019s file and\n\nexecution behavior to find out information about the possible damage extent, production and\n\ndeployment of block lists, and early warning to law enforcement authorities. To this end, we\n\npropose BanDIT, a dynamic analysis system that provides identification of bankers and tracking\n\nof servers used in banker infections.\n\nIn spite of some of the techniques presented on this chapter not being exactly novel, we are\n\nnot aware of any other work that (i) yields the combined use of these techniques, (ii) applies\n\nthem to identify bankers as a complement to dynamic analysis system reports, and (iii) focuses\n\non the identification of Brazilian bankers based on their traits. Thus, the main purpose of\n\nBanDIT is to aggregate value to the dynamic analysis of malware by identifying bankers that\n\nbehave like Brazilian ones, making it possible to screen them out for further analysis. The main\n\ncontributions of this chapter are as follows:\n\n\u2022 We proposed a scheme to analyze and identify malware samples that act as bankers\nthrough a combination of visual similarity identification, network signature matching and\n\nfile system change monitoring.\n\n\u2022 We implemented a prototype of our proposed system (BanDIT) and analyzed over 15\nhundred unique malware samples, mostly from phishing e-mail messages. Furthermore,\n\nwe leveraged an empirical analysis of the execution behavior presented by the bankers\n\nthat were identified through BanDIT.\n\n\u2022 We reported all the e-mail and IP addresses/domains that were involved in bankers in-\nfections (used for sending/receiving stolen credentials, or as a download base for other\n\nmalware pieces). We also developed a Web site for tracking infected IP addresses related\n\nto malware samples that attack Internet banking users.\n\n\n\n5.3. Background: Internet Banking and Bankers 59\n\n5.3 Background: Internet Banking and Bankers\n\nInternet banking access brought convenience to users, allowing them to perform money\n\ntransfers, payments and account status verification without going physically to a bank agency.\n\nHowever, Internet access is also convenient to attackers, as they can subtract money funds\n\nanonymously while avoiding getting shot or arrested. To minimize risks, banks deploy security\n\nmechanisms intended to protect online transactions, which range from mailed password tables\n\nto hardware tokens (Figure 5.1). Together with the bank account card passwords, these mech-\n\nanisms provide additional authentication factors, making it harder to forge a valid transaction.\n\n(a) Hardware token (b) Password table\n\nFigure 5.1: Additional Internet banking authentication factors\n\n5.3.1 Hardware Tokens\n\nSome banks provide hardware (security) tokens to their clients so that they have a second\n\nauthentication factor. Thus, every time a client performs an online financial operation, he/she\n\nmust provide the number that is currently showing in the device\u2019s display, or else the operation\n\nis not completed. Moreover, this kind of authentication has a short timeout, forcing the client\n\nto input several different numbers if performing several operations within anything but a short\n\ntime frame. This approach is useful to secure the clients online bank accounts even when their\n\naccess credentials are compromised. However, due to the complexity (and cost) to deploy and\n\nmanage millions of users/devices and synchronize their security tokens, few banks are using this\n\ntype of device and those which are usually provide it only to enterprise users.\n\n5.3.2 Password Tables\n\nTo increase the security of an online financial transaction while promoting another authen-\n\ntication (cheaper than a hardware token), some banks provide password tables to their clients.\n\nWhen a client performs an online financial operation, the Internet banking server requests the\n\nvalue of some index from this table to validate that operation. Differently from hardware to-\n\nkens, password tables\u2019 indexes can be reused, as the table may not be changed frequently 1. In\n\naddition, it is common that the same password table index is used during an entire Internet\n\nbanking session, no matter how many financial operations are performed. Security is in fact\n\nachieved by setting a very low number of failed attempts at a transaction (usually three to five)\n\nbefore a full lock out of the account, after which the user is forced to use yet another set of\n\n1I used to have a password table that did not change for about two years.\n\n\n\n60 Chapter 5. Malware Detection\n\nauthentication factors and communication channels to restore online operation. This may also\n\ninvolve a visit to a bank branch.\n\n5.3.3 Anatomy of a Banker Infection\n\nBanker attacks affect both server and client sides. On the server side, possible actions that\n\nattackers can take are: i) to register \u201cmistyped\u201d bank domains and deploy sites that clone\n\nthe legitimate Internet banking site, in order to deceive careless users and ii) to compromise\n\nvulnerable servers/sites, so they can host a clone of the targeted Internet banking site or the\n\nbanker executable. Furthermore, attackers may spread phishing messages containing attached\n\nbanker executable files, or links to fake/compromised sites (to directly grab information using\n\ncloned interfaces or to download the banker).\n\nOn the client side, bankers leverage a myriad of techniques to mislead users, such as the\n\noverlapping of Internet banking form fields, the interception of network communications, the\n\nmodification of name resolution and proxy configuration files, the sending of e-mail messages\n\nwarning about updates to the Internet banking security solution installed on the victim\u2019s sys-\n\ntems, the use of keyloggers that filter Internet banking content to log only important data and\n\nso on. In the last few years, we have been observing that most of the Brazilian bankers infect\n\nusers through sending of phishing content that leads to the download of an executable. Once\n\ndownloaded and installed, this executable presents a GUI (which may simulate a browser) that\n\n\u201cguides\u201d the victim into providing sensitive information (e.g., bank agency, account number,\n\ncredit card number and verification code, Internet banking password, token values, password\n\ntable values etc.).\n\nThis trend may be due to the fact that users can easily realize the fraud in infections where\n\nthe attacker supplies a (weird) link to a cloned site, such as http://something-in- another-\n\ncountry/http/www.mybank/index.php. Apparently, it makes more sense to the user to down-\n\nload and execute files named&lt;bankname>-iToken.exe or&lt;bankname>- security-update.exe.\n\nAlthough Brazilian banks claim that they do not send messages regarding either sensitive data\n\nand security mechanisms, or asking for their clients\u2019 information, banker attacks have been and\n\nare still being performed successfully on a steady pace.\n\nTo pretend legitimacy, a successful phisher has to insert some items in the message to\n\nconvince users to install the banker and inadvertently compromise their machines and online\n\nbanking credentials. A typical phishing message is illustrated in Figure 5.2\u2014(a) the \u201cfrom\u201d\n\nfield contains an address that seems to come from the bank, (b) the body header has the bank\n\nlogos, (c) the body message request a security update (token synchronization) and provides a\n\ncontrol number, (d) the link points the user to a banker download (disguised as a \u201ccontinue\u201d\n\nfor the updating process) and, finally, the message ends with (e) the bank disclaimer and phone\n\nnumbers.\n\nAfter downloaded and executed, the banker actually steals the user\u2019s information. This can\n\nhappen in two ways, online or offline. In an online stealing, the attacker subverts the hardware\n\ntoken usage by distracting the user during the slice of time in which the token value is valid\n\n(about 3 minutes). After asking for the user to input the credentials required for the bank\n\nsite access, the banker sends this information to the attacker (through HTTP methods, e-mail,\n\n\n\n5.3. Background: Internet Banking and Bankers 61\n\nFigure 5.2: A successful phishing message.\n\nremote database or FTP server), shows a screen requesting the code that is currently on the\n\nhardware token display (Figure 5.3) and then usually shows a dynamic bar that mimics an\n\nupdate (Figure 5.4), ensuring that the user waits for the completion of the \u201cupdating\u201d process.\n\nMeanwhile, the attacker uses the stolen credentials and valid token code to perform online\n\ntransactions.\n\nThis attack is difficult to perform as it demands that the attacker be online as the user is\n\nperforming a financial operation. In addition, it is not scalable, as one attacker is not able to\n\nperform more than one attack of this type at a time.\n\nA similar way to steal online bank credentials is to persuade the user into inserting the\n\nentire password table. Thus, the attacker receives all required information in an unmanned way\n\nand thus can later perform a variety of financial operations without a time constraint. The\n\nmodus operandi is the same as above but, after asking for the users bank site credentials, the\n\nbanker shows a screen requiring the values from a password table. Some bankers are even better\n\ndeveloped than others and check if the user is not inserting repeated values among the positions.\n\nAn example illustrating different banker screens to steal the entire password table is depicted\n\nin Figure 5.5.\n\nOther ways to inadvertently redirect the user to a cloned banking site may involve either\n\nthe modification of the system \u201chosts\u201d file, or the loading of a PAC (proxy auto-config) file. The\n\n\n\n62 Chapter 5. Malware Detection\n\nFigure 5.3: Banker screen to steal token value.\n\nFigure 5.4: Distraction screens to allow an attacker to steal online banks while the user waits.\n\n\u201chosts\u201d file maps hostnames to IP addresses, being the starting point to resolve a hostname query\n\non the victim\u2019s system. Malware can modify this file to map known Internet banking URLs to\n\nIP addresses that are hosting cloned sites containing forms to steal users\u2019 credentials. The other\n\nmethod forces the browser to load a PAC file, which defines the proxy that a Web browser should\n\nuse to access a given URL through the JavaScript function FindProxyForURL(url, host). A\n\nPAC file created on the victim\u2019s system provides IP addresses that might lead to cloned sites,\n\nthus allowing us to identify owned Internet servers.\n\nBased on the observation of the bankers\u2019 common behavior, we defined a (non-exhaustive)\n\nset of potentially dangerous activities that may be used to identify them. These activities are\n\nbriefly described below:\n\n\u2022 Stealing of user credentials or financial information (CS), and of system or user data (IS),\nsuch as username, machine name, hard disk serial number, O.S. version etc.\n\n\u2022 E-mail sending (ES) from the infected system, to send out sensitive data or to deliver\nspam to extend the attack by further propagation.\n\n\n\n5.3. Background: Internet Banking and Bankers 63\n\nFigure 5.5: Banker screen to steal all values from the user\u2019s password table.\n\n\u2022 Subversion of Internet browsing through the modification of the name resolution file (hosts)\n(HC) or the browser proxy using PAC files (PL).\n\n\u2022 Presence of images related to Internet banking sites, as banks do not send executable files\nto their clients (at least in Brazil), as well as an autonomous program not being supposed\n\nto have embedded bank images.\n\nHence, in addition to the already existing aforementioned behaviors (CS, IS, ES, HC, PL),\n\nwe include the Internet Banking forgery (BF) due to the presence of this type of image during\n\nthe execution or within the binary file.\n\n5.3.4 Other Works about Bankers\n\nThe financial motivation behind malware infections justifies (from the standpoint of a cy-\n\nbercriminal) the increasing spread of bankers. Next, we present some research works regarding\n\nbanker detection.\n\nIn [51], the author discusses the behavior of bankers targeting German, Swedish and Brazil-\n\nian Internet banks, and the mechanisms employed by banks to protect their customer accounts,\n\nsuch as one-time-passwords (OTP) and transaction numbers (TAN). He proposes a tool called\n\n\u201cMstrings\u201d, which searches the memory of an analysis system (during a malware sample\u2019s ex-\n\necution) for known Internet banking-related strings. Although this scheme is effective against\n\nbankers that act as keyloggers when the user is accessing the Internet bank site, it may be\n\nineffective against bankers that rely on social engineering and that do not depend on the user\n\naccess to the Internet bank site.\n\nBuescher et al. [27] present a banker detection scheme that checks for hooks on Internet\n\nExplorer to steal user\u2019s information. To do so, the authors developed BankSafe, a component\n\n\n\n64 Chapter 5. Malware Detection\n\nthat verifies for API changes during Internet Explorer execution. After a malware sample runs\n\nin a controlled environment, BankSafe checks for hooking fingerprints to detect if some type\n\nof hook was installed on Internet Explorer during the analysis time. The authors claim that\n\nBankSafe produces very good detection results, however it is limited to detecting bankers that\n\ninstall hooks.\n\nIn [98], the authors present an approach to detect phishing Web pages, which is based on a\n\nvisual detection scheme that lets the user know beforehand that his/her data is being intercepted\n\nby an attacker. Phishing detection is based on three features extracted from the analyzed Web\n\npages: the text portion, the images and the visual appearance of the page when it is rendered in\n\nthe browser. To detect the phishing attempt, they need a database of legitimate Web pages to be\n\ncompared to suspicious pages. To avoid overloading the browser due to the heavy comparisons,\n\nthe authors propose to work together with other phishing detection tools (AntiPhish and DOM\n\nAntiPhish), which do not compare Web page contents. Those tools verify the user\u2019s input data\n\nand the domain where it is used to alert if the same data serve as input for two different domains.\n\nThe combination of approaches allows for a more accurate phishing detection, less prone to false\n\npositives. Their limitation is that they only detect phishing attempts that are based on fake\n\nWeb pages during a user\u2019s browsing session, missing bankers that forge an Internet bank site\n\nthrough windows from their own executable file (such as Brazilian ones).\n\nBotzilla [126] uses a network signature detection scheme that is closely related to part of\n\nour work, since we also perform our network traffic detection step based on invariant content\n\npatterns. Botzilla\u2019s goal is to detect malware \u201cphoning home\u201d, i.e. contacting an attacker\n\ncontrolled site to send information. Botzilla\u2019s signatures address some malware classes whose\n\nsamples were collected from a large university network, yielding a detection rate of about 94.5%.\n\nIn [68], Holz et al. analyze the underground economy of stolen credentials and the phenom-\n\nena of keyloggers that communicate with criminals through dropzones, i.e. publicly writable\n\ndirectories on attacker-owned Internet servers, which serve as exchange points for the keylog-\n\nger\u2019s collected data. Their analysis is focused on Limbo (a Browser Helper Object for Internet\n\nExplorer) and ZeuS (a keylogger attached to spam) samples. To automate the keylogger sam-\n\nple analysis, they developed SimUser, a tool based on AutoIt that simulates arbitrary user\n\nbehavior\u2014keystrokes, mouse movement, manipulation of windows\u2014according to predefined\n\ntemplates.\n\n5.4 System Overview\n\nIn this section we present BanDIT, the Banker Detection and Infection Tracking system that\n\nwe have developed to identify bankers and their resulting compromised assets (IP addresses, e-\n\nmail accounts).\n\n5.4.1 Architecture\n\nWe developed BanDIT on the top of our own dynamic analysis system, BehEMOT (see\n\nChapter 4), which monitors the execution of a malware sample and the processes it spawns (or\n\nwrites into the memory of). Inside the monitoring environment, we also developed a component\n\n\n\n5.4. System Overview 65\n\nbased on AutoIt2 to interact with screens and error popups, and to take screenshots. Moreover,\n\nwe capture the network traffic off the analysis environment, so that payloads are reliably ob-\n\ntained. We also use Foremost3 to extract the images or screens that are embedded in a banker\n\nbinary file. An overview of BanDIT is shown in Figure 5.6.\n\nFigure 5.6: Overview of BanDIT.\n\nBanDIT\u2019s identification process relies on three steps, which are explained as follows:\n\nVisual Similarity. In this step, we perform the recognition of known Internet banking\n\nlogos, capitalizing on the fact that attackers are restricted on the number of variations in the\n\nbank site patterns, or else phishing is bound to fail. Thus, it is important that an attacker keeps\n\nthe logo positions and colors to successfully lure the user. To accomplish the visual identification,\n\nwe obtain figures from the banker binary file, from network connections that download images\n\n(even from the legitimate Internet banking site), and from windows presented by the banker\n\nduring its execution. Gathering images from these sources increases our chances to obtain them\n\nif the banker avoids screenshots, ciphers the traffic or its binary is specially packed. To verify if\n\na malware extracted image contains bank logos, we use JavaCV4, an interface to the OpenCV5\n\nlibrary that contains a class to search for an object inside an image using the Speed-Up Robust\n\nFeatures algorithm [14]. To do so, we developed a component that searches for the logos of\n\nthe five major Brazilian banks within the extracted images. Moreover, we submit all images\n\nto Tesseract6, an Optical Character Recognition engine. We then search the resulting text for\n\nkeywords present in our specially crafted banker-related terms dictionary.\n\nNetwork Traffic. We have been observing that, within our samples, bankers use to send\n\nstolen data from the victim\u2019s system through HTTP requests. The analysis of these requests\n\nrevealed some patterns that allowed us to develop \u201cnetwork signatures\u201d to verify for banker-\n\nrelated activities in the network traffic that is captured during the dynamic malware analysis.\n\nListing 5.1 exemplifies the contents of a POST request related to a banker infection. We verified\n\nthat some bankers send this type of request as soon as they are executed, followed by a similar\n\none containing Internet banking information provided by a victim.\n\n2http://www.autoitscript.com\n3http://foremost.sourceforge.net/\n4http://code.google.com/p/javacv/\n5http://opencv.org/\n6http://code.google.com/p/tesseract-ocr/\n\n\n\n66 Chapter 5. Malware Detection\n\nListing 5.1: A banker POST request.\n\npraquem=XXXXXXX@gmail . com\n&amp; t i t u l o =NOME DA MAQUINA\nVitima da Key R e v o l t a d o\n&amp;t e x t o=\n???????????????????????????????????\ni n f e c t i z i n h o\n???????????????????????????????????\nComputador Nome . . : NOME DA MAQUINA\nMac . . : XX?XX?XX?XX?XX?XX\nNumero S e r i e HD . . : xxxxxxxx\n???????????????????????????????????\nData . . : 4 / 2 4 / 2 0 1 2\nHora . . : 8 : 3 5 : 3 4 AM\n???????????????????????????????????\n\nThe network traffic analysis step also allows us to obtain PAC files, images, URLs, e-mail\n\nand IP addresses of abused servers, which are used in our identification process and reported to\n\ncompetent authorities.\n\nFile System. To detect changes that bankers commonly perform in infected systems, such\n\nas the inclusion of PAC files, modifications to the \u201chosts\u201d file, and attempts to disable security\n\nmechanisms (AVs, firewall, automatic updates), we monitor malware execution using our SSDT\n\nhooking driver. We are able to obtain PAC files if bankers drop them on the victim\u2019s system\n\nor by downloading them from URLs that are set as values in the registry Internet Settings\\\nAutoConfigURL key. To evaluate the obtained PAC files and to check for redirection of bank\n\nsite URLs, we execute the PAC code using a JavaScript processor based on Rhino [104] and\n\ncall the produced FindProxyForURL function using Internet banking domains as parameters.\n\nThus, even if the JavaScript code found inside the PAC file is obfuscated, it will eventually\n\ndeobfuscate itself and FindProxyForURL will be called. The result of the analysis of the PAC\n\npresented in Listings 5.2 and 5.3 is shown in Listing 5.4. Furthermore, we obtain the \u201chosts\u201d file\n\nfrom the infected system after the dynamic analysis is done, which is then searched for Internet\n\nbanking domains.\n\nListing 5.2: Example of an obfuscated PAC.\n\ne v a l ( f u n c t i o n ( p , a , c , k , e , d ){e=f u n c t i o n ( c ){r e t u r n c }; i f ( ! \u2019 \u2019 . r e p l a c e\n( / \u02c6 / , S t r i n g ) ){w h i l e ( c??){d [ c ]= k [ c ] | | c}k =[ f u n c t i o n ( e ){r e t u r n d [ e\n] } ] ; e=f u n c t i o n ( ){r e t u r n \u2019\\\\w+ \u2019}; c =1}; w h i l e ( c??){ i f ( k [ c ] ) {p=p .\nr e p l a c e ( new RegExp ( \u2019\\\\b\u2019+ e ( c ) + \u2019\\\\b \u2019 , \u2019 g \u2019 ) , k [ c ] ) }}r e t u r n p}( \u2019 2 5\n1 7 ( 1 4 , 1 1 ){7 4 =\\ \u2019 4\\ \u2019 , 1 =\\ \u2019 1\\ \u2019 , 2 =\\ \u2019 2\\ \u2019 , 5 =\\ \u2019 5\\ \u2019 , 3 =\\ \u2019 3\\ \u2019 ; 7 8=16\n1 5 ( \u201d?. \u201d+ 2 + \u201d1 2 .?\u201d , 1 + \u201d1 0 .?\u201d , \u201d?. \u201d+ 1 + \u201d1 0 .?\u201d , \u201d?.\u201d+4+2+1+5+\u201d.?\u201d,\n4+2+1+5+\u201d.?\u201d, 1 + 1 + \u201d.?\u201d, \u201d?. \u201d+ 1 + 1 + \u201d.?\u201d , 2 + \u201d1 2 .?\u201d , 2 + \u201d1 3 \u201d+ 3 + \u201d.?\u201d,\n\u201d?. \u201d+ 2 + \u201d1 3 \u201d+ 3 + \u201d.?\u201d ) ; 2 9 ( 7 6=0;6<8.26;6++) {2 7 ( 2 8 ( 1 1 , 8 [ 6 ] ) ) {9 \u201d2 4\n2 3 . 1 9 . 2 0 . 2 1 : 2 2 \u201d}}9 \u201d1 8 \u201d} \u2019 , 1 0 , 3 0 , \u2019 |b | s | l |h | c | p a 1 s | v a r | naxz | r e t u r n |\nr a d e s c o | h o s t | a n t a n d e r | a n t a n d e r e m p r e s a r i a | u r l | Array |new |\nFindProxyForURL |DIRECT|2 5 4 |6 3 |1 3 3 |8 0 |6 5 |PROXY| f u n c t i o n | l e n g t h | i f |\nshExpMatch | f o r \u2019 . s p l i t ( \u2019 | \u2019 ) , 0 ,{}) )\n\n\n\n5.5. Empirical Evaluation 67\n\nListing 5.3: Example of a deobfuscated PAC.\n\nf u n c t i o n FindProxyForURL ( u r l , h o s t ){\nv a r h=\u2019h \u2019 , b=\u2019b \u2019 , s =\u2019 s \u2019 , c =\u2019 c \u2019 , l =\u2019 l \u2019 ;\nv a r naxz=new Array ( \u201d?. \u201d+ s +\u201da n t a n d e r .?\u201d , b+\u201dr a d e s c o .?\u201d , \u201d? . \u201d+ b\n\n+\u201dr a d e s c o .?\u201d , \u201d? . \u201d+ h+s+b+c + \u201d.?\u201d , h+s+b+c + \u201d.?\u201d , b+b + \u201d.?\u201d , \u201d?. \u201d+\nb+b + \u201d.?\u201d , s +\u201da n t a n d e r .?\u201d , s +\u201da n t a n d e r e m p r e s a r i a \u201d+ l\n+ \u201d.?\u201d , \u201d?. \u201d+ s +\u201da n t a n d e r e m p r e s a r i a \u201d+ l + \u201d.?\u201d) ;\n\nf o r ( v a r p a 1 s =0; pa1s<naxz . l e n g t h ; p a 1 s++){\ni f ( shExpMatch ( h o s t , naxz [ p a 1 s ] ) ){\n\nr e t u r n \u201dPROXY 6 5 . 2 5 4 . 6 3 . 1 3 3 : 8 0 \u201d\n} } r e t u r n \u201dDIRECT\u201d }\n\nListing 5.4: Results of the analysis of the PAC in the previous example.\n\nbb . com . b r ?> 6 5 . 2 5 4 . 6 3 . 1 3 3 : 8 0\nb r a d e s c o . com . b r ?> 6 5 . 2 5 4 . 6 3 . 1 3 3 : 8 0\nh s b c . com . b r ?> 6 5 . 2 5 4 . 6 3 . 1 3 3 : 8 0\ns a n t a n d e r . com . b r ?> 6 5 . 2 5 4 . 6 3 . 1 3 3 : 8 0\ns a n t a n d e r e m p r e s a r i a l . com . b r ?> 6 5 . 2 5 4 . 6 3 . 1 3 3 : 8 0\n\n5.4.2 Data Extraction and Dynamic Execution\n\nThe previous process of obtaining logos, creating a banker-related terms dictionary, and\n\ndeveloping network/file system signatures involved the manual analysis of 1,194 malware samples\n\nobtained from phishing (and analyzed) between August, 2010 and July, 2011.\n\nFor our current tests, we selected 1,653 malware samples mainly from phishing messages and\n\npartners/contributors, all of them obtained in 20127. We submitted these samples to BanDIT,\n\nwhich runs on a virtualized Windows XP with Service Pack 3 for four minutes. This process\n\nincludes the external capture of network traffic and the extraction of images from the binary\n\nfile using Foremost. Moreover, we scanned all samples with the Avira antivirus engine to obtain\n\ntheir assigned labels. We normalized these labels to focus on the type/family of the malware\n\nsample. Table 5.1 shows the distribution of samples among malware families.\n\n5.5 Empirical Evaluation\n\nFrom Table 5.1, ? 23% of the 1,653 samples are not detected as malware by the antivirus\nengine (ID = 15), and ? 10% of the samples (ID = 16) are distributed among 63 distinct\nfamilies. The remaining of the samples is divided into the 14 families with highest incidence.\n\nBelow, we discuss the behaviors found in the samples, map their families and leverage BanDIT\n\nidentification results.\n\n7These 1,653 malware samples belong to the full dataset, which was used to the evaluation of our taxonomy\nin the previous chapter.\n\n\n\n68 Chapter 5. Malware Detection\n\nTable 5.1: Distribution of malware samples among Avira-assigned families.\nAV ID AV Label Total\n\n01 Agent 2.2%\n02 Atraps 6.4%\n03 Banker 17.7%\n04 Crypt 9.1%\n05 Delf 2.7%\n06 Delphi 5.8%\n07 Downloader 1.1%\n08 Gen 3.3%\n09 Graftor 2.5%\n10 Offend 3.0%\n11 Spy 5.4%\n12 Vb 4.4%\n13 Virtool 1.0%\n14 Zusy 2.0%\n15 NOT DETECTED 23.2%\n16 Other families 10.2%\n\n5.5.1 Observed Behavior\n\nBefore testing BanDIT, we manually analyzed our samples and searched for the set of be-\n\nhaviors defined in Section 5.3.3. We found 1,520 samples that behaved like bankers. Figure 5.7\n\nshows the amount of samples that presented each behavior. As also observed in Chapter 4,\n\ninformation stealing is the most frequent behavior found in our reduced dataset, followed by\n\nPAC loading, e-mail sending and the presence of bank-related images.\n\nFigure 5.7: Percentage of banker samples per presented behavior.\n\nTable 5.2 associates the malware family IDs to each observed behavior8. One can see that\n\n8IS = Information Stealing (Credential + System/User); ES = Email Sending; HC = Hosts Changing; PL =\nPAC Loading; BF = Bank Forgery (Internet banking images).\n\n\n\n5.5. Empirical Evaluation 69\n\nsamples labeled as \u201cbankers\u201d presented all of the selected behaviors: stealing credentials and\n\nsystem data, sending e-mail messages, loading PAC files, interfering with the \u201chosts\u201d file and\n\ncarrying bank logos, as expected. However it is worth mentioning that, except for \u201cHosts\n\nChanging\u201d and \u201cBank Forgery\u201d, all other banker-related behaviors were presented by all AV-\n\nassigned families, making the AV classification rather dull. Interestingly, bank-related images\n\nfound in samples do not correlate to the specific \u201cbanker\u201d AV label.\n\nTable 5.2: Behaviors presented (columns) by malware families (rows) under manual inspection.\nIS ES HC PL BF\n\n01 X X X X\n02 X X X X\n03 X X X X X\n04 X X X X X\n05 X X X X\n06 X X X X\n07 X X X\n08 X X X X\n09 X X X X\n10 X X X X\n11 X X X X\n12 X X X X\n13 X X X\n14 X X X X\n15 X X X X\n16 X X X X X\n\n5.5.2 BanDIT Results\n\nTo conclude our study about banker behavior, we evaluate BanDIT\u2019s results and compare\n\nour findings to the manual analysis previously provided. The main advantage of BanDIT is\n\nto aggregate different techniques into one component so as to identify banker-related behavior.\n\nFigure 5.8 shows how many of our 1,520 manually labeled samples (as bankers) were identified\n\nby each of the BanDIT\u2019s techniques. BanDIT was able to identify banker-related behavior\n\nin 1,502 (98.8%) samples. Network pattern matching was the most effective, but filesystem\n\nmodification monitoring and image analysis were also important, since that both (combined)\n\nidentified 539 (35.5%) samples.\n\n5.5.3 Infection Tracking\n\nDuring BanDIT\u2019s evaluation, we were able to identify 88 e-mail addresses that were compro-\n\nmised or specifically created to receive stolen data from banker\u2019s infected victims. Furthermore,\n\nwe pinpointed 183 IP addresses of attacker-owned/compromised servers that have been used\n\nto host malware pieces, such as PAC files, or to act as fake bank sites. For the purpose of in-\n\nformation leverage, we deployed a Web site (inspired on https://zeustracker.abuse.ch and\n\n\n\n70 Chapter 5. Malware Detection\n\nFigure 5.8: BanDIT\u2019s identification results\n\n\n\n5.5. Empirical Evaluation 71\n\nhttps://spyeyetracker.abuse.ch) based on Google Maps API [61] that tracks IP addresses\n\ncontacted by bankers and associates them with the type of infection (through a hosts or PAC\n\nfile, or by evading information via POST method). A screenshot of the Web site\u2019s main page is\n\nin Figure 5.9, where each marker provides geographical information about the compromised IP\n\naddresses and the infection type.\n\nFigure 5.9: Screenshot of BanDIT\u2019s Web site.\n\nWe found that 77.1% of the samples that evaded information through the network ended up\n\ncontacting IP addresses from Brazil, United States and Germany. Additionally, 80.7% of the\n\nIP addresses used in PAC files and \u201chosts\u201d files are from United States, Brazil and France. The\n\ne-mail accounts used by the bankers were notified to the corresponding e-mail providers and the\n\nIP addresses were notified to the competent authorities.\n\n5.5.4 Discussion\n\nIn our analysis, we considered that banks do not send executable files through e-mail to\n\ntheir clients, as major Brazilian banks claim on their Internet banking sites. The comparison of\n\nour manually obtained results to those produced by BanDIT shows that our system identified\n\ninformation stealing patterns on 94.6% of the samples, which stands pretty well to the 95.1%\n\nobtained by the manual process. This difference may be due to user interactions that might be\n\nrequired by the sample but were not done during the BanDIT analysis. Regarding the visual\n\n\n\n72 Chapter 5. Malware Detection\n\nsimilarity searching, BanDIT found Internet banking related images on 12.1% of samples, the\n\nsame amount that we found manually. This shows that the combination of logo searching and\n\nkeyword matching in the text obtained by an OCR was very effective. BanDIT\u2019s filesystem\n\nmonitoring led to the identification of changes in the \u201chosts\u201d file or loading of PAC files in 26.6%\n\nof our samples; in contrast, manual inspection identified this type of behavior in 29.1% of the\n\nsamples (PL + HC). In this case, the difference may be caused by problems during the sample\n\nexecution, such as PAC file unavailable, analysis timeout or the need for human interaction.\n\nFinally, our manual search for e-mail sending allowed us to find compromised servers and e-mail\n\naddresses.\n\nAlthough we chose not to address ZeuS and SpyEye samples, since there already are related\n\nwork addressing them (e.g., [27], [57]), we also tested the deBank tool9. It is intended to detect\n\nbanker variants from some known families, such as SpyEye and ZeuS through matching of\n\ncertain patterns found in the infected system\u2019s memory. We executed, one at a time, around 70\n\nSpyEye and ZeuS samples obtained from [2] and [3], and then launched the tool. Unfortunately,\n\nnone of them was detected by deBank, maybe because they are newer than the last available\n\nversion of the tool. This test was interesting as it corroborated the importance of screening\n\nout banker samples for further analysis, since traditional detection tools can be easily bypassed.\n\nWe conclude that behavior-based approaches, such as BanDIT, may be useful to help develop\n\ncounter-measures, although they are not intended for real-time detection. In addition, BanDIT\n\nidentification components can be easily linked to available dynamic analysis systems.\n\n5.6 Limitations and Future Work\n\nAs happens with every detection scheme, once the signature generation process is exposed,\n\nattackers are prone to change their malware. However, security researchers live an arms race\n\nagainst cybercriminals. Hence, we must remain alert for new malicious trends and techniques\n\nin order to develop new defensive countermeasures. Every signature-based scheme is prone to\n\nbe bypassed once attackers find out the signature generation process. This causes an arms\n\nrace between security people and cybercriminals, requiring this type of system to be constantly\n\nupdated. Another limitation that our system suffers is related to evasion techniques that affect\n\nall dynamic malware analysis systems, (e.g., waiting for a certain number of reboots before\n\npresenting the malicious behavior). However, since we are able to extract images from the sample\n\nfile, our visual similarity technique may identify a banker right away. Due to our observations\n\nthat most Brazilian bankers send the stolen information unencrypted, we currently do not handle\n\nencrypted network traffic. Thus, the current implementation would not be able to identify stolen\n\ndata sent by an encrypted channel.\n\nHowever, the detection steps based on images and file system modifications could do this job.\n\nFurthermore, we can improve the system to monitor the network traffic before it is encrypted,\n\nsolving this issue. The image recognition process may fail when malware employ overlays to\n\npresent the bank images, because the traditional screenshot capture the contents presented in\n\nthe overlay. But, to evade all image gathering techniques employed by our system, the malware\n\n9http://www.fitsec.com/tools/DeBank.exe\n\n\n\n5.7. Concluding Remarks 73\n\nalso have to use encryption when obtaining the images from the network and keep it obfuscated\n\nwhen it is stored inside the malware file. Also, rootkit-based malware could potentially subvert\n\nour filesystem monitoring component, however only two samples of our dataset loaded drivers\n\nand one of them was identified by BanDIT as a banker.\n\nTherefore, the use of more than one detection method is important because it allows the\n\nsystem to identify a malicious behavior even when one or two of the employed methods fail.\n\nFuture works include making the infection tracking system available to the public, addressing\n\nencrypted network traffic and developing dissectors to extend our network protocol coverage.\n\nFinally, we are working on the relationship of samples to malware development kits so as to\n\nprovide information to law enforcement agencies.\n\n5.7 Concluding Remarks\n\nAs more sophisticated bankers appear, the need for counter-measures and fast response\n\nincreases. Thus, it is important to identify and extract relevant information about bankers so\n\nthat they can be screened out during dynamic analysis for further and deeper investigation. In\n\nthis chapter, we introduced BanDIT, a system that dynamically analyzes malware in order to\n\nidentify bankers. BanDIT\u2019s identification process combines visual similarity searching, network\n\ntraffic pattern matching and filesystem modification monitoring. BanDIT\u2019s evaluation shows\n\nthat it is effective to screen bankers out (98.8% of correct identifications) of a dataset of general\n\nmalware. Moreover, BanDIT helps incident responders to warn victims in a timely manner, to\n\nnotify infected ISPs and servers and to create blacklists that can be quickly deployed to avoid\n\nmore banker infections to take place. Finally, we showed that our behavior-centric taxonomy\n\ncan be extended to address specific types of malware and to help in detection procedures.\n\n\n\n74 Chapter 5. Malware Detection\n\n\n\nChapter 6\nMalware Visualization\n\n6.1 Introduction\n\nAnother possible use for malware behavioral profiles is to serve as input to visualization tools.\n\nVisual analysis of malware behavior can facilitate the work of incident responders, as well as\n\nhelp in the search for unusual patterns. In this chapter, we show how visualization can improve\n\nthe analysis of malware-related incidents. To this end, we developed two tools that handle and\n\npresent samples\u2019 extracted execution behavior, the behavioral spiral and the malicious timeline.\n\nThese tools take advantage of our dynamic malware analysis system, BehEMOT, to generate\n\ninteractive and visual environments regarding a malware sample execution. A great advantage\n\nof visually analysing malware behavior is the possibility to verify the \u201csimilarity\u201d among families,\n\nas well as the separability among them.\n\n6.2 Interactive, Visual-Aided Tools to Analyze Malware\n\nBehavior\n\nWe saw previously that malware samples usually disseminate through the Internet and can\n\ncause incidents with severe damage to confidentiality, integrity or availability of systems and\n\ndata. Most malware are not target-oriented, attacking as many systems as they can, so that\n\nan attacker can gain control and use of the victim\u2019s resources or steal sensitive data. However,\n\nthere are cases in which malware have specific targets and are thoroughly designed to delude the\n\nvictim, talking the unsuspecting user into supplying confidential information, as it happens in\n\nattacks directed to a government infrastructure. In both situations, severe incidents caused by\n\nmalware can disrupt an entire network of systems by disseminating through headquarters and\n\nthen to branch offices or can also cause irreparable damage by exposing confidential information.\n\nWhen attacks succeed in breaking into a computer system, forensic procedures can be fol-\n\nlowed in order to find out:\n\n\u2022 How the attack was perpetrated;\n\n\u2022 Where the points of collection of information are (downloading of tools and sending of\ndata);\n\n75\n\n\n\n76 Chapter 6. Malware Visualization\n\n\u2022 What happened during the attack to the system.\n\nIn the case of malware attacks, it is important to collect the binary that infected the system\n\nor was downloaded after the target system was compromised. This binary may then provide\n\nsome clues leading to a deeper understanding of the techniques used by the attacker and the\n\npurpose of the attack. This can be done by running this malware in a controlled environment\n\nand monitoring all the filesystem and network activities to compose a specific behavioral trace,\n\nas we have been doing for this thesis results.\n\nMalicious behavioral traces are in essence a log of the events performed by a malware on\n\na compromised system, but this amounts to large chunks of data. Such logs are difficult to\n\nanalyze as we have to stress out interesting segments of behavior (main malicious actions) while\n\nsimultaneously having to obtain a general overview of the extension of the damage. However,\n\nthe information obtained from this analysis is paramount to provide adequate incident response\n\nand mitigation procedures. In those cases of massive amounts of textual data to analyze, we\n\ncan apply visualization techniques that can greatly enhance the analysis of logs and allow us to\n\nquickly spot important actions performed by a specific malware and to better understand the\n\nchain of malicious events that led to the compromise of the target system.\n\nThe main contributions of this section are:\n\n\u2022 We developed two visualization tools\u2014the behavioral spiral and the malicious timeline\u2014\nto aid security analysts to observe the behavior that a malicious software presents during\n\nan attack. Those tools are interactive and they allow a user to walk through the behavior\n\nwhile performing zoom, rotate, and gathering of detailed information for each malware\n\naction.\n\n\u2022 We discuss visual classification of malware families and show that our tool can be used\nto visually identify an unknown malware sample based on its comparison to previously\n\nknown malware, and that is a step towards a visual dictionary of malicious code.\n\n\u2022 We distribute online a beta version of our prototype, so that the community can benefit\nfrom it and use it freely.\n\n6.2.1 Related Work\n\nThere are several research works that use visualization tools to overcome the plenty of data\n\nprovided by textual logs related to security. Some of them are not open to the public, others are\n\nneither intuitive to use nor interactive, and there are those whose results are more difficult to\n\nbe visually interpreted by security analysts than if they search manually through the log files.\n\nQuist and Liebrock [120] applied visualization techniques to understand the behavior of\n\ncompiled executables. Their VERA (Visualization of Executables for Reversing and Analy-\n\nsis) framework helps the analysts to have a better understanding of the execution flow of the\n\nexecutable, making the reverse engineering process faster.\n\nConti et al. [36] developed a system that helps the context-independent analysis of binary\n\nand data files, providing a quick view of the big picture context and internal structure of files\n\n\n\n6.2. Interactive, Visual-Aided Tools to Analyze Malware Behavior 77\n\nthrough visualization. In a forensic context it is especially helpful when analyzing files with\n\nundocumented formats and searching for hidden text messages in binary files.\n\nTrinius et al. [157] used visualization to enhance the comprehension of malicious software\n\nbehavior. They used treemaps and thread graphs to display the actions of the executable and to\n\nhelp the analyst identify and classify malicious behavior. While their thread graphs can confuse\n\na human analyst with lots of overlapped information and lack of interactivity, our timeline\n\n(Section 6.2.3) allows a walk-through over the chain of events performed by different processes\n\ncreated and related to the execution of a certain malware sample, as well as the magnification of\n\ninteresting regions, information gathering about selected actions and annotation. Furthermore,\n\nour behavioral spiral represents temporal action, whereas their proposed treemaps consist of\n\nthe actions\u2019 distribution frequency. Again, there is a lack of interactivity and excessive data, as\n\nwe handle only actions that can cause changes on the target system. However, similarly to our\n\nwork, it is not possible to visually classify every malware family, as variant samples can pertain\n\nto a class while presenting completely different behavior regarding the order or nature of the\n\nperformed actions.\n\nFinally, reviewing logs from intrusion detection systems is an important task to identify\n\nnetwork attacks and understand these attacks after they happened. There are several tools that\n\nuse visualization for this purpose; each one has its own approach and is better than others at\n\nspecific situations. To take advantage of those tools the DEViSE (Data Exchange for Visualizing\n\nSecurity Events) framework [124] provides the analysts a way to pass data through different\n\ntools, obtaining a better understanding of the data by aggregating more extracted information.\n\n6.2.2 Data Gathering\n\nTo visualize malware behavioral data, we first need to collect malware samples that have\n\nbeen currently seen in the wild and then analyze them to extract the actions they would perform\n\nin an attack to a target system. In the sections below, we discuss our approaches to malware\n\ncollection and behavior extraction.\n\nMalware Collection\n\nTo collect malware samples that spread through the Internet, we use our automated collection\n\narchitecture [64], which uses mixed honeypots technology (low and medium interaction) [119] to\n\ncapture malicious binaries for MS Windows systems. Honeypots are systems that are deployed\n\nto be compromised so as to lure attackers to reveal their methods and tools by the compromise\n\nof a highly controlled environment. The collection architecture consists of a Honeyd [118] node\n\nto forward attacks against certain vulnerable ports to a Dionaea [153] system, which emulates\n\nvulnerable MS Windows services in those forwarded ports and actually downloads the malware\n\nsample. During 2010 we captured more than 400 unique samples, which are used as our test\n\ndataset in this chapter.\n\n\n\n78 Chapter 6. Malware Visualization\n\nBehavior Extraction\n\nTo extract the behavior of a malicious software, we run it in a controlled environment and\n\nmonitor the actions it performs during the execution in the target system. Those actions are\n\nbased on the system calls executed that are relevant to security, i.e. if they modify the status\n\nof the system or access sensitive information, such as file writing, process creation, changes in\n\nregistry values or keys, network connections, mutex creation and so on. The dynamic analysis\n\nenvironment used for behavior extraction is BehEMOT [63], our system that was presented on\n\nChapter 4. It produces logs in which each line means one action performed by the monitored\n\nmalware sample or a child process and is in the form \u201ctimestamp, source, operation, type,\n\ntarget\u201d. For instance, lets suppose that a malware sample \u201cmw.exe\u201d created a process entitled\n\n\u201cdownloader.exe\u201d, which connects to port 80 of an Internet IP address X.Y.W.Z to download a\n\nfile a.jpg to a temporary location TEMP. The log file produced by BehEMOT would have the\n\nfollowing three lines:\n\nts1, mw.exe, CREATE, PROCESS, downloader.exe\n\nts2, downloader.exe, CONNECT, NET, X.Y.Z.W:80\n\nts3, downloader.exe, WRITE, FILE, TEMP/a.jpg\n\nTherefore, we use the BehEMOT behavior format to input the textual data to our visualiza-\n\ntion tools, which are described in the next section. It is worth noting that logs produced from\n\nmalware sample execution can be thousands of lines long, motivating the use of visual tools to\n\naid the process of human analysis.\n\n6.2.3 Interactive Visualization Tools for Behavioral Analysis\n\nThe behavior of a malicious program can be interpreted as a chain of sequential actions\n\nperformed on a system (as seen in the previous section), which involves operating system inter-\n\nactions and network connections. The analysis of those operations can provide the steps that\n\nwere performed in an attack to understand the incident as a whole, as well as detailed informa-\n\ntion about what was changed in a system, such as libraries that were overwritten, infected files,\n\ndownloaded data and even evaded information.\n\nUsually, antivirus developers analyze unknown malware samples to create signatures or\n\nheuristics for detection. This is an overwhelming process and involves plenty of manual work,\n\nas a human analyst has to search for pieces of data that characterize the sample as part of an\n\nalready known malware class or create a new identifier to it. Actually, this process is worse due\n\nto the increasing amount of new malware made from \u2018do-it-yourself\u2019 kits and variants of older\n\nones. Sometimes, a malware is assigned to a family (and detected by an antivirus engine) based\n\non the value of a mutex it creates, or on a specific process that it launches with a particular\n\nname, or on the kind of information it sends to the network.\n\nOur motivation to develop visual tools is to make it easy to process and pinpoint very\n\nspecialized information and then to help a human analyst to focus in the interesting actions\n\nperformed by a malware sample. This way, it is possible to quickly analyze new malware\n\nby visualizing their overall behavior and expanding only those actions that an experienced\n\n\n\n6.2. Interactive, Visual-Aided Tools to Analyze Malware Behavior 79\n\nanalyst considers suspicious or important. Also, public available dynamic analysis systems\n\n(e.g. [72], [155], [26]) provide textual reports full of information that would be easier to be\n\ninterpreted if an analyst could visually manipulate it. To fill this gap, we developed two tools\n\nthat transform a textual report from a dynamic analysis system into an interactive and visual\n\nbehavior, which are explained below.\n\nTimeline and Magnifier\n\nMalware time series events can also be visualized in simple x-y plots, where the x axis\n\nrepresents the time and the y axis some information about the event. The time information on\n\nthe x axis can be any of the following: i) the absolute time of occurrence of an event; ii) the\n\nrelative time of occurrence (counted from a particular initial value); or iii) a simple sequence\n\nthat implies the order of occurrence of the events.\n\nThe event information can be plotted using several different methods, often specifically tai-\n\nlored to a particular purpose. The height on the y axis can be used to represent the frequency\n\nof occurrence, severity or intensity of a given event, if such information is known, or a dis-\n\ncrete representation of event types. Decorations such as different marks for additional event\n\ncharacteristics can also be used to allow representation of more data dimensions than just two.\n\nAdditional graphical elements may also be used, but one should always take care not to overload\n\nthe plot with too much graphical content, which may confuse the user and hinder his/her ability\n\nto draw quick conclusions from the plot.\n\nAn example x-y plot used to represent malware time series events is given in Figures 6.1 and 6.2\n\n(events selected by the tool\u2019s user to be a search pattern are underlined in light red; automati-\n\ncally matched events are underlined in dark red). They show the corresponding tool in action,\n\nas it parses a malicious behavior file with malware events ordered by action timestamp and\n\nplots the result using a simple, interactive interface. The tool draws the whole time series in\n\ntwo panels: on the top panel all points on the series are plotted, with the x axis representing\n\nthe order in which events occurred and the y axis representing the action associated with an\n\nevent (which are not in any particular order and can be rearranged). Also, events are plotted as\n\ndots of different colors, according to the process id that performed such actions. For example,\n\nif the malware associated process created two child processes and also required service from an\n\nalready running process, we would have four different colors in the graphic: malware, first child,\n\nsecond child and the running process). Not all possible monitored actions have to be performed\n\nby a malware, so the y axis varies accordingly to what was present in the captured behavioral\n\ntrace.\n\nPlots created by this tool are also interactive. Since there are many events on the top\n\nsection of the plot, it is hard to see exactly which one follows which one, so a region of interest\n\n(highlighted under a translucent yellow region on the plot) can be selected by the user. Selection\n\nis done by dragging the region with the mouse, which also causes the region of interest to be\n\nshown enlarged on the bottom panel of the plot. The x and y axes and plot colors follows\n\nthe ones in the top section. The bottom part of the plot also conveys information about the\n\ndiversity and variability of operation types in its gray background: darker backgrounds suggest\n\na higher diversity, whereas lighter backgrounds point to higher similarity.\n\n\n\n80 Chapter 6. Malware Visualization\n\nFigure 6.1: Timeline and Magnifier tool representing malicious events.\n\nFigure 6.2: Sequence of selected events (user and automatic).\n\nMalicious Spiral\n\nThe goal of this tool is to present an ordered sequence of all malicious actions of an attack\n\nin a spiral format, using an iconic representation. The spiral representation is useful to show\n\nthe big picture of a malware sample behavior and also to allow quick visual comparisons among\n\ndifferent malware samples even in the presence of variants. Instead of using a straight line\n\nbroken in columns [50], the spiral format is less prone to confusion as small variances present\n\nin the behavior of malware from the same class usually keep the general visual appearance that\n\nmodels a family.\n\nBy exploiting the viewing abilities available, an investigator can zoom in and out, turn,\n\ntilt, select behavior slices, view the logged action in textual form and compare it with other\n\nbehavioral data, if available. Thus, we provide not only an overview of the attack, but also\n\n\n\n6.2. Interactive, Visual-Aided Tools to Analyze Malware Behavior 81\n\nthe possibility of identifying certain behavioral patterns that could help in the classification of\n\nmalware samples (Section 6.2.4).\n\nThe operations and types that are monitored and used to produce a behavior log are shown\n\nin Table 6.1, as well as all icons that are used to represent them. We divided the table lines\n\nin four groups of operations with similar purpose on each subsystem type, e.g., a CONNECT\n\noperation in a NET type has the same effect as that of a CREATE REGISTRY, i.e. they prepare\n\nthe environment for an active operation that will represent a registry value being written or a\n\nnetwork connection being opened that later might send data. In the same way, a READ FILE\n\nor REGISTRY, a RECEIVE NET and a QUERY MUTEX are all passive operations, and so\n\non.\n\nTable 6.1: Icons for monitored operations and types.\nAction / Type MUTEX FILE PROC REG NET\n\nREAD\n\nQUERY\n\nRECEIVE\n\nWRITE\n\nSEND\n\nCONNECT\n\nCREATE\n\nDISCONNECT\n\nDELETE\n\nTERMINATE\n\nRELEASE\n\n6.2.4 Tests and Analysis of Results\n\nAlthough we have developed the timeline and the spiral tools based on the same kind of\n\nlog format, they have different usage. The timeline and magnifier tool can be used by any user\n\nto do a \u201cbehavioral walk-through\u201d, while verifying how many processes were launched, what\n\nactions they performed and from what kind, etc. On the other hand, the spiral tool can be used\n\nto visually identify malware from the same family, while simultaneously depicting an iconic\n\noverview of the behavior that can be manipulated to show more detailed information (present\n\nin the log file). In this section, we show how the spiral tool serves as a visual dictionary and how\n\nit can help classify malware from the same family. To the extent of our tests, we extracted the\n\nexecution behavior from 425 malware samples collected by the system described in Section 6.2.2\n\nand dynamically analyzed them with the system described in Section 6.2.2.\n\nAll malware samples from our dataset are currently found \u201cin the wild\u201d and together consti-\n\ntute variants from 31 families. Scanning them with the up to date ClamAV antivirus engine [33]\n\n\n\n82 Chapter 6. Malware Visualization\n\nreveals 94 unidentified samples. By observing the generated spirals, we realized that it is pos-\n\nsible to group some of them by their visual behavior. Also, malware samples from different\n\nfamilies present similar behavioral patterns among samples from their own class, while at the\n\nsame time keeping a dissimilarity from other classes\u2019 samples. This differentiation factor present\n\nin the visual patterns is an important indicative that clustering algorithms, artificial intelligence\n\nand data mining techniques can be applied to our logs to classify malware based on behavioral\n\nsimilarities.\n\nIn Figure 6.3, we chose two trojan families\u2014Pincav and Zbot\u2014and selected three samples of\n\neach one to be printed side-by-side. Notice that even when the malware samples from a family\n\nperform variant operations, they still keep a behavioral pattern that can be used to characterize\n\nthem in the same class.\n\nFigure 6.3: Behavioral spirals for \u2018Pincav\u2019 (a) and \u2018Zbot\u2019 (b).\n\nAnother interesting fact is that if a malware sample tried to do more network connections\n\nthan another one from the same family (e.g., malicious scans) or if it performed fewer actions\n\nor crashed, it is possible to clearly notice the similarities between an incomplete behavior and\n\na larger one, as shown in Figure 6.4, which contains three samples of the Allaple family ((a)\n\na sample that could not connect to the network and stopped its activities; (b) a sample that\n\nperformed a short network scan; (c) a sample performing a massive scan, where each red sphere\n\nmeans a connection to a different IP address).\n\nIn Figure 6.5, we depict the behavioral spirals from four different malware families\u2014the\n\nworms Palevo and Autorun; the Trojans Buzus and FakeSSH. Notice that we can visualize\n\nthe separability of the classes with minor variances among behaviors from the same family\n\nfor Palevo, Autorun and FakeSSH. In the case of Buzus, one can observe that the first two\n\nbehaviors significantly differ from the last ones, putting those samples apart from each other\n\n\n\n6.3. Concluding Remarks 83\n\nFigure 6.4: Three \u2018Allaple\u2019 worm variants.\n\nis an automated classification scheme. However, in Figure 6.6, one can also realize that a\n\nsample whose AV assigned label is \u201cUNKNOWN\u201d\u2014i.e. an unidentified sample\u2014presents a\n\nvisual behavior that is quite similar to a sample from the trojan family \u201cInject\u201d.\n\n!\"#$%&amp;'()*\"+ !\"#$%,-.\"#-/+ 0#\"1'/%2-3-4+ 0#\"1'/%5'6)778+\n\n!\n\n!\n\n!\n!\n\n! !\n\n!\n\n!\n!\n\n! !\n\n!\n\n!\n\n! !\n\n!\nFigure 6.5: Visual behavior extracted from four malware families.\n\n6.3 Concluding Remarks\n\nIn this chapter we proposed two interactive, visual-aided tools to increase the efficiency in\n\nmalware analysis, which allow security analysts to overview malicious behaviors. Moreover,\n\nour tools allow walking through over the logs, annotation and highlighting of interesting events\n\nand actions, searching for patterns, deeper understanding of the damage performed on a target\n\n\n\n84 Chapter 6. Malware Visualization\n\nFigure 6.6: Unidentified malware (right) sample visually classified as a known threat (left).\n\nsystem and visual comparison among malware samples. Hence, the possibility of visual family\n\ndistinction suggests that we can apply, in the future, other automated techniques to classify,\n\ncluster or mine behavioral data. It is also possible to visualize which parts of a malware sample\n\nbehavior are similar to another one\u2019s, indicating the same functionality or even code reuse.\n\n\n\nChapter 7\nMalware Classification\n\n7.1 Introduction\n\nIn this chapter, we introduce another way of extracting behavioral profiles, this time through\n\na lower level tracing of the malware execution to capture performed instructions and their written\n\nvalues. Using these traces, we developed a two-step approach to group malware samples that\n\nare quite similar according to an empirically established threshold. We show that this type of\n\nbehavior can be effectively used to cluster malware samples into families with good results by\n\ncomparing our produced clustering with three distinct reference clustering sets. We also map\n\nthe value traces back to the original instructions, thus showing that it is possible to search for\n\nsimilar blocks of code between two malware samples. The achieved results indicate that it is\n\npossible to improve the proposed techniques to find code reuse present in malware variants or\n\nsamples that are produced using malicious development kits.\n\n7.2 Motivation\n\nMalicious software (malware) is a significant threat for cyber security. It has evolved from\n\nprograms used to infect other programs and do damage to a personal computer, to political\n\nweapons and pathways to organized crime. Current malware operations vary from stealing sen-\n\nsitive data (secret documents, credentials, credit card numbers and other financial information)\n\nto attacking critical infrastructure and SCADA systems, as seen with the Stuxnet incident [52].\n\nToday\u2019s malware employs many different ways to propagate, including social engineering tech-\n\nniques to deceive a user to click on e-mail attachments [39], as well as drive-by download attacks\n\nthat exploit web browsers and their plug-ins [172].\n\nBesides the diversity of purposes and propagation vectors that can be observed in current\n\nmalware, cyber criminals have started to sell \u201cdo-it-yourself\u201d kits that allow anyone to create\n\ncustomized malicious code. Moreover, malware developers usually apply obfuscation techniques\n\n(e.g., polymorphism and packing) to avoid detection by the security mechanisms installed on\n\na victim\u2019s system. The result is a plethora of new samples that are discovered every day.\n\nThis massive amount of malware variants overwhelms security analysts, and it increases the\n\ndifficulty for anti-virus (AV) software providers to update their product\u2019s databases in a timely\n\n85\n\n\n\n86 Chapter 7. Malware Classification\n\nfashion [44].\n\nObfuscation techniques are a powerful tool to render static malware analysis approaches\n\nineffective and to defeat those security tools (such as anti-virus scanners) that rely on signatures.\n\nTo address this problem, researchers have proposed dynamic analysis systems, which rely on the\n\nobserved runtime activities (behavior) for detection and classification. With dynamic analysis,\n\na malware sample is run inside an instrumented environment, and the sample\u2019s actions are\n\nmonitored. To capture and model the behavior of malicious code, dynamic analysis systems\n\ntypically rely on system calls. The underlying assumption is that system calls capture the\n\ninteractions of a program with its environment, and they can be used to monitor all persistent\n\nchanges to the operating system. Also, system calls are relatively easy to capture (e.g., by\n\nhooking the system call table), and user-mode malware has no way to bypass the system call\n\ninterface.\n\nUnfortunately, system calls are not the perfect solution. They treat the program as a black\n\nbox and capture activity at a relatively high level. For example, two programs might be very\n\ndifferent \u201cinside\u201d but might yield the same, visible effect to the \u201coutside\u201d by invoking the same\n\nsystem calls. While this might not be an immediate problem for malware detectors, it makes\n\nit hard to distinguish between different malware families. More problematic, a malware author\n\nhas a lot of flexibility in disguising behavior that is recorded at the system call level. For\n\nexample, independent system calls can be scheduled in different order. Moreover, a particular\n\nchange to the operating system can often be achieved through different system calls. Previous\n\nresearch [60] has demonstrated that system-call-based intrusion detection systems can be evaded\n\nby replacing one sequence of system calls with a semantically-equivalent but different one.\n\nFinally, researchers have introduced third-generation mutation engines that provide functional\n\npolymorphism: program activity at the system call level is automatically obfuscated [75].\n\nTo address the limitations of system-call-based detection and classification, we propose a\n\nnovel approach to capture and model program (malware) behavior. Our approach is based on\n\nmonitoring the data values that a program produces while it is performing its computations.\n\nMore precisely, while the program is executing, we record a trace that contains all the values that\n\n(a certain subset of) instructions write. These writes can go either to a destination register or a\n\nmemory location. By looking at the intermediate data values that a computation produces, we\n\nanalyze the execution of a program at a much finer level of granularity than by simply observing\n\nsystem calls. The main intuition is that by using the data values, we can produce a very detailed\n\nprofile that captures the activity of individual functions. Also, data values are tied very closely\n\nto the purpose (semantics) of a computation, and, hence, are not as easy to disguise as the code\n\nthat performs the computation. Malware authors have introduced many ways in which code\n\ncan be altered so that syntactically different instructions implement the same algorithm (e.g.,\n\ndead code insertion, register renaming, instruction substitution). However, when an algorithm\n\ncomputes something, we would expect that, at certain points, the results (and temporary values)\n\nfor this computation hold specific values. Our goal is to leverage these values to identify (possibly\n\ndifferent) code that \u201ccomputes the same thing.\u201d\n\nWe introduce a mechanism to record a trace of values that are written by \u201cinteresting\u201d\n\ninstructions. Leveraging these traces (one for each program execution), we have built two\n\n\n\n7.3. Related Work 87\n\ntechniques that implement tasks that are important for malware analysis. First, we propose an\n\nefficient clustering technique to find malware samples that perform similar activity (implement\n\nsimilar computation), and, hence, are very likely to belong to the same malware family. Second,\n\nwe show how traces can be used to find code reuse between samples that are different. That\n\nis, we look for similar subsets in traces that are mostly different. This allows us to find code\n\nsnippets that are shared between malware samples of different families.\n\nThe main contributions presented on this chapter are the following:\n\n\u2022 We propose a novel approach to capture and model behavior from dynamically analyzed\nmalware. This approach is based on the sequence of values that a program writes (to\n\nmemory or registers).\n\n\u2022 We describe an efficient, two-step decision procedure to decide whether two value traces\n(produced by the execution of two programs) are similar. This is important because value\n\ntraces can be very large.\n\n\u2022 We leverage the aforementioned decision procedure to implement malware clustering and\ncode reuse identification.\n\n\u2022 We implemented a prototype system and collected the execution traces for more than\n16 thousand malware samples. We demonstrate that the clustering results produced by\n\nour system have a good precision, and we show that we can find code reuse in unrelated\n\nmalware families.\n\n7.3 Related Work\n\nMalware analysis, detection, and classification remain as open problems in the security field,\n\nas there is no holy grail that completely solves all these issues. In addition, malware authors\n\nare always developing new ways to subvert or evade security mechanisms. There are several\n\nprevious systems that use assembly instructions to address malware identification/classification,\n\nbut, to the best of our knowledge, there are no approaches that leverage memory manipulation\n\n(write) operations and values. In addition, most of the works that used assembly instructions\n\ncollected them through binary static analysis techniques, which is provably limited for malware\n\ndetection [103].\n\nDynamic malware analyzers such as [86], [168], [111] and [26] operate at the system call\n\nlevel and currently do not log the low-level values of an execution (memory and registers).\n\nVirtICE [122] could obtain this information from a malware sample by monitoring it from outside\n\nthe emulated execution environment, but it does not collect this information in an automated\n\nway and it is not publicly available. Ether [45] performs both instruction and system call tracing\n\nto analyze malware in a transparent way by using hardware virtualization extensions, but it has\n\nseveral of prerequisites on the type of operating system, architecture and platform, which can\n\nlimit its use.\n\nIndeed, we can divide malware classification techniques according to how the traces were\n\nobtained \u2014 i.e. through either static or dynamic analysis \u2014 and to the type of behavior gathered\n\n\n\n88 Chapter 7. Malware Classification\n\n\u2014 i.e. either lower-level or assembly-related data or higher-level or system call information.\n\nBelow, we discuss recent research based on static and dynamic analysis.\n\n7.3.1 Static Analysis Approaches\n\nShankarapani et al. [134] propose two detection methods to recognize known malware vari-\n\nants without the need of new AV signatures: SAVE, which generates signatures based on a\n\nmalware sample API calls sequence through the static analysis of its executable, and MEDiC,\n\nin which the signature of a malware sample is part of its disassembled code. SAVE performs\n\nan optimal alignment algorithm before applying similarity measure functions (cosine, extended\n\nJaccard, and Pearson correlation). This kind of algorithm does not scale well if there are too\n\nmany sequences or if the sequences are very large. For executable files whose size is among ?500\nBytes to ?1000 Bytes, the detection time can be in a range of few seconds (considering just one\nexecutable). They claim that MEDiC is more accurate in detection due to the different data\n\nused (assembly instructions) and then test it against a very limited set of known families \u2014\n\nlabeled by AVs \u2014 with few variants of each family to demonstrate their detection capabilities.\n\nKinable and Kostakis [82] performed a study of malware classification based on call graph\n\nclustering, where they measured the similarity of call graphs that were extracted from malicious\n\nbinaries through matches that try to minimize the edit distance between a pair of graphs. In this\n\ncontext, a call graph is built after obtaining the function names from a sample through static\n\nanalysis. The authors conclude that it is difficult to partition malware samples in well-defined\n\nclusters using k-means based algorithms, and chose to use the DBSCAN algorithm to cluster\n\nsome sets, the larger having 1,050 samples. They state that this larger set had 72% correct\n\nclusters.\n\nZhang and Reeves [173] propose a method to detect malware variants that uses automated\n\nstatic analysis to extract the executable file semantics. These semantic templates are charac-\n\nterized based on the system calls executed by a malware sample and used in a weighted pattern\n\nmatching algorithm that computes the degree of similarity between two code fragments. To\n\ngenerate a semantic template, they disassemble a malware sample and identify instructions that\n\naffect the values in memory or registers related to the target address of the call instruction.\n\nThose instructions are considered the code patterns of the templates and are input to a maxi-\n\nmum weighted matching algorithm that calculates the similarity degree based on the mean of\n\nthe similarity scores from matched pairs of elements. The authors use a few samples to test the\n\nproposed approach (less than a thousand), and they claim that it is possible to identify code\n\nreuse among malware variants by using the similarity coefficient calculation. In our work, we\n\nidentify which instructions are being reused (and in which part of the trace), and our templates\n\nare based on instructions (arithmetic and logic) that modify values in memory and registers.\n\n7.3.2 Dynamic Analysis Approaches\n\nPark et al. [114] present a classification method that uses a directed behavioral graph ex-\n\ntracted from system calls through dynamic analysis. The generated directed graphs from two\n\nmalware samples are compared computing the maximal common subgraph between them and\n\n\n\n7.3. Related Work 89\n\nthe size of this subgraph is used as the similarity metric. They evaluated their method on 300\n\nmalware samples divided into 6 families, and 80 benign Windows applications.\n\nBailey et al. [12] developed a method based on the behavior extracted from a malware\n\nsample after executing it in a virtualized environment. This behavior is considered the malware\u2019s\n\nfingerprint and represents the set of actions that changed the system state, such as files written,\n\nprocesses created, registry keys modified, and network connection attempts. They discuss the\n\nAV labeling inconsistency problems, which is also a motivation for our work. The tests were\n\nperformed on a dataset of 3,700 samples from which the fingerprints were extracted. The\n\nnormalized compression distance (NCD) was used as a similarity metric, and the pairwise single-\n\nlinkage hierarchical clustering algorithm was used for classification purposes. However, as the\n\ndistance matrix computation is an O(N2) operation, as it requires the calculation of the distances\n\namong every each pair, the process cannot scale well to larger datasets.\n\nRieck et al. [125] propose the use of machine learning techniques on malware behaviors\n\ncomposed of changes that occurred in a target system in term of API function calls. They ran\n\ntheir experiments on more than 10,000 malware samples divided into 14 families labeled by AV\n\nsoftware. The behavioral profiles obtained from dynamic analysis serve as a basis to feature\n\nextraction and use the vector space model and the bag of words techniques. After that, the\n\nSupport Vector Machines method is applied to the feature sets for classification purposes. The\n\nresults presented show that their approach can characterize unknown new malware samples by\n\nassigning them to previously-defined clusters.\n\nBayer et al. [15] present a scalable clustering approach to classify malware samples based on\n\nthe behavior they present while attacking a system. Dynamic analysis is used to generate the\n\nbehavioral profiles \u2014 sequences of enriched and generalized information abstracted from system\n\ncall data. The similarity metric used in their work is the Jaccard index, which is then used as an\n\ninput to the LSH clustering method. To create a reference clustering set and verify the results\n\naccomplished by their work, they selected 2,658 samples for which there were a major degree\n\nof agreement among 6 AV programs, regarding the samples\u2019 attributed labels. They show that\n\ntheir approach could analyze 75,692 samples in 2 hours and 18 minutes.\n\nVery recently, Jang et al. [78] introduced BitShred, an algorithm for fast malware clustering.\n\nIn this paper, the authors present a new way to efficiently simplify and cluster features from\n\ninputs such as (static) code bytes and (dynamic) system call traces. The work is orthogonal\n\nto ours: The authors focus on improving clustering performance based on well-known malware\n\nactivity models. We on the other hand introduce a novel and robust way to model malware\n\nactivity.\n\nAs discussed, there is a myriad of possibilities to classify malware. However, previous work\n\nsuffers from limitations, such as scalability constraints, a restricted utility of the results, the sole\n\nuse of AV labeling as ground truth, or performing comparisons using a very limited malware\n\ndataset distributed among few different families. In our approach, we do not use AV labels as\n\nour main reference clustering; instead, the AV labels are used as an additional reference for the\n\nclassification scheme. Moreover, our approach is more robust compared to previous work based\n\non system call sequences and/or byte values in executable code. This is because we focus on the\n\ndata values that are written by computation. These values reflect much closer the semantics of\n\n\n\n90 Chapter 7. Malware Classification\n\nexecution.\n\n7.4 Data Value Traces\n\nIn this section, we discuss how we build data value traces to capture the activity of a (mal-\n\nware) program. To obtain these traces, we developed a prototype system that runs malware\n\nsamples in an emulated environment. The prototype was developed using PyDBG [133]. This\n\nprovides us with tight control of the debugging process. Also, PyDBG provides features to\n\nhide its debugging activity, which is useful to foil most malware attempts to detect the analysis\n\nenvironment.\n\nWe use our prototype to record an ordered sequence of instructions that modify at least one\n\nregister or memory value; that is, we are only interested in instructions that write to memory. For\n\neach of these instructions, we store the numeric value(s) of all memory locations and registers to\n\nwhich this instruction writes (typically, this is one). For instance, if a malware sample executes\n\nthe instruction sub esp,0x58, we will log in our trace the line sub esp,0x58; 0x12ff58, which\n\ncorresponds to the instruction and the new value written to register %esp, which is 0x12ff58 in\n\nthis example (assuming that the initial value of %esp was 0x12ffb0). When the malware process\n\nterminates or a timeout is reached, we also take a snapshot of the content of the malware\u2019s\n\nexecutable (code) segments. This information is needed later to identify code reuse between\n\nmalware samples, but it is not required to identify similarity between samples.\n\nTo collect the sequence of executed instructions, our system runs the sample in single-\n\nstep debugging mode. More precisely, we single step through the code within the malware\n\nexecutable (and all code dynamically generated by the malware). However, calls that are made\n\nto standard operating system libraries are not logged, nor are the instructions executed inside\n\nthese libraries. Fortunately, the system dynamically-loaded libraries (DLLs) are loaded into\n\nthe memory region ranging from 0x70000000 to 0x78000000 (in Microsoft Windows XP). This\n\nspeeds up the monitoring process and makes the resulting traces smaller. Also, it focuses the\n\ndata collection on the actual malicious code.\n\nTo increase the efficiency of the collection process and to minimize the size of the traces,\n\nwe only log a selected subset of instructions related to logic and arithmetic operations, namely:\n\nadd, adc, sub, sbb, mul, imul, div, idiv, neg, xadd, aaa, cmpxchg, aad, aam, aas, daa, das,\n\nnot, xor, and, or. We focus on these instructions because we are mostly interested in character-\n\nizing computations that the malware performs. Such computations will almost always involve\n\narithmetic and logic instructions. Other instructions, such as data move or stack manipulation\n\nroutines, are mostly used to prepare the environment for a computation, and hence, are less\n\ncharacteristic than the values that emerge directly as the result of a computation.\n\nNote that the arithmetic instructions inc and dec are missing from the set of instructions\n\nthat we are interested in. The reason is that we found these instructions to be typically involved\n\nin simple counters (for example, for loops), or in cases where a variable is first set to zero and\n\nthen increased. Such counters reveal little information about the data that is being computed.\n\nSince these instructions appear very frequently, we decided to remove them from the traces. We\n\nalso decided to remove instructions from the trace when they write the value 0, as this constant\n\n\n\n7.5. Comparing Traces 91\n\nis not very characteristic of a particular computation.\n\nWe apply one last transformation to convert a sequence of instructions into the final data\n\nvalue trace. This transformation works by moving a sliding window of length two over the\n\ninstruction sequence. For the two instructions in the window, we extract the two data values\n\nthat these instructions write (one value for each instruction) and we aggregate then into a pair\n\nof values \u2013 a bigram. This bigram becomes one element of the data value trace. After the\n\nbigram is appended to the data value trace, we advance the sliding window by one instruction.\n\nFigure 7.1 shows an example of how a sequence of instructions is transformed into a data value\n\ntrace (First, the instructions INC, DEC and those that write a \u20180\u2019 are removed. Then, the\n\nbigrams are generated from the remaining values).\n\n!\n!\n!\n!\n!\n!\n!\n!\n\n!\n!\n!\n!\n\nRAW!\nINSTRUCTIONS!\n\nFILTERED!\nINSTRUCTIONS!\n\nPRODUCED!\nBIGRAM!\n\nxor$eax,eax$(>$0x0$\nneg!ecx!9>!0x20!\n\nadd!eax,[0x45c120]!9>!0x9!\ninc$[ebp(0x118]$(>$0x6$\nadd!ecx,[0x45c104]!9>!0x6!\n\nsub!ecx,0x2!9>!0x4!\nmul!ecx!9>!0x4!\n\nneg!ecx!9>!0x20!\nadd!eax,[0x45c120]!9>!0x9!\nadd!ecx,[0x45c104]!9>!0x6!\n\nsub!ecx,0x2!9>!0x4!\nmul!ecx!9>!0x4!\n\n0x20,!0x9!\n0x9,!0x6!\n0x6,!0x4!\n0x4,!0x4!\n\nFigure 7.1: Steps to produce a data value trace from a sequence of instructions.\n\nThe reason for transforming the sequence of instructions (or written) values into bigrams\n\nis the following: If we would compare simple traces of individual values, it is more likely that\n\ntwo values in two traces match by accident. By combining subsequent values into pairs, we\n\nadd a simple form of context to individual data values. We found that this extra context\n\nsignificantly lowers the fraction of coincidental matches and improves the separation between\n\ndifferent program executions.\n\n7.5 Comparing Traces\n\nAs discussed in the previous section, we capture the activity of a malware program by\n\ncollecting a trace that consists of a sequence of bigrams of data values that this program has\n\nwritten. For a number of applications (such as malware classification and clustering), we require\n\na technique to determine whether the activities of two malware samples are similar. To perform\n\nthis comparison, we have developed a two-step algorithm. This algorithm operates on two data\n\nvalue traces as input and outputs a similarity measure S. S is a value between 0 and 1, where 0\n\nmeans completely different and 1 means identical. The two steps of the algorithm are explained\n\nin the next sections.\n\n\n\n92 Chapter 7. Malware Classification\n\n7.5.1 Step 1: Quick Comparison\n\nThe goal of the first step is to decide whether two traces are similar enough to warrant a\n\nfurther, more detailed comparison. This step works by creating a small \u201cidentifier\u201d for each\n\ntrace. This identifier is based on the k least-frequent bigrams that appear in a trace. The\n\nunderlying assumption behind this choice is that if two samples are variants of each other, they\n\nshould share some specific features or attributes that are particular to their family. Thus, we\n\ncan discard the most common bigrams, which can appear within many different families, and\n\nfocus on the specifics of a certain family\u2019s fingerprint. We have experimentally determined that\n\na value of k = 100 yields good results.\n\nMore formally, we state our approach as follows. Let IDM1 and IDM2 be the k least-frequent\n\nbigrams from traces produced by malware samples M1 and M2. We compare these two malware\n\nidentifiers by applying the Jaccard index [165] as follows:\n\nJ(IDM1,IDM2 ) =\nIDM1?IDM2\nIDM1?IDM2\n\n, 0 ? J ? 1\n\nIf, and only if, the Jaccard index (ranging from 0 to 1) is greater than the empirically estab-\n\nlished threshold of 0.31, we move to the second step. Otherwise, the result of this computation\n\nis used as the similarity value (which indicates low similarity).\n\n7.5.2 Step 2: Full Similarity Computation\n\nIn the next step, we compute the overlap of the entire two traces. More specifically, we\n\ncompute the longest common subsequence (LCS) between them. Suppose that T1 and T2 are\n\ndifferent data value traces and that L1 and L2 are their lengths, respectively. The similarity\n\nbetween the two traces is then calculated as follows:\n\nC(M1,M2) =\nLCS(T1,T2)\nmin(L1,L2)\n\nWe chose the longest common subsequence over the longest common substring to tolerate\n\nsmall differences in the computations. Moreover, we note that using a standard LCS algorithm\n\ncan be computationally expensive. We addressed this by calculating the LCS based on the GNU\n\ndiff tool [164] output. Our experiments, evaluating a standard LCS implemented in C++ and\n\nour approximate LCS computation showed that we could accomplish faster results using our\n\napproach \u2014 in some cases ?500\u00d7 faster \u2014 with no significant loss of accuracy.\nThe original diff tool has the nice property that it inserts \u201cbarriers\u201d while computing the\n\nlongest common subsequences present in a textual input. Our diff-based LCS approach, re-\n\nferred from now on as eDiff, enhances this capability by (i) marking the regions that differ\n\nbetween two traces and (ii) by mapping the shared subsequences to the original instructions in\n\nthe respective execution traces. As a result, we know exactly what malware code produced sim-\n\nilar memory writes. This will be useful for identifying code reuse, as explained in Section 7.7.2.\n\nTo map value traces back to instructions, we simply link the bigram values in the value traces\n\nto the raw instructions that produced those values.\n\n1To choose this threshold (T ), we performed tests with an increment of 0.1 for the range 0.0 &lt;T ? 0.5\n\n\n\n7.6. Applications 93\n\n7.6 Applications\n\nIn this section, we discuss two applications that we built on top of our malware trace similar-\n\nity technique. The first application is clustering; the idea is to group samples that show similar\n\nactivity based on their value traces. The second application uses the data value traces to find\n\ncases of code reuse. That is, we want to find cases in which malware samples that belong to\n\ndifferent families share one or more snippets of identical code.\n\n7.6.1 Clustering\n\nThe input to the malware clustering application are a set of N data value traces, one trace\n\nfor each of the N samples to be clustered. The goal is to find groups of malware samples that\n\nare similar. Clustering is implemented in two steps: pre-clustering and inter-cluster merging.\n\nPre-clustering: The goal of the pre-clustering step is to quickly generate an initial clustering\n\nand avoid having to perform N2/2 comparisons. To accomplish this, we sequentially process\n\neach of the N samples, one after another (in random order), as follows: First of all, two samples\n\nare compared using the quick-comparison technique and, if their similarity is within the defined\n\nthreshold, they are compared again, this time using the full comparison technique (eDiff). If\n\nthey present over 70% of similarity, there is a decision step to elect a cluster leader and they\n\nare grouped together (Figure 7.2).\n\nFigure 7.2: Quick comparison technique in action: forming a new cluster.\n\n\n\n94 Chapter 7. Malware Classification\n\nThe comparison proceeds. Each new sample is compared to all cluster leaders (explained\n\nbelow), using the similarity computation described earlier (quick + full comparison techniques).\n\nWhen the trace for the new sample exhibits more than 70% similarity with one or more cluster\n\nleaders, this sample is merged with the existing cluster for which the similarity is highest.\n\nWhen merging a trace with an existing cluster, we need to elect a new cluster leader (a\n\ncluster leader is basically the trace that is selected to represent the entire cluster). For this,\n\nwe must make a selection between the existing cluster leader and the new trace. We select\n\nthe longer trace as the new leader (Figure 7.3). We do this to increase the probability that a\n\nsample, whose behavior is similar to the activity of malware in a cluster, is properly matches\n\nwith that cluster. In other words, by selecting the longest trace as the cluster leader, a new\n\ntrace has more chances to find a long, common subsequence. By removing from the comparison\n\ncomputation all except one trace for each cluster, we greatly reduce the number of comparisons\n\nthat need to be performed.\n\nFigure 7.3: Election of a new leader based on trace length.\n\nOtherwise, either the sample (and its trace) forms a cluster with a another sample that is\n\nstill not member of another cluster, or it is inserted into a new cluster of its own, thus becoming\n\nthe cluster leader. Figure 7.3 shows the following case: since none of the leaders are well suited,\n\nthen the sample forms a cluster with another element that is not member of any previous cluster.\n\nInter-cluster merging: The pre-clustering step results in a set of initial clusters whose traces\n\nshare at least 70% similarity. However, due to the nature of the quick comparison (first step\n\n\n\n7.6. Applications 95\n\nFigure 7.4: Sample clustered with a previously unclustered sample.\n\nof the similarly comparison), there can be clusters that should be merged but are not. That\n\nis, it is possible that two traces are actually quite similar, yet their least-frequent bigrams are\n\ntoo different to pass the threshold. In this case, there are different clusters containing malware\n\nfrom the same family, and it is desirable to merge these clusters. The merging step is applied\n\nto the output of the pre-clustering step so as to generate a reduced amount of clusters. To this\n\nend, we perform a pairwise comparison between all cluster leaders, using our eDiff algorithm.\n\nIf their similarity is greater than the same 70% threshold defined previously, the clusters are\n\nmerged. This is illustrated in Figure 7.5.\n\nAs a byproduct of the merging step, the distances between all clusters are calculated. This\n\nyields a distance matrix, which can be analyzed to obtain insights into the phylogeny of the\n\nmalware samples. For example, we could build a malware family tree (dendogram) by applying\n\nhierarchical clustering.\n\n7.6.2 Code Reuse Identification\n\nAs mentioned previously, when comparing two traces, our algorithm not only computes a\n\ngeneral similarity (overlap) score but also determines which parts of the traces are identical.\n\nWhen we find a stretch of values that are identical between two traces generated by executing\n\ndifferent samples, we might naturally ask the question whether these values were produced by\n\n\n\n96 Chapter 7. Malware Classification\n\nFigure 7.5: Inter-cluster merging being applied to an initial set of clusters.\n\nsimilar code. This would allow us to identify code that is shared between samples that are\n\notherwise different.\n\nTo identify code reuse, when eDiff compares two data value traces, it stores for each ele-\n\nment (bigram) in the traces whether this element is unique to the trace or shared between both\n\ntraces. For instance, let us assume that we have two traces. One contains the three bigrams:\n\n(0x1,0x2), (0x2,0x4), and (0x4,0x5); the other contains the four bigrams: (0x1,0x2),\n\n(0x2,0x7), (0x7,0x4), and (0x4,0x5). In this case, eDiff would find that the first and last\n\nelement in each trace are shared, while the middle one(s) are unique (to each trace). To find\n\ncode reuse, we check both traces for the presence of at least four consecutive elements that are\n\nshared. The threshold of four was empirically determined and allows us to find shared code\n\nroughly at the function level. A higher threshold would be possible when we want to find longer\n\nparts of shared code. A lower threshold often yields accidental matches that do not reflect true\n\ncode reuse.\n\nNext, we require a mechanism to \u201cmap back\u201d values in a data value trace to the instruc-\n\ntions that produced them. This can be done easily because we retain the original instruction\n\nsequences that were recorded during dynamic analysis. However, these instructions are only\n\npart of the entire malware code, because we drop all non-arithmetic, non-logic instructions and\n\nall instructions that write a zero. Instead, we would like to find these instructions, as well as\n\nthe surrounding ones, in the code of the malware. This mapping-back process can be better\n\n\n\n7.7. Evaluation 97\n\nillustrated by the example of Figure 7.6, which shows that the code reuse identification process\n\nmaps matching values to the original instructions so as to allow the search of actual code sharing\n\n(related to the instructions that produced the same written value and the surrounding ones). To\n\ndo it, we leverage the dump of the program\u2019s executable sections that we obtained as described\n\nin Section 7.4.\n\nFigure 7.6: Code reuse identification process.\n\nTo find the code in the malware program that contains the \u201cshared instructions\u201d (i.e. those\n\nfour, consecutive instructions that wrote values shared between traces), we proceed as follows:\n\nThe shared instructions are transformed into a regular expression pattern. This pattern contains\n\nthe instructions in order, but applies the following modifications. First, we remove repeated,\n\nduplicate instructions (or blocks of instructions). This is because a certain instruction might\n\nhave been executed inside a loop. Hence, it would appear multiple times in the dynamic trace,\n\nalthough it is only present once in the static code region. Second, we insert a wildcard after each\n\ninstruction. This wildcard allows for a certain number of non-arithmetic, non-logic instructions\n\nthat might have been present in the code but have been dropped from the dynamic trace.\n\nThe resulting pattern is then matched against the dumped code segment. When a match\n\nis found, we consider the resulting code block as a candidate for reuse. All matches that are\n\nfound for each trace are compared, and when we find a sequence of identical code of a minimum\n\nlength, we identify the code snippet as reused between malware samples.\n\n7.7 Evaluation\n\nIn this section, we first describe the experiments we performed to evaluate the quality of\n\nour clustering results. Then, we discuss the code reuse we found among samples. To perform\n\n\n\n98 Chapter 7. Malware Classification\n\nthe experiments, we analyzed Windows PE32 executable programs with our system. For each\n\nexecutable, we collected a data value trace as described previously.\n\nIn total, we submitted 18,285 malware samples for analysis. Each sample was executed\n\nfor ten minutes. We obtained a non-empty trace for 16,248 of these samples; the remaining\n\nones produced an empty log. There can be many different reasons for an empty log - a malware\n\nsample might be broken, its runtime dependencies (libraries) might not all be present, or it might\n\nuse aggressive anti-debugging techniques. However, overall, we obtained results for a significant\n\nmajority of the malware samples. The samples were provided to us by the maintainers of a\n\ndynamic malware analysis system. They represent a diverse and recent set of different malware\n\nfamilies that are currently active in the wild.2\n\n7.7.1 Malware Clustering\n\nThe evaluation of the quality of a clustering algorithm is a complicated task [77], as clustering\n\nresults are often not objectively right or wrong but depend on a number of factors, such as\n\nthe metrics used to calculate the distances among samples and clusters, the final amount of\n\nclusters generated, the chosen heuristics, etc. A straightforward way to evaluate the results of\n\na clustering run is to use a reference clustering. More precisely, we want to measure the degree\n\nof agreement between the clusters obtained by our system and the clusters of a reference set.\n\nWe used three different ways to obtain a reference clustering: one based on the static analysis\n\nof malware, one based on the dynamic analysis of malware, and the last one based on anti-virus\n\n(AV) labels. To generate these reference clustering sets, we proceeded as follows.\n\n\u2022 For the static reference clustering, we used the output of a system provided to us by the\nauthors of Jacob et al. [76]. This system looks for similarities in the bytes (instructions)\n\nof malware binaries that \u201cshine through\u201d packing.\n\n\u2022 For the dynamic (behavioral) reference, the results were provided by clustering the results\n(reports) produced by the malware dynamic analysis tool that was the source of the\n\nsamples. We used an approach similar to the one described in [15].\n\n\u2022 For the AV label clustering quality measure, we scanned all the samples with three dif-\nferent antivirus engines ([9], [10], [58]). Then, we relabeled the results using only the\n\ngeneral identifier for each label, skipping the versions (e.g., Trojan.Zbot-4955 became\n\n\u201czbot,\u201d Worm.Allaple-316 became \u201callaple,\u201d and so on). We assigned those compact labels\n\nto the samples already distributed in clusters that our approach produced and, finally,\n\nwe calculated the level of agreement based on this attribution. Moreover, we calculated\n\nstatistics about how many samples each one of the anti-virus programs was not able to\n\ndetect, the cases in which all three AV engines agreed in their labeling, and whether they\n\ncompletely disagreed or not.\n\nAfter we generated the reference clustering sets, we borrowed the precision and recall metrics\n\nfrom [15] to measure the quality of our clustering results. In that work, the authors state that\n\n2For a complete list of MD5 sums of the samples, please contact the authors.\n\n\n\n7.7. Evaluation 99\n\nthe precision aims to measure how well a clustering algorithm can distinguish among different\n\nsamples, i.e. if each of our generated clusters contains only samples from the same family. Thus,\n\nif we have a reference clustering result T = T1,T2, ...,Tt, where t is the number of clusters, and\n\nour clustering approach results in C = C1,C2, ...,Cc, where c is the number of the generated\n\nclusters, for a dataset A = a1,a2, ...,an with n samples, the precision Pj of a cluster can be\n\ncalculated as follows, for each Cj ? C:\n\nPj = max(|Cj ?T1|, |Cj ?T2|, ..., |Cj ?Tt|)\n\nThen, the overall precision P is calculated as:\n\nP =\n(P1+P2+...+Pc)\n\nn\n\nThe recall metric serves as a basis to measure how well a clustering algorithm can recognizes\n\nsimilar samples, i.e. if samples of the same family are grouped together. Here, the goal is to have\n\nall samples from one family assigned to the same cluster by our algorithm. Hence, assuming a\n\nreference clustering T = T1,T2, ...,Tt \u2014 with t clusters \u2014 and a clustering C = C1,C2, ...,Cc\n\u2014 with c clusters \u2014 under evaluation, for each Tj ? T , we proceed in the following way to\ncalculate the recall Rj value:\n\nRj = max(|C1 ?Tj|, |C2 ?Tj|, ..., |C3 ?Tj|)\n\nThe overall recall R is calculated as:\n\nR =\n(R1+R2+...+Rt)\n\nn\n\nThe product of the values obtained from the overall precision and recall can be used to\n\nmeasure the overall clustering quality (Q = P \u00d7R).\nFor the their reference clustering based on AV labels, we measured the quality of our clus-\n\ntering scheme by defining the level of agreement related to the labels assigned to each sample in\n\na cluster. Perdisci et al. [115] proposed to use two indexes (cohesion and separation) to validate\n\ntheir HTTP-based malware behavioral clustering. Those indexes use AV label graphs (undi-\n\nrected, weighted graphs) to verify that AV engines assign labels consistently within a cluster,\n\nand to check whether the families are well grouped. However, their approach \u201cattenuates the\n\neffect of AV label inconsistency\u201d due to the way the Cohesion Index is defined (there is a \u201cgap\u201d\n\nand a \u201cdistance\u201d value that causes a boost in cohesion). To avoid this boost, we define a simpler\n\nlevel of agreement A for a cluster j that is calculated as:\n\nAj =\n?\n\nmax(labelN )\nTj(total samples in j)\n\nwhere labelN is the set of the assigned labels and their related frequencies for each AV engine\n\nfor each cluster (N = avg,avira,fprot).\n\nThis level-of-agreement value A corresponds to the average of the most assigned label per AV\n\nengine in a certain cluster. For instance, one of our clusters contains three samples (identified\n\nby the binary\u2019s MD5) and the comma separated values assigned by the three AV engines, as\n\nshown below.\n\n\n\n100 Chapter 7. Malware Classification\n\nMALWARE MD5 AVG,AVIRA,F-PROT\n\n072cb45db4b7e34142183bc70bf8b489 agent_r,agent,busky\n\n050a0b8b78cad111352b372417e467fe agent_r,agent,busky\n\n063d85386df0edb28b3f0182b83a4fe3 agent_r,runner,busky\n\nIn this example, we have labelavg = 3, labelavira = 2 (the \u201cagent\u201d label), and labelfprot = 3.\n\nAs a result, we a have a sum of 8 from the labels over 9 samples, resulting in a level of agreement\n\nA = 0.89 for this cluster. This is a simple, unbiased way to calculate the quality of our clusters\n\nand produced very good results during the full dataset evaluation, which is presented below.\n\nPreliminary tests. Before we applied our clustering technique to the entire dataset, we ran\n\npreliminary experiments using a smaller subset, which consisted of 1,000 random samples. Those\n\ninitial tests were important to experiment with and determine different threshold parameters.\n\nIn particular, we varied the similarity threshold for the second step of the algorithm from 0 to\n\n100% (incrementing by 10% after each iteration).\n\nThe precision and recall values for the different thresholds can be seen in Figure 7.7 and\n\nin Figure 7.8 where we compare our results to the static and behavioral reference clustering,\n\nrespectively.\n\n 0\n\n 0.2\n\n 0.4\n\n 0.6\n\n 0.8\n\n 1\n\n 0  20  40  60  80  100\n\nP\nre\n\nci\nsi\n\non\n a\n\nnd\n R\n\nec\nal\n\nl v\nal\n\nue\ns\n\nSimilarity threshold (%)\n\nPrecision Static\nRecall Static\n\nFigure 7.7: Precision and recall of a reduced dataset of 1,000 samples (static clustering).\n\nThe static reference clustering for these 1,000 samples consists of 546 clusters and the behav-\n\nioral reference clustering consists of 335 clusters. The quality values calculated for each iteration\n\n(different threshold value), as well as the amount of clusters produced by our approach, can be\n\nseen in Table 7.1 (QS and QB are respectively the quality of our clustering related to the static\n\nand behavioral reference clustering). The highest quality, i.e. the average between the obtained\n\nstatic and behavioral quality values was observed for a similarity threshold of 70%. Moreover,\n\nthe AV labels\u2019 level-of-agreement value for this threshold is also very high (0.894).\n\nFull dataset. In the next step, we ran our system on the entire data set. Based on the results\n\nof the preliminary evaluation, we defined a similarity threshold of 70% for the eDiff process. We\n\ncontinued to use the initially-established Jaccard index threshold of 0.3 for the quick comparison.\n\nThe amount of clusters produced by the two reference clustering sets for the 16,248 samples\n\nwith traces were 7,900 clusters for the static approach and 3,410 for the behavioral one. Our\n\n\n\n7.7. Evaluation 101\n\n 0\n\n 0.2\n\n 0.4\n\n 0.6\n\n 0.8\n\n 1\n\n 0  20  40  60  80  100\nP\n\nre\nci\n\nsi\non\n\n a\nnd\n\n R\nec\n\nal\nl v\n\nal\nue\n\ns\n\nSimilarity threshold (%)\n\nPrecision Behavioral\nRecall Behavioral\n\nFigure 7.8: Precision and recall of a reduced dataset of 1,000 samples (dynamic clustering).\n\nTable 7.1: Quality (Q) and amount (#) of our produced clustering (1,000 samples).\nT 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%\n# 551 583 586 586 588 591 602 612 639 734 1000\nQS 0.579 0.701 0.700 0.700 0.700 0.701 0.708 0.710 0.717 0.673 0.548\nQB 0.485 0.554 0.552 0.552 0.554 0.555 0.554 0.554 0.537 0.476 0.336\n\napproach produced 7,793 clusters that were compared to the reference clustering sets, generating\n\nthe precision values of 0.758 and 0.846 and the recall values of 0.81 and 0.572 for the static\n\nand behavioral reference, respectively. Calculating the AV labels\u2019 level-of-agreement for our\n\nclustering yielded 0.871. These results are summarized in Table 7.2, along with the associated\n\nquality results.\n\nTable 7.2: Precision, Recall and Quality for the three reference clustering sets (T = 70%).\nRef. Clustering Precision Recall Quality\n\nStatic 0.758 0.810 0.614\nBehavioral 0.846 0.572 0.485\nAV labeling - - 0.871\n\nThe values from Table 7.2 yield average results of 0.802, 0.691, and 0.656 for precision, recall,\n\nand quality, respectively. It took 37 hours and 42 minutes to produce our clustering: 13 hours\n\nwere spent in the pre-clustering step and 24 hours and 42 minutes in the merging step. The\n\nmerging step is slower (it requires\nNC\u00d7(NC+1)\n\n2\ncomparisons, where NC is the amount of clusters)\n\nas it involves comparing all the leaders of the clusters with each other, using eDiff. However,\n\nthis is a crucial step, as it calculates the distances between all clusters and merges those whose\n\nsamples have been incorrectly discarded by the quick comparison step.\n\nInterestingly, for the entire malware set, the three AV engines completely agreed for only\n\n8% of 18,285 samples. Moreover, all three AV engines agreed that 13.93% of the samples\n\nwere \u201cclean,\u201d being unable to detect them as a malware (although all AV engines had the\n\nlatest signatures). Note that all our samples were obtained as part of exploits (e.g., from\n\n\n\n102 Chapter 7. Malware Classification\n\nhoneypots specifically tailored to act as malware collectors) and from collections containing\n\nverified malware, and hence, they are very likely malicious. More in detail, AVG, Avira, and\n\nF-Prot were individually unable to detect 19.01%, 15.50% and 20.28% of all malware samples.\n\nDiscussion. The use of different reference clustering sets is important to validate a new ap-\n\nproach. In particular, it allows for a richer understanding of the clustering schemes used as\n\nground truth, as well as of our new clustering.\n\nWhen we used the static clustering as ground truth, the precision obtained was 0.758, and\n\nthe recall was 0.810. The use of the behavioral clustering as reference yielded a precision value\n\nof 0.846 and a recall value of 0.572. Finally, the AV labels\u2019 level-of-agreement resulted in a\n\nvalue of 0.871, corroborating our clustering scheme by showing that similarly labeled samples\n\nare mostly grouped together by our approach.\n\nOverall, we find that the more specialized the reference clustering is, the better the recall\n\nfor our approach. On the other hand, the more generalized the reference cluster is, the better\n\nour precision. When looking at the static clustering, we find that it tends to split the samples\n\naccording to the structural information of the binary file, as well as to the packer they used.\n\nThis leads to cases in which the samples of one specific malware family are separated into more\n\nthan one cluster (because they are packed or encrypted with different tools). As a result, we\n\nobtain very specific clusters (which translates to good recall values).\n\nBehavioral clustering is more generic, as it groups samples based on the actions they perform\n\nin a dynamic analysis system. This leads to the generation of a smaller amount of clusters, as\n\nthe general behavior of a malware family after unpacking tends to be similar. Thus, the relaxed\n\nboundaries of behavioral clustering result in better precision for our approach (it is less likely\n\nthat we miss that two samples are different). However, the behavioral clustering results in a\n\nworse recall, as it is more likely that our approach is more precise and (correctly) splits a cluster\n\nof different families that exhibited similar behavior. Indeed, the AV labels\u2019 level-of-agreement\n\nvalue is consistent with the precision values found for the other reference clustering sets, showing\n\nthat our clusters are well formed and contain mostly samples from the same family.\n\nTo summarize, we find that our approach achieves a good clustering of malware samples.\n\nThe results fit in between those produced by the static and the behavioral clustering approaches,\n\nand we were able to expose and account for certain errors present when performing clustering\n\nusing static measures or dynamic runtime activity.\n\n7.7.2 Code Reuse\n\nTo look for code reuse in samples that likely belong to different malware families, we only\n\ncheck pairs of malware clusters that are sufficiently different. More precisely, based on the\n\nclustering results obtained in the previous step, we look for pairs of clusters that have a similarity\n\nscore between 10% and 30%. We identified 974 pairs of clusters that fulfill this requirement.\n\nFor each of these pairs (i.e. for the corresponding cluster leaders), we ran our code reuse\n\nidentification technique (as explained in Section 7.6.2). That is, we first checked for four con-\n\nsecutive, shared values among each pair of traces. When such a stretch of values was found, we\n\nproduced the corresponding code pattern and matched it against the dumped malware code. For\n\neach pattern match, we subsequently checked whether the identified code regions were identical.\n\n\n\n7.7. Evaluation 103\n\nWe discovered 15 pairs (involving ten different clusters) that share code between them. More\n\nprecisely, we found seven different blocks of code that seem to be reused among samples. These\n\ncode blocks can be seen in the Table 7.3. We sent the ten representatives (one for each cluster)\n\nto VirusTotal [67]. Looking at the results, we noticed that the most common label assigned\n\nto all of them refers to different Trojan malware that all seem to attack online games (and,\n\napparently, shared code to do so).\n\nTable 7.3: Blocks of code shared among samples.\nInstructions\n\nadd ebx,ebx ; jnz 0x4070f9 ; pop es ; mov ebx,[esi] ; push ds ; sub esi,0xfffffffc\n\nadd ebx,ebx ; jnz 0x40710b ; pop es ; mov ebx,[esi] ; push ds ; sub esi,0xfffffffc\n\nadd ebx,ebx ; jnc 0x407100 ; out dx,eax ; jnz 0x40711c ; or [ebx-0x3117ce2],ecx ; mov ebx,[esi] ; push ds ; sub esi,0xfffffffc\n\nadd ebx,ebx ; jnz 0x40713b ; pop es ; mov ebx,[esi] ; push ds ; sub esi,0xfffffffc\n\nadd ebx,ebx ; jnz 0x407148 ; pop es ; mov ebx,[esi] ; push ds ; sub esi,0xfffffffc\n\nadd ebx,ebx ; jnz 0x407158 ; pop es ; mov ebx,[esi] ; push ds ; sub esi,0xfffffffc\n\nadd ebx,ebx ; jnc 0x40714d ; out dx,eax ; jnz 0x407169 ; or [ebx-0x3117ce2],ecx ; mov ebx,[esi] ; push ds ; sub esi,0xfffffffc\n\nIn an additional experiment, we applied the eDiff algorithm directly to the instructions\n\nextracted from the static, dumped code regions (for all 974 pairs of clusters). This resulted in\n\n889 pairs with less than 30% of similarity, and only three pairs with a similarity score above\n\n70%. The different similarity values for the memory-mapped code regions for all 974 pairs can\n\nbe seen in Table 7.4. As expected, the code similarity is low, which is well captured by the fact\n\nthat the data value traces are also dissimilar. That is, different malware samples produce, in\n\nalmost all cases, very different data value traces (recall that the 974 pairs reflect clusters that\n\nhave produced different value traces).\n\nTable 7.4: Similarity scores (S) for static malware code.\nS (%) 0-10 10-20 20-30 30-40 40-50 50-60 60-70 70-80 80-90 90-100\nPairs 787 79 23 52 15 6 9 1 2 0\n\nThe three aforementioned exceptions, where the static code regions (instructions) are more\n\nthan 70% similar, involve six unique clusters. This cases are interesting because they represent\n\n(somewhat) similar code that has resulted in different value traces. In Table 7.5, we show those\n\npairs, their respective AV labels, and the portion of code they share (as produced by eDiff).\n\nTable 7.5: Shared code rate (%) of malware samples\u2019 pairs and respective AV labels.\nPair AV labels (summarized): AVG | Avira | F-Prot Share %\n\nMW 1 Downloader.Generic7 | Dldr.Delphi.Gen | Downldr2 76.22\nMW 2 Downloader.Generic7 | Dldr.Delphi.Gen | Downldr2\nMW 3 Downloader.Agent | DR/Zlob.Gen | NSIS.gen 84.66\nMW 4 Generic12 | DR/Zlob.Gen | Zlob.X.gen\nMW 5 Downloader.Zlob | DR/Zlob.Gen | DldrX 86.70\nMW 6 FakeAlert | DR/Zlob.Gen | SuspPack.AJ.gen\n\n\n\n104 Chapter 7. Malware Classification\n\nAs we can observe in Table 7.5, the AV labels assigned to the first pair\u2019s samples are generic,\n\ni.e. they do not refer to any family and they were probably assigned by heuristics that verified\n\na \u201cdownloader-like\u201d behavior. Although this pair shares 76.22% of its samples\u2019 static code and\n\ntheir AV labels are consistent, the runtime behaviors were very different. This could be due\n\nto the fact that certain remote resources were not available, and as a result, the downloaders\n\nmight have exhibited different behavior. Another possibility is that the downloader simply\n\nfetches, installs, and runs different malware components (that result in different activity). For\n\nthe other two pairs, we found code similarities of 84.66% and 86.70%, respectively. We can\n\nobserve significant disagreement among the labels, some distinct enough such as SuspPack and\n\nFakeAlert, others linking the pairs to the Zlob Trojan family [166]. Again, most of the labels\n\nagreed that the samples act as downloaders. The common theme among all three cases is that\n\nthe samples likely share some common downloading code. This results in the samples to be\n\ngrouped together based on their static code. However, for the various reasons discussed above,\n\nthe programs exhibited different activity at the trace level.\n\n7.8 Concluding Remarks\n\nMalware classification is an important process to improve systems security, as it allows for the\n\nidentification of malicious programs based on attributes that can be used to generate signatures\n\nfor detection or incident response.\n\nIn this chapter, we empirically demonstrated that the values stored in memory and registers\n\nafter write operations can be used to detect and cluster malware in families. We also presented\n\na different approach to perform the similarity score calculation that is simple and effective\n\nwhen applied to the malware problem. We compared the results from more than 16 thousand\n\nmalware samples executed and processed in our prototype system to three reference clustering\n\nsets\u2014static, behavioral (dynamic), and AV labeling\u2014and ours reached an average precision\n\nvalue of 0.802 for the first two sets and a level of agreement value of 0.871 for the last one.\n\nFinally, we showed that our classification process can also be used to verify for code reuse,\n\nwhich helps to investigate the sharing of functions in different families of malware. This result\n\nis very promising, because it is a first step towards a mechanism to search for common functions\n\nor procedures with specific functionality that are reused in malicious code that is seen in the\n\nwild. This, in turn, can then be used by law enforcement during attribution analysis.\n\n\n\nChapter 8\nConclusion\n\nThis thesis discusses several aspects related to the behavior of malicious programs, from the\n\ndefinition of potentially dangerous activities that malware may perform during an infection, to\n\nthe proposition of a behavior-based taxonomy, to the detection, clustering and visualization of\n\nmalware. The aim of the research work presented in this thesis is mainly to provide a better\n\nunderstanding of how the diversity of current malware samples actually behave, as well as to\n\naid in the development of practical and effective incident response procedures. In this thesis, we\n\nintroduced a general, flexible and extensible taxonomy, yet of simple use and easy to understand,\n\nwhich provides an overall view of malware infection. We showed that this taxonomy may be\n\nused in a plenty of applications, which are distributed among this thesis\u2019 chapters. Below, we\n\npresent a review of the topics discussed in this thesis.\n\nIn Chapter 2, we provide a background about malicious software and malware taxonomies.\n\nWe briefly presented a history of the evolution of malware, since they were only concepts to their\n\nchanging into weapons of an already established cyber war. We focused on the multiple behaviors\n\nthat a malware sample can exhibit in order to accomplish its infection, unlike the malware\u2019s\n\nwell-behaved nature present in the current classification scheme. This led us to discuss the\n\nnaming scheme adopted by antivirus (AV) vendors, which does not handle modern malware\n\nvery well, confusing the users and security analysts. Then, we discussed some security-related\n\ntaxonomies and taxonomic properties, as well as we described several taxonomies regarding\n\nspecific types of malware.\n\nIn Chapter 3, we introduce our proposed taxonomy. Initially, we discussed the behavioral\n\naspects of malware and some recent work related to malware behavior. We also defined, in the\n\nscope of this thesis, what is the general behavior of a program (divided among the active, passive\n\nand neutral subsets) and what is the suspicious behavior, which can be involved in malware\n\nattacks. Furthermore, we gathered 24 suspicious behaviors that are potentially dangerous to\n\na computer system and classified them in network or operating system activity groups. Based\n\non those behaviors, we leveraged a behavior-centric taxonomy that considers four classes, the\n\nsuspicious behaviors associated to each of them, and the violated security principle.\n\nIn Chapter 4, we evaluate the proposed behavior-centric taxonomy using over 12 thousand\n\nrecent malware samples collected in the wild, either from phishing e-mail messages and dona-\n\ntions from collaborators, or from malware collectors and public databases. We introduced our\n\n105\n\n\n\n106 Chapter 8. Conclusion\n\ninfrastructure for dynamic malware analysis, which was used to run all the malware samples\n\nfrom our dataset in a controlled environment in order to extract their behavioral profiles. We\n\napplied our taxonomy to the samples dataset and evaluated the produced results. In addition,\n\nwe obtained some AV labels and classified the samples accordingly. Finally, we compared these\n\ntwo approaches with respect to information they are able to provide to their users, showing that\n\nour taxonomy is very useful to yield a better understanding about AV detected (and undetected)\n\nmalware.\n\nIn Chapter 5, we present BanDIT, a system to detect Internet banking malicious programs\n\n(bankers) that is built upon a specialization of our dynamic malware analysis system and our\n\nbehavior-centric taxonomy. We showed that our proposed taxonomy can be easily extended to\n\nadd more behaviors, as well as that it can be used in different scopes (other than classification).\n\nIn this case, we borrowed behaviors from the taxonomy to identify bankers, which are a major\n\nthreat for Internet banking users, and empirically showed that we are able to detect almost\n\nall bankers of a malware dataset using three techniques: visual identification, network pattern\n\nmatching and monitoring of filesystem changes.\n\nIn Chapter 6, we leverage two interactive visualization tools that take advantage of behav-\n\nioral profiles to aid in computer security incident response procedures. The goal is to apply\n\nvisualization techniques to the behavioral trace to produce an easy to use system whose intent\n\nis to allow an analyst to interact with the malware execution steps and identify patternsor\n\nsimilarities among malware families and unknown samples.\n\nIn Chapter 7, we introduce a novel way to classify malware that, otherwise based on the exe-\n\ncution behavior, considered the values written in memory or registers to generate the behavioral\n\nprofiles. We analyzed over 16 thousand malware samples and proposed a heuristic method to\n\napproximate the longest common subsequence (LCS) function to calculate the similarity among\n\nthem. We proposed a clustering technique that involved two steps, a quick comparison and a\n\nfull and more expensive comparison to group our malware samples. The results indicated that\n\nwe were able to cluster them with precision rates higher than 0.8 and that our results were\n\nconsistent with other clustering approaches (static, dynamic and AV labeling reference sets).\n\nFuture Work\n\nThe study of malware behavior is a wide research field that requires constant monitoring\n\nas new technologies rise. Malware behavior can also be obtained in a great variety of forms\n\n(e.g., reverse engineering, static analysis, debugging, disassembling, controlled running etc.).\n\nMoreover, there is still not a widely adopted standard to handle malware, creating several\n\nopportunities for future works.\n\nWe outline below some possible future works involving the themes discussed in this thesis.\n\nIt is worthwhile to note that each chapter has its own discussion about the limitations and the\n\nadditional work that can be done regarding its respective subject.\n\nBehavioral Extraction. There is a plethora of research works aiming to monitor intrusive\n\nactivities and to extract malware features from the execution of samples in controlled environ-\n\nments. However, novel hardware features and new versions of operating systems often change\n\n\n\n107\n\nthe status quo, either from the malware developer perspective, or from the security researcher.\n\nFurthermore, malware variants are able to subvert current monitoring systems, consequently\n\ncreating the need for updates in these systems so as to handle a broader range of malware\n\ntypes.\n\nClassification. As underlined in this thesis, our behavior-centric taxonomy can be extended\n\nto address new potentially dangerous behaviors. The discovering of new behaviors involves the\n\ncontinuous analysis of malware samples that appear in the wild, improving the classification\n\nprocess as a whole. In addition, ongoing future works include evolving the taxonomy until it can\n\nbecome a standard, as well as to test the effectiveness of using well-established machine learning\n\nalgorithms to perform malware classification in a more precise and automated (unsupervised)\n\nway.\n\nDetection. Finally, newly discovered behaviors, features and monitoring methods can help\n\nthe detection process. Detection is important since it may improve the security of systems\n\n(and its users), turning feasible the development of new tools and solutions to serve as coun-\n\ntermeasures for malware infections. Moreover, additional detection techniques can allow the\n\nimprovement of AV engines.\n\nPublications\n\nThe following list includes the published results that served as the basis for this text. Most\n\nof them are ranked by Brazilian Qualis Ranking 2012-2014, as shown next.\n\n1. An Empirical Analysis of Malicious Internet Banking Software Behavior. Andre?\n\nRicardo Abed Gre?gio, Vitor Monte Afonso, Victor Furuse Martins, Dario Simo?es Fernan-\n\ndes Filho, Paulo L??cio de Geus, Mario Jino. ACM Symposium on Applied Computing\n\n(SAC). Coimbra, Portugal, March, 2013. Qualis A1.\n\n2. Tracking Memory Writes for Malware Classification and Code Reuse Identifi-\n\ncation. Andre? Ricardo Abed Gre?gio, Paulo L??cio de Geus, Christopher Kruegel, Giovanni\n\nVigna. 9th Conference on Detection of Intrusions and Malware and Vulnerability Assess-\n\nment (DIMVA), Lecture Notes in Computer Science, Springer Verlag. Greece, July 2012.\n\nQualis B1.\n\n3. Pinpointing Malicious Activities through Network and System-Level Malware\n\nExecution Behavior. Andre? Ricardo Abed Gre?gio, Vitor Monte Afonso, Dario Simo?es\n\nFernandes Filho, Paulo L??cio de Geus, Mario Jino, Rafael Duarte Coelho dos Santos.\n\n12th International Conference on Computational Science and Its Applications (ICCSA),\n\nLecture Notes in Computer Science, Springer Verlag. Brazil, June 2012. Qualis B1.\n\n4. Interactive, Visual-Aided Tools to Analyze Malware Behavior. Andre? Ricardo\n\nAbed Gre?gio, Alexandre Or Cansian Baruque, Vitor Monte Afonso, Dario Simo?es Fer-\n\nnandes Filho, Paulo L??cio de Geus, Mario Jino, Rafael Duarte Coelho dos Santos. 12th\n\nInternational Conference on Computational Science and Its Applications (ICCSA), Lec-\n\nture Notes in Computer Science, Springer Verlag. Brazil, June 2012. Qualis B1.\n\n\n\n108 Chapter 8. Conclusion\n\n5. A Hybrid Framework to Analyze Web and OS Malware. Vitor Monte Afonso,\n\nDario Simo?es Fernandes Filho, Andre? Ricardo Abed Gre?gio, Paulo L??cio de Geus, Mario\n\nJino. IEEE International Conference on Communications (ICC), Proceedings of the IEEE\n\nICC\u201912. Canada, June 2012. Qualis A2.\n\n6. (In Portuguese) Ana?lise Visual de Comportamento de Co?digo Malicioso. Alexan-\n\ndre Or Cansian Baruqu, Andre? Ricardo Abed Gre?gio, Paulo L??cio de Geus. Workshop de\n\nTrabalhos de Iniciac?a?o Cient??fica e de Graduac?a?o (WTICG), Anais do XI SBSEG. Brazil,\n\n2011.\n\n7. (In Portuguese) Ana?lise Comportamental de Co?digo Malicioso atrave?s da Mon-\n\nitorac?a?o de Chamadas de Sistema e Tra?fego de Rede. Dario Simo?es Fernandes\n\nFilho, Andre? Ricardo Abed Gre?gio, Vitor Monte Afonso, Rafael Duarte Coelho dos San-\n\ntos, Mario Jino, Paulo L??cio de Geus. Simpo?sio Brasileiro em Seguranc?a da Informac?a?o e\n\nde Sistemas Computacionais (SBSEG), Anais do X SBSEG. Brazil, October 2010. Qualis\n\nB4.\n\nOther published papers that are not directly related to this thesis are:\n\n1. A Malware Detection System Inspired on the Human Immune System. Isabela\n\nLiane Oliveira, Andre? Ricardo Abed Gre?gio, Adriano Mauro Cansian. 12th International\n\nConference on Computational Science and Its Applications (ICCSA), Lecture Notes in\n\nComputer Science, Springer Verlag. Brazil, June 2012. Qualis B1.\n\n2. Analysis of web-related threats in ten years of logs from a scientific portal.\n\nRafael Duarte Coelho dos Santos, Andre? Ricardo Abed Gre?gio, Jordan Raddick, Vamsi\n\nVattki, Alex Szalay. Cyber Sensing 2012, Proceedings of SPIE. USA, May 2012.\n\n3. Behavioral analysis of malicious code through network traffic and system call\n\nmonitoring. Andre? Ricardo Abed Gre?gio, Dario Simo?es Fernandes Filho, Vitor Monte\n\nAfonso, Rafael Duarte Coelho dos Santos, Mario Jino, Paulo L??cio de Geus. Defense,\n\nSecurity and Sensing 2011, Proceedings of SPIE. USA, April 2011.\n\n4. Visualization techniques for malware behavior analysis. Andre? Ricardo Abed Gre?-\n\ngio, Rafael Duarte Coelho dos Santos. Defense, Security and Sensing 2011, Proceedingsof\n\nSPIE. USA, April 2011.\n\n5. A hybrid system for analysis and detection of web-based client-side malicious\n\ncode. Vitor Monte Afonso, Andre? Ricardo Abed Gre?gio, Dario Simo?es Fernandes Filho,\n\nPaulo L??cio de Geus. IADIS International Conference WWW/Internet (ICWI\u20192011), Pro-\n\nceedings of ICWI, 2011. Qualis B2.\n\n6. (In Portuguese) Sistema de coleta, ana?lise e detecc?a?o de co?digo malicioso baseado\n\nno sistema imunolo?gico humano. Isabela Liane Oliveira, Andre? Ricardo Abed Gre?gio,\n\nAdriano Mauro Cansian. Confere?ncia IADIS Ibero-Americana WWW/Internet (CIAWI),\n\nAnais da CIAWI, 2011.\n\n\n\n109\n\n7. (In Portuguese) xFile: Uma Ferramenta Modular para Identificac?a?o de Packers\n\nem Executa?veis do Microsoft Windows. Victor Furuse Martins, Andre? Ricardo\n\nAbed Gre?gio, Vitor Monte Afonso, Dario Simo?es Fernandes Filho, Paulo L??cio de Geus.\n\nWorkshop de Trabalhos de Iniciac?a?o Cient??fica e de Graduac?a?o (WTICG), Anais do X\n\nSBSEG. Brazil, October 2010.\n\n8. Malware distributed collection and pre-classification system using honeypot\n\ntechnology. Andre? Ricardo Abed Gre?gio, Isabela Liane Oliveira, Rafael Duarte Coelho\n\ndos Santos, Adriano Mauro Cansian, Paulo L??cio de Geus. Data Mining, Intrusion Detec-\n\ntion, Information Security and Assurance, and Data Networks Security. Proceedings of\n\nSPIE Defense, Security and Sensing, USA, 2009.\n\nFurthermore, during the review of related research works, we produced two book chapters\n\nthat were presented as short courses:\n\n1. (In Portuguese) Te?cnicas para Ana?lise Dina?mica de Malware. Dario Simo?es Fer-\n\nnandes Filho, Vitor Monte Afonso, Victor Furuse Martins, Andre? Ricardo Abed Gre?gio,\n\nPaulo L??cio de Geus, Mario Jino, Rafael Duarte Coelho dos Santos. Minicursos do SBSEG\n\n2011, pp.107\u2013147, SBC, Brazil, 2011.\n\n2. (In Portuguese) Ana?lise e Visualizac?a?o de Logs de Seguranc?a. Rafael Duarte Coelho\n\ndos Santos, Andre? Ricardo Abed Gre?gio. Livro de Minicursos do Computer on the Beach,\n\nUnivali, Brazil, 2010.\n\nSubmitted Articles\n\nFinally, we submitted two articles to journals specialized in computer security:\n\n1. A Behavior-Centric Malware Taxonomy. Andre? Ricardo Abed Gre?gio, Vitor Monte\n\nAfonso, Dario Simo?es Fernandes Filho, Paulo L??cio de Geus, Mario Jino. Computers &amp;\n\nSecurity, ISSN: 0167-4048, Elsevier. Submitted in October 2012. Qualis B1.\n\n2. Tracking Memory Writes for Malware Classification and Code Reuse Iden-\n\ntification (Extended Version). Andre? Ricardo Abed Gre?gio, Paulo L??cio de Geus,\n\nChristopher Kruegel, Giovanni Vigna. Journal of Computer Security, ISSN: 0926-227X,\n\nIOS Press. Submitted in June 2012.\n\n\n\n110 Chapter 8. Conclusion\n\n\n\nAppendix A\nExample of BehEMOT Report\n\n111\n\n\n\n112 Appendix A. Example of BehEMOT Report\n\n\n\n113\n\n\n\n114 Bibliography\n\n\n\nBibliography\n\n[1] Moheeb Abu Rajab, Jay Zarfoss, Fabian Monrose, and Andreas Terzis. A multifaceted\n\napproach to understanding the botnet phenomenon. In Proceedings of the 6th ACM SIG-\n\nCOMM conference on Internet measurement, IMC \u201906, pages 41\u201352, New York, NY, USA,\n\n2006. ACM.\n\n[2] abuse.ch. Spyeye tracker. https://spyeyetracker.abuse.ch, 2011. Accessed on June,\n\n2012.\n\n[3] abuse.ch. Zeus tracker. https://zeustracker.abuse.ch/, 2011. Accessed on June, 2012.\n\n[4] Leonard M. Adleman. An Abstract Theory of Computer Viruses. In Proceedings of the 8th\n\nAnnual International Cryptology Conference on Advances in Cryptology, pages 354\u2013374,\n\nLondon, UK, 1990. Springer-Verlag.\n\n[5] Vitor Monte Afonso, Dario Simo?es Fernandes Filho, Andre? Ricardo Abed Gre?gio, Paulo L??-\n\ncio de Geus, and Mario Jino. A hybrid framework to analyze web and os malware. In\n\nProceedings of the IEEE Internactional Conference of Communications (ICC), Ottawa,\n\nCanada, June 2012.\n\n[6] Edward Amoroso. Fundamentals of Computer Security Technology. Prentice-Hall PTR,\n\n1st edition, April 1994.\n\n[7] James P. Anderson. Computer Security Technology Planning Study. Technical Report\n\nESD-TR-73-51, Electronic Systems Division, USAF, L. G. Hanscom Field, Bedford, Mas-\n\nsachusetts, October 1972.\n\n[8] Taimur Aslam, Ivan Krsul, and Eugene Spafford. Use of A Taxonomy of Security Faults.\n\nIn Proceedings of the 19th National Information Systems Security Conference, pages 551\u2013\n\n560, 1996.\n\n[9] AVG. Avg antivirus. http://www.avg.com, 2012.\n\n[10] Avira. Avira antivirus. http://www.avira.com, 2012.\n\n[11] M. Bailey, E. Cooke, F. Jahanian, D. Watson, and J. Nazario. The Blaster Worm: Then\n\nand Now. Security Privacy, IEEE, 3(4):26\u201331, July/August 2005.\n\n115\n\n\n\n116 Bibliography\n\n[12] Michael Bailey, Jon Oberheide, Jon Andersen, Zhuoqing Morley Mao, Farnam Jahanian,\n\nand Jose Nazario. Automated Classification and Analysis of Internet Malware. In Pro-\n\nceedings of the 10th International Symposium on Recent Advances in Intrusion Detection\n\n(RAID \u201907), pages 178\u2013197, Gold Coast, Australia, September 2007.\n\n[13] Davide Balzarotti, Marco Cova, Christoph Karlberger, Christopher Kruegel, Engin Kirda,\n\nGiovanni Vigna, et al. Efficient Detection of Split Personalities in Malware. In Proceedings\n\nof the Network and Distributed System Security Symposium (NDSS), San Diego, CA,\n\nFebruary 2010.\n\n[14] H. Bay, T. Tuytelaars, and L. Van Gool. Surf: Speeded up robust features. Computer\n\nVision\u2013ECCV 2006, pages 404\u2013417, 2006.\n\n[15] Ulrich Bayer, Paolo Milani Comparetti, Clemens Hlauscheck, Christopher Kruegel, and\n\nEngin Kirda. Scalable, Behavior-Based Malware Clustering. In 16th Symposium on Net-\n\nwork and Distributed System Security (NDSS), 2009.\n\n[16] BBC. Stuxnet worm hits Iran nuclar plant staff computers. http://www.bbc.co.uk/\n\nnews/world-middle-east-11414483. Acessed on March 9, 2012, September 2010.\n\n[17] Philippe Beaucamps. Advanced Polymorphic Techniques. In Proceedings of World\n\nAcademy of Science, Engineering and Technology, volume 25, 2007.\n\n[18] Michael Becher, Felix C. Freiling, Johannes Hoffmann, Thorsten Holz, Sebastian Uellen-\n\nbeck, and Christopher Wolf. Mobile security catching up? revealing the nuts and bolts\n\nof the security of mobile devices. In Proceedings of the 2011 IEEE Security and Privacy\n\nSymposium, pages 96\u2013111, May 2011.\n\n[19] Boldizsa?r Bencsa?th, Ga?bor Pe?k, Levente Buttya?n, and Ma?rk Fe?legyha?zi. Duqu: A\n\nStuxnet-like malware found in the wild. Technical report, Laboratory of Cryptography\n\nand System Security (CrySyS), Department of Telecommunications, Budapest University\n\nof Technology and Economics, Hungaria, October 2011.\n\n[20] H. Binsalleeh, T. Ormerod, A. Boukhtouta, P. Sinha, A. Youssef, M. Debbabi, and\n\nL. Wang. On the Analysis of the Zeus Botnet Crimeware Toolkit. In Privacy Secu-\n\nrity and Trust (PST), 2010 Eighth Annual International Conference on, pages 31\u201338,\n\nAugust 2010.\n\n[21] Matt Bishop. Vulnerability Analysis: an Extended Abstract. In Recent Advances in\n\nIntrusion Detection, 1999.\n\n[22] Matt Bishop. Computer Security: Art and Science. Addison-Wesley, 1st edition, December\n\n2002.\n\n[23] Martin Boldt, Bengt Carlsson, and Andreas Jacobsson. Exploring Spyware Effects. In\n\nNordic Workshop on Secure IT Systems (NORDSEC), Helsinki, Finland, 2004.\n\n\n\nBibliography 117\n\n[24] Vesselin Bontchev. Possible Macro Virus Attacks and How to Prevent Them. Computers\n\n&amp; Security, 15:595\u2013626, 1996.\n\n[25] Vesselin Bontchev. Current Status of the CARO Malware Naming Scheme. In Virus\n\nBulletin (VB2005), Dublin, Ireland, 2005.\n\n[26] S. Buehlmann and C. Liebchen. Joebox: a secure sandbox application for windows to\n\nanalyse the behaviour of malware. http://www.joebox.org, 2012.\n\n[27] Armin Buescher, Felix Leder, and Thomas Siebert. Banksafe information stealer detec-\n\ntion inside the web browser. In Proceedings of the 14th international conference on Re-\n\ncent Advances in Intrusion Detection, RAID\u201911, pages 262\u2013280, Berlin, Heidelberg, 2011.\n\nSpringer-Verlag.\n\n[28] Pedro H. Calais, Douglas E. V. Pires, Dorgival Olavo Guedes, Wagner Meira, Cristine\n\nHoepers, and Klaus Steding-jessen. A campaign-based characterization of spamming\n\nstrategies. In Proceedings of the Fifth Conference on Email and Anti-Spam (CEAS),\n\n2008.\n\n[29] Kevin Zhijie Chen, Guofei Gu, Jose Nazario, Xinhui Han, and Jianwei Zhuge. WebPa-\n\ntrol: Automated collection and replay of web-based malware scenarios. In Proceedings\n\nof the 2011 ACM Symposium on Information, Computer, and Communication Security\n\n(ASIACCS\u201911), March 2011.\n\n[30] Thomas Chen and Jean-Marc Robert. The Evolution of Viruses and Worms. In William\n\nW. S. Chen, editor, Statistical Methods in Computer Security, pages 265\u2013282. CRC Press,\n\n2004.\n\n[31] Xu Chen, Jon Andersen, Z. Morley, Mao Michael, and Bailey Jose Nazario. Towards an\n\nunderstanding of anti-virtualization and anti-debugging behavior in modern malware. In\n\nProceedings of the International Conference on Dependable Systems and Networks, 2008.\n\n[32] Chia Yuan Cho, Juan Caballero, Chris Grier, Vern Paxson, and Dawn Song. Insights\n\nfrom the inside: a view of botnet management from infiltration. In Proceedings of the\n\n3rd USENIX conference on Large-scale exploits and emergent threats: botnets, spyware,\n\nworms, and more, LEET\u201910, pages 2\u20132, Berkeley, CA, USA, 2010. USENIX Association.\n\n[33] ClamAV. Clam antivirus. http://www.clamav.net, 2012.\n\n[34] Fred Cohen. Computer Viruses. PhD thesis, University of Southern California, 1986.\n\n[35] Fred Cohen. Computer Viruses: Theory and Experiments. Computers &amp; Security, 6:22\u2013\n\n35, February 1987.\n\n[36] Gregory Conti, Erik Dean, Matthew Sinda, and Benjamin Sangster. Visual reverse en-\n\ngineering of binary and data files. In Proceedings of the 5th international workshop on\n\nVisualization for Computer Security, VizSec \u201908, pages 1\u201317, Berlin, Heidelberg, 2008.\n\nSpringer-Verlag.\n\n\n\n118 Bibliography\n\n[37] Peter Coogan. Spyeye bot versus zeus bot. http://www.symantec.com/connect/blogs/\n\nspyeye-bot-versus-zeus-bot, February 2010. Accessed on May, 2012.\n\n[38] Evan Cooke, Farnam Jahanian, and Danny McPherson. The zombie roundup: understand-\n\ning, detecting, and disrupting botnets. In Proceedings of the Steps to Reducing Unwanted\n\nTraffic on the Internet on Steps to Reducing Unwanted Traffic on the Internet Workshop,\n\nSRUTI\u201905, pages 39\u201344, Berkeley, CA, USA, 2005. USENIX Association.\n\n[39] M. Cova, C. Kruegel, and G. Vigna. There is No Free Phish: An Analysis of \u201cFree\u201d and\n\nLive Phishing Kits. In Proceedings of the USENIX Workshop On Offensive Technologies\n\n(WOOT), San Jose, CA, August 2008.\n\n[40] M. Cova, C. Kruegel, and G. Vigna. Detection and analysis of drive-by-download attacks\n\nand malicious javascript code. In Proceedings of the 19th international conference on\n\nWorld wide web, WWW \u201910, pages 281\u2013290, New York, NY, USA, 2010. ACM.\n\n[41] Cult of the Dead Cow. Back Orifice Windows Remote Administration Tool. http:\n\n//www.cultdeadcow.com/tools/bo.html. Accessed on March 5, 2012, 1998.\n\n[42] David Dagon, Guofei Gu, Christopher P. Lee, and Wenke Lee. A Taxonomy of Botnet\n\nStructures. In 23rd Annual Computer Security Applications Conference (ACSAC), pages\n\n325\u2013339, December 2007.\n\n[43] Anthony Desnos, Eric Filiol, and Ivan Lefou. Detecting (and creating !) a hvm rootkit\n\n(aka bluepill-like). Journal in Computer Virology, 7(1):23\u201349, February 2011.\n\n[44] DHS. A roadmap for cybersecurity research. http://www.cyber.st.dhs.gov/docs/DHS-\n\nCybersecurity-Roadmap.pdf, 2009.\n\n[45] Artem Dinaburg, Paul Royal, Monirul Sharif, and Wenke Lee. Ether: malware analysis\n\nvia hardware virtualization extensions. In Proceedings of the 15th ACM conference on\n\nComputer and Communications Security, CCS \u201908, pages 51\u201362, New York, NY, USA,\n\n2008. ACM.\n\n[46] M. Egele, C. Kruegel, E. Kirda, and G. Vigna. PiOS: Detecting Privacy Leaks in iOS\n\nApplications. In Proceedings of the Network and Distributed System Security Symposium\n\n(NDSS), San Diego, CA, February 2011.\n\n[47] M. Egele, P. Wurzinger, C. Kruegel, and E. Kirda. Defending browsers against drive-by\n\ndownloads: Mitigating heap-spraying code injection attacks. Detection of Intrusions and\n\nMalware, and Vulnerability Assessment, pages 88\u2013106, 2009.\n\n[48] Manuel Egele, Christopher Kruegel, Engin Kirda, Heng Yin, and Dawn Song. Dynamic\n\nSpyware Analysis. In Proceedings of the USENIX Annual Technical Conference, Berkeley,\n\nCA, USA, 2007. USENIX Association.\n\n\n\nBibliography 119\n\n[49] Manuel Egele, Theodoor Scholte, Engin Kirda, and Christopher Kruegel. A Survey on\n\nAutomated Dynamic Malware Analysis Techniques and Tools. ACM Computing Surveys,\n\n44(2), February 2012.\n\n[50] Stephen G. Eick, Joseph L. Steffen, and Eric E. Sumner, Jr. Seesoft-a tool for visualizing\n\nline oriented software statistics. IEEE Trans. Softw. Eng., 18(11):957\u2013968, November\n\n1992.\n\n[51] F-Secure Corp. The trojan money spinner, 2007. Available at http://www.f-secure.\n\ncom/weblog/archives/VB2007_TheTrojanMoneySpinner.pdf.\n\n[52] Nicolas Falliere, Liam O Murchu, and Eric Chien. W32.Stuxnet Dossier. Technical report,\n\nSymantec Security Response, February 2011.\n\n[53] Hanno Fallmann, Gilbert Wondracek, and Christian Platzer. Covertly probing under-\n\nground economy marketplaces. In Seventh Conference on Detection of Intrusions and\n\nMalware &amp; Vulnerability Assessment (DIMVA), 2010.\n\n[54] Eric Filiol. Computer viruses: from theory to applications. Springer, 2005.\n\n[55] Eric Filiol. Malware pattern scanning schemes secure against black-box analysis. Journal\n\nin Computer Virology, 2(1):35\u201350, 2006.\n\n[56] Eric Filiol, Gre?goire Jacob, and Mickae?l Le Liard. Evaluation methodology and theoret-\n\nical model for antiviral behavioural detection strategies. Journal in Computer Virology,\n\n3(1):23\u201337, 2007.\n\n[57] Fitsec. Tool release: A banking trojan detection tool. http://www.fitsec.com/blog/\n\nindex.php/2011/08/15/tool-release-a-banking-trojan-detection-tool/, 2011.\n\nAccessed on June, 2012.\n\n[58] FProt. F-prot antivirus. http:\\\\www.f-prot.com, 2012.\n\n[59] Lee Garber. Melissa Virus Creates a New Type of Threat. Computer, 32:16\u201319, June\n\n1999.\n\n[60] Jonathon Giffin, Somesh Jha, and Barton Miller. Automated discovery of mimicry attacks.\n\nIn Symposium on Recent Advances in Intrusion Detection (RAID), 2006.\n\n[61] Google. Google maps api. https://developers.google.com/maps/, 2012. Acessed on\n\nJune, 2012.\n\n[62] Sarah Gordon. What a (winword.)concept. Virus Bulletin, September 1995.\n\n[63] Andre? Gre?gio, Dario S. Fernandes, Vitor Afonso, Rafael Santos, Mario Jino, and Paulo L.\n\nde Geus. Behavioral analysis of malicious code through network traffic and system call\n\nmonitoring. In Proc. of the SPIE, volume 8059, 2011.\n\n\n\n120 Bibliography\n\n[64] AndrA? c\u00a9 Ricardo Abed Gregio, Isabela L. Oliveira, Rafael Duarte Coelho dos Santos,\nAdriano M. Cansian, and Paulo L. de Geus. Malware distributed collection and pre-\n\nclassification system using honeypot technology. In Proceedings of SPIE, volume 7344.\n\nData Mining, Intrusion Detection, Information Security and Assurance, and Data Net-\n\nworks Security 2009., SPIE, 2009.\n\n[65] Simon Hansman and Ray Hunt. A taxonomy of network and computer attacks. Computers\n\n&amp; Security, 24(1):31\u201343, 2005.\n\n[66] Harold Joseph Highland. A Macro Virus. Computers &amp; Security, 8:178\u2013188, 1989.\n\n[67] Hispasec. Virustotal. http://www.virustotal.com/, 2012.\n\n[68] Thorsten Holz, Markus Engelberth, and Felix Freiling. Learning more about the under-\n\nground economy: a case-study of keyloggers and dropzones. In Proceedings of the 14th\n\nEuropean conference on Research in computer security, ESORICS\u201909, pages 1\u201318, Berlin,\n\nHeidelberg, 2009. Springer-Verlag.\n\n[69] John D. Howard and Thomas A. Longstaff. A Common Language for Computer Security\n\nIncidents. Technical Report SAND98-8667, Sandia National Laboratories, Albuquerque,\n\nNew Mexico 87185 and Livermore, California 94550, October 1998.\n\n[70] IBM. The cost of a data breach. IBM Systems Magazine, pages 14\u201315, September/October\n\n2011.\n\n[71] Claudiu Ilioiu. What is trojan banking, computer virus\n\ndesigned to attack online transactions. http://www.\n\nfinancial-magazine.org/what-is-trojan-banking-computer-virus-designed\n\n-to-attack-online-transactions-66473.html, May 2012. Accessed on May, 2012.\n\n[72] iSecLab. Anubis - analyzing unknown binaries. http://anubis.iseclab.org/, 2007.\n\n[73] Gregoire Jacob, Paolo Milani Comparetti, Matthias Neugschwandtner, Christopher\n\nKruegel, and Giovanni Vigna. A static, packer-agnostic filter to detect similar malware\n\nsamples. In Ninth Conference on Detection of Intrusions and Malware &amp; Vulnerability\n\nAssessment (DIMVA), 2012.\n\n[74] Gre?goire Jacob, Herve? Debar, and Eric Filiol. Malware behavioral detection by attribute-\n\nautomata using abstraction from platform and language. In Proceedings of the 12th Inter-\n\nnational Symposium on Recent Advances in Intrusion Detection, RAID \u201909, pages 81\u2013100,\n\nBerlin, Heidelberg, 2009. Springer-Verlag.\n\n[75] Gregoire Jacob, Eric Filiol, and Herve Debar. Functional polymorphic engines: formali-\n\nsation, Implementation and use cases. J. Comput. Virol., 5(3), 2008.\n\n[76] Gregoire Jacob, Matthias Neugschwandtner, Paolo Milani Comparetti, Christopher\n\nKruegel, and Giovanni Vigna. A static, packer-agnostic filter to detect similar malware\n\nsamples. Technical Report 2010-26, UCSB, November 2010.\n\n\n\nBibliography 121\n\n[77] A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: a review. ACM Comput.\n\nSurv., 31:264\u2013323, 1999.\n\n[78] J. Jang, D. Brumley, and S. Venkataraman. BitShred: Feature Hashing Malware for\n\nScalable Triage and Semantic Analysis. In ACM Conference on Computer and Commu-\n\nnications Security (CCS), 2011.\n\n[79] Martin Karresand. Separating Trojan Horses, Viruses and Worms - A Proposed Taxon-\n\nomy of Software Weapons. In IEEE Information Assurance Workshop, pages 127\u2013134,\n\n2003.\n\n[80] Kaspersky. Number of the week: 780 new malicious programs designed to steal users\u2019\n\nonline banking data detected every day, 2012. Available at http://www.kaspersky.com/\n\nabout/news/virus/2012/Number_of_the_week_780_new_malicious_programs.\n\n[81] Brendan P. Kehoe. Zen and the Art of the Internet. https://www.cs.indiana.edu/\n\ndocproject/zen/zen-1.0_toc.html, January 1992.\n\n[82] Joris Kinable and Orestis Kostakis. Malware classification based on call graph clustering.\n\nJ. Comput. Virol., 7(4):233\u2013245, November 2011.\n\n[83] Dhilung Kirat, Giovanni Vigna, and Christopher Kruegel. BareBox: Efficient Malware\n\nAnalysis on Bare-Metal. In Proceedings of the Annual Computer Security Applications\n\nConference (ACSAC), Orlando, FL, December 2011.\n\n[84] Brian Krebs. \u2019Citadel\u2019 Trojan Touts Trouble-Ticket System. http://krebsonsecurity.\n\ncom/2012/01/citadel-trojan-touts-trouble-ticket-system/. Accessed on March 9,\n\n2012, January 2012.\n\n[85] Ivan Krsul. Software Vulnerability Analysis. PhD thesis, Purdue University, May 1998.\n\n[86] Christopher Kruegel, Engin Kirda, and Ulrich Bayer. TTAnalyze: A tool for analyzing\n\nmalware. In Proceedings of the 15th European Institute for Computer Antivirus Research\n\n(EICAR 2006) Annual Conference, April 2006.\n\n[87] Christopher Kruegel, Engin Kirda, Ulrich Bayer, Davide Balzarotti, and Imam Habibi.\n\nInsights into current malware behavior. In 2nd USENIX Workshop on Large-Scale Exploits\n\nand Emergent Threats (LEET), Boston, April 2009.\n\n[88] Eduardo Labir. VX Reversing II, Sasser.B. The Code Breakers Journal, 1(1), 2004.\n\n[89] Carl E. Landwehr, Alan R. Bull, John P. McDermott, and William S. Choi. A Taxonomy\n\nof Computer Program Security Flaws. ACM Computing Surveys, 26:211\u2013254, September\n\n1994.\n\n[90] Tobias Lauinger, Engin Kirda, and Pietro Michiardi. Paying for piracy? an analysis\n\nof one-click hosters\u2019 controversial reward schemes. In 15th Internationa Symposium on\n\nResearch in Attacks, Intrusions and Defenses (RAID), 2012.\n\n\n\n122 Bibliography\n\n[91] Kirill Levchenko, Andreas Pitsillidis, Neha Chachra Br, Tristan Halvorson, Chris Kanich,\n\nChristian Kreibich, He Liu, Damon Mccoy, Nicholas Weaver, Vern Paxson, Geoffrey M.\n\nVoelker, and Stefan Savage. Click trajectories: End-to-end analysis of the spam value\n\nchain. In In Proceedings of IEEE Symposium on Security &amp; Privacy, pages 431\u2013446,\n\n2011.\n\n[92] Martina Lindorfer, Clemens Kolbitsch, and Paolo Milani Comparetti. Detecting\n\nenvironment-sensitive malware. In International Symposium on Recent Advances in In-\n\ntrusion Detection (RAID), Menlo Park, CA, USA, September 2011.\n\n[93] Ulf Lindqvist and Erland Jonsson. How to Systematically Classify Computer Security\n\nIntrusions. In Proceedings of the 1997 IEEE Symposium on Security and Privacy, SP \u201997,\n\npages 154\u2013163, Washington, DC, USA, 1997. IEEE Computer Society.\n\n[94] Carl Linnaeus. Systema naturae, sive regna tria naturae systematice proposita per classes,\n\nordines, genera, &amp; species. 1st edition, 1735.\n\n[95] Weiqin Ma, Pu Duan, Sanmin Liu, Guofei Gu, and Jyh-Charn Liu. Shadow Attacks:\n\nAutomatically Evading System-Call-Behavior based Malware Detection. Springer Journal\n\nin Computer Virology, 2012.\n\n[96] Mariette Manktelow. History of Taxonomy. Department of Systematic Biology,\n\nUppsala University. http://atbi.eu/summerschool/files/summerschool/Manktelow_\n\nSyllabus.pdf. Acesso realizado em 27 de fevereiro de 2012, 2008.\n\n[97] Lorenzo Martignoni, Elizabeth Stinson, Matt Fredrikson, Somesh Jha, and John C.\n\nMitchell. A layered architecture for detecting malicious behaviors. In Proceedings of\n\nthe 11th international symposium on Recent Advances in Intrusion Detection, RAID \u201908,\n\npages 78\u201397, Berlin, Heidelberg, 2008. Springer-Verlag.\n\n[98] Eric Medvet, Engin Kirda, and Christopher Kruegel. Visual-similarity-based phishing\n\ndetection. In Proceedings of the 4th international conference on Security and privacy in\n\ncommunication netowrks, SecureComm \u201908, pages 22:1\u201322:6, New York, NY, USA, 2008.\n\nACM.\n\n[99] Charles D. Michener, John O. Corliss, Richard S. Cowan, Peter H. Raven, Curtis W.\n\nSabrosky, Donald F. Squires, and G. W. Wharton. Systematics in Support of Biologi-\n\ncal Research. Technical report, Division of Biology and Agriculture, National Research\n\nCouncil, Washington, DC, January 1970.\n\n[100] Microsoft. Win32/allaple, 2007. Available at http://www.microsoft.com/security/\n\nportal/Threat/Encyclopedia/Entry.aspx?Name=Win32%2fAllaple.\n\n[101] D. Moore, V. Paxson, S. Savage, C. Shannon, S. Staniford, and N. Weaver. Inside the\n\nSlammer Worm. Security Privacy, IEEE, 1(4):33\u201339, July/August 2003.\n\n\n\nBibliography 123\n\n[102] David Moore, Colleen Shannon, and Jeffery Brown. Code-Red: a Case Study on the\n\nSpread and Victims of an Internet Worm. In Proceedings of the 2nd ACM SIGCOMM\n\nWorkshop on Internet Measurment, IMW \u201902, pages 273\u2013284, New York, NY, USA, 2002.\n\nACM.\n\n[103] A. Moser, C. Kruegel, and E. Kirda. Limits of static analysis for malware detection. In\n\nProc. of the 23rd Annual Computer Security Applications Conference, ACSAC \u201907, pages\n\n421 \u2013430, December 2007.\n\n[104] Mozilla. Rhino: Javascript for java. http://www.mozilla.org/rhino, 2012. Accessed on\n\nMay, 2012.\n\n[105] Lysa Myers. Aim for Bot Coordination. In Virus Bulletin (VB2006), pages 35\u201337, Mon-\n\ntreal, Canada, October 2006.\n\n[106] J. Nazario. Phoneyc: A virtual client honeypot. In Proceedings of the 2nd USENIX\n\nconference on Large-scale exploits and emergent threats: botnets, spyware, worms, and\n\nmore, pages 6\u20136. USENIX Association, 2009.\n\n[107] Matthew Nelson. Developer creates the first Java virus and names it \u2019Strange Brew\u2019.\n\nhttp://www.javaworld.com/javaworld/jw-09-1998/jw-09-iw-virus.html. Accessed\n\non March 5, 2012, August 1998.\n\n[108] John Von Neumann and Arthur W. Burks. Theory of Self-Reproducing Automata. Uni-\n\nversity of Illinois, 1st edition, 1966.\n\n[109] Peter G. Neumann and Donn B. Parker. A Summary of Computer Misuse Techniques.\n\nIn 12th National Computer Security Conference, Baltimore, MD, pages 396\u2013406, October\n\n1989.\n\n[110] NHM. What is Taxonomy. UK Natural History Museum. http://www.nhm.\n\nac.uk/nature-online/science-of-natural-history/taxonomy-systematics/\n\nwhat-is-taxonomy/index.html. Acesso realizado em 27 de fevereiro de 2012, 2012.\n\n[111] Norman. Norman sandbox whitepaper. http://download.norman.no/whitepapers/\n\nwhitepaper\\_Norman\\_SandBox.pdf, 2003.\n\n[112] J. C. Oliveros. VENNY. An interactive tool for comparing lists with Venn Diagrams.\n\nhttp://bioinfogp.cnb.csic.es/tools/venny/index.html. Acessed on September 13,\n\n2012, 2007.\n\n[113] Bob Page. A Report on the Internet Worm. http://www.ee.ryerson.ca/~elf/hack/\n\niworm.html, 1988.\n\n[114] Younghee Park, Douglas Reeves, Vikram Mulukutla, and Balaji Sundaravel. Fast malware\n\nclassification by automated behavioral graph matching. In Proceedings of the Sixth Annual\n\nWorkshop on Cyber Security and Information Intelligence Research, CSIIRW \u201910, pages\n\n45:1\u201345:4, New York, NY, USA, 2010. ACM.\n\n\n\n124 Bibliography\n\n[115] Roberto Perdisci, Wenke Lee, and Nick Feamster. Behavioral clustering of http-based\n\nmalware and signature generation using malicious network traces. In Proceedings of the\n\n7th USENIX conference on Networked Systems Design and Implementation, NSDI\u201910,\n\npages 26\u201326, Berkeley, CA, USA, 2010. USENIX Association.\n\n[116] Phillip Porras, Hassen Sa??di, and Vinod Yegneswaran. A Multi-perspective Analysis of\n\nthe Storm (Peacomm) Worm. Technical report, Computer Science Laboratory, SRI In-\n\nternational, 333 Ravenswood Ave., Menlo Park, CA 94025, October 2007.\n\n[117] Phillip Porras, Hassen Sa??di, and Vinod Yegneswaran. An Analysis of Conficker\u2019s Logic\n\nand Rendezvous Points. Technical report, Computer Science Laboratory, SRI Interna-\n\ntional, 333 Ravenswood Ave., Menlo Park, CA 94025, February 2009.\n\n[118] Niels Provos. Honeyd: a virtual honeypot daemon, 2003. Available at http://www.citi.\n\numich.edu/u/provos/papers/honeyd-eabstract.pdf.\n\n[119] Niels Provos and Thorsten Holz. Virtual honeypots: from botnet tracking to intrusion\n\ndetection. Addison-Wesley Professional, first edition, 2007.\n\n[120] D.A. Quist and L.M. Liebrock. Visualizing compiled executables for malware analysis.\n\nIn Visualization for Cyber Security, 2009. VizSec 2009. 6th International Workshop on,\n\npages 27 \u201332, oct. 2009.\n\n[121] Danny Quist and Val Smith. Detecting the Presence of Virtual Machines Using the Local\n\nData Table, 2008. http://www.offensivecomputing.net/files/active/0/vm.pdf.\n\n[122] Nguyen Anh Quynh and Kuniyasu Suzaki. Virt-ice: Next-generation debugger\n\nfor malware analysis. https://media.blackhat.com/bh-us-10/whitepapers/Anh/\n\nBlackHat-USA-2010-Anh-Virt-ICE-wp.pdf, 2010.\n\n[123] Costin Raiu. A Virus by Any Other Name: Virus Nam-\n\ning Practices. http://www.symantec.com/connect/articles/\n\nvirus-any-other-name-virus-naming-practices. Accessed on March 1, 2012,\n\nJune 2002.\n\n[124] Huw Read, Konstantinos Xynos, and Andrew Blyth. Presenting devise: data exchange\n\nfor visualizing security events. IEEE Comput. Graph. Appl., 29(3):6\u201311, May 2009.\n\n[125] Konrad Rieck, Thorsten Holz, Carsten Willems, Patrick Du?ssel, and Pavel Laskov. Learn-\n\ning and classification of malware behavior. In Proceedings of the 5th international confer-\n\nence on Detection of Intrusions and Malware, and Vulnerability Assessment, DIMVA \u201908,\n\npages 108\u2013125, Berlin, Heidelberg, 2008. Springer-Verlag.\n\n[126] Konrad Rieck, Guido Schwenk, Tobias Limmer, Thorsten Holz, and Pavel Laskov. Botzilla:\n\ndetecting the \u201dphoning home\u201d of malicious software. In Proceedings of the 2010 ACM\n\nSymposium on Applied Computing, SAC \u201910, pages 1978\u20131984, New York, NY, USA,\n\n2010. ACM.\n\n\n\nBibliography 125\n\n[127] Joanna Rutkowska. Introducing Stealth Malware Taxonomy. http://invisiblethings.\n\norg/papers/malware-taxonomy.pdf. Acesso realizado em 28 de fevereiro de 2012, 2006.\n\n[128] Stefan Saroiu, Steven D. Gribble, and Henry M. Levy. Measurement and Analysis of\n\nSpyware in a University Environment. In Proceedings of the ACM/USENIX Symposium\n\non Networked Systems Design and Implementation (NSDI), pages 141\u2013153, 2004.\n\n[129] Bruce Schneier. The zotob storm. Security Privacy, IEEE, 3(6):96, November/December\n\n2005.\n\n[130] Seculert. Citadel - An Open Source Malware Project. http://blog.seculert.com/\n\n2012/02/citadel-open-source-malware-project.html. Accessed on March 9, 2012,\n\nFebruary 2012.\n\n[131] SecureList. Net-worm.win32.allaple.a, 2007. Available at http://www.securelist.com/\n\nen/descriptions/old145521.\n\n[132] C. Seifert and R. Steenson. Capture - honeypot client (capture-hpc), 2006.\n\n[133] Justin Seitz. Gray Hat Python: Python Programming for Hackers and Reverse Engineers.\n\nNo Starch Press, San Francisco, CA, USA, 2009.\n\n[134] Madhu Shankarapani, Subbu Ramamoorthy, Ram Movva, and Srinivas Mukkamala. Mal-\n\nware detection using assembly and api call sequences. J. Comput. Virol., 7:107\u2013119, 2011.\n\n[135] Seungwon Shin and Guofei Gu. Conficker and Beyond: a Large-Scale Empirical Study. In\n\nProceedings of the 26th Annual Computer Security Applications Conference, ACSAC \u201910,\n\npages 151\u2013160, New York, NY, USA, 2010. ACM.\n\n[136] Seungwon Shin, Raymond Lin, and Guofei Gu. Cross-analysis of botnet victims: New\n\ninsights and implications. In Proceedings of the 14th International Symposium on Recent\n\nAdvances in Intrusion Detection (RAID\u201911)), September 2011.\n\n[137] John F. Shoch and Jon A. Hupp. The Worm Programs\u2014Early Experience with a Dis-\n\ntributed Computation. Communications of the ACM, 25:172\u2013180, March 1982.\n\n[138] R. Shyamasundar, Harshit Shah, and N. Kumar. Malware: From Modelling to Practical\n\nDetection. In Tomasz Janowski and Hrushikesha Mohanty, editors, Distributed Computing\n\nand Internet Technology, volume 5966 of Lecture Notes in Computer Science, pages 21\u201339.\n\nSpringer Berlin / Heidelberg, 2010.\n\n[139] Garry Sidaway. The Rise and Rise of Bot Networks. Network Security, 2005(5):19\u201320,\n\nMay 2005.\n\n[140] Ed Skoudis and Lenny Zeltser. Malware: Fighting Malicious Code. Prentice Hall, 1st\n\nedition, 2003.\n\n\n\n126 Bibliography\n\n[141] Fridrik Skulason, Alan Solomon, and Vesselin Bontchev. CARO Naming Scheme. http:\n\n//www.caro.org/naming/scheme.html. Accessed on March 1, 2012, 1991.\n\n[142] Eugene H. Spafford. The Internet Worm Program: An Analysis. Technical Report CSD-\n\nTR-823, Department of Computer Sciences, Purdue University, West Lafayette, Indiana,\n\nNovember 1988.\n\n[143] Stuart Staniford, Vern Paxson, and Nicholas Weaver. How to Own the Internet in Your\n\nSpare Time. In Proceedings of the 11th USENIX Security Symposium, pages 149\u2013167,\n\nBerkeley, CA, USA, 2002. USENIX Association.\n\n[144] B. Stone-Gross, R. Abman, R. Kemmerer, C. Kruegel, D. Steigerwald, and G. Vigna. The\n\nUnderground Economy of Fake Antivirus Software. In Proceedings of the Workshop on\n\nEconomics of Information Security (WEIS), 2011.\n\n[145] B. Stone-Gross, T. Holz, G. Stringhini, and G. Vigna. The Underground Economy of\n\nSpam: A Botmaster\u2019s Perspective of Coordinating Large-Scale Spam Campaigns. In\n\nUSENIX Workshop on Large-Scale Exploits and Emergent Threats (LEET), 2011.\n\n[146] B. Stone-Gross, R. Stevens, A. Zarras, R. Kemmerer, C. Kruegel, and G. Vigna. Under-\n\nstanding Fraudulent Activities in Online Ad Exchanges. In Proceedings of the Internet\n\nMeasurement Conference (IMC), 2011.\n\n[147] Brett Stone-Gross, Marco Cova, Bob Gilbert, Richard Kemmerer, Christopher Kruegel,\n\nand Giovanni Vigna. Analysis of a Botnet Takeover. IEEE Security &amp; Privacy Magazine,\n\n9(1):64\u201372, January/February 2011.\n\n[148] G. Stringhini, M. Egele, C. Kruegel, and G. Vigna. Poultry markets: On the underground\n\neconomy of twitter followers. In Workshop on Online Social Network (WOSN). ACM,\n\n2012.\n\n[149] G. Stringhini, C. Kruegel, and G. Vigna. Detecting spammers on social networks. In\n\nAnnual Computer Security Applications Conference, 2010.\n\n[150] Peter Szor. The Art of Computer Virus Research and Defense. Addison-Wesley, 1st\n\nedition, February 2005.\n\n[151] Sapon Tanachaiwiwat and Ahmed Helmy. VACCINE: War of the Worms in Wired and\n\nWireless Networks. In Proceedings of the IEEE INFOCOM, Barcelona, Spain, April 2006.\n\n[152] The Honeynet Project. Nepenthes - the finest collection, 2008. Available at http://www.\n\nhoneynet.org/project/nepenthes.\n\n[153] The Honeynet Project. Dionaea: catches bugs, 2009. Available at http://dionaea.\n\ncarnivore.it/.\n\n\n\nBibliography 127\n\n[154] Kurt Thomas and David M. Nicol. The Koobface Botnet and the Rise of Social Malware.\n\nIn Malicious and Unwanted Software (MALWARE), 2010 5th International Conference\n\non, pages 63\u201370, October 2010.\n\n[155] Threat Expert Ltd. Threatexpert. http://www.threatexpert.com, 2012. Accessed on\n\nMay, 2012.\n\n[156] TrendMicro. The ZLOB Show: Trojan Poses as Fake Video Codec, Loads More\n\nThreats. http://about-threats.trendmicro.com/archivevulnerability.aspx?\n\nlanguage=us&amp;name=The+ZLOB+Show:+Trojan+Poses+as+Fake+Video+Codec,+Loads+\n\nMore+Threats. Accessed on March 8, 2012, 2012.\n\n[157] P. Trinius, T. Holz, J. Gobel, and F.C. Freiling. Visual analysis of malware behavior using\n\ntreemaps and thread graphs. In Visualization for Cyber Security, 2009. VizSec 2009. 6th\n\nInternational Workshop on, pages 33 \u201338, oct. 2009.\n\n[158] UPI. New malware attacks target online banking. http://www.upi.com/Science_News/\n\n2012/02/02/New-malware-attacks-target-online-banking/UPI-25351328224292/,\n\nFebruary 2012. Accessed on May, 2012.\n\n[159] US Department of Homeland Security. Current hard problems in infosec research. issue 7\n\nof 11: Combatting malware and botnets. Technical report, DHS, November 2009.\n\n[160] VxHeavens. Virus database, 2010. Available at http://vx.netlux.org/.\n\n[161] Nicholas Weaver, Vern Paxson, Stuart Staniford, and Robert Cunningham. A Taxonomy\n\nof Computer Worms. In Proceedings of the 2003 ACM Workshop on Rapid Malcode\n\n(WORM), pages 11\u201318, New York, NY, USA, 2003.\n\n[162] James A. Whittaker and Andres De Vivanco. Neutralizing Windows-based Malicious\n\nMobile Code. In Proceedings of the 2002 ACM Symposium on Applied Computing, SAC\n\n\u201902, pages 242\u2013246, New York, NY, USA, 2002. ACM.\n\n[163] Georg Wicherski. pehash: a novel approach to fast malware clustering. In Proceedings\n\nof the 2nd USENIX conference on Large-scale exploits and emergent threats: botnets,\n\nspyware, worms, and more, LEET\u201909, pages 1\u20131, Berkeley, CA, USA, 2009. USENIX\n\nAssociation.\n\n[164] Wikipedia. Gnu diff. http://en.wikipedia.org/wiki/Diff, 2002.\n\n[165] Wikipedia. The jaccard index. http://en.wikipedia.org/wiki/Jaccard\\_index, 2005.\n\n[166] Wikipedia. Zlob trojan, 2011. Available at http://en.wikipedia.org/wiki/Zlob\\\n\n_trojan.\n\n[167] Wikipedia. Systematics. http://en.wikipedia.org/wiki/Systematics. Acesso real-\n\nizado em 27 de fevereiro de 2012, 2012.\n\n\n\n128 Bibliography\n\n[168] Carsten Willems, Thorsten Holz, and Felix Freiling. Toward Automated Dynamic Malware\n\nAnalysis Using CWSandbox. IEEE Security and Privacy, 5:32\u201339, March 2007.\n\n[169] Chester Wisniewski. Malware shuts down hospital near At-\n\nlanta, Georgia. http://nakedsecurity.sophos.com/2011/12/13/\n\nmalware-shuts-down-hospital-near-atlanta-georgia/. Accessed on April 1,\n\n2012, December 2011.\n\n[170] Chao Yang, Robert Harkreader, and Guofei Gu. Die free or live hard? empirical evaluation\n\nand new design for fighting evolving twitter spammers. In Proceedings of the 14th Inter-\n\nnational Symposium on Recent Advances in Intrusion Detection (RAID\u201911)), September\n\n2011.\n\n[171] Junjie Zhang, Xiapu Luo, Roberto Perdisci, Guofei Gu, Wenke Lee, and Nick Feamster.\n\nBoosting the scalability of botnet detection using adaptive traffic sampling. In Proceedings\n\nof the 2011 ACM Symposium on Information, Computer, and Communication Security\n\n(ASIACCS\u201911), March 2011.\n\n[172] Junjie Zhang, Christian Seifert, Jack W. Stokes, and Wenke Lee. Arrow: Generating sig-\n\nnatures to detect drive-by downloads. In Proceedings of the 20th International conference\n\non World Wide Web, WWW \u201911, pages 187\u2013196, New York, NY, USA, 2011. ACM.\n\n[173] Qinghua Zhang and D.S. Reeves. Metaaware: Identifying metamorphic malware. In Proc.\n\nof the 23rd Annual Computer Security Applications Conference, ACSAC \u201907, pages 411\n\n\u2013420, December 2007.\n\n[174] Cliff Changchun Zou, Weibo Gong, and Don Towsley. Code Red Worm Propagation\n\nModeling and Analysis. In Proceedings of the 9th ACM conference on Computer and\n\nCommunications Security, CCS \u201902, pages 138\u2013147, New York, NY, USA, 2002. ACM."}]}}}