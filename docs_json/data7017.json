{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.09780"}, {"@name": "filename", "#text": "14774_000710038.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNIVERSIDADE FEDERAL DO RIO GRANDE DO SUL \n\nINSTITUTO DE INFORM\u00c1TICA \n\nPROGRAMA DE P\u00d3S-GRADUA\u00c7\u00c3O EM COMPUTA\u00c7\u00c3O \n\n \n\n \n\n \n\n \n\n \n\nSANDRO RAMA FIORINI \n\n \n\n \n\n \n\nS-Chart: Um Arcabou\u00e7o para \nInterpreta\u00e7\u00e3o Visual de Gr\u00e1ficos \n\n \n\n \n\n \n\n \n\nDisserta\u00e7\u00e3o apresentada como requisito \nparcial para a obten\u00e7\u00e3o do grau de Mestre \nem Ci\u00eancia da Computa\u00e7\u00e3o \n\n \n\n \n\nProf. Dr\u00aa. Mara Abel \n\nOrientadora \n\n \n\n \n\nProf. Dr. Claiton M. dos Santos Scherer \n\nCo-orientador \n\n \n\nPorto Alegre, mar\u00e7o de 2009.\n\n\n\nCIP \u2013 CATALOGA\u00c7\u00c3O NA PUBLICA\u00c7\u00c3O \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nUNIVERSIDADE FEDERAL DO RIO GRANDE DO SUL \nReitor: Prof. Carlos Alexandre Netto \nVice-Reitor: Prof. Rui Vicente Oppermann \nPr\u00f3-Reitor de P\u00f3s-Gradua\u00e7\u00e3o: Prof. Aldo Bolten Lucion \nDiretor do Instituto de Inform\u00e1tica: Prof. Fl\u00e1vio Rech Wagner \nCoordenador do PPGC: Prof. \u00c1lvaro Freitas Moreira \nBibliotec\u00e1ria-Chefe do Instituto de Inform\u00e1tica: Beatriz Regina B. Haro \n\nFiorini, Sandro Rama \n\nS-Chart: Um Arcabou\u00e7o para Interpreta\u00e7\u00e3o Visual de Gr\u00e1-\nficos / Sandro Rama Fiorini. Porto Alegre: Programa de P\u00f3s-\nGradua\u00e7\u00e3o em Computa\u00e7\u00e3o, 2009. \n\n122 p.:il. \n\nDisserta\u00e7\u00e3o (mestrado) \u2013 Universidade Federal do Rio \nGrande do Sul. Programa de P\u00f3s-Gradua\u00e7\u00e3o em Computa-\n\u00e7\u00e3o. Porto Alegre, BR \u2013 RS, 2009. Orientador: Prof. Dr\u00aa. Mara \nAbel; Co-orientador: Prof. Dr. Claiton M. dos Santos Scherer. \n\n1.Vis\u00e3o Computacional. 2.Interpreta\u00e7\u00e3o Sem\u00e2ntica de \nGr\u00e1ficos. 3.Representa\u00e7\u00e3o de Conhecimento Visual. I. Abel, \nMara.  II. Scherer, Claiton. III. T\u00edtulo. \n\n\n\nAGRADECIMENTOS \n\nVejo os agradecimentos que fa\u00e7o aqui como uma continua\u00e7\u00e3o dos agradeci-\nmentos que fiz no meu trabalho de conclus\u00e3o. No entanto, agora tenho um pro-\nblema mais complicado, pois agradecer a todos que contribuem em um trabalho \ndeste tamanho \u00e9 quase imposs\u00edvel.  \n\nInicialmente devo agradecer a UFRGS e o Instituto de Inform\u00e1tica por mais \ndois anos onde me propiciaram o melhor dos ambientes para o desenvolvimen-\nto do trabalho apresentado nesta disserta\u00e7\u00e3o. Agora tenho ainda mais orgulho \nde estar ligado a essas institui\u00e7\u00f5es. Agrade\u00e7o tamb\u00e9m ao CNPq, por ter financi-\nado o meu trabalho por esses dois. \n\nSou grato a todos os colegas e amigos que estiveram comigo ao longo desses \ndois anos no grupo de Bancos de Dados Inteligentes: Alexandre Lorenzatti, Joel \nCarbonera, Felipe Victoreti, Carlos Santin, Mar\u00edlia Mello, Laura Mastella, Willi-\nan Gon\u00e7alves e Bruno Nunes! Todos foram e s\u00e3o muito importantes. Sem toda \nessa turma certamente este trabalho seria muito mais dif\u00edcil de ser completado.  \n\nGostaria de agradecer ao meu co-orientador, o Professor Claiton Scherer, do \nInstituto de Geoci\u00eancias, pelo tempo despendido tentando ensinar um pouco de \nestratigrafia para um simples mestrando de computa\u00e7\u00e3o. Sem ele, este trabalho \nseria imposs\u00edvel. \n\nFechando os agradecimentos acad\u00eamicos, devo fazer um agradecimento es-\npecial a minha orientadora Professora Mara Abel. J\u00e1 passados mais de seis anos \nde orienta\u00e7\u00e3o, devo admitir que os seus conselhos e desafios formaram grande \n\u2013 se n\u00e3o a maior \u2013 parte do meu perfil profissional.  \n\nAmigos novamente! Posso recortar e colar essa parte dos agradecimentos \nque escrevi no meu trabalho de conclus\u00e3o. Ter amizades duradouras \u00e9 a chave \npara a manuten\u00e7\u00e3o da sanidade em um trabalho de p\u00f3s-gradua\u00e7\u00e3o. Enilton, o \nmais antigo e parceiro para id\u00e9ias infantis e sem a menor possibilidade de reali-\nza\u00e7\u00e3o ?. Eduardo Castro, que desde os prim\u00f3rdios do col\u00e9gio \u00e9 o meu eterno \n\u201ccolega\u201d: no col\u00e9gio, na faculdade, do laborat\u00f3rio, de trabalho. Grande parceiro \npara ouvir as minhas id\u00e9ias ca\u00f3ticas que conduziram finalmente a este trabalho. \nAo Grupo dos Cinco, composto pelos meus amigos Bill, Francisco, Gustavo e \nLeandro. Agora j\u00e1 mais dilu\u00eddo pelas responsabilidades, ainda \u00e9 a minha prin-\ncipal fonte de risadas e relaxamento intelectual. Obrigado de novo pela compa-\nnhia e apoio de voc\u00eas. \n\n\n\n 4\n\nAgrade\u00e7o tamb\u00e9m a minha fam\u00edlia, especialmente \u00e0 minha tia Maria e ao \nmeu primo Fabian pelo apoio e pela companhia que n\u00e3o consigo encontrar em \noutro lugar. \n\nAgrade\u00e7o aos meus pais: o seu Olir e a dona Marlene. N\u00e3o vou repetir o que \nj\u00e1 agradeci antes. Seria \u201cchover no molhado\u201d. Sou imensamente grato pelo seu \napoio nesses \u00faltimos anos, mesmo quando o filho n\u00e3o entendia isso direito.  \n\nPor fim, apenas para deixar registrado para o futuro: meu agnosticismo ain-\nda continua.  \n\n\n\n \n\n \n\nSUM\u00c1RIO\n\nLISTA DE ABREVIATURAS E SIGLAS ............................................................ 7\u00a0\nLISTA DE FIGURAS .......................................................................................... 8\u00a0\nLISTA DE TABELAS ....................................................................................... 10\u00a0\nRESUMO.......................................................................................................... 11\u00a0\nABSTRACT ...................................................................................................... 12\u00a0\n1\u00a0 INTRODU\u00c7\u00c3O .................................................................................... 13\u00a0\n1.1\u00a0 Modelos de conhecimento visual em tr\u00eas n\u00edveis .......................................... 14\u00a0\n1.2\u00a0 Interpreta\u00e7\u00e3o sem\u00e2ntica de gr\u00e1ficos ............................................................ 16\u00a0\n1.3\u00a0 Objetivo ........................................................................................................... 19\u00a0\n1.4\u00a0 Dom\u00ednio de aplica\u00e7\u00e3o: sistema InteliStrata ................................................. 19\u00a0\n1.5\u00a0 Organiza\u00e7\u00e3o dos cap\u00edtulos ............................................................................. 20\u00a0\n\n2\u00a0 INTERPRETA\u00c7\u00c3O SEM\u00c2NTICA DE IMAGENS................................ 21\u00a0\n2.1\u00a0 Representa\u00e7\u00e3o de Conhecimento Visual ...................................................... 24\u00a0\n2.2\u00a0 Abordagens de interpreta\u00e7\u00e3o sem\u00e2ntica ...................................................... 25\u00a0\n2.2.1\u00a0 Abordagem 1: Agregados ............................................................................ 25\u00a0\n2.2.2\u00a0 Abordagem 2: Abdu\u00e7\u00e3o ............................................................................... 27\u00a0\n2.2.3\u00a0 Abordagem 3: Espa\u00e7os Conceituais ........................................................... 29\u00a0\n2.2.4\u00a0 Abordagem 4: Abordagem Orion ............................................................... 31\u00a0\n2.3\u00a0 Discuss\u00e3o e Compara\u00e7\u00e3o entre Abordagens de Interpreta\u00e7\u00e3o Sem\u00e2ntica \nde Imagens ..................................................................................................................... 34\u00a0\n\n3\u00a0 S-Chart: UM MODELO PARA INTERPRETA\u00c7\u00c3O SEM\u00c2NTICA DE \nGR\u00c1FICOS ...................................................................................................... 37\u00a0\n3.1\u00a0 Linguagem de Representa\u00e7\u00e3o ....................................................................... 38\u00a0\n3.2\u00a0 Arquitetura do Framework S-Chart ............................................................ 39\u00a0\n3.2.1\u00a0 N\u00edvel sem\u00e2ntico ............................................................................................. 40\u00a0\n3.2.2\u00a0 N\u00edvel visual .................................................................................................... 41\u00a0\n3.2.3\u00a0 N\u00edvel anal\u00f3gico .............................................................................................. 46\u00a0\n3.2.4\u00a0 Mapeamento e ancoramento simb\u00f3lico ..................................................... 49\u00a0\n3.2.5\u00a0 Componente de Interpreta\u00e7\u00e3o ..................................................................... 54\u00a0\n\n4\u00a0 ESTRATIGRAFIA DE SEQU\u00caNCIAS ................................................. 61\u00a0\n4.1\u00a0 Apresenta\u00e7\u00e3o do dom\u00ednio .............................................................................. 61\u00a0\n4.2\u00a0 Interpreta\u00e7\u00e3o de sequ\u00eancias em perfis de raios gama ................................ 63\u00a0\n\n\n\n \n\n \n\n4.3\u00a0 An\u00e1lise de perfis por wavelets ....................................................................... 64\u00a0\n4.3.1\u00a0 Detec\u00e7\u00e3o de sequ\u00eancias: wavelet gaussiana .............................................. 66\u00a0\n4.3.2\u00a0 Detec\u00e7\u00e3o de parassequ\u00eancias: wavelet smoothtooth ............................... 67\u00a0\n\n5\u00a0 SISTEMA INTELISTRATA ................................................................. 70\u00a0\n5.1\u00a0 Objetivos do sistema ...................................................................................... 70\u00a0\n5.2\u00a0 Arquitetura do sistema .................................................................................. 71\u00a0\n5.2.1\u00a0 Modelos de representa\u00e7\u00e3o e extens\u00f5es ...................................................... 72\u00a0\n5.2.2\u00a0 Componentes de infra-estrutura ................................................................. 78\u00a0\n5.2.3\u00a0 Componentes de interpreta\u00e7\u00e3o ................................................................... 81\u00a0\n5.3\u00a0 Valida\u00e7\u00e3o do sistema InteliStrata ................................................................. 84\u00a0\n5.3.1\u00a0 Prepara\u00e7\u00e3o dos perfis ................................................................................... 84\u00a0\n5.3.2\u00a0 Avalia\u00e7\u00e3o dos resultados e valida\u00e7\u00e3o ........................................................ 85\u00a0\n\n6\u00a0 CONCLUS\u00c3O ..................................................................................... 89\u00a0\n6.1\u00a0 Framework S-Chart e modelos de conhecimento visual ............................ 89\u00a0\n6.2\u00a0 Sugest\u00e3o para trabalhos futuros ................................................................... 90\u00a0\n\nREFER\u00caNCIAS ................................................................................................ 92\u00a0\nANEXO  METAMODELO DA LINUGAGEM OWL .......................................... 96\u00a0\nAP\u00caNDICE  DESCRI\u00c7\u00c3O RDF/XML DOS MODELOS OWL DE \nCONHECIMENTO VISUAL DO SISTEMA INTELISTRATA ............................ 97\u00a0\nB.1\u00a0 Modelo do n\u00edvel anal\u00f3gico ............................................................................. 97\u00a0\nB.1.1\u00a0 Modelo OWL do n\u00edvel anal\u00f3gico ................................................................ 97\u00a0\nB.1.2\u00a0 Modelo OWL para processamento de sinais .......................................... 100\u00a0\nB.2\u00a0 Modelo do n\u00edvel visual ................................................................................. 101\u00a0\nB.3\u00a0 Modelo do n\u00edvel sem\u00e2ntico .......................................................................... 110\u00a0\nB.3.1\u00a0 Modelo OWL do n\u00edvel sem\u00e2ntico ............................................................. 110\u00a0\nB.3.2\u00a0 Modelo OWL do dom\u00ednio .......................................................................... 110\u00a0\nB.4\u00a0 Modelo de ancoramento simb\u00f3lico ............................................................. 113\u00a0\nB.5\u00a0 Modelos Adicionais ...................................................................................... 115\u00a0\nB.5.1\u00a0 Modelo OWL do sistema InteliStrata ....................................................... 115\u00a0\nB.5.2\u00a0 Modelo OWL de rela\u00e7\u00f5es de ordem (desigualdades) ........................... 118\u00a0\nB.5.3\u00a0 Detectores simb\u00f3licos ................................................................................. 119\u00a0\n\n\n\n \n\n \n\nLISTA DE ABREVIATURAS E SIGLAS \n\nOWL Ontology Web Language \n\nSWRL Semantic Web Rule Language \n\nDL Description Logics \n\nMFS Maximum Flooding Durface \n\nMIS M\u00e1quina de Interpreta\u00e7\u00e3o Sem\u00e2ntica \n\nMIV  M\u00e1quina de Interpreta\u00e7\u00e3o Visual \n\nTWC Transformada Wavelet Cont\u00ednua \n\n \n\n \n\n\n\n \n\n \n\nLISTA DE FIGURAS\n\nFigura 1.1: Exemplo de representa\u00e7\u00e3o em tr\u00eas n\u00edveis sem\u00e2nticos. ....................... 15\u00a0\n\nFigura 1.2: Representa\u00e7\u00e3o gr\u00e1fica de dados num\u00e9ricos. ........................................ 16\u00a0\n\nFigura 1.3: Diferen\u00e7as entre interpreta\u00e7\u00e3o de imagens naturais e gr\u00e1ficos. ........ 18\u00a0\n\nFigura 2.1: Exemplo de interpreta\u00e7\u00e3o por ancoramento simb\u00f3lico. ..................... 23\u00a0\n\nFigura 2.2: Exemplo de hierarquia de composi\u00e7\u00e3o. ................................................ 27\u00a0\n\nFigura 2.3: Passos para extra\u00e7\u00e3o das linhas como primitivas de baixo n\u00edvel de \numa imagem. ............................................................................................ 28\u00a0\n\nFigura 2.4: Representa\u00e7\u00e3o de um martelo em um espa\u00e7o superquadr\u00e1tico e \nconceitual. ................................................................................................. 29\u00a0\n\nFigura 2.5: Fragmento do componente terminol\u00f3gico da abordagem, utilizando \na representa\u00e7\u00e3o gr\u00e1fica de KL-ONE. ..................................................... 30\u00a0\n\nFigura 2.6: Exemplo de representa\u00e7\u00e3o de uma laranja em uma imagem \nutilizando tr\u00eas n\u00edveis sem\u00e2nticos. .......................................................... 32\u00a0\n\nFigura 2.7. Exemplo de mapeamento do conceito Superf\u00edcie El\u00edptica do n\u00edvel \nvisual para o n\u00edvel anal\u00f3gico utilizando conjuntos fuzzy. ................. 34\u00a0\n\nFigura 3.1: Componentes da arquitetura do framework S-Chart. .......................... 40\u00a0\n\nFigura 3.2: Taxonomia de entidades visuais. ........................................................... 42\u00a0\n\nFigura 3.3: Taxonomia de propriedade visuais com defini\u00e7\u00e3o de contradom\u00ednio \nde valores. A especializa\u00e7\u00e3o do dom\u00ednio \u00e9 omitida. ........................... 43\u00a0\n\nFigura 3.4: Exemplo de modelagem de contradom\u00ednios de propriedades visuais.\n .................................................................................................................... 44\u00a0\n\nFigura 3.5: Extens\u00e3o da modelagem de contradom\u00ednios de propriedades visuais.\n .................................................................................................................... 44\u00a0\n\nFigura 3.6: Taxonomia de rela\u00e7\u00f5es espaciais. .......................................................... 45\u00a0\n\nFigura 3.7: Taxonomia de entidades anal\u00f3gicas e rela\u00e7\u00f5es de composi\u00e7\u00e3o. ....... 46\u00a0\n\nFigura 3.8: Taxonomia b\u00e1sica de funcionalidades de processamento de sinal... 49\u00a0\n\nFigura 3.9: Arquitetura do componente de interpreta\u00e7\u00e3o. .................................... 55\u00a0\n\nFigura 4.1: Perfil t\u00edpico em diferentes escalas. Raios gama em destaque. ........... 61\u00a0\n\n\n\n \n\n \n\nFigura 4.2: Express\u00f5es gen\u00e9ricas das fei\u00e7\u00f5es geol\u00f3gicas no perfil. ....................... 64\u00a0\n\nFigura 4.3: Wavelet gussiana 2. ................................................................................. 65\u00a0\n\nFigura 4.4: Transformada wavelet gaussiana 2 em um perfil de raios gama. ...... 66\u00a0\n\nFigura 4.5: Transformada wavelet sawtooth em um perfil de raios gama. ........ 68\u00a0\n\nFigura 5.1: Arquitetura de componentes do sistema InteliStrata. ........................ 71\u00a0\n\nFigura 5.2: Depend\u00eancias entre ontologias OWL do sistema InteliStrata. .......... 72\u00a0\n\nFigura 5.3: Ontologia da Estratigrafia. ...................................................................... 73\u00a0\n\nFigura 5.4: Modelo para representa\u00e7\u00e3o de dados brutos. ...................................... 75\u00a0\n\nFigura 5.5: Componentes de infra-estrutura do sistema InteliStrata. .................. 79\u00a0\n\nFigura 5.6: Componentes de interpreta\u00e7\u00e3o do sistema InteliStrata. ..................... 81\u00a0\n\nFigura 5.7: Interpreta\u00e7\u00e3o de parte do perfil Tenneco Rattlesnake State 2-12. ......... 83\u00a0\n\nFigura 5.8: Compara\u00e7\u00e3o das interpreta\u00e7\u00f5es do especialista e do sistema \nInteliStrata para Se\u00e7\u00e3o 1. ......................................................................... 87\u00a0\n\nFigura 5.9: Compara\u00e7\u00e3o das interpreta\u00e7\u00f5es do especialista e do sistema \nInteliStrata para Se\u00e7\u00e3o 2. ......................................................................... 88\u00a0\n\n\n\n \n\n \n\nLISTA DE TABELAS\n\nTabela 2.1: Tabela de compara\u00e7\u00e3o entre as quatro abordagens estudadas. ........ 36\u00a0\n\nTabela 3.1: Primitivas OWL necess\u00e1rias para representa\u00e7\u00e3o de primitivas \nvisuais do framework S-Chart. .............................................................. 39\u00a0\n\nTabela 3.2: Avalia\u00e7\u00e3o da fun\u00e7\u00e3o fuzzy:associa. .................................................. 54\u00a0\n\nTabela 3.3: Vari\u00e1veis de contexto para interpreta\u00e7\u00e3o sem\u00e2ntica .......................... 56\u00a0\n\n\n\n \n\n \n\n \n\nRESUMO \n\nInterpreta\u00e7\u00e3o sem\u00e2ntica de imagens tem se mostrado uma das fronteiras mais \npromissoras da \u00e1rea de Vis\u00e3o Computacional, especificamente aplicada a inter-\npreta\u00e7\u00e3o imagens. Nas abordagens que est\u00e3o sendo propostas atualmente, co-\nnhecimento visual explicitamente modelado \u00e9 utilizado com algoritmos de ra-\ncioc\u00ednio simb\u00f3lico combinados a algoritmos de processamento de imagem a fim \nde se extrair o conte\u00fado de imagens e associ\u00e1-lo a modelos semanticamente ri-\ncos. \n\nEste trabalho apresenta uma abordagem de interpreta\u00e7\u00e3o sem\u00e2ntica de ima-\ngens especificamente voltada para interpreta\u00e7\u00e3o de gr\u00e1ficos de linhas, chamada \nS-Chart. Ela consiste um conjunto de modelos de conhecimento e algoritmos \nque podem ser instanciados para interpreta\u00e7\u00e3o de gr\u00e1ficos em diversos dom\u00ed-\nnios. Os modelos s\u00e3o representados em tr\u00eas n\u00edveis sem\u00e2nticos e aplicam o con-\nceito de ancoramento simb\u00f3lico (symbol grounding) para mapear as primitivas \nentre os n\u00edveis. Os algoritmos de interpreta\u00e7\u00e3o propostos fazem a intera\u00e7\u00e3o en-\ntre o racioc\u00ednio simb\u00f3lico de alto n\u00edvel e os algoritmos de processamento de si-\nnal para os dados brutos dos gr\u00e1ficos analisados. \n\nPara demonstrar a aplicabilidade do framework S-Chart, foi desenvolvido o \nsistema InteliStrata, uma aplica\u00e7\u00e3o no dom\u00ednio da Geologia, voltada para inter-\npreta\u00e7\u00e3o sem\u00e2ntica de gr\u00e1ficos de perfis de po\u00e7o.  Utilizando a aplica\u00e7\u00e3o, foram \ninterpretados dois perfis de raios gama capturados em po\u00e7os de explora\u00e7\u00e3o, de \nmodo que o sistema identificasse a presen\u00e7a de Sequ\u00eancias Estratigr\u00e1ficas e su-\nperf\u00edcies de inunda\u00e7\u00e3o m\u00e1ximas. Os resultados foram comparados com a inter-\npreta\u00e7\u00e3o de um ge\u00f3logo especialista sobre os mesmos dados. O sistema aponta \nas mesmas sequ\u00eancias j\u00e1 identificadas e oferece outras op\u00e7\u00f5es de interpreta\u00e7\u00e3o \ncompat\u00edveis com as do ge\u00f3logo utilizando os mesmos dados.  \n\nO framework S-Chart tem seus pontos fortes nos seus modelos representa-\n\u00e7\u00e3o de conhecimento visual independentes de dom\u00ednio, que permitem a utiliza-\n\u00e7\u00e3o do mesmo arcabou\u00e7o em diferentes aplica\u00e7\u00f5es e, em especial, no seu mode-\nlo de ancoramento simb\u00f3lico entre primitivas de representa\u00e7\u00e3o. \n\nPalavras-Chave: Interpreta\u00e7\u00e3o Sem\u00e2ntica de Gr\u00e1ficos, Conhecimento Visual, \nModelos de Conhecimento, Ancoramento Simb\u00f3lico, Vis\u00e3o Computacional \n\n\n\n \n\n \n\n \n\nS-Chart: A Framework for Visual Interpretation of Line Charts  \n\nABSTRACT \n\nSemantic image interpretation is one of the most promising frontiers in the \nComputer Vision area, specifically when applied to Image Interpretation. To \nreach semantic interpretation, visual knowledge explicitly represented is ap-\nplied by symbolic reasoning algorithms combined with image processing algo-\nrithms in order to extract the content of the images and associate it with seman-\ntically rich models. \n\nThis work describes the S-Chart approach, a semantic image interpretation \napproach designed for interpretation of line charts. It is structured as a set of \nknowledge models and algorithms that can be instantiated to accomplish chart \ninterpretation in other domains. The models are represented in three semantic \nlevels and apply the concept of symbol grounding in order to map the primi-\ntives between the levels. The interpretation algorithms carry out the interaction \nbetween the symbolic reasoning in the high level, and the signal processing al-\ngorithms in the low level data. \n\nIn order to demonstrate the applicability of the S-Chart framework, we de-\nveloped the InteliStrata system, an application in Geology for the semantic in-\nterpretation of well log profiles.  Using the application, we have interpreted the \ngraphs of two gamma-ray profiles captured in exploration wells, to indicate the \nposition of Stratigraphic Sequences and the maximum flooding surfaces. The \nresults were compared with the interpretation of an experienced geologist using \nthe same data input. The system was able to point the same identified se-\nquences and offered alternative interpretation that were compatible with the \ngeologist interpretation over the data.   \n\nThe S-Chart framework demonstrates its effectiveness on interpretation of \npictorial information in knowledge intensive domains. The stronger points of \nthe approach are its domain independent models for visual knowledge repre-\nsentation and, specially, the application of a symbol grounding model to pro-\nvide a correlation between representation primitives. \n\n \n\nKeywords: Semantic Chart Interpretation, Visual Knowledge, Knowledge \nModels, Symbol Grounding, Computer Vision. \n\n\n\n \n\n \n\n \n\n1 INTRODU\u00c7\u00c3O \n\nEste trabalho descreve um estudo na \u00e1rea de vis\u00e3o computacional. Mais es-\npecificamente, sobre representa\u00e7\u00e3o de conhecimento visual e interpreta\u00e7\u00e3o se-\nm\u00e2ntica de informa\u00e7\u00f5es pictoriais.  \n\nPor muitos anos, um dos principais desafios de pesquisa na computa\u00e7\u00e3o foi \na busca por meios eficientes para armazenagem de grandes quantidade de da-\ndos, textuais e n\u00e3o textuais. Tendo atingido um patamar razo\u00e1vel de desenvol-\nvimento nesta \u00e1rea, o foco passou a ser maneiras eficientes de extrair informa-\n\u00e7\u00f5es \u00fateis dessa imensa quantidade de dados, armazenadas durante anos em \nbases distribu\u00eddas pelo mundo. Em se tratando de dados textuais, \u00e9 significante \no grau de desenvolvimento de ferramentas para extra\u00e7\u00e3o de conte\u00fado, como \nferramentas de busca e descoberta de conhecimento. Da mesma forma, com o \navan\u00e7o nas capacidades de armazenamento, as mesmas bases de dados est\u00e3o \ncada vez mais repletas de dados n\u00e3o-textuais, como imagem, som e v\u00eddeo, cujo \nconte\u00fado tamb\u00e9m deve ser extra\u00eddo e interpretado. No entanto, no caso de da-\ndos pictoriais, foco deste trabalho, ainda s\u00e3o relativamente raros os resultados \nde pesquisas na extra\u00e7\u00e3o e interpreta\u00e7\u00e3o do seu conte\u00fado.  \n\nGrande parte dos trabalhos na \u00e1rea de extra\u00e7\u00e3o e interpreta\u00e7\u00e3o de conte\u00fado \nde imagens que focam em m\u00e9todos puramente num\u00e9ricos e estoc\u00e1sticos, como \nem Gomez &amp; Dactu (2007) e Fan et al. (2005), sem dar a devida aten\u00e7\u00e3o aos as-\npectos relacionado a modelagem sem\u00e2ntica do conte\u00fado. Enquanto tais m\u00e9to-\ndos apresentam resultados positivos em dom\u00ednios visualmente menos comple-\nxos, elas falham em dom\u00ednios onde o acesso ao conte\u00fado das imagens requer \numa grande quantidade de conhecimento visual. Estes s\u00e3o denominados dom\u00ed-\nnios imag\u00edsticos (YIP; ZHAO, 1996), como \u00e9 o caso da medicina (OGIELA; \nTADEUSIEWICZ, 2003), geologia (SANTIN, 2008), vigil\u00e2ncia (WITHAGEN, \n2006) e etc. \n\nPerceber porque os m\u00e9todos de interpreta\u00e7\u00e3o citados falham em dom\u00ednios \nimag\u00edsticos \u00e9 relativamente simples. Embora o exato mecanismo de funciona-\nmento da vis\u00e3o humana (e de outros processos sens\u00f3rios) ainda seja disputado \npela ci\u00eancia (BARSALOU, 1999), \u00e9 poss\u00edvel entend\u00ea-la como um processo que \nenvolve dois componentes: um componente sens\u00f3rio e um cognitivo. O compo-\nnente sens\u00f3rio se encarrega do processamento b\u00e1sico da vis\u00e3o (como detec\u00e7\u00e3o \nde regi\u00f5es, bordas, objetos em movimento e etc.). O componente cognitivo apli-\nca conhecimento visual a respeito do dom\u00ednio onde a cena visualizada se encon-\ntra e, com base nele, interpreta as informa\u00e7\u00f5es sens\u00f3rias em s\u00edmbolos que repre-\n\n\n\n14 \n\n \n\n \n\nsentam o seu conte\u00fado. O fluxo de informa\u00e7\u00f5es entre esses componentes \u00e9 cir-\ncular. Enquanto o componente sens\u00f3rio processa e repassa informa\u00e7\u00f5es visuais \nb\u00e1sicas para o componente cognitivo, este guia o processamento do componen-\nte sens\u00f3rio influindo na sele\u00e7\u00e3o das informa\u00e7\u00f5es que ser\u00e3o processadas. Usual-\nmente, estes dois componentes n\u00e3o existem nas abordagens cl\u00e1ssicas. As t\u00e9cni-\ncas puramente baseadas em processamento de imagens podem ser comparadas \nao componente sens\u00f3rio. Elas produzem interpreta\u00e7\u00f5es baseadas somente nos \ndados brutos das imagens, sem utilizar \u2013 ao menos explicitamente \u2013 conheci-\nmento visual sobre a imagem, como contexto, rela\u00e7\u00f5es espaciais e etc. Esse pro-\ncesso \u00e9 especialmente importante em dom\u00ednios imag\u00edsticos, onde a interpreta-\n\u00e7\u00e3o de dados visuais (imagens, cenas e etc.) \u00e9 fortemente baseada em conheci-\nmento visual sobre o dom\u00ednio. Por exemplo, devido ao treinamento e experi\u00ean-\ncias, m\u00e9dicos conseguem visualizar estruturas em imagens de raios-x que s\u00e3o \ninacess\u00edveis a um leigo no assunto. Isso demonstra o qu\u00e3o necess\u00e1rio \u00e9 haver \numa integra\u00e7\u00e3o entre o processamento de baixo n\u00edvel e mecanismos de simb\u00f3li-\ncos de alto n\u00edvel em sistemas de interpreta\u00e7\u00e3o de imagens. No entanto, os tipos \nde sistemas citados anteriormente (num\u00e9ricos e estoc\u00e1sticos) falham em atingir \neste objetivo, pois n\u00e3o implementam completamente componentes m\u00ednimos da \nvis\u00e3o.  \n\nEvidentemente, as abordagens cl\u00e1ssicas ainda continuam sendo aprimora-\ndas. Por\u00e9m, atualmente \u00e9 poss\u00edvel encontrar sistemas de vis\u00e3o computacional \nque buscam incorporar os dois componentes da vis\u00e3o. Estes sistemas s\u00e3o refe-\nrenciados como sistemas de interpreta\u00e7\u00e3o sem\u00e2ntica de imagens, pois, al\u00e9m do \nprocessamento num\u00e9rico, aplicam conhecimento visual para extrair o conte\u00fado \nde imagens e represent\u00e1-lo em modelos semanticamente ricos. Eles buscam in-\ntegrar modelos de conhecimento visual com algoritmos de processamento de \nimagens, a fim de implementar um mecanismo de interpreta\u00e7\u00e3o autom\u00e1tico \ninspirado na vis\u00e3o humana. Estes modelos de conhecimento visual descrevem \nas entidades existentes no dom\u00ednio das imagens, bem como as suas fei\u00e7\u00f5es vi-\nsuais e inter-rela\u00e7\u00f5es espaciais. Como ser\u00e1 apresentado nos pr\u00f3ximos cap\u00edtulos, \nsistemas de interpreta\u00e7\u00e3o sem\u00e2ntica s\u00e3o mais eficientes para interpreta\u00e7\u00e3o em \ndom\u00ednios imag\u00edsticos. \n\n1.1 Modelos de conhecimento visual em tr\u00eas n\u00edveis \nExistem diversas formas de se representar conhecimento visual. Contudo \n\ngrande parte das abordagens de interpreta\u00e7\u00e3o sem\u00e2ntica utiliza modelos de repre-\nsenta\u00e7\u00e3o em tr\u00eas n\u00edveis sem\u00e2nticos. Cada n\u00edvel sem\u00e2ntico representa em um grau \ndiferente de abstra\u00e7\u00e3o as entidades contidas em uma imagem.  \n\nO n\u00edvel sem\u00e2ntico mais alto \u00e9 o n\u00edvel sem\u00e2ntico propriamente dito. Ele repre-\nsenta as entidades do dom\u00ednio da imagem. Usualmente, os modelos nesse n\u00edvel \nmodelam o conhecimento de dom\u00ednio independe de aspectos visuais.  \n\nO n\u00edvel mais baixo de abstra\u00e7\u00e3o \u00e9 representado pelo n\u00edvel anal\u00f3gico. Ele cap-\ntura informa\u00e7\u00f5es de baixo n\u00edvel de uma imagem, geralmente informa\u00e7\u00f5es es-\nsencialmente quantitativas. O conjunto de primitivas desse n\u00edvel \u00e9 formado por \n\n\n\n15 \n\n \n\n \n\npixel, conjuntos de pixels, c\u00f3digos de cores e outros \u00edndices num\u00e9ricos. Em ge-\nral, esse n\u00edvel faz a integra\u00e7\u00e3o entre o dom\u00ednio dos algoritmos de interpreta\u00e7\u00e3o \nde imagem e o dom\u00ednio simb\u00f3lico. \n\n\u00c9 f\u00e1cil perceber a dist\u00e2ncia sem\u00e2ntica entre esses dois n\u00edveis opostos. H\u00e1 \numa grande diferen\u00e7a de prop\u00f3sito entre informa\u00e7\u00f5es sobre, por exemplo, pixel \ne entidades do dom\u00ednio. Para diminuir este \u201cdegrau\u201d sem\u00e2ntico, existe o n\u00edvel \nvisual intermedi\u00e1rio. Ele expressa o conte\u00fado da imagem em termos de primiti-\nvas visuais gen\u00e9ricas e compartilhadas, como formas geom\u00e9tricas, propriedades \nvisuais e rela\u00e7\u00f5es espaciais. Por exemplo, na Figura 1.1 a mesma entidade \u00e9 ex-\npressa como um morango no n\u00edvel sem\u00e2ntico, uma regi\u00e3o de pixels no n\u00edvel a-\nnal\u00f3gico e como uma forma de cora\u00e7\u00e3o com cor vermelha e textura granulada \nno n\u00edvel visual. Assim, em um processo de interpreta\u00e7\u00e3o simb\u00f3lico dessa ima-\ngem, o algoritmo n\u00e3o interpreta entidades do dom\u00ednio diretamente dos dados \nanal\u00f3gicos da imagem, ele antes interpreta os dados anal\u00f3gicos em inst\u00e2ncias \nde primitivas visuais e, a partir destas, infere as entidades de dom\u00ednio. \n\n \nFigura 1.1: Exemplo de representa\u00e7\u00e3o em tr\u00eas n\u00edveis sem\u00e2nticos. \n\nOutro conceito relacionado aos modelos de conhecimento visual utilizado \nneste trabalho \u00e9 o problema do ancoramento simb\u00f3lico (tradu\u00e7\u00e3o livre do ingl\u00eas \nsymbol grounding problem). Ele est\u00e1 relacionado ao problema da interpreta\u00e7\u00e3o de \num sistema de s\u00edmbolos, que de acordo com Harnad (1990, 1994), est\u00e1 pura-\nmente a cargo do interpretador. Ou seja, o s\u00edmbolo por si s\u00f3 n\u00e3o reflete a sua in-\nterpreta\u00e7\u00e3o. Para que essa interpreta\u00e7\u00e3o seja inerente ao sistema, os s\u00edmbolos \ndevem ser \u201cancorados\u201d em um substrato sens\u00f3rio-motor. Como, no exemplo da \n\n\n\n16 \n\n \n\n \n\nfigura Figura 1.1, o s\u00edmbolo \u201cmorango\u201d s\u00f3 tem real significado se associado com \nas informa\u00e7\u00f5es sens\u00f3rias b\u00e1sicas (pixels, regi\u00f5es de pixels e etc.) representadas \npela imagem no n\u00edvel anal\u00f3gico. Essa quest\u00e3o est\u00e1 diretamente relacionada \u00e0 in-\nterpreta\u00e7\u00e3o sem\u00e2ntica de imagens. \n\nEste trabalho prop\u00f5e um framework para interpreta\u00e7\u00e3o sem\u00e2ntica, que inte-\ngra os conceitos de modelos em tr\u00eas n\u00edveis sem\u00e2nticos e ancoramento simb\u00f3lico. \nEste framework \u00e9 voltado para um tipo espec\u00edfico de dados pictoriais, apresen-\ntado a seguir. \n\n1.2 Interpreta\u00e7\u00e3o sem\u00e2ntica de gr\u00e1ficos \nAs tarefas realizadas por especialistas humanos freq\u00fcentemente incluem a \n\norganiza\u00e7\u00e3o e interpreta\u00e7\u00e3o de todo tipo de dados colhidos do ambiente. Esses \ndados podem variar consideravelmente na sua forma e apresenta\u00e7\u00e3o. Em al-\nguns casos, o especialista que realiza a interpreta\u00e7\u00e3o busca maneiras de projetar \nesses dados complexos de alguma forma que evidencie fei\u00e7\u00f5es importantes. Por \nexemplo, dado um economista que busca identificar tend\u00eancias de varia\u00e7\u00e3o de \n\n \nFigura 1.2: Representa\u00e7\u00e3o gr\u00e1fica de dados num\u00e9ricos. \n\n\n\n17 \n\n \n\n \n\npre\u00e7os de um dado ativo financeiro. Analisando somente os dados brutos da s\u00e9-\nrie temporal desse ativo (ex.: uma tabela simples de pre\u00e7os indexada pelo tem-\npo), o economista dificilmente perceber\u00e1 que tipo de tend\u00eancia ou padr\u00e3o de \ncomportamento que eles apresentam (Figura 1.2a). A proje\u00e7\u00e3o dos dados em \num gr\u00e1fico (ex.: tempo \u00d7 pre\u00e7o) converte a sua varia\u00e7\u00e3o num\u00e9rica em um padr\u00e3o \nvisual, mais f\u00e1cil de ser reconhecido e interpretado. Al\u00e9m disso, em dom\u00ednios \ncomplexos, o processo de interpreta\u00e7\u00e3o visual desse tipo de dado \u00e9 fortemente \ncalcado em conhecimento de dom\u00ednio. Ou seja, padr\u00f5es visuais apresentados \nnos gr\u00e1ficos s\u00e3o reconhecidos e relacionados com entidades do dom\u00ednio onde se \nd\u00e1 a interpreta\u00e7\u00e3o. Este trabalho prop\u00f5e uma forma de capturar este compor-\ntamento de interpreta\u00e7\u00e3o visual realizado por um especialista ao analisar um \ngr\u00e1fico como o exposto na Figura 1.2b. Mais especificamente, ser\u00e1 demonstrado \ncomo algoritmos de processamento num\u00e9rico destas s\u00e9ries de dados podem ser \ncombinados com algoritmos e modelos de racioc\u00ednio simb\u00f3lico. A proposta a-\npresentada utiliza os princ\u00edpios de interpreta\u00e7\u00e3o sem\u00e2ntica, de forma a combi-\nnar mecanismos de extra\u00e7\u00e3o de padr\u00f5es com conhecimento de dom\u00ednio, atrav\u00e9s \nde um modelo de representa\u00e7\u00e3o em tr\u00eas n\u00edveis sem\u00e2nticos. \n\nA necessidade de uma abordagem de interpreta\u00e7\u00e3o sem\u00e2ntica espec\u00edfica pa-\nra gr\u00e1ficos como o da Figura 1.2b pode n\u00e3o parecer t\u00e3o importante em um pri-\nmeiro momento. Entretanto, ela fica evidente quando se compara a natureza \ndos dados que comp\u00f5em um gr\u00e1fico. As abordagens de interpreta\u00e7\u00e3o sem\u00e2ntica \nde imagens usuais focam especificamente na interpreta\u00e7\u00e3o de imagens natu-\nrais1, digitalizadas por c\u00e2meras e outros dispositivos de captura. Nesse caso, os \ndados gerados s\u00e3o representados em uma matriz de duas dimens\u00f5es, com a in-\nforma\u00e7\u00e3o de cor em cada posi\u00e7\u00e3o da matriz (Figura 1.3a). Os algoritmos de pro-\ncessamento de baixo n\u00edvel (segmenta\u00e7\u00e3o, agrupamento e etc.) geralmente anali-\nsam esses dados como se este fosse um sinal de duas dimens\u00f5es espaciais. Ou \nseja, uns conjuntos de valores indexados por duas dimens\u00f5es cont\u00ednuas. J\u00e1 no \ncaso dos gr\u00e1ficos considerados aqui, a s\u00e9rie de dados que carrega a informa\u00e7\u00e3o \nrelevante tem essencialmente uma dimens\u00e3o cont\u00ednua (Figura 1.3b). Essa s\u00e9rie \npode ser analisada como um sinal de uma dimens\u00e3o. Dessa forma, existe uma \nincompatibilidade essencial entre a natureza dos dados processados pelas a-\nbordagens cl\u00e1ssicas de interpreta\u00e7\u00e3o sem\u00e2ntica de imagens e os dados que s\u00e3o \ninterpretados como gr\u00e1ficos. A implica\u00e7\u00e3o disso \u00e9 que novas primitivas devem \nser criadas a fim de que seja poss\u00edvel extrair e representar informa\u00e7\u00f5es de baixo \nn\u00edvel de sinais de uma dimens\u00e3o cont\u00ednua. De forma semelhante, a interpreta-\n\u00e7\u00e3o visual de gr\u00e1ficos requer primitivas visuais espec\u00edficas, que capturem fei-\n\u00e7\u00f5es como tipos de curvas e suas propriedades. Este trabalho prop\u00f5e novas \nprimitivas anal\u00f3gicas e visuais para dar suporte a interpreta\u00e7\u00e3o sem\u00e2ntica de \n\n                                                 \n\n \n\n1 O termo imagem natural se refere aqui a representa\u00e7\u00f5es que capturam cenas de uma reali-\ndade f\u00edsica. Fotos ou mesmo pinturas s\u00e3o exemplos de imagens naturais. \n\n\n\n18 \n\n \n\n \n\ngr\u00e1ficos, em conjunto com alguns algoritmos para processamento e interpreta-\n\u00e7\u00e3o desse tipo de dados. \n\nDeste ponto em diante, o termo \u201cgr\u00e1fico\u201d se refere a proje\u00e7\u00f5es gr\u00e1ficas com \nlinhas como a da Figura 1.2b e o termo \u201csinal\u201d ao conjunto de dados brutos que \nas geram. \n\n0 0 0 00\n\n0 0 10 52\n\n0 9 1 23\n\n00 34 14 85\n\n00 56 65 21\n\n00\n\n21\n\n42\n\n98\n\n12\n\n(i,j)\n\n0 12 34 67 76\n\n(i)\n\nInterpreta\u00e7\u00e3o \nHumana\n\nInterpreta\u00e7\u00e3o\nSem\u00e2ntica\n\n(a) Imagem Natural\n\n(b) Gr\u00e1fico\n\nSinalVisualiza\u00e7\u00e3o\n\nVisualiza\u00e7\u00e3o Sinal\n\n(i,j)\n\n(i,j)\n\n(i) (i)\n\n \nFigura 1.3: Diferen\u00e7as entre interpreta\u00e7\u00e3o de imagens naturais e gr\u00e1ficos. \n\n\n\n19 \n\n \n\n \n\n1.3 Objetivo \nO objetivo principal deste trabalho \u00e9 propor um framework para interpreta-\n\n\u00e7\u00e3o sem\u00e2ntica de gr\u00e1ficos, chamado S-Chart,. Ele apresenta os seguintes com-\nponentes: \n\n\u2022 Um modelo de representa\u00e7\u00e3o de conhecimento visual para suporte a in-\nterpreta\u00e7\u00e3o de gr\u00e1ficos. Este modelo \u00e9 composto por tr\u00eas modelos repre-\nsentando os n\u00edveis sem\u00e2nticos e um modelo de mapeamento entre estes \nn\u00edveis. Cada n\u00edvel apresenta primitivas espec\u00edficas para garantir a repre-\nsenta\u00e7\u00e3o de entidades da imagem em diferentes n\u00edveis de abstra\u00e7\u00e3o. O \nmodelo de mapeamento apresenta primitivas para modelagem da liga\u00e7\u00e3o \nentre os n\u00edveis; \n\n\u2022 Algoritmos de interpreta\u00e7\u00e3o simb\u00f3licos para operacionalizar a interpre-\nta\u00e7\u00e3o sem\u00e2ntica com base nos modelos. Eles coordenam os algoritmos de \nprocessamento de imagem e os integram no processo de racioc\u00ednio sim-\nb\u00f3lico. \n\n1.4 Dom\u00ednio de aplica\u00e7\u00e3o: sistema InteliStrata \nEste trabalho apresenta tamb\u00e9m o sistema InteliStrata, uma implementa\u00e7\u00e3o \n\ndo framework S-Chart voltada para interpreta\u00e7\u00e3o de gr\u00e1ficos no dom\u00ednio da \nGeologia, mas especificamente na Estratigrafia de Sequ\u00eancias. Este sistema de-\nmonstra como os conceitos apresentados no framework S-Chart podem ser im-\nplementados em um sistema real de interpreta\u00e7\u00e3o.  \n\nO sistema InteliStrata representa um dos componentes de um projeto em de-\nsenvolvimento de um sistema de conhecimento para interpreta\u00e7\u00e3o estratigr\u00e1fica \nde bacias sedimentares a partir de dados de po\u00e7o e afloramento. O sistema se \nestrutura a partir de uma ontologia de dom\u00ednio de estruturas sedimentares e \num conjunto de ferramentas de visualiza\u00e7\u00e3o e integra\u00e7\u00e3o de dados. \n\nA tarefa realizada pelo sistema InteliStrata \u00e9 a interpreta\u00e7\u00e3o estratigr\u00e1fica no \ncontexto da Estratigrafia de Sequencias. A Estratigrafia de Sequencias \u00e9 uma \u00e1-\nrea de Geologia que estuda a rela\u00e7\u00e3o entre as varia\u00e7\u00f5es hist\u00f3ricas do n\u00edvel do \nmar na Terra e a deposi\u00e7\u00e3o de sedimentos. A tarefa de interpreta\u00e7\u00e3o consiste \nem analisar os dados sobre os estratos de sedimentos que comp\u00f5em uma bacia \nde deposi\u00e7\u00e3o em uma dada regi\u00e3o e, a partir das suas caracter\u00edsticas e padr\u00f5es \nde empilhamento, inferir os ciclos (\u201csequ\u00eancias\u201d) de varia\u00e7\u00f5es do n\u00edvel no mar \nna regi\u00e3o. Essa informa\u00e7\u00e3o \u00e9 bastante importante para a atividade prospec\u00e7\u00e3o \nde reservat\u00f3rios de petr\u00f3leo.  \n\nA an\u00e1lise dos estratos \u00e9 feita de duas formas. Diretamente, com base em a-\nmostras de rocha extra\u00eddas de po\u00e7os de prospec\u00e7\u00e3o. Ou indiretamente, com ba-\nse em medidas feitas em po\u00e7os de onde n\u00e3o se extraem testemunhos (visto que \neste \u00e9 um processo caro). Uma dessas medidas \u00e9 o perfil de raios gama, uma \nmedida de radioatividade da rocha feita ao longo do po\u00e7o. O resultado \u00e9 um \ngr\u00e1fico semelhante a um eletro-encefalograma. Com base na an\u00e1lise visual des-\n\n\n\n20 \n\n \n\n \n\nse gr\u00e1fico, o ge\u00f3logo tenta inferir fei\u00e7\u00f5es geol\u00f3gicas relativas \u00e0s varia\u00e7\u00f5es do n\u00ed-\nvel do mar, como sequ\u00eancias e parassequ\u00eancias. A interpreta\u00e7\u00e3o considera que \nprogress\u00e3o (avan\u00e7o) ou regress\u00e3o (retrocesso) do n\u00edvel do mar gera registros \ncom desenhos caracter\u00edsticos nos perfis de raios gama. Esse padr\u00e3o visual \u00e9 re-\nconhecido pelo ge\u00f3logo quando realiza a interpreta\u00e7\u00e3o.  \n\nA tarefa de interpreta\u00e7\u00e3o do sistema InteliStrata \u00e9, com base em um perfil de \nraios gama, sugerir interpreta\u00e7\u00f5es de sequ\u00eancias e parassequ\u00eancias. Uma se-\nqu\u00eancia sedimentar \u00e9 uma sucess\u00e3o de estratos geneticamente relacionados \n(formados na mesma \u00e9poca pelos mesmos processos sedimentares) cujos limites \ns\u00e3o definidos em resposta a uma queda relativa do n\u00edvel do mar. Enquanto pa-\nrassequ\u00eancias s\u00e3o os blocos de constru\u00e7\u00e3o das sequ\u00eancias, limitados por oscila-\n\u00e7\u00f5es menores do n\u00edvel do mar (DELLA F\u00c1VERA, 2001; VAN WAGONER et al., \n1990). \n\nUm objetivo secund\u00e1rio do sistema InteliStrata \u00e9 demonstrar a implementa-\n\u00e7\u00e3o do framework S-Chart com a utiliza\u00e7\u00e3o de formalismos e ferramentas off the \nshelf. Por exemplo, para representa\u00e7\u00e3o dos modelos de conhecimento visual que \ncomp\u00f5es os n\u00edveis sem\u00e2nticos s\u00e3o utilizadas linguagens padr\u00e3o da Web Sem\u00e2n-\ntica. Isso permite que ferramentas padronizadas sejam utilizadas na implemen-\nta\u00e7\u00e3o do sistema. \n\n1.5 Organiza\u00e7\u00e3o dos cap\u00edtulos \nO cap\u00edtulo 2 aprofunda a discuss\u00e3o dos conceitos relacionados \u00e0 interpreta-\n\n\u00e7\u00e3o sem\u00e2ntica de imagens, j\u00e1 descritos anteriormente. Ela tamb\u00e9m faz uma an\u00e1-\nlise de alguns frameworks para interpreta\u00e7\u00e3o j\u00e1 existentes na literatura e os \ncompara. \n\nO cap\u00edtulo 3 apresenta e detalha o framework S-Chart. A sua arquitetura de \nmodelos de conhecimento visual \u00e9 apresentada, bem como os modelos de ma-\npeamento entre n\u00edveis sem\u00e2nticos. Ao fim do cap\u00edtulo s\u00e3o apresentados e deta-\nlhados os algoritmos de interpreta\u00e7\u00e3o simb\u00f3lica que operacionalizam a inter-\npreta\u00e7\u00e3o sem\u00e2ntica. \n\nO cap\u00edtulo 4 apresenta uma breve discuss\u00e3o sobre a Estratigrafia de Sequ\u00ean-\ncias, dom\u00ednio de aplica\u00e7\u00e3o deste trabalho. \n\nO cap\u00edtulo 5 descreve o sistema  InteliStrata. \u00c9 demonstrado como o frame-\nwork S-Chart pode ser implementado em um sistema real para interpreta\u00e7\u00e3o de \nexpress\u00f5es gr\u00e1ficas de perfis de po\u00e7o na estratigrafia de sequ\u00eancias. Aspectos de \nsistema n\u00e3o abordados pelo framework s\u00e3o desenvolvidos nesse cap\u00edtulo. Ao \nfinal do cap\u00edtulo s\u00e3o analisados dois casos de interpreta\u00e7\u00e3o de perfil utilizando \no sistema e confrontando seus resultados com a interpreta\u00e7\u00e3o dos mesmos per-\nfis pelo especialista no dom\u00ednio.  \n\nNo cap\u00edtulo 6 s\u00e3o apresentadas as conclus\u00f5es e poss\u00edveis trabalhos futuros \npara extens\u00e3o dos conceitos apresentados. \n\n\n\n \n\n \n\n \n\n2 INTERPRETA\u00c7\u00c3O SEM\u00c2NTICA DE IMAGENS \n\nO principal desafio dos sistemas de vis\u00e3o computacional \u00e9 interpretar corre-\ntamente o conte\u00fado de imagens. Um sistema desse tipo deve ter como sa\u00edda \numa descri\u00e7\u00e3o, formal ou n\u00e3o, dos objetos presentes em uma imagem, bem co-\nmo a sua classifica\u00e7\u00e3o e suas propriedades visuais. Por exemplo, um sistema de \nvis\u00e3o computacional para interpreta\u00e7\u00e3o de imagens de sat\u00e9lite pode ter como \nsa\u00edda quais artefatos de uma dada imagem s\u00e3o casas, quais s\u00e3o carros e quais \ns\u00e3o estradas, al\u00e9m da maneira como esses objetos est\u00e3o relacionados topologi-\ncamente.  \n\nAt\u00e9 hoje foram pesquisadas diversas formas de solu\u00e7\u00e3o para o problema de \ninterpreta\u00e7\u00e3o de imagens. A primeira gera\u00e7\u00e3o de sistemas de interpreta\u00e7\u00e3o bus-\ncava solucionar o problema de interpreta\u00e7\u00e3o atrav\u00e9s da aplica\u00e7\u00e3o simples de al-\ngoritmos processamento de imagens para reconhecimento de formas geom\u00e9tri-\ncas. No entanto, essas abordagens se mostraram ineficazes ao tentar replicar o \ncomportamento humano na interpreta\u00e7\u00e3o em dom\u00ednios com tarefas de grande \ncomplexidade visual, como geologia e medicina. Nesses dom\u00ednios, especialistas \nhumanos utilizam uma grande quantidade de conhecimento de dom\u00ednio \u2013 ge-\nralmente impl\u00edcito \u2013 para realizar a interpreta\u00e7\u00e3o. Para uma pessoa leiga, os ar-\ntefatos presentes em uma imagem de Raios-X podem n\u00e3o fazer sentido algum, \nenquanto que para um m\u00e9dico, esses artefatos representam \u00f3rg\u00e3os internos e \nposs\u00edveis doen\u00e7as. O m\u00e9dico sabe quais as fei\u00e7\u00f5es visuais que um \u00f3rg\u00e3o ou uma \ndoen\u00e7a apresentam em uma imagem de Raio-X. Ele utiliza esse conhecimento \nvisual para interpretar os artefatos da imagem em informa\u00e7\u00f5es significativas. \nAbordagens puramente baseadas em processamento de imagens n\u00e3o conse-\nguem capturar esse comportamento de interpreta\u00e7\u00e3o, pois carecem de uma re-\npresenta\u00e7\u00e3o expl\u00edcita do conhecimento visual do dom\u00ednio onde est\u00e3o sendo a-\nplicados, que possa guiar a solu\u00e7\u00e3o do problema (MAILLOT, 2005).  \n\nA partir da d\u00e9cada de 80, come\u00e7ou o surgimento dos primeiros trabalhos u-\nnindo conceitos de representa\u00e7\u00e3o de conhecimento visual com t\u00e9cnicas de pro-\ncessamento de imagens (CREVIER; LEPAGE, 1997), dando origem aos primei-\nros sistemas de interpreta\u00e7\u00e3o sem\u00e2ntica de imagens, como os sistemas SIGMA e \nACRONYM (MATSUYAMA, 1987). Esses sistemas buscavam imitar o compor-\ntamento de interpreta\u00e7\u00e3o de imagens de um especialista em dom\u00ednios visual-\nmente complexos. \n\nUm sistema de interpreta\u00e7\u00e3o sem\u00e2ntica integra algoritmos de processamento \nde imagem com mecanismos de racioc\u00ednio simb\u00f3lico, com o intuito de capturar \n\n\n\n22 \n\n \n\n \n\no conte\u00fado de uma imagem atrav\u00e9s um modelo simb\u00f3lico semanticamente rico. \nEnquanto os algoritmos de processamento extraem as fei\u00e7\u00f5es visuais b\u00e1sicas da \nimagem (bordas, regi\u00f5es, cores, texturas e etc.), os mecanismos de racioc\u00ednio \nsimb\u00f3lico combinam e interpretam tais fei\u00e7\u00f5es de acordo com um modelo que \nrepresente conhecimento visual do dom\u00ednio onde a imagem se insere. Esse mo-\ndelo define as entidades que podem estar presentes na imagem e os seus inter-\nrelacionamentos. O resultado da interpreta\u00e7\u00e3o \u00e9 um modelo simb\u00f3lico, seman-\nticamente rico, do conte\u00fado da imagem. Uma vez capturado, esse conte\u00fado po-\nde ser disponibilizado para consulta ou outros tipos de infer\u00eancias de mais alto \nn\u00edvel. \n\nO principal componente do processo de interpreta\u00e7\u00e3o sem\u00e2ntica \u00e9 o modelo \nde conhecimento visual que lhe d\u00e1 suporte. Esse modelo explicita as entidades \ndo dom\u00ednio de discurso das imagens, bem como as suas inter-rela\u00e7\u00f5es espaciais, \nmereol\u00f3gicas, taxon\u00f4micas e outras rela\u00e7\u00f5es pertinentes ao dom\u00ednio, visuais ou \nn\u00e3o. Por exemplo, um modelo de conhecimento visual para interpreta\u00e7\u00e3o de \nimagens de sat\u00e9lite certamente conter\u00e1 os conceitos como Casa, Estrada e Au?\ntom\u00f3vel, em conjunto com rela\u00e7\u00f5es espaciais como aoLadoDe, sobre e pr\u00f3xi?\nmoDe. Modelos de conhecimento visual como este d\u00e3o algumas vantagens aos \nsistemas de interpreta\u00e7\u00e3o. Em primeiro lugar, eles explicitam o conhecimento \nvisual utilizado no sistema, facilitando a sua depura\u00e7\u00e3o e manuten\u00e7\u00e3o. Eles \ntamb\u00e9m ajudam a melhorar o resultado do processo de interpreta\u00e7\u00e3o como um \ntodo, uma vez que podem guiar os algoritmos de processamento de baixo n\u00edvel. \nNo mesmo exemplo, se uma regi\u00e3o da imagem foi identificada como uma ins-\nt\u00e2ncia de Estrada, e se o modelo especifica que casas est\u00e3o sempre pr\u00f3ximas de \nestradas, ent\u00e3o o mecanismo de interpreta\u00e7\u00e3o pode buscar por fei\u00e7\u00f5es visuais \nde casas pr\u00f3ximas a regi\u00e3o classificada como uma estrada. \n\nEm geral, os modelos de conhecimento tentam proporcionar alguma forma \nde ancoramento simb\u00f3lico (HARNAD, 1990, 1994) das entidades do dom\u00ednio. Sis-\ntemas que utilizam esse conceito partem do princ\u00edpio que cada s\u00edmbolo do do-\nm\u00ednio \u00e9 reconhecido no ambiente dado algum padr\u00e3o b\u00e1sico de impulsos nas \nsuas entradas anal\u00f3gicas. Ou seja, as entidades de alto n\u00edvel sem\u00e2ntico s\u00e3o \u201can-\ncoradas\u201d nas fei\u00e7\u00f5es de baixo n\u00edvel que indicam a sua detec\u00e7\u00e3o. Assim, uma vez \nque essas fei\u00e7\u00f5es s\u00e3o reconhecidas nas entradas, o sistema pode assinalar a de-\ntec\u00e7\u00e3o da entidade representada pelo s\u00edmbolo. No caso de sistemas de interpre-\nta\u00e7\u00e3o de imagens, as entidades que devem ser reconhecidas das imagens s\u00e3o \nmapeadas nas fei\u00e7\u00f5es visuais que possibilitam a sua detec\u00e7\u00e3o, como uma regi\u00e3o \nde pixels com alguma caracter\u00edstica espec\u00edfica.  \n\nO ancoramento simb\u00f3lico \u00e9 importante para a interpreta\u00e7\u00e3o sem\u00e2ntica, pois \npermite a interpreta\u00e7\u00e3o seja feita em dois sentidos. No sentido top-down, as en-\ntidades de alto n\u00edvel indicam aos algoritmos de processamento quais s\u00e3o as fei-\n\u00e7\u00f5es visuais espec\u00edficas que est\u00e3o esperando. Os algoritmos buscam especifica-\nmente por essas fei\u00e7\u00f5es e indicam a sua presen\u00e7a ou n\u00e3o. Caso positivo, a enti-\ndade visual pode ser indicada como reconhecida. No sentido bottom-up, em \nprimeiro lugar os algoritmos de processamento extraem todas as fei\u00e7\u00f5es poss\u00ed-\n\n\n\n23 \n\n \n\n \n\nveis da imagem. Ap\u00f3s isso, as fei\u00e7\u00f5es extra\u00eddas s\u00e3o analisadas em busca das fei-\n\u00e7\u00f5es esperadas por cada uma das entidades do dom\u00ednio. Nos casos onde h\u00e1 cor-\nrespond\u00eancia, as entidades s\u00e3o marcadas como reconhecidas. No entanto, em \nmuitas das abordagens de interpreta\u00e7\u00e3o sem\u00e2ntica s\u00e3o utilizados os dois senti-\ndos de interpreta\u00e7\u00e3o, iterativamente. Por exemplo, uma dada imagem de sat\u00e9li-\nte \u00e9 analisada em um programa de processamento de imagens (Figura 2.1a), re-\nsultando na extra\u00e7\u00e3o de duas regi\u00f5es de pixels. A aplica\u00e7\u00e3o inicial de uma in-\nterpreta\u00e7\u00e3o bottom-up interpreta os dois segmentados como os conceitos Estra?\nda e Rio em um modelo simb\u00f3lico (Figura 2.1b). Esse mesmo modelo define \nque na superposi\u00e7\u00e3o de entidades do tipo Estrada e Rio pode haver uma enti-\ndade do tipo Ponte. Ent\u00e3o o mecanismo de interpreta\u00e7\u00e3o, em uma interpreta\u00e7\u00e3o \nno sentido top-down, ajusta o foco dos algoritmos de processamento de imagem \npara buscar uma entidade com as caracter\u00edsticas visuais da entidade Ponte no \ncruzamento das duas regi\u00f5es segmentadas anteriormente (Figura 2.1c). Se estas \ncaracter\u00edsticas visuais forem encontradas, ent\u00e3o a interpreta\u00e7\u00e3o de Ponte \u00e9 ob-\ntida. \n\n \nFigura 2.1: Exemplo de interpreta\u00e7\u00e3o por ancoramento simb\u00f3lico.  \n\n(a) \n\n(b) \n(c) \n\n\n\n24 \n\n \n\n \n\nGeralmente, uma vez que o s\u00edmbolo \u00e9 reconhecido em uma imagem, o algo-\nritmo realiza um mapeamento expl\u00edcito entre ele e as fei\u00e7\u00f5es visuais que lhe de-\nram origem. Isso prov\u00ea uma maneira do mecanismo de interpreta\u00e7\u00e3o \u2013 ou o seu \nusu\u00e1rio \u2013 revisitarem as informa\u00e7\u00f5es que deram origem a uma dada interpreta-\n\u00e7\u00e3o. \n\nPor fim, a interpreta\u00e7\u00e3o sem\u00e2ntica de imagens permite associar significado \naos dados visuais anal\u00f3gicos, atrav\u00e9s de modelos conceituais que representam o \nconhecimento contido nas imagens analisadas. Esses modelos conceituais d\u00e3o \nsuporte aos algoritmos de processamento de imagens e possibilitam a utiliza\u00e7\u00e3o \ndo conhecimento visual capturado na solu\u00e7\u00e3o de problemas e em mecanismos \nde infer\u00eancia para suporte a tomada de decis\u00e3o. \n\n2.1 Representa\u00e7\u00e3o de Conhecimento Visual \nUma vez que o conhecimento visual tem um papel fundamental na interpre-\n\nta\u00e7\u00e3o sem\u00e2ntica de imagens, diversos trabalhos focam em encontrar maneiras \nde incorpor\u00e1-lo em sistemas de vis\u00e3o computacional de forma efetiva. Prova-\nvelmente, o maior desafio, do ponto de vista de sistema, \u00e9 represent\u00e1-lo de for-\nma expl\u00edcita em algum tipo de estrutura com alto n\u00edvel sem\u00e2ntico e que d\u00ea su-\nporte a todo o processo de racioc\u00ednio visual.  \n\nComo apontado por Hudelot e colegas (2005), a an\u00e1lise de sistemas de vis\u00e3o \ncomputacional baseados em conhecimento visual (VISIONS2, SIGMA3, \nPROGAL (OSSOLA et al., 1996), MESSIE4 e etc.) induz a conclus\u00e3o que os seus \nmodelos de representa\u00e7\u00e3o s\u00e3o estruturados em pelo menos tr\u00eas n\u00edveis de abs-\ntra\u00e7\u00e3o (Figura 1.1): um baixo n\u00edvel anal\u00f3gico, um alto n\u00edvel sem\u00e2ntico e um n\u00edvel \nvisual intermedi\u00e1rio. Cada n\u00edvel busca tratar os aspectos de representa\u00e7\u00e3o de \num tipo espec\u00edfico de informa\u00e7\u00e3o.  \n\nO n\u00edvel sem\u00e2ntico, mais alto na escala de abstra\u00e7\u00e3o, representa as entidades \ndo dom\u00ednio que podem ser reconhecidas na imagem. O n\u00edvel anal\u00f3gico engloba \nas informa\u00e7\u00f5es ligadas diretamente aos pixels que comp\u00f5em a imagem, como \nbordas, valores de cor e regi\u00f5es. Em geral, informa\u00e7\u00f5es no n\u00edvel anal\u00f3gico s\u00e3o \nobtidas diretamente por algoritmos de processamento de imagem. O mapea-\nmento intermedi\u00e1rio entre os dois \u00e9 representado pelo n\u00edvel visual. Ele \u00e9 com-\nposto por primitivas visuais gen\u00e9ricas, como formas geom\u00e9tricas e rela\u00e7\u00f5es to-\npol\u00f3gicas  \n\nAs entidades de cada n\u00edvel s\u00e3o mapeadas para uma ou mais entidades do \nn\u00edvel inferior. Primitivas do n\u00edvel sem\u00e2ntico s\u00e3o definidas em termos de primi-\n\n                                                 \n\n \n2 (HANSON; RISEMAN, 1978). \n3 (MATSUYAMA, 1987). \n4 (SANDAKLY; GIRAUDON, 1994). \n\n\n\n25 \n\n \n\n \n\ntivas no n\u00edvel visual e essas, por sua vez, s\u00e3o definidas em termos de primitivas \nno n\u00edvel anal\u00f3gico. De fato, a exist\u00eancia de um modelo intermedi\u00e1rio especifi-\ncamente constru\u00eddo para defini\u00e7\u00e3o de aspectos visuais de entidades do dom\u00ednio \ntraz diversas vantagens a sistemas de interpreta\u00e7\u00e3o. A primeira \u00e9 a diminui\u00e7\u00e3o \ndo grande lacuna sem\u00e2ntica (semantic gap) entre n\u00edvel anal\u00f3gico e o n\u00edvel visual, \na fim de flexibilizar o processo de interpreta\u00e7\u00e3o e torn\u00e1-lo mais imune a ru\u00eddos \nadvindos do processamento inicial nos dados anal\u00f3gicos (CHELLA et al., 1997). \nEle tamb\u00e9m melhora a comunica\u00e7\u00e3o do sistema com o usu\u00e1rio, pois o ser hu-\nmano utiliza informa\u00e7\u00f5es no n\u00edvel visual para representar fei\u00e7\u00f5es visuais e se \ncomunicar. Em especial, \u201cespecialistas em diferentes dom\u00ednios freq\u00fcentemente \nusam e trocam um vocabul\u00e1rio visual gen\u00e9rico para descrever conceitos sem\u00e2n-\nticos nos seus dom\u00ednios\u201d (HUDELOT et al., 2005). Por fim, o n\u00edvel visual permi-\nte uma maior independ\u00eancia entre a representa\u00e7\u00e3o e a aplica\u00e7\u00e3o, o que propor-\nciona maior reusabilidade dos modelos gerados. \n\nA seguir s\u00e3o apresentados alguns trabalhos encontrados na literatura que u-\ntilizam os conceitos apresentados at\u00e9 aqui. \n\n2.2 Abordagens de interpreta\u00e7\u00e3o sem\u00e2ntica \nEm geral, os projetos de sistemas de interpreta\u00e7\u00e3o sem\u00e2ntica de imagens a-\n\npresentam as suas propostas de representa\u00e7\u00e3o de conhecimento visual dentro \nde um framework completo, incluindo mecanismos de infer\u00eancia visual (anco-\nramento sem\u00e2ntico, racioc\u00ednio simb\u00f3lico e etc.) e algoritmos de processamento \nde imagens. \n\nNas se\u00e7\u00f5es seguintes, ser\u00e3o descritas as quatro abordagens de representa\u00e7\u00e3o \nde conhecimento visual que melhor se encaixam na vis\u00e3o de representa\u00e7\u00e3o em \ntr\u00eas n\u00edveis sem\u00e2nticos. Em cada uma ser\u00e1 dada uma vis\u00e3o geral das caracter\u00edsti-\ncas da abordagem e uma descri\u00e7\u00e3o mais detalhada de cada n\u00edvel de representa-\n\u00e7\u00e3o. Ao fim, as abordagens s\u00e3o confrontadas. \n\n2.2.1 Abordagem 1: Agregados \nA abordagem apresentada em  Neumann &amp; M\u00f6ller (2008) foca na utiliza\u00e7\u00e3o \n\nde l\u00f3gica de descri\u00e7\u00e3o (DL) para representa\u00e7\u00e3o de conhecimento e sistema de \nracioc\u00ednio pra interpreta\u00e7\u00e3o de cenas. Inicialmente criada para monitora\u00e7\u00e3o de \ntr\u00e1fego, a abordagem tamb\u00e9m inclui primitivas para representa\u00e7\u00e3o de objetos \nao longo do tempo. \n\nOs construtos b\u00e1sicos de modelagem s\u00e3o os agregados (do ingl\u00eas aggregates), \nque representam conceitos presentes nas imagens atrav\u00e9s da agrega\u00e7\u00e3o das suas \npartes, satisfazendo restri\u00e7\u00f5es espa\u00e7o-temporais. Os agregados s\u00e3o mapeados \npara a representa\u00e7\u00e3o de baixo n\u00edvel (pixels) atrav\u00e9s da GSD (Geometrical Scene \nDescription). GSDs s\u00e3o \u201cdescri\u00e7\u00f5es quantitativas de propriedades visuais de ce-\nnas que variam no tempo\u201d (JARKE et al., 1989) no n\u00edvel visual. Os autores ainda \napontam que os servi\u00e7os de infer\u00eancia comuns de l\u00f3gica descritiva (verifica\u00e7\u00e3o \n\n\n\n26 \n\n \n\n \n\nde consist\u00eancias, classifica\u00e7\u00e3o e etc.) podem ser utilizados em modelos sem\u00e2nti-\ncos de imagens representados com esse paradigma. \n\n2.2.1.1 N\u00edvel Sem\u00e2ntico \n\nAs principais entidades dessa abordagem s\u00e3o os agregados, utilizados para \nrepresentar situa\u00e7\u00f5es e objetos no modelo conceitual. Um agregado \u00e9 basica-\nmente um conceito definido pela descri\u00e7\u00e3o das partes que o comp\u00f5e. Ele ainda \ncont\u00e9m um conjunto de restri\u00e7\u00f5es espa\u00e7o-temporais que definem as condi\u00e7\u00f5es e \no contexto de ocorr\u00eancia do agregado (e as suas partes) na imagem. Uma parte \ntamb\u00e9m pode ser um agregado, o que induz uma estrutura mereol\u00f3gica dos \nconceitos. Al\u00e9m disso, os agregados podem constituir uma hierarquia taxon\u00f4-\nmica.  \n\nNessa representa\u00e7\u00e3o, os objetos mais b\u00e1sicos de uma cena s\u00e3o agregados es-\npeciais, compostos por: um objeto f\u00edsico ou um \u201ccorpo\u201d no mundo 3D; uma \u201cvi-\ns\u00e3o\u201d que constitui a evid\u00eancia visual do objeto no campo de vis\u00e3o da c\u00e2mera. \nAtrav\u00e9s dessas duas propriedades, as entidades de alto n\u00edvel s\u00e3o mapeadas pa-\nra uma representa\u00e7\u00e3o no n\u00edvel visual.  \n\nOs autores defendem que o n\u00edvel sem\u00e2ntico pode ser representado com uma \nl\u00f3gica de descri\u00e7\u00e3o ALCF(D), pois ela \u00e9 o suficiente para atender os requisitos de \nrepresenta\u00e7\u00e3o dos agregados. Al\u00e9m disso, a representa\u00e7\u00e3o em DL permite que \nse utilizem ferramentas de infer\u00eancia da DL (como RACER5 ou FaCT++6) para \nchecagem de consist\u00eancia e infer\u00eancia sobre os modelos visuais. \u00a0\n\n2.2.1.2 N\u00edvel Visual \n\nA abordagem n\u00e3o especifica claramente como \u00e9 constitu\u00eddo o n\u00edvel visual de \nrepresenta\u00e7\u00e3o. Segundo apresentado Neumann e seus colegas, a representa\u00e7\u00e3o \nintermedi\u00e1ria se d\u00e1 pela GSD (Geometrical Scene Description). J\u00e1 segundo \n(HERZOG, 1995), a GSD tem o objetivo de representar a cena original sem ne-\nnhuma perda de informa\u00e7\u00e3o. Ela descreve, para cada frame de uma cena, dados \nde posi\u00e7\u00e3o e orienta\u00e7\u00e3o dos objetos, bem como seu modelo tridimensional. \n\nA constru\u00e7\u00e3o de uma descri\u00e7\u00e3o GSD pode ser autom\u00e1tica ou manual. Por \nexemplo, o sistema VITRA descrito por Herzog, consegue reconstruir automati-\ncamente modelos tridimensionais de carros, mas o cen\u00e1rio de fundo deve ser \nconstru\u00eddo manualmente.  \n\n2.2.1.3 N\u00edvel anal\u00f3gico \n\nEmbora citado, nenhum dos trabalhos estudados descrevem exatamente \ncomo se d\u00e1 o mapeamento do GSD para o pixel.  Sabe-se apenas que os dados \n\n                                                 \n\n \n5 http://www.racer-systems.com/ \n6 http://owl.man.ac.uk/factplusplus/ \n\n\n\n27 \n\n \n\n \n\nbrutos s\u00e3o mapeados por algoritmos de processamento de imagens que resul-\ntam em descri\u00e7\u00f5es GSD. \n\n2.2.2 Abordagem 2: Abdu\u00e7\u00e3o \nInicialmente proposta por Murray Shanahan e colegas em (2004; 1996) para \n\naplica\u00e7\u00e3o em rob\u00f3tica, a abordagem abdutiva consiste em um modelo l\u00f3gico de \npercep\u00e7\u00e3o visual. Ele \u00e9 caracterizado da seguinte forma: seja ? uma teoria que \ndefine as rela\u00e7\u00f5es entre os objetos de uma cena e as informa\u00e7\u00f5es de baixo n\u00edvel \nque lhes d\u00e3o origem. Ent\u00e3o, dada uma conjun\u00e7\u00e3o ? de f\u00f3rmulas representando \numa cole\u00e7\u00e3o de informa\u00e7\u00f5es imag\u00edsticas de baixo n\u00edvel, o papel da percep\u00e7\u00e3o \nvisual \u00e9 encontrar uma conjun\u00e7\u00e3o de f\u00f3rmulas ? tal que, \n\n???  ? ?. \n\nEm outras palavras, a abordagem define, dentro de um contexto l\u00f3gico, o \nancoramento sem\u00e2ntico onde o modelo conceitual ? \u00e9 mapeado para os dados \nsensoriais ? atrav\u00e9s do mapeamento definido em ?. A tarefa de um sistema de \npercep\u00e7\u00e3o visual \u00e9 encontrar o conjunto ? que melhor explica os dados sensori-\nais em ?. \n\nO modelo de infer\u00eancia descrita por Shanahan e colegas utiliza as aborda-\ngens top-down e bottom-up. O algoritmo infere diversos poss\u00edveis conjuntos de \nhip\u00f3teses de explica\u00e7\u00e3o ? e escolhe, com base em um c\u00e1lculo de probabilidade, \nqual a hip\u00f3tese que melhor explica a imagem. \n\n2.2.2.1 N\u00edvel Sem\u00e2ntico \n\nEmbora Shanahan n\u00e3o defina explicitamente um n\u00edvel sem\u00e2ntico, Cohn e co-\nlegas (2003) sugerem, dentro do mesmo paradigma, que o modelo conceitual ? \ndeve estar definido como uma hierarquia mereol\u00f3gica, como apresentado no \nexemplo da Figura 2.2. \n\n \nFigura 2.2: Exemplo de hierarquia de composi\u00e7\u00e3o (adaptado de (COHN, \n\nANTHONY G. et al., 2003)). \n\nSala\n\nMesa\nCh\u00e3o\n\nCadeira\n\nEstante\n\nDoc1 Doc2 ... Tampo\n\nEncosto\n\nAssento\nRodas\n\nEstrutura Livros\n\nLivro VerdeLivro Vermelho\n\nRegi\u00e3o Azul\n\nRegi\u00e3o Preta\n\nRegi\u00e3o Cinza\n\npixel(a,b) pixel(c,h) pixel(f,e)\n\n(a)\n\n(b)\n\n\n\n28 \n\n \n\n \n\n2.2.2.2 N\u00edvel Visual \n\nO n\u00edvel Visual \u00e9 definido como um conjunto de axiomas l\u00f3gicos de primeira \nordem contidos no conjunto ?. Esses axiomas relacionam primitivas de baixo \nn\u00edvel, como retas e pontos, com primitivas do n\u00edvel visual, como regi\u00f5es e vo-\nlumes. Al\u00e9m disso, uma peculiaridade da abordagem \u00e9 a possibilidade de ma-\npear ru\u00eddo identificado pelos algoritmos de baixo n\u00edvel.  \n\nPor exemplo, dada uma primitiva de baixo n\u00edvel Line(w,p1,p2), que identifica \numa reta w entre os pontos p1 e p2. Um conjunto de axiomas v\u00e1lidos no n\u00edvel vi-\nsual seria (copiado do original): \n\n( )[ ] ( ) ( )[ ]\n( ) ( )[ ] ( ) ( )[ ]\n\n( )[ ] ( )\n\n1 2 1 2\n\n1 2 1 2 1 2 1 2\n\n1 2 1 2\n\nRe p , p  Line w, p , p  r gion r SideOf w, r\nSideOf w , r SideOf w ,r w w Parallel w , w   Joins w , w\n p , p  Line w, p , p   Noise w\n\n? ? ? ?\n? ? ? ? ?\n\n? ?\n \n\nO primeiro axioma explica a presen\u00e7a de uma linha vis\u00edvel pela presen\u00e7a de \numa regi\u00e3o vis\u00edvel, enquanto a segunda linha define uma regi\u00e3o com quatro la-\ndos. A abordagem abdutiva tamb\u00e9m permite a modelagem de ru\u00eddo no n\u00edvel \nintermedi\u00e1rio. Assim, inst\u00e2ncias de primitivas do baixo n\u00edvel, como Line, que \nn\u00e3o s\u00e3o mapeadas por nenhum axioma no n\u00edvel visual podem ser interpretadas \ncomo ru\u00eddo. \n\nCohn e colegas tamb\u00e9m descrevem o mapeamento para o n\u00edvel sem\u00e2ntico \ncomo uma Hierarquia Observacional, como no mapeamento do objeto Encosto \nna figura Figura 2.2a. O mapeamento para o n\u00edvel anal\u00f3gico \u00e9 descrito por uma \nHierarquia Sensorial, como no exemplo da Figura 2.2b, onde uma entidade vi-\nsual e descrita em termos de pixels por pixels em determinadas coordenadas do \nespa\u00e7o. \n\n2.2.2.3 N\u00edvel anal\u00f3gico \n\nO n\u00edvel anal\u00f3gico da abordagem abdutiva \u00e9 composto por primitivas sim-\nples como ponto ou linha, extra\u00eddos da imagem por algoritmos de processa-\nmento de imagem. O n\u00edvel anal\u00f3gico raramente conter\u00e1 o dado bruto em si.  \n\n \nFigura 2.3: Passos para extra\u00e7\u00e3o das linhas como primitivas de baixo n\u00edvel de \n\numa imagem (SHANAHAN, MURRAY; RANDELL, DAVID, 2004). \n\nPor exemplo, em Shanahan e colegas (2004), imagens capturadas por um ro-\nb\u00f4 s\u00e3o processadas por um algoritmo de detec\u00e7\u00e3o de bordas baseado no opera-\ndor Sobel (Figura 2.3). Ent\u00e3o um algoritmo seguidor de bordas \u00e9 utilizado para \nextrair as inst\u00e2ncias de primitivas de baixo n\u00edvel, como: \n\n\n\n29 \n\n \n\n \n\n[ ] [ ]( )\n[ ] [ ]( )\n\n1, 238 157 241 147\n2 240 159 247 157\n\nLine , , ,\nLine , , , ,\n\n \n\nA partir dessas primitivas \u00e9 poss\u00edvel inferir regi\u00f5es e conceitos de maior n\u00ed-\nvel sem\u00e2ntico nos n\u00edveis superiores, como descrito na se\u00e7\u00e3o 2.2.2.2. \n\n2.2.3 Abordagem 3: Espa\u00e7os Conceituais \nA Teoria dos Espa\u00e7os Conceituais, apresentadas por Peter G\u00e4rdenfors (2004), \n\napresenta o conceito de espa\u00e7o conceitual, um espa\u00e7o m\u00e9trico onde entidades s\u00e3o \ncaracterizadas por um n\u00famero de dimens\u00f5es qualitativas (como cor, coordena-\ndas espaciais, tamanho, etc.). Essa teoria pode ser aplicada em v\u00e1rias \u00e1reas de \nIntelig\u00eancia Artificial, sendo que Chella e colegas (1997) propuseram a sua utili-\nza\u00e7\u00e3o na \u00e1rea de vis\u00e3o computacional, dentro do contexto da rob\u00f3tica. Nessa \nabordagem, o espa\u00e7o conceitual faz o papel de ponte entre a representa\u00e7\u00e3o de \nbaixo n\u00edvel e a representa\u00e7\u00e3o simb\u00f3lica.  \n\nChella e colegas introduzem o conceito de knoxel, um ponto gen\u00e9rico no es-\npa\u00e7o conceitual, correspondendo a uma entidade primitiva no n\u00edvel visual (co-\nmo uma regi\u00e3o ou volume). Na abordagem, os knoxels s\u00e3o volumes obtidos da \nimagem por algoritmos de processamento e mapeados para o n\u00edvel sem\u00e2ntico \n(CHELLA et al., 2001). Por exemplo, um martelo \u201cgen\u00e9rico\u201d pode ser represen-\ntado por dois knoxels no n\u00edvel visual, como na Figura 2.4a. O conjunto de knoxels \n{k1, k2} \u00e9 ent\u00e3o mapeado para o conceito Hammer no n\u00edvel sem\u00e2ntico como re-\npresentado na Figura 2.4b. \n\nA correla\u00e7\u00e3o entre os knoxels e as entidades do n\u00edvel sem\u00e2ntico \u00e9 realizada \natrav\u00e9s de um algoritmo de aten\u00e7\u00e3o, utilizando gera\u00e7\u00e3o e teste de hip\u00f3teses. \n\n \nFigura 2.4: Representa\u00e7\u00e3o de um martelo em um espa\u00e7o superquadr\u00e1tico e con-\n\nceitual (CHELLA et al., 2001). \n\n\n\n30 \n\n \n\n \n\n2.2.3.1 N\u00edvel Sem\u00e2ntico \n\nO n\u00edvel sem\u00e2ntico descreve a cena percebida em termo de uma linguagem \nl\u00f3gica de alto n\u00edvel. \u00c9 adotado um formalismo de representa\u00e7\u00e3o h\u00edbrido, consti-\ntu\u00eddo por um componente terminol\u00f3gico e um componente assertivo. O primei-\nro cont\u00e9m o modelo conceitual propriamente dito, enquanto o segundo guarda \na descri\u00e7\u00e3o de uma cena individual (inst\u00e2ncias). \n\nO componente terminol\u00f3gico \u00e9 baseado em uma taxonomia de objetos, al\u00e9m \nde induzir rela\u00e7\u00f5es de composi\u00e7\u00e3o entre os objetos. Por exemplo, a Figura 2.5 \ndemonstra a especializa\u00e7\u00e3o da entidade gen\u00e9rica Object - e sua rela\u00e7\u00e3o has-part - \nna a entidade Hammer. Nesse caso, conforme a Figura 2.4b, as entidades primi-\ntivas Box-shaped e Cylinder-chaped s\u00e3o representa\u00e7\u00f5es diretas de knoxels do n\u00edvel \nvisual. \n\nJ\u00e1 o componente assertivo representa as inst\u00e2ncias de uma cena utilizando \nl\u00f3gica de primeira ordem. Por exemplo, a declara\u00e7\u00e3o da inst\u00e2ncia Hammer#1 do \nconceito Hammer \u00e9 dada pela f\u00f3rmula \n\n#1\u00a0 . \n\nPara expressar que a rela\u00e7\u00e3o has-handle entre Hammer#1 e o knoxel Cylinder-\nshaped#1, declara-se a f\u00f3rmula \n\n? #1, #1 . \n\nAl\u00e9m disso, o componente de terminol\u00f3gico cont\u00e9m representa\u00e7\u00f5es para re-\nla\u00e7\u00f5es espaciais e topol\u00f3gicas entre objetos. \n\n \nFigura 2.5: Fragmento do componente terminol\u00f3gico da abordagem, utilizando \n\na representa\u00e7\u00e3o gr\u00e1fica de KL-ONE (CHELLA et al., 1997). \n\n2.2.3.2 N\u00edvel Visual \n\nComo dito, a primitiva de representa\u00e7\u00e3o do n\u00edvel visual \u00e9 uma forma 3D \nprimitiva chamada knoxel. Nos trabalhos de Chella e colegas, as primitivas para \nrepresenta\u00e7\u00e3o do knoxel s\u00e3o as superquadr\u00e1ticas.  \n\n\n\n31 \n\n \n\n \n\nSuperquadr\u00e1ticas s\u00e3o formas geom\u00e9tricas derivadas de uma equa\u00e7\u00e3o qua-\ndr\u00e1tica param\u00e9trica com as fun\u00e7\u00f5es trigonom\u00e9tricas elevadas a dois expoentes \nreais. Em resumo, um knoxel superquadr\u00e1tico \u00e9 representado por um vetor no \nespa\u00e7o , ou seja, um knoxel k \u00e9 dado por \n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\n\nonde \u00a0 \u00a0 \u00a0 \u00a0\u00a0  definem a forma da superquadr\u00e1tica e \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \ndefinem a posi\u00e7\u00e3o especial e inclina\u00e7\u00e3o. Al\u00e9m disso, os knoxels podem ser agru-\npados em clusters de percep\u00e7\u00e3o (PC). Por exemplo, a Figura 2.4a sugere um PC \ndado por k1 e k2. \n\nA rela\u00e7\u00e3o entre os knoxels e as entidades no n\u00edvel superior \u00e9 representada a-\ntrav\u00e9s da fun\u00e7\u00e3o de interpreta\u00e7\u00e3o \n\n?C:C PC \n\nque mapeia o conjunto C de inst\u00e2ncias no componente assertivo para o con-\njunto de todos os clusters de percep\u00e7\u00e3o no n\u00edvel visual. Por exemplo, no exem-\nplo da figura Figura 2.4: \n\n? #1 \u00a0 ,   \nou ainda, \n\n? Cylinder?shaped#1 \u00a0 , \n? Cylinder?shaped#1 ? #1 .\u00a0 \n\nA fun\u00e7\u00e3o ? \u00e9 inferida por um algoritmo baseado em aten\u00e7\u00e3o que utiliza o \nconhecimento contido no n\u00edvel sem\u00e2ntico em um esquema de infer\u00eancia top-\ndown. O algoritmo busca por poss\u00edveis objetos atrav\u00e9s dos knoxels j\u00e1 identifica-\ndos. Ainda no exemplo da Figura 2.4, se o knoxel k2 j\u00e1 foi identificado, o algo-\nritmo ir\u00e1 supor a existencial potencial de um martelo e ir\u00e1 realizar uma buscar \nno n\u00edvel visual pelo knoxel k1. Se k2 sugerir a exist\u00eancia de outros objetos, ser\u00e1 \nfeita uma busca por evid\u00eancias que comprovem a exist\u00eancia de todos eles. \n\n2.2.3.3 N\u00edvel anal\u00f3gico \n\nO n\u00edvel anal\u00f3gico, na abordagem dos espa\u00e7os conceituais, \u00e9 constitu\u00eddo so-\nmente dos dados brutos da imagem, sem nenhum tipo de abstra\u00e7\u00e3o inicial. \n(CHELLA et al., 2001) listam diversos trabalhos que tratam da extra\u00e7\u00e3o de for-\nmas superquadr\u00e1ticas em imagens reais, mesmo com a presen\u00e7a de oclus\u00f5es.  \n\n2.2.4 Abordagem 4: Abordagem Orion \nA proposta apresentada pelo Grupo Orion (HUDELOT, 2005; HUDELOT et \n\nal., 2005; MAILLOT, 2005) define uma abordagem completa de vis\u00e3o cognitiva \nque se encaixa com precis\u00e3o na representa\u00e7\u00e3o em tr\u00eas n\u00edveis sem\u00e2nticos Figura \n2.6.  \n\nUma das principais preocupa\u00e7\u00f5es da abordagem \u00e9 a modelagem do anco-\nramento simb\u00f3lico entre o n\u00edvel sem\u00e2ntico e o n\u00edvel anal\u00f3gico. Por isso, duas \nontologias s\u00e3o propostas para mapeamento entre os tr\u00eas n\u00edveis.  \n\n\n\n32 \n\n \n\n \n\n \nFigura 2.6: Exemplo de representa\u00e7\u00e3o de uma laranja em uma imagem utilizan-\n\ndo tr\u00eas n\u00edveis sem\u00e2nticos (HUDELOT et al., 2005). \n\nA Ontologia de Conceitos Visuais faz o papel de um modelo intermedi\u00e1rio en-\ntre o n\u00edvel sem\u00e2ntico e o n\u00edvel anal\u00f3gico, representando as entidades do modelo \nconceitual atrav\u00e9s de \u201cum vocabul\u00e1rio comum utilizado por humanos para re-\npresentar visualmente objetos e cenas\u201d (HUDELOT et al., 2005).  \n\nJ\u00e1 a Ontologia de Conceitos Imag\u00edsticos mapeia os resultados brutos dos algo-\nritmos de processamento de imagens para o n\u00edvel visual. Ela descreve as ima-\ngens e os resultados dos algoritmos do ponto de vista do especialista em pro-\ncessamento de imagens. Al\u00e9m disso, a ontologia inclui conceitos para represen-\ntar as funcionalidades dos algoritmos de processamento de imagem, o que \npermite atrelar as entidades do n\u00edvel intermedi\u00e1rio aos processos que s\u00e3o utili-\nzados para identific\u00e1-las e extra\u00ed-las das imagens. \n\nA infer\u00eancia do ancoramento sem\u00e2ntico utiliza as duas formas de interpreta-\n\u00e7\u00e3o sem\u00e2ntica de imagens (top-down e bottom-up). \n\nC\u00e9line Hudelot (2005) prop\u00f5e uma plataforma completa para interpreta\u00e7\u00e3o \nsem\u00e2ntica de imagens utilizando a abordagem Orion. A implementa\u00e7\u00e3o do sis-\ntema foi realizada com a plataforma LAMA (CRUB\u00c9ZY et al., 1998) para desen-\nvolvimento de sistemas baseados em conhecimento. A aplica\u00e7\u00e3o foi validada \ndentro do dom\u00ednio da Biologia, para diagn\u00f3stico de doen\u00e7as em roseiras. \n\n2.2.4.1 N\u00edvel Sem\u00e2ntico \n\nO n\u00edvel sem\u00e2ntico representa o conhecimento visual eliciado de um especia-\nlista no dom\u00ednio da aplica\u00e7\u00e3o. A abordagem define a forma com que o conhe-\ncimento deve ser eliciado, definindo os seguintes passos para a tarefa: \n\n\u2022 Primeiramente, o especialista no dom\u00ednio da aplica\u00e7\u00e3o prov\u00ea uma taxo-\nnomia de conceitos do dom\u00ednio. Esse modelo tamb\u00e9m inclui rela\u00e7\u00f5es co-\nmo parte-de; \n\n\n\n33 \n\n \n\n \n\n\u2022 Ent\u00e3o, os especialistas utilizam a Ontologia de Conceitos Visuais para \ndescrever os conceitos do dom\u00ednio com base na sua apar\u00eancia visual e \nsuas rela\u00e7\u00f5es espaciais; \n\n\u2022 Opcionalmente, o processo pode incluir a anota\u00e7\u00e3o de amostras de ima-\ngens utilizando o modelo sem\u00e2ntico. \n\n2.2.4.2 N\u00edvel Visual \n\nO n\u00edvel visual \u00e9 representado pela j\u00e1 citada Ontologia de Conceitos Visuais. Ela \n\u00e9 uma ontologia independente de dom\u00ednio que permite modelar explicitamente \nos aspectos visuais de objetos do mundo, abstra\u00eddos de qualquer dado num\u00e9ri-\nco. Ela \u00e9 composta por: \n\n\u2022 Conceitos Espaciais que descrevem objetos geometricamente. S\u00e3o conceitos \ncomo forma, tamanho e localiza\u00e7\u00e3o. S\u00e3o tamb\u00e9m representadas rela\u00e7\u00f5es es-\npaciais como topologia, dist\u00e2ncia e orienta\u00e7\u00e3o. \n\n\u2022 Conceitos para Cor, com termos relacionados a matiz, luminosidade e sa-\ntura\u00e7\u00e3o.  \n\n\u2022 Conceitos para Textura, obtidos por experimentos da comunidade de ci\u00ean-\ncia cognitiva. S\u00e3o conceitos como textura granulada e orientada ou uniforme.  \n\nComo dito na se\u00e7\u00e3o anterior, essa ontologia \u00e9 diretamente mapeada para a \nontologia de dom\u00ednio no n\u00edvel sem\u00e2ntico. \n\n2.2.4.3 N\u00edvel anal\u00f3gico \n\nComo apresentado na se\u00e7\u00e3o 2.2.4.2, no n\u00edvel anal\u00f3gico os dados brutos da \nimagem s\u00e3o interpretados por algoritmos de processamento de imagem e o re-\nsultado \u00e9 representado pela Ontologia de Conceitos Imag\u00edsticos, formada por pri-\nmitivas de representa\u00e7\u00e3o ligadas ao dom\u00ednio de processamento de imagens na \ncomputa\u00e7\u00e3o. Ela \u00e9 formada pelas seguintes partes: \n\n\u2022 Um conjunto de 11 conceitos representando diferentes tipos de estruturas \nde dados que podem ser extra\u00eddos de imagens, como regi\u00f5es e arestas, ou \nestruturas mais complexas, como grafos de regi\u00f5es e de vizinhan\u00e7a.  \n\n\u2022 Um conjunto de 167 conceitos para representar caracter\u00edsticas que podem \nser medidas em imagens, como \u00e1rea, posi\u00e7\u00e3o e propriedades de formas, \ncor e texturas. \n\nA ontologia tamb\u00e9m cont\u00e9m conceitos para representar o conhecimento li-\ngado aos algoritmos de processamento de imagem. \n\nTodos esses conceitos permitem a constru\u00e7\u00e3o de uma requisi\u00e7\u00e3o de proces-\nsamento de imagem com base no conhecimento representado no n\u00edvel visual e \nque o resultado do processamento seja mapeado para ele. \n\nO mapeamento pode acontecer de duas formas. Na forma autom\u00e1tica, para \num dado conceito visual (azul claro, por exemplo), s\u00e3o escolhidas as caracter\u00edsti-\ncas imag\u00edsticas que melhor descrevem o conceito. A escolha \u00e9 feita utilizando a \n\n\n\n34 \n\n \n\n \n\nt\u00e9cnica de Analise Discriminante Linear (ADL), com base em imagens manual-\nmente anotadas por especialistas no dom\u00ednio. As caracter\u00edsticas escolhidas for-\nmam a entrada do detector do conceito visual. Ele \u00e9 constitu\u00eddo por uma M\u00e1-\nquina de Vetor de Suporte (SVM, do ingl\u00eas Support Vector Machine), treinada \ncom base em imagens anotadas manualmente e espec\u00edficas para o treinamento. \n\nNo mapeamento manual, a liga\u00e7\u00e3o entre os conceitos do n\u00edvel visual e as ca-\nracter\u00edsticas da imagem \u00e9 explicitamente constru\u00edda. A correspond\u00eancia entre as \ncaracter\u00edsticas imag\u00edsticas num\u00e9ricas e os conceitos no n\u00edvel visual \u00e9 represen-\ntada por conjuntos fuzzy. Por exemplo, na Figura 2.7, o conceito Superf\u00edcie El\u00edp-\ntica no n\u00edvel visual \u00e9 mapeado para o n\u00edvel anal\u00f3gico por cinco conjuntos fuzzy \ndefinidos sobre a primitiva anal\u00f3gica excentricidade.  \n\n \nFigura 2.7. Exemplo de mapeamento do conceito Superf\u00edcie El\u00edptica do n\u00edvel vi-\n\nsual para o n\u00edvel anal\u00f3gico utilizando conjuntos fuzzy (HUDELOT, 2005). \n\n2.3 Discuss\u00e3o e Compara\u00e7\u00e3o entre Abordagens de Interpreta-\n\u00e7\u00e3o Sem\u00e2ntica de Imagens \n\nNo cap\u00edtulo anterior foram descritas quatro abordagens de interpreta\u00e7\u00e3o de \nconhecimento visual baseados em modelos de representa\u00e7\u00e3o em tr\u00eas n\u00edveis co-\nnhecimento.  \n\nA primeira abordagem estudada, dos agregados, foca principalmente na re-\npresenta\u00e7\u00e3o no n\u00edvel sem\u00e2ntico com uma l\u00f3gica descritiva formal. Ela trata de \nquest\u00f5es importantes no dom\u00ednio visual, como representa\u00e7\u00e3o taxon\u00f4mica e me-\nreol\u00f3gica, com a introdu\u00e7\u00e3o de uma entidade conceitual b\u00e1sica chamada agre-\ngado. No campo da infer\u00eancia, os autores justificam a utiliza\u00e7\u00e3o de uma l\u00f3gica \ndescritiva m\u00ednima, pois isso permite que os j\u00e1 bem estudados servi\u00e7os de infe-\n\n\n\n35 \n\n \n\n \n\nr\u00eancia da l\u00f3gica descritiva sejam utilizados para validar os modelos visuais e \nderivar novas interpreta\u00e7\u00f5es. \n\nNo entanto, o ponto fraco da abordagem dos agregados est\u00e1 nos n\u00edveis infe-\nriores. Pouco se fala sobre as formas de mapeamento do n\u00edvel sem\u00e2ntico para os \nn\u00edveis inferiores. As informa\u00e7\u00f5es a respeito do modelo GSD s\u00e3o demasiadamen-\nte esparsas na literatura.  Ainda sim, pelo estudo das informa\u00e7\u00f5es dispon\u00edveis, o \nGSD n\u00e3o prov\u00ea uma forma de representa\u00e7\u00e3o clara e a forma de mapeamento en-\ntre ele e os outros n\u00edveis n\u00e3o est\u00e1 totalmente clara. \n\nJ\u00e1 na abordagem abdutiva, o foco est\u00e1 na representa\u00e7\u00e3o nos n\u00edveis visual e \nimag\u00edstico e no mapeamento entre os dois. A modelagem \u00e9 baseada em l\u00f3gica \nde primeira ordem, onde as entidades do n\u00edvel visual s\u00e3o definidas como axio-\nmas sobre primitivas do n\u00edvel anal\u00f3gico. Isso permite a verifica\u00e7\u00e3o formal do \nconhecimento modelado. Al\u00e9m disso, a abordagem inclui no\u00e7\u00e3o de ru\u00eddo no n\u00ed-\nvel visual, tornando a proposta menos suscet\u00edvel a erros dos algoritmos de pro-\ncessamento de imagens. Como as primitivas do n\u00edvel anal\u00f3gico s\u00e3o visualmente \nsimples (linhas e pontos), a extra\u00e7\u00e3o delas tamb\u00e9m se torna simples e robusta. \n\nO ponto fraco da abordagem abdutiva est\u00e1 na sua simplicidade. Nenhum \ndos n\u00edveis inferiores busca representar caracter\u00edsticas visuais como cor e textu-\nra. Isso limita a interpreta\u00e7\u00e3o no n\u00edvel conceitual a somente \u00e0 forma e contorno \ndos objetos. Al\u00e9m disso, a modelagem no n\u00edvel conceitual ainda foi pouco ex-\nplorada.  \n\nA proposta dos espa\u00e7os conceituais se encaixa melhor que as duas anteriores \nna abordagem em tr\u00eas n\u00edveis conceituais. Ela define um \u00f3timo arcabou\u00e7o te\u00f3ri-\nco para representa\u00e7\u00e3o de conhecimento visual em todos os n\u00edveis. O n\u00edvel se-\nm\u00e2ntico define uma ontologia de representa\u00e7\u00e3o gen\u00e9rica, que pode ser estendi-\nda, e uma representa\u00e7\u00e3o para as suas inst\u00e2ncias. O n\u00edvel visual \u00e9 mapeado para \no n\u00edvel sem\u00e2ntico atrav\u00e9s de fun\u00e7\u00f5es de mapeamento formais e bem definidas, \ninterpretadas atrav\u00e9s de um mecanismo de racioc\u00ednio imag\u00edstico baseado em \naten\u00e7\u00e3o. \n\nA abordagem, embora bastante s\u00f3lida, sofre o mesmo problema de simplici-\ndade da abordagem abdutiva. O n\u00edvel visual leva em conta somente a forma de \nobjetos visuais, deixando de fora atributos como cor, textura e etc. Isso inviabi-\nliza a utiliza\u00e7\u00e3o da abordagem em \u00e1reas onde essas s\u00e3o as caracter\u00edsticas que \ndefinem os objetos. \n\nFinalmente, ao contr\u00e1rio das outras propostas, a abordagem Orion foca re-\nalmente na representa\u00e7\u00e3o e interpreta\u00e7\u00e3o em dom\u00ednios intensivos em conheci-\nmento visual. Ela define uma abordagem completa de vis\u00e3o cognitiva, definin-\ndo modelos de representa\u00e7\u00e3o em todos os tr\u00eas n\u00edveis e seus respectivos mape-\namentos. O problema do ancoramento sem\u00e2ntico \u00e9 abordado diretamente, com \npropostas de ancoramento manual e com t\u00e9cnicas de aprendizado de m\u00e1quina.  \n\nA proposta Orion falha em n\u00e3o apresentar uma possibilidade de expans\u00e3o \npara interpreta\u00e7\u00e3o de v\u00eddeos, integrando no\u00e7\u00f5es formais de modelagem de e-\nventos. Al\u00e9m disso, embora completa, a proposta pode se tornar muito comple-\n\n\n\n36 \n\n \n\n \n\nxa para aplica\u00e7\u00e3o em dispositivos com pouco poder computacional embarcado \n(como rob\u00f3tica).  \n\nPor fim, a Tabela 2.1 faz uma compara\u00e7\u00e3o direta entre as abordagens estu-\ndadas, levando em conta as diversas dimens\u00f5es pertinentes \u00e0 interpreta\u00e7\u00e3o se-\nm\u00e2ntica de imagens. Ela evidencia uma dicotomia interessante entre a aborda-\ngem Orion e as demais. Nota-se que a abordagem Orion se baseia em um for-\nmalismo de representa\u00e7\u00e3o menos estruturado (Frames, em contraponto com o \nformalismo l\u00f3gico). Isso est\u00e1 em conformidade com a aplica\u00e7\u00e3o b\u00e1sica em do-\nm\u00ednios intensivos em conhecimento, que normalmente requerem modelos de \nrepresenta\u00e7\u00e3o flex\u00edveis e menos estruturados, sem grande preocupa\u00e7\u00e3o com \nperformance. J\u00e1 nas outras abordagens, em especial a abdu\u00e7\u00e3o e de espa\u00e7os \nconceituais, a formaliza\u00e7\u00e3o l\u00f3gica e matem\u00e1tica (como a superquadr\u00e1ticas) se \nadaptam aos requisitos de performance e robustez exigidos por sistemas rob\u00f3ti-\ncos e de tempo real.  \n\nTabela 2.1: Tabela de compara\u00e7\u00e3o entre as quatro abordagens estudadas. \n\n Abordagem 1: Agregados \nAbordagem 2: \n\nAbdu\u00e7\u00e3o \n\nAbordagem 3: \nEspa\u00e7os  \n\nConceituais \n\nAbordagem 4: \nOrion \n\nFormalismo de \nRepresenta\u00e7\u00e3o L\u00f3gica descritiva \n\nL\u00f3gica de pri-\nmeira ordem \n\nL\u00f3gica, Frames e \nsuperquadr\u00e1ticas \n\nFrames \n\nAplica\u00e7\u00e3o  \nB\u00e1sica \n\nInterpreta\u00e7\u00e3o de \ncenas simples \n\nRob\u00f3tica e inter-\npreta\u00e7\u00e3o de ce-\nnas (tr\u00e2nsito) \n\nRob\u00f3tica \n\nRecupera\u00e7\u00e3o de \nimagens e inter-\npreta\u00e7\u00e3o de ce-\n\nnas em dom\u00ednios \nintensivos em \nconhecimento \n\nAncoramento \nSem\u00e2ntico \n\nN\u00e3o definido ex-\nplicitamente; \n\npossivelmente \nmanual. \n\nAbordagem \nh\u00edbrida (top-down \n\ne bottom-up) \n\nAbordagem \nh\u00edbrida (top-down \n\ne bottom-up) \n\nAbordagem h\u00ed-\nbrida (top-down e \n\nbottom-up) ou \nmanualmente \n\nProcessamento \nde imagem \n\nQualquer um \nque extraia mo-\ndelos GSD de \n\nimagens \n\nAlgoritmo de de-\ntec\u00e7\u00e3o e extra\u00e7\u00e3o \n\nde bordas \n\nQualquer algo-\nritmo que gere \nvolumes super-\nquadr\u00e1ticos de \n\nimagens \n\nQualquer algo-\nritmo de proces-\nsamento de ima-\ngens ou manu-\n\nalmente (via ano-\nta\u00e7\u00e3o) \n\n \n\n\n\n \n\n \n\n \n\n3 S-Chart: UM MODELO PARA INTERPRETA\u00c7\u00c3O \nSEM\u00c2NTICA DE GR\u00c1FICOS \n\nEste cap\u00edtulo descreve o framework S-Chart, a principal contribui\u00e7\u00e3o deste  \ndeste trabalho. O framework S-Chart busca capturar em modelos e algoritmos o \ncomportamento de interpreta\u00e7\u00e3o visual realizado por um especialista ao anali-\nsar um gr\u00e1fico como o exposto na Figura 1.2b. Mais especificamente, ser\u00e1 de-\nmonstrado como algoritmos de processamento de sinais podem ser combinados \ncom algoritmos e modelos de racioc\u00ednio simb\u00f3lico a fim de chegar a uma inter-\npreta\u00e7\u00e3o simb\u00f3lica do gr\u00e1fico. A proposta apresentada utiliza os princ\u00edpios de \ninterpreta\u00e7\u00e3o sem\u00e2ntica, de forma a combinar mecanismos de extra\u00e7\u00e3o de pa-\ndr\u00f5es com conhecimento de dom\u00ednio. \n\nPara chegar a interpreta\u00e7\u00e3o sem\u00e2ntica da proje\u00e7\u00e3o gr\u00e1fica de um sinal, o \nframework S-Chart prop\u00f5e modelos e algoritmos em tr\u00eas n\u00edveis sem\u00e2nticos. O \nestudo de outras abordagens de interpreta\u00e7\u00e3o sem\u00e2ntica apresentadas no cap\u00ed-\ntulo anterior e do requisito de aplicabilidade em dom\u00ednios intensivos em conhe-\ncimento visual, sugerem a incorpora\u00e7\u00e3o dos seguintes conceitos ao framework \nS-Chart:  \n\n\u2022 Incorpora\u00e7\u00e3o de ontologias de dom\u00ednio. O modelo que representa os ob-\njetos do dom\u00ednio \u00e9 incorporado no n\u00edvel sem\u00e2ntico. Embora ele possa ser \nmais orientado \u00e0 aplica\u00e7\u00e3o, \u00e9 interessante que o n\u00edvel sem\u00e2ntico possa in-\ncorporar modelos de conhecimento propriamente dito, como ontologias \nde dom\u00ednio. Ontologias de dom\u00ednio capturam conhecimento comparti-\nlhado sobre um determinado dom\u00ednio de forma n\u00e3o amb\u00edgua. Uma onto-\nlogia de dom\u00ednio aplicada ao n\u00edvel sem\u00e2ntico permite que as informa\u00e7\u00f5es \nextra\u00eddas dos gr\u00e1ficos sejam compartilhadas mais eficientemente com ou-\ntros agentes e sistemas. Em especial, estas informa\u00e7\u00f5es podem ser dispo-\nnibilizadas a outros mecanismos de racioc\u00ednio simb\u00f3lico para realiza\u00e7\u00e3o \nde infer\u00eancias adicionais ao sistema de interpreta\u00e7\u00e3o visual. \n\n\u2022 Primitivas de modelagem independentes de dom\u00ednio. Como explicitado \nanteriormente, novas primitivas se fazem necess\u00e1rias para suporte a in-\nterpreta\u00e7\u00e3o de gr\u00e1ficos e dos dados onde eles se baseiam. Elas se locali-\nzam no n\u00edvel anal\u00f3gico e no n\u00edvel visual. Elas tamb\u00e9m devem ser gen\u00e9ri-\ncas o suficiente para permitir que o framework seja reutiliz\u00e1vel em diver-\nsos dom\u00ednios de aplica\u00e7\u00e3o. \n\n\n\n38 \n\n \n\n \n\n\u2022 Ancoramento simb\u00f3lico expl\u00edcito. O mapeamento entre os s\u00edmbolos dos \ntr\u00eas n\u00edveis deve ser explicitamente representado. Em t\u00e9cnicas de mapea-\nmento conexionistas, um n\u00famero suficiente de casos \u00e9 necess\u00e1rio para \ntreinamento e teste das redes que operacionalizam os mapeamentos. No \nentanto, em dom\u00ednios restritos, mas intensivos em conhecimento visual, \nnem sempre se tem acesso ao n\u00famero de casos necess\u00e1rios para treina-\nmento. Uma vez que este trabalho foca em dom\u00ednios como este, se faz ne-\ncess\u00e1ria uma forma de mapeamento direta e que possa ser explicitamente \nrepresentada. \n\n\u2022 Modelo process\u00e1vel por computador: o formalismo escolhido para re-\npresenta\u00e7\u00e3o dos modelos de conhecimento deve ser formal e estruturado \no suficiente para ser diretamente process\u00e1vel por computador. Ou seja, os \nmodelos de conhecimento devem ser process\u00e1veis diretamente pelos al-\ngoritmos de interpreta\u00e7\u00e3o, sem a necessidade de mape\u00e1-los manualmente \npara formalismos de baixo n\u00edvel. \n\nAs se\u00e7\u00f5es descrevem seguintes os modelos e algoritmos que comp\u00f5es o fra-\nmework S-Chart incorporando os conceitos apresentados. Na se\u00e7\u00e3o seguinte, \ns\u00e3o feitas algumas defini\u00e7\u00f5es sobre a linguagem de representa\u00e7\u00e3o utilizada ao \nlongo do cap\u00edtulo. A seguir, s\u00e3o apresentados os modelos de conhecimento vi-\nsual em tr\u00eas n\u00edveis, seguidos de algoritmos para interpreta\u00e7\u00e3o sem\u00e2ntica sobre \nestes modelos. \n\n3.1 Linguagem de Representa\u00e7\u00e3o \nO formalismo escolhido para representa\u00e7\u00e3o dos modelos de conhecimento \n\nvisual e ancoramento simb\u00f3lico \u00e9 a linguagem OWL 1.0 (MCGUINNESS; \nHARMELEN, 2004). OWL foi proposto pela W3C como uma linguagem para \nrepresenta\u00e7\u00e3o de conhecimento na Web. No entanto, a sua padroniza\u00e7\u00e3o tem \nlevado a uma aceita\u00e7\u00e3o maior para a formaliza\u00e7\u00e3o de conhecimento e informa-\n\u00e7\u00e3o nos mais diferentes tipos de sistemas.  \n\nA escolha de OWL como linguagem de representa\u00e7\u00e3o neste trabalho se d\u00e1 \npor fatores de natureza conceitual a pr\u00e1tica. Do ponto de vista conceitual, a lin-\nguagem combina uma sem\u00e2ntica bem definida com uma expressividade sufici-\nente para representar os construtos do framework S-Chart. Todos os modelos \napresentados a seguir (com exce\u00e7\u00e3o dos modelos de mapeamento) podem ser \nmodelados com a sublinguagem OWL DL, que equivale \u00e0 l\u00f3gica de descri\u00e7\u00e3o \n\n. A Tabela 3.1 mostra quais primitivas OWL DL s\u00e3o utilizadas pra \nrepresentar as principais primitivas S-Chart detalhadas nas pr\u00f3ximas sess\u00f5es. \nAdicionalmente, modelos descritos em OWL DL herdam as propriedades for-\nmais dessa , o que possibilita uma modelagem mais precisa. De fato, Neu-\nmann e colegas (2008) suportam id\u00e9ia da l\u00f3gica descritiva como uma ferramen-\nta para formaliza\u00e7\u00e3o de conhecimento visual. Uma segunda caracter\u00edstica im-\nportante da linguagem \u00e9 a possibilidade de metamodelagem, ou seja, \u00e9 poss\u00edvel \nrela\u00e7\u00f5es entre elementos dos modelos criados na linguagem com elementos do \n\n\n\n39 \n\n \n\n \n\nmetamodelo da pr\u00f3pria linguagem (como os elementos classe e propriedade). \nDessa forma \u00e9 poss\u00edvel definir extens\u00f5es da pr\u00f3pria linguagem de representa-\n\u00e7\u00e3o. Essa caracter\u00edstica \u00e9 importante para cria\u00e7\u00e3o das regras de mapeamentos \nentre os n\u00edveis de conhecimento visual, como apresentado na se\u00e7\u00e3o 3.2.4 a se-\nguir.  \n\nTabela 3.1: Primitivas OWL necess\u00e1rias para representa\u00e7\u00e3o de primitivas visu-\nais do framework S-Chart. \n\nPrimitiva S-Chart Primitiva OWL DL \nEntidades Visuais Class \n\nPropriedades Visuais ObjectProperty e Class \n\nRela\u00e7\u00f5es Espaciais ObjectProperty \n\nEntidades Anal\u00f3gicas Class \n\nPropriedades Anal\u00f3gicas DatatypeProperty \n\nDo ponto de vista pr\u00e1tico \u2013 e n\u00e3o menos importante \u2013, a linguagem OWL \napresenta uma s\u00e9rie de caracter\u00edsticas que facilitam a sua utiliza\u00e7\u00e3o em sistemas \nde conhecimento, como uma sintaxe bem defina (XML) e uma grande comuni-\ndade de usu\u00e1rios (com o desenvolvimento de ferramentas de suporte a mode-\nlagem e desenvolvimento). Na opini\u00e3o do autor deste trabalho, a utiliza\u00e7\u00e3o de \nOWL diretamente como linguagem de representa\u00e7\u00e3o no framework S-Chart \npode facilitar a instancia\u00e7\u00e3o do framework nas diversas \u00e1reas de aplica\u00e7\u00e3o. No \nCap\u00edtulo 5, ser\u00e1 demonstrado como a linguagem pode utilizada para imple-\nmenta\u00e7\u00e3o de um sistema de interpreta\u00e7\u00e3o visual. \n\nNas se\u00e7\u00f5es seguintes, \u00e9 utilizada a sintaxe OWL Manchester (HORRIDGE et \nal., 2006) para representa\u00e7\u00e3o de express\u00f5es OWL, a fim de facilitar a leitura. Ao \ncontr\u00e1rio da sintaxe padr\u00e3o XML/OWL, a sintaxe Manchester \u00e9 menos prolixa e \nmais simples de ser compreendida por seres humanos. \n\n3.2 Arquitetura do Framework S-Chart \nA arquitetura do framework S-Chart \u00e9 composta por tr\u00eas elementos funda-\n\nmentais (Figura 3.1): um componente de representa\u00e7\u00e3o de conhecimento visual, \num componente de ancoramento simb\u00f3lico (ou \u201cmapeamento\u201d) e um compo-\nnente de interpreta\u00e7\u00e3o e infer\u00eancia de informa\u00e7\u00f5es visuais.  \n\nO componente de representa\u00e7\u00e3o \u00e9 composto por um modelo de dividido em \ntr\u00eas n\u00edveis de representa\u00e7\u00e3o (sem\u00e2ntico, visual e anal\u00f3gico). Como em outras \nabordagens de interpreta\u00e7\u00e3o simb\u00f3lica, esses tr\u00eas n\u00edveis representam as infor-\nma\u00e7\u00f5es extra\u00eddas do sinal em graus crescentes de abstra\u00e7\u00e3o. O n\u00edvel anal\u00f3gico \ncaptura informa\u00e7\u00f5es num\u00e9ricas extra\u00eddas diretamente do sinal, o n\u00edvel visual \ncaptura fei\u00e7\u00f5es visuais da proje\u00e7\u00e3o gr\u00e1fica desse sinal, e o n\u00edvel sem\u00e2ntico cap-\ntura as entidades do dom\u00ednio reconhecidas visualmente no gr\u00e1fico. \n\n\n\n40 \n\n \n\n \n\n \nFigura 3.1: Componentes da arquitetura do framework S-Chart. \n\nA informa\u00e7\u00e3o utilizada para mapeamento entre entidades de n\u00edveis adjacen-\ntes \u00e9 representada pelo componente de ancoramento simb\u00f3lico. Ele \u00e9 que indica \nexplicitamente como o processo de interpreta\u00e7\u00e3o deve abstrair entidades de um \nn\u00edvel para o outro. Esse mapeamento indica, por exemplo, como em qual confi-\ngura\u00e7\u00e3o certas fei\u00e7\u00f5es anal\u00f3gicas devem aparecer no sinal para indicar a pre-\nsen\u00e7a de uma fei\u00e7\u00e3o visual.  \n\nO componente de interpreta\u00e7\u00e3o processa o sinal em conjunto com os mode-\nlos de representa\u00e7\u00e3o e ancoramento simb\u00f3lico at\u00e9 inferir algum objeto do dom\u00ed-\nnio presente no sinal. Esse mecanismo se baseia em gera\u00e7\u00e3o e teste de hip\u00f3teses \ne se divide em duas partes. A m\u00e1quina de interpreta\u00e7\u00e3o visual infere fei\u00e7\u00f5es visu-\nais das informa\u00e7\u00f5es contidas no n\u00edvel anal\u00f3gico. Inst\u00e2ncias de entidades visuais \ns\u00e3o criadas (gera\u00e7\u00e3o) e classificadas conforme os dados anal\u00f3gicos extra\u00eddos do \nsinal (teste). De forma an\u00e1loga, a m\u00e1quina de interpreta\u00e7\u00e3o sem\u00e2ntica, infere enti-\ndades do n\u00edvel sem\u00e2ntico conforme as fei\u00e7\u00f5es visuais extra\u00eddas pela m\u00e1quina de \ninterpreta\u00e7\u00e3o visual. \n\nNas subse\u00e7\u00f5es seguintes, cada um dos componentes da arquitetura do fra-\nmework S-Chart \u00e9 descrito em detalhes.  \n\n3.2.1 N\u00edvel sem\u00e2ntico \nO n\u00edvel sem\u00e2ntico comporta o modelo de conhecimento que define as entida-\n\ndes do dom\u00ednio que podem ser identificadas no sinal interpretado. Todas essas \nentidades devem estar organizadas em uma \u00fanica estrutura taxon\u00f4mica e/ou \nmereol\u00f3gica. Ou seja, todos os conceitos do dom\u00ednio devem ser estar relaciona-\ndos por alguma rela\u00e7\u00e3o de sub-classe ou de sub-parte.  \n\nComo apontado nos objetivos, ontologias de dom\u00ednio podem ser utilizadas \ncomo modelo para o n\u00edvel sem\u00e2ntico. Ontologias s\u00e3o constru\u00eddas com o intuito \nde capturar o conhecimento consensual de determinado dom\u00ednio. Quando mo-\n\n\n\n41 \n\n \n\n \n\ndeladas corretamente prevendo integra\u00e7\u00e3o de modelos, podem ser utilizadas \ncomo suporte para comunica\u00e7\u00e3o de diversos agentes (sistemas, usu\u00e1rio e etc). \nAssim, um sistema de conhecimento baseado em uma ontologia de dom\u00ednio \npoder\u00e1 integrar um sistema S-Chart se essa ontologia atender a estrutura b\u00e1sica \napresentada anteriormente. No Cap\u00edtulo 5, \u00e9 apresentada uma aplica\u00e7\u00e3o onde \u00e9 \nmodelada uma ontologia no dom\u00ednio da Estratigrafia de Sequ\u00eancias utilizada \ncomo modelo de conhecimento de dom\u00ednio no n\u00edvel sem\u00e2ntico. \n\nPara facilitar a importa\u00e7\u00e3o desses modelos de conhecimento, o componente \nde representa\u00e7\u00e3o define uma primitiva auxiliar no n\u00edvel sem\u00e2ntico na forma da \nclasse EntidadeSem\u00e2ntica. Essa entidade representa qualquer objeto do dom\u00ed-\nnio de discurso que foi extra\u00eddo pelo sistema de interpreta\u00e7\u00e3o. Ou seja, qualquer \nobjeto interpretado ser\u00e1 inst\u00e2ncia de um conceito do dom\u00ednio e da classe Enti?\ndadeSem\u00e2ntica, em uma rela\u00e7\u00e3o de heran\u00e7a m\u00faltipla. O seu papel no processo \nde interpreta\u00e7\u00e3o ficar\u00e1 mais claro nas se\u00e7\u00f5es seguintes. \n\n3.2.2 N\u00edvel visual \nAo contr\u00e1rio do n\u00edvel sem\u00e2ntico, o n\u00edvel visual \u00e9 independente do dom\u00ednio de \n\naplica\u00e7\u00e3o. Ele apresenta exclusivamente as primitivas que representam fei\u00e7\u00f5es \nvisuais gen\u00e9ricas, identific\u00e1veis por qualquer ser humano em gr\u00e1ficos como o \nda Figura 1.2b. Por causa disso, o modelo de conhecimento que captura as pri-\nmitivas visuais pode ser classificado como uma ontologia visual, uma vez que ela \nrepresenta simbolicamente os elementos visuais de uma conceitualiza\u00e7\u00e3o com-\npartilhada. \n\nAs fei\u00e7\u00f5es visuais de um gr\u00e1fico s\u00e3o capturadas por tr\u00eas tipos de construtos \nb\u00e1sicos: (i) as entidades visuais, que representam os objetos visuais concretos; (ii) \nas propriedades visuais, que caracterizam as entidades; (iii) rela\u00e7\u00f5es espaciais, defi-\nnidas entre as entidades visuais. Todas essas primitivas modeladas em uma on-\ntologia, organizadas como uma taxonomia de conceitos e de rela\u00e7\u00f5es.  \n\n3.2.2.1 Entidades Visuais \n\nUma entidade visual corresponde a uma fei\u00e7\u00e3o visual concreta, que foi reco-\nnhecida no gr\u00e1fico. Esse conceito \u00e9 capturado pela classe EntidadeVisual no \nmodelo ontol\u00f3gico. Somente entidades visuais t\u00eam extens\u00e3o na realidade, logo, \nqualquer objeto visual inferido pela interpreta\u00e7\u00e3o visual ser\u00e1 inst\u00e2ncia da classe \nEntidadeVisual ou de alguma de suas subclasses. \n\nA classe EntidadeVisual \u00e9 especializada nos diversos tipos de entidades \nvisuais que podem aparecer em um gr\u00e1fico (Figura 3.2). Como apresentado no \nCap\u00edtulo 2, diversos trabalhos propuseram ontologias para representa\u00e7\u00e3o de \nconhecimento no n\u00edvel visual. Em geral, essas ontologias compartilham as \nmesmas primitivas elementares. As primitivas mais escuras na Figura 3.2 foram \npropostas no modelo de conhecimento visual proposto pela abordagem Orion \n(se\u00e7\u00e3o 2.2.4) e reutilizadas aqui. As novas primitivas definidas neste trabalho \ndescrevem fei\u00e7\u00f5es visuais espec\u00edficas de gr\u00e1ficos, como tipos de curvas e pontos \n\n\n\n42 \n\n \n\n \n\nm\u00e1ximos e m\u00ednimos. Essa listagem n\u00e3o pretende ser extensiva e pode ser esten-\ndida com outras primitivas (ex.: outros tipos de curva) conforme a necessidade. \n\n3.2.2.2 Propriedades Visuais \n\nAlgumas fei\u00e7\u00f5es visuais s\u00e3o modeladas como propriedades de entidades vi-\nsuais. Ou seja, s\u00e3o fei\u00e7\u00f5es visuais que tem a sua exist\u00eancia dependente da exis-\nt\u00eancia de uma entidade visual. Dessa forma, todas as propriedades visuais t\u00eam \no seu dom\u00ednio definido em EntidadeVisual ou em alguma de suas subclasses. \nAs propriedades visuais tamb\u00e9m s\u00e3o estruturadas como uma taxonomia de \npropriedades, segundo a rela\u00e7\u00e3o de subpropriedade de OWL (Figura 3.3). No \nentanto, a defini\u00e7\u00e3o do contradom\u00ednio de propriedades visuais necessita de \numa discuss\u00e3o adicional. \n\nO n\u00edvel visual descreve simbolicamente aspectos visuais gen\u00e9ricos de uma \nimagem. Aspectos que possam ser descritos por uma linguagem comum a \nqualquer imagem, livre de detalhes de baixo n\u00edvel. Essa op\u00e7\u00e3o exclui a possibi-\n\n \nFigura 3.2: Taxonomia de entidades visuais. \n\n\n\n43 \n\n \n\n \n\nlidade de defini\u00e7\u00e3o de propriedades visuais atrav\u00e9s de contradom\u00ednios cont\u00ed-\nnuos, num\u00e9ricos. Ou seja, no framework S-Chart, as propriedades visuais ma-\npeiam inst\u00e2ncias de entidades visuais em conjuntos de valores expressos na \nforma de s\u00edmbolos ling\u00fc\u00edsticos ou valores simb\u00f3licos. Por exemplo, proprieda-\ndes como comprimento podem assumir somente valores ling\u00fc\u00edsticos como \nlongo, muito longo, curto e etc. Neste trabalho, estes valores s\u00e3o vistos como \ninst\u00e2ncias de uma categoria de valores poss\u00edveis (ex.: ValoresDeComprimento). \nEssa alternativa de modelagem \u00e9 baseada na proposta de Alan Rector \n(RECTOR, ALAN, 2005), fundamentada na caracteriza\u00e7\u00e3o formal de espa\u00e7os de \nqualidades (quality spaces) (GANGEMI et al., 2003). Assim, o contradom\u00ednio de \ncada propriedade visual \u00e9 modelado como um conceito espec\u00edfico, cujas inst\u00e2n-\ncias caracterizam os poss\u00edveis valores que a propriedade pode assumir. A Figu-\nra 3.4 apresenta um exemplo disso. \n\n \nFigura 3.3: Taxonomia de propriedade visuais com defini\u00e7\u00e3o de contradom\u00ednio \n\nde valores. A especializa\u00e7\u00e3o do dom\u00ednio \u00e9 omitida. \n\nContudo, existem alguns aspectos de propriedade visuais que devem ser le-\nvados em conta. \u00c9 sabido que a interpreta\u00e7\u00e3o humana de propriedades visuais \ncomo comprimento \u00e9 bastante subjetiva. Ela varia conforme o contexto que se es-\nt\u00e1 considerando ou a entidade a que se refere. Por exemplo, do ponto de vista \nvisual, a representa\u00e7\u00e3o de um avi\u00e3o com comprimento longo certamente \u00e9 dife-\nrente da interpreta\u00e7\u00e3o do comprimento longo para a representa\u00e7\u00e3o de um carro. \nAmbos adquirem um significado diferente, pois se referem a entidades visuais \nem escalas diferentes. Se o mesmo conjunto de valores simb\u00f3licos para com-\nprimento \u00e9 utilizado para caracterizar entidades em escalas diferentes, ser\u00e1 im-\nposs\u00edvel interpret\u00e1-las de forma correta. Uma propriedade visual n\u00e3o pode ter \num contradom\u00ednio com um \u00fanico conjunto de valores. Pelo menos n\u00e3o obriga-\ntoriamente. \n\n\n\n44 \n\n \n\n \n\n \nFigura 3.4: Exemplo de modelagem de contradom\u00ednios de propriedades visuais. \n\nPara resolver este problema \u2013 ao mesmo tempo em que se mant\u00e9m a restri-\n\u00e7\u00e3o de contradom\u00ednio com valores simb\u00f3licos \u2013 escolheu-se estender o modelo \napresentado anteriormente permitindo a representa\u00e7\u00e3o dos contradom\u00ednios de \npropriedades visuais como uma parti\u00e7\u00e3o de classes (Figura 3.5). Nesse modelo \nas inst\u00e2ncias que a comp\u00f5em s\u00e3o os poss\u00edveis valores para a propriedade. As-\nsim, propriedades visuais que tem mais de uma interpreta\u00e7\u00e3o em um dado do-\nm\u00ednio de discurso podem ser especializadas para suportar mais de um tipo de \ncontradom\u00ednio7. \n\nEm alguns casos \u00e9 preciso que se mantenha uma rela\u00e7\u00e3o de ordem expl\u00edcita \nentre os s\u00edmbolos que constituem o contradom\u00ednio de propriedades visuais, a \nfim de se simplificar o processo de interpreta\u00e7\u00e3o. No caso da propriedade com?\nprimento, por exemplo, existe uma rela\u00e7\u00e3o de \u201ctamanho\u201d entre os elementos \ndo seu contradom\u00ednio (longo \u00e9 maior que m\u00e9dio que, por sua vez, \u00e9 maior que \ncurto). Para representar esse tipo de rela\u00e7\u00e3o, o n\u00edvel visual define a proprieda-\nde maiorQue e a sua inversa menorQue, ambas transitivas, anti-sim\u00e9tricas e irre-\nflexivas. \n\nEntidadeVisual ValorDeComprimento\ntemComprimento\n\nlongom\u00e9diocurto\n\nComprimentoDeAvi\u00e3o ComprimentoDeCarroComprimentoGen\u00e9rico\n\nlongoAvi\u00e3om\u00e9dioAvi\u00e3ocurtoAvi\u00e3o longoCarrocurtoCarro\n\n \nFigura 3.5: Extens\u00e3o da modelagem de contradom\u00ednios de propriedades visuais. \n\n                                                 \n\n \n7 A rela\u00e7\u00e3o de subpropriedade permite tamb\u00e9m a especializa\u00e7\u00e3o das propriedades visuais, o \n\nque tamb\u00e9m colabora para solu\u00e7\u00e3o do problema de m\u00faltiplos dom\u00ednios. \n\n\n\n45 \n\n \n\n \n\n3.2.2.3 Rela\u00e7\u00f5es Espaciais \n\nRela\u00e7\u00f5es espaciais capturam as formas de relacionamento entre entidades do \ndom\u00ednio visual. Elas podem ser rela\u00e7\u00f5es de orienta\u00e7\u00e3o ou rela\u00e7\u00f5es topol\u00f3gicas. \nA sua fun\u00e7\u00e3o \u00e9 permitir a combina\u00e7\u00e3o de entidades visuais em entidades mais \ncomplexas. Da mesma forma como acontece com as propriedades visuais, as re-\nla\u00e7\u00f5es espaciais s\u00e3o representadas em OWL como um taxonomia de proprieda-\ndes (Figura 3.6). A propriedade OWL temRela\u00e7\u00e3oEspacial\u00a0 constitui a raiz \ndessa taxonomia. Se dom\u00ednio e contradom\u00ednio s\u00e3o definidos no conceito Enti?\ndadeVisual, bem como todas as suas subpropriedades. \n\n \nFigura 3.6: Taxonomia de rela\u00e7\u00f5es espaciais. \n\nRepresenta\u00e7\u00e3o de conhecimento e racioc\u00ednio sobre rela\u00e7\u00f5es topol\u00f3gicas s\u00e3o \nt\u00f3picos bastante recorrentes na literatura. Em um dos trabalhos mais importan-\nte da \u00e1rea, Cohn e colegas (1997; 1992) propuseram um conjunto de primitivas \n\n\n\n46 \n\n \n\n \n\nsimples e robusto para representa\u00e7\u00e3o de rela\u00e7\u00f5es topol\u00f3gicas, chamado RCC-8. \nO seu objetivo \u00e9 capturar todas as poss\u00edveis rela\u00e7\u00f5es topol\u00f3gicas entre duas en-\ntidades f\u00edsicas. No framework S-Chart as primitivas do RCC-8 s\u00e3o modeladas \nna forma de uma taxonomia, como em Santin (2008), conforme a Figura 3.6. \n\nRela\u00e7\u00f5es de orienta\u00e7\u00e3o tamb\u00e9m s\u00e3o importantes para modelar como dois ob-\njetos est\u00e3o posicionados um em rela\u00e7\u00e3o ao outro. O n\u00edvel visual disponibiliza as \npropriedades acimaDe, abaixoDe, aDireitaDe e aEsquerdaDe. Essas quatro \nrela\u00e7\u00f5es induzem um espa\u00e7o de duas dimens\u00f5es espaciais no n\u00edvel visual. Co-\nmo dito anteriormente, embora o processamento do sinal se d\u00ea em um espa\u00e7o \nde uma dimens\u00e3o, o racioc\u00ednio no n\u00edvel visual \u00e9 baseado em um espa\u00e7o duas \ndimens\u00f5es. \n\n3.2.3 N\u00edvel anal\u00f3gico \nAs primitivas no n\u00edvel anal\u00f3gico representam informa\u00e7\u00f5es extra\u00eddas direta-\n\nmente pelos algoritmos de processamento de sinal, como pontos, intervalos e \npadr\u00f5es. Analogamente ao n\u00edvel visual, as primitivas anal\u00f3gicas se dividem em \nentidades anal\u00f3gicas e suas propriedades (Figura 3.7).  \n\n \nFigura 3.7: Taxonomia de entidades anal\u00f3gicas e rela\u00e7\u00f5es de composi\u00e7\u00e3o. \n\nUm sinal anal\u00f3gico digitalizado \u00e9 caracterizado como um conjunto de pon-\ntos ordenados por uma dimens\u00e3o espacial. Uma entidade anal\u00f3gica \u00e9 um conjun-\nto de um ou mais pontos em alguma disposi\u00e7\u00e3o. Neste trabalho, uma entidade \nvisual pode ser um ponto, um conjunto de pontos, um intervalo ou um conjun-\nto de intervalos (Figura 3.7). Entidade b\u00e1sica de um sinal, o Ponto \u00e9 descrito pe-\nlas propriedades valor e \u00edndice: \n\n\u00a0\nDatatypeProperty:\u00a0valor\u00a0\n\u00a0 Annotations:\u00a0\u00a0\n\u00a0 \u00a0 rdfs:comment\u00a0\u201cValor\u00a0da\u00a0medida\u00a0de\u00a0um\u00a0Ponto\u00a0(y)\u201d\u00a0\n\u00a0 Domain:\u00a0Ponto\u00a0\n\u00a0 Range:\u00a0float\u00a0\u00a0\n\u00a0\u00a0\u00a0Characteristics:\u00a0Functional\u00a0\n\u00a0\nDatatypeProperty:\u00a0indice\u00a0\n\u00a0 Annotations:\u00a0\u00a0\n\u00a0\n\n\n\n47 \n\n \n\n \n\n\u00a0\n\u00a0 \u00a0 rdfs:comment\u00a0\u201c\u00cdndice\u00a0da\u00a0medide\u00a0de\u00a0um\u00a0Ponto\u00a0(x)\u201d\u00a0\n\u00a0 Domain:\u00a0Ponto\u00a0\n\u00a0 Range:\u00a0float\u00a0\u00a0\n\u00a0\u00a0\u00a0Characteristics:\u00a0Functional\u00a0\n\u00a0\n\nUma entidade anal\u00f3gica pode ser formada por outras. Essas rela\u00e7\u00f5es de con-\njuntos s\u00e3o capturadas por rela\u00e7\u00f5es de composi\u00e7\u00e3o, como a propriedade tem?\nPonto entre ConjuntoDePontos e Ponto. No caso da primitiva Intervalo, al-\nguns pontos podem ter um papel especial de ponto inicial, final, central, entre \noutros. Abaixo segue uma lista destas rela\u00e7\u00f5es. \n\n\u00a0\nObjectProperty:\u00a0temPonto\u00a0\n\u00a0\u00a0\u00a0\u00a0Domain:\u00a0ConjuntoDePontos\u00a0\n\u00a0\u00a0\u00a0\u00a0Range:\u00a0Ponto\u00a0\n\u00a0\nObjectProperty:\u00a0temPontoInicial\u00a0\n\u00a0\u00a0\u00a0\u00a0SubPropertyOf:\u00a0temPonto\u00a0\n\u00a0\u00a0\u00a0\u00a0Domain:\u00a0Intervalo\u00a0\n\u00a0\u00a0\u00a0\u00a0Characteristics:\u00a0Functional\u00a0\n\u00a0\nObjectProperty:\u00a0temPontoCentral\u00a0\n\u00a0\u00a0\u00a0\u00a0SubPropertyOf:\u00a0temPonto\u00a0\n\u00a0\u00a0\u00a0\u00a0Domain:\u00a0Intervalo\u00a0\n\u00a0\u00a0\u00a0\u00a0Characteristics:\u00a0Functional\u00a0\n\u00a0\nObjectProperty:\u00a0temPontoFinal\u00a0\n\u00a0\u00a0\u00a0\u00a0SubPropertyOf:\u00a0temPonto\u00a0\n\u00a0\u00a0\u00a0\u00a0Domain:\u00a0Intervalo\u00a0\n\u00a0\u00a0\u00a0\u00a0Characteristics:\u00a0Functional\u00a0\n\u00a0\nObjectProperty:\u00a0temPontoM\u00e1ximo\u00a0\n\u00a0 \u00a0Annotations:\u00a0\u00a0\n\u00a0 \u00a0 rdfs:comment\u00a0\u201cPonto\u00a0de\u00a0valor\u00a0m\u00e1ximo\u00a0de\u00a0um\u00a0Intervalo\u201d\u00a0\n\u00a0\u00a0\u00a0\u00a0SubPropertyOf:\u00a0temPonto\u00a0\n\u00a0\u00a0\u00a0\u00a0Domain:\u00a0Intervalo\u00a0\n\u00a0\u00a0\u00a0\u00a0Characteristics:\u00a0Functional\u00a0\n\u00a0\nObjectProperty:\u00a0temPontoM\u00ednimo\u00a0\n\u00a0 \u00a0Annotations:\u00a0\u00a0\n\u00a0 \u00a0 rdfs:comment\u00a0\u201cPonto\u00a0de\u00a0valor\u00a0m\u00ednimo\u00a0de\u00a0um\u00a0Intervalo\u201d\u00a0\n\u00a0\u00a0\u00a0\u00a0SubPropertyOf:\u00a0temPonto\u00a0\n\u00a0\u00a0\u00a0\u00a0Domain:\u00a0Intervalo\u00a0\n\u00a0\u00a0\u00a0\u00a0Characteristics:\u00a0Functional\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\n\nSemelhante ao que o ocorre no n\u00edvel visual, as entidades anal\u00f3gicas s\u00e3o ca-\nracterizadas por propriedades anal\u00f3gicas, fei\u00e7\u00f5es anal\u00f3gicas extra\u00eddas por algo-\nritmos de processamento num\u00e9rico. Cada entidade anal\u00f3gica \u00e9 definida pelo \nseu pr\u00f3prio conjunto de propriedades. Em geral, uma propriedade anal\u00f3gica \u00e9 \num \u00edndice num\u00e9rico calculado sobre as informa\u00e7\u00f5es anal\u00f3gicas contidas no si-\nnal. Alguns exemplos: \n\n \n\n\n\n48 \n\n \n\n \n\n\u00a0\nDatatypeProperty:\u00a0temPropriedadeAnal\u00f3gica\u00a0\n\u00a0 Domain:\u00a0EntidadeAnal\u00f3gica\u00a0\n\u00a0 Range:\u00a0float\u00a0\u00a0\n\u00a0\nDatatypeProperty:\u00a0temAreaAbsoluta\u00a0\n\u00a0 Domain:\u00a0Intervalo\u00a0\n\u00a0 Annotations:\u00a0\u00a0\n\u00a0 \u00a0 rdfs:comment\u00a0\u201cValor\u00a0de\u00a0\u00e1rea\u00a0total\u00a0sob\u00a0a\u00a0curva\u00a0de\u00a0um\u00a0Intervalo\u201d\u00a0\n\u00a0 SubPropertyOf:\u00a0temPropriedadeAnal\u00f3gica\u00a0\n\u00a0\nDatatypeProperty:\u00a0temArea\u00a0\n\u00a0 Domain:\u00a0Intervalo\u00a0\n\u00a0 Annotations:\u00a0\u00a0\n\u00a0 \u00a0 rdfs:comment\u00a0\u201cValor\u00a0da\u00a0integral\u00a0de\u00a0um\u00a0Intervalo\u201d\u00a0\n\u00a0 SubPropertyOf:\u00a0temPropriedadeAnal\u00f3gica\u00a0\n\u00a0\nDatatypeProperty:\u00a0temComprimento\u00a0\n\u00a0 Domain:\u00a0Intervalo\u00a0\n\u00a0 Annotations:\u00a0\u00a0\n\u00a0 \u00a0 rdfs:comment\u00a0\u201cValor\u00a0de\u00a0comprimento\u00a0de\u00a0um\u00a0Intervalo\u201d\u00a0\n\u00a0 SubPropertyOf:\u00a0temPropriedadeAnal\u00f3gica\u00a0\n\u00a0\nDatatypeProperty:\u00a0temTendencia\u00a0\n\u00a0 Domain:\u00a0Intervalo\u00a0\n\u00a0 Annotations:\u00a0\u00a0\n\u00a0 \u00a0 rdfs:comment\u00a0\u201cValor\u00a0de\u00a0inclina\u00e7\u00e3o\u00a0de\u00a0uma\u00a0reta\u00a0entre\u00a0Ponto\u00a0inicial\u00a0\u00a0\n\u00a0 \u00a0 \u00a0 e\u00a0Ponto\u00a0final\u00a0de\u00a0um\u00a0Intervalo\u201d\u00a0\n\u00a0 SubPropertyOf:\u00a0temPropriedadeAnal\u00f3gica\u00a0\n\u00a0\nDatatypeProperty:\u00a0temM\u00e9dia\u00a0\n\u00a0 Domain:\u00a0Intervalo\u00a0\n\u00a0 Annotations:\u00a0\u00a0\n\u00a0 \u00a0 rdfs:comment\u00a0\u201cValor\u00a0m\u00e9dio\u00a0da\u00a0curva\u00a0em\u00a0um\u00a0Intervalo\u201d\u00a0\n\u00a0 SubPropertyOf:\u00a0temPropriedadeAnal\u00f3gica\u00a0\n\u00a0\n\u00a0\nDatatypeProperty:\u00a0temGrauDeRu\u00eddo\u00a0\n\u00a0 Annotations:\u00a0\u00a0\n\u00a0 \u00a0 rdfs:comment\u00a0\u201cGrau\u00a0de\u00a0ru\u00eddo\u00a0em\u00a0uma\u00a0EntidadeAnal\u00f3gica\u201d\u00a0\n\u00a0 SubPropertyOf:\u00a0temPropriedadeAnal\u00f3gica\u00a0\n\u00a0\n\nOs algoritmos de processamento de sinal dispon\u00edveis tamb\u00e9m s\u00e3o modela-\ndos no n\u00edvel anal\u00f3gico, dado o importante papel que exercem na interpreta\u00e7\u00e3o. \nOutros trabalhos buscam representar esse tipo de informa\u00e7\u00e3o no n\u00edvel anal\u00f3gi-\nco, como \u00e9 o caso do projeto Orion apresentado na se\u00e7\u00e3o 2.2.4. Dessa forma, \u00e9 \nposs\u00edvel manter uma rela\u00e7\u00e3o expl\u00edcita entre as entidades visuais extra\u00eddas do \nsinal e os algoritmos que a extra\u00edram. Essa informa\u00e7\u00e3o \u00e9 importante, uma vez \nque o algoritmo usado para extrair uma entidade pode dizer muito sobre a sua \nnatureza. Aqui, os algoritmos s\u00e3o classificados em uma taxonomia simples, \ndemonstrada na Figura 3.8. O relacionamento entre as entidades visuais e os al-\ngoritmos de processamento se d\u00e1 propriedade pela propriedade \u00e9Extra\u00eddoCom. \nUma entidade \u00e9 extra\u00edda com um dado grau de certeza, capturado pela rela\u00e7\u00e3o \ntemFor\u00e7aDeExtra\u00e7\u00e3o. Mais especificamente: \n\n\n\n49 \n\n \n\n \n\n\u00a0\nObjectProperty:\u00a0\u00e9Extra\u00eddoComo\u00a0\n\u00a0\u00a0\u00a0\u00a0Domain:\u00a0EntidadeAnal\u00f3gica\u00a0\n\u00a0\u00a0\u00a0\u00a0Range:\u00a0Segmentador\u00a0\n\u00a0\nDatatypeProperty:\u00a0temFor\u00e7aDeExtra\u00e7\u00e3o\u00a0\n\u00a0 Domain:\u00a0EntidadeAnal\u00f3gica\u00a0\n\u00a0 Range:\u00a0float\u00a0\u00a0\n\u00a0\n\nEmbora o n\u00edvel anal\u00f3gico n\u00e3o busque representar todos os poss\u00edveis tipos de \nalgoritmos, ele serve como uma base para futuras extens\u00f5es, conforme as neces-\nsidades de cada dom\u00ednio de aplica\u00e7\u00e3o.  \n\n \nFigura 3.8: Taxonomia b\u00e1sica de funcionalidades de processamento de sinal. \n\n3.2.4 Mapeamento e ancoramento simb\u00f3lico \nCada n\u00edvel sem\u00e2ntico \u00e9 um modelo por si s\u00f3, independente dos demais. No \n\nentanto, para que os n\u00edveis possam ser combinados, \u00e9 necess\u00e1rio algum tipo de \nmapeamento. Essencialmente, o problema de ancoramento simb\u00f3lico entre os \nn\u00edveis pode ser dividido em duas partes. A primeira tange ao mapeamento de \nprimitivas mais abstratas em primitivas menos abstratas. Ou seja, como entida-\ndes b\u00e1sicas de um n\u00edvel podem ser combinadas para gerar uma entidade no n\u00ed-\nvel sem\u00e2ntico superior. Por exemplo, como e quais primitivas anal\u00f3gicas (ex.: \npixels e conjuntos de pixels) devem ser combinadas para indicar a exist\u00eancia de \numa entidade no n\u00edvel visual (ex.: uma curva de algum padr\u00e3o espec\u00edfico). A \nsegunda parte do problema consiste em, depois de realizada a extra\u00e7\u00e3o de uma \ninst\u00e2ncia de entidade no n\u00edvel superior, manter uma rela\u00e7\u00e3o concreta desta com \nas inst\u00e2ncias que serviram como evid\u00eancias no n\u00edvel inferior.  \n\nA fim de manter os modelos de mapeamento corretamente estruturados, \u00e9 \ndefinido que entidades e objetos de um n\u00edvel de abstra\u00e7\u00e3o podem ser mapeados \nexclusivamente no n\u00edvel imediatamente inferior. Ou seja, entidades do n\u00edvel \nsem\u00e2ntico podem ser mapeadas exclusivamente no n\u00edvel visual e estas, por sua \nvez, no n\u00edvel anal\u00f3gico. \n\nUma peculiaridade deste modelo \u00e9 que a formaliza\u00e7\u00e3o do mapeamento entre \nprimitivas \u00e9 definida com base no mapeamento entre inst\u00e2ncias. Embora essa \nrela\u00e7\u00e3o pare\u00e7a contra-intuitiva, ela se deve a forma como os algoritmos de in-\nterpreta\u00e7\u00e3o operam. A necessidade dessa rela\u00e7\u00e3o \u00e9 detalhada na se\u00e7\u00e3o 3.2.5 a \nseguir.  \n\n\n\n50 \n\n \n\n \n\n3.2.4.1 Mapeamento entre inst\u00e2ncias \n\nO ancoramento simb\u00f3lico requer que entidades interpretadas sejam ligadas \nexplicitamente \u00e0s evid\u00eancias que suportam essa interpreta\u00e7\u00e3o. Como descrito \nanteriormente, neste trabalho essas entidades interpretadas \u2013 e as suas evid\u00ean-\ncias \u2013 s\u00e3o representadas como inst\u00e2ncias de entidades de conhecimento visual. \nAssim, um modelo de ancoramento simb\u00f3lico deve incorporar uma forma de \nmapeamento expl\u00edcito entra as inst\u00e2ncias que representam as entidades detec-\ntadas em um n\u00edvel e as inst\u00e2ncias que representam as evid\u00eancias encontradas \nno n\u00edvel inferior. Para isso, o modelo de mapeamento incorpora uma rela\u00e7\u00e3o \nb\u00e1sica e quatro rela\u00e7\u00f5es espec\u00edficas: \n\n\u00a0\nObjectProperty:\u00a0temMapeamentoSimb\u00f3lico\u00a0\n\u00a0\nObjectProperty:\u00a0mapeamentoSem\u00e2nticoParaVisual\u00a0\n\u00a0 SubPropertyOf:\u00a0temMapeamentoSimb\u00f3lico\u00a0\n\u00a0 Domain:\u00a0EntidadeSem\u00e2ntica\u00a0\n\u00a0 Range:\u00a0EntidadeVisual\u00a0\n\u00a0 InverseOf:\u00a0mapeamentoVisualParaSem\u00e2ntico\u00a0\n\u00a0\nObjectProperty:\u00a0mapeamentoVisualParaSem\u00e2ntico\u00a0\n\u00a0 SubPropertyOf:\u00a0temMapeamentoSimb\u00f3lico\u00a0\n\u00a0 InverseOf:\u00a0mapeamentoSem\u00e2nticoParaVisual\u00a0\n\u00a0\nObjectProperty:\u00a0mapeamentoVisualParaAnal\u00f3gico\u00a0\n\u00a0 SubPropertyOf:\u00a0temMapeamentoSimb\u00f3lico\u00a0\n\u00a0 Domain:\u00a0EntidadeVisual\u00a0\n\u00a0 Range:\u00a0EntidadeAnal\u00f3gica\u00a0\n\u00a0 InverseOf:\u00a0mapeamentoAnal\u00f3gicoParaVisual\u00a0\n\u00a0\nObjectProperty:\u00a0mapeamentoAnal\u00f3gicoParaVisual\u00a0\n\u00a0 SubPropertyOf:\u00a0temMapeamentoSimb\u00f3lico\u00a0\n\u00a0 InverseOf:\u00a0mapeamentoVisualParaAnal\u00f3gico\u00a0\n\u00a0\n\nAs quatro rela\u00e7\u00f5es ajudam a definir limites claros entre os n\u00edveis, estrutu-\nrando-os. Ou seja, entidades do n\u00edvel sem\u00e2ntico podem ser mapeadas somente \npara entidades do n\u00edvel visual e estas somente para entidade no n\u00edvel anal\u00f3gico. \nN\u00e3o \u00e9 poss\u00edvel mapear o n\u00edvel sem\u00e2ntico diretamente no n\u00edvel anal\u00f3gico. \n\n3.2.4.2 Mapeamento entre primitivas: detectores simb\u00f3licos \n\nO mapeamento entre primitivas de n\u00edveis de abstra\u00e7\u00e3o distintos \u00e9 definido \npor detectores simb\u00f3licos. Um detector simb\u00f3lico define quais s\u00e3o as condi\u00e7\u00f5es \nnecess\u00e1rias para que uma dada primitiva sem\u00e2ntica ou visual seja corretamente \ndetectada. Os mecanismos de interpreta\u00e7\u00e3o utilizam essas condi\u00e7\u00f5es para testar \nas hip\u00f3teses de entidades sem\u00e2nticas e visuais. Por exemplo, um detector sim-\nb\u00f3lico para a primitiva sem\u00e2ntica Sequ\u00eancia define que uma inst\u00e2ncia de se-\nqu\u00eancia ser\u00e1 interpretada somente se uma inst\u00e2ncia da primitiva visual Curva?\nGaussiana estiver presente e sua propriedade temComprimento tiver o valor \nlongo. \n\n\n\n51 \n\n \n\n \n\nCada primitiva detect\u00e1vel \u00e9 mapeada por um conjunto com um ou mais de-\ntectores especializados. Da mesma forma que o mapeamento entre inst\u00e2ncias, \num detector relaciona primitivas somente entre n\u00edveis de abstra\u00e7\u00e3o adjacentes \n(sem\u00e2ntico/visual e visual/anal\u00f3gico). Cada detector \u00e9 modelado como uma \n\u00fanica regra. O formalismo escolhido aqui para a defini\u00e7\u00e3o de regras \u00e9 a lingua-\ngem SWRL (Semantic Web Rule Language), uma linguagem de regras definida \nsobre a linguagem OWL (HORROCKS et al., 2004). Para ser eficiente na mode-\nlagem de detectores simb\u00f3licos, a defini\u00e7\u00e3o de SWRL deve ser restringida. Ini-\ncialmente, uma regra SWRL tem a forma \n\n, \n\nonde ambos \u2013 antecedente e conseq\u00fcente \u2013 s\u00e3o compostos por uma conjun\u00e7\u00e3o \nde \u00e1tomos na forma \u2026 . Os \u00e1tomos s\u00e3o predicados n-\u00e1rios (ou \ndatalogs) semelhantes aos da l\u00f3gica de primeira ordem. Eles s\u00e3o de tr\u00eas tipos b\u00e1-\nsicos: (i) predicados un\u00e1rios representando classes do modelo (ex.: Pessoa(?x)); \n(ii) predicados bin\u00e1rios, representando propriedades do modelo (ex.: temFi-\nlho(?x, ?y)); e (iii) predicados n-\u00e1rios, representando fun\u00e7\u00f5es embutidas da lin-\nguagem SWRL (ex.: somar(?r, ?op1, ?op2)). Um exemplo de regra SWRL \u00e9 \n\nPessoa(?x)\u00a0?\u00a0temFilho(?x,\u00a0Jo\u00e3o)\u00a0?\u00a0temPai(Jo\u00e3o,\u00a0?x)\u00a0\u00a0\n\nque infere a propriedade temPai sobre o individuo de nome Jo\u00e3o, com base na \nclasse Pessoa e na propriedade temFilho. Uma regra SWRL \u00e9 satisfeita se, para \numa dada combina\u00e7\u00e3o de valores poss\u00edveis para as vari\u00e1veis (s\u00edmbolos prece-\ndidos de ponto-de-interroga\u00e7\u00e3o), o antecedente for satisfeito. Se isso acontecer, \no mecanismo de infer\u00eancia SWRL infere que o conseq\u00fcente tamb\u00e9m \u00e9 verdadei-\nro. \n\nPara aplica\u00e7\u00e3o em detectores simb\u00f3licos, os poss\u00edveis predicados que com-\np\u00f5em o antecedente e o conseq\u00fcente devem ser restritos, a fim de n\u00e3o permitir \nmapeamentos entre n\u00edveis n\u00e3o adjacentes. Assim, dado um conjunto P de pre-\ndicados un\u00e1rios (conceitos), bin\u00e1rios (propriedades) e predicados n-\u00e1rios (fun-\n\u00e7\u00f5es), sobre primitivas de um modelo de conhecimento visual. Dados os con-\njuntos de predicados Pinf de primitivas de um dado n\u00edvel (ex.: n. anal\u00f3gico), Psup \nde primitivas do n\u00edvel de sem\u00e2ntico imediatamente superior (ex.: n. visual), Pmap \nde primitivas de mapeamento entre inst\u00e2ncias e Pfun de fun\u00e7\u00f5es de SWRL, tal \nque inf sup map funP P P P P? ? ? ? . Dada uma regra r, um conjunto A de predicados \ndo seu antecedente e um conjunto C de predicados do seu conseq\u00fcente. Ou seja, \nse { }, , , ,1 2 3 nA a a a ... h=  e { }, , , ,1 2 3 mC c c c ... c= , a regra r \u00e9 dada por \n\n1 2 3... ...1 2 3 n ma a a a c c c c? ? ? ? ? ? ? ? ? . \n\nA regra r \u00e9 um detector simb\u00f3lico se inf sup( )map funA P P P P? ? ? ?  e \nsup( )funC P P? ? . Nessa forma, um detector simb\u00f3lico pode ter como anteceden-\n\nte um conjunto de primitivas em ambos os n\u00edveis relacionados, por\u00e9m pode ge-\nrar novas conclus\u00f5es somente no n\u00edvel de abstra\u00e7\u00e3o superior considerado. Isso, \nem conjunto com as rela\u00e7\u00f5es de mapeamento entre inst\u00e2ncias da se\u00e7\u00e3o anterior, \n\n\n\n52 \n\n \n\n \n\norganiza o dom\u00ednio e evita que entidades do dom\u00ednio sejam inferidas direta-\nmente a partir do sinal. \n\nComo mencionado anteriormente, cada primitiva detect\u00e1vel \u00e9 mapeada por \num conjunto de detectores simb\u00f3licos. Essa rela\u00e7\u00e3o \u00e9 formalizada restringindo-\nse o conjunto de axiomas C da seguinte forma. Dado um conjunto Pd composto \nde predicados representando primitivas detect\u00e1veis de um modelo, um predi-\ncado ? ? Pd e um conjunto dS P? ?  contendo ? e todas as suas subprimitivas. \nDado um conjunto DS de todas as regras de detec\u00e7\u00e3o desse modelo, uma regra r \n? DS e um conjunto Cr corresponde ao conjunto de predicados do conseq\u00fcente \nda regra r. Ent\u00e3o existe uma rela\u00e7\u00e3o , pDS?  tal que ?DS DS?  e \n\n( )r pr s r DS s C s S?? ? ? ? ? ? ? . Dessa forma, toda regra de detec\u00e7\u00e3o associada a \numa primitiva deve conter no seu conseq\u00fcente essa mesma primitiva ou algu-\nma de suas subprimitivas (subclasse ou subpropriedade). Por exemplo, consi-\nderando um detector simb\u00f3lico que mapeia a primitiva sem\u00e2ntica Sequ\u00eancia \nnas primitivas visuais CurvaGaussiana e temComprimento com valor longo. \nPara atender a todas restri\u00e7\u00f5es apresentadas anteriormente, ele teria a forma:  \n\n\u00a0\nEntidadeSem\u00e2ntica(?es)\u00a0?\u00a0mapeamentoSem\u00e2nticoParaVisual(?es,\u00a0?ev)\u00a0\u00a0\n\u00a0 ?\u00a0EntidadeVisual(?ev)\u00a0?\u00a0CurvaGaussiana(?ev)\u00a0\u00a0\n\u00a0 ?\u00a0temComprimento(?ev,longo)\u00a0\n?\u00a0Sequencia(?es)\u00a0\u00a0\n\u00a0\n\n\u00c9 importante que os detectores possam ser integrados diretamente nos mo-\ndelos OWL utilizados para representar o conhecimento visual, uma vez que co-\nnectam os n\u00edveis de abstra\u00e7\u00e3o representados nesse formalismo. O padr\u00e3o SWRL \ndefine ainda um metamodelo para representa\u00e7\u00e3o de regras integradas a mode-\nlos OWL. Ele associa explicitamente \u00e1tomos que comp\u00f5em as regras \u00e0s classes, \npropriedades e fun\u00e7\u00f5es correspondentes. Assim, classes e propriedades utiliza-\ndas nas regras podem ser checadas contra o modelo onde est\u00e3o representadas. \n\n Al\u00e9m disso, o metamodelo pode ser estendido para adicionar novas caracte-\nr\u00edsticas \u00e0s regras. Essa caracter\u00edstica \u00e9 importante, pois permite estender a lin-\nguagem SWRL para dar suporte ao agrupamento de regras em conjuntos de de-\ntectores simb\u00f3licos e ao relacionamento expl\u00edcito destes conjuntos com as primi-\ntivas de conhecimento visual que devem ser extra\u00eddas. Na pr\u00e1tica, Martin \nO\u2019Connor (O\u2019CONNOR et al., 2005) prop\u00f5e uma extens\u00e3o no metamodelo de \nSWRL, incluindo alguns construtos para agrupamento de regras. De forma \nsimplificada, eles s\u00e3o:  \n\n\u00a0\nClass:\u00a0RuleGroup\u00a0\n\u00a0 SubClassOf:\u00a0Entity\u00a0\n\u00a0\nObjectProperty:\u00a0hasRuleGroup\u00a0\n\u00a0 Domain:\u00a0swrl:Imp\u00a0\n\u00a0 Range:\u00a0RuleGroup\u00a0\n\u00a0\n\n\n\n53 \n\n \n\n \n\nonde swrl:Imp caracteriza a meta-entidade que captura uma regra SWRL. Ou \nseja, por esse modelo, regras SWRL pode ser agrupados em inst\u00e2ncias de Rule?\nGroup. Os servi\u00e7os de racioc\u00ednio de regras que d\u00e3o suporte a esse construto po-\ndem executar conjuntos de regras separadamente. \n\nAinda sim, n\u00e3o \u00e9 poss\u00edvel representar a rela\u00e7\u00e3o (?, DS?) entre uma primitiva \ne um conjunto de regras. Para isso, este trabalho define as seguintes metapro-\npriedades: \n\n\u00a0\nObjectProperty:\u00a0extra\u00eddoPorDS\u00a0\n\u00a0 Annotations:\u00a0\u00a0\n\u00a0 \u00a0 rdfs:comment\u00a0\u201cRelaciona\u00a0primitivas\u00a0com\u00a0grupos\u00a0de\u00a0\u00a0\n\u00a0 \u00a0 \u00a0 detectores\u00a0sim\u00f3licos.\u00a0Dom\u00ednio\u00a0pode\u00a0ser\u00a0qualquer\u00a0construto\u201d\u00a0\n\u00a0 Range:\u00a0swrla:RuleGroup\u00a0\n\u00a0 InverseOf:\u00a0extraiPrimitiva\u00a0\n\u00a0 Characteristics:\u00a0Functional,\u00a0InverseFunctional\u00a0\n\u00a0\nObjectProperty:\u00a0extraiPrimitiva\u00a0\n\u00a0 Domain:\u00a0swrla:RuleGroup\u00a0\n\u00a0 Range:\u00a0owl:Thing\u00a0\n\u00a0 InverseOf:\u00a0extra\u00eddoPorDS\u00a0\n\u00a0\n\nO mecanismo de interpreta\u00e7\u00e3o utiliza a rela\u00e7\u00e3o extra\u00eddoPorDS junto com os \ngrupos de regras SWRL para acionar somente o conjunto de detectores simb\u00f3li-\ncos necess\u00e1rios a extra\u00e7\u00e3o de uma primitiva. \n\nOs detectores simb\u00f3licos s\u00e3o utilizados para mapeamento entre quaisquer \nn\u00edveis. No entanto, o mapeamento entre do n\u00edvel visual e o n\u00edvel anal\u00f3gico deve \nlevar em conta a convers\u00e3o de valores num\u00e9ricos em objetos simb\u00f3licos. Por e-\nxemplo, dever ser poss\u00edvel representar explicitamente que o valor MuitoLongo \npara a propriedade visual comprimento corresponde a um comprimento anal\u00f3-\ngico em um dado intervalo de valores (ex.: entre 200m e  1500m). \n\nDe fato, o problema de quantiza\u00e7\u00e3o de valores \u00e9 recorrente na Intelig\u00eancia \nArtificial. Entre as diversas poss\u00edveis solu\u00e7\u00f5es existentes na literatura, est\u00e1 a so-\nlu\u00e7\u00e3o de mapeamento por conjuntos fuzzy proposta inicialmente por Corades-\nchi e colegas (CORADESCHI et al., 2001). No seu trabalho, Coradeschi define \nque uma propriedade anal\u00f3gica pode ser convertida para valores simb\u00f3licos a-\ntrav\u00e9s de conjuntos fuzzy definidos sobre o seu contradom\u00ednio. Um conjunto \nfuzzy \u00e9 definido como um par ,  onde D \u00e9 um conjunto de valores poss\u00edveis \ne m uma fun\u00e7\u00e3o tal que : 0,1 , chamada fun\u00e7\u00e3o de associa\u00e7\u00e3o. Para cada \nx D? , m(x) d\u00e1 o grau de associa\u00e7\u00e3o de x ao conjunto D. Se m(x) = 0, ent\u00e3o diz-se \nque o x n\u00e3o pertence ao conjunto fuzzy ,D m . Dando r\u00f3tulos simb\u00f3licos para \nos conjuntos e agrupando-os sobre um mesmo espa\u00e7o de valores D, \u00e9 poss\u00edvel \nquantizar esse espa\u00e7o de valores. \n\nA inclus\u00e3o de conjuntos fuzzy para mapeamento entre os n\u00edveis visual e ana-\nl\u00f3gico requer que a defini\u00e7\u00e3o dos detectores simb\u00f3licos seja sutilmente amplia-\nda. Em especial, o conjunto de predicados A definido anteriormente, que cor-\n\n\n\n54 \n\n \n\n \n\nresponde \u00e0s primitivas de hip\u00f3tese, deve prover algum tipo operador fuzzy. Es-\nse operador \u00e9 definido como uma fun\u00e7\u00e3o SWRL n-\u00e1ria na forma  \n\n1 1 2 2: (? , ? , ? , ? , ? , ? , , ? , ? )n nfuzzy associa v r fa tc fa tc fa tcL , \n\nonde as vari\u00e1veis ?v e ?r s\u00e3o interpretadas como o valor testado pela fun\u00e7\u00e3o e o \ntermo resultante, respectivamente. Cada dupla ?fan e ?tcn define uma fun\u00e7\u00e3o de \nassocia\u00e7\u00e3o trapezoidal com a sintaxe [v1 v2 v3 v4] ({ }1, 2 , 3, 4v v v v D D? ? ? ) e \nrespectivo termo que representa o conjunto. Os termos devem pertencer ao \nmesmo dom\u00ednio de valores de uma propriedade visual. Por exemplo, o detector \nsimb\u00f3lico  \n\n\u00a0\nEntidadeVisual(?ev)\u00a0? EntidadeAnal\u00f3gica(?ea)\u00a0\u00a0\n\u00a0 ? mapeamentoVisualParaAnal\u00f3gico(?ev,\u00a0?ea)\u00a0\u00a0\n\u00a0 ? Intervalo(?ea)\u00a0?\u00a0comprimento(?vn)\u00a0\u00a0\n\u00a0 ? fuzzy:associa(?vn,\u00a0?r,\u00a0\u201c[0,1\u00a05\u00a010\u00a015]\u201d,\u00a0comprimentoCurto,\u00a0\n\u00a0 \u00a0\u00a0 \u201c[10\u00a015\u00a020\u00a025]\u201d,\u00a0comprimentoLongo)\u00a0\u00a0\n\u00a0 ?\u00a0temComprimento(?ev,\u00a0?r)\u00a0\n\u00a0\n\nconverte valores anal\u00f3gicos de comprimento para valores simb\u00f3licos de tem?\nComprimento no n\u00edvel visual. A Tabela 3.2 abaixo mostra uma s\u00e9rie de poss\u00edveis \nvalores para as vari\u00e1veis ?vn e ?r do exemplo anterior e o resultado da avalia-\n\u00e7\u00e3o do predicado. \n\nTabela 3.2: Avalia\u00e7\u00e3o da fun\u00e7\u00e3o fuzzy:associa. \n?vn ?r Avalia\u00e7\u00e3o \n0,0 comprimentoCurto Falso \n\n1,2 \ncomprimentoCurto Verdadeiro \ncomprimentoLongo Falso \n\n11,0 \ncomprimentoCurto Verdadeiro \ncomprimentoLongo Verdadeiro \n\n21 \ncomprimentoCurto Falso \ncomprimentoLongo Verdadeiro \n\n30 comprimentoLongo Falso \n\nOs detectores simb\u00f3licos permitem, ent\u00e3o, que se estruturem os modelos \nde conhecimento organizadamente. Eles fornecem meios para facilitar a infe-\nr\u00eancia entre os n\u00edveis sem\u00e2nticos, ao mesmo tempo em que mant\u00e9m o n\u00edvel de \nexpressividade dos modelos. \n\n3.2.5 Componente de Interpreta\u00e7\u00e3o \nA m\u00e1quina de interpreta\u00e7\u00e3o sem\u00e2ntica da abordagem S-Chart \u00e9 operaciona-\n\nlizada por dois algoritmos que, juntos, realizam a extra\u00e7\u00e3o de fei\u00e7\u00f5es simb\u00f3licas \ndo sinal por gera\u00e7\u00e3o e teste de hip\u00f3tese. O seu funcionamento \u00e9 baseado na ma-\nnipula\u00e7\u00e3o dos modelos de conhecimento visual atrav\u00e9s dos seus tr\u00eas n\u00edveis se-\nm\u00e2nticos. Eles tamb\u00e9m fazem uso dos detectores simb\u00f3licos e dos mapeamen-\ntos entre inst\u00e2ncias do componente de ancoramento descrito anteriormente, a-\nl\u00e9m de acionar os algoritmos de processamento anal\u00f3gico do sinal.  \n\n\n\n55 \n\n \n\n \n\nA arquitetura da m\u00e1quina de interpreta\u00e7\u00e3o \u00e9 demonstrada na Figura 3.9. A \nsua entrada \u00e9 composta pelo sinal digitalizado e um conceito do dom\u00ednio que \ndeve ser encontrado no sinal. Esse conceito faz o papel de hip\u00f3tese inicial, uma \nvez que a leva em conta tamb\u00e9m suas subclasses e subpartes. O resultado final \nda interpreta\u00e7\u00e3o s\u00e3o inst\u00e2ncias de conceitos do dom\u00ednio relacionados \u00e0 hip\u00f3tese \ninicial de busca. \n\n \nFigura 3.9: Arquitetura do componente de interpreta\u00e7\u00e3o. \n\nEssa arquitetura se divide em dois componentes b\u00e1sicos, conforme mostra a \nFigura 3.9. A m\u00e1quina de interpreta\u00e7\u00e3o sem\u00e2ntica (MIS) operacionaliza o ancora-\nmento dos conceitos do n\u00edvel sem\u00e2ntico para o n\u00edvel visual. Ela tenta confirmar \na presen\u00e7a de conceitos no dom\u00ednio com base na suas extens\u00f5es no n\u00edvel visual, \ndefinidos por detectores simb\u00f3licos. Ao mesmo tempo, a MIS coloca a cargo da \nm\u00e1quina de interpreta\u00e7\u00e3o visual (MIV) a extra\u00e7\u00e3o das primitivas visuais direta-\nmente do n\u00edvel anal\u00f3gico. O seu papel \u00e9 acionar os algoritmos de processamen-\nto de sinal para extra\u00e7\u00e3o de fei\u00e7\u00f5es anal\u00f3gicas no sinal dado como entrada no \ncomponente de interpreta\u00e7\u00e3o e interpret\u00e1-los em termos de primitivas visuais \nvia os seus pr\u00f3prios detectores simb\u00f3licos.  \n\nA representa\u00e7\u00e3o dos algoritmos neste trabalho requer algumas explica\u00e7\u00f5es. \nAmbos os algoritmos utilizam informa\u00e7\u00f5es de contexto durante racioc\u00ednio, co-\nmo os modelos de conhecimento visual, inst\u00e2ncias do modelo e o sinal propri-\namente dito. O contexto \u00e9 proporcionado por uma estrutura Contexto definida \nna Tabela 3.3. Essa estrutura \u00e9 utilizada para armazenar os resultados das infe-\nr\u00eancias e troca de informa\u00e7\u00f5es entre as m\u00e1quinas MIS e MIV. \n\nAl\u00e9m disso, em alguns lugares, os algoritmos se referem a primitivas de re-\npresenta\u00e7\u00e3o de conhecimento do OWL (na forma prefixo:primitiva). Essas \n\n\n\n56 \n\n \n\n \n\nprimitivas se organizam em uma ontologia de representa\u00e7\u00e3o de conhecimento \n(ver Anexo). \n\nTabela 3.3: Vari\u00e1veis de contexto para interpreta\u00e7\u00e3o sem\u00e2ntica \nContexto.NivelSem\u00e2ntico.TBox\u00a0 Conjunto de primitivas do n\u00edvel sem\u00e2ntico \nContexto.NivelSem\u00e2ntico.ABox\u00a0 Conjunto de inst\u00e2ncias de primitivas do n\u00edvel sem\u00e2ntico \n\nContexto.N\u00edvelVisual.TBox\u00a0 Conjunto de primitivas do n\u00edvel visual \nContexto.N\u00edvelVisual.ABox\u00a0 Conjunto de inst\u00e2ncias de primitivas do n\u00edvel visual \n\nContexto.N\u00edvelAnal\u00f3gico.Box\u00a0 Conjunto de primitivas do n\u00edvel anal\u00f3gico \nContexto.N\u00edvelAnal\u00f3gico.ABox\u00a0 Conjunto de inst\u00e2ncias de primitivas do n\u00edvel anal\u00f3gico \n\nContexto.Sinal\u00a0 Representa\u00e7\u00e3o digital do sinal analisado \n\nNas se\u00e7\u00f5es seguintes, as m\u00e1quinas MIS e MIV s\u00e3o descritas em maior deta-\nlhe. \n\n3.2.5.1 M\u00e1quina de interpreta\u00e7\u00e3o sem\u00e2ntica (MIS) \n\nA MIS busca combinar fei\u00e7\u00f5es visuais extra\u00eddas do n\u00edvel anal\u00f3gico para de-\ntectar entidades sem\u00e2nticas que tenham express\u00e3o visual. A sua entrada corres-\nponde a um conjunto de conceitos do n\u00edvel sem\u00e2ntico que indica uma hip\u00f3tese \ninicial de entidade a ser extra\u00edda. As sa\u00eddas correspondem \u00e0s inst\u00e2ncias de enti-\ndades do dom\u00ednio efetivamente encontradas no sinal. O processo de interpreta-\n\u00e7\u00e3o visual \u00e9 operacionalizado pelo Algoritmo 3.1. \n\nMais especificamente, a sua entrada corresponde a um conjunto de classes \ndo n\u00edvel sem\u00e2ntico (no caso, classes do tipo owl:Class) em hipoInicial. Elas \ncorrespondem \u00e0s primitivas do n\u00edvel sem\u00e2ntico que formam as hip\u00f3teses de en-\ntidades presentes no sinal. O primeiro la\u00e7o do algoritmo (linhas 5-8) verifica se \ntodas as primitivas de hipoInicial s\u00e3o mesmo primitivas do n\u00edvel sem\u00e2ntico.  \n\nO segundo la\u00e7o (linhas 12-14) busca por todos os conceitos relacionados \u00e0s \nprimitivas iniciais atrav\u00e9s da fun\u00e7\u00e3o buscaRelacionados(owl:Class\u00a0primi?\ntiva). Essa fun\u00e7\u00e3o busca o fecho transitivo de todas as subclasses e subpartes \nde primitiva. O la\u00e7o resulta no conjunto hipoCompleta de todas as primitivas \nque podem ser encontradas no sinal. \n\nO terceiro la\u00e7o (linhas 22-30)  separa as primitivas de hipoCompleta que a-\npresentam uma express\u00e3o visual no n\u00edvel visual. Isso \u00e9 realizado buscando por \nprimitivas do dom\u00ednio que est\u00e3o relacionadas a conjuntos de detectores simb\u00f3-\nlicos pela rela\u00e7\u00e3o de mapeamento extra\u00eddoPorDS. Os detectores simb\u00f3licos de \ncada conjunto s\u00e3o tomados um a um para processamento (linha 24).  Eles s\u00e3o \nagrupados no conjunto detectoresSimb\u00f3licosSelecionados para posterior \nexecu\u00e7\u00e3o. A processo de separa\u00e7\u00e3o das primitivas visuais (linhas 26-29) consiste \nem procurar no antecedente de cada detector simb\u00f3lico \u00e1tomos que represen-\ntem primitivas pertencentes ao n\u00edvel visual. As primitivas encontradas (concei-\ntos ou propriedades visuais) s\u00e3o separadas no conjunto primitivasVisuai?\nsEsperadas. \n\nAs primitivas visuais esperadas s\u00e3o ent\u00e3o encaminhadas para processamen-\nto na interpreta\u00e7\u00e3oAnal\u00f3gica (linha 35). O resultado da interpreta\u00e7\u00e3o \u00e9 \ncomposto de inst\u00e2ncias de primitivas visuais que podem ou n\u00e3o ser significan-\n\n\n\n57 \n\n \n\n \n\ntes para interpreta\u00e7\u00e3o. Ap\u00f3s, cada uma dessas mesmas inst\u00e2ncias s\u00e3o mapeadas \nem um \u00fanica inst\u00e2ncia de EntidadeSm\u00e2ntica atrav\u00e9s do procedimento mapVi?\nsualSem\u00e2ntico(), descrito no Algoritmo 3.2. \n\nO procedimento executaDetectoresSimb\u00f3licos(swrl:Imp\u00a0cds{})  apli-\nca as regras que constituem os detectores simb\u00f3licos selecionados sobre o mo-\ndelo de conhecimento simb\u00f3lico (modelos mais inst\u00e2ncias), realizando a infe-\nr\u00eancia propriamente dita. Uma vez que os detectores s\u00e3o formalizados em na \nlinguagem SWRL, essa fun\u00e7\u00e3o pode corresponder \u00e0 execu\u00e7\u00e3o de uma ferramen-\nta de interpreta\u00e7\u00e3o de regras SWRL. O resultado ser\u00e1 a classifica\u00e7\u00e3o das inst\u00e2n-\ncias de EntidadeSem\u00e2ntica em classes do dom\u00ednio mais espec\u00edficas. Ao fim, \ninst\u00e2ncias do n\u00edvel sem\u00e2ntico n\u00e3o classificadas como alguma entidade do do-\nm\u00ednio \u2013 portanto inst\u00e2ncias somente da classe EntidadeSem\u00e2ntica \u2013 s\u00e3o remo-\nvidas no ultimo la\u00e7o do algoritmo (linhas 45-50). \n\nO resultado de todo o processo de interpreta\u00e7\u00e3o visual pode ser encontrado \nem Contexto.N\u00edvelSem\u00e2ntico.Inst. No entanto, por conveni\u00eancia, a fun\u00e7\u00e3o \nde interpreta\u00e7\u00e3o retorna diretamente as inst\u00e2ncias resultantes do algoritmo. \n1 interpreta\u00e7\u00e3oSem\u00e2ntica\u00a0(owl:Class\u00a0hipoInicial{})\u00a0:\u00a0EntidadeSem\u00e2ntica{}\u00a0\n2 \u00a0\n3 \u00a0 //verifica\u00a0se\u00a0todas\u00a0os\u00a0conceitos\u00a0de\u00a0hipotese\u00a0\u00a0\n4 \u00a0 //pertencem\u00a0ao\u00a0dom\u00ednio\u00a0\n5 \u00a0 owl:Class\u00a0hipoInicialVerificada{};\u00a0\n6 \u00a0 para?cada\u00a0c\u00a0?\u00a0hipoInicial\u00a0fa\u00e7a\u00a0\u00a0\n7 \u00a0 \u00a0 se\u00a0(c\u00a0?\u00a0Contexto.NivelSem\u00e2ntico.TBox)\u00a0ent\u00e3o\u00a0\n8 \u00a0 \u00a0 \u00a0 hipoInicialVerificada\u00a0=\u00a0hipoInicialVerificada\u00a0?\u00a0c;\u00a0\n9 \u00a0\n10 \u00a0\n11 \u00a0\u00a0\u00a0//busca\u00a0todas\u00a0os\u00a0conceitos\u00a0relacionados\u00a0com\u00a0as\u00a0hipoteses\u00a0inicial\u00a0\n12 \u00a0 owl:Class\u00a0hipoCompleta{};\u00a0\n13 \u00a0 para?cada\u00a0c\u00a0?\u00a0hipoInicialVerificada\u00a0fa\u00e7a\u00a0\u00a0\n14 \u00a0 \u00a0 hipoCompleta\u00a0=\u00a0hipoCompleta\u00a0?\u00a0buscaRelacionadosSem\u00e2ntico(c);\u00a0\n15 \u00a0\n16 \u00a0 //seleciona\u00a0quais\u00a0entidades\u00a0do\u00a0dom\u00ednio\u00a0t\u00eam\u00a0express\u00e3o\u00a0visual,\u00a0\n17 \u00a0 //ou\u00a0seja,\u00a0quais\u00a0s\u00e3o\u00a0mapeadas\u00a0por\u00a0detectores\u00a0simb\u00f3licos\u00a0\n18 \u00a0 //e\u00a0quais\u00a0primitivas\u00a0visuais\u00a0(classes\u00a0e\u00a0propriedades)\u00a0s\u00e3o\u00a0utilizadas\u00a0\n19 \u00a0 owl:Class\u00a0entidadesMapeadas{};\u00a0\n20 \u00a0 swrl:Imp\u00a0detectoresSimb\u00f3licosSelecionados{};\u00a0\n21 \u00a0 rdf:Resource\u00a0primitivasVisuaisEsperadas{};\u00a0\n22 \u00a0 para?cada\u00a0c\u00a0?\u00a0hipoCompleta\u00a0fa\u00e7a\u00a0\u00a0\n23 \u00a0 \u00a0 se\u00a0:extra\u00eddoPorDS(c,\u00a0DS)\u00a0ent\u00e3o\u00a0\n24 \u00a0 \u00a0 \u00a0 para?cada\u00a0r\u00a0?\u00a0DS\u00a0fa\u00e7a\u00a0{\u00a0\n25 \u00a0 \u00a0 \u00a0 \u00a0\u00a0detectoresSimb\u00f3licosSelecionados\u00a0=\u00a0detectoresSimb\u00f3licosSelecionados\u00a0?\u00a0r;\u00a0\n26 \u00a0 \u00a0 \u00a0 \u00a0 rdf:Resource\u00a0atomosC\u00a0=\u00a0r.antecedente;\u00a0\n27 \u00a0 \u00a0 \u00a0 \u00a0 para?cada\u00a0atomo\u00a0?\u00a0DS\u00a0fa\u00e7a\u00a0\u00a0\n28 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 se\u00a0atomo\u00a0?\u00a0Contexto.NivelVisual.TBox\u00a0ent\u00e3o\u00a0\n29 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0\u00a0\u00a0primitivasVisuaisEsperadas\u00a0=\u00a0primitivasVisuaisEsperadas\u00a0?\u00a0atomo;\u00a0\n30 \u00a0 \u00a0 \u00a0 }\u00a0\n31 \u00a0 \u00a0 \u00a0 \u00a0\n32 \u00a0 //aciona\u00a0o\u00a0componente\u00a0de\u00a0interpreta\u00e7\u00e3o\u00a0anal\u00f3gica\u00a0\u00a0\n33 \u00a0 //\u00a0as\u00a0entidade\u00a0visuais\u00a0resultantes\u00a0s\u00e3o\u00a0acessiveis\u00a0\u00a0\n34 \u00a0 //\u00a0em\u00a0Contexto.NivelVisual.Inst\u00a0\n35 \u00a0 interpreta\u00e7\u00e3oAnal\u00f3gica(primitivasVisuaisEsperadas);\u00a0\n36 \u00a0\n37 \u00a0 //mapeia\u00a0cada\u00a0entidade\u00a0visual\u00a0em\u00a0Contexto.NivelVisual.Inst\u00a0\u00a0\n38 \u00a0 //como\u00a0uma\u00a0instancia\u00a0de\u00a0:EntidadeSem\u00e2ntica\u00a0em\u00a0Contexto.NivelSem\u00e2ntico.Inst\u00a0\n39 \u00a0 mapVisualSem\u00e2ntico();\u00a0\n\n\n\n58 \n\n \n\n \n\n40 \u00a0\n41 \u00a0 //executa\u00a0detectores\u00a0simb\u00f3licos\u00a0das\u00a0entidades\u00a0sem\u00e2nticas\u00a0separados\u00a0anteriormente\u00a0\n42 \u00a0 executaDetectoresSimb\u00f3licos(detectoresSimb\u00f3licosSelecionados);\u00a0\n43 \u00a0 \u00a0\n44 \u00a0 //remove\u00a0inst\u00e2ncias\u00a0n\u00e3o\u00a0classificadas,\u00a0ou\u00a0seja,\u00a0hipoteses\u00a0que\u00a0n\u00e3o\u00a0se\u00a0confirmaram\u00a0\n45 \u00a0 EntidadeSem\u00e2ntica\u00a0resultado{};\u00a0\n46 \u00a0 para?cada\u00a0es\u00a0?\u00a0Contexto.N\u00edvelSem\u00e2ntico.ABox\u00a0fa\u00e7a\u00a0\n47 \u00a0 \u00a0 se\u00a0?c(rdf:type(es,\u00a0c)\u00a0?\u00a0c\u00a0?\u00a0EntidadeSem\u00e2ntica)\u00a0ent\u00e3o\u00a0\n48 \u00a0 \u00a0 \u00a0 Contexto.N\u00edvelSem\u00e2ntico.ABox\u00a0=\u00a0Contexto.N\u00edvelSem\u00e2ntico.ABox\u00a0?\u00a0es\u00a0\n49 \u00a0 \u00a0 sen\u00e3o\u00a0\n50 \u00a0 \u00a0 \u00a0 resultado\u00a0=\u00a0resultado\u00a0?\u00a0es;\u00a0\n51 \u00a0 //para\u00a0conveniencias,\u00a0retorna\u00a0entidades\u00a0classificadas\u00a0\n52 \u00a0 //elas\u00a0podem\u00a0ser\u00a0acessadas\u00a0fora\u00a0do\u00a0algortimo\u00a0em\u00a0\u00a0\n53 \u00a0 retorna\u00a0resultado;\u00a0\n54 }\u00a0\n\nAlgoritmo 3.1: fun\u00e7\u00e3o de opera\u00e7\u00e3o da m\u00e1quina de interpreta\u00e7\u00e3o sem\u00e2ntica \n55 mapVisualSem\u00e2ntico\u00a0(){\u00a0\n56 \u00a0\n57 \u00a0 //agrupa\u00a0inst\u00e2ncias\u00a0de\u00a0EntidadeVisuais\u00a0\n58 \u00a0 :EntidadeVisual\u00a0entidadesDetectadas{};\u00a0\n59 \u00a0 para?cada\u00a0inst\u00a0?\u00a0Contexto.NivelVisual.ABox\u00a0fa\u00e7a\u00a0\n60 \u00a0 \u00a0 se\u00a0owl:SubClassOf(inst,\u00a0:EntidadeVisual)\u00a0ent\u00e3o\u00a0\n61 \u00a0 \u00a0 \u00a0 entidadesDetectadas\u00a0=\u00a0entidadesDetectadas\u00a0?\u00a0r;\u00a0\n62 \u00a0 \u00a0\n63 \u00a0 //cria\u00a0uma\u00a0EntidadeSem\u00e2ntica\u00a0para\u00a0EntidadeVisual\u00a0n\u00e3o\u00a0mapeada\u00a0\n64 \u00a0 para?cada\u00a0iev\u00a0?\u00a0entidadesDetectadas\u00a0fa\u00e7a\u00a0\n65 \u00a0 \u00a0 se\u00a0!(?x(mapeamentoSem\u00e2nticoParaVisual(x,\u00a0iev)))\u00a0ent\u00e3o\u00a0{\u00a0\n66 \u00a0 \u00a0 \u00a0 EntidadeSemantica\u00a0novaEntidade\u00a0=\u00a0novaInstancia(:EntidadeSemantica);\u00a0\n67 \u00a0 \u00a0 \u00a0 Contexto.NivelVisual.ABox\u00a0=\u00a0Contexto.NivelVisual.ABox\u00a0\u00a0\n68 \u00a0 \u00a0 \u00a0 \u00a0 ?\u00a0novaEntidade\u00a0?\u00a0mapeamentoSem\u00e2nticoParaVisual(novaEntidade,\u00a0iev);\u00a0\n69 \u00a0 \u00a0 }\u00a0\n70 }\u00a0\n\nAlgoritmo 3.2: procedimento de mapeamento visual/sem\u00e2ntico \n\n3.2.5.2 M\u00e1quina de interpreta\u00e7\u00e3o visual (MIV) \n\nA m\u00e1quina MIV \u00e9 executada a partir de requisi\u00e7\u00f5es da m\u00e1quina MIS. Ela re-\ncebe como entrada um conjunto de primitivas visuais que possivelmente exis-\ntem no sinal e tenta confirm\u00e1-las atrav\u00e9s dos seus detectores simb\u00f3licos mapea-\ndos em primitivas do n\u00edvel anal\u00f3gico. A MIV se encarrega ainda de acionar os \nmecanismos de processamento de sinal para extra\u00e7\u00e3o das caracter\u00edsticas anal\u00f3-\ngicas do sinal. Embora o algoritmo n\u00e3o tenha uma sa\u00edda propriamente dita, os \nresultados da sua execu\u00e7\u00e3o (inst\u00e2ncias de EntidadeVisual) s\u00e3o alocados em \nContexto.N\u00edvelVisual.Abox para que a maquina MIS tenha acesso. O algo-\nritmo que operacionaliza a m\u00e1quina MIV \u00e9 descrito pelo Algoritmo 3.3. \n\nO primeiro la\u00e7o (linhas 4-6) busca por primitiva relacionadas na taxonomia \nonde elas est\u00e3o inseridas. Essa entidade pode ser uma classe ou uma rela\u00e7\u00e3o. \nMais especificamente, a fun\u00e7\u00e3o buscaRelacionadosVisual(rdf:Resource\u00a0\nres) retorna o conjunto de todas as subclasses de res e todas as suas superclas-\nses, caso res seja uma classe. Se res \u00e9 uma rela\u00e7\u00e3o, ent\u00e3o o retorno da fun\u00e7\u00e3o \u00e9 \num conjunto com todas as sub-rela\u00e7\u00f5es e super-rela\u00e7\u00f5es de res.  \n\nCom a hip\u00f3tese visual completa, busca-se por detectores simb\u00f3licos associa-\ndos \u00e0s primitivas visuais em hipoVisualCompleta (linhas 12-24). De forma \n\n\n\n59 \n\n \n\n \n\nsemelhante ao que ocorre do terceiro la\u00e7o do algoritmo de interpreta\u00e7\u00e3o sem\u00e2n-\ntica, o algoritmo analisa os detectores simb\u00f3licos encontrados em busca de pri-\nmitivas anal\u00f3gicas referenciadas (classes ou rela\u00e7\u00f5es). Essas entidade s\u00e3o guar-\ndadas no conjunto primitivasAnal\u00f3gicasEsperadas. \n\nAs linhas 28-34 operacionalizam a extra\u00e7\u00e3o das primitivas anal\u00f3gicas espe-\nradas. Cada uma das primitivas \u00e9 repassada ao componente de processamento \nde sinal pela fun\u00e7\u00e3o extrairEntidadeAnal\u00f3gica(rdf:Resource\u00a0 p).  Essa \nfun\u00e7\u00e3o deve acionar um algoritmo de processamento de sinal (armazenada na \nestrutura Contexto.Sinal) espec\u00edfico para extra\u00e7\u00e3o da primitiva p. As inst\u00e2n-\ncias de primitivas extra\u00eddas devem ser guardadas em Contex?\nto.N\u00edvelSem\u00e2ntico.ABox. A fun\u00e7\u00e3o retorna a quantidade de inst\u00e2ncias extra-\n\u00eddas. De fato, a implementa\u00e7\u00e3o dessa funcionalidade pode corresponder a um \ncomponente de software complexo por si s\u00f3. Uma vez que essa fun\u00e7\u00e3o n\u00e3o de-\npende de aspectos de representa\u00e7\u00e3o e interpreta\u00e7\u00e3o de conhecimento visual, a \nsua descri\u00e7\u00e3o detalhada foge do escopo deste trabalho e \u00e9 omitida. No entanto, \nno estudo de caso descrito no Cap\u00edtulo 5 \u00e9 apresentada uma vers\u00e3o simplificada \n\u2013 mas efetiva \u2013 para ela. O la\u00e7o \u00e9 executado at\u00e9 que nenhum novo resultado seja \ngerado. Isso garante que poss\u00edveis rela\u00e7\u00f5es de depend\u00eancia entre primitivas n\u00e3o \ninfluenciem nos resultados. \n\nO procedimento mapAnal\u00f3gicoVisual() executa fun\u00e7\u00e3o semelhante ao \nprocedimento descrito em Algoritmo 3.3, porem dessa vez mapeando inst\u00e2ncias \nde EntidadeAnal\u00f3gica para inst\u00e2ncias de EntidadeVisual. J\u00e1 o procedimento \nexecutaDetectoresSimb\u00f3licos(swrl:Imp\u00a0 cds{}) executa os detectores \nsimb\u00f3licos de entidade visuais para classific\u00e1-las em primitivas mais espec\u00edfi-\ncas.  Por fim, o algoritmo retorna o controle da execu\u00e7\u00e3o para a m\u00e1quina MIS, \nsendo que o resultado da execu\u00e7\u00e3o est\u00e1 armazenado em Contex?\nto.NivelVisual.TBox.  \n1 interpreta\u00e7\u00e3oVisual(rdf:Resource\u00a0hipoVisualInicial{}){\u00a0\n2 \u00a0\n3 \u00a0\u00a0\u00a0//busca\u00a0todas\u00a0os\u00a0conceitos\u00a0relacionados\u00a0com\u00a0as\u00a0hipoteses\u00a0inicial\u00a0\n4 \u00a0 rdf:Resource\u00a0hipoVisualCompleta{};\u00a0\n5 \u00a0 para?cada\u00a0c\u00a0?\u00a0hipoVisualInicial\u00a0fa\u00e7a\u00a0\u00a0\n6 \u00a0 \u00a0 hipoVisualCompleta\u00a0=\u00a0hipoVisualCompleta\u00a0?\u00a0buscaRelacionadosVisual(c);\u00a0\n7 \u00a0 \u00a0\n8 \u00a0 \u00a0 \u00a0\n9 \u00a0 //seleciona\u00a0as\u00a0entidades\u00a0visuais\u00a0que\u00a0realmente\u00a0t\u00eam\u00a0express\u00e3o\u00a0anal\u00f3gica,\u00a0\n10 \u00a0 //ou\u00a0seja,\u00a0quais\u00a0s\u00e3o\u00a0mapeadas\u00a0por\u00a0detectores\u00a0simb\u00f3licos\u00a0\n11 \u00a0 //e\u00a0quais\u00a0primitivas\u00a0anal\u00f3gicas\u00a0(classes\u00a0e\u00a0propriedades)\u00a0s\u00e3o\u00a0utilizadas\u00a0\n12 \u00a0 rdf:Resource\u00a0entidadesMapeadas{};\u00a0\n13 \u00a0 swrl:Imp\u00a0detectoresSimb\u00f3licosSelecionados{};\u00a0\n14 \u00a0 rdf:Resource\u00a0primitivasAnal\u00f3gicasEsperadas{};\u00a0\n15 \u00a0 para?cada\u00a0c\u00a0?\u00a0hipoVisualCompleta\u00a0fa\u00e7a\u00a0\u00a0\n16 \u00a0 \u00a0 se\u00a0:extra\u00eddoPorDS(c,\u00a0DS)\u00a0ent\u00e3o\u00a0\n17 \u00a0 \u00a0 \u00a0 para?cada\u00a0r\u00a0?\u00a0DS\u00a0fa\u00e7a\u00a0{\u00a0\n18 \u00a0 \u00a0 \u00a0 \u00a0\u00a0detectoresSimb\u00f3licosSelecionados\u00a0=\u00a0detectoresSimb\u00f3licosSelecionados\u00a0?\u00a0r;\u00a0\n19 \u00a0 \u00a0 \u00a0 \u00a0 rdf:Resource\u00a0atomosC\u00a0=\u00a0r.antecedente;\u00a0\n20 \u00a0 \u00a0 \u00a0 \u00a0 para?cada\u00a0atomo\u00a0?\u00a0DS\u00a0fa\u00e7a\u00a0\u00a0\n21 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 se\u00a0atomo\u00a0?\u00a0Contexto.N\u00edvelAnal\u00f3gico.TBox\u00a0ent\u00e3o\u00a0\n22 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 primitivasAnal\u00f3gicasEsperadas\u00a0=\u00a0primitivasAnal\u00f3gicasEsperadas\u00a0\u00a0\n23 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ?\u00a0atomo;\u00a0\n24 \u00a0 \u00a0 \u00a0 }\u00a0\n\n\n\n60 \n\n \n\n \n\n25 \u00a0\n26 \u00a0 //Aciona\u00a0os\u00a0algoritmos\u00a0de\u00a0processamento\u00a0de\u00a0sinal\u00a0para\u00a0extra\u00e7\u00e3o\u00a0\u00a0\n27 \u00a0 //\u00a0de\u00a0entidades\u00a0anal\u00f3gicas\u00a0esperadas\u00a0\n28 \u00a0 Inteiro\u00a0resultado;\u00a0\n29 \u00a0 fa\u00e7a{\u00a0\n30 \u00a0 \u00a0 resultado\u00a0=\u00a00;\u00a0\n31 \u00a0 \u00a0 para?cada\u00a0p\u00a0?\u00a0hipoVisualCompleta\u00a0fa\u00e7a\u00a0\n32 \u00a0 \u00a0 \u00a0 resultado\u00a0=\u00a0extrairEntidadeAnal\u00f3gica(p);\u00a0\n33 \u00a0 \u00a0 \u00a0\n34 \u00a0 }\u00a0enquanto\u00a0resultado\u00a0?\u00a00;\u00a0\n35 \u00a0\n36 \u00a0 //mapeia\u00a0cada\u00a0EntidadeAnal\u00f3gica\u00a0em\u00a0Contexto.NivelAnal\u00f3gico.Inst\u00a0\u00a0\n37 \u00a0 //como\u00a0uma\u00a0instancia\u00a0de\u00a0EntidadeVisual\u00a0em\u00a0Contexto.Nivelvisual.Inst\u00a0\n38 \u00a0 mapAnal\u00f3gicoVisual();\u00a0\n39 \u00a0\n40 \u00a0 //executa\u00a0detectores\u00a0simb\u00f3licos\u00a0das\u00a0entidades\u00a0visuais\u00a0separados\u00a0anteriormente\u00a0\n41 \u00a0 executaDetectoresSimb\u00f3licos(detectoresSimb\u00f3licosSelecionados);\u00a0\n42 }\u00a0\n\nAlgoritmo 3.3: procedimento de opera\u00e7\u00e3o da m\u00e1quina de interpreta\u00e7\u00e3o visual \n\n3.2.5.3 Considera\u00e7\u00f5es sobre ancoramento simb\u00f3lico \n\nO funcionamento geral do componente de interpreta\u00e7\u00e3o pode ser classifica-\ndo com uma abordagem mista de ancoramento simb\u00f3lico. Ele operacionaliza o \nracioc\u00ednio top-down, ao restringir as poss\u00edveis interpreta\u00e7\u00f5es a partir da hip\u00f3tese \ninicial informada. Somente os detectores simb\u00f3licos relacionados \u00e0s hip\u00f3teses \niniciais \u2013 por rela\u00e7\u00f5es de taxonomia ou partonomia \u2013 ser\u00e3o acionados. Ou seja, a \ngera\u00e7\u00e3o de hip\u00f3teses no \u201ctopo\u201d da arquitetura \u00e9 restrita pela estrutura do mo-\ndelo de dom\u00ednio e pela hip\u00f3tese inicial. O caminho at\u00e9 a \u201cbase\u201d \u00e9 realizado a-\ntrav\u00e9s do processamento dos detectores simb\u00f3licos. \n\nPor outro lado, o processo bottom-up \u00e9 iniciado no momento que a m\u00e1quina \nMIV extrai informa\u00e7\u00f5es sens\u00f3rias ao acionar os algoritmos de processamento de \nsinal. As informa\u00e7\u00f5es extra\u00eddas s\u00e3o propagadas aos n\u00edveis superiores aplicando-\nse os detectores simb\u00f3licos previamente selecionados no processamento top-\ndown. \n\n \n\n\n\n \n\n \n\n \n\n4 ESTRATIGRAFIA DE SEQU\u00caNCIAS \n\nEste cap\u00edtulo descreve brevemente o dom\u00ednio de aplica\u00e7\u00e3o deste trabalho, a \nEstratigrafia de Sequ\u00eancias, sub-\u00e1rea da Geologia. Os conceitos apresentados \naqui suportam a discuss\u00e3o sobre o sistema InteliStrata, apresentado no cap\u00edtulo \nseguinte. O sistema InteliStrata \u00e9 uma aplica\u00e7\u00e3o do framework S-Chart para in-\nterpreta\u00e7\u00e3o de gr\u00e1ficos no dom\u00ednio da Estratigrafia de Sequ\u00eancias. \n\nO foco da discuss\u00e3o sobre a Estratigrafia de Sequencias feita aqui est\u00e1 na ta-\nrefa interpreta\u00e7\u00e3o estratigr\u00e1fica, que consiste na identifica\u00e7\u00e3o de fei\u00e7\u00f5es geol\u00f3-\ngicas em perfis de po\u00e7o, mais especificamente, perfis de raios gama, como o re-\npresentado na Figura 4.1. A identifica\u00e7\u00e3o das fei\u00e7\u00f5es baseia-se na busca por pa-\ndr\u00f5es espec\u00edficos na curva de raio gama e nas suas inter-rela\u00e7\u00f5es espaciais. \n\n \nFigura 4.1: Perfil t\u00edpico em diferentes escalas. Raios gama em destaque. \n\nInicialmente, ser\u00e1 apresentado o dom\u00ednio da Estratigrafia de Sequ\u00eancias, A \nseguir o foco \u00e9 direcionado a interpreta\u00e7\u00e3o estratigr\u00e1fica. Por fim, \u00e9 discutida a \nefic\u00e1cia da utiliza\u00e7\u00e3o de wavelets para an\u00e1lise b\u00e1sica de perfis de raios gama.  \n\n4.1 Apresenta\u00e7\u00e3o do dom\u00ednio \nA Estratigrafia de Sequ\u00eancias \u00e9 uma \u00e1rea de Geologia que estuda o hist\u00f3rico \n\nde forma\u00e7\u00e3o dos estratos que comp\u00f5em o subsolo terrestre em termos de varia-\n\u00e7\u00f5es do n\u00edvel do mar e taxas de sedimenta\u00e7\u00e3o. Nessa \u00e1rea, diferentes sequ\u00eancias \n\n\n\n62 \n\n \n\n \n\nde estratos indicam processos de forma\u00e7\u00e3o distintos. O correto entendimento \ndestes processos \u00e9 importante para diversas outras \u00e1reas, especialmente para a \nGeologia de Petr\u00f3leo, onde a interpreta\u00e7\u00e3o dos processos que controlaram a \nforma\u00e7\u00e3o de um reservat\u00f3rio define as estrat\u00e9gias de explora\u00e7\u00e3o e produ\u00e7\u00e3o de \n\u00f3leo. \n\nO objetivo principal do sistema InteliStrata \u00e9 sugerir interpreta\u00e7\u00f5es de se-\nqu\u00eancias. Uma sequ\u00eancia corresponde a um ciclo completo de descida e subida \ndo n\u00edvel do mar. Em geral, esse fen\u00f4meno afeta uma regi\u00e3o localizada (800 a 80 \nmil quil\u00f4metros quadrados) e pode levar de 100 mil a 5 milh\u00f5es de anos para se \ncompletar.  Os diversos momentos de um ciclo influenciam diferentemente na \nordem de deposi\u00e7\u00e3o dos sedimentos na regi\u00e3o onde ele acontece. Por exemplo, \n\u00e0 medida que o n\u00edvel do mar sobe em um dado local, ocorre a deposi\u00e7\u00e3o de um \nsedimento mais lamoso e menos poroso. Quando o n\u00edvel do mar desce no mes-\nmo local, ocorre a deposi\u00e7\u00e3o de um sedimento mais grosso, formando uma ro-\ncha mais porosa. De fato, varia\u00e7\u00f5es de porosidade da rocha t\u00eam uma grande \ncorrela\u00e7\u00e3o com varia\u00e7\u00f5es no n\u00edvel do mar. Dessa forma, estudando-se as varia-\n\u00e7\u00f5es de porosidade ao longo da profundidade do subsolo terrestre, \u00e9 poss\u00edvel se \nter uma ideia aproximada dos ciclos varia\u00e7\u00e3o do n\u00edvel do mar naquela regi\u00e3o, e \nlogo, das sequ\u00eancias. \n\nA interpreta\u00e7\u00e3o de sequ\u00eancias \u00e9 feita com base em dados coletados em po\u00e7os \nde sondagem com at\u00e9 8000 metros de profundidade, perfurados ao longo de \numa regi\u00e3o de interesse. Desses po\u00e7os, dois tipos b\u00e1sicos de dados s\u00e3o coleta-\ndos: testemunhos e perfis de po\u00e7o. Durante a perfura\u00e7\u00e3o do po\u00e7o, um tipo espe-\ncial de broca extrai amostras de rochas na forma de pequenos cilindros. Estas \namostras d\u00e3o ao ge\u00f3logo a possibilidade de analisar diretamente a rocha que \nconstitui o terreno. Ele descreve precisamente as caracter\u00edsticas de cada estrato \nda amostra (como tipo de rocha, porosidade, tamanho de gr\u00e3o, estrutura e etc.) \ne as organiza visualmente em uma coluna estratigr\u00e1fica. Com base na an\u00e1lise \nvisual da coluna estratigr\u00e1fica, o ge\u00f3logo consegue identificar visualmente os \npadr\u00f5es de empilhamento de sedimentos e, a partir da\u00ed, identificar a sequ\u00eancia \ncom um grande grau de precis\u00e3o. Esse processo \u00e9 feito em diversos po\u00e7os, de \nforma que, ap\u00f3s as informa\u00e7\u00f5es serem correlacionadas, \u00e9 poss\u00edvel identificar \ncomo uma mesma sequ\u00eancia afeta toda uma regi\u00e3o. \n\nNo entanto, o processo de perfura\u00e7\u00e3o com testemunhagem \u00e9 consideravel-\nmente caro. Durante o estudo de uma regi\u00e3o, poucos po\u00e7os s\u00e3o testemunhados. \nOs demais s\u00e3o analisados atrav\u00e9s de perfilagem s\u00edsmica (el\u00e9trica, raios gama, \nentre outras). Ap\u00f3s ser perfurado, o po\u00e7o \u00e9 perpassado por uma sonda ao longo \nde toda a sua profundidade. Durante a descida, a sonda faz diversos tipos de \nmedidas da rocha a sua volta, em intervalos de aproximadamente 20 cm (vari-\nando conforme a medida). E resultado \u00e9 um perfil do po\u00e7o, um gr\u00e1fico que de-\nmonstra a varia\u00e7\u00e3o das diversas medidas ao longo da sua profundidade. Exis-\ntem v\u00e1rios tipos de medidas. Cada uma correlacionada com alguma caracter\u00eds-\ntica. Padr\u00f5es de varia\u00e7\u00e3o nessas medidas refletem diferentes tipos de caracter\u00eds-\nticas do terreno. Ou seja, os perfis de po\u00e7o servem como um instrumento indire-\n\n\n\n63 \n\n \n\n \n\nto de an\u00e1lise do terreno, quando, por exemplo, a an\u00e1lise direta da rocha pelo \ntestemunho n\u00e3o \u00e9 realizada. Um dos tipos de medida para interpreta\u00e7\u00e3o de se-\nqu\u00eancias \u00e9 o perfil de raios gama. De forma simplificada, ele mede a radia\u00e7\u00e3o \ngama emitida pelas rochas de um po\u00e7o. Atrav\u00e9s da radia\u00e7\u00e3o \u00e9 poss\u00edvel inferir a \nporosidade de uma rocha. Em geral, quanto maior a leitura de raios gama, me-\nnor \u00e9 a porosidade e vice-versa. Como dito anteriormente, a porosidade da ro-\ncha tem uma grande correla\u00e7\u00e3o com a ocorr\u00eancia de sequ\u00eancias, por isso, ge\u00f3lo-\ngos utilizam o perfil de raios gama como uma ferramenta para identific\u00e1-las.  \n\nEm geral, a interpreta\u00e7\u00e3o de sequ\u00eancias combina a an\u00e1lise de testemunhos \ncom a an\u00e1lise de perfis. No entanto, por ser de custo inferior ao da testemunha-\ngem, freq\u00fcentemente o perfil \u00e9 o \u00fanico dado dispon\u00edvel, sendo necess\u00e1rio extra-\nir interpreta\u00e7\u00f5es geol\u00f3gicas \u00fateis somente a partir dos perfis. A identifica\u00e7\u00e3o \ndos tipos e limites de sequ\u00eancias \u00e9 uma tarefa que requer ao ge\u00f3logo um trei-\nnamento razo\u00e1vel em Estratigrafia. Mesmo quando domina o conhecimento ne-\ncess\u00e1rio, a an\u00e1lise de perfilagens com centenas de metros de profundidade mos-\ntra-se uma atividade manual morosa e consumidora de tempo.  Essa \u00e9 a moti-\nva\u00e7\u00e3o do sistema InteliStrata. Ele deve identificar sequ\u00eancias poss\u00edveis a partir \nde um perfil de raios gama e sugeri-las para o usu\u00e1rio. Outra vantagem desse \nsistema \u00e9 que ele possibilita ao ge\u00f3logo estratigr\u00e1fico economizar tempo, suge-\nrindo uma interpreta\u00e7\u00e3o inicial.  \n\nNa se\u00e7\u00e3o seguinte, a interpreta\u00e7\u00e3o de sequ\u00eancia por perfil de raios gama \u00e9 \ndetalhada e \u00e9 demonstrada a efetividade de um algoritmo de processamento \npara identifica\u00e7\u00e3o de sequ\u00eancias e parassequ\u00eancias.  \n\n4.2 Interpreta\u00e7\u00e3o de sequ\u00eancias em perfis de raios gama \nA identifica\u00e7\u00e3o de sequ\u00eancias em perfis de raios gama \u00e9 um racioc\u00ednio pre-\n\ndominantemente visual. O ge\u00f3logo especialista analisa o gr\u00e1fico do perfil visu-\nalmente, buscando padr\u00f5es de varia\u00e7\u00e3o na curva que casem com padr\u00f5es de va-\nria\u00e7\u00e3o conhecidos e que indicam a presen\u00e7a de determinadas fei\u00e7\u00f5es geol\u00f3gicas. \nAl\u00e9m disso, a an\u00e1lise visual \u00e9 condicionada pelo contexto e conhecimento pr\u00e9-\nvio a respeito da geologia da regi\u00e3o, visto que o padr\u00e3o visual de uma fei\u00e7\u00e3o \ngeol\u00f3gica pode mudar conforme a bacia sedimentar onde ela se insere. \n\nExistem in\u00fameras fei\u00e7\u00f5es geol\u00f3gicas que podem ser interpretadas em um \nperfil. Neste trabalho, o foco \u00e9 na interpreta\u00e7\u00e3o de tr\u00eas tipos de fei\u00e7\u00f5es: sequ\u00ean-\ncias, parassequ\u00eancias e superf\u00edcies de inunda\u00e7\u00e3o m\u00e1xima. \n\nSequ\u00eancias, como mencionando anteriormente, s\u00e3o formadas por grandes \nciclos de varia\u00e7\u00e3o do n\u00edvel do mar, que influenciam na forma\u00e7\u00e3o dos estratos de \nsedimentos. Em um perfil de raios-gama, uma sequ\u00eancia tem a express\u00e3o seme-\nlhante a uma curva gaussiana (Figura 4.2a): um movimento de subida e descida \ndo n\u00edvel do mar relativamente suaves. Uma sequ\u00eancia pode ter, no perfil, uma \nespessura entre 15 e 1500 metros aproximadamente. \n\nJ\u00e1 parassequ\u00eancia s\u00e3o, simplificadamente, pequenos ciclos locais de varia\u00e7\u00e3o \nno n\u00edvel do mar dentro de uma sequ\u00eancia. Podem ser vistas como um ciclo de \n\n\n\n64 \n\n \n\n \n\nmenor ordem. No perfil, uma parassequ\u00eancia se caracteriza como uma curva \nque inicia por uma varia\u00e7\u00e3o negativa abrupta e uma recupera\u00e7\u00e3o suave at\u00e9 o \nmesmo n\u00edvel (Figura 4.2b). A sua espessura est\u00e1 em uma escala inferior \u00e0 se-\nqu\u00eancia, variando entre aproximadamente 3 e 60 metros.  \n\n \nFigura 4.2: Express\u00f5es gen\u00e9ricas das fei\u00e7\u00f5es geol\u00f3gicas no perfil. \n\nA superf\u00edcie de inunda\u00e7\u00e3o m\u00e1xima \u00e9 o ponto de uma sequ\u00eancia onde o n\u00edvel \ndo mar atinge o seu ponto m\u00e1ximo e come\u00e7a a baixar. No perfil, ele \u00e9 facilmente \nidentificado como o ponto mais alto da curva que forma a sequ\u00eancia.  \n\nO relacionamento entre essas tr\u00eas fei\u00e7\u00f5es \u00e9 utilizado para refinar a interpre-\nta\u00e7\u00e3o. Por exemplo, parassequ\u00eancias geralmente est\u00e3o inseridas em uma se-\nqu\u00eancia. Logo, a interpreta\u00e7\u00e3o de uma parassequ\u00eancia \u00e9 realizada ap\u00f3s a identi-\nfica\u00e7\u00e3o dos limites da seq\u00fc\u00eancia onde ela se insere. Da mesma forma, a escala \nda an\u00e1lise \u00e9 determinante para a correta identifica\u00e7\u00e3o de sequ\u00eancias ou paras-\nsequ\u00eancias, uma vez que a assinatura das duas fei\u00e7\u00f5es \u00e9 muito similar, exceto \npelo contexto e escala em que ocorrem.  \n\nA m\u00e1quina de interpreta\u00e7\u00e3o do sistema InteliStrata depende de um algorit-\nmo de processamento de sinal que fa\u00e7a a segmenta\u00e7\u00e3o inicial do perfil, de acor-\ndo com a escala onde as fei\u00e7\u00f5es a serem interpretadas ocorrem e as fei\u00e7\u00f5es bus-\ncadas. A seguir \u00e9 analisada uma proposta de segmenta\u00e7\u00e3o por wavelets, baseado \nna detec\u00e7\u00e3o dos padr\u00f5es de curva que formam as fei\u00e7\u00f5es geol\u00f3gicas procuradas.  \n\n4.3 An\u00e1lise de perfis por wavelets \nAt\u00e9 a data de escrita deste trabalho, n\u00e3o existe nenhuma solu\u00e7\u00e3o autom\u00e1tica \n\npara interpreta\u00e7\u00e3o de sequ\u00eancias descrita na literatura. Da mesma forma, ne-\nnhum sistema estratigr\u00e1fico atualmente no mercado oferece essa facilidade. Por \noutro lado, alguns autores exploram a utiliza\u00e7\u00e3o de t\u00e9cnicas matem\u00e1ticas e \ncomputacionais, em especial processamento de sinal, para auxilio da interpreta-\n\u00e7\u00e3o de fen\u00f4menos c\u00edclicos em dados de perfil. Enquanto alguns autores focam \nna an\u00e1lise da transformada de fourier (SILVA, 2001), algumas propostas explo-\nram  a possibilidade da an\u00e1lise espectral por wavelets ser uma boa ferramenta \npara detec\u00e7\u00e3o manual de sequ\u00eancias (CHOUDHURY et al., 2007). \n\nDo ponto de vista emp\u00edrico, o uso de wavelets \u00e9 a op\u00e7\u00e3o mais interessante. A \nan\u00e1lise de sinais via transformada de Fourier \u00e9 eficaz somente em sinais peri\u00f3-\ndicos. Ao contr\u00e1rio disso, sequ\u00eancias \u2013 e as demais fei\u00e7\u00f5es geol\u00f3gicas aqui con-\nsideradas \u2013 s\u00e3o n\u00e3o-peri\u00f3dicas quanto a sua ocorr\u00eancia em um perfil, onde co-\n\n\n\n65 \n\n \n\n \n\nexistem em diferentes escalas e freq\u00fc\u00eancias. Exatamente neste ponto que a \ntransformada wavelet leva vantagem. A transformada wavelet cont\u00ednua (TWC) \nresponde a essas varia\u00e7\u00f5es de ciclos em diferentes escalas e freq\u00fc\u00eancias.  \n\nConceitualmente, o processamento da TWC \u00e9 relativamente direto. O espec-\ntro resultante de um TWC pode ser visto como uma resposta de similaridade de \num determinado pulso de onda peri\u00f3dica com todas as partes de um sinal, em \nv\u00e1rias escalas. As diferentes wavelets s\u00e3o caracterizadas pelo formato de pulso \naplicado na transformada. Por exemplo, a Figura 4.3 representa o pulso utiliza-\ndo pela wavelet gaussiana 2. J\u00e1 o espectro resultante de um TWC tem o mesmo \ncomprimento do sinal e altura correspondente ao n\u00famero de escalas definidas \npara an\u00e1lise pelo usu\u00e1rio. Ele demonstra a resposta do sinal em compara\u00e7\u00e3o ao \npulso da wavelet.  Em geral, partes do sinal que se assemelham a wavelet t\u00eam \numa resposta maior a partes que n\u00e3o se assemelham. Esse comportamento tor-\nna a TWC uma ferramenta interessante para reconhecimento de padr\u00f5es, se o \npadr\u00e3o buscado puder ser codificado como uma wavelet. \n\n \nFigura 4.3: Wavelet gussiana 2. \n\nCom base nesta capacidade, este trabalho prop\u00f5e a utiliza\u00e7\u00e3o de duas TWC \npara processamento inicial do sinal que comp\u00f5em os gr\u00e1ficos dos perfis de raios \ngama. Os algoritmos propostos tomam o papel dos algoritmos de processamen-\nto de imagem convencionais. O objetivo \u00e9 segmentar o sinal em intervalos, con-\nforme a resposta de similaridade dada pelo TWC. A escolha das wavelets utili-\nzadas se deu atrav\u00e9s de testes emp\u00edricos de resposta aos padr\u00f5es de curva dese-\njados. Um estudo mais sistem\u00e1tico de diferentes wavelets seria necess\u00e1rio para \nse garantir que a op\u00e7\u00e3o utilizada garante o melhor resultado na segmenta\u00e7\u00e3o, \nmas a sele\u00e7\u00e3o do algoritmo de processamento de imagem \u00e9 secund\u00e1ria para a \ncontribui\u00e7\u00e3o buscada neste trabalho.  \n\nOs testes foram realizados sobre um perfil j\u00e1 interpretado pelo especialista e \nque cobre aproximadamente 340 metros. O perfil digitalizado cont\u00e9m 16.465 \namostras, resultando em um per\u00edodo de amostragem de aproximadamente \n0,018 metro. A seguir as duas TWC testadas s\u00e3o detalhadas. \n\n\n\n66 \n\n \n\n \n\n4.3.1 Detec\u00e7\u00e3o de sequ\u00eancias: wavelet gaussiana \nComo descrito anteriormente, uma sequ\u00eancia se apresenta no perfil de forma \n\nsemelhante a uma curva gaussiana. Isso induz a ideia de que a TWC com a wa-\nvelet gaussiana possa ser eficiente na detec\u00e7\u00e3o de sequ\u00eancias em perfis. Para \ndemonstrar isso, o perfil de teste foi analisado atrav\u00e9s da TWC dispon\u00edvel no \nsoftware Matlab (MATHWORKS INC.). O teste \u00e9 descrito a seguir. \n\nInicialmente, \u00e9 considerada a banda de freq\u00fc\u00eancias correspondente ao inter-\nvalo de per\u00edodos t\u00edpico de sequ\u00eancias. Como mencionado anteriormente, uma \n\n \nFigura 4.4: Transformada wavelet gaussiana 2 em um perfil de raios gama. \n\n\n\n67 \n\n \n\n \n\nsequ\u00eancia pode ter um per\u00edodo que varia entre 15 e 1500 metros de espessura \nno perfil. Para simplificar a TWC, o perfil \u00e9 re-amostrado para uma freq\u00fc\u00eancia \n0,013 amostras por metro, correspondendo a um per\u00edodo de amostragem de \n7,62 metros aproximadamente. Isso minimiza a presen\u00e7a de ciclos com menos \nde 15 metros no perfil (ru\u00eddos de alta frenq\u00fc\u00eancia). \n\nA TWC \u00e9 aplicada sobre o sinal resultante, agora com 44 das 16.465 amostras \nanteriores. Os par\u00e2metros utilizados para a TWC s\u00e3o os seguintes: \n\n\u2022 Wavelet: Gaussiana n\u00famero 2 (dispon\u00edvel no pacote de wavelets do Ma-\ntlab), escolhida com base na sua semelhan\u00e7a com o padr\u00e3o de curva de \numa sequ\u00eancia; \n\n\u2022 Escalas: determinadas pela f\u00f3rmula ( ) 2ns n = , onde, no caso deste sinal, \n0 2 4n , , ,= L . Essas escalas garantem que o resultado da TWC fique res-\n\ntrito a ciclos com per\u00edodos de 15 a 1500 metros. \n\n\u2022 Extens\u00e3o: sim\u00e9trica em ambos os lados do sinal, a fim de minimizar as \ndistor\u00e7\u00f5es de borda. \n\nO resultado da aplica\u00e7\u00e3o dessa wavelet sobre o perfil \u00e9 demonstrado na Figu-\nra 4.4. \u00c0 direita, o espectro de coeficientes resultando da TWC demonstra onde \no padr\u00e3o de curva gaussiana est\u00e1 mais evidente (regi\u00f5es mais claras). A linha \npontilhada marca a interpreta\u00e7\u00e3o de limites de sequ\u00eancia conforme feita pelo \nespecialista sobre o perfil de teste (esquerda). \u00c9 poss\u00edvel notar que os picos no \nespectro (setas) correspondem a aproximadamente ao centro das sequ\u00eancias, e \nos seus correspondentes vales as bordas de sequ\u00eancia. Isso \u00e9 mais evidente nas \nsequ\u00eancias de maior escala, como a Sequ\u00eancia 2 e, em certa medida, a Sequ\u00eancia \n1. Isso demonstra a boa resposta da wavelet gaussiana 2 ao padr\u00e3o de curva \ngaussiano definido para sequ\u00eancia. \n\nCom base nesse resultado, este trabalho considera que a TWC \u00e9 uma ferra-\nmenta suficiente para processamento inicial do perfil. Ela identifica padr\u00f5es \ncorrespondentes a sequ\u00eancias, que podem ser utilizados para alimentar os algo-\nritmos simb\u00f3licos no sistema InteliStrata. No entanto, os algoritmos simb\u00f3licos \ndevem garantir que ru\u00eddos sejam minimamente propagados no processo de in-\nterpreta\u00e7\u00e3o (especialmente ru\u00eddos de alta freq\u00fc\u00eancia). \n\n4.3.2 Detec\u00e7\u00e3o de parassequ\u00eancias: wavelet smoothtooth \nA detec\u00e7\u00e3o de parassequ\u00eancias por wavelets se d\u00e1 de forma semelhante \u00e0 de-\n\ntec\u00e7\u00e3o de sequ\u00eancias, por\u00e9m com algumas diferen\u00e7as. Inicialmente, o padr\u00e3o de \ncurva de uma parassequ\u00eancia \u00e9 diferente de uma gaussiana, como demonstrado \nna Figura 4.2 anterior. Al\u00e9m disso, essa curva n\u00e3o tem correspondente entre as \nwavelets da biblioteca padr\u00e3o. Por isso, este trabalho prop\u00f5e uma nova wavelet \nespec\u00edfica pare detec\u00e7\u00e3o deste padr\u00e3o de curva. Ela foi criada dentro da fun\u00e7\u00e3o \nde cria\u00e7\u00e3o de wavelets do aplicativo Matlab, seguindo o perfil de uma parasse-\nqu\u00eancia padr\u00e3o, e batizada de wavelet smoothtooth, devido a semelhan\u00e7a do pa-\ndr\u00e3o original com um per\u00edodo da onda peri\u00f3dica padr\u00e3o dente-de-serra.  \n\n\n\n68 \n\n \n\n \n\nNeste teste, o sinal foi reamostrado para o per\u00edodo de 1,5 metros, conforme o \nper\u00edodo m\u00ednimo desejado. O resultado \u00e9 um sinal com 217 amostras. Al\u00e9m dis-\nso, os par\u00e2metros utilizados para a TWC s\u00e3o: \n\n\u2022 Wavelet: Smoothtooth; \n\n\u2022 Escalas: determinadas pela f\u00f3rmula ( ) 2ns n = , onde 1 2 5n , , ,= L . Essas \nescalas garantem que o resultado da TWC fique restrito a faixa de ciclos \nde parassequ\u00eancias, com per\u00edodos de 3 a 60 metros. \n\n \nFigura 4.5: Transformada wavelet sawtooth em um perfil de raios gama. \n\n\n\n69 \n\n \n\n \n\n\u2022 Extens\u00e3o: tamb\u00e9m sim\u00e9trica em ambos os lados do sinal, a fim de mini-\nmizar ru\u00eddos de borda. \n\nOs resultados na aplica\u00e7\u00e3o da TWC com essa wavelet em um perfil \u00e9 demons-\ntrado na Figura 4.5. As setas claras marcam os picos que correspondem aproxi-\nmadamente \u00e0s parassequ\u00eancias determinadas pelo especialista (ps). Embora \nparte delas tenha sido discriminada, algumas n\u00e3o o s\u00e3o, como \u00e9 o caso ps1, on-\nde n\u00e3o aconteceram picos (seta escura inferior). H\u00e1 tamb\u00e9m falsos positivos, \ncomo as marcadas pelas duas setas escuras superiores. Isso ocorre devido a es-\ncala relativamente pequena das parassequ\u00eancias. Uma vez que elas aparecem \nem freq\u00fc\u00eancias maiores, elas se confundem com ru\u00eddos de alta freq\u00fc\u00eancia do \nperfil. Ainda sim, pode-se concluir que a wavelet smoothtooth pode ser utiliza-\nda para auxiliar na extra\u00e7\u00e3o de parassequ\u00eancias do perfil. \n\n\n\n \n\n \n\n \n\n5 SISTEMA INTELISTRATA \n\nEste cap\u00edtulo detalha a implementa\u00e7\u00e3o do sistema InteliStrada, uma aplica-\n\u00e7\u00e3o do framework S-Chart para interpreta\u00e7\u00e3o de gr\u00e1ficos no dom\u00ednio da Estra-\ntigrafia de Sequ\u00eancias O objetivo do sistema InteliStrata \u00e9, dado como entrada \num perfil de raios gama, fornecer ao usu\u00e1rio uma sugest\u00e3o de interpreta\u00e7\u00e3o de \nsequ\u00eancias, parassequ\u00eancias e superf\u00edcies de inunda\u00e7\u00e3o m\u00e1xima. \n\nNaturalmente, o sistema InteliStrada complementa a defini\u00e7\u00e3o do frame-\nwork S-Chart do ponto de vista da implementa\u00e7\u00e3o. Nas se\u00e7\u00f5es seguintes, ser\u00e3o \nexplorados aspectos da infra-estrutura de software necess\u00e1ria para operaciona-\nlizar os conceitos apresentados no cap\u00edtulo 3. Al\u00e9m disso, s\u00e3o tamb\u00e9m explora-\ndos aspectos de implementa\u00e7\u00e3o espec\u00edficos da interpreta\u00e7\u00e3o estratigr\u00e1fica. \n\n5.1 Objetivos do sistema \nO objetivo do sistema InteliStrata \u00e9 sugerir interpreta\u00e7\u00f5es estratigr\u00e1ficas so-\n\nbre perfis de raios gama. Padr\u00f5es visuais de comportamento da curva em perfis \nde raio gama sugerem a presen\u00e7a de sequ\u00eancias, parassequ\u00eancias e superf\u00edcies \nde inunda\u00e7\u00e3o m\u00e1xima. O sistema captura e combina esses padr\u00f5es com conhe-\ncimento de dom\u00ednio, em um processo de interpreta\u00e7\u00e3o sem\u00e2ntica. Mais especifi-\ncamente, o sistema sugere poss\u00edveis inst\u00e2ncias de sequ\u00eancias, parassequ\u00eancias e \nsuperf\u00edcies de inunda\u00e7\u00e3o m\u00e1xima presentes no perfil. Para realizar essa tarefa, o \nsistema InteliStrata implementa e especializa o framework S-Chart. \n\nDo ponto de vista de sistema, o desenvolvimento do InteliStrata segue dois \nobjetivos principais: \n\n\u2022 Utiliza\u00e7\u00e3o de modelos semanticamente ricos na implementa\u00e7\u00e3o. Um \ndos princ\u00edpios mais importantes na implementa\u00e7\u00e3o de sistema intensivos \nem conhecimento \u00e9 o princ\u00edpio da preserva\u00e7\u00e3o de estrutura (SCHREIBER \net al., 1999; FIORINI, 2006). Por ele, o modelo de implementa\u00e7\u00e3o (arquite-\ntura, modelo de classes e etc.) de um sistema de conhecimento deve bus-\ncar manter ao m\u00e1ximo a estrutura dos modelos de conhecimento. Isto fa-\ncilita a manuten\u00e7\u00e3o em um cen\u00e1rio onde os pr\u00f3prios modelos de conhe-\ncimento s\u00e3o suscet\u00edveis a mudan\u00e7as constantes, al\u00e9m de facilitar o traba-\nlho de implementa\u00e7\u00e3o e manuten\u00e7\u00e3o. Em um caso ideal, o modelo de co-\nnhecimento deve ser especificado em uma linguagem poss\u00edvel de ser a-\ncessada diretamente pelo sistema de conhecimento (como linguagens de \nrepresenta\u00e7\u00e3o baseadas em XML). Dessa forma, o c\u00f3digo do sistema de \n\n\n\n71 \n\n \n\n \n\nconhecimento pode se restringir ao m\u00e1ximo \u00e0 implementa\u00e7\u00e3o dos algo-\nritmos de racioc\u00ednios. \n\n\u2022 Emprego de ferramentas off the shelf. O sistema InteliStrata \u00e9 baseado no \nframework S-Chart, cujos modelos de representa\u00e7\u00e3o s\u00e3o definidos em \nlinguagens formais de representa\u00e7\u00e3o de conhecimento, como OWL e \nSWRL. Uma vez que elas s\u00e3o process\u00e1veis por software, existem diversas \nferramentas que d\u00e3o suporte a manipula\u00e7\u00e3o, manuten\u00e7\u00e3o e racioc\u00ednio so-\nbre modelos descritos nessas linguagens. Assim, \u00e9 poss\u00edvel que estas fer-\nramentas sejam utilizadas como componentes de infra-estrutura para o \ndesenvolvimento de um sistema de interpreta\u00e7\u00e3o sem\u00e2ntica, minimizan-\ndo o esfor\u00e7o de implementa\u00e7\u00e3o nessas \u00e1reas (como estrutura de dados, \npor exemplo). \n\nEstes objetivos influenciam diretamente a arquitetura do sistema InteliStrata \ne sua forma de implementa\u00e7\u00e3o. \n\n5.2 Arquitetura do sistema \nUm vis\u00e3o geral da arquitetura do sistema InteliStrata \u00e9 apresentada na Figu-\n\nra 5.1. Os componentes que a formam podem ser divididos em tr\u00eas conjuntos: \n(i) um conjunto de componentes que constituem o sistema de interpreta\u00e7\u00e3o \npropriamente dito; (ii) com conjunto de componentes de software para infra-\nestrutura; (iii) um conjunto de modelos OWL que representam os modelos de \nconhecimento utilizados pelo software.  \n\nNas pr\u00f3ximas se\u00e7\u00f5es, cada um desses componentes \u00e9 detalhado, bem como a \nsua interrela\u00e7\u00e3o. \n\n \nFigura 5.1: Arquitetura de componentes do sistema InteliStrata. \n\n\n\n72 \n\n \n\n \n\n5.2.1 Modelos de representa\u00e7\u00e3o e extens\u00f5es \nComo apresentado anteriormente, o framework S-Chart define um conjunto \n\nde modelos de conhecimento visual para dar suporte a interpreta\u00e7\u00e3o sem\u00e2ntica. \nAlguns desses modelos devem ser supridos pelo sistema que implementa o \nframework (como \u00e9 o caso do modelo de dom\u00ednio no n\u00edvel sem\u00e2ntico) enquanto \noutros modelos s\u00e3o disponibilizados pelo pr\u00f3prio framework, com a possibili-\ndade de extens\u00e3o (modelos no n\u00edvel visual e anal\u00f3gico).  \n\n \nFigura 5.2: Depend\u00eancias entre ontologias OWL do sistema InteliStrata. \n\nNo sistema, cada um dos modelos \u00e9 descrito em uma ontologia OWL8. A Fi-\ngura 5.2 mostra a rela\u00e7\u00e3o de depend\u00eancia entre as ontologias e os seus respecti-\nvos prefixos. As ontologias AnalogLevelOntology, VisualLevelOntology, \nSemanticLevelOntology e SignalProcessingOntology modelam, respecti-\nvamente, os tr\u00eas n\u00edveis sem\u00e2nticos e a ontologia de funcionalidades de proces-\nsamento de sinal. A StratigraphyOntology captura o conhecimento de dom\u00ed-\nnio da estratigrafia de sequ\u00eancias. Todas elas s\u00e3o agregadas em uma ontologia \nde aplica\u00e7\u00e3o chamada InteliStrataOntology. A sua fun\u00e7\u00e3o \u00e9 agregar as de-\nmais em um s\u00f3 arcabou\u00e7o, al\u00e9m de servir de reposit\u00f3rio para as extens\u00f5es reali-\nzadas nos modelo de conhecimento visual. Nas se\u00e7\u00f5es seguintes, cada uma des-\nsas extens\u00f5es \u00e9 detalhada. \n\n                                                 \n\n \n8 Embora o OWL descreva qualquer modelo da sua linguagem como uma \u201contologia\u201d, cla-\n\nramente o termo n\u00e3o \u00e9 o mais preciso. Um modelo OWL \u2013 e de qualquer outra linguagem \u2013\npode ser caracterizado como uma ontologia somente se modela formalmente uma conceituali-\nza\u00e7\u00e3o compartilhada (como a defini\u00e7\u00e3o dada por Gruber e Borst (1998)). No entanto, mant\u00e9m-\nse o termo aqui para manter consist\u00eancia com o vocabul\u00e1rio de OWL. \n\n\n\n73 \n\n \n\n \n\n5.2.1.1 Ontologia de dom\u00ednio: Estratigrafia de Sequ\u00eancias \n\nO conhecimento sobre Estratigrafia que d\u00e1 suporte a interpreta\u00e7\u00e3o estrati-\ngr\u00e1fica \u00e9 capturado por uma ontologia modelada em StratigraphyOntology. \nUma vez que esta ontologia n\u00e3o existe publicamente, parte do desenvolvimento \ndo sistema InteliStrata focou em, junto com um especialista em Estratigrafia, e-\nliciar o conhecimento de dom\u00ednio m\u00ednimo necess\u00e1rio para realiza\u00e7\u00e3o da inter-\npreta\u00e7\u00e3o estratigr\u00e1fica. A principal parte do conhecimento eliciado \u00e9 modelada \nna ontologia de dom\u00ednio (cuja estrutura b\u00e1sica \u00e9 apresentada na Figura 5.3). Ou-\ntros conceitos s\u00e3o capturados na forma de extens\u00f5es do n\u00edvel visual e na defini-\n\u00e7\u00e3o dos detectores simb\u00f3licos (detalhados a seguir).  \n\nComo mencionado anteriormente, o sistema utiliza conhecimento de dom\u00ed-\nnio para extrair inst\u00e2ncias de sequ\u00eancias, parassequ\u00eancias e superf\u00edcies de i-\nnunda\u00e7\u00e3o m\u00e1xima. Estes tr\u00eas tipos de entidades s\u00e3o capturados na ontologia \n(Figura 5.3). O modelo tamb\u00e9m apresenta rela\u00e7\u00f5es de composi\u00e7\u00e3o entre estas as \nentidades do modelo, semelhantes \u00e0 rela\u00e7\u00e3o de composi\u00e7\u00e3o existente entre os \nconceitos cora\u00e7\u00e3o e pessoa. Neste modelo, a composi\u00e7\u00e3o \u00e9 representada intuiti-\nvamente pela rela\u00e7\u00e3o transitiva hasPart. Essa rela\u00e7\u00e3o ser\u00e1 inferida atrav\u00e9s das \nrela\u00e7\u00f5es topol\u00f3gicas entre as entidades visuais que ancoram cada um desses \nconceitos.  \n\n \n\nFigura 5.3: Ontologia da Estratigrafia. \n\n\n\n74 \n\n \n\n \n\nA ontologia modelada certamente est\u00e1 longe de representar uma conceitua-\nliza\u00e7\u00e3o completa o suficiente para ser considerada uma ontologia da Estratigra-\nfia. No entanto, o modelo m\u00ednimo apresentado \u00e9 o suficiente para suportar a in-\nterpreta\u00e7\u00e3o estratigr\u00e1fica a que este sistema se prop\u00f5e fazer 9.  \n\n5.2.1.2 Extens\u00f5es: n\u00edvel visual \n\nA ontologia no n\u00edvel visual proposta pelo framework S-Chart \u00e9 constitu\u00edda \npor primitivas visuais b\u00e1sicas, utilizadas na interpreta\u00e7\u00e3o de qualquer tipo de \ngr\u00e1fico. No entanto, h\u00e1 a possibilidade de extens\u00e3o do modelo com primitivas \nvisuais espec\u00edficas de cada dom\u00ednio de interpreta\u00e7\u00e3o. No caso do sistema Inte-\nliStrata, foi detectada a necessidade de apenas um tipo de extens\u00e3o. \n\nComo j\u00e1 mencionado anteriormente, em dom\u00ednios complexos, propriedades \nvisuais id\u00eanticas podem ter interpreta\u00e7\u00f5es diferentes, dependendo do contexto \nonde s\u00e3o aplicadas. Tomando-se como exemplo sequ\u00eancias e parassequ\u00eancias. \nA extens\u00e3o visual de ambas as entidades cont\u00e9m a propriedade que captura a \nideia de comprimento. No entanto, a escala de interpreta\u00e7\u00e3o da propriedade va-\nria entre elas. Uma sequ\u00eancia longa (entre 142 m e 845 metros) est\u00e1 em uma es-\ncala muito diferente de uma parassequ\u00eancia longa (entre 43 metros e 76 me-\ntros). Se essa diferen\u00e7a n\u00e3o for levada em conta, o algoritmo de interpreta\u00e7\u00e3o \nn\u00e3o ser\u00e1 capaz de diferenciar em qual escala se encontra uma dada entidade vi-\nsual ainda n\u00e3o classificada como sequ\u00eancia ou parassequ\u00eancia. \n\nDessa forma, a primitiva LengthValue \u00e9 estendida com duas subclasses de-\nfinidas como: \n\n\u00a0\nClass:\u00a0SequenceLengthValue\u00a0\n\u00a0 EquivalentTo:\u00a0\n\u00a0 \u00a0 ValorDeComprimento\u00a0\u00a0\n\u00a0 \u00a0 and\u00a0({VeryShortLengthSequence,\u00a0\n\u00a0 \u00a0 \u00a0 ShortLengthSequence,\u00a0\n\u00a0 \u00a0 \u00a0 MediumLengthSequence,\u00a0\n\u00a0 \u00a0 \u00a0 LongLengthSequence,\u00a0\n\u00a0 \u00a0 \u00a0 VeryLongLengthSequence})\u00a0\n\u00a0\nClass:\u00a0ParassequenceLengthValue\u00a0\n\u00a0 EquivalentTo:\u00a0\n\u00a0 \u00a0 ValorDeComprimento\u00a0\u00a0\n\u00a0 \u00a0 and\u00a0({ShortLengthParassequence,\u00a0\n\u00a0 \u00a0 \u00a0 MediumLengthParassequence,\u00a0\u00a0\n\u00a0 \u00a0 \u00a0 LongLengthParassequenc})\u00a0\n\u00a0\n\n                                                 \n\n \n9 A arquitetura aqui proposta dever\u00e1 ser integrada a ontologia completa de dom\u00ednio que es-\n\nt\u00e1 sendo elaborada pelo mestrando Alexandre Lorenzatti, neste mesmo programa de p\u00f3s-\ngradua\u00e7\u00e3o. Resultados s\u00e3o previstos para o final do ano de 2009. \n\n\n\n75 \n\n \n\n \n\nAs inst\u00e2ncias que formam os dois contradom\u00ednios de valores de comprimen-\ntos s\u00e3o modeladas tamb\u00e9m como diferentes entre si.  \n\nEstas s\u00e3o as \u00fanicas extens\u00f5es necess\u00e1rias para o n\u00edvel visual. Eventualmente, \nelas ser\u00e3o utilizadas para defini\u00e7\u00e3o dos detectores simb\u00f3licos entre os n\u00edveis \nsem\u00e2nticos. \n\n5.2.1.3 Extens\u00f5es: n\u00edvel anal\u00f3gico e processamento de sinal \n\nO n\u00edvel anal\u00f3gico, embora n\u00e3o receba uma extens\u00e3o propriamente dita, re-\ncebe novas entidades necess\u00e1rias para suporte de aspectos ligados ao sistema. \nEssas extens\u00f5es permitem que entidades do modelo referenciem de forma ho-\nmog\u00eanea containeres dos dados brutos que comp\u00f5em o sinal.  \n\nIdealmente, os dados digitais que formam o sinal deveriam ser totalmente \nrepresentados em termos de primitivas do n\u00edvel anal\u00f3gico. Por exemplo, como \numa cadeia de inst\u00e2ncias da primitiva Ponto. No entanto, tal solu\u00e7\u00e3o \u00e9 tecnica-\nmente invi\u00e1vel. Uma vez que um sinal pode ter at\u00e9 dezenas de milhares de a-\nmostras, seria necess\u00e1rio o mesmo n\u00famero de inst\u00e2ncias da classe Ponto para \nrepresent\u00e1-los. Isso sobrecarregaria desnecessariamente os algoritmos de inter-\npreta\u00e7\u00e3o, dado que somente alguns desses pontos s\u00e3o significativos para o pro-\ncesso de infer\u00eancia. A solu\u00e7\u00e3o para esse problema \u00e9 a inclus\u00e3o de primitivas que \npossam representar os dados digitais que comp\u00f5em um sinal de forma eficiente, \nsem que se perca a liga\u00e7\u00e3o entre o modelo e esses dados. Para isso, s\u00e3o defini-\ndas as primitivas apresentadas na Figura 5.4. \n\n \nFigura 5.4: Modelo para representa\u00e7\u00e3o de dados brutos.  \n\nNo modelo proposto, todas as entidades anal\u00f3gicas devem referenciar al-\ngum container de dados pela propriedade hasRawDataContainer. Cabe aos al-\ngoritmos de processamento e interpreta\u00e7\u00e3o carregar e interpretar estes dados de \nforma correta.  \n\nA segunda extens\u00e3o \u00e9 simples e direta. O framework S-Chart disponibiliza \num ontologia simples para representa\u00e7\u00e3o de algoritmos de processamento de \nsinal. Algoritmos utilizados no sistema devem ser representados como inst\u00e2n-\ncias desta ontologia. Evidentemente, essas inst\u00e2ncias n\u00e3o se preocupam em re-\npresentar o funcionamento interno dos algoritmos (detalhados nas se\u00e7\u00f5es 4.3 e \n5.2.2.1). Elas existem para que os pr\u00f3prios algoritmos tenham a sua exist\u00eancia \ndescrita no modelo, de modo que possam ser referenciados como discriminado-\n\n\n\n76 \n\n \n\n \n\nres no processo de interpreta\u00e7\u00e3o, por exemplo. Os dois algoritmos s\u00e3o represen-\ntados da seguinte forma: \n\n\u00a0\nIndividual:\u00a0SmoothtoothSPF\u00a0\n\u00a0\u00a0\u00a0\u00a0Types:\u00a0WaveletSegmentator\u00a0\n\u00a0\nIndividual:\u00a0Gaussian2SPF\u00a0\n\u00a0\u00a0\u00a0\u00a0Types:\u00a0WaveletSegmentator\u00a0\n \n\nCabe ao sistema manter a liga\u00e7\u00e3o entre estas inst\u00e2ncias e os componentes de \nsoftware que elas representam. De fato, isso \u00e9 realizado pelo componente de ge-\nrenciamento de processamento de sinal, descrito na se\u00e7\u00e3o 5.2.3.1 a seguir. \n\nAs novas extens\u00f5es definidas das \u00faltimas se\u00e7\u00f5es s\u00e3o suficientes para permi-\ntir a modelagem dos modelos de conhecimento visual. No entanto, ainda resta a \nmodelagem dos detectores simb\u00f3licos sobre essas primitivas.  \n\n5.2.1.4 Detectores simb\u00f3licos \n\nOs detectores simb\u00f3licos mapeiam explicitamente entidades entre os n\u00edveis \nsem\u00e2nticos do modelo de conhecimento visual. O framework S-Chart define \nque os detectores simb\u00f3licos sejam modelados como regras SWRL com uma es-\ntrutura bem definida. Em geral, os detectores s\u00e3o definidos especificamente pa-\nra cada dom\u00ednio de aplica\u00e7\u00e3o, uma vez que a interpreta\u00e7\u00e3o visual pode variar \nentre dom\u00ednios distintos. \n\nO sistema InteliStrata cont\u00e9m um total de 14 detectores (regras), divididos \nem 9 conjuntos, que s\u00e3o respons\u00e1veis pelo mapeamento. Todos eles s\u00e3o apre-\nsentados no Apendice. Neste cap\u00edtulo \u00e9 descrito o exemplo de mapeamento do \nconceito dom:Sequence da ontologia de dom\u00ednio no n\u00edvel sem\u00e2ntico at\u00e9 as en-\ntidades anal\u00f3gicas correspondentes. \n\nInicialmente, o conceito dom:Sequence \u00e9 mapeado para um grupo de detec-\ntores simb\u00f3licos chamado sdgDomSequence. Esse grupo mant\u00e9m refer\u00eancia pa-\nra os detectores formados para extrair a entidade sem\u00e2ntica de entidades visu-\nais. No caso do conceito dom:Sequence, apenas um detector \u00e9 utilizado (sdSe?\nquence): \n\n\u00a0\nmapo:mappingSemanticToVisual(?de,\u00a0?ve)\u00a0\u00a0\u00a0\n\u00a0 ? vlo:GaussianCurve(?ve)\u00a0\u00a0\u00a0\n ? vlo:gaussianCurveCharacteristic(?ve,\u00a0?pattern)\u00a0\u00a0\u00a0\n ? swrlineq:greaterThanOrEqual(?pattern,\u00a0vlo:StrongPattern)\u00a0\u00a0\u00a0\n ? vlo:length(?ve,\u00a0?length)\u00a0\u00a0\u00a0\n ? swrlineq:greaterThanOrEqual(?length,\u00a0MediumLengthSequence)\u00a0\u00a0\n?\u00a0dom:Sequence(?de)\u00a0\n\u00a0\u00a0\n\n De acordo com o detector, uma sequ\u00eancia tem como express\u00e3o visual uma \ncurva gaussiana com caracter\u00edstica forte, com um comprimento maior ou igual a \ncurto dentro da escala de tamanho de sequ\u00eancia. Cada uma dessas primitivas \nvisuais, por sua vez, deve ser extra\u00edda do n\u00edvel anal\u00f3gico. Por esse motivo, elas \n\n\n\n77 \n\n \n\n \n\ntamb\u00e9m apresentam detectores espec\u00edficos definidos em termos de primitivas \nanal\u00f3gicas. A primitiva vlo:GaussianCurve, por exemplo, \u00e9 associada a um \ngrupo de detectores (sdgGaussianCurve). Esse grupo cont\u00e9m o seguinte detec-\ntor. \n\n\u00a0\nmapo:mappingVisualToAnalogic(?ve,\u00a0?al)\u00a0\u00a0\u00a0\n\u00a0 ? al:Interval(?al)\u00a0\u00a0\u00a0\n\u00a0 ? spo:apExtractedWith(?al,\u00a0spo:Gaussian2SPF)\u00a0\u00a0\u00a0\n\u00a0 ? spo:apExtractionStrength(?al,\u00a0?vstrength)\u00a0\u00a0\u00a0\n\u00a0 ? fuzzy:match(?vstrength,\u00a0?strength,\u00a0\u00a0\n\u00a0 \u00a0\u00a0 \"[0,\u00a00,\u00a00.2,\u00a00.3]\",\u00a0vlo:VeryWeakPattern,\u00a0\u00a0\n\u00a0 \u00a0\u00a0 \"[0.2,\u00a00.3,\u00a00.4,\u00a00.5]\",\u00a0vlo:WeakPattern,\u00a0\u00a0\n\u00a0 \u00a0\u00a0 \"[0.4,\u00a00.5,\u00a00.6,\u00a00.7]\",\u00a0vlo:MediumPattern,\u00a0\u00a0\n\u00a0 \u00a0\u00a0 \"[0.6,\u00a00.7,\u00a00.8,\u00a00.9]\",\u00a0vlo:StrongPattern,\u00a0\u00a0\n\u00a0 \u00a0\u00a0 \"[0.8,\u00a00.9,\u00a01,\u00a01]\",\u00a0vlo:VeryStrongPattern)\u00a0\n\u00a0?\u00a0vlo:GaussianCurve(?ve)\u00a0\u00a0\u00a0\n\u00a0 ? vlo:gaussianCurveCharacteristic(?ve,\u00a0?strength)\u00a0\n\u00a0\n\nEle define que uma curva gaussiana \u00e9 expressa no sinal na forma de um a?\nlo:Interval extra\u00eddo pelo algoritmo spo:Gaussian2SPF. O mesmo detector \nse encarrega de inferir o valor caracter\u00edstico da curva. O valor \u00e9 inferido atrav\u00e9s \nda fun\u00e7\u00e3o fuzzy embutida fuzzy:match, que atribui os valores caracter\u00edsticos \nconforme o valor de intensidade (spo:apExtractionStrength) corresponden-\nte. Em outro exemplo, a propriedade visual vlo:hasLength \u00e9 extra\u00edda por um \nconjunto contento dois detectores (sdSequenceLength e sdParassequence?\nLength): \n\n\u00a0\nmapo:mappingVisualToAnalogic(?ve,\u00a0?al)\u00a0\u00a0\u00a0\n\u00a0 ? al:Interval(?al)\u00a0\u00a0\u00a0\n\u00a0 ? al:apLength(?al,\u00a0?value)\u00a0\u00a0\u00a0\n\u00a0 ? fuzzy:match(?value,\u00a0?fv,\u00a0\u00a0\n\u00a0 \u00a0\u00a0 \"[0,\u00a00,\u00a066,\u00a082]\",\u00a0VeryShortLengthSequence,\u00a0\u00a0\n\u00a0 \u00a0\u00a0 \"[66,\u00a082,\u00a0146,\u00a0210]\",\u00a0ShortLengthSequence,\u00a0\u00a0\n\u00a0 \u00a0\u00a0 \"[146,\u00a0210,\u00a0466,\u00a0722]\",\u00a0MediumLengthSequence,\u00a0\u00a0\n\u00a0 \u00a0\u00a0 \"[466,\u00a0722,\u00a01746,\u00a02770]\",\u00a0LongLengthSequence,\u00a0\u00a0\n\u00a0 \u00a0\u00a0 \"[1746,\u00a02770,\u00a05000,\u00a07500]\",\u00a0VeryLongLengthSequence)\u00a0\n?\u00a0vlo:length(?ve,\u00a0?fv)\u00a0\n\u00a0\nmapo:mappingVisualToAnalogic(?ve,\u00a0?al)\u00a0\u00a0\u00a0\n\u00a0 ? al:Interval(?al)\u00a0\u00a0\u00a0\n\u00a0 ? al:apLength(?al,\u00a0?value)\u00a0\u00a0\u00a0\n\u00a0 ? fuzzy:match(?value,\u00a0?fv,\u00a0\u00a0\n\u00a0 \u00a0\u00a0 \"[5,\u00a010,\u00a050,\u00a060]\",\u00a0ShortLengthParassequence,\u00a0\u00a0\n\u00a0 \u00a0\u00a0 \"[50,\u00a060,\u00a0140,\u00a0150]\",\u00a0MediumLengthParassequence,\u00a0\u00a0\n\u00a0 \u00a0\u00a0 \"[140,\u00a0150,\u00a0200,\u00a0250]\",\u00a0LongLengthSequence)\u00a0\u00a0\n?\u00a0vlo:length(?ve,\u00a0?fv)\u00a0\n\u00a0\n\nAmbos extraem valores de comprimento contextualizados \u2013 para sequ\u00eancia \nou parassequ\u00eancia. Ambos tamb\u00e9m utilizam a fun\u00e7\u00e3o fuzzy:match para inferir \n\n\n\n78 \n\n \n\n \n\nos valores ling\u00fc\u00edsticos para propriedade visual. Os valores utilizados para os \nconjuntos foram escolhidos com base no conhecimento eliciado do dom\u00ednio. \n\n Embora ausentes no exemplo anterior, as rela\u00e7\u00f5es espaciais tamb\u00e9m s\u00e3o an-\ncoradas no n\u00edvel anal\u00f3gico. Os seus detectores simb\u00f3licos s\u00e3o relativamente in-\ndependentes de dom\u00ednio, pois s\u00e3o definidos em fun\u00e7\u00e3o de entidades gen\u00e9ricas \nno n\u00edvel anal\u00f3gico. Todos eles s\u00e3o agrupados em um conjunto relacionado \u00e0 \npropriedade vlo:hasSpatialRelationWith, que inclui todas as propriedades \nespaciais. Um exemplo de detector para infer\u00eancia da rela\u00e7\u00e3o topol\u00f3gica de par-\nte pr\u00f3pria sobre intervalos: \n\n\u00a0\nmapo:mappingVisualToAnalogic(?ve1,\u00a0?al1)\u00a0\u00a0\u00a0\n\u00a0 ?\u00a0alo:Interval(?al1)\u00a0\u00a0\u00a0\n\u00a0 ?\u00a0alo:hasStartPoint(?al1,\u00a0?sp1)\u00a0\u00a0\u00a0\n\u00a0 ?\u00a0alo:hasEndPoint(?al1,\u00a0?ep1)\u00a0\u00a0\u00a0\n\u00a0 ?\u00a0alo:index(?sp1,\u00a0?vsx1)\u00a0\u00a0\u00a0\n\u00a0 ?\u00a0alo:index(?ep1,\u00a0?vex1)\u00a0\u00a0\u00a0\n\u00a0 ?\u00a0mapo:mappingVisualToAnalogic(?ve2,\u00a0?al2)\u00a0\u00a0\u00a0\n\u00a0 ?\u00a0alo:Interval(?al2)\u00a0\u00a0\u00a0\n\u00a0 ?\u00a0alo:hasStartPoint(?al2,\u00a0?sp2)\u00a0\u00a0\u00a0\n\u00a0 ?\u00a0alo:hasEndPoint(?al2,\u00a0?ep2)\u00a0\u00a0\u00a0\n\u00a0 ?\u00a0alo:index\u00a0(?sp2,\u00a0?vsx2)\u00a0\u00a0\u00a0\n\u00a0 ?\u00a0alo:index\u00a0(?ep2,\u00a0?vex2)\u00a0\u00a0\u00a0\n\u00a0 ?\u00a0swrlb:greaterThan(?vsx2,\u00a0?vsx1)\u00a0\u00a0\u00a0\n\u00a0 ?\u00a0swrlb:greaterThan(?vex1,\u00a0?vex2)\u00a0\u00a0\n\u00a0\n?\u00a0vlo:isNonTangentialProperPartOf(?ve2,\u00a0?ve1)\u00a0\u00a0\u00a0\n\u00a0 ?\u00a0vlo:hasForNonTangentialProperPartOf(?ve1,\u00a0?ve2)\u00a0\n\u00a0\n\nEsse detector relaciona intervalos que est\u00e3o propriamente contidos em ou-\ntros intervalos, testando os limites de cada um. O resultado \u00e9 uma rela\u00e7\u00e3o is?\nNonTangentialProperPartOf (e a sua inversa hasForNonTangentialProper?\nPartOf) entre o intervalo contido e o intervalo que cont\u00e9m. \n\nOs detectores definidos no sistema InteliStrata, bem como os demais mode-\nlos de conhecimento visual est\u00e3o completamente descritos no Anexo. \n\n5.2.2 Componentes de infra-estrutura \nPara dar suporte a todos os servi\u00e7os de racioc\u00ednio e processamento de sinal, \n\no sistema InteliStrata emprega componentes desenvolvidos por terceiros. Sobre \nestes componentes de infra-estrutura (Figura 5.5) s\u00e3o constru\u00eddos os demais al-\ngoritmos de interpreta\u00e7\u00e3o. A fim de justificar os componentes escolhidos, al-\ngumas considera\u00e7\u00f5es s\u00e3o feitas. \n\n\n\n79 \n\n \n\n \n\n \nFigura 5.5: Componentes de infra-estrutura do sistema InteliStrata. \n\nA primeira se refere \u00e0 representa\u00e7\u00e3o dos modelos de conhecimento. Como \ndiscutido na se\u00e7\u00e3o 3.1, os modelos de conhecimento do framework S-Chart us\u00e3o \nformalizados na linguagem OWL. Essa linguagem tem suporte de algumas fer-\nramentas modelagem, sendo o software Prot\u00e9g\u00e9 (KNUBLAUCH et al., 2004) o \nescolhido para utiliza\u00e7\u00e3o no InteliStrata. Essa escolha \u00e9 pautada por alguns mo-\ntivos, sendo os principais: \n\n\u2022 No momento da escrita deste trabalho, o Prot\u00e9g\u00e9 \u00e9 certamente a mais po-\npular e est\u00e1vel ferramenta para modelagem a manipula\u00e7\u00e3o de OWL. Ela \nconta com uma grande comunidade de usu\u00e1rios e sua distribui\u00e7\u00e3o \u00e9 livre. \n\n\u2022 A ferramenta disponibiliza uma interface de programa\u00e7\u00e3o que permite a \nmanipula\u00e7\u00e3o e consulta de modelos OWL diretamente de outras aplica-\n\u00e7\u00f5es. Esta facilidade permite que o sistema InteliStrata manipule os mo-\ndelos de conhecimento visual diretamente, sem a necessidade da sua \nconvers\u00e3o para paradigmas de representa\u00e7\u00e3o de informa\u00e7\u00e3o menos ex-\npressivos (como paradigma relacional). Isso atende diretamente ao obje-\ntivo de desenvolvimento com preserva\u00e7\u00e3o de estrutura. \n\n\u2022 A arquitetura da pr\u00f3pria ferramenta \u00e9 extens\u00edvel, permitindo a cria\u00e7\u00e3o e \nintegra\u00e7\u00e3o de extens\u00f5es e a sua utiliza\u00e7\u00e3o via a interface de software. Pa-\nra o sistema InteliStrata \u00e9 utilizada a extens\u00e3o SWRLTab (O\u2019CONNOR et \nal., 2005), direcionado manipula\u00e7\u00e3o de regras SWRL. Essa extens\u00e3o tem a \nsua import\u00e2ncia em si, de forma que permite a defini\u00e7\u00e3o e implementa-\n\u00e7\u00e3o de extens\u00f5es sobre a pr\u00f3pria linguagem SWRL, uma caracter\u00edstica \nimportante para defini\u00e7\u00e3o dos detectores fuzzy. \n\nA execu\u00e7\u00e3o das regras SWRL \u00e9 garantida pelo software Jess (FRIEDMAN, \n2003), uma m\u00e1quina para execu\u00e7\u00e3o de regras tamb\u00e9m extens\u00edvel. Embora o Jess \nseja uma pacote de software independente, a sua interface de programa\u00e7\u00e3o po-\nde ser facilmente integrada ao Prot\u00e9g\u00e9, via SWRLTab. De fato, atualmente a \nm\u00e1quina Jess \u00e9 a \u00fanica m\u00e1quina que permite a execu\u00e7\u00e3o de regras SWRL fun-\n\u00e7\u00f5es embutidas definidas pelo usu\u00e1rio. Adicionalmente, \u00e9 importante ressaltar \nque o sistema InteliStrata n\u00e3o faz uso de raciocinadores , como os implemen-\ntados nas ferramentas Pellet (PARSIA et al., 2005) ou FaCT++ (TSARKOV; \nHORROCKS, 2006), uma vez que os modelos do sistema n\u00e3o apresentam rela-\n\u00e7\u00f5es impl\u00edcitas e as inst\u00e2ncias dos modelos s\u00e3o geradas j\u00e1 na sua classifica\u00e7\u00e3o \ndefinitiva.  \n\n\n\n80 \n\n \n\n \n\nA escolha das ferramentas Prot\u00e9g\u00e9 e Jess tamb\u00e9m implica que a implementa-\n\u00e7\u00e3o seja baseada no ambiente Java (LINDHOLM; YELLIN, 1999), uma vez que \nessas duas disponibilizam as suas interfaces de programa\u00e7\u00e3o nessa linguagem. \n\nQualquer sistema de interpreta\u00e7\u00e3o como este requer algum tipo servi\u00e7o para \nprocessamento num\u00e9rico que seja eficiente. No caso do sistema InteliStrata, es-\nses servi\u00e7os de processamento devem dar suporte ao desenvolvimento de pro-\ncessamento de sinal de uma dimens\u00e3o. Existe pouco suporte nativo para a lin-\nguagem Java. Por isso, escolheu-se utilizar o software matem\u00e1tico Matlab \nR2008a j\u00e1 mencionado anteriormente, que disponibiliza diversos pacotes para \nprocessamento de dados num\u00e9ricos e, em especial, processamento de sinal. Por \nisso, o terceiro e \u00faltimo grande componente de infra-estrutura \u00e9 o software Ma-\ntlab. Os processamentos realizados com ele s\u00e3o melhor detalhados na subse\u00e7\u00e3o \nseguinte. \n\nPor fim, as ferramentas apresentadas garantem uma infra-estrutura adequa-\nda que atende aos objetivos do sistema InteliStrada. O suporte da ferramenta \nProt\u00e9g\u00e9 \u00e0 manipula\u00e7\u00e3o direta dos modelos de conhecimento ajuda na manuten-\n\u00e7\u00e3o da estrutura.  \n\n5.2.2.1 Algoritmos de processamento por wavelet \n\nO processamento inicial do sinal \u00e9 realizado dentro do software Matlab a-\ntrav\u00e9s da aplica\u00e7\u00e3o da TWC com as wavelets apresentadas nas se\u00e7\u00f5es 4.3. No en-\ntanto, a aplica\u00e7\u00e3o n\u00e3o \u00e9 direta. O sinal necessita de tratamento pr\u00e9-\nprocessamento e p\u00f3s-processamento, onde o resultado bruto da TWC \u00e9 tratado \nantes de ser disponibilizado aos n\u00edveis superiores de racioc\u00ednio. \n\nA TWC para ambas as wavelets passam por processamentos semelhantes, \nvariando em alguns par\u00e2metros. Os passos do algoritmo s\u00e3o os seguintes: \n\n\u2022 O sinal \u00e9 re-amostrado para freq\u00fc\u00eancia m\u00ednima necess\u00e1ria para detec\u00e7\u00e3o \nde sequ\u00eancias (wavelet gaussiana) ou parassequ\u00eancias (wavelet smoothto-\noth). A freq\u00fc\u00eancia m\u00ednima \u00e9 derivada atrav\u00e9s do per\u00edodo m\u00ednimo de uma \nsequ\u00eancia (15 metros) ou parassequ\u00eancia (3 metros). O resultado \u00e9 um si-\nnal com menor quantidade de amostras, menor ru\u00eddo da alta freq\u00fc\u00eancia e \nmais eficiente para processamento; \n\n\u2022 A TWC \u00e9 aplicada sobre o sinal re-amostrado. Em ambos os casos, a \ntransformada \u00e9 configurada para utilizar extens\u00f5es espelhadas no sinal, a \nfim de amenizar os problemas de processamento na borda; \n\nNeste pontos, os o algoritmo para a wavelet guassiana se diferencia da wave-\nlet smoothtooth. Para wavelet gaussiana: \n\n\u2022 O espectro resultante \u00e9 normalizado por n\u00edvel; \n\n\u2022 Considera-se o espectro como uma superf\u00edcie e procura-se pelos m\u00e1ximos \nlocais na superf\u00edcie.  \n\n\n\n81 \n\n \n\n \n\n\u2022 Sendo que cada m\u00e1ximo esta contida em uma das escalas, s\u00e3o procurados \nos m\u00ednimos \u00e0 direita e a esquerda dentro da escala, considerando apenas \nessa escala. Os pares de m\u00ednimos formam os limites de segmenta\u00e7\u00e3o \n\nNo caso da wavelet sawtooth: \n\n\u2022 O espectro \u00e9 normalizado e invertido; \n\n\u2022 Consideram-se cada escala do espectro e procura-se pelos m\u00e1ximos locais \nem cada uma. \n\n\u2022 A seguir, s\u00e3o encontrados os m\u00ednimos locais de cada lado dos m\u00e1ximos. \nOs pares de m\u00ednimas formam os limites de segmenta\u00e7\u00e3o. \n\nNesse ponto os algoritmos voltam a ser iguais: \n\n\u2022 Em seguida, um la\u00e7o iterativo busca pelos limites de cada intervalo en-\ncontrado e segmenta o sinal de acordo com esses limites. O pico de cada \nintervalo \u00e9 dado como a for\u00e7a padr\u00e3o (que acabada dando origem \u00e0 pro-\npriedade caracter\u00edstica no n\u00edvel visual). Quanto mais alto o n\u00famero, mais \na curva para o intervalo se parece com o padr\u00e3o da wavelet. \n\nAo final, os dados s\u00e3o organizados e repassados ao ambiente Java para con-\nvers\u00e3o em entidades do modelo de conhecimento (alo:Interval em geral).  \n\n5.2.3 Componentes de interpreta\u00e7\u00e3o \nOs componentes de interpreta\u00e7\u00e3o caracterizam a m\u00e1quina de interpreta\u00e7\u00e3o \n\nsem\u00e2ntica em si. Estes componentes s\u00e3o tr\u00eas (Figura 5.6): (i) o componente geren-\nciador de processamento de sinal, que trata de gerenciar a segmenta\u00e7\u00e3o e extra\u00e7\u00e3o \ndo sinal a ser analisado pelo sistema; (ii) o componente de interpreta\u00e7\u00e3o, que im-\nplementa as m\u00e1quinas MIS e MIV descritas no cap\u00edtulo anterior; e (iii) o compo-\nnente de interface gr\u00e1fica com o usu\u00e1rio (GUI), que disponibiliza o resultado da \ninterpreta\u00e7\u00e3o ao usu\u00e1rio final. \n\nOs tr\u00eas componentes trocam informa\u00e7\u00f5es dentro de um contexto comparti-\nlhado. Esse contexto \u00e9 dado pela ontologia OWL InteliStrataOntology. De \nfato, essa \u00e9 uma extens\u00e3o da utiliza\u00e7\u00e3o da estrutura Contexto das m\u00e1quinas \nMIS e MIV, descritas na se\u00e7\u00e3o 3.2.5 no cap\u00edtulo anterior. \n\n \nFigura 5.6: Componentes de interpreta\u00e7\u00e3o do sistema InteliStrata. \n\n\n\n82 \n\n \n\n \n\n5.2.3.1 Gerenciador de processamento de sinal \n\nO gerenciador de processamento de sinal tem por fun\u00e7\u00e3o delegar e gerenciar \na aplica\u00e7\u00e3o dos algoritmos de processamento presentes no sistema. Ele recebe \nprimitivas anal\u00f3gicas que devem ser extra\u00eddas diretamente do sinal e aciona o \nalgoritmo adequado para a sua extra\u00e7\u00e3o. O resultado da extra\u00e7\u00e3o s\u00e3o inst\u00e2ncias \ndessas primitivas inclu\u00eddas no modelo OWL para que sejam utilizados no pro-\ncesso de interpreta\u00e7\u00e3o simb\u00f3lico. \n\nCada algoritmo de processamento pode processar mais de uma primitiva \npor vez. Por exemplo, um algoritmo que extrai um conjunto de intervalos pode \nao mesmo tempo calcular outras propriedades como comprimento, ponto inici-\nal e final e etc. \n\nGrande parte dos algoritmos \u00e9 implementado dentro do ambiente Java do \nsistema InteliStrata. No entanto, a extra\u00e7\u00e3o por wavelets \u00e9 repassada, via Java \nRMI, para m\u00f3dulos nativos do sistema Matlab. Nele, os algoritmos de extra\u00e7\u00e3o \nutilizam as funcionalidades dos pacotes de processamento de sinal para ajusta o \nsinal que comp\u00f5e o perfil de po\u00e7o e extrair as fei\u00e7\u00f5es visuais conforme descrito \nna se\u00e7\u00e3o anterior. O resultado bruto \u00e9 repassado para o ambiente Java e conver-\ntido em entidades anal\u00f3gicas dentro da ontologia OWL. \n\n5.2.3.2 Componente de interpreta\u00e7\u00e3o \n\nO componente de interpreta\u00e7\u00e3o implementa as m\u00e1quinas MIS e MIV, con-\nforme os algoritmos especificados na se\u00e7\u00e3o 3.2.5. Embora a implementa\u00e7\u00e3o seja \nbastante direta em rela\u00e7\u00e3o \u00e0 especifica\u00e7\u00e3o, alguns aspectos necessitam uma a-\nten\u00e7\u00e3o especial. \n\nInicialmente, todas as manipula\u00e7\u00f5es de entidades dos modelos de conheci-\nmento s\u00e3o realizadas diretamente sobre as ontologias OWL que representam \nesses modelos. Isso \u00e9 feito atrav\u00e9s da interface de programa\u00e7\u00e3o do aplicativo \nProt\u00e9g\u00e9. Dessa forma, as entidades manipuladas n\u00e3o precisam ser convertidas \npara algum outro formalismo (como relacional, por exemplo) a fim de serem u-\ntilizadas. \n\nOs algoritmos das m\u00e1quinas MIS e MIV necessitam de algum mecanismo \npara execu\u00e7\u00e3o dos detectores simb\u00f3licos, definidos como regras SWRL. No sis-\ntema InteliStrata, a execu\u00e7\u00e3o das regras \u00e9 feita pelo componente Jess. A interface \ndo componente Jess com o sistema InteliStrata \u00e9 realizada pelo componente \nSWRLTab. \n\n5.2.3.3 Componente de interface \n\nO componente de interface gr\u00e1fica (GUI) fornece ao usu\u00e1rio um meio para \nmanipular e visualizar os resultados gerados pela interpreta\u00e7\u00e3o. Idealmente, a \ninterface deve prover as seguintes funcionalidades: \n\n\u2022 Filtragem interativa das informa\u00e7\u00f5es interpretadas. A interface deve \npermitir ao usu\u00e1rio filtrar os resultados da interpreta\u00e7\u00e3o, seja para \n\n\n\n83 \n\n \n\n \n\nmelhor visualiza\u00e7\u00e3o, seja para excluir interpreta\u00e7\u00f5es esp\u00farias que po-\ndem ocorrer; \n\n\u2022 Carregamento de perfis de po\u00e7o e salvamento de interpreta\u00e7\u00e3o: o \nsistema deve permitir que dados de perfis de po\u00e7os sejam importados \ne que o resultado das interpreta\u00e7\u00f5es seja salvo; \n\n\u2022 Exibi\u00e7\u00e3o gr\u00e1fica interativa: a exibi\u00e7\u00e3o dos resultados deve ser gr\u00e1fica \ne interativa (com opera\u00e7\u00f5es de zoom e etc.) \n\nDefinidos esses requisitos, \u00e9 necess\u00e1rio ressaltar que o foco principal deste \ntrabalho \u00e9 o desenvolvimento de um aplicativo prot\u00f3tipo que demonstre a via-\nbilidade do framework S-Chart para interpreta\u00e7\u00e3o de gr\u00e1ficos. Devido a esse fa-\nto, o prot\u00f3tipo implementado aqui apenas demonstra como estas funcionalida-\ndes podem ser alcan\u00e7ados. Uma vers\u00e3o operacional deste sistema demandaria \num estudo de interface e estrat\u00e9gias de visualiza\u00e7\u00e3o de dados.   \n\nO componente de interface projetado para o prot\u00f3tipo permite a visualiza-\n\u00e7\u00e3o de todos os resultados da interpreta\u00e7\u00e3o. Fun\u00e7\u00f5es de carregamento de dados, \nsalvamento e filtragem foram implementadas diretamente no c\u00f3digo, como \numa prova de conceito. A interface, com o resultado da interpreta\u00e7\u00e3o para o \nperfil do po\u00e7o Tenneco Rattlesnake State 2-12 \u00e9 demonstrado na Figura 5.7. \n\n \nFigura 5.7: Interpreta\u00e7\u00e3o de parte do perfil Tenneco Rattlesnake State 2-12. \n\nUm dos aspectos importantes do componente de interface \u00e9 que os resulta-\ndos da interpreta\u00e7\u00e3o s\u00e3o recuperados diretamente dos modelos OWL, via \nProt\u00e8g\u00e8. A consulta \u00e9 realizada com a linguagem SPARQL, linguagem padr\u00e3o \nde consulta para bases de dados RDF e OWL. Ela representa uma forma consis-\ntente para pesquisa de informa\u00e7\u00f5es geradas nos modelos. Al\u00e9m disso, os pr\u00f3-\n\n\n\n84 \n\n \n\n \n\nprios modelos podem orientar a pesquisa. Por exemplo, para exibi\u00e7\u00e3o das enti-\ndades na Figura 5.7, todas as sequ\u00eancias s\u00e3o recuperadas inicialmente. Para exi-\nbi\u00e7\u00e3o, os atributos anal\u00f3gicos associados com cada sequ\u00eancia s\u00e3o recuperados. \nA seguir, conforme o modelo, as partes de cada sequ\u00eancia (parassequ\u00eancia e \nsuperf\u00edcie de inunda\u00e7\u00e3o m\u00e1xima) s\u00e3o recuperadas e tamb\u00e9m exibidas com base \nnos dados anal\u00f3gicos onde est\u00e3o ancoradas. Outro aspecto, \u00e9 que consultas \nSPARQL podem ser geradas dinamicamente. Em um sistema completo, elas \npodem ser usadas para implementar um mecanismo de filtragem din\u00e2mica das \ninforma\u00e7\u00f5es do modelo. \n\n5.3 Valida\u00e7\u00e3o do sistema InteliStrata \nAqui ser\u00e1 demonstrada a avalia\u00e7\u00e3o de dois perfis de po\u00e7os para os quais e-\n\nxiste interpreta\u00e7\u00e3o detalhada. As duas se\u00e7\u00f5es escolhidas para estudo de caso \ndeste trabalho tem significado hist\u00f3rico para a Geologia.  Seu estudo deu ori-\ngem \u00e0s propostas originais de interpreta\u00e7\u00e3o de bacias sedimentares a partir da \nidentifica\u00e7\u00e3o da oscila\u00e7\u00e3o do n\u00edvel dos oceanos ao longo do tempo geol\u00f3gico, ou \nseja, deu origem \u00e0 pr\u00f3pria \u00e1rea de Estratigrafia de Sequ\u00eancias. Elas foram utili-\nzadas como exemplos na publica\u00e7\u00e3o introdut\u00f3ria da \u00e1rea de Estratigrafia de Se-\nqu\u00eancias de Van Wagoner e colegas (1990) e constituem a escolha ideal para tes-\nte do sistema InteliStrata pois a sua interpreta\u00e7\u00e3o estratigr\u00e1fica j\u00e1 \u00e9 consolidada \ne reconhecida. \n\nA metodologia de avalia\u00e7\u00e3o \u00e9 direta e t\u00edpica em sistemas de conhecimento: o \nsistema \u00e9 v\u00e1lido se, para um dado perfil e uma dada interpreta\u00e7\u00e3o desse perfil, \no especialista no dom\u00ednio considera o resultado da interpreta\u00e7\u00e3o relevante. \n\nPara valida\u00e7\u00e3o do sistema InteliStrata foram utilizadas duas se\u00e7\u00f5es retiradas \nde dois perfis de raios gama distintos. As se\u00e7\u00f5es s\u00e3o: \n\n\u2022 Se\u00e7\u00e3o 1 de raios gama com aproximadamente 340 metros, retirada a par-\ntir da profundidade 820m do perfil medido no po\u00e7o Tenneco Rattlesnake \nState 2-12, localizado na regi\u00e3o de Book Cliffs, em Utah, EUA.  \n\n\u2022 Se\u00e7\u00e3o 2 de raios gama com aproximadamente 360 metros, retirada a par-\ntir da profundidade 30m do perfil medido no po\u00e7o Exxon Production Rese-\narch Co. Sego Canyon n\u00ba 2, tamb\u00e9m localizado na regi\u00e3o de Book Cliffs.\n  \n\n5.3.1 Prepara\u00e7\u00e3o dos perfis \nAs vers\u00f5es originais dos perfis foram obtidas no site do Departamento de \n\nRecursos Naturais do governo do estado de Utah, EUA (DEPARTMENT OF \nNATURAL RESOURCES, 2009). Eles s\u00e3o disponibilizados como imagens digi-\ntalizadas dos perfis em papel, no formato TIFF com 1 bit de cor, como a Figura \n4.1 no in\u00edcio deste cap\u00edtulo.  \n\nPara utiliza\u00e7\u00e3o no sistema InteliStrata, o perfil deve ser totalmente digitali-\nzado. O processo de digitaliza\u00e7\u00e3o das imagens dos perfis foi implementado da \nseguinte forma: \n\n\n\n85 \n\n \n\n \n\n\u2022 A imagem do perfil \u00e9 limpa de outras informa\u00e7\u00f5es at\u00e9 restar somente a \n\u00e1rea que representa o perfil de raios gama. Em seguida a imagem \u00e9 ero-\ndida para eliminar a maior parte de ru\u00eddos e imperfei\u00e7\u00f5es. \n\n\u2022 Da imagem do perfil \u00e9 derivada uma m\u00e1scara que descreve a somente \ncurva do perfil com uma espessura maior. Esse processo \u00e9 realizado ma-\nnualmente. \n\n\u2022 A imagem limpa e a m\u00e1scara s\u00e3o carregadas no programa Matlab. Um \nalgoritmo desenvolvido como parte deste trabalho faz a digitaliza\u00e7\u00e3o. A \ncada linha de pixels da imagem limpa, encontram-se os limites da m\u00e1sca-\nra. Dentro deste limite, o algoritmo busca pela maior linha de pixels pin-\ntados e calcula o seu centro. Este deve ser o centro da linha que caracteri-\nza o perfil. Esse valor \u00e9 gravado num vetor e repete-se o processo para a \npr\u00f3xima linha. Posteriormente, os valores de posi\u00e7\u00e3o do vetor s\u00e3o con-\nvertidos para a escala de leitura do perfil de raios gama.   \n\n\u2022 Eventualmente, algumas leituras s\u00e3o rejeitadas e o sinal ganha o valor ze-\nro em alguns pontos. Estes problemas de digitaliza\u00e7\u00e3o s\u00e3o eliminados \ncom algoritmos de interpola\u00e7\u00e3o. \n\nO resultado do processo \u00e9 uma representa\u00e7\u00e3o vetorial do sinal original do \nperfil. Para utiliza\u00e7\u00e3o no sistema InteliStrata, uma inst\u00e2ncia de FileRawData?\nHolder \u00e9 criada, apontando para um arquivo com esse vetor. \n\nNuma aplica\u00e7\u00e3o real, os pr\u00f3prios sistemas de perfilagem de po\u00e7o geram o \narquivo com o vetor de dados que seria a entrada do sistema InteliStrata.    \n\n5.3.2 Avalia\u00e7\u00e3o dos resultados e valida\u00e7\u00e3o \nO primeiro fator importante na avalia\u00e7\u00e3o das interpreta\u00e7\u00f5es obtidas pelo sis-\n\ntema InteliStrata se refere a forma como \u00e9 feita a interpreta\u00e7\u00e3o estratigr\u00e1fica. \nComo descrito anteriormente, uma interpreta\u00e7\u00e3o completa \u00e9 obtida atrav\u00e9s da \ncorrela\u00e7\u00e3o de diversas informa\u00e7\u00f5es, n\u00e3o somente do perfil de raios gama. De \nacordo com o especialista, a interpreta\u00e7\u00e3o baseada puramente no perfil ocorre \nquando as informa\u00e7\u00f5es complementares ainda n\u00e3o est\u00e3o dispon\u00edveis. O resul-\ntado da interpreta\u00e7\u00e3o do perfil tem o papel de dar a primeira ideia de quais s\u00e3o \nas fei\u00e7\u00f5es geol\u00f3gicas presentes (sequ\u00eancia, parassequ\u00eancias e etc.), para que, \nposteriormente, sejam ajustadas conforme a disponibilidade de dados de teste-\nmunho, s\u00edsmica ou estudos geol\u00f3gicos anteriores da bacia sedimentar. Dessa \nforma, o resultado da interpreta\u00e7\u00e3o realizada pelo sistema InteliStrata deve ser \ncomparado com o resultado da an\u00e1lise preliminar do perfil, feita pelo especia-\nlista sem a complementa\u00e7\u00e3o de outros dados geol\u00f3gicos. \n\nO primeiro teste foi realizado com o perfil da Se\u00e7\u00e3o 1 e \u00e9 demonstrado na Fi-\ngura 5.8. A Interpreta\u00e7\u00e3o A apresenta a interpreta\u00e7\u00e3o realizada pelo especialista \nlevando em conta somente o perfil. J\u00e1 as interpreta\u00e7\u00f5es B (B1, B2, B3, B4 e B5) \ns\u00e3o as obtidas pelo sistema InteliStrata.  \n\nInicialmente, \u00e9 poss\u00edvel notar uma discord\u00e2ncia entre o n\u00famero de interpre-\nta\u00e7\u00f5es do especialista e do sistema. De fato, o sistema sugere interpreta\u00e7\u00f5es al-\n\n\n\n86 \n\n \n\n \n\nternativas para as mesmas sequ\u00eancias. Tr\u00eas delas (B1, B2 e B4) concordam razo-\navelmente com os limites de sequ\u00eancia da interpreta\u00e7\u00e3o gabarito. No entanto, \nn\u00e3o h\u00e1 nenhuma interpreta\u00e7\u00e3o do sistema que sugira a presen\u00e7a da Sequ\u00eancia 3. \n\u00c9 poss\u00edvel ajustar os n\u00edveis de ru\u00eddo para possibilitar a sua interpreta\u00e7\u00e3o. No en-\ntanto, tal ajuste possibilita a passagem de sequ\u00eancias esp\u00farias na interpreta\u00e7\u00e3o \nfinal.  \n\nNo caso das superf\u00edcies de inunda\u00e7\u00e3o m\u00e1xima (mfs), todas as interpreta\u00e7\u00f5es \ndo sistema concordam com a do especialista (ex.: seta B). \n\nJ\u00e1 a interpreta\u00e7\u00e3o das parassequ\u00eancias \u00e9 mais ruidosa, gerando interpreta-\n\u00e7\u00f5es duplas e (ex.: seta A) falsos positivos (ex: seta C). No entanto, em alguns \ncasos, h\u00e1 concord\u00e2ncia quase exata, como as parasequ\u00eancias 8 e 9 na Sequ\u00eancia \n2 e, em um menor grau, a parasequ\u00eancias 3 na Sequ\u00eancia 1. Essa maior discor-\nd\u00e2ncia na interpreta\u00e7\u00e3o ocorre devido a menor escala das parassequ\u00eancias. Fei-\n\u00e7\u00f5es em escalas muito pequenas se confundem com ru\u00eddos de alta freq\u00fc\u00eancia \ndurante segmenta\u00e7\u00e3o do sinal, sendo, por isso, eliminadas no processamento \nsimb\u00f3lico.  \n\nO segundo teste foi realizado com o perfil da Se\u00e7\u00e3o 2, demonstrado na Figu-\nra 5.9. A Interpreta\u00e7\u00e3o A apresenta a interpreta\u00e7\u00e3o realizada pelo especialista \nlevando em conta somente o perfil. J\u00e1 as interpreta\u00e7\u00f5es B (B1, B2, B3 e B4) s\u00e3o as \nobtidas pelo sistema InteliStrata.  \n\nDo ponto de vista qualitativo, a interpreta\u00e7\u00e3o da Se\u00e7\u00e3o 2 \u00e9 semelhante a da \nSe\u00e7\u00e3o 1, com destaque positivo para a grande coincid\u00eancia da interpreta\u00e7\u00e3o B3 \ncom a Sequ\u00eancia 1. \n\nPor fim, os resultados apresentados aqui foram descritos como satisfat\u00f3rios \npelo especialista, mesmo havendo discrep\u00e2ncias entre a interpreta\u00e7\u00e3o sugerida \ne a feita pelo sistema. A racionaliza\u00e7\u00e3o por tr\u00e1s desse fato \u00e9 a imprecis\u00e3o ineren-\nte \u00e0 interpreta\u00e7\u00e3o estratigr\u00e1fica por perfis de raios gama. A marca\u00e7\u00e3o precisa \ndos limites das fei\u00e7\u00f5es \u00e9 uma tarefa significativamente complexa e um tanto \nsubjetiva, especialmente quando se leva em conta somente a informa\u00e7\u00e3o do per-\nfil. Um fato que corrobora com essa an\u00e1lise \u00e9 a afirma\u00e7\u00e3o feita pelo especialista \nao confrontar os resultados, declarando que algumas das fei\u00e7\u00f5es interpretadas \npelo sistema s\u00e3o vis\u00f5es v\u00e1lidas sobre o perfil, mesmo contrariando a sua pr\u00f3-\npria interpreta\u00e7\u00e3o. Um exemplo \u00e9 a diferen\u00e7a de interpreta\u00e7\u00e3o da mfs apontada \npela seta D na figura Figura 5.9. O especialista afirma que a interpreta\u00e7\u00e3o dada \npelo sistema para a mfs tamb\u00e9m \u00e9 uma interpreta\u00e7\u00e3o poss\u00edvel, quando n\u00e3o es-\ntao dispon\u00edveis outros dados geol\u00f3gicos. \n\nOs resultados mostram-se ainda mais v\u00e1lidos quando se considera o tempo \ndemandado para a interpreta\u00e7\u00e3o manual dos perfis pelos profissionais aptos a \nrealizar interpreta\u00e7\u00e3o de sequ\u00eancias. O processamento autom\u00e1tico associado ao \najustes manuais necess\u00e1rios para obter um conjunto v\u00e1lido de interpreta\u00e7\u00f5es \nrequerem um tempo significativamente menor para a tarefa de interpreta\u00e7\u00e3o \nquando comparado ao necess\u00e1rio para realizar a atividade na realidade atual.  \n\n\n\n \n\n \n\n \n\n \nFigura 5.8: Compara\u00e7\u00e3o das interpreta\u00e7\u00f5es do especialista e do sistema InteliStrata para Se\u00e7\u00e3o 1. \n\n\n\n88 \n\n \n\n \n\nB\n\n \nFigura 5.9: Compara\u00e7\u00e3o das interpreta\u00e7\u00f5es do especialista e do sistema InteliStrata para Se\u00e7\u00e3o 2. \n\n\n\n \n\n \n\n \n\n6 CONCLUS\u00c3O \n\nA \u00e1rea de vis\u00e3o computacional \u00e9 de grande import\u00e2ncia para computa\u00e7\u00e3o. A \ntarefa de interpretar o conte\u00fado de dados pict\u00f3ricos \u00e9 bastante desafiadora e \ntem sido abordada de diversas maneiras nas \u00faltimas duas d\u00e9cadas. Uma dessas \nmaneiras \u00e9 a interpreta\u00e7\u00e3o sem\u00e2ntica de imagens, \u00e1rea deste trabalho. Ela busca \nunir os esfor\u00e7os de pesquisa alcan\u00e7ados nas \u00e1reas de processamento de imagens \ne de representa\u00e7\u00e3o de conhecimento, especialmente conhecimento visual. \n\nEste trabalho prop\u00f4s um framework completo para interpreta\u00e7\u00e3o sem\u00e2ntica \nde gr\u00e1ficos, um tipo espec\u00edfico de imagem que representa visualmente um sinal \nde uma dimens\u00e3o. O S-Chart, como \u00e9 chamado, define modelos de conhecimen-\nto visual em tr\u00eas n\u00edveis sem\u00e2nticos e aplica conceitos de ancoramento simb\u00f3lico \npara realizar o mapeamento entres entidades destes n\u00edveis. Al\u00e9m de propor al-\ngoritmos gen\u00e9ricos para operacionalizar a interpreta\u00e7\u00e3o visual com base nos \nmodelos de conhecimento. \n\nEste trabalho tamb\u00e9m descreveu o sistema InteliStrata, uma implementa\u00e7\u00e3o \ndo framework S-Chart para interpreta\u00e7\u00e3o de gr\u00e1ficos no dom\u00ednio da Geologia, \nmais especificamente, no dom\u00ednio da Estratigrafia de Sequ\u00eancias. O objetivo do \nsistema InteliStrata \u00e9 identificar fei\u00e7\u00f5es geol\u00f3gicas (sequ\u00eancias, parassequ\u00eancias \ne superf\u00edcies de inunda\u00e7\u00e3o m\u00e1xima) com base na interpreta\u00e7\u00e3o sem\u00e2ntica de \ngr\u00e1ficos de perfis de raios gama. Os resultados obtidos foram considerados pelo \nespecialista em Estratigrafia de Sequ\u00eancias que acompanhou o projeto como \ncompat\u00edveis com a interpreta\u00e7\u00e3o dada por um ge\u00f3logo com experi\u00eancia nesse \ntipo de interpreta\u00e7\u00e3o a partir dos mesmos dados. \n\n6.1 Framework S-Chart e modelos de conhecimento visual \nA an\u00e1lise de propostas de interpreta\u00e7\u00e3o sem\u00e2ntica existentes na literatura \n\ndemonstrou que poucas delas s\u00e3o voltadas para representa\u00e7\u00e3o e interpreta\u00e7\u00e3o \nde dados pict\u00f3ricos em dom\u00ednios imag\u00edsticos. Al\u00e9m disso, nenhuma das pro-\npostas aborda a interpreta\u00e7\u00e3o de gr\u00e1ficos, cuja import\u00e2ncia \u00e9 relevante em di-\nversos dom\u00ednios. Tampouco foram encontradas abordagens que se baseiam em \npadr\u00f5es de representa\u00e7\u00e3o abertos, o que dificulta a integra\u00e7\u00e3o dos resultados da \ninterpreta\u00e7\u00e3o com outros sistema de conhecimento, por exemplo. Por esses mo-\ntivos, desenvolveu-se uma nova abordagem de interpreta\u00e7\u00e3o sem\u00e2ntica de ima-\ngens voltada para interpreta\u00e7\u00e3o de gr\u00e1ficos. \n\n\n\n90 \n\n \n\n \n\nOs resultados positivos do framework S-Chart se dividem em duas partes. \nPrimeiramente, o modelo de representa\u00e7\u00e3o de conhecimento visual em tr\u00eas n\u00ed-\nveis conseguiu capturar o conhecimento necess\u00e1rio para interpreta\u00e7\u00e3o de gr\u00e1fi-\ncos de forma independente da aplica\u00e7\u00e3o, garantindo a reusabilidade da aborda-\ngem em outros dom\u00ednios. Isso se deu na forma de primitivas de representa\u00e7\u00e3o \nem todos os n\u00edveis sem\u00e2nticos, com destaque para as primitivas no n\u00edvel visual. \nOutro grande avan\u00e7o no framework S-Chart foi a defini\u00e7\u00e3o de uma maneira \nhomog\u00eanea de mapeamento entre n\u00edveis sem\u00e2nticos, na forma dos detectores \nsimb\u00f3licos. \n\nEm segundo lugar, a escolha da linguagem OWL e SWRL como formalismo \nde representa\u00e7\u00e3o dos modelos de conhecimento facilita a implementa\u00e7\u00e3o do \nframework em sistema de interpreta\u00e7\u00e3o, como se demonstrou com o sistema In-\nteliStrata. As vantagens sobre a utiliza\u00e7\u00e3o de formalismos espec\u00edficos s\u00e3o diver-\nsas, desde a utiliza\u00e7\u00e3o de uma linguagem j\u00e1 bem formalizada at\u00e9 a integra\u00e7\u00e3o \ncom outros sistemas que utilizam a mesma linguagem.  \n\nO sistema InteliStrata demonstrou como o framework S-Chart  pode ser im-\nplementado em um sistema real para interpreta\u00e7\u00e3o de perfis de po\u00e7o, no dom\u00ed-\nnio Estratigrafia de Sequ\u00eancia. O sistema complementa partes do framework \ndefinidas como dependente de dom\u00ednio. Essas partes s\u00e3o um modelo de dom\u00ed-\nnio simples descrevendo os principais conceitos da Estratigrafia de Sequ\u00eancia, \nprimitivas visuais dependentes do dom\u00ednio e alguns detectores simb\u00f3licos. A-\nl\u00e9m disso, foi demonstrado como componentes de software e sistemas de tercei-\nros podem ser integrados para dar suporte a interpreta\u00e7\u00e3o sem\u00e2ntica. Os resul-\ntados apresentados pelo sistema InteliStrata foram validados e considerados sa-\ntisfat\u00f3rios pelo especialista no dom\u00ednio. \n\n6.2 Sugest\u00e3o para trabalhos futuros \nDurante o desenvolvimento do framework, foram propostas diversas primi-\n\ntivas de representa\u00e7\u00e3o, especialmente no n\u00edvel visual. Embora o sistema InteliS-\ntrata fa\u00e7a uso de apenas algumas delas, claramente novas primitivas podem ser \ndefinidas. De fato, ao contr\u00e1rio do que acontece com imagens reais, n\u00e3o existem \ntrabalhos que definam par\u00e2metros visuais gen\u00e9ricos em gr\u00e1ficos. Assim, \u00e0 me-\ndida que novas aplica\u00e7\u00f5es sejam desenvolvidas, a ontologia que modela o n\u00edvel \nvisual pode ser incrementada como novas primitivas. \n\nUm problema encontrado durante o desenvolvimento do modelo do n\u00edvel \nvisual foi dar uma representa\u00e7\u00e3o simb\u00f3lica textual adequada a alguns conceitos. \nA representa\u00e7\u00e3o textual nem sempre se mostrou eficiente pra capturar o signifi-\ncado completo do conceito. Como no caso dos tipos de curvas modeladas e, em \nespecial, da entidade CurvaSigmoide. Uma curva sigm\u00f3ide tem o mesmo for-\nmato de uma curva log\u00edstica. Assim, se ambos os conceitos forem modelados, \neles ser\u00e3o equivalentes, gerando redund\u00e2ncias no modelo. Entretanto, se, ao in-\nv\u00e9s de um s\u00edmbolo textual, fosse usado um s\u00edmbolo gr\u00e1fico para representar o \nconceito (ex.: um desenho da curva), a sua representa\u00e7\u00e3o se tornaria mais natu-\nral. Esse problema pode ser resolvido atrav\u00e9s do desenvolvimento de primiti-\n\n\n\n91 \n\n \n\n \n\nvas de representa\u00e7\u00e3o de conhecimento que aceitem o uso de \u00edcones e figuras \ncomo representa\u00e7\u00e3o simb\u00f3lica10.  \n\nUma lacuna deixada no desenvolvimento do framework foi o tratamento \ndos \u00edndices de pertin\u00eancia resultantes das fun\u00e7\u00f5es fuzzy utilizadas pelos descri-\ntores simb\u00f3licos. De fato, os \u00edndices de caracter\u00edstica utilizados no n\u00edvel visual \nconsistem na alternativa encontrada para modelar os \u00edndices de pertin\u00eancias re-\nsultados das fun\u00e7\u00f5es fuzzy no modelo visual. Embora n\u00e3o a ideal, essa modela-\ngem se mostrou eficiente para os fins deste trabalho. No entanto, no momento \nda escrita desta disserta\u00e7\u00e3o, uma nova vers\u00e3o da linguagem OWL est\u00e1 sendo \ndefinida e esta poderia modelar facilmente essas informa\u00e7\u00f5es. As novas primi-\ntivas antevistas permitiriam a modelagem de rela\u00e7\u00f5es de anota\u00e7\u00e3o sobre qual-\nquer entidade do modelo, at\u00e9 mesmo sobre axiomas entre inst\u00e2ncias. Dessa \nforma, seria poss\u00edvel anotar, por exemplo, um grau de certeza na rela\u00e7\u00e3o entre \numa inst\u00e2ncia e a sua classe. Deste modo, as primitiva temCaracteristica u-\nsada no framework S-Chart poderia passar a ser uma rela\u00e7\u00e3o de anota\u00e7\u00e3o sobre \nentidades visuais extra\u00eddas do n\u00edvel anal\u00f3gico. \n\nPor fim, como foi afirmado no desenvolvimento do trabalho, a defini\u00e7\u00e3o \ncompleta de um m\u00f3dulo para gerenciar a aplica\u00e7\u00e3o de algoritmos de processa-\nmento de imagem fogem do escopo deste trabalho. No entanto, ele \u00e9 de grande \nimport\u00e2ncia para um sistema de interpreta\u00e7\u00e3o sem\u00e2ntica. Um m\u00f3dulo deste ti-\npo deveria ser capaz de, dado um conjunto de primitivas anal\u00f3gicas que devem \nser extra\u00eddas do sinal, decidir quais algoritmos aplicar e em qual ordem. Defini-\ndos como servi\u00e7os de processamento, suas interfaces devem ser formalizadas \ndentro dos modelos, presumivelmente em uma extens\u00e3o do modelo de proces-\nsamento de sinal descrito anteriormente.  \n\n \n\n                                                 \n\n \n10 No momento da escrita deste trabalho, esta alternativa de representa\u00e7\u00e3o est\u00e1 tamb\u00e9m \n\nsendo pesquisada por Alexandre Lorenzatti (vide note anterior). \n\n\n\n \n\n \n\n \n\nREFER\u00caNCIAS \n\nBARSALOU, L. W. Perceptual symbol systems. Behavioral and Brain Sciences, \nNew York. v. 22, n. 4, p. 577-660, 1999. \n\nCHELLA, A.; FRIXIONE, M.; GAGLIO, S. A cognitive architecture for artificial \nvision. Artificial Intelligence, Amsterdan. v. 89, n. 1-2, p. 73-111, 1997. \n\nCHELLA, A.; FRIXIONE, M.; GAGLIO, S. Conceptual Spaces for Computer Vi-\nsion Representations. Artificial Intelligence Review, Dordrecht. v. 16, n. 2, p. \n137-152, 2001. \n\nCHOUDHURY, S. et al. Use of Wavelet Transformation for Geophysical Well-\nLog Data Analysis.  In: 15th International Conference on Digital Signal Process-\ning.  Proceedings... , Cadiff (UK) 2007. p. 647-650. \n\nCOHN, A. G. et al. Qualitative Spatial Representation and Reasoning with the \nRegion Connection Calculus. GeoInformatica, Boston. v. 1, n. 3, p. 275-316, \n1997. \n\nCOHN, A. G. et al. Towards an Architecture for Cognitive Vision Using Quali-\ntative Spatio-temporal Representations and Abduction. Spatial Cognition III, \nBerlin: Springer, 2003. p. 246-262. (Lecture Notes in Computer Science, 2685). \n\nCOLOMB, R. et al. The Object Management Group Ontology Definition Meta-\nmodel. Ontologies for Software Engineering and Software Technology, Ber-\nlin: Springer, 2006. p. 217-247. \n\nCORADESCHI, S. et al. Fuzzy anchoring.  In: The 10th IEEE International Con-\nference on Fuzzy Systems.  Proceedings... , [S.l.]. v. 1, 2001. p. 111-114. \n\nCREVIER, D.; LEPAGE, R. Knowledge-based image understanding systems: a \nsurvey. Comput. Vis. Image Underst., [S.l.]. v. 67, n. 2, p. 160-185, 1997. \n\nCRUB\u00c9ZY, M.; MARCOS, M.; MOISAN, S. Experiments in Building Program \nSupervision Engines from Reusable Components.  In: WORKSHOP on Applica-\ntions of Ontologies and Problem-Solving Methods.  Proceedings... , Brighton, \nEngland 1998. p. 44-53. \n\nDELLA F\u00c1VERA, J. C. Fundamentos de estratigrafia moderna. Rio de Janeiro: \nEdUERJ, 2001, \n\nDEPARTMENT OF NATURAL RESOURCES. State of Utah - Oil and Gas Pro-\ngram - Home Page. 2009. Dispon\u00edvel em:&lt;http://oilgas.ogm.utah.gov/>. A-\ncesso em: 25 Fev 2009. \n\n\n\n93 \n\n \n\n \n\nFAN, J. et al. Statistical modeling and conceptualization of natural images. Pat-\ntern Recognition, [S.l.]. v. 38, n. 6, p. 865-885, 2005. \n\nFIORINI, S. R. Uma Proposta de Arquitetura de Componentes pra Sistemas de \nConhecimento para Avalia\u00e7\u00e3o de Reservat\u00f3rios de Petr\u00f3leo. 2006. 65 p. Mono-\ngrafia (Bacharelado em Ci\u00eancia da Computa\u00e7\u00e3o) - Instituto de Inform\u00e1tica, Uni-\nversidade Federal do Rio Grande do Sul. \n\nFRIEDMAN, E. Jess in action: rule-based systems in java. Greenwich, US: \nManning Publications Co., 2003, \n\nGANGEMI, A. et al. Sweetening WORDNET with DOLCE. AI Magazine, \nMenlo Park, US. v. 24, n. 3, p. 13-24, 2003. \n\nG\u00c4RDENFORS, P. Conceptual Spaces: The Geometry of Thought. Cambridge, \nMassachussetts: The MIT Press, 2004, \n\nGOMEZ, I.; DATCU, M. A Bayesian multi-class image content retrieval.  In: In-\nternational Geoscience and Remote Sensing Symposium.  Proceedings... , Los \nAlamitos, USA: IEEE, 2007. p. 326-329. \n\nHANSON, A.; RISEMAN, E. VISIONS: A computer system for interpreting \nscenes. Computer Vision Systems, [S.l.]. 1978. \n\nHARNAD, S. The symbol grounding problem. Phys. D, [S.l.]. v. 42, n. 1-3, p. \n335-346, 1990. \n\nHARNAD, S. Computation Is Just Interpretable Symbol Manipulation: Cog-\nnition Isn't. 1994. Dispon\u00edvel em:&lt;http://cogprints.org/1592/>. Acesso em: 29 \nJan 2009. \n\nHERZOG, G. From visual input to verbal output in the visual translator.  In: \nAAAI Fall Symposium on Computational Models for Integrating Language and \nVision.  Proceedings... , Cambridge, USA: AAAI, 1995. \n\nHORRIDGE, M. et al. The Manchester OWL Syntax.  In: OWLED*06 Workshop \non OWL: Experiences and Directions.  Proceedings... , Athens, USA v. 216, \n2006. \n\nHORROCKS, I. et al. SWRL: A Semantic Web Rule Language Combining \nOWL and RuleML. 2004. Dispon\u00edvel em: \n<http://www.w3.org/Submission/SWRL/>. Acesso em: 17 Fev 2009. \n\nHUDELOT, C. Towards a Cognitive Vision Platform for Semantic Image In-\nterpretation; Application to the Recognition of Biological Organisms. 2005. \n275 p. Thesis (Phd in Computer Science) - Universit\u00e9 de Nice Sophia Antipolis. \n\nHUDELOT, C.; MAILLOT, N.; THONNAT, M. Symbol Grounding for Semantic \nImage Interpretation: From Image Data to Semantics.  In: Tenth IEEE Interna-\ntional Conference on Computer Vision, 2005.  Proceedings... , Los Alamitos, \nUSA: IEEE, 2005. p. 1875. \n\n\n\n94 \n\n \n\n \n\nJARKE, M. et al. KBMS requirements of knowledge-based systems. Founda-\ntions of knowledge base management, New York: Springer-Verlag, 1989. p. \n381-394. \n\nKNUBLAUCH, H. et al. The Prot\u00e9g\u00e9 OWL Plugin: An Open Development En-\nvironment for Semantic Web Applications. The Semantic Web \u2013 ISWC 2004, \n[S.l.]. 2004. p. 229-243. \n\nLINDHOLM, T.; YELLIN, F. Java Virtual Machine Specification. Addison-\nWesley Longman Publishing Co., Inc., 1999, \n\nMAILLOT, N. Ontology Based Object Learning and Recognition. 2005. 166 p. \nThesis (Phd in Computer Science) - \u00c9cole Doctorale STIC, Universit\u00e9 de Nice. \n\nMATHWORKS INC. Matlab 2008a. Natick, USA \n\nMATSUYAMA, T. Knowledge-Based Aerial Image Understanding Systems and \nExpert Systems for Image Processing. IEEE Transactions on Geoscience and \nRemote Sensing, New York. v. GE-25, n. 3, p. 305-316, 1987. \n\nMCGUINNESS, D. L.; HARMELEN, F. V. OWL Web Ontology: Language \nOverview. 2004. Dispon\u00edvel em:&lt;http://www.w3.org/TR/owl-features/>. \nAcesso em: 17 Fev 2009. \n\nNEUMANN, B.; MOLLER, R. On scene interpretation with description logics. \nImage and Vision Computing, [S.l.]. v. 26, n. 1, p. 82-101, 2008. \n\nO\u2019CONNOR, M. et al. Supporting Rule System Interoperability on the Semantic \nWeb with SWRL. The Semantic Web \u2013 ISWC 2005, [S.l.]. 2005. p. 974-986. \n\nOGIELA, M. R.; TADEUSIEWICZ, R. Artificial intelligence structural imaging \ntechniques in visual pattern analysis and medical data understanding. Pattern \nRecognition, Oxford. v. 36, n. 10, p. 2441-2452, 2003. \n\nOSSOLA, J.; BR\u00c9MOND, F.; THONNAT, M. A Communication Level in a Dis-\ntributed Architecture for Object Recognition.  In: 8th International Conference \non Systems Research Informatics and Cybernetics.  Proceedings... , [S.l.]. 1996. \n\nPARSIA, B.; SIRIN, E.; KALYANPUR, A. Debugging OWL ontologies.  In: 14th \nInternational Conference on World Wide Web.  Proceedings... , USA: ACM, \n2005. p. 633-640. \n\nRANDELL, D. A.; CUI, Z.; COHN, A. G. A Spatial Logic based on Regions and \nConnection.  In: 3rd Internation Conference on Knowledge Representation and \nReasoning.  Proceedings... , San Mateo 1992. p. 165\u2013176. \n\nRECTOR, A. Representing Specified Values in OWL: \"value partitions\" and \n\"value sets\". 2005. Dispon\u00edvel em:&lt;http://www.w3.org/TR/swbp-specified-\nvalues/>. Acesso em: 17 Fev 2009. \n\nSANDAKLY, F.; GIRAUDON, G. Scene analysis system.  In: IEEE International \nConference in Image Processing, 1994.  Proceedings... , [S.l.]. v. 3, 1994. p. 806-\n810 vol.3. \n\n\n\n95 \n\n \n\n \n\nSANTIN, C. E. Construtos ontol\u00f3gicos para representa\u00e7\u00e3o simb\u00f3lica de co-\nnhecimento visual. 2008. 103 p. Disserta\u00e7\u00e3o (Mestrado em Computa\u00e7\u00e3o) - Insti-\ntuto de Inform\u00e1tica, Universidade Federal do Rio Grande do Sul. \n\nSCHREIBER, G. et al. Knowledge Engineering and Management: The Com-\nmonKADS Methodology. Cambridge, USA: The MIT Press, 1999, \n\nSHANAHAN, M. Robotics and the Common Sense Informatics Situation.  In: \nSpring Symposium on Planning with Incomplete Information for Robot Prob-\nlems.  Proceedings... , Menlo Park, USA: AAAI, 1996. p. 95-106. \n\nSHANAHAN, M.; RANDELL, D. A Logic-Based Formulation of Active Visual \nPerception.  In: Principles of Knowledge Representation and Reasoning: Pro-\nceedings of the Ninth International Conference (KR2004).  Proceedings... , Men-\nlo Park, Calif. 2004. p. 64-72. \n\nSILVA, J. G. R. D. Estudo de cicloestratigrafia nos dep\u00f3sitos eopermianos do \nGrupo Itarar\u00e9, Bacia do Paran\u00e1, nos Estados de Santa Catarina e Rio Grande \ndo Sul, baseado em dados de testemunho e de perfis de raios gama. 2001. Dis-\nserta\u00e7\u00e3o (Mestrado em Geologia) - Instituto de Geoci\u00eancias, Universidade Fede-\nral do Rio Grande do Sul. \n\nSTUDER, R.; BENJAMINS, V. R.; FENSEL, D. Knowledge engineering: princi-\nples and methods. Data &amp; Knowledge Engineering, [S.l.]. v. 25, n. 1-2, p. 161-\n197, 1998. \n\nTSARKOV, D.; HORROCKS, I. FaCT++ Description Logic Reasoner: System \nDescription. Automated Reasoning, Berlin: Springer, 2006. p. 292-297. (Lecture \nNotes in Computer Science, 4130). \n\nVAN WAGONER, J. C. et al. Siliciclastic sequence stratigraphy in well logs, \ncores, and outcrops. Tulsa, US: AAPG, 1990, \n\nWITHAGEN, P. J. Object detection and segmentation for visual surveillance. \n2006. 173 p. Thesis (PhD in Computer Science) - University of Amsterdam. \n\nYIP, K.; ZHAO, F. Spatial Aggregation: Theory and Applications. Journal of Ar-\ntificial Intelligence Research, [S.l.]. v. 5, p. 1--26, 1996. \n\n \n\n\n\n \n\n \n\n \n\nANEXO  METAMODELO DA LINUGAGEM OWL \n\nOs algoritmos das m\u00e1quinas MIS e MIV descritos na se\u00e7\u00e3o 3.2.5 fazem refe-\nrencia a objetos do metamodelo de OWL a RDF. Embora este ele esteja impl\u00edcito \nna defini\u00e7\u00e3o da pr\u00f3pria linguagem, um metamodelo para OWL est\u00e1 sendo es-\ntandardizado pela OMG (Object Managemnt Group) em conjunto com outras \nlinguagens de representa\u00e7\u00e3o (COLOMB et al., 2006). A Figura A.1 apresenta os \nobjetos do metamodelo que permitem um melhor entendimento dos algoritmos \ndescritos. \n\n \nFigura A.1: Hierarquia de construtos de representa\u00e7\u00e3o de OWL. \n\nAs primitivas da linguagem SWRL n\u00e3o s\u00e3o contemplados pela OMG. No en-\ntanto, segundo a descri\u00e7\u00e3o da linguagem, o construto swrl:Imp que aparece \nnos algoritmos das m\u00e1quinas MIS e MIV descritas na se\u00e7\u00e3o 3.2.5 \u00e9 uma inst\u00e2n-\ncia de OWLClass. A sua fun\u00e7\u00e3o \u00e9 descrever um inst\u00e2ncias de uma regra SWRL \n\n \n\n\n\n \n\n \n\n \n\nAP\u00caNDICE  DESCRI\u00c7\u00c3O RDF/XML DOS MODELOS \nOWL DE CONHECIMENTO VISUAL DO SISTEMA \n\nINTELISTRATA \n\nNeste ap\u00eandice encontra-se os modelos OWL que s\u00e3o utilizados pelo sistema \nInteliStrata. A representa\u00e7\u00e3o utilizada \u00e9 a RDF/XML padr\u00e3o de OWL.  \n\nTodos os modelos apresentados, com exce\u00e7\u00e3o dos apresentados na se\u00e7\u00e3o B.5, \ns\u00e3o independentes de dom\u00ednio e podem ser aplicados diretamente em outros \nsistemas. \n\nB.1 Modelo do n\u00edvel anal\u00f3gico  \n\nB.1.1 Modelo OWL do n\u00edvel anal\u00f3gico \n<?xml version=\"1.0\"?> \n<rdf:RDF \n    xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" \n    xmlns:protege=\"http://protege.stanford.edu/plugins/owl/protege#\" \n    xmlns:xsp=\"http://www.owl-ontologies.com/2005/08/07/xsp.owl#\" \n    xmlns:owl=\"http://www.w3.org/2002/07/owl#\" \n    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\" \n    xmlns:swrl=\"http://www.w3.org/2003/11/swrl#\" \n    xmlns:swrlb=\"http://www.w3.org/2003/11/swrlb#\" \n    xmlns=\"http://www.owl-ontologies.com/AnalogLevelOntology.owl#\" \n    xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\" \n  xml:base=\"http://www.owl-ontologies.com/AnalogLevelOntology.owl\"> \n &lt;owl:Ontology rdf:about=\"\"/> \n &lt;owl:Class rdf:ID=\"PointSet\"> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:ID=\"AnalogEntity\"/> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"SignalRawDataContainer\"> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:ID=\"RawDataContainer\"/> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"IntervalSet\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#PointSet\"/> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"Interval\"> \n   &lt;rdfs:subClassOf> \n\n\n\n98 \n\n \n\n \n\n     &lt;owl:Restriction> \n       &lt;owl:onProperty> \n         &lt;owl:DatatypeProperty rdf:ID=\"hasArea\"/> \n       &lt;/owl:onProperty> \n       &lt;owl:maxCardinality rdf:datatype=\"http://www.w3.org/2001/XMLSchema#int\" \n        >1</owl:maxCardinality> \n     &lt;/owl:Restriction> \n   &lt;/rdfs:subClassOf> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Restriction> \n       &lt;owl:onProperty> \n         &lt;owl:DatatypeProperty rdf:ID=\"hasAbsoluteArea\"/> \n       &lt;/owl:onProperty> \n       &lt;owl:maxCardinality rdf:datatype=\"http://www.w3.org/2001/XMLSchema#int\" \n        >1</owl:maxCardinality> \n     &lt;/owl:Restriction> \n   &lt;/rdfs:subClassOf> \n   &lt;rdfs:subClassOf rdf:resource=\"#PointSet\"/> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Restriction> \n       &lt;owl:onProperty> \n         &lt;owl:DatatypeProperty rdf:ID=\"hasNoiseRate\"/> \n       &lt;/owl:onProperty> \n       &lt;owl:maxCardinality rdf:datatype=\"http://www.w3.org/2001/XMLSchema#int\" \n        >1</owl:maxCardinality> \n     &lt;/owl:Restriction> \n   &lt;/rdfs:subClassOf> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Restriction> \n       &lt;owl:onProperty> \n         &lt;owl:DatatypeProperty rdf:ID=\"hasLength\"/> \n       &lt;/owl:onProperty> \n       &lt;owl:maxCardinality rdf:datatype=\"http://www.w3.org/2001/XMLSchema#int\" \n        >1</owl:maxCardinality> \n     &lt;/owl:Restriction> \n   &lt;/rdfs:subClassOf> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Restriction> \n       &lt;owl:onProperty> \n         &lt;owl:DatatypeProperty rdf:ID=\"hasTendence\"/> \n       &lt;/owl:onProperty> \n       &lt;owl:maxCardinality rdf:datatype=\"http://www.w3.org/2001/XMLSchema#int\" \n        >1</owl:maxCardinality> \n     &lt;/owl:Restriction> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"FileSignalRawDataContainer\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#SignalRawDataContainer\"/> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"Point\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#AnalogEntity\"/> \n &lt;/owl:Class> \n &lt;owl:ObjectProperty rdf:ID=\"hasRawDataContainer\"> \n   &lt;rdfs:range rdf:resource=\"#SignalRawDataContainer\"/> \n   &lt;rdfs:domain rdf:resource=\"#AnalogEntity\"/> \n\n\n\n99 \n\n \n\n \n\n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"hasPoint\"> \n   &lt;rdfs:range rdf:resource=\"#Point\"/> \n   &lt;rdfs:domain rdf:resource=\"#PointSet\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"hasStartPoint\"> \n   &lt;rdfs:domain rdf:resource=\"#Interval\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasPoint\"/> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#FunctionalProperty\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"hasCenterPoint\"> \n   &lt;rdfs:domain rdf:resource=\"#Interval\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasPoint\"/> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#FunctionalProperty\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"hasMaximumPoint\"> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasPoint\"/> \n   &lt;rdfs:domain rdf:resource=\"#PointSet\"/> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#FunctionalProperty\"/> \n   &lt;rdfs:range rdf:resource=\"#Point\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"hasEndPoint\"> \n   &lt;rdfs:domain rdf:resource=\"#Interval\"/> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#FunctionalProperty\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasPoint\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"hasMinimumPoint\"> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#FunctionalProperty\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasPoint\"/> \n   &lt;rdfs:range rdf:resource=\"#Point\"/> \n   &lt;rdfs:domain rdf:resource=\"#PointSet\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:DatatypeProperty rdf:about=\"#hasAbsoluteArea\"> \n   &lt;rdfs:range rdf:resource=\"http://www.w3.org/2001/XMLSchema#float\"/> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:DatatypeProperty rdf:ID=\"hasAnalogicProperty\"/> \n   &lt;/rdfs:subPropertyOf> \n   &lt;rdfs:domain rdf:resource=\"#Interval\"/> \n &lt;/owl:DatatypeProperty> \n &lt;owl:DatatypeProperty rdf:ID=\"value\"> \n   &lt;rdfs:domain rdf:resource=\"#Point\"/> \n   &lt;rdfs:range rdf:resource=\"http://www.w3.org/2001/XMLSchema#float\"/> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#FunctionalProperty\"/> \n &lt;/owl:DatatypeProperty> \n &lt;owl:DatatypeProperty rdf:about=\"#hasLength\"> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:DatatypeProperty rdf:about=\"#hasAnalogicProperty\"/> \n   &lt;/rdfs:subPropertyOf> \n   &lt;rdfs:range rdf:resource=\"http://www.w3.org/2001/XMLSchema#float\"/> \n   &lt;rdfs:domain rdf:resource=\"#Interval\"/> \n &lt;/owl:DatatypeProperty> \n &lt;owl:DatatypeProperty rdf:about=\"#hasArea\"> \n   &lt;rdfs:domain rdf:resource=\"#Interval\"/> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:DatatypeProperty rdf:about=\"#hasAnalogicProperty\"/> \n\n\n\n100 \n\n \n\n \n\n   &lt;/rdfs:subPropertyOf> \n   &lt;rdfs:range rdf:resource=\"http://www.w3.org/2001/XMLSchema#float\"/> \n &lt;/owl:DatatypeProperty> \n &lt;owl:DatatypeProperty rdf:ID=\"index\"> \n   &lt;rdfs:range rdf:resource=\"http://www.w3.org/2001/XMLSchema#float\"/> \n   &lt;rdfs:domain rdf:resource=\"#Point\"/> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#FunctionalProperty\"/> \n &lt;/owl:DatatypeProperty> \n &lt;owl:DatatypeProperty rdf:about=\"#hasAnalogicProperty\"> \n   &lt;rdfs:domain rdf:resource=\"#AnalogEntity\"/> \n &lt;/owl:DatatypeProperty> \n &lt;owl:DatatypeProperty rdf:about=\"#hasNoiseRate\"> \n   &lt;rdfs:range rdf:resource=\"http://www.w3.org/2001/XMLSchema#float\"/> \n   &lt;rdfs:domain rdf:resource=\"#Interval\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasAnalogicProperty\"/> \n &lt;/owl:DatatypeProperty> \n &lt;owl:DatatypeProperty rdf:about=\"#hasTendence\"> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasAnalogicProperty\"/> \n   &lt;rdfs:range rdf:resource=\"http://www.w3.org/2001/XMLSchema#float\"/> \n   &lt;rdfs:domain rdf:resource=\"#Interval\"/> \n &lt;/owl:DatatypeProperty> \n &lt;owl:DatatypeProperty rdf:ID=\"hasLocationPath\"> \n   &lt;rdfs:range rdf:resource=\"http://www.w3.org/2001/XMLSchema#anyURI\"/> \n   &lt;rdfs:domain rdf:resource=\"#FileSignalRawDataContainer\"/> \n &lt;/owl:DatatypeProperty> \n</rdf:RDF> \n\nB.1.2 Modelo OWL para processamento de sinais \n<?xml version=\"1.0\"?> \n<rdf:RDF \n    xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" \n    xmlns:protege=\"http://protege.stanford.edu/plugins/owl/protege#\" \n    xmlns:xsp=\"http://www.owl-ontologies.com/2005/08/07/xsp.owl#\" \n    xmlns=\"http://www.owl-ontologies.com/SignalProcessingOntology.owl#\" \n    xmlns:owl=\"http://www.w3.org/2002/07/owl#\" \n    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\" \n    xmlns:swrl=\"http://www.w3.org/2003/11/swrl#\" \n    xmlns:swrlb=\"http://www.w3.org/2003/11/swrlb#\" \n    xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\" \n    xmlns:alo=\"http://www.owl-ontologies.com/AnalogLevelOntology.owl#\" \n  xml:base=\"http://www.owl-ontologies.com/SignalProcessingOntology.owl\"> \n &lt;owl:Ontology rdf:about=\"\"> \n   &lt;owl:imports  \n\nrdf:resource=\"http://www.owl-ontologies.com/AnalogLevelOntology.owl\"/> \n &lt;/owl:Ontology> \n &lt;owl:Class rdf:ID=\"PropertyExtractor\"> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:ID=\"SignalProcessingFunctionality\"/> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"SizePropertyExtractor\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#PropertyExtractor\"/> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"Segmentator\"> \n\n\n\n101 \n\n \n\n \n\n   &lt;rdfs:subClassOf rdf:resource=\"#SignalProcessingFunctionality\"/> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"FourierSegmentator\"> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:ID=\"BasicSegmentator\"/> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:about=\"#BasicSegmentator\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#Segmentator\"/> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"WaveletSegmentator\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#BasicSegmentator\"/> \n &lt;/owl:Class> \n &lt;owl:ObjectProperty rdf:ID=\"isExtractedWith\"> \n   &lt;rdfs:range rdf:resource=\"#SignalProcessingFunctionality\"/> \n   &lt;rdfs:domain  \n\nrdf:resource=\"http://www.owl-ontologies.com/ \nAnalogLevelOntology.owl#AnalogEntity\"/> \n\n &lt;/owl:ObjectProperty> \n &lt;owl:DatatypeProperty rdf:ID=\"hasExtractionStrength\"> \n   &lt;rdfs:range rdf:resource=\"http://www.w3.org/2001/XMLSchema#float\"/> \n   &lt;rdfs:subPropertyOf \n\n rdf:resource=\"http://www.owl-ontologies.com/ \nAnalogLevelOntology.owl#hasAnalogicProperty\"/> \n\n &lt;/owl:DatatypeProperty> \n &lt;WaveletSegmentator rdf:ID=\"SmoothToothCurveSPF\"/> \n &lt;WaveletSegmentator rdf:ID=\"Symlet8SPF\"/> \n &lt;WaveletSegmentator rdf:ID=\"Gaussian2SPF\"/> \n</rdf:RDF> \n\nB.2 Modelo do n\u00edvel visual \nO modelo no n\u00edvel visual consiste em somente um modelo OWL. \n<?xml version=\"1.0\"?> \n<rdf:RDF \n    xmlns:ineq=\"http://www.owl-ontologies.com/InequalityOntology.owl#\" \n    xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" \n    xmlns:protege=\"http://protege.stanford.edu/plugins/owl/protege#\" \n    xmlns:xsp=\"http://www.owl-ontologies.com/2005/08/07/xsp.owl#\" \n    xmlns:owl=\"http://www.w3.org/2002/07/owl#\" \n    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\" \n    xmlns:swrl=\"http://www.w3.org/2003/11/swrl#\" \n    xmlns:swrlb=\"http://www.w3.org/2003/11/swrlb#\" \n    xmlns=\"http://www.owl-ontologies.com/VisualLevel.owl#\" \n    xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\" \n  xml:base=\"http://www.owl-ontologies.com/VisualLevel.owl\"> \n &lt;owl:Ontology rdf:about=\"\"> \n   &lt;owl:imports \n\n rdf:resource=\"http://www.owl-ontologies.com/InequalityOntology.owl\"/> \n &lt;/owl:Ontology> \n &lt;owl:Class rdf:ID=\"VerticalLine\"> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:ID=\"Line\"/> \n   &lt;/rdfs:subClassOf> \n\n\n\n102 \n\n \n\n \n\n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"GenericCharacteristicValue\"> \n   &lt;owl:equivalentClass> \n     &lt;owl:Class> \n       &lt;owl:oneOf rdf:parseType=\"Collection\"> \n         &lt;GenericCharacteristicValue rdf:ID=\"VeryStrongPattern\"> \n           &lt;ineq:greaterThan> \n             &lt;GenericCharacteristicValue rdf:ID=\"StrongPattern\"> \n               &lt;ineq:smallerThan rdf:resource=\"#VeryStrongPattern\"/> \n               &lt;ineq:greaterThan> \n                 &lt;GenericCharacteristicValue rdf:ID=\"MediumPattern\"> \n                   &lt;ineq:greaterThan> \n                     &lt;GenericCharacteristicValue rdf:ID=\"WeakPattern\"> \n                       &lt;ineq:smallerThan rdf:resource=\"#MediumPattern\"/> \n                       &lt;ineq:greaterThan> \n                         &lt;GenericCharacteristicValue rdf:ID=\"VeryWeakPattern\"> \n                           &lt;ineq:smallerThan rdf:resource=\"#WeakPattern\"/> \n                         &lt;/GenericCharacteristicValue> \n                       &lt;/ineq:greaterThan> \n                     &lt;/GenericCharacteristicValue> \n                   &lt;/ineq:greaterThan> \n                   &lt;ineq:smallerThan rdf:resource=\"#StrongPattern\"/> \n                 &lt;/GenericCharacteristicValue> \n               &lt;/ineq:greaterThan> \n             &lt;/GenericCharacteristicValue> \n           &lt;/ineq:greaterThan> \n         &lt;/GenericCharacteristicValue> \n         &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n         &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n         &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n         &lt;GenericCharacteristicValue rdf:about=\"#VeryWeakPattern\"/> \n       &lt;/owl:oneOf> \n     &lt;/owl:Class> \n   &lt;/owl:equivalentClass> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:ID=\"CharacteristicValue\"/> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:about=\"#CharacteristicValue\"> \n   &lt;rdfs:subClassOf> \n\n\n\n103 \n\n \n\n \n\n     &lt;owl:Class rdf:ID=\"VisualPropertyValue\"/> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryWeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"GeometricEntity\"> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:ID=\"VisualEntity\"/> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"Point\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#GeometricEntity\"/> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n\n\n\n104 \n\n \n\n \n\n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryWeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:about=\"#Line\"> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:ID=\"OpenCurve\"/> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"InclinedLine\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#Line\"/> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"SmoothToothCurve\"> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:about=\"#OpenCurve\"/> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"LengthValue\"> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:about=\"#VisualPropertyValue\"/> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryWeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"SinusoidCurve\"> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:about=\"#OpenCurve\"/> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"GenericLengthValue\"> \n   &lt;owl:equivalentClass> \n\n\n\n105 \n\n \n\n \n\n     &lt;owl:Class> \n       &lt;owl:oneOf rdf:parseType=\"Collection\"> \n         &lt;GenericLengthValue rdf:ID=\"ShortLength\"> \n           &lt;ineq:greaterThan> \n             &lt;GenericLengthValue rdf:ID=\"VeryShortLength\"> \n               &lt;ineq:smallerThan rdf:resource=\"#ShortLength\"/> \n             &lt;/GenericLengthValue> \n           &lt;/ineq:greaterThan> \n           &lt;ineq:smallerThan> \n             &lt;GenericLengthValue rdf:ID=\"MediumLength\"> \n               &lt;ineq:greaterThan rdf:resource=\"#ShortLength\"/> \n               &lt;ineq:smallerThan> \n                 &lt;GenericLengthValue rdf:ID=\"LongLength\"> \n                   &lt;ineq:smallerThan> \n                     &lt;GenericLengthValue rdf:ID=\"VeryLongLength\"> \n                       &lt;ineq:greaterThan rdf:resource=\"#LongLength\"/> \n                     &lt;/GenericLengthValue> \n                   &lt;/ineq:smallerThan> \n                   &lt;ineq:greaterThan rdf:resource=\"#MediumLength\"/> \n                 &lt;/GenericLengthValue> \n               &lt;/ineq:smallerThan> \n             &lt;/GenericLengthValue> \n           &lt;/ineq:smallerThan> \n         &lt;/GenericLengthValue> \n         &lt;GenericLengthValue rdf:about=\"#VeryLongLength\"/> \n         &lt;GenericLengthValue rdf:about=\"#LongLength\"/> \n         &lt;GenericLengthValue rdf:about=\"#MediumLength\"/> \n         &lt;GenericLengthValue rdf:about=\"#VeryShortLength\"/> \n       &lt;/owl:oneOf> \n     &lt;/owl:Class> \n   &lt;/owl:equivalentClass> \n   &lt;rdfs:subClassOf rdf:resource=\"#LengthValue\"/> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryWeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n\n\n\n106 \n\n \n\n \n\n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"MinimumPoint\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#Point\"/> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"PointSet\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#GeometricEntity\"/> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"MaximumPoint\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#Point\"/> \n &lt;/owl:Class> \n &lt;owl:Class rdf:about=\"#VisualPropertyValue\"> \n   &lt;owl:equivalentClass> \n     &lt;owl:Class> \n       &lt;owl:unionOf rdf:parseType=\"Collection\"> \n         &lt;owl:Class rdf:about=\"#LengthValue\"/> \n         &lt;owl:Class rdf:about=\"#CharacteristicValue\"/> \n       &lt;/owl:unionOf> \n     &lt;/owl:Class> \n   &lt;/owl:equivalentClass> \n &lt;/owl:Class> \n &lt;owl:Class rdf:about=\"#OpenCurve\"> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:ID=\"Curve\"/> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n\n\n\n107 \n\n \n\n \n\n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"SigmoidCurve\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#OpenCurve\"/> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryWeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"GaussianCurve\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#OpenCurve\"/> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:oneOf rdf:parseType=\"Collection\"> \n     &lt;GenericCharacteristicValue rdf:about=\"#VeryStrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#StrongPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#MediumPattern\"/> \n     &lt;GenericCharacteristicValue rdf:about=\"#WeakPattern\"/> \n   &lt;/owl:oneOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:about=\"#Curve\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#PointSet\"/> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"TriangularCurve\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#OpenCurve\"/> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"HorizontalLine\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#Line\"/> \n &lt;/owl:Class> \n &lt;owl:ObjectProperty rdf:ID=\"isOver\"> \n   &lt;owl:inverseOf> \n     &lt;owl:ObjectProperty rdf:ID=\"isUnder\"/> \n   &lt;/owl:inverseOf> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:ObjectProperty rdf:ID=\"hasOrientationPositionTo\"/> \n   &lt;/rdfs:subPropertyOf> \n &lt;/owl:ObjectProperty> \n\n\n\n108 \n\n \n\n \n\n &lt;owl:ObjectProperty rdf:ID=\"isAtRightOf\"> \n   &lt;owl:inverseOf> \n     &lt;owl:ObjectProperty rdf:ID=\"isAtLeftOf\"/> \n   &lt;/owl:inverseOf> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:ObjectProperty rdf:about=\"#hasOrientationPositionTo\"/> \n   &lt;/rdfs:subPropertyOf> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"isDiscreteOf\"> \n   &lt;rdfs:domain rdf:resource=\"#VisualEntity\"/> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:ObjectProperty rdf:ID=\"hasTopologicalRelationWith\"/> \n   &lt;/rdfs:subPropertyOf> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"hasSpatialRelationWith\"> \n   &lt;rdfs:range rdf:resource=\"#VisualEntity\"/> \n   &lt;rdfs:domain rdf:resource=\"#VisualEntity\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"hasSmoothness\"> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:ObjectProperty rdf:ID=\"hasVisualProperty\"/> \n   &lt;/rdfs:subPropertyOf> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"hasConvexity\"> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:ObjectProperty rdf:about=\"#hasVisualProperty\"/> \n   &lt;/rdfs:subPropertyOf> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:about=\"#hasOrientationPositionTo\"> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasSpatialRelationWith\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:about=\"#isAtLeftOf\"> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasOrientationPositionTo\"/> \n   &lt;owl:inverseOf rdf:resource=\"#isAtRightOf\"/> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#TransitiveProperty\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:about=\"#hasTopologicalRelationWith\"> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasSpatialRelationWith\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"hasForNonTangentialProperPartOf\"> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:ObjectProperty rdf:ID=\"hasForProperPart\"/> \n   &lt;/rdfs:subPropertyOf> \n   &lt;owl:inverseOf> \n     &lt;owl:ObjectProperty rdf:ID=\"isNonTangentialProperPartOf\"/> \n   &lt;/owl:inverseOf> \n   &lt;rdfs:domain rdf:resource=\"#VisualEntity\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:about=\"#hasForProperPart\"> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasTopologicalRelationWith\"/> \n   &lt;owl:inverseOf> \n     &lt;owl:ObjectProperty rdf:ID=\"isProperPartOf\"/> \n   &lt;/owl:inverseOf> \n   &lt;rdfs:domain rdf:resource=\"#VisualEntity\"/> \n &lt;/owl:ObjectProperty> \n\n\n\n109 \n\n \n\n \n\n &lt;owl:ObjectProperty rdf:about=\"#isUnder\"> \n   &lt;owl:inverseOf rdf:resource=\"#isOver\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasOrientationPositionTo\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"hasCurvature\"> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:ObjectProperty rdf:about=\"#hasVisualProperty\"/> \n   &lt;/rdfs:subPropertyOf> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"hasHeight\"> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:ObjectProperty rdf:about=\"#hasVisualProperty\"/> \n   &lt;/rdfs:subPropertyOf> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"hasLength\"> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:ObjectProperty rdf:about=\"#hasVisualProperty\"/> \n   &lt;/rdfs:subPropertyOf> \n   &lt;rdfs:range rdf:resource=\"#LengthValue\"/> \n   &lt;rdfs:domain rdf:resource=\"#Curve\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"isTopologicallyEqualsTo\"> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasTopologicalRelationWith\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"partialOverlaps\"> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasTopologicalRelationWith\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:about=\"#isNonTangentialProperPartOf\"> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:ObjectProperty rdf:about=\"#isProperPartOf\"/> \n   &lt;/rdfs:subPropertyOf> \n   &lt;owl:inverseOf rdf:resource=\"#hasForNonTangentialProperPartOf\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:about=\"#isProperPartOf\"> \n   &lt;owl:inverseOf rdf:resource=\"#hasForProperPart\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasTopologicalRelationWith\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"isExternallyConnectedTo\"> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#isDiscreteOf\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:about=\"#hasVisualProperty\"> \n   &lt;rdfs:range rdf:resource=\"#VisualPropertyValue\"/> \n   &lt;rdfs:domain rdf:resource=\"#VisualEntity\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"isTangentialProperPartOf\"> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#isProperPartOf\"/> \n   &lt;owl:inverseOf> \n     &lt;owl:ObjectProperty rdf:ID=\"hasForTangentialProperPart\"/> \n   &lt;/owl:inverseOf> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"idDisconnectedOf\"> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#isDiscreteOf\"/> \n   &lt;rdfs:domain rdf:resource=\"#VisualEntity\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:about=\"#hasForTangentialProperPart\"> \n\n\n\n110 \n\n \n\n \n\n   &lt;rdfs:domain rdf:resource=\"#VisualEntity\"/> \n   &lt;owl:inverseOf rdf:resource=\"#isTangentialProperPartOf\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasForProperPart\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:FunctionalProperty rdf:ID=\"hasCharacteristic\"> \n   &lt;rdfs:range rdf:resource=\"#GenericCharacteristicValue\"/> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#ObjectProperty\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasVisualProperty\"/> \n   &lt;rdfs:domain rdf:resource=\"#GeometricEntity\"/> \n &lt;/owl:FunctionalProperty> \n &lt;owl:FunctionalProperty rdf:ID=\"hasGaussianCurveCharacteristic\"> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasCharacteristic\"/> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#ObjectProperty\"/> \n   &lt;rdfs:domain rdf:resource=\"#GaussianCurve\"/> \n &lt;/owl:FunctionalProperty> \n &lt;owl:FunctionalProperty rdf:ID=\"hasSmoothToothCurveCharacteristic\"> \n   &lt;rdfs:domain rdf:resource=\"#SmoothToothCurve\"/> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#ObjectProperty\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#hasCharacteristic\"/> \n &lt;/owl:FunctionalProperty> \n &lt;owl:AllDifferent/> \n</rdf:RDF> \n\nB.3 Modelo do n\u00edvel sem\u00e2ntico \nO modelo n\u00edvel sem\u00e2ntico consiste em dois modelos OWL. \n\nB.3.1 Modelo OWL do n\u00edvel sem\u00e2ntico \n<?xml version=\"1.0\"?> \n<rdf:RDF \n    xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" \n    xmlns:protege=\"http://protege.stanford.edu/plugins/owl/protege#\" \n    xmlns:xsp=\"http://www.owl-ontologies.com/2005/08/07/xsp.owl#\" \n    xmlns:owl=\"http://www.w3.org/2002/07/owl#\" \n    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\" \n    xmlns:swrl=\"http://www.w3.org/2003/11/swrl#\" \n    xmlns:swrlb=\"http://www.w3.org/2003/11/swrlb#\" \n    xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\" \n    xmlns=\"http://www.owl-ontologies.com/SemanticLevelOntology.owl#\" \n  xml:base=\"http://www.owl-ontologies.com/SemanticLevelOntology.owl\"> \n &lt;owl:Ontology rdf:about=\"\"/> \n &lt;owl:Class rdf:ID=\"SemanticEntity\"/> \n</rdf:RDF> \n\nB.3.2 Modelo OWL do dom\u00ednio \n<?xml version=\"1.0\"?> \n<rdf:RDF \n    xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" \n    xmlns:protege=\"http://protege.stanford.edu/plugins/owl/protege#\" \n    xmlns:xsp=\"http://www.owl-ontologies.com/2005/08/07/xsp.owl#\" \n    xmlns:part \n\n=\"http://www.w3.org/2001/sw/BestPractices/OEP/SimplePartWhole/part.owl#\" \n    xmlns:owl=\"http://www.w3.org/2002/07/owl#\" \n\n\n\n111 \n\n \n\n \n\n    xmlns=\"http://www.owl-ontologies.com/StratigraphyOntology.owl#\" \n    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\" \n    xmlns:swrl=\"http://www.w3.org/2003/11/swrl#\" \n    xmlns:swrlb=\"http://www.w3.org/2003/11/swrlb#\" \n    xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\" \n  xml:base=\"http://www.owl-ontologies.com/StratigraphyOntology.owl\"> \n &lt;owl:Ontology rdf:about=\"\"> \n   &lt;owl:imports \nrdf:resource=\"http://www.w3.org/2001/sw/BestPractices/OEP/SimplePartWhole/part.o\nwl\"/> \n &lt;/owl:Ontology> \n &lt;owl:Class rdf:ID=\"FloodingSurface\"> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:ID=\"StratigraphicSurface\"/> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:unionOf rdf:parseType=\"Collection\"> \n     &lt;owl:Class rdf:ID=\"Parassequence\"/> \n     &lt;owl:Class rdf:about=\"#FloodingSurface\"/> \n     &lt;owl:Class rdf:ID=\"SequenceBoundary\"/> \n   &lt;/owl:unionOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"MaximumFloodingSurface\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#FloodingSurface\"/> \n &lt;/owl:Class> \n &lt;owl:Class rdf:about=\"#Parassequence\"> \n   &lt;owl:disjointWith> \n     &lt;owl:Class rdf:ID=\"Sequence\"/> \n   &lt;/owl:disjointWith> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:ID=\"StratigraphicUnit\"/> \n   &lt;/rdfs:subClassOf> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Restriction> \n       &lt;owl:onProperty \nrdf:resource=\"http://www.w3.org/2001/sw/BestPractices/OEP/SimplePartWhole/part.o\nwl#hasPart\"/> \n       &lt;owl:allValuesFrom rdf:resource=\"#FloodingSurface\"/> \n     &lt;/owl:Restriction> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:ID=\"StratigraphicEntity\"/> \n &lt;owl:Class rdf:about=\"#SequenceBoundary\"> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:about=\"#StratigraphicSurface\"/> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:unionOf rdf:parseType=\"Collection\"> \n     &lt;owl:Class rdf:about=\"#Parassequence\"/> \n     &lt;owl:Class rdf:about=\"#MaximumFloodingSurface\"/> \n   &lt;/owl:unionOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:about=\"#Sequence\"> \n\n\n\n112 \n\n \n\n \n\n   &lt;owl:disjointWith rdf:resource=\"#Parassequence\"/> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Class rdf:about=\"#StratigraphicUnit\"/> \n   &lt;/rdfs:subClassOf> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Restriction> \n       &lt;owl:allValuesFrom> \n         &lt;owl:Class> \n           &lt;owl:unionOf rdf:parseType=\"Collection\"> \n             &lt;owl:Class rdf:ID=\"SystemTract\"/> \n             &lt;owl:Class rdf:about=\"#MaximumFloodingSurface\"/> \n             &lt;owl:Class rdf:about=\"#SequenceBoundary\"/> \n           &lt;/owl:unionOf> \n         &lt;/owl:Class> \n       &lt;/owl:allValuesFrom> \n       &lt;owl:onProperty \nrdf:resource=\"http://www.w3.org/2001/sw/BestPractices/OEP/SimplePartWhole/part.o\nwl#hasPart\"/> \n     &lt;/owl:Restriction> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:about=\"#StratigraphicSurface\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#StratigraphicEntity\"/> \n   &lt;owl:disjointWith> \n     &lt;owl:Class rdf:about=\"#StratigraphicUnit\"/> \n   &lt;/owl:disjointWith> \n &lt;/owl:Class> \n &lt;owl:Class rdf:about=\"#StratigraphicUnit\"> \n   &lt;rdfs:subClassOf> \n     &lt;owl:Restriction> \n       &lt;owl:allValuesFrom> \n         &lt;owl:Class> \n           &lt;owl:unionOf rdf:parseType=\"Collection\"> \n             &lt;owl:Class rdf:about=\"#StratigraphicSurface\"/> \n             &lt;owl:Class rdf:about=\"#StratigraphicUnit\"/> \n           &lt;/owl:unionOf> \n         &lt;/owl:Class> \n       &lt;/owl:allValuesFrom> \n       &lt;owl:onProperty \nrdf:resource=\"http://www.w3.org/2001/sw/BestPractices/OEP/SimplePartWhole/part.o\nwl#hasPart\"/> \n     &lt;/owl:Restriction> \n   &lt;/rdfs:subClassOf> \n   &lt;rdfs:subClassOf rdf:resource=\"#StratigraphicEntity\"/> \n   &lt;owl:disjointWith rdf:resource=\"#StratigraphicSurface\"/> \n &lt;/owl:Class> \n &lt;owl:Class> \n   &lt;owl:unionOf rdf:parseType=\"Collection\"> \n     &lt;owl:Class rdf:about=\"#Parassequence\"/> \n     &lt;owl:Class rdf:about=\"#MaximumFloodingSurface\"/> \n     &lt;owl:Class rdf:about=\"#SequenceBoundary\"/> \n   &lt;/owl:unionOf> \n &lt;/owl:Class> \n &lt;owl:Class rdf:about=\"#SystemTract\"> \n   &lt;rdfs:subClassOf rdf:resource=\"#StratigraphicUnit\"/> \n\n\n\n113 \n\n \n\n \n\n   &lt;rdfs:subClassOf> \n     &lt;owl:Restriction> \n       &lt;owl:onProperty \nrdf:resource=\"http://www.w3.org/2001/sw/BestPractices/OEP/SimplePartWhole/part.o\nwl#hasPart\"/> \n       &lt;owl:allValuesFrom rdf:resource=\"#Parassequence\"/> \n     &lt;/owl:Restriction> \n   &lt;/rdfs:subClassOf> \n &lt;/owl:Class> \n</rdf:RDF> \n\nB.4 Modelo de ancoramento simb\u00f3lico \nO modelo de ancoramento simb\u00f3lico consiste em um modelo OWL. \n<?xml version=\"1.0\"?> \n<rdf:RDF \n    xmlns:protege=\"http://protege.stanford.edu/plugins/owl/protege#\" \n    xmlns:xsp=\"http://www.owl-ontologies.com/2005/08/07/xsp.owl#\" \n    xmlns:swrlx=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/swrlx.owl#\" \n    xmlns:spo=\"http://www.owl-ontologies.com/SignalProcessingOntology.owl#\" \n    xmlns:swrlm=\"http://swrl.stanford.edu/ontologies/built-ins/3.4/swrlm.owl#\" \n    xmlns:swrlb=\"http://www.w3.org/2003/11/swrlb#\" \n    xmlns:vlo=\"http://www.owl-ontologies.com/VisualLevel.owl#\" \n    xmlns:temporal=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/temporal.owl#\" \n    xmlns:tbox=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/tbox.owl#\" \n    xmlns:slo=\"http://www.owl-ontologies.com/SemanticLevelOntology.owl#\" \n    xmlns:fuzzy=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/fuzzy.owl#\" \n    xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" \n    xmlns=\"http://www.owl-ontologies.com/MappingOntology.owl#\" \n    xmlns:owl=\"http://www.w3.org/2002/07/owl#\" \n    xmlns:sqwrl=\"http://sqwrl.stanford.edu/ontologies/built-ins/3.4/sqwrl.owl#\" \n    xmlns:abox=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/abox.owl#\" \n    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\" \n    xmlns:swrl=\"http://www.w3.org/2003/11/swrl#\" \n    xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\" \n    xmlns:swrla=\"http://swrl.stanford.edu/ontologies/3.3/swrla.owl#\" \n  xml:base=\"http://www.owl-ontologies.com/MappingOntology.owl\"> \n &lt;owl:Ontology rdf:about=\"\"> \n   &lt;owl:imports \n\n rdf:resource=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/fuzzy.owl\"/> \n   &lt;owl:imports \n\n rdf:resource=\"http://www.owl-ontologies.com/SemanticLevelOntology.owl\"/> \n   &lt;owl:imports \n\n rdf:resource=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/swrlx.owl\"/> \n   &lt;owl:imports \n\n rdf:resource=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/temporal.owl\"/> \n   &lt;owl:imports \n\n rdf:resource=\"http://swrl.stanford.edu/ontologies/built-ins/3.4/swrlm.owl\"/> \n   &lt;owl:imports rdf:resource=\"http://swrl.stanford.edu/ontologies/3.3/swrla.owl\"/> \n   &lt;owl:imports \n\n rdf:resource=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/abox.owl\"/> \n   &lt;owl:imports \n\n rdf:resource=\"http://sqwrl.stanford.edu/ontologies/built-ins/3.4/sqwrl.owl\"/> \n   &lt;owl:imports  \n\n\n\n114 \n\n \n\n \n\nrdf:resource=\"http://www.owl-ontologies.com/VisualLevel.owl\"/> \n   &lt;owl:imports \n\n rdf:resource=\"http://www.owl-ontologies.com/SignalProcessingOntology.owl\"/> \n   &lt;owl:imports \n\n rdf:resource=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/tbox.owl\"/> \n &lt;/owl:Ontology> \n &lt;rdfs:Class \nrdf:about=\"http://swrl.stanford.edu/ontologies/3.3/swrla.owl#RuleGroup\"/> \n &lt;owl:ObjectProperty rdf:ID=\"groundedByDG\"> \n   &lt;rdfs:range \nrdf:resource=\"http://swrl.stanford.edu/ontologies/3.3/swrla.owl#RuleGroup\"/> \n   &lt;owl:inverseOf> \n     &lt;owl:ObjectProperty rdf:ID=\"groundingPrimitive\"/> \n   &lt;/owl:inverseOf> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"upwardMapLink\"> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:ObjectProperty rdf:ID=\"mappingLink\"/> \n   &lt;/rdfs:subPropertyOf> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"downwardMapLink\"> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#mappingLink\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"mappingAnalogicToVisual\"> \n   &lt;owl:inverseOf> \n     &lt;owl:ObjectProperty rdf:ID=\"mappingVisualToAnalogic\"/> \n   &lt;/owl:inverseOf> \n   &lt;rdfs:range \n\n rdf:resource=\"http://www.owl-ontologies.com/VisualLevel.owl#VisualEntity\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#upwardMapLink\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:about=\"#mappingVisualToAnalogic\"> \n   &lt;owl:inverseOf rdf:resource=\"#mappingAnalogicToVisual\"/> \n   &lt;rdfs:domain \n\n rdf:resource=\"http://www.owl-ontologies.com/VisualLevel.owl#VisualEntity\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#downwardMapLink\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:ID=\"mappingSemanticToVisual\"> \n   &lt;rdfs:range \n\n rdf:resource=\"http://www.owl-ontologies.com/VisualLevel.owl#VisualEntity\"/> \n   &lt;owl:inverseOf> \n     &lt;owl:ObjectProperty rdf:ID=\"mappingVisualToSemantic\"/> \n   &lt;/owl:inverseOf> \n   &lt;rdfs:domain rdf:resource \n\n=\"http://www.owl-ontologies.com/SemanticLevelOntology.owl#SemanticEntity\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#downwardMapLink\"/> \n &lt;/owl:ObjectProperty> \n &lt;owl:ObjectProperty rdf:about=\"#mappingVisualToSemantic\"> \n   &lt;rdfs:range rdf:resource \n\n=\"http://www.owl-ontologies.com/SemanticLevelOntology.owl#SemanticEntity\"/> \n   &lt;owl:inverseOf rdf:resource=\"#mappingSemanticToVisual\"/> \n   &lt;rdfs:domain rdf:resource \n\n=\"http://www.owl-ontologies.com/VisualLevel.owl#VisualEntity\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#upwardMapLink\"/> \n &lt;/owl:ObjectProperty> \n\n\n\n115 \n\n \n\n \n\n &lt;owl:ObjectProperty rdf:about=\"#groundingPrimitive\"> \n   &lt;rdfs:domain  \n rdf:resource=\"http://swrl.stanford.edu/ontologies/3.3/swrla.owl#RuleGroup\"/> \n   &lt;owl:inverseOf rdf:resource=\"#groundedByDG\"/> \n &lt;/owl:ObjectProperty> \n</rdf:RDF> \n\nB.5 Modelos Adicionais \nOs modelos adicionais constituem a ontologia de sistema e outra ontologia \n\nde rela\u00e7\u00f5es de ordem.  \n\nB.5.1 Modelo OWL do sistema InteliStrata \n<?xml version=\"1.0\"?> \n<rdf:RDF xmlns=\"http://www.owl-ontologies.com/InteliSrata.owl#\" \n     xml:base=\"http://www.owl-ontologies.com/InteliSrata.owl\" \n     xmlns:slo=\"http://www.owl-ontologies.com/SemanticLevelOntology.owl#\" \n     xmlns:dom=\"http://www.owl-ontologies.com/StratigraphyOntology.owl#\" \n     xmlns:spo=\"http://www.owl-ontologies.com/SignalProcessingOntology.owl#\" \n     xmlns:abox=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/abox.owl#\" \n     xmlns:sqwrl=\"http://sqwrl.stanford.edu/ontologies/built-ins/3.4/sqwrl.owl#\" \n     xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\" \n     xmlns:swrl=\"http://www.w3.org/2003/11/swrl#\" \n     xmlns:fuzzy=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/fuzzy.owl#\" \n     xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" \n     xmlns:alo=\"http://www.owl-ontologies.com/AnalogLevelOntology.owl#\" \n     xmlns:protege=\"http://protege.stanford.edu/plugins/owl/protege#\" \n     xmlns:xsp=\"http://www.owl-ontologies.com/2005/08/07/xsp.owl#\" \n     xmlns:swrlx=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/swrlx.owl#\" \n     xmlns:mapo=\"http://www.owl-ontologies.com/MappingOntology.owl#\" \n     xmlns:vlo=\"http://www.owl-ontologies.com/VisualLevel.owl#\" \n     xmlns:ineq=\"http://www.owl-ontologies.com/InequalityOntology.owl#\" \n     xmlns:swrlm=\"http://swrl.stanford.edu/ontologies/built-ins/3.4/swrlm.owl#\" \n     xmlns:temporal=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/temporal.owl#\" \n     xmlns:swrli=\"http://swrl.stanford.edu/ontologies/built-ins/3.4/swrli.owl#\" \n     xmlns:swrlb=\"http://www.w3.org/2003/11/swrlb#\" \n     xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\" \n     xmlns:owl=\"http://www.w3.org/2002/07/owl#\" \n     xmlns:tbox=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/tbox.owl#\" \n     xmlns:part= \n\n\"http://www.w3.org/2001/sw/BestPractices/OEP/SimplePartWhole/part.owl#\" \n     xmlns:swrlineq=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/swrli.owl#\" \n     xmlns:swrla=\"http://swrl.stanford.edu/ontologies/3.3/swrla.owl#\"> \n   &lt;owl:Ontology rdf:about=\"\"> \n       &lt;owl:imports \n\n rdf:resource=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/abox.owl\"/> \n       &lt;owl:imports \n\n rdf:resource=\"http://sqwrl.stanford.edu/ontologies/built-ins/3.4/sqwrl.owl\"/> \n       &lt;owl:imports  \n\nrdf:resource=\"http://swrl.stanford.edu/ontologies/3.3/swrla.owl\"/> \n       &lt;owl:imports \n\n rdf:resource=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/temporal.owl\"/> \n       &lt;owl:imports \n\n\n\n116 \n\n \n\n \n\n rdf:resource=\"http://www.owl-ontologies.com/StratigraphyOntology.owl\"/> \n       &lt;owl:imports \n\n rdf:resource=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/swrli.owl\"/> \n       &lt;owl:imports \n\n rdf:resource=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/swrlx.owl\"/> \n       &lt;owl:imports  \n  rdf:resource=\"http://www.owl-ontologies.com/MappingOntology.owl\"/> \n       &lt;owl:imports \n\n rdf:resource=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/tbox.owl\"/> \n       &lt;owl:imports \n\n rdf:resource=\"http://swrl.stanford.edu/ontologies/built-ins/3.3/fuzzy.owl\"/> \n   &lt;/owl:Ontology> \n       &lt;rdf:Description rdf:about=\"&amp;dom;MaximumFloodingSurface\"> \n       &lt;mapo:groundedByDG rdf:resource=\"#sdgMaximumFloodingSurface\"/> \n   &lt;/rdf:Description> \n   &lt;rdf:Description rdf:about=\"&amp;dom;Parassequence\"> \n       &lt;mapo:groundedByDG rdf:resource=\"#sdgParassequence\"/> \n   &lt;/rdf:Description> \n   &lt;rdf:Description rdf:about=\"&amp;dom;Sequence\"> \n       &lt;mapo:groundedByDG rdf:resource=\"#sdgDomSequence\"/> \n   &lt;/rdf:Description> \n   &lt;ParassequenceLengthValue rdf:ID=\"LongLengthParassequence\"> \n       &lt;ineq:greaterThan rdf:resource=\"#MediumLengthParassequence\"/> \n   &lt;/ParassequenceLengthValue> \n   &lt;SequenceLengthValue rdf:ID=\"LongLengthSequence\"> \n       &lt;ineq:smallerThan rdf:resource=\"#VeryLongLengthSequence\"/> \n       &lt;ineq:greaterThan rdf:resource=\"#MediumLengthSequence\"/> \n   &lt;/SequenceLengthValue> \n   &lt;ParassequenceLengthValue rdf:ID=\"MediumLengthParassequence\"> \n       &lt;ineq:smallerThan rdf:resource=\"#LongLengthParassequence\"/> \n       &lt;ineq:greaterThan rdf:resource=\"#ShortLengthParassequence\"/> \n   &lt;/ParassequenceLengthValue> \n   &lt;SequenceLengthValue rdf:ID=\"MediumLengthSequence\"> \n       &lt;ineq:smallerThan rdf:resource=\"#LongLengthSequence\"/> \n       &lt;ineq:greaterThan rdf:resource=\"#ShortLengthSequence\"/> \n   &lt;/SequenceLengthValue> \n   &lt;owl:Class rdf:ID=\"ParassequenceLengthValue\"> \n       &lt;owl:equivalentClass> \n           &lt;owl:Class> \n               &lt;owl:oneOf rdf:parseType=\"Collection\"> \n                   &lt;rdf:Description rdf:about=\"#LongLengthParassequence\"/> \n                   &lt;rdf:Description rdf:about=\"#MediumLengthParassequence\"/> \n                   &lt;rdf:Description rdf:about=\"#ShortLengthParassequence\"/> \n               &lt;/owl:oneOf> \n           &lt;/owl:Class> \n       &lt;/owl:equivalentClass> \n       &lt;rdfs:subClassOf rdf:resource=\"&amp;vlo;LengthValue\"/> \n   &lt;/owl:Class> \n   &lt;swrla:RuleGroup rdf:ID=\"sdgDomSequence\"> \n       &lt;swrla:isRuleGroupEnabled  \n  rdf:datatype=\"&amp;xsd;boolean\">true</swrla:isRuleGroupEnabled> \n       &lt;mapo:groundingPrimitive rdf:resource=\"&amp;dom;Sequence\"/> \n   &lt;/swrla:RuleGroup> \n   &lt;swrla:RuleGroup rdf:ID=\"sdgGaussianCurve\"> \n       &lt;swrla:isRuleGroupEnabled \n\n\n\n117 \n\n \n\n \n\n rdf:datatype=\"&amp;xsd;boolean\">true</swrla:isRuleGroupEnabled> \n       &lt;mapo:groundingPrimitive rdf:resource=\"&amp;vlo;GaussianCurve\"/> \n   &lt;/swrla:RuleGroup> \n   &lt;swrla:RuleGroup rdf:ID=\"sdgMaximumFloodingSurface\"> \n       &lt;swrla:isRuleGroupEnabled  \n  rdf:datatype=\"&amp;xsd;boolean\">true</swrla:isRuleGroupEnabled> \n       &lt;mapo:groundingPrimitive rdf:resource=\"&amp;dom;MaximumFloodingSurface\"/> \n   &lt;/swrla:RuleGroup> \n   &lt;swrla:RuleGroup rdf:ID=\"sdgMaximumPoint\"> \n       &lt;swrla:isRuleGroupEnabled  \n  rdf:datatype=\"&amp;xsd;boolean\">true</swrla:isRuleGroupEnabled> \n       &lt;mapo:groundingPrimitive rdf:resource=\"&amp;vlo;MaximumPoint\"/> \n   &lt;/swrla:RuleGroup> \n   &lt;swrla:RuleGroup rdf:ID=\"sdgParassequence\"> \n       &lt;swrla:isRuleGroupEnabled  \n  rdf:datatype=\"&amp;xsd;boolean\">true</swrla:isRuleGroupEnabled> \n       &lt;mapo:groundingPrimitive rdf:resource=\"&amp;dom;Parassequence\"/> \n   &lt;/swrla:RuleGroup> \n   &lt;swrla:RuleGroup rdf:ID=\"sdgSmoothToothCurve\"> \n       &lt;swrla:isRuleGroupEnabled \n\n rdf:datatype=\"&amp;xsd;boolean\">true</swrla:isRuleGroupEnabled> \n       &lt;mapo:groundingPrimitive rdf:resource=\"&amp;vlo;SmoothToothCurve\"/> \n   &lt;/swrla:RuleGroup> \n   &lt;swrla:RuleGroup rdf:ID=\"sdgVloLength\"> \n       &lt;swrla:isRuleGroupEnabled  \n  rdf:datatype=\"&amp;xsd;boolean\">true</swrla:isRuleGroupEnabled> \n       &lt;mapo:groundingPrimitive rdf:resource=\"&amp;vlo;hasLength\"/> \n   &lt;/swrla:RuleGroup> \n   &lt;swrla:RuleGroup rdf:ID=\"sdgVloSpatialRelation\"> \n       &lt;swrla:isRuleGroupEnabled \n\n rdf:datatype=\"&amp;xsd;boolean\">true</swrla:isRuleGroupEnabled> \n       &lt;mapo:groundingPrimitive rdf:resource=\"&amp;vlo;hasVisualProperty\"/> \n   &lt;/swrla:RuleGroup> \n   &lt;owl:Class rdf:ID=\"SequenceLengthValue\"> \n       &lt;owl:equivalentClass> \n           &lt;owl:Class> \n               &lt;owl:oneOf rdf:parseType=\"Collection\"> \n                   &lt;rdf:Description rdf:about=\"#LongLengthSequence\"/> \n                   &lt;rdf:Description rdf:about=\"#MediumLengthSequence\"/> \n                   &lt;rdf:Description rdf:about=\"#ShortLengthSequence\"/> \n                   &lt;rdf:Description rdf:about=\"#VeryLongLengthSequence\"/> \n                   &lt;rdf:Description rdf:about=\"#VeryShortLengthSequence\"/> \n               &lt;/owl:oneOf> \n           &lt;/owl:Class> \n       &lt;/owl:equivalentClass> \n       &lt;rdfs:subClassOf rdf:resource=\"&amp;vlo;LengthValue\"/> \n   &lt;/owl:Class> \n   &lt;ParassequenceLengthValue rdf:ID=\"ShortLengthParassequence\"> \n       &lt;ineq:smallerThan rdf:resource=\"#MediumLengthParassequence\"/> \n   &lt;/ParassequenceLengthValue> \n   &lt;SequenceLengthValue rdf:ID=\"ShortLengthSequence\"> \n       &lt;ineq:smallerThan rdf:resource=\"#MediumLengthSequence\"/> \n       &lt;ineq:greaterThan rdf:resource=\"#VeryShortLengthSequence\"/> \n   &lt;/SequenceLengthValue> \n   &lt;SequenceLengthValue rdf:ID=\"VeryLongLengthSequence\"> \n\n\n\n118 \n\n \n\n \n\n       &lt;ineq:greaterThan rdf:resource=\"#LongLengthSequence\"/> \n   &lt;/SequenceLengthValue> \n   &lt;SequenceLengthValue rdf:ID=\"VeryShortLengthSequence\"> \n       &lt;ineq:smallerThan rdf:resource=\"#ShortLengthSequence\"/> \n   &lt;/SequenceLengthValue> \n   &lt;rdf:Description rdf:about=\"&amp;vlo;GaussianCurve\"> \n       &lt;mapo:groundedByDG rdf:resource=\"#sdgGaussianCurve\"/> \n   &lt;/rdf:Description> \n   &lt;rdf:Description rdf:about=\"&amp;vlo;hasLength\"> \n       &lt;rdfs:domain rdf:resource=\"&amp;vlo;Curve\"/> \n       &lt;mapo:groundedByDG rdf:resource=\"#sdgVloLength\"/> \n   &lt;/rdf:Description> \n   &lt;rdf:Description rdf:about=\"&amp;vlo;hasVisualProperty\"> \n       &lt;rdfs:domain rdf:resource=\"&amp;vlo;VisualEntity\"/> \n       &lt;mapo:groundedByDG rdf:resource=\"#sdgVloSpatialRelation\"/> \n   &lt;/rdf:Description> \n   &lt;rdf:Description rdf:about=\"&amp;vlo;hasSmoothToothCurveCharacteristic\"/> \n   &lt;rdf:Description rdf:about=\"&amp;vlo;MaximumPoint\"> \n       &lt;mapo:groundedByDG rdf:resource=\"#sdgMaximumPoint\"/> \n   &lt;/rdf:Description> \n   &lt;rdf:Description rdf:about=\"&amp;vlo;SmoothToothCurve\"> \n       &lt;mapo:groundedByDG rdf:resource=\"#sdgSmoothToothCurve\"/> \n   &lt;/rdf:Description> \n</rdf:RDF> \n\nB.5.2 Modelo OWL de rela\u00e7\u00f5es de ordem (desigualdades) \n<?xml version=\"1.0\"?> \n<rdf:RDF \n    xmlns=\"http://www.owl-ontologies.com/InequalityOntology.owl#\" \n    xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" \n    xmlns:protege=\"http://protege.stanford.edu/plugins/owl/protege#\" \n    xmlns:xsp=\"http://www.owl-ontologies.com/2005/08/07/xsp.owl#\" \n    xmlns:owl=\"http://www.w3.org/2002/07/owl#\" \n    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\" \n    xmlns:swrl=\"http://www.w3.org/2003/11/swrl#\" \n    xmlns:swrlb=\"http://www.w3.org/2003/11/swrlb#\" \n    xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\" \n  xml:base=\"http://www.owl-ontologies.com/InequalityOntology.owl\"> \n &lt;owl:Ontology rdf:about=\"\"/> \n &lt;owl:TransitiveProperty rdf:ID=\"greaterThan\"> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:TransitiveProperty rdf:ID=\"inequalityRelation\"/> \n   &lt;/rdfs:subPropertyOf> \n   &lt;owl:inverseOf> \n     &lt;owl:TransitiveProperty rdf:ID=\"smallerThan\"/> \n   &lt;/owl:inverseOf> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#ObjectProperty\"/> \n &lt;/owl:TransitiveProperty> \n &lt;owl:TransitiveProperty rdf:about=\"#smallerThan\"> \n   &lt;rdfs:subPropertyOf> \n     &lt;owl:TransitiveProperty rdf:about=\"#inequalityRelation\"/> \n   &lt;/rdfs:subPropertyOf> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#ObjectProperty\"/> \n   &lt;owl:inverseOf rdf:resource=\"#greaterThan\"/> \n\n\n\n119 \n\n \n\n \n\n &lt;/owl:TransitiveProperty> \n &lt;owl:TransitiveProperty rdf:about=\"#inequalityRelation\"> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#ObjectProperty\"/> \n &lt;/owl:TransitiveProperty> \n &lt;owl:SymmetricProperty rdf:ID=\"equals\"> \n   &lt;owl:inverseOf rdf:resource=\"#equals\"/> \n   &lt;rdfs:subPropertyOf rdf:resource=\"#inequalityRelation\"/> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#TransitiveProperty\"/> \n   &lt;rdf:type rdf:resource=\"http://www.w3.org/2002/07/owl#ObjectProperty\"/> \n &lt;/owl:SymmetricProperty> \n</rdf:RDF> \n\nB.5.3 Detectores simb\u00f3licos \nEmbora os detectores simb\u00f3licos perten\u00e7am ao modelo OWL do sistema In-\n\nteliStrata, a sua codifica\u00e7\u00e3o RDF/XML \u00e9 consideravelmente prolixa. Por isso, \nsomente a representa\u00e7\u00e3o direta dos detectores \u00e9 descrita aqui. \n\nA Tabela B.1 na p\u00e1gina seguinte apresenta os detectores e a qual primitiva \nest\u00e3o relacionados via grupos de detectores. \n\n\n\n \n\n \n\n \n\nTabela B.1: Detectores simb\u00f3licos e rela\u00e7\u00e3o com primitivas ancoradas. \n\nPrimitiva Detector Simb\u00f3lico (regra SWRL) \n\ndom:Sequence \nmapo:mappingSemanticToVisual(?de, ?ve)  ?  vlo:GaussianCurve(?ve)   \n?  vlo:hasGaussianCurveCharacteristic(?ve, ?pattern)  ?  swrlineq:greaterThanOrEqual(?pattern, vlo:StrongPattern)   \n?  vlo:hasLength(?ve, ?length)  ?  swrlineq:greaterThanOrEqual(?length, MediumLengthSequence) \n ? dom:Sequence(?de) \n\ndom:Parassequence \n\nmapo:mappingSemanticToVisual(?de, ?ve)  ?  vlo:SmoothToothCurve(?ve)   \n?  vlo:hasSmoothToothCurveCurveCharacteristic(?ve, ?pattern)   \n?  swrlineq:greaterThanOrEqual(?pattern, vlo:MediumPattern)   \n?  vlo:hasLength(?ve, ?length)  ?  swrlineq:greaterThanOrEqual(?length, ShortLengthParassequence)   \n?  vlo:isProperPartOf(?ve, ?sequenceVe)  ?  mapo:mappingSemanticToVisual(?sequenceDe, ?sequenceVe)  \n?  dom:Sequence(?sequenceDe)  \n? dom:Parassequence(?de)  ?  part:hasPart_directly(?sequenceDe, ?de) \n\ndom:MaximumFloodingSurface \nmapo:mappingSemanticToVisual(?de, ?ve)  ?  vlo:MaximumPoint(?ve)  ?  vlo:isProperPartOf(?ve, ?sequenceVe)   \n?  mapo:mappingSemanticToVisual(?sequenceDe, ?sequenceVe)  ?  dom:Sequence(?sequenceDe)  \n? dom:MaximumFloodingSurface(?de)  ?  part:hasPart_directly(?sequenceDe, ?de) \n\nvlo:MaximumPoint \nmapo:mappingVisualToAnalogic(?ve, ?ae)  ?  alo:Interval(?ae2)  ?  alo:hasMaximumPoint(?ae2, ?ae)  \n? vlo:MaximumPoint(?ve) \n\nvlo:hasLength \n\nmapo:mappingVisualToAnalogic(?ve, ?al)  ?  alo:Interval(?al)  ?  alo:hasLength(?al, ?value)   \n?  fuzzy:match(?value, ?fv, \"[5, 10, 50, 60]\", ShortLengthParassequence, \"[50, 60, 140, 150]\", MediumLengthParassequence, \n\n\"[140, 150, 200, 250]\", LongLengthSequence)  \n? vlo:hasLength(?ve, ?fv) \nmapo:mappingVisualToAnalogic(?ve, ?al)  ?  alo:Interval(?al)  ?  alo:hasLength(?al, ?value)   \n?  fuzzy:match(?value, ?fv, \"[0, 0, 66, 82]\", VeryShortLengthSequence, \"[66, 82, 146, 210]\", ShortLengthSequence, \"[146, 210, \n\n466, 722]\", MediumLengthSequence, \"[466, 722, 1746, 2770]\", LongLengthSequence, \"[1746, 2770, 5000, 7500]\", \nVeryLongLengthSequence)  \n\n? vlo:hasLength(?ve, ?fv) \n\nvlo:SmoothToothCurve \n\nmapo:mappingVisualToAnalogic(?ve, ?al)  ?  alo:Interval(?al)  ?  spo:isExtractedWith(?al, spo:SmoothToothCurveSPF)   \n?  spo:hasExtractionStrength(?al, ?vstrength)   \n?  fuzzy:match(?vstrength, ?strength, \"[0, 0, 0.2, 0.3]\", vlo:VeryWeakPattern, \"[0.2, 0.3, 0.4, 0.5]\", vlo:WeakPattern, \"[0.4, 0.5, \n\n0.6, 0.7]\", vlo:MediumPattern, \"[0.6, 0.7, 0.8, 0.9]\", vlo:StrongPattern, \"[0.8, 0.9, 1, 1]\", vlo:VeryStrongPattern) \n ? vlo:SmoothToothCurve(?ve)  ?  vlo:hasSmoothToothCurveCharacteristic(?ve, ?strength) \n\nvlo:GaussianCurve \n\nmapo:mappingVisualToAnalogic(?ve, ?al)  ?  alo:Interval(?al)  ?  spo:isExtractedWith(?al, spo:Gaussian2SPF)   \n?  spo:hasExtractionStrength(?al, ?vstrength)   \n?  fuzzy:match(?vstrength, ?strength, \"[0, 0, 0.2, 0.3]\", vlo:VeryWeakPattern, \"[0.2, 0.3, 0.4, 0.5]\", vlo:WeakPattern, \"[0.4, 0.5, \n\n0.6, 0.7]\", vlo:MediumPattern, \"[0.6, 0.7, 0.8, 0.9]\", vlo:StrongPattern, \"[0.8, 0.9, 1, 1]\", vlo:VeryStrongPattern)  \n? vlo:GaussianCurve(?ve)  ?  vlo:hasGaussianCurveCharacteristic(?ve, ?strength) \n\n\n\n121 \n\n \n\n \n\nvlo:hasSpatialRelationWith \n\nmapo:mappingVisualToAnalogic(?ve1, ?al1)  ?  alo:Interval(?al1)  ?  alo:hasCenterPoint(?al1, ?cp1)   \n?  alo:index(?cp1, ?vx1)  ?  mapo:mappingVisualToAnalogic(?ve2, ?al2)  ?  alo:Interval(?al2)   \n?  alo:hasCenterPoint(?al2, ?cp2)  ?  alo:index(?cp2, ?vx2)  ?  swrlb:greaterThanOrEqual(?vx1, ?vx2)  \n? vlo:isAtRightOf(?ve1, ?ve2)  ?  vlo:isAtLeftOf(?ve2, ?ve1) \nmapo:mappingVisualToAnalogic(?ve1, ?al1)  ?  alo:Interval(?al1)  ?  alo:hasStartPoint(?al1, ?sp1)   \n?  alo:hasEndPoint(?al1, ?ep1)  ?  alo:index(?sp1, ?vsx1)  ?  alo:index(?ep1, ?vex1)   \n?  mapo:mappingVisualToAnalogic(?ve2, ?al2)  ?  alo:Interval(?al2)  ?  alo:hasStartPoint(?al2, ?sp2)   \n?  alo:hasEndPoint(?al2, ?ep2)  ?  alo:index(?sp2, ?vsx2)  ?  alo:index(?ep2, ?vex2)  ?  swrlb:greaterThan(?vsx2, ?vex1)  \n? vlo:isDiscreteOf(?ve1, ?ve2) \nmapo:mappingVisualToAnalogic(?ve1, ?al1)  ?  alo:Interval(?al1)  ?  alo:hasStartPoint(?al1, ?sp1)   \n?  alo:hasEndPoint(?al1, ?ep1)  ?  alo:index(?sp1, ?vsx1)  ?  alo:index(?ep1, ?vex1)   \n?  mapo:mappingVisualToAnalogic(?ve2, ?al2)  ?  alo:Interval(?al2)  ?  alo:hasStartPoint(?al2, ?sp2)  \n ?  alo:hasEndPoint(?al2, ?ep2)  ?  alo:index(?sp2, ?vsx2)  ?  alo:index(?ep2, ?vex2)  ?  swrlb:equal(?vsx2, ?vsx1)   \n?  swrlb:equal(?vex2, ?vex1)  \n? vlo:isTopologicallyEqualsTo(?ve1, ?ve2) \nmapo:mappingVisualToAnalogic(?ve1, ?al1)  ?  alo:Interval(?al1)  ?  alo:hasEndPoint(?al1, ?ep1)   \n?  alo:index(?ep1, ?vex1)  ?  mapo:mappingVisualToAnalogic(?ve2, ?al2)  ?  alo:Interval(?al2)   \n?  alo:hasStartPoint(?al2, ?sp2)  ?  alo:index(?sp2, ?vsx2)  ?  swrlb:equal(?vsx2, ?vex1) \n ? vlo:isExternallyConnectedTo(?ve1, ?ve2)  ?  vlo:isExternallyConnectedTo(?ve2, ?ve1) \nmapo:mappingVisualToAnalogic(?ve1, ?al1)  ?  alo:Interval(?al1)  ?  alo:hasStartPoint(?al1, ?sp1)   \n?  alo:hasEndPoint(?al1, ?ep1)  ?  alo:index(?sp1, ?vsx1)  ?  alo:index(?ep1, ?vex1)   \n?  mapo:mappingVisualToAnalogic(?ve2, ?al2)  ?  alo:Interval(?al2)  ?  alo:hasStartPoint(?al2, ?sp2)   \n?  alo:hasEndPoint(?al2, ?ep2)  ?  alo:index(?sp2, ?vsx2)  ?  alo:index(?ep2, ?vex2)  ?  swrlb:greaterThan(?vsx2, ?vsx1)   \n?  swrlb:greaterThan(?vex1, ?vex2)  \n? vlo:isNonTangentialProperPartOf(?ve2, ?ve1)  ?  vlo:hasForNonTangentialProperPartOf(?ve1, ?ve2) \nmapo:mappingVisualToAnalogic(?ve1, ?al1)  ?  alo:Interval(?al1)  ?  alo:hasStartPoint(?al1, ?sp1)   \n?  alo:hasEndPoint(?al1, ?ep1)  ?  alo:index(?sp1, ?vsx1)  ?  alo:index(?ep1, ?vex1)   \n?  mapo:mappingVisualToAnalogic(?ve2, ?al2)  ?  alo:Interval(?al2)  ?  alo:hasStartPoint(?al2, ?sp2)   \n?  alo:hasEndPoint(?al2, ?ep2)  ?  alo:index(?sp2, ?vsx2)  ?  alo:index(?ep2, ?vex2)   \n?  swrlb:equal(?vsx2, ?vsx1)  ?  swrlb:greaterThan(?vex1, ?vex2) \n ? vlo:isTangentialProperPartOf(?ve2, ?ve1)  ?  vlo:hasForTangentialProperPart(?ve1, ?ve2) \nmapo:mappingVisualToAnalogic(?ve1, ?al1)  ?  alo:Interval(?al1)  ?  alo:hasStartPoint(?al1, ?sp1)   \n?  alo:hasEndPoint(?al1, ?ep1)  ?  alo:index(?sp1, ?vsx1)  ?  alo:index(?ep1, ?vex1)   \n?  mapo:mappingVisualToAnalogic(?ve2, ?al2)  ?  alo:Interval(?al2)  ?  alo:hasStartPoint(?al2, ?sp2)   \n?  alo:hasEndPoint(?al2, ?ep2)  ?  alo:index(?sp2, ?vsx2)  ?  alo:index(?ep2, ?vex2)  ?  swrlb:greaterThan(?vsx2, ?vsx1)   \n?  swrlb:equal(?vex1, ?vex2)  \n? vlo:isTangentialProperPartOf(?ve2, ?ve1)  ?  vlo:hasForTangentialProperPart(?ve1, ?ve2) \n\n\n\n122 \n\n \n\n \n\nmapo:mappingVisualToAnalogic(?ve1, ?al1)  ?  alo:Interval(?al1)  ?  alo:hasStartPoint(?al1, ?sp1)   \n?  alo:hasEndPoint(?al1, ?ep1)  ?  alo:index(?sp1, ?vsx1)  ?  alo:index(?ep1, ?vex1)   \n?  mapo:mappingVisualToAnalogic(?ve2, ?al2)  ?  alo:Interval(?al2)  ?  alo:hasStartPoint(?al2, ?sp2)   \n?  alo:hasEndPoint(?al2, ?ep2)  ?  alo:index(?sp2, ?vsx2)  ?  alo:index(?ep2, ?vex2)   \n?  swrlb:greaterThan(?vex1, ?vsx2)  ?  swrlb:greaterThan(?vex2, ?vex1)  \n? vlo:partialOverlaps(?ve1, ?ve2) \nmapo:mappingVisualToAnalogic(?ve1, ?al1)  ?  alo:Interval(?al1)  ?  alo:hasStartPoint(?al1, ?sp1)   \n?  alo:hasEndPoint(?al1, ?ep1)  ?  alo:index(?sp1, ?vsx1)  ?  alo:index(?ep1, ?vex1)   \n?  mapo:mappingVisualToAnalogic(?ve2, ?al2)  ?  alo:Point(?al2)  ?  alo:hasPoint(?al1, ?al2)   \n?  alo:index(?al2, ?vx2)  ?  swrlb:greaterThan(?vx2, ?vsx1)  ?  swrlb:greaterThan(?vex1, ?vx2) \n ? vlo:isNonTangentialProperPartOf(?ve2, ?ve1)  ?  vlo:hasForNonTangentialProperPartOf(?ve1, ?ve2) \nmapo:mappingVisualToAnalogic(?ve1, ?al1)  ?  alo:Interval(?al1)  ?  alo:hasStartPoint(?al1, ?sp1)   \n?  alo:index(?sp1, ?vsx1)  ?  mapo:mappingVisualToAnalogic(?ve2, ?al2)  ?  alo:Point(?al2)  ?  alo:hasPoint(?al1, ?al2)   \n?  alo:index(?al2, ?vx2)  ?  swrlb:equal(?vsx1, ?vx2) ? vlo:isTangentialProperPartOf(?ve2, ?ve1)   \n?  vlo:hasForTangentialProperPart(?ve1, ?ve2) \nmapo:mappingVisualToAnalogic(?ve1, ?al1)  ?  alo:Interval(?al1)  ?  alo:hasEndPoint(?al1, ?ep1)   \n?  alo:index(?ep1, ?vex1)  ?  mapo:mappingVisualToAnalogic(?ve2, ?al2)  ?  alo:Point(?al2)   \n?  alo:hasPoint(?al1, ?al2)  ?  alo:index(?al2, ?vx2)  ?  swrlb:equal(?vex1, ?vx2)  \n? vlo:isTangentialProperPartOf(?ve2, ?ve1)  ?  vlo:hasForTangentialProperPart(?ve1, ?ve2)"}]}}}