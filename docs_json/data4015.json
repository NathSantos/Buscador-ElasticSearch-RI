{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.08010"}, {"@name": "filename", "#text": "12786_DISSERTA%c3%87%c3%83O%20Igor%20Rafael%20de%20Oliveira%20Pona.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "P\u00f3s-Gradua\u00e7\u00e3o em Ci\u00eancia da Computa\u00e7\u00e3o\nIGOR RAFAEL DE OLIVEIRA PONA\nPROPOSTA DE UMA IMPLEMENTA\u00c7\u00c3O OTIMIZADA DO ALGORITMO RTM.3D EM OPEN.CL PARA PLATAFORMAS BASEADAS EM FPGAS\nUniversidade Federal de Pernambuco posgraduacao@cin.ufpe.br www.cin.ufpe.br/~posgraduacao\nRECIFE\n2016\nIgor Rafael de Oliveira Pona\nPROPOSTA DE UMA IMPLEMENTA\u00c7\u00c3O OTIMIZADA DO ALGORITMO RTM.3D EM OPEN.CL PARA PLATAFORMAS BASEADAS EM FPGAS\nDisserta\u00e7\u00e3o de Mestrado apresentada ao Programa de P\u00f3s-gradua\u00e7\u00e3o em Ci\u00eancia da Computa\u00e7\u00e3o da Universidade Federal de Pernambuco como requisito parcial para a obten\u00e7\u00e3o do t\u00edtulo de Mestre em Ci\u00eancia da Computa\u00e7\u00e3o.\nORIENTADOR(A): Prof.. Manoel Eusebio de Lima\nRECIFE\n2016\nCataloga\u00e7\u00e3o na fonte\nBibliotec\u00e1ria Monick Raquel Silvestre da S. Portes, CRB4-1217\nP792p Pona, Igor Rafael de Oliveira\nProposta de uma implementa\u00e7\u00e3o otimizada do algoritmo RTM.3D em OPEN.CL para plataformas baseadas em FPGAs / Igor Rafael de Oliveira Pona. - 20l6.\n66 f.: il., fig., tab.\nOrientador: Manoel Eus\u00e9bio de Lima.\nDisserta\u00e7\u00e3o (Mestrado) - Universidade Federal de Pernambuco. CIn, Ci\u00eancia da Computa\u00e7\u00e3o, Recife, 2016.\nInclui refer\u00eancias e ap\u00eandices.\n1. Engenharia da computa\u00e7\u00e3o. 2. Arquitetura de computador. 3. FPGA. I. Lima, Manoel Eus\u00e9bio de (orientador). II. T\u00edtulo.\n621.39\tCDD (23. ed.)\tUFPE- MEI 2017-116\nIgor Rafael de Oliveira Pona\nProposta de uma Implementa\u00e7\u00e3o Otimizada do Algoritmo RTM.3D em OPEN.CL para Plataformas baseadas em FPGAs\nDisserta\u00e7\u00e3o de Mestrado apresentada ao Programa de P\u00f3s-gradua\u00e7\u00e3o em Ci\u00eancia da Computa\u00e7\u00e3o da Universidade Federal de Pernambuco como requisito parcial para a obten\u00e7\u00e3o do t\u00edtulo de Mestre em Ci\u00eancia da Computa\u00e7\u00e3o.\nAprovado em: 08/09/2016.\nBANCA EXAMINADORA\nProfa. Dra. Edna Natividade da Silva Barros\nCentro de Inform\u00e1tica/UFPE\nProf. Dr. Victor Wanderley Costa de Medeiros Departamento de Estat\u00edstica e Inform\u00e1tica/UFRPE\nProf. Dr. Manoel Eus\u00e9bio de Lima Centro de Inform\u00e1tica/UFPE (Orientador)\nAgradecimentos\nAgrade\u00e7o a minha m\u00e3e Simone, pelo apoio, motiva\u00e7\u00e3o, amizade e amor. Ao Marcelo que \u00e9 mais do que um pai, um grande amigo. Aos meus irm\u00e3os Ytalo e Yasminy pelo companheirismo e amizade. A todos que fazem parte desta grande fam\u00edlia que vai al\u00e9m dos la\u00e7os sangu\u00edneos.\nAgrade\u00e7o aos meus professores, por seus ensinamentos, dedica\u00e7\u00e3o, paci\u00eancia e amizade. Ao professor Manoel Eusebio, pela oportunidade, conselhos e orienta\u00e7\u00e3o. Aos professores do grupo HPCin que me deram suporte no decorrer desta pesquisa, e contribu\u00edram com esta disserta\u00e7\u00e3o.\nAos amigos que fiz no grupo HPCin, Joelma Souza, Severino Jos\u00e9 (Biu) e Thyago Maia, pela amizade, ajuda e disposi\u00e7\u00e3o de compartilhar conhecimentos.\nSou grato a todos que contribu\u00edram na minha caminhada at\u00e9 este momento.\nResumo\nA demanda por sistemas de alto desempenho cresce junto ao desenvolvimento cient\u00edfico e econ\u00f4mico e dentro das mais diversas \u00e1reas, passando por modelagens cient\u00edficas, intelig\u00eancia artificial, criptografia, computa\u00e7\u00e3o em nuvem, etc. A prospec\u00e7\u00e3o de petr\u00f3leo e g\u00e1s natural faz parte desses sistemas, exigindo o processamento de dados com um volume acima dos Terabytes e ao custo de semanas ou meses de execu\u00e7\u00e3o, no intuito de procurar bols\u00f5es no subsolo; al\u00e9m de sua import\u00e2ncia estrat\u00e9gica devido ao pr\u00e9-sal. Essa procura faz uso da equa\u00e7\u00e3o ac\u00fastica de propaga\u00e7\u00e3o de onda, e apresenta como uma de suas solu\u00e7\u00f5es o m\u00e9todo de diferen\u00e7as finitas (MDF) pelo algoritmo de RTM (Reverse Time Migration). Essa solu\u00e7\u00e3o demanda uma grande quantidade de opera\u00e7\u00f5es em ponto flutuante, exigindo hardwares com arquiteturas dedicados a essa finalidade como FPGAs e GPGPUs. Neste trabalho fazemos uma an\u00e1lise sobre essas arquiteturas para o algoritmo RTM em OpenCL na sua vers\u00e3o 3D, assim como as poss\u00edveis otimiza\u00e7\u00f5es ao se aproveitar da portabilidade do c\u00f3digo em OpenCL de GPGPUs para FPGAs. Avaliamos os recursos utilizados em s\u00ednteses feitas pelo SDK OpenCL da Altera para o FPGA Stratix V A7, para em um segundo momento, desenvolver um c\u00f3digo que tenta otimizar o uso desses recursos que est\u00e3o dispon\u00edveis no FPGA. E por fim, analisamos os resultados obtidos frente a outras arquiteturas.\nPalavras-chave: HPC. FPGA. OpenCL. RTM 3D.\nAbstract\nThe high-performance computing systems increase with scientific and economic development through several fields like scientific modeling, artificial intelligence, cryptography, cloud computing, etc. The oil and natural gas extraction is among of these systems, requiring data processing with sizes greater than Terabytes and with the cost of weeks or months of execution time, in order to look for underground reservoir; as well as its strategic importance due to the pre-salt. The oil extraction makes use of acoustic wave equation, and has the finite difference method (FDM) as one of your solutions through the algorithm of RTM (Reverse Time Migration). This solution requires a lot of floating point operations and a hardware with dedicated architecture as FPGAs and GPGPUs. This work we analyze these architectures to implement the RTM 3D algorithm with OpenCL, as well as the possibly of take advantage of code portability of OpenCL for FPGAs GPGPUs. We evaluate the resources used in syntheses made by the OpenCL SDK Altera Stratix V A7 FPGA, and in a second moment, to develop a code that attempts to optimize the use of these resources that are available in the FPGA. Finally, we analyze the results against other architectures.\nKeywords: HPC. FPGA. OpenCL. RTM 3D.\nLista de ilustra\u00e7\u00f5es\nFigura 1 - Prospec\u00e7\u00e3o de petr\u00f3leo e g\u00e1s natural............................... 18\nFigura 2 - Modelagem e migra\u00e7\u00e3o s\u00edsmica - M\u00e9todos ............................ 19\nFigura 3 - OpenCL - Computer Device........................................... 20\nFigura 4 - Arquitetura Stratix V.............................................. 22\nFigura 5 - ALM - Adaptive Logic Module........................................ 23\nFigura 6 - Fermi Streaming Multiprocessor (SM)................................ 24\nFigura 7 - Graphics Core Next \"GCN 1.0\"AMD Southern Islands\tSeries Block\nDiagram...................................................... 25\nFigura 8 - Stencil e os pontos de VEL, PPF e CPF que resultam\tno NPF.......... 33\nFigura 9 - Pseudoc\u00f3digo RTM 3D................................................ 33\nFigura 10 - Diagrama de Execu\u00e7\u00e3o do Host/Device (OpenCL)...................... 34\nFigura 11 - GPU - Exemplo de Varredura pelo Stencil lendo os pontos de\tCPF . .\t35\nFigura 12 - FPGA - Exemplo de Varredura pelo Stencil lendo os\tpontos\tde CPF . 36\nFigura 13 - Fluxo de Execu\u00e7\u00e3o SDK OpenCL - Altera............................. 38\nFigura 14 - S\u00edntese OpenCL RTM 3D - \u00c1rvore hier\u00e1rquica........................ 39\nFigura 15 - Throughput Gpoints/Sec ........................................... 45\nFigura 16 - TDP Watts / Gpoints/Sec........................................... 45\nFigura 17 - S\u00edntese\tOpenCL\tRTM\t3D\t- Qsys\tBoard ............................. 53\nFigura 18 - S\u00edntese\tOpenCL\tRTM\t3D\t- Qsys\tKernel System...................... 54\nFigura 19 - S\u00edntese\tOpenCL\tRTM\t3D\t- Qsys\tSystem ............................ 54\nFigura 20 - S\u00edntese\tOpenCL\tRTM\t3D .......................................... 55\nFigura 21 - Modelagem RTM\t3D\t- Dim.\t356\t- 100 Steps......................... 63\nFigura 22 - Modelagem RTM\t3D\t- Dim.\t356\t- 100 Steps /\tPontos................ 64\nFigura 23 - Modelagem RTM\t3D\t- Dim.\t356\t- 300 Steps /\tPontos ............... 65\nFigura 24 - Modelagem RTM\t3D\t- Dim.\t356\t- 500 Steps /\tPontos ............... 66\nTabela 1\t-\tStratix V - Especifica\u00e7\u00f5es.......................................... 23\nTabela 2\t-\tTrabalhos - \u00cdndice ................................................. 31\nTabela 3\t-\tTrabalhos - Hardwares............................................... 31\nTabela 4\t-\tTrabalhos - Caracter\u00edsticas......................................... 31\nTabela 5\t-\tStratix V - Recursos utilizados .................................... 38\nTabela 6\t-\tOtimiza\u00e7\u00f5es......................................................... 42\nTabela 7\t-\tConfigura\u00e7\u00f5es....................................................... 43\nTabela 8\t-\tResultados - Portabilidade OpenCL .................................. 44\nTabela 9\t-\tResultados - CPU X GPU X FPGA....................................... 44\nALM\tAdaptive Logic Modules\nAPI\tApplication Programming Interface\nARM\tAdvanced RISC Machine\nASIC\tApplication Specific Integrated Circuits\nAVX\tAdvanced Vector Extensions\nCLB\tConfigurable Logic Block\nCMOS\tComplementary Metal-Oxide-semiconductor\nCPU\tCentralProcessing Unit\nCUDA\tCompute Unified Device Architecture\nEUVL\tExtreme Ultraviolet Lithography\nFPGA\tField Programmable Gate Array\nGDDR\tGraphics Double Data Rate\nGPGPU\tGeneral Purpose GPU\nGPU\tGraphics Processing Unit\nHDL\tHardware Description Language\nIOB\tInput/Output Block\nLAB\tLogic Array Blocks\nLLVM\tLow Level Virtual Machine\nLUT\tLook-Up Table\nMDF\tMigra\u00e7\u00e3o por Diferen\u00e7as Finitas\nMIMD\tMultiple Instruction Multiple Data\nMISD\tMultiple Instruction streams, Single Data stream\nOpenCL\tOpen Computing Language\nRTM\tReverse Time Migration\nSDK\tSoftware Development Kit\nSIMD\tSingle Instruction Multiple Data\nSISD\nSSE\nSingle Instruction stream, Single Data stream\nStreaming SIMD Extensions\nSumario\n1\tIntrodu\u00e7\u00e3o............................................................13\n2\tFundamenta\u00e7\u00e3o Te\u00f3rica.................................................16\n2.1\tProspec\u00e7\u00e3o de petr\u00f3leo e g\u00e1s natural ................................ 16\n2.2\tOpenCL............................................................... 19\n2.3\tArquiteturas FPGA e GPU.............................................. 21\n2.3.1\tFPGA - Field Programmable Gate Array................................. 21\n2.3.2\tGPU - Graphics Processing Unit....................................... 23\n3\tTrabalhos Relacionados................................................26\n3.1\tEvaluation of successive CPUs/APUs/GPUs based on an OpenCL finite\ndifference stencil .................................................. 26\n3.2\tSynthesis of Platform Architectures\tfrom OpenCL Programs............. 27\n3.3\tAnalyzing the energy-efficiency of\tsparse matrix multiplication on heterogeneous systems: A comparative study of GPU, Xeon Phi and FPGA.................... 28\n3.4\tScaling Reverse Time Migration Performance through Reconfigurable Data-\nflow Engines ........................................................ 28\n3.5\tComparing Hardware Accelerators\tin Scientific Applications: A Case Study . 28\n3.6\tConclus\u00f5es........................................................... 29\n4\tImplementa\u00e7\u00e3o.........................................................32\n4.1\tO algoritmo RTM 3D .................................................. 32\n4.2\tC\u00f3digo - GPU ........................................................ 35\n4.3\tC\u00f3digo - FPGA ....................................................... 35\n4.4\tS\u00edntese do c\u00f3digo OpenCL em FPGA .................................... 37\n4.5\tConclus\u00f5es........................................................... 38\n5\tOtimiza\u00e7\u00f5es ..........................................................40\n5.1\tConclus\u00f5es .......................................................... 42\n6\tResultados............................................................43\n6.1\tConclus\u00f5es .......................................................... 46\n7\tConclus\u00e3o.............................................................47\nRefer\u00eancias...........................................................49\nAp\u00eandices....................................................52\nAP\u00caNDICE A\t-\tS\u00edntese OpenCL RTM 3D...................53\nAP\u00caNDICE B\t-\tC\u00f3digo RTM 3D OpenCL....................56\nB.1\tC\u00f3digo\tOpenCL -\tFPGA\t- Arquivo rtm3d_config.h..... 56\nB.2\tC\u00f3digo\tOpenCL -\tFPGA\t- Arquivo rtm3d.cl........... 56\nB.3\tC\u00f3digo\tOpenCL -\tGPU -\tArquivo rtm3d.cl ............ 59\nAP\u00caNDICE C\t- Imagens\tResultantes...................63\nI Introdu\u00e7\u00e3o\nNo decorrer dos anos da fabrica\u00e7\u00e3o de circuitos integrados em wafers (pratos) de materiais semicondutores, como o sil\u00edcio, a fotolitograf\u00eda \u00e9 a t\u00e9cnica mais comum em sua produ\u00e7\u00e3o. Essa t\u00e9cnica permite gravar vias e componentes eletr\u00f4nicos pela irradia\u00e7\u00e3o de luz ultravioleta, passando por mascaras que def\u00ednem a deposi\u00e7\u00e3o de metais nos wafers e v\u00e3o se sobrepor em camadas para a forma\u00e7\u00e3o do circuito. Assim, \u00e9 poss\u00edvel produzir circuitos que ocupam uma menor \u00e1rea e um menor consumo de pot\u00eancia el\u00e9trica, pois como o menor tamanho \u00e9 poss\u00edvel obter transistores que operam com uma menor resist\u00eancia el\u00e9trica e irradiam menos calor. No entanto, durante os anos, surgiram quest\u00f5es e paradigmas referentes a sua concep\u00e7\u00e3o e utiliza\u00e7\u00e3o, como o limite de frequ\u00eancia de opera\u00e7\u00e3o em temperatura ambiente, o limite de tens\u00e3o, o limite no paralelismo de instru\u00e7\u00f5es para uma determinada estrutura de dado e o limite na quantidade de vias f\u00edsicas, ou tamanho de palavra no circuito. Esses paradigmas motivaram o aumento da densidade de transistores em uma mesma \u00e1rea, para obter um maior desempenho e um maior n\u00famero de fun\u00e7\u00f5es l\u00f3gicas, como prop\u00f5em a lei de Moore 1965 (MOORE'S...). Mas a partir de 2006 esse movimento vem perdendo for\u00e7a (HENNESSY; PATTERSON, 2011, p. 100), principalmente com as dificuldades impostas durante o processo de fabrica\u00e7\u00e3o.\nEssa dif\u00edculdade se d\u00e1 devido ao tamanho do comprimento de onda da luz ultravioleta que \u00e9 de 193 nan\u00f4metros (nm), e \u00e9 maior do que as f\u00edssuras nas mascaras (16-10mn), criando defeitos durante o processo de litograf\u00eda e por vezes exigindo um maior tempo de exposi\u00e7\u00e3o e um maior n\u00famero de mascaras na fabrica\u00e7\u00e3o. Atualmente, as proje\u00e7\u00f5es indicam essa dif\u00edculdade de produ\u00e7\u00e3o em circuitos abaixo de 10 nan\u00f4metros, usando as t\u00e9cnicas e materiais vigentes, como o processo de nanolitograf\u00eda em ultravioleta (EUVL -Extreme ultraviolet lithography) Wu e Kumar (2014), janice m golda (2016), Ann Steffora Mutschler (2015).\nEm decorr\u00eancia desta dificuldade de produ\u00e7\u00e3o dos circuitos e no intuito de manter o crescimento no desempenho, os fabricantes optaram por aumentar o paralelismo pelo n\u00famero de cores em um mesmo chip, ou pelo uso de instru\u00e7\u00f5es vetoriais. No entanto, o conceito de paralelismo \u00e9 mais antigo e surge com Flynn em 1966, Hennessy e Patterson\n(2011, p. 197). Flynn define a taxonom\u00eda de arquiteturas paralelas em quatro categorias; s\u00e3o elas: SISD (Single instruction stream, single data stream), SIMD (Single Instruction Multiple Data), MISD (Multiple instruction streams, single data stream) e MIMD (Multiple instruction streams, multiple data streams). Esta categoriza\u00e7\u00e3o se d\u00e1 pelo tipo de depend\u00eancia l\u00f3gica das opera\u00e7\u00f5es ou instru\u00e7\u00f5es, e da estrutura do dado a ser processado por essas instru\u00e7\u00f5es. Portanto, SISD \u00e9 a categoria que apresenta a depend\u00eancia tanto no sequenciamento l\u00f3gico, quanto na estrutura de dado; SIMD possu\u00edmos um conjunto de dados que apresenta o mesmo sequenciamento l\u00f3gico e \u00e9 independente na estrutura de dado; MISD \u00e9 a categoria que permite aplicar m\u00faltiplas sequencias l\u00f3gicas a uma mesma estrutura de dado; e por fim, MIMD \u00e9 a categoria que n\u00e3o apresenta nenhuma depend\u00eancia, nem no sequenciamento l\u00f3gico, e nem na estrutura de dado. Essa abstra\u00e7\u00e3o l\u00f3gica pode ser extrapolada tanto a n\u00edvel de Hardware, quanto a n\u00edvel de Software, para al\u00e9m dos processos em execu\u00e7\u00e3o no sistema operacional; como por exemplo, uma aplica\u00e7\u00e3o que roda em Clusters espalhados em v\u00e1rios Data Centers.\nPara o cen\u00e1rio no qual o volume de dados processado cresce junto ao n\u00famero de usu\u00e1rios e sistemas voltados para internet, e junto ao desenvolvimento cientifico que exige modelos de maior complexidade e quantidade de dados - E como exemplo desse cen\u00e1rio podemos citar: o Big Data, modelos cient\u00edficos de f\u00edsica qu\u00e2ntica, processamento de imagens, intelig\u00eancia artificial, criptografia e modelos s\u00edsmicos com sensores mais apurados e com uma maior resolu\u00e7\u00e3o - Em resumo, problemas atuais para os quais o desempenho \u00e9 obtido pela melhoria no design das arquiteturas para favorecer o paralelismo e que consideram as limita\u00e7\u00f5es de desempenho atuais. Para esse cen\u00e1rio, \u00e9 refor\u00e7ada a necessidade de se trabalhar com sistemas que permitam tanto o paralelismo no processamento, quanto no paralelismo de dados. Esse \u00faltimo, por vezes, \u00e9 alcan\u00e7ado ao se fazer interfaces com outros sistemas, que podem ser de arquiteturas distintas, heterog\u00eaneas. Essas plataformas heterog\u00eanias fornecem uma escalabilidade e estabilidade, sem grandes depend\u00eancias da arquitetura, e dando suporte as instru\u00e7\u00f5es do tipo SIMD e MIMD. Com essa finalidade surge a Open Computing Language (OpenCL), uma linguagem (API) para escrever programas que funcionam em diferentes arquiteturas (KHRONOS.ORG).\nContudo, o processo de usar sistemas com arquiteturas distintas pode apresentar uma grande diferen\u00e7a de desempenho e dificuldades ao se portar o c\u00f3digo de uma arquitetura para outra. Essa dificuldade se d\u00e1 principalmente ao tipo de depend\u00eancia de dados que o problema apresenta, algumas caracter\u00edsticas intr\u00ednsecas do algoritmo e da arquitetura empregada. S\u00e3o esses fatores que v\u00e3o determinar se \u00e9 poss\u00edvel usar o paralelismo na solu\u00e7\u00e3o do problema.\nc\u00f3digo de GPU para FPGA. Realizando uma an\u00e1lise de cada arquitetura envolvida nesse processo com o intuito de diminuir o esfor\u00e7o necess\u00e1rio para implementar esses sistemas heterog\u00eaneos.\nEssa analise far\u00e1 uso do algoritmo de Reverse Time Migration em sua vers\u00e3o 3D (RTM 3D), o qual \u00e9 utilizado no processo de modelagem e migra\u00e7\u00e3o em superf\u00edcies de relevo complexos, que possui uma grande import\u00e2ncia na prospec\u00e7\u00e3o de petr\u00f3leo e g\u00e1s natural, principalmente ap\u00f3s o pr\u00e9-sal. Este algoritmo requer o processamento de uma quantidade massiva de dados, portanto, um grande esfor\u00e7o computacional. Problemas reais, como a an\u00e1lise do subsolo em \u00e1reas como a do pr\u00e9-sal, exigem processamento de banco de dados da ordem de terabytes de informa\u00e7\u00e3o, o que pode representar semanas a meses de computa\u00e7\u00e3o. (MEDEIROS, 2013, p. 15).\nE para viabilizar o processamento dessa quantidade de dados, usamos as seguintes plataformas na implementa\u00e7\u00e3o deste algoritmo em OpenCL; plataforma da Nallatech 385, com o dispositivo FPGA Stratix V A7 da Altera, plataforma GTX 580 com a microarquite-tura Fermi, da Nvidia e a plataforma HD 7970 Tahiti da AMD com microarquitetura \"GCN 1st gen\". E com o algoritmo RTM 3D para cada uma dessas plataformas, realizaremos um estudo comparativo do desempenho computacional com \u00eanfase na plataforma que possui FPGA. Demostrando o qu\u00e3o \u00e9 necess\u00e1rio a otimiza\u00e7\u00e3o do c\u00f3digo em OpenCL para estes tipos de dispositivos, frente aos tradicionais sistemas baseados em GPUs, no sentido de se conseguir um melhor desempenho computacional. Assim, o objetivo principal desta disserta\u00e7\u00e3o \u00e9 demonstrar que embora o uso de OpenCL facilite bastante a codifica\u00e7\u00e3o e compila\u00e7\u00e3o de algoritmos para dispositivos com FPGAs, esta linguagem quando escrita para GPU, ainda \u00e9 ineficiente em aproveitar todos os recursos dispon\u00edveis no FPGA. Sendo necess\u00e1rio uma an\u00e1lise e modifica\u00e7\u00e3o adicional do c\u00f3digo em OpenCL.\nEsta disserta\u00e7\u00e3o est\u00e1 d\u00edvida em 7 cap\u00edtulos; no cap\u00edtulo 2 \u00e9 apresentada uma breve revis\u00e3o bibliogr\u00e1fica sobre a modelagem e migra\u00e7\u00e3o s\u00edsmica, fornecendo alguns fundamentos necess\u00e1rios a esta disserta\u00e7\u00e3o, nos conceitos de prospec\u00e7\u00e3o e da origem do RTM. Nas sess\u00f5es seguintes s\u00e3o apresentados os conceitos e fundamentos do OpenCL e as arquiteturas utilizadas na disserta\u00e7\u00e3o, FPGA e GPUs. No cap\u00edtulo 3 apresentamos os trabalhos relacionados. No cap\u00edtulo 4 discute-se a implementa\u00e7\u00e3o do algoritmo RTM 3D, o c\u00f3digo para GPU e FPGA, assim como a s\u00edntese resultante do SDK OpenCL da Altera. No cap\u00edtulo 5 discute-se em detalhes as otimiza\u00e7\u00f5es necess\u00e1rias para melhorar o desempenho do RTM 3D no FPGA. Em seguida, no cap\u00edtulo 6, os resultados s\u00e3o apresentados. Finalmente no cap\u00edtulo 7 s\u00e3o apresentadas as conclus\u00f5es da disserta\u00e7\u00e3o e elencados os trabalhos futuros.\n^2\tFundamenta\u00e7\u00e3o Te\u00f3rica\nNesta se\u00e7\u00e3o relacionamos os principais conceitos sobre a prospec\u00e7\u00e3o de petr\u00f3leo, incluindo uma vis\u00e3o geral da aquisi\u00e7\u00e3o de dados, modelagem e migra\u00e7\u00e3o. Detalhando o processo de migra\u00e7\u00e3o com o algoritmo RTM (se\u00e7\u00e3o 2.1), e apresentamos a API do OpenCL (se\u00e7\u00e3o 2.2), que \u00e9 a linguagem utilizada na implementa\u00e7\u00e3o, e em seguida mostramos as caracter\u00edsticas das arquiteturas utilizadas neste trabalho (se\u00e7\u00e3o 2.3).\n2.1\tProspec\u00e7\u00e3o de petr\u00f3leo e g\u00e1s natural\nO processo de prospec\u00e7\u00e3o de petr\u00f3leo e g\u00e1s natural pode ser divido em tr\u00eas principais etapas: aquisi\u00e7\u00e3o, processamento e interpreta\u00e7\u00e3o (YILMAZ, 2001), e ocorre tanto em terra quanto em mares e oceanos. No caso da prospec\u00e7\u00e3o em mares e oceanos, um navio de pesquisa s\u00edsmica e destacado para a tarefa, e conforme exemplificado na Figura 1, o processo de aquisi\u00e7\u00e3o depende da produ\u00e7\u00e3o de ondas sonoras que s\u00e3o geradas por um canh\u00e3o de ar comprimido, propagando ondas nas camadas do subsolo. Essas ondas s\u00e3o refletidas ou refratadas conforme as diferentes caracter\u00edsticas do solo, at\u00e9 serem capturadas por sensores especiais que neste caso s\u00e3o os hidrofones. Ap\u00f3s o processo de aquisi\u00e7\u00e3o, \u00e9 gerado um modelo de refer\u00eancia de acordo com equa\u00e7\u00f5es de onda, que vai se juntar as informa\u00e7\u00f5es coletadas para, durante a etapa de processamento, ser realizada a migra\u00e7\u00e3o s\u00edsmica, confrontando com as informa\u00e7\u00f5es capturadas pelos hidrofones para gerar uma sa\u00edda de dados que corresponde ao um imageamento das camadas do subsolo. \u00c9 esse imageamento das camadas que \u00e9 usado durante a \u00faltima etapa de interpreta\u00e7\u00e3o.\nSequem abaixo todas as 16 etapas do processo convencional de prospec\u00e7\u00e3o segundo (YILMAZ, 2001):\n1.\tPreprocessing\nDemultiplexing Reformatting Editing Geometric Spreading Correction\nSetup of Field Statics\n2.\tDeconvolution and Trace Balancing\n3.\tCMP Sorting\n4.\tVelocity Analysis\n5.\tResidual Statics Corrections\n6.\tVelocity Analysis\n7.\tNormal-Moveout Correction (NMO)\n8.\tDip-Moveout Correction (DMO)\n9.\tInverse NMO Correction\n10.\tVelocity Analysis\n11.\tNMO Correction, Muting and Stacking\n12.\tDeconvolution\n13.\tTime-Variant Spectral Whitening\n14.\tTime-Variant Filtering\n15.\tMigration\n16.\tGain Application\nEsse trabalho aborda a 15o etapa do processo de prospec\u00e7\u00e3o, que \u00e9 a migra\u00e7\u00e3o s\u00edsmica - Migration. O processo de migra\u00e7\u00e3o s\u00edsmica pode ser obtido atrav\u00e9s de v\u00e1rios m\u00e9todos, conforme resumido por KR\u00dcGER (2012) na Figura 2. E cada um desses m\u00e9todos acabam pertencendo a uma categoria, conforme descrito no artigo de Gray et al. (2001) em um resumo hist\u00f3rico sobre modelagens e migra\u00e7\u00f5es s\u00edsmicas. O \u00faltimo autor descreve que a migra\u00e7\u00e3o por tempo, Time migration, \u00e9 executada construindo previamente um campo de velocidade que estima e avalia em cada ponto da imagem, o tempo necess\u00e1rio \u00e0 onda ir do emissor ao receptor, considerando as reflex\u00f5es dos obst\u00e1culos de \u00e2ngulos pr\u00f3ximos ao perpendicular do emissor. Esses objetos perpendiculares s\u00e3o os v\u00e1rios n\u00edveis de camadas do solo, e o tempo medido considerar o efeito NMO/stack (Normal Moveout), que \u00e9 um procedimento para compensar a dist\u00e2ncia entre emissores e os diferentes receptores, considerando um mesmo ponto no subsolo. J\u00e1 na migra\u00e7\u00e3o por profundidade, Gray et al. (2001) descreve que o campo n\u00e3o \u00e9 de velocidade como no m\u00e9todo anterior, mas sim de intervalos constru\u00eddos por m\u00e9dias de velocidades que podem ser medidas pelo ge\u00f3logo no local, usando equipamentos e t\u00e9cnicas distintos para apresentar resultados mais pr\u00f3ximos das coordenadas reais do subsolo. No entanto, a migra\u00e7\u00e3o por profundidade \u00e9 mais custosa do que a migra\u00e7\u00e3o por tempo, e as an\u00e1lises s\u00e3o interpretadas com \u00eanfase nas frequ\u00eancias e no tempo, com a precis\u00e3o da dist\u00e2ncia entre a superf\u00edcie e as camadas do subsolo, em segundo n\u00edvel de import\u00e2ncia.\nnas imagens geradas em superf\u00edcies irregulares. Este m\u00e9todo, no entanto, \u00e9 mais custoso computacionalmente, exigindo uma massa de dados em seu processamento bem maior que o m\u00e9todo de Kichhoff e, por conseguinte, mais recursos computacionais.\nO m\u00e9todo de Kirchhoff, que \u00e9 menos custoso, gera resultados n\u00e3o t\u00e3o precisos para regi\u00f5es subterr\u00e2neas onde as camadas de rocha n\u00e3o s\u00e3o regulares e est\u00e3o situadas a altas profundidades, como no pr\u00e9-sal. Panetta et al. (2007) faz refer\u00eancia aos problemas de interfer\u00eancia e ru\u00eddos no imageamento.\nPor fim, Gray et al. (2001) descreve que melhores resultados s\u00e3o obtidos ao reverter o processo de an\u00e1lise, usando diferen\u00e7as finitas, por onde o problema e abordado da perspectiva inicial aos receptores. Assim o algoritmo de RTM \u00e9 apresentado como op\u00e7\u00e3o valiosa quando o foco \u00e9 a qualidade do resultado, ao mesmo tempo em que demanda de um relevante esfor\u00e7o computacional Medeiros (2013). O algoritmo RTM em particular \u00e9 descrito com mais detalhes na se\u00e7\u00e3o 4.\nFigura 1 - Prospec\u00e7\u00e3o de petr\u00f3leo e g\u00e1s natural.\nRochas imperme\u00e1veis\nSeismic Depth Migration\nMarmousi Dataset\nAquisi\u00e7\u00e3o s\u00edsmica\nImagem\nNavio de pesquisa s\u00edsmica\nCanh\u00e3o de ar\nHidrofones\nCamadas sedimentares!1\nOndas Refletidas\nsolo oce\u00e1nico\nFonte: Imagem de Aquisi\u00e7\u00e3o s\u00edsmica baseada em similar encontrada em: Aquisi\u00e7\u00e3o... (2016); Marmousei Dataset: KR\u00dcGER (2012).\nFigura 2 - Modelagem e migra\u00e7\u00e3o s\u00edsmica - M\u00e9todos.\n\u2022\tPDE \u2014 Partial Dierential Equations\n\u2022\tWE \u2014 Wave Equation\nFonte: KR\u00dcGER (2012).\n2.2\tOpenCL\nOpen Computing Language, ou OpenCL, \u00e9 um padr\u00e3o de linguagem para c\u00e1lculos que pode ser usado em diferentes plataformas, e \u00e9 mantido por um cons\u00f3rcio chamado Khronos Group, ao qual fazem parte v\u00e1rias empresas como: Altera, AMD, Apple, Intel, Nvidia e Xilinx. Sua linguagem \u00e9 baseada em C99 (ISO/IEC 9899:1999) e sua API permite controlar dispositivos heterog\u00eaneos com \u00eanfase em algumas formas de paralelismo. Desta forma \u00e9 poss\u00edvel portar o c\u00f3digo para diferentes arquiteturas de processadores como CPUs, GPUs, DSPs e FPGAs.\nO c\u00f3digo necess\u00e1rio para usar esses dispositivos de c\u00e1lculo \u00e9 dividido em duas partes, o c\u00f3digo do Host e o c\u00f3digo do Kernel. O c\u00f3digo do Host \u00e9 respons\u00e1vel por instanciar, configurar e controlar os dispositivos atrav\u00e9s de uma API, e tamb\u00e9m instanciar os dados que ser\u00e3o enviados e recebidos para o dispositivo durante a execu\u00e7\u00e3o. Portanto o c\u00f3digo do programa \u00e9 escrito em C com as extens\u00f5es \u201c[.c]\u201d e \u201c[.h]\u201d, onde podemos obter informa\u00e7\u00f5es sobre a plataforma e os dispositivos que a API est\u00e1 acessando. Desta forma, com as informa\u00e7\u00f5es acessadas, podemos alocar os dados em buffers de mem\u00f3ria que em seguida ser\u00e3o transferidos para o dispositivo. J\u00e1 o c\u00f3digo do Kernel recebe os dados dos buffers e os envia para cada unidade de processamento, conforme programado no c\u00f3digo de extens\u00e3o \u201c[cl]\u201d, que possui os m\u00e9todos a serem executados no dispositivo. Esse c\u00f3digo deve levar em conta o paralelismo intr\u00ednseco da arquitetura do dispositivo. Ao final do processamento o host pode fazer a leitura dos resultados no dispositivo. Esse controle\ntamb\u00e9m pode ser escrito por chamadas de eventos na API.\nPara o OpenCL, cada dispositivo possui um conjunto de unidades de processamento, e dentro de cada unidade, um conjunto de elementos de processamento (PEs, Figura 3). Cada PE \u00e9 respons\u00e1vel por executar uma Thread. Esses dois n\u00edveis compartilham quatro n\u00edveis hier\u00e1rquicos de mem\u00f3ria: Global, Read-only, local e private (KHRONOS.ORG).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 3 - OpenCL - Computer Device.\nFonte: Autor.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u2022\tGlobal Data \u00e9 uma regi\u00e3o de mem\u00f3ria compartilhada para todos os PE, possuindo uma maior lat\u00eancia.\n\u2022\tO Read-only pode ser lido por todos os elementos, assim como o Global Data, e \u00e9 escrito apenas pelo Host, possui uma menor lat\u00eancia do que a Global, apesar de estar no mesmo n\u00edvel.\n\u2022\tA Local Data \u00e9 compartilhada dentro de um mesmo grupo de PE, servindo para compartilhar valores sem uma grande penalidade no tempo de acesso.\n\u2022\tA Private Data s\u00e3o os registradores de cada PE e com a menor lat\u00eancia no tempo de acesso, e sem penalidade de concorr\u00eancia.\nAo se estruturar o c\u00f3digo do Host e do Kernel \u00e9 importante considerar as estruturas de divis\u00e3o na mem\u00f3ria e nas unidades de processamento de cada dispositivo, adequando o c\u00f3digo ao paralelismo do problema. No Kernel, al\u00e9m desta hierarquia de mem\u00f3ria, temos os comandos que auxiliam na sincroniza\u00e7\u00e3o das threads ao acesso de mem\u00f3ria em n\u00edveis compartilhados, como barriers.\nPortable Intermed\u00edate Representation) (KHRONOS.ORG). Assim \u00e9 poss\u00edvel entregar um c\u00f3digo pr\u00e9-compilado para ser executado na LLVM. Esse problema pode ser evitado nos FPGAs devido ao pr\u00f3prio processo de configura\u00e7\u00e3o do dispositivo, como ser\u00e1 demostrado na se\u00e7\u00e3o 4.4.\nPara a execu\u00e7\u00e3o do OpenCL em FPGAs, o c\u00f3digo do kernel pode sofrer adi\u00e7\u00e3o de macros e de atributos para serem usados durante a s\u00edntese, auxiliando a configura\u00e7\u00e3o do paralelismo. A s\u00edntese do c\u00f3digo \u00e9 feita em algumas etapas anteriores a execu\u00e7\u00e3o, onde o c\u00f3digo \u00e9 convertido para uma linguagem de descri\u00e7\u00e3o de Hardware, HDL, e tamb\u00e9m \u00e9 adicionado um wrapper para comunica\u00e7\u00e3o com os barramentos e mem\u00f3ria. Por fim, \u00e9 gerado um bitStream que configurar\u00e1 o FPGA. Esse processo de otimiza\u00e7\u00e3o ser\u00e1 abordado por completo na se\u00e7\u00e3o 4.4.\n2.3\tArquiteturas FPGA e GPU\n2.3.1\tFPGA - Field Programmable Gate Array\nDispositivos l\u00f3gicos reconfigur\u00e1veis, como os Field programmable Gate Arrays (FPGAs), s\u00e3o circuitos eletr\u00f4nicos integrados, que podem ter sua l\u00f3gica modificada, reconfigurada pelo usu\u00e1rio, em fun\u00e7\u00e3o do algoritmo a ser implementado em seu n\u00facleo. Este comportamento \u00e9 bem diferente da grande maioria dos circuitos tradicionais, como GPUs e CPUs, que embora possam ser programados, n\u00e3o podem ter seus circuitos internos customizados para outras fun\u00e7\u00f5es diferentes daqueles previamente estabelecidas em seu projeto original.\nOs FPGAs s\u00e3o compostos por uma s\u00e9rie de componentes, tais como: blocos l\u00f3gicos, bancos de mem\u00f3ria, cores de microprocessadores, os quais, atrav\u00e9s de uma malha de roteamento podem ser utilizados, de acordo com a funcionalidade desejada pelo projetista. Esses blocos, ou c\u00e9lulas l\u00f3gicas, recebem o nome de CLBs (Configurable Logic Block) que s\u00e3o conectados por v\u00e1rias matrizes de roteamento at\u00e9 os blocos que fazem a entrada/sa\u00edda (input/output), os IOB. Al\u00e9m desses, temos os blocos que s\u00e3o respons\u00e1veis por fazer conex\u00f5es e podem receber v\u00e1rios nomes como crossbar switch, cross-point switch, matrix switch e outros, dependendo da tecnologia e do fabricante.\nNeste trabalho usamos a placa 385-A7 da Nallatech, a qual possui como elemento principal de processamento o FPGA Stratix V GX A7 da Altera. Sua arquitetura \u00e9 an\u00e1loga ao explicado acima, com algumas diferen\u00e7as discutidas a seguir.\nNa Stratix V os CLB s\u00e3o chamados de LAB - Logic Array Block - (Mostrados na Figura 4 como o nome de Core Logic Fabric). Usando a metade de um LAB pode-se formar uma MLAB ou Memory LAB.\nFigura 4 - Arquitetura Stratix V.\nCora Logic Fabric\nVariable-Precision DSP Blocks\nM2\u00dcK Internal\nMemory Blocks\nFractional PLLs\nEmbedded HerdCopy Block: PCI Express Gen J, Gen?, Genl\nHand IP Per Transceiver:\nJGJfG PCS, 10G Ethernet PCS, Interlaken PCS\nHigh-Speed\nSerial TianSCelVBrt\nFonte: Altera (2010a)\ns\u00e3o compostos basicamente de duas LUTs, dois somadores e quatro registradores, Figura 5. Um ALM possui quatro modos de opera\u00e7\u00e3o: Normal, Extended LUT, Arithmetic e Shared arithmetic. No modo normal \u00e9 poss\u00edvel fazer combina\u00e7\u00f5es das entradas das duas LUTs, dividindo em duas fun\u00e7\u00f5es separadas ou usando como uma mesma fun\u00e7\u00e3o. J\u00e1 no modo Extended LUT, quando as sete primeiras entradas n\u00e3o fazem o uso dos registradores, o oitavo pino pode fazer uso direto de um registrador. No modo Arithmetic s\u00e3o usados dois conjuntos de quatro entradas para os dois somadores, e \u00e9 poss\u00edvel fazer Carry Chain entre os ALMs. No modo Shared Arithmetic \u00e9 poss\u00edvel usar o somador com tr\u00eas entradas em uma LUT, resultando em uma fun\u00e7\u00e3o de seis entradas, tamb\u00e9m \u00e9 poss\u00edvel usar esse modo em Carry Chain (Altera, 2010b).\nAl\u00e9m das ALMs temos outros blocos que auxiliam ao montar as fun\u00e7\u00f5es logicas, como os DSP que s\u00e3o respons\u00e1veis por c\u00e1lculos de ponto flutuante de 9, 18, 27 e 36-bit, tamb\u00e9m \u00e9 poss\u00edvel somar, subtrair e acumular opera\u00e7\u00f5es de 64-bit; os Fractional PLLs que fazem a sincronia dos pulsos de clock, podem dividir ou multiplicar os pulsos; M20k Memory s\u00e3o blocos dedicados ao armazenamento de dados entre as opera\u00e7\u00f5es. Por fim, temos os blocos de interface I/O: PciExpress, Transceiver e Serial.\nAbaixo segue a tabela de Especifica\u00e7\u00f5es do Stratix V.\nFigura 5 - ALM - Adaptive Logic Module.\nTabela 1 - Stratix V - Especifica\u00e7\u00f5es\nProduct Line\t5SGXA7\nLEs (K)\t622\nALMs\t234.720\nRegisters\t938.880\nM20K memory blocks\t2.560\nM20K memory (Mb)\t50\nMLAB memory (Mb)\t7.16\nVariable-precision DSP blocks\t256\n18 x 18 multipliers\t512\n2.3.2\tGPU - Graphics Processing Unit\nas GPGPU - General Purpose GPU, que \u00e9 justamente para o uso destes processadores gr\u00e1ficos para al\u00e9m de seu prop\u00f3sito inicial, como simula\u00e7\u00f5es de modelos cient\u00edficos, redes neurais, criptografia e outros. Hoje \u00e9 poss\u00edvel contratar servidores virtualizados com acesso a essas GPGPUs para serem utilizadas em diversas aplica\u00e7\u00f5es. Tamb\u00e9m podemos citar a grande evolu\u00e7\u00e3o desses dispositivos em sistemas embarcados e aparelhos m\u00f3veis.\nEssa evolu\u00e7\u00e3o influenciou na arquitetura desses processadores gr\u00e1ficos, privilegiando opera\u00e7\u00f5es vetoriais atrav\u00e9s de instru\u00e7\u00f5es SIMD - Single Instruction, Multiple Data - que s\u00e3o processadas em grupos com uma determinada quantidade de unidades de processamento ou PEs (Figura 3). Na Nvidia essas unidades s\u00e3o chamadas de \u201cCuda Cores\u201d (Figura 6) e na AMD levam o nome de \u201cCompute Unit\u201d (Figura 7). S\u00e3o elas que executam threads nas GPGPUs. Outro aspecto dessa especializa\u00e7\u00e3o aconteceu na arquitetura de mem\u00f3ria, que foi modificada para trabalhar com uma maior quantidade de dados, as GDDRs. Atualmente, existem mem\u00f3rias GDDRs que trabalham com 256 bits at\u00e9 512-bits de barramento, ou seja, podem ser acessados o equivalente a 16 valores ponto-flutuante de precis\u00e3o simples de 32 bits. Hoje as GDDRs est\u00e3o na sua quinta vers\u00e3o; s\u00e3o nessas mem\u00f3rias que os buffers enviados pelo host ser\u00e3o armazenados.\nFigura 6 - Fermi Streaming Multiprocessor (SM).\nDispatch Unit\nWarp\nFermi Streaming Multiprocessor (SM)\nFonte: Nvidia (2010)\nCore\tCore\nCore\tCore\nCore\tCore\nCore\tCore\nCore\tCore\nCore\tCore\nCore\tCore\nCore\tCore\nFigura 7 - Graphics Core Next \"GCN 1.0\"AMD Southern Islands Series Block Diagram.\n&amp;ALU\nvALU\nvALU\nvALU\nDPP Array\nCompute Unit\nvGPR\nsALU\nvALU\nvGPR\nProgram Counter\nProgram Counter\n\u2018Discrete GPU - Physical Device Memory; APU - Region of system for GPU direct access\nHost CPU\nHost Application Compute Driver\nSystem Memory\nCommands\nInstructions and Constants\nInputs and Outputs\nSourthern Islands Device Memory *\nCommands\nInstructions and Constants\nInputs and Outputs\nReturn Buffers\nPrivate Data\nJVIMIO ACCESS\nSouthern Islands Series Processor\nConstant Cache\nCompute Unit\nCompute Unit\nProgram Counter\nProgram\nCounter\nUltra-Threaded Dispatch Processor\nI\nCommand Processors\nFonte: AMD - Advanced Micro Devices, Inc. (2012)\n^3\tTrabalhos Relacionados\nOs trabalhos relacionados a seguir foram selecionados pela similaridade de algoritmo, hardware ou t\u00e9cnica proposta. O primeiro artigo Evaluation of successive CPUs/APUs/G-PUs based on an OpenCL finite difference stencil (CALANDRA et al., 2013) faz uso de OpenCL para implementar o algoritmo de diferen\u00e7as finitas. O segundo artigo Synthesis of Platform Architectures from OpenCL Programs (OWAIDA et al., 2011), demonstra outra forma de se sintetizar c\u00f3digos em OpenCL para FPGA. O terceiro artigo Analyzing the energy-efficiency of sparse matrix multiplication on heterogeneous systems: A comparative study of GPU, Xeon Phi and FPGA (GIEFERS et al., 2016), faz uso de algoritmos de multiplica\u00e7\u00e3o de matrizes com hardware de GPU e FPGA similares a este trabalho. O artigo Scaling Reverse Time Migration Performance through Reconfigurable Dataflow Engines (WEBER et al., 2011), faz uso de uma dataflow engine an\u00e1logo ao proposto neste trabalho. E por fim, o artigo Comparing Hardware Accelerators in Scientific Applications: A Case Study (FU et al., 2014) faz um comparativo com hardwares similares a essa disserta\u00e7\u00e3o.\n3.1\tEvaluation of successive CPUs/APUs/GPUs based on an OpenCL finite difference stencil\nNo artigo de Calandra et al. (2013), temos uma avalia\u00e7\u00e3o do algoritmo de diferen\u00e7as finitas 3D que foi implementado em OpenCL e faz parte do RTM. O artigo faz uso de tr\u00eas arquiteturas, CPU, GPU discreta e GPU integradas com foco em APUs (Accelerated Processing Unit). As APUs s\u00e3o SOCs com CPU e GPU integrados e tem a capacidade de compartilhar mem\u00f3ria, evitado assim, a transfer\u00eancia dos buffers entre as mem\u00f3rias da CPU e da GPU. Cada um desses tr\u00eas tipos de dispositivos usou a melhor implementa\u00e7\u00e3o considerando uma m\u00e1scara de opera\u00e7\u00e3o de 8o ordem, com uma estrat\u00e9gia de implementa\u00e7\u00e3o vetorizada em Z similar ao deste trabalho.\nj\u00e1 a GPU discreta obteve um valor de 256 GFlop/s. Esses valores foram obtidos em 10 execu\u00e7\u00f5es seguidas, mais o tempo de transfer\u00eancia para a mem\u00f3ria principal.\nNa conclus\u00e3o o autor comenta que o fato da n\u00e3o exist\u00eancia do gargalo na transfer\u00eancia de dados atrav\u00e9s da interface PCI Express, favorece o desempenho das APUs. No entanto, a taxa de transfer\u00eancia entre a mem\u00f3ria e a GPU da APU e a quantidade de mem\u00f3ria, ainda s\u00e3o menores do que as encontradas nas GPUs dedicadas. Portanto, o desempenho ainda \u00e9 maior nas GPUs dedicadas, por exemplo, a HD 7970 pode fazer mais de 500 Gflops (CALANDRA et al., 2013). N\u00e3o \u00e9 feito nenhuma avalia\u00e7\u00e3o de consumo el\u00e9trico nos testes, por\u00e9m, o autor cita que pelo TDP em uma propor\u00e7\u00e3o de 3 APUs para uma GPU dedicada, pode haver uma melhor raz\u00e3o entre consumo e desempenho.\nO artigo n\u00e3o apresenta um dispositivo de FPGA, e a GPU HD 7970 - Tahiti \u00e9 do mesmo modelo que usamos neste trabalho.\n3.2\tSynthesis of Platform Architectures from OpenCL Programs\nOWAIDA et al., abordam outra forma de se fazer a s\u00edntese para um FPGA a partir de um c\u00f3digo OpenCL. O Silicon-OpenCL (SOpenCL) \u00e9 uma extens\u00e3o apresentada pelo autor que configura o FPGA para dar suporte a uma LLVM - Low Level Virtual Maquine. Portanto, \u00e9 gerado um compilador que interpreta o c\u00f3digo OpenCL e o transforma em um c\u00f3digo intermedi\u00e1rio (IR - Intermediate Representation) que ser\u00e1 executado por essa LLVM.\nA avalia\u00e7\u00e3o experimental \u00e9 feita com seis aplica\u00e7\u00f5es escritas em OpenCL e C, em tr\u00eas configura\u00e7\u00f5es distintas Ca, Cb, Cc. A configura\u00e7\u00f5es Ca ocupa o m\u00ednimo de recursos (FUs e I/O), a Cc \u00e9 a que usa o m\u00e1ximo de recursos, e por fim, a Cb \u00e9 o intermedi\u00e1rio entre as duas configura\u00e7\u00f5es anteriores. Nos resultados ele apresenta um gr\u00e1fico para cada uma das seis aplica\u00e7\u00f5es, apresentando o tempo de execu\u00e7\u00e3o e o clock resultante de cada s\u00edntese, para cada configura\u00e7\u00e3o. No caso das tr\u00eas primeiras aplica\u00e7\u00f5es, n\u00e3o h\u00e1 uma grande diferen\u00e7a no tempo de execu\u00e7\u00e3o e no clock obtido. Isso se deve ao fato de serem simples benchmarks de adi\u00e7\u00e3o, convolu\u00e7\u00e3o e multiplica\u00e7\u00e3o vetorial. Assim o autor demostra que n\u00e3o h\u00e1 grandes perdas ao se adotar o SOpenCL nestes casos, e em seguida, nas tr\u00eas \u00faltimas aplica\u00e7\u00f5es, fica demostrado que na maioria dos casos h\u00e1 uma melhora no tempo de execu\u00e7\u00e3o, quando o SOpenCL e a estrutura de cache proposta s\u00e3o utilizados.\n3.3\tAnalyzing the energy-efficiency of sparse matrix multiplication on heterogeneous systems: A comparative study of GPU, Xeon Phi and FPGA\nGiefers et al. (2016) faz an\u00e1lise de performance e efici\u00eancia el\u00e9trica em quatro sistemas: CPU, Acelerador com m\u00faltiplos CPUs, GPUs e FPGAs usando respectivamente Intel Xeon E5-2630v2, Intel Xeon Phi 5110P, Nvidia Tesla K20 GK110 e Nallatech 385N_A7. Neste \u00faltimo caso foi feita a s\u00edntese usando o SDK OpenCL da Altera. E para executar essa an\u00e1lise foram usados dois tipos de algoritmos de multiplica\u00e7\u00e3o de matrizes o SpMV (Sparse matrix-vector) e SpMM (Sparse matrix-matrix), com dados obtidos de um subgrupo de 181 matrizes de uma cole\u00e7\u00e3o chamada UF sparse matrix collection.\nO autor faz men\u00e7\u00e3o a limita\u00e7\u00e3o ao se transferir dados pela Pci Express, o que favorece a CPU por n\u00e3o depender desse fator para sua execu\u00e7\u00e3o. Mas quando eliminado o custo da transfer\u00eancia de dados, a GPU e o Xeon Phi demostram um melhor desempenho do que CPU e o FPGA. No entanto, o FPGA foi notoriamente superior ao se analisar a efici\u00eancia energ\u00e9tica (Gflops/W).\n3.4\tScaling Reverse Time Migration Performance through Reconfigurable Dataflow Engines\nNa refer\u00eancia (FU et al., 2014), o autor explica que a explora\u00e7\u00e3o de petr\u00f3leo e g\u00e1s exigem algoritmos de grande demanda computacional, e devido aos limites na taxa de transfer\u00eancia das memorias, \u00e9 dif\u00edcil escalar a desempenho em geral, mesmo aumentando o n\u00famero de cores, pois o acesso a mem\u00f3ria aumenta de forma geom\u00e9trica. Assim ele demostra qual \u00e9 a efici\u00eancia obtida ao se adotar os FPGAs, projetados com \u00eanfase no fluxo de dados (data-flow engine).\nPara a avalia\u00e7\u00e3o de desempenho ele usa dois modelos de FPGA: MAX2, MAX3, comparando com um sistema de dois processados Intel - Sandy Bridge, cada um com 8 n\u00facleos, totalizando 16. Na CPU foi feita uma vers\u00e3o do algoritmo em OpenMP, assim foi obtido um speedup de 4.5x em rela\u00e7\u00e3o a CPU e uma efici\u00eancia no consumo de energia de 10.2x. No entanto, esse artigo n\u00e3o faz nenhuma compara\u00e7\u00e3o com GPUs.\n3.5\tComparing Hardware Accelerators in Scientific Applications: A\nCase Study\n9400m e o FPGA Virtex-4 LX160 Weber et al. (2011) utilizando as linguagens OpenCL, CUDA, Brook+ e C++, conforme a disponibilidade no dispositivo alvo. A implementa\u00e7\u00e3o do FPGA foi realizada em VHDL.\nOs autores comentam que o desempenho da Randeon 4879 n\u00e3o foi satisfat\u00f3rio quando comparado com as outras GPUs, tanto na linguagem destinada a plataforma, quanto usando o OpenCL. Eles acreditam que esse fato esteja ligado ao n\u00e3o suporte, na \u00e9poca, do n\u00edvel de mem\u00f3ria local, restando apenas o n\u00edvel global. Assim quando o n\u00famero de part\u00edculas usadas na simula\u00e7\u00e3o passa de 104, a Nvidia GTX 285 se mostrou superior no desempenho. Tamb\u00e9m demostra que o fato da linguagem Book+ usar o cache de textura, n\u00edvel local de mem\u00f3ria, da Firestream 9170 contribuiu para uma diferen\u00e7a significante no resultado final.\nEles ainda comentam que a Radeon 4870 possui uma configura\u00e7\u00e3o de hardware superior. Eles ainda afirmam que, com a exce\u00e7\u00e3o do VHDL, as linguagens forneceram uma facilidade no desenvolvimento e na depura\u00e7\u00e3o, mas esse fato citado ja \u00e9 superado pelas ferramentas atuais, tanto da Altera quanto da Xilinx. Os autores tamb\u00e9m comentam que devido as essas dificuldades, o tempo de desenvolvimento em VHDL levou aproximadamente um ano. E por fim, eles comentam sobre a facilidade de sintaxe devido as abstra\u00e7\u00f5es para gerenciar threads, tanto no OpenCL, quanto em CUDA, junto \u00e0 similaridade de suas sintaxes. E ainda afirmam que existe uma diferen\u00e7a de desempenho que favorece o uso de CUDA sobre OpenCL, em dispositivos da Nvidia.\n3.6\tConclus\u00f5es\nN\u00e3o foi encontrada, nas principais publica\u00e7\u00f5es da \u00e1rea nenhuma abordagem similar, e infelizmente, n\u00e3o foi poss\u00edvel a discuss\u00e3o diretamente a trabalhos relacionados com essa implementa\u00e7\u00e3o, em OpenCL, do algoritmo para modelagem e migra\u00e7\u00e3o computacional RTM 3D. Sendo assim, abordou-se trabalhos que tratam de exemplos que usam OpenCL em arquiteturas de interesse da disserta\u00e7\u00e3o, e seus respectivos desempenhos, em classes de problemas que requerem processamento de alto desempenho.\nA Tabela 2 \u00e9 utilizada apenas para referenciar os trabalhos nas tabelas a seguir. As Tabela 3 e 4 apresentadas mostram as arquiteturas utilizadas em cada trabalho descrito acima, e as an\u00e1lises que foram realizadas em cada um destes respectivamente, em termos de arquitetura. Nesta disserta\u00e7\u00e3o a \u00eanfase ser\u00e1 dada a tr\u00eas itens importantes quando tratamos de FPGAs: o speedup alcan\u00e7ado, por se tratar da solu\u00e7\u00e3o de problemas que requerem um alto desempenho, a efici\u00eancia energ\u00e9tica, medida aqui em termos de dissipa\u00e7\u00e3o de pot\u00eancia e os limites encontrados nestes dispositivos em fun\u00e7\u00e3o dos recursos de l\u00f3gica associada a cada componente.\nmostrar o qu\u00e3o ainda \u00e9 deficiente a gera\u00e7\u00e3o de sistemas descritos em OpenCL para FPGAs, em termos de desempenho, quando comparado a GPUs. Por outro lado, pode-se ver que \u00e9 poss\u00edvel se obter, com pequenos ajustes no c\u00f3digo do programa em OpenCL, um aumento expressivo de ganho de desempenho em FPGAs. Tamb\u00e9m \u00e9 importante ressaltar, nesta discuss\u00e3o entre arquiteturas, o ganho relativo em dissipa\u00e7\u00e3o de pot\u00eancia nos FPGAs em rela\u00e7\u00e3o a CPUs e GPUs. Neste sentido, como uma segunda contribui\u00e7\u00e3o faz-se tamb\u00e9m uma an\u00e1lise do desempenho relativo das arquiteturas por Watt dissipado, desta feita tendo um problema RTM 3D como exemplo. Esta m\u00e9trica \u00e9 importante devido a necessidade cada vez maior de se economizar energia em Data Centers.\nTabela 2 - Trabalhos - \u00cdndice\n\tTrabalhos\n1\tEvaluation of successive CPUS/APUS/GPUS based on an OpenCL finite difference stencil\n2\tSynthesis of platform architectures from OpenCL programs\n3\tAnalyzing the energy-efficiency of sparse matrix multiplication on heterogeneous systems: A comparative study of GPU, Xeon Phi and FPGA\n4\tScaling reverse time migration performance through reconfigurable dataflow engines\n5\tComparing hardware accelerators in scientific applications: a case study\n6\tEsta Disserta\u00e7\u00e3o\nTabela 3 - Trabalhos - Hardwares\n\tCPU\tGPU\tFPGA\tAPU\tXeon Phi\n1\tx\tx\t-\tx\t-\n2\t-\t-\tx\t-\t-\n3\tx\tx\tx\t-\tx\n4\t-\t-\tx\t-\t-\n5\tx\tx\tx\t-\t-\n6\tx\tx\tx\t-\t-\nTabela 4 - Trabalhos - Caracter\u00edsticas\n\tSpeedup\tPower Efficiency\t\u00c1rea - FPGA\tT\u00e9cnica\n1\tx\tx\t-\tMem\u00f3ria compartilhada -Pcie x Intregrated GPU\n2\tx\t-\t-\tSOpenCL (Silicon-OpenCL)\n3\tx\tx\tx\tSpMV, SpMM\n4\tx\tx\tx\tDataflow-Oriented (DFE)\n5\tx\t-\t-\tQUANTUM MONTE CARLO\n6\tx\tx\tx\tRTM 3D OpenCL FPGA\n^4 Implementa\u00e7\u00e3o\nNeste cap\u00edtulo ser\u00e1 demostrado como foi desenvolvida a etapa de modelagem s\u00edsmica do algoritmo RTM 3D, explicado em detalhes na se\u00e7\u00e3o 4.1, e sua implementa\u00e7\u00e3o em GPU e FPGA s\u00e3o discutidas na se\u00e7\u00e3o 4.2 e se\u00e7\u00e3o 4.3. E por fim, \u00e9 demonstrado como o c\u00f3digo \u00e9 sintetizado no arquivo que ser\u00e1 aplicado ao FPGA se\u00e7\u00e3o 4.4.\n4.1\tO algoritmo RTM 3D\nA prospec\u00e7\u00e3o de petr\u00f3leo ou g\u00e1s natural representa a procura por bols\u00f5es de menor densidade nas camadas do subsolo e independe se a pesquisa \u00e9 feita em solo ou em meio l\u00edquido (mar, oceano, rio, etc.). Para detectar esses bols\u00f5es no subsolo um pulso s\u00edsmico \u00e9 gerado, fazendo ondas se propagarem no meio at\u00e9 serem refletidas ou refratadas de volta aos sensores. Esses sensores podem ser de dois tipos: geofones ou hidrofones; para a terra ou mar respectivamente. As informa\u00e7\u00f5es desses sensores ser\u00e3o usadas para gerar um modelo de refer\u00eancia, com a participa\u00e7\u00e3o de ge\u00f3logos em etapas do processo para gerar as entradas do algoritmo de RTM que resulta em um mapeamento dos poss\u00edveis locais das jazidas.\nO modelo de refer\u00eancia \u00e9 produzido a partir da equa\u00e7\u00e3o de onda ac\u00fastica/el\u00e1stica para, de forma reversa ao tempo, ir comparando com os sinais detectados pelos sensores. E ent\u00e3o formar o imageamento das camadas de diferentes densidades no subsolo. O algoritmo \u00e9 baseado na equa\u00e7\u00e3o de onda abaixo:\nThe laplace-transformed homogeneous 3D acoustic wave equation (SHIN; SHIN;\nCALANDRA, 2016) (LIU et al., 2013):\ns2\t2 d2p d2p d2p\nI2 p = v ~dX + dy2 + dz2\n(4.1)\nOnde: s - Positive Laplace damping constant; c - Acoustic wave velocity; p - Pressure wave field.\nordem no tempo, pois os valores atuais e o valor da matriz na \u00faltima rodada tamb\u00e9m entram na equa\u00e7\u00e3o. Assim, \u00e9 necess\u00e1ria uma matriz para os valores de pontos no instante atual ou CPF (Current Pressure Field) e, outra de mesmo tamanho para o instante anterior ou PPF (Previous Pressure Field). Al\u00e9m delas, \u00e9 necess\u00e1ria a matriz VEL que cont\u00e9m o modelo de velocidades. Os novos valores de campo de press\u00e3o calculados atrav\u00e9s dessas tr\u00eas matrizes s\u00e3o armazenados na matriz de campo de press\u00e3o seguinte, denominada NPF (Next Pressure Field). E para operar a propaga\u00e7\u00e3o, \u00e9 feita uma varredura de m\u00e1scara (Stencil) na matriz de CPF como \u00e9 demostrado na Figura 8, junto com a varredura de cada matriz, que s\u00e3o inicializadas com valores de ponto flutuante com 32 bit. Na Figura 9 o pseudoc\u00f3digo de refer\u00eancia demonstra os valores do c\u00e1lculo e como o valor do Stencil \u00e9 obtido. Por fim, temos um diagrama de execu\u00e7\u00e3o do Host/Device na Figura 10.\nFigura 8 - Stencil e os pontos de VEL, PPF e CPF que resultam no NPF\nFigura 9 - Pseudoc\u00f3digo RTM 3D\n//Loop no tempo\n//radius=2\nfor (i=2;i<dimZ-2;i++) {\nfor(j=2;j<dimY-2;j++) { for (k=2;k<dimX-2;k++) { npf[i][j][k] = (2.0f * cpf[i][j][k] +\n(vel [i] [j ] [k] *\n((coeff[0] * (cpf [i] [j-2] [k]+cpf [i] [j+2] [k]+cpf [i-2] [j] [k] + cpf[i+2] [j] [k]+cpf [i] [j] [k-2]+cpf [i] [j] [k+2])) + (coeff[l] * (cpf [i] [j-1] [k]+cpf[i] [j+1] [k]+cpf [i-1] [j] [k] + cpf[i+l] [j] [k]+cpf[i] [j] [k-l]+cpf[i] [j] [k+1])) + (coeff[2J * cpf [i] [j] [k]) > - ppf [i] [j] [k])>;\nFonte: Baseado no c\u00f3digo apresentado por Medeiros (2013).\nFigura 10 - Diagrama de Execu\u00e7\u00e3o do Host/Device (OpenCL)\nKernel()\nDEVICE\nRTM3D\nInicializa\u00e7\u00e3o da API OpenCL -(Plataforma, Contexto, Kernel)\nInicializa\u00e7\u00e3o dos Buffers da API OpenCL. (Host&lt;-> Device)\nLoop de Execu\u00e7\u00e3o do Kernel (Time Step)\nProfile da execu\u00e7\u00e3o\nLimpeza dos Buffers\nTroca de Buffers\nCPF<-> PPF\nCompara\u00e7\u00e3o com\nRTM3D de\nRefer\u00eancia\nEnvio dos buffers do Host para para o Device\nInicializa\u00e7\u00e3o dos Buffers: PPF, CPF, VEL, Coeff.\nHOST\nFonte: Autor.\n4.2\tC\u00f3digo - GPU\nO c\u00f3digo de OpenCL de GPU foi produzido com base no exemplo de Diferen\u00e7as Finitas disponibilizado pela Nvidia e o c\u00f3digo do Host \u00e9 implementado conforme descrito na sess\u00e3o anterior. No algoritmo para GPU a configura\u00e7\u00e3o do paralelismo \u00e9 definida pela quantidade de workItens em cada workgroup, conforme suportado por cada dispositivo. Esses valores s\u00e3o configurados na etapa de Inicializa\u00e7\u00e3o da API mostrado na Figura 10.\nAp\u00f3s a chamada do Kernel que foi distribu\u00eddo entre os workgroups e workitens, \u00e9 poss\u00edvel realizar a chamada de m\u00e9todos que identificam qual o \u00edndice da thread, em rela\u00e7\u00e3o ao contexto Global, Local e do Item no paralelismo. E com esses \u00edndices \u00e9 poss\u00edvel criar uma janela de execu\u00e7\u00e3o (Figura 11) localizada na mem\u00f3ria local e respons\u00e1vel por compartilhar os valores de um mesmo workgroup. Al\u00e9m da janela, cada thread cria valores privados correspondentes aos valores laterais do Stencil, que est\u00e3o fora da janela.\nFigura 11 - GPU - Exemplo de Varredura pelo Stencil lendo os pontos de CPF\nJanela de execu\u00e7\u00e3o\nVarredura do Stenci\nFonte: Autor.\n\u00c9 importante notar que os valores laterais v\u00e3o ser aproveitados durante o deslocamento em profundidade da thread, eliminado o menor valor em z. E que cada thread e respons\u00e1vel por alimentar o valor atual da janela, obrigando a sincroniza\u00e7\u00e3o ap\u00f3s os deslocamentos e ap\u00f3s alimentar o valor no grupo local.\n4.3\tC\u00f3digo - FPGA\nAo contr\u00e1rio de como ocorre em outras arquiteturas, tais como GPU e CPU, o OpenCL para FPGA n\u00e3o \u00e9 compilado em tempo de execu\u00e7\u00e3o. Ele \u00e9 sintetizado em uma linguagem de descri\u00e7\u00e3o de Hardware (HDL), e dele \u00e9 gerado um bitStream que \u00e9 gravado no FPGA para configur\u00e1-lo. Outro ponto de diverg\u00eancia \u00e9 o c\u00f3digo do dispositivo escrito em OpenCL. Ele n\u00e3o segue a estrutura habitual de se trabalhar com m\u00faltiplas threads divididas em workGroup e workItem, pois se pressup\u00f5e uma fraca depend\u00eancia e concorr\u00eancia ao acesso a mem\u00f3ria. E no caso do algoritmo de RTM, existe a depend\u00eancia dos valores no stencil como explicado na Figura 8, onde os valores dos vizinhos s\u00e3o usados para calcular o valor central no stencil. Assim o adequado foi utilizar-se do modelo de uma \u00fanica thread, onde o paralelismo do c\u00e1lculo \u00e9 obtido atrav\u00e9s da t\u00e9cnica de desenrolar os loops. Essa t\u00e9cnica de codifica\u00e7\u00e3o ao OpenCL (#pragma unroll [n]) permite que o compilador desenrole os loops instanciando um pipeline de hardware executando um determinado n\u00famero de intera\u00e7\u00f5es simultaneamente.\nPara o c\u00e1lculo, o algoritmo lineariza o volume de entrada e desliza atrav\u00e9s de uma janela de varredura na qual a matriz \u00e9 dividida em volumes menores ou maiores. Essa divis\u00e3o sistem\u00e1tica para varredura permite utilizar os valores do stencil alocados na mem\u00f3ria local do FPGA, economizando acessos a mem\u00f3ria global do dispositivo. Esses sub-cubos s\u00e3o de tamanho: 2 * RADIUS * DIMX * DIMY + PAR_POINTS, aonde DIMX e DIMY correspondem as dimens\u00f5es da janela de leitura que devem ser m\u00faltiplos dos PAR_POINTS. Esses valores s\u00e3o multiplicados por duas vezes o valor do RADIUS para acumular quatro camadas na ordenada Z.\nFigura 12 - FPGA - Exemplo de Varredura pelo Stencil lendo os pontos de CPF\nFonte: Autor.\nquantidade \u00e9 igual ao PAR_POINTS, que \u00e9 o n\u00famero correspondente a quantidade de c\u00e1lculo simult\u00e2neo ao se fazer o desenrolar do loop. Quando essa janela chega ao final da coordenada Z, uma nova janela \u00e9 processada at\u00e9 percorrer toda a extens\u00e3o da matriz.\n4.4\tS\u00edntese do c\u00f3digo OpenCL em FPGA\nA s\u00edntese do SDK OpenCL da Altera \u00e9 feita a partir do arquivo .cl, que cont\u00eam o m\u00e9todo Kernel. Ele \u00e9 transformado em seu correspondente Verilog e a ele \u00e9 adicionado um wrapper que far\u00e1 a comunica\u00e7\u00e3o com a camada acima, que \u00e9 um segundo arquivo que faz as liga\u00e7\u00f5es aos arquivos de acesso aos recursos da placa como pinos I/O e controlador de mem\u00f3ria. Assim, o projeto fica constitu\u00eddo de 4 principais arquivos TOP.v que \u00e9 o arquivo principal e mais tr\u00eas que s\u00e3o, board.qsys com os competentes da placa como PciExpress, DMA e os bancos de mem\u00f3ria DDR3; kernel______system.qsys que \u00e9 a vers\u00e3o\nHDL correspondente ao arquivo OpenCL mais o inv\u00f3lucro; e system.qsys que faz a liga\u00e7\u00e3o entre os dois arquivos anteriores. Esses arquivos s\u00e3o projetos do Qsys demonstrados no Ap\u00eandice A.\nTodo esse processo de composi\u00e7\u00e3o \u00e9 feito durante a execu\u00e7\u00e3o do aoc, que \u00e9 respons\u00e1vel por compilar o arquivo .cl que \u00e9 enviado com um dos par\u00e2metros. Tamb\u00e9m \u00e9 necess\u00e1rio informar o nome da placa do FPGA para o qual foi instalado o drive do SDK OpenCL da Altera. Al\u00e9m desses par\u00e2metros podemos informar se vai ser necess\u00e1rio gerar recursos de profile, para acompanhar o desempenho do programa. Ainda \u00e9 poss\u00edvel separar os bancos de mem\u00f3ria, o que for\u00e7a a s\u00edntese a separar o endere\u00e7amento de cada um, e alguns outros par\u00e2metros que controlam as opera\u00e7\u00f5es de ponto-flutuante. Durante a execu\u00e7\u00e3o o programa vai informando as etapas da s\u00edntese e quanto de recurso foi utilizado. A Figura 13 mostra o fluxo para executar a s\u00edntese e a Figura 14 mostra os IPs e os elementos de hardware resultantes.\nAo t\u00e9rmino da execu\u00e7\u00e3o do aoc, um arquivo com extens\u00e3o .aocx \u00e9 gerado, Este arquivo \u00e9 respons\u00e1vel por configurar o FPGA atrav\u00e9s de outro comando, chamado aocl flash. O programa aocl \u00e9 respons\u00e1vel por instalar o drive, configurar e diagnosticar o FPGA.\nFigura 13 - Fluxo de Execu\u00e7\u00e3o SDK OpenCL - Altera.\nHastcpp\tRTM3D.cl\n\u25a0 1 \u25a0 I \u25a0\t\t\nNVIDIA -GTX 580\tAMO - HD 7970 Fonte: Autor.\tNallatech 385 Stratix VA7 FPGA\nTabela 5 - Stratix V - Recursos utilizados\nLEs:\t26.9334%\nFFs:\t18.9825%\nRAMs:\t44.5703%\nDSPs:\t34.3750%\nTotal Util.:\t43.5587%\n4.5\tConclus\u00f5es\nFigura 14 - S\u00edntese OpenCL RTM 3D - \u00c1rvore hier\u00e1rquica\nFonte: Autor.\n^5\tOtimiza\u00e7\u00f5es\nA abordagem direta do uso do c\u00f3digo de GPUs para FPGA apresenta um baixo desempenho devido \u00e0s diferen\u00e7as de arquitetura. Portanto, iremos explicar as otimiza\u00e7\u00f5es necess\u00e1rias para se melhor aproveitar os recursos dispon\u00edveis do OpenCL para FPGAs.\nO primeiro aspecto importante no processo de portabilidade do c\u00f3digo, discutido na se\u00e7\u00e3o 4.2, \u00e9 a configura\u00e7\u00e3o do paralelismo que depende do tamanho de Workitens em cada Workgroup, influenciando na quantidade de recursos utilizados no FPGA. Essa configura\u00e7\u00e3o \u00e9 feita ao se adicionar duas linhas de c\u00f3digo antes do m\u00e9todo do kernel, a primeira \u00e9 o attribute reqd_work_group_size, informando o tamanho do workgroup\nlocal de 32x32 itens. O segundo indica o n\u00famero de opera\u00e7\u00f5es de instru\u00e7\u00f5es simult\u00e2neas, attribute num_simd__work__items, que \u00e9 igual a 8. \u00c9 importante alinhar o n\u00famero de\ninstru\u00e7\u00f5es com a janela local, neste caso 8 * 4 = 32. Foram feitas tentativas de s\u00edntese com tamanhos diferentes, como 64x64 que resulta em falha por falta de \u00e1rea, assim como usar tamanhos menores de 16x16 que resultaram em um menor desempenho. Varia\u00e7\u00f5es no n\u00famero de instru\u00e7\u00f5es SIMD apresentaram o mesmo comportamento.\nOutro aspecto est\u00e1 na caracter\u00edstica de varredura e de thread do algoritmo da GPU, que exige um maior n\u00famero de acesso \u00e0 mem\u00f3ria principal do FPGA, pois o c\u00e1lculo utilizado neste trabalho l\u00ea 15 valores de ponto flutuante de 32 bits de dado, ignorando as constantes que v\u00e3o vir de caches separadas. S\u00e3o 13 valores do Stencil, 1 de velocidade e 1 do PPF, em um total de 480 bits para cada valor calculado no NPF. Esses valores devem passar pelo barramento de 72 bits que o FPGA tem para com os dois bancos de DDR3, determinando um m\u00e1ximo de dois valores 32 bits em cada opera\u00e7\u00e3o de acesso na mem\u00f3ria. Isso constitui em um gargalo, mesmo se consideramos o aproveitamento de valores na mem\u00f3ria local e privada de cada thread na execu\u00e7\u00e3o e o acesso de rajada na mem\u00f3ria do dispositivo.\nPara superar esses dois aspectos foi necess\u00e1rio trazer uma maior quantidade de valores para as regi\u00f5es internas do FPGA, aumentando o tamanho da janela de varredura at\u00e9 cobrir o Stencil por completo. Assim quando um segundo ponto na mesma regi\u00e3o do Stencil for calculado, n\u00e3o ser\u00e1 necess\u00e1rio trazer uma grande quantidade de valores para a\nmem\u00f3ria local. Por\u00e9m existem outras caracter\u00edsticas a serem observadas.\nAinda assim, devemos observar o problema de concorr\u00eancia ao se calcular m\u00faltiplos pontos, pois \u00e9 necess\u00e1rio sincronizar o acesso de cada thread aos valores globais para pr\u00e9-alimentar os valores locais que ser\u00e3o compartilhados no Workgrop usando barrier. Essa sincronia \u00e9 um consumo extra de recursos que pode ser otimizado na execu\u00e7\u00e3o do c\u00f3digo em FPGA, j\u00e1 que h\u00e1 uma depend\u00eancia entre os pontos do mesmo plano, Figura 11.\nPor isso, o sistema de multi-thread \u00e9 substitu\u00eddo por um paralelismo obtido por um desenrolar de loop para processar uma determinada sequ\u00eancia de pontos, em um modelo de dataflow que n\u00e3o faz uso de um indexador matricial para armazenar a janela de varredura. Deste modo, para fazer andar com a janela de execu\u00e7\u00e3o, \u00e9 necess\u00e1rio reindexar todos os pontos da janela, para alimentar os novos pontos de acordo com a quantidade no PAR_POINTs. Contudo, esse processo \u00e9 feito a um custo menor de execu\u00e7\u00e3o, do que o acesso \u00e0 mem\u00f3ria externa. No caso de se manter o indexador matricial, implica como consequ\u00eancia programar uma l\u00f3gica de endere\u00e7os por ponteiros que aumentaria a necessidade de espa\u00e7o em mem\u00f3ria, ou em reaproveitar o \u00edndice no deslocamento, acrescentando l\u00f3gica ao problema e podendo diminuir o desempenho. A quantidade de vezes que esse loop \u00e9 desenrolado \u00e9 configurado pelo n\u00famero de PAR_POINTs.\nEnt\u00e3o para conseguir maximizar o tamanho de \u00e1rea \u00e9 importante descobrir o maior janelamento poss\u00edvel, respeitando o alinhamento SIMD de itens simult\u00e2neos no PAR_POINTs. A configura\u00e7\u00e3o que apresentou o melhor resultado no desempenho foi a de 6 PAR_POINTs, com uma janelamento de 180x180x4, sendo 180 um m\u00faltiplo direto de 6 por uma quest\u00e3o de alinhamento, conforme exemplificado na Figura 12. E o tamanho externo deve seguir a mesma l\u00f3gica, ou seja, ser m\u00faltiplo de 180, e considerar os valores de borda para acomodar o Stencil.\nA quantidade de mem\u00f3ria e o tamanho do problema de entrada \u00e9 mais um aspecto a ser avaliado na otimiza\u00e7\u00e3o de acordo com cada dispositivo. Desta forma a maior janela poss\u00edvel no FPGA deve ser de dimens\u00e3o menor que 360, que neste caso foi de 352 em cada dimens\u00e3o, mais a borda do Stencil, 356. Se considerando as matrizes tridimensionais VEL, PPF, CPF e NPF, o tamanho total aproximado de mem\u00f3ria utilizada no dispositivo \u00e9 de 3563 * 32 bits * 4 Matrizes = 5.775.106.048 bits, que convertidos para bytes resultam em 688 Mb. O pr\u00f3ximo m\u00faltiplo de 180 \u00e9 540, resultando em 2.403 Mb, valor superior ao do menor dispositivo, a GTX 580 com 1.5Gb.\n192x192X4 o erro de placement foi devido \u00e0 adi\u00e7\u00e3o de 32 fifos a mais que n\u00e3o couberam no FPGA por falta de blocos de mem\u00f3ria interna, e devido a localiza\u00e7\u00e3o dessas FIFOs, o seu prov\u00e1vel uso seria na sincroniza\u00e7\u00e3o dos dados ao acessar a controladora de mem\u00f3ria do FPGA para alimentar os valores no janelamento.\nNo decorrer dos testes, o SDK mostrou uma determinada instabilidade, pois cada s\u00edntese desta etapa necessitava de 8hs de execu\u00e7\u00e3o e muitas vezes o processo quebrou por falta de recurso, demostrando poss\u00edvel vazamento de mem\u00f3ria ou falha no algoritmo, que resultava em um uso de mais de 50GB na mem\u00f3ria RAM.\n5.1\tConclus\u00f5es\nTabela 6 - Otimiza\u00e7\u00f5es\nA otimiza\u00e7\u00e3o obtida fica caracterizada pelo tamanho m\u00e1ximo de pontos processados em paralelo, que consideram os aspectos explicados acima e mantiveram o alinhamento s\u00edncrono com a controladora de mem\u00f3ria do FPGA. Assim temos o valor de 6 PAR_POINTs simult\u00e2neos, bem como o maior janelamento poss\u00edvel de s\u00edntese, que \u00e9 igual a 180 nas duas dimens\u00f5es vezes o tamanho do stencil. Esses par\u00e2metros est\u00e3o definidos no c\u00f3digo que est\u00e1 no ap\u00eandice se\u00e7\u00e3o B.2 nas linhas 3, 4 e 6, bem como o tamanho de janelamento que \u00e9 definido na linha 17.\n^6 Resultados\nNesta se\u00e7\u00e3o s\u00e3o mostrados os dados referentes \u00e0 etapa de modelagem s\u00edsmica do algoritmo RTM nas plataformas GPU, CPU e FPGA. Os experimentos est\u00e3o focados principalmente em um comparativo de desempenho para cada arquitetura, no teste de implementa\u00e7\u00e3o de portabilidade do OpenCL e no desempenho da FPGA usando OpenCL ao inv\u00e9s de uma HDL. As implementa\u00e7\u00f5es do algoritmo s\u00edsmico, restrito a etapa de modelagem s\u00edsmica se deu na vers\u00e3o 1.2 do OpenCL. A Tabela 7 mostra as configura\u00e7\u00f5es usadas.\nTabela 7 - Configura\u00e7\u00f5es\nPlaca\tFabricante\tNallatech\tNVIDIA\tAMD\n\tNome\tp385 A7\tGTX 580\tHD 7970\n\tProcessors Units\t6 PAR POINT\t16 SM / 512 cuda cores\t2048 Stream Processors\n\tClock (MHz)\t212,9\t772\t950\n\tTDP (W)\t16\t244\t300\n\tTec. Fabr. (nm)\t28\t40\t28\n\tTransistors (Million)\t14.3M ASIC gates or up to 1.19M logic elements\t3000\t4313\n\tDie Size (mm2)\t-\t520\t352\n\tS.O.\tCentos 6.8\tCentos 6.8\tWin 8.1\nMem\u00f3ria\tTec.\tDDR3\tGDDR5\tGDDR5\n\tBandwidth (GB/s)\t25,6\t192\t264\n\tClock (MHz)\t933\t2004\t1375\n\tBus width (bit)\t72\t384\t384\n\tSize (GB )\t8\t1,5\t3\nOs principais par\u00e2metros de execu\u00e7\u00e3o do algoritmo s\u00e3o as dimens\u00f5es das matrizes. Por uma quest\u00e3o de alinhamento de mem\u00f3ria, que \u00e9 diferente em cada uma das arquiteturas exploradas, foram testados diferentes tamanhos de matrizes, de acordo com a l\u00f3gica programada para as bordas do stencil. O crit\u00e9rio final de escolha para o tamanho das matrizes considerou os valores mais pr\u00f3ximos, que obtivessem o melhor desempenho em cada uma das plataformas. O referencial de desempenho dos resultados est\u00e1 centrado no Throughput com a sa\u00edda em GigaPoints por segundo, calculados a partir da m\u00e9dia de 100 passos do algoritmo.\nA primeira etapa de testes consistiu na verifica\u00e7\u00e3o da portabilidade de c\u00f3digos desenvolvidos em OpenCL. Para isto o c\u00f3digo escrito para GPU foi usado sem altera\u00e7\u00f5es no FPGA, e em seguida foi escrito uma vers\u00e3o que considera as modifica\u00e7\u00f5es para aproveitar melhor os recursos do FPGA. Os resultados obtidos neste primeiro teste s\u00e3o apresentados na Tabela 8.\nTabela 8 - Resultados - Portabilidade OpenCL\nVers\u00e3o\tPlataforma\tC\u00f3d.\tHardware\tThroughput Gpoints/Sec\tTime (s)\nOpenCL 1.2\tFPGA - Altera\tGPU\tNallatech p385 A7\t0,2224\t0,1957\nOpenCL 1.2\tFPGA - Altera\tFPGA\tNallatech p385 A7\t0,5100\t0,0879\nPercebe-se que o desempenho do c\u00f3digo otimizado para a plataforma FPGA \u00e9 cerca de 2,29 vezes melhor do que o c\u00f3digo sem qualquer otimiza\u00e7\u00e3o. Isto mostra que o OpenCL realmente atende a sua proposta de ser uma linguagem port\u00e1vel para ambientes heterog\u00eaneos; no entanto, se a demanda por alto desempenho for cr\u00edtica na aplica\u00e7\u00e3o em quest\u00e3o, \u00e9 fundamental a adapta\u00e7\u00e3o e otimiza\u00e7\u00e3o do c\u00f3digo para a plataforma alvo.\nTabela 9 - Resultados - CPU X GPU X FPGA\nVers\u00e3o\tArq.\tC\u00f3d.\tFab.\tHardware\tThroughput Gpoints/Sec\tTime(s)\tTDP(W)\t(TDP)/(Gp/s)\nOpencl 1.2\tFPGA\tGPU\tAltera\tp385 A7\t0,2224\t0,19570\t25\t112,410\nOpencl 1.2\tFPGA\tFPGA\tAltera\tp385 A7\t0,5100\t0,08790\t16\t31,372\nOpencl 1.2\tGPU\tGPU\tAMD\tHD 7970\t5,8399\t0,00747\t300\t51,371\nOpencl 1.2\tGPU\tGPU\tNvidia\tGTX 580\t0,0579\t0,77858\t244\t54,679\nOpencl 2.0\tCPU\tGPU\tIntel\ti7-2600k\t0,0130\t3,34436\t95\t7307,692\nFigura 15 - Throughput Gpoints/Sec\nTDP / Gpoints/Sec (w/Gps)\tGpoints/Sec\nFonte: Autor.\nFigura 16 - TDP Watts / Gpoints/Sec\nFonte: Autor.\n6.1\tConclus\u00f5es\nO uso de OpenCL para desenvolvimento de projetos em FPGAs parece promissor. Suas vantagens s\u00e3o o tempo de desenvolvimento de projetos e possibilidades de se ter modelos de refer\u00eancia, com c\u00f3digos similares aos de produ\u00e7\u00e3o. Sua curva de aprendizagem \u00e9 r\u00e1pida j\u00e1 que se assemelha a linguagens de alto n\u00edvel compat\u00edveis com outras arquiteturas de mercado. Particularmente para FPGA, embora seja promissora, em suas vers\u00f5es atuais, ajustes de c\u00f3digo ainda precisam ser feitos para se ter desempenho aceit\u00e1vel em aplica\u00e7\u00f5es de alta complexidade e processamento massivo de dados. Um outro aspecto relevante demonstrado aqui \u00e9 que, mesmo apresentando um baixo desempenho computacional em rela\u00e7\u00e3o GPUS, os FPGAs continuam demonstrando vantagens sobre CPUs, e apresentando uma rela\u00e7\u00e3o Gflops/s/w menor que todas as arquiteturas aqui discutidas.\n^7\tConclus\u00e3o\nDurante o desenvolvimento dessa pesquisa e processos de teste, houveram tr\u00eas importantes atualiza\u00e7\u00f5es no SDK OpenCL da Altera. Elas trouxeram melhorias no compilador OpenCL e novos recursos, por exemplo, o suporte a emula\u00e7\u00e3o de execu\u00e7\u00e3o em CPU. O OpenCL vem sendo constantemente trabalhado e melhorado pela comunidade respons\u00e1vel, sua implementa\u00e7\u00e3o \u00e9 cada vez mais eficiente e facilitada. A tend\u00eancia de mercado \u00e9 que a plataforma OpenCL seja cada vez mais competente perante seus concorrentes e se fortale\u00e7a no mercado de HPC.\nNo decorrer dos testes foi evidenciado que o uso consciente dos par\u00e2metros de s\u00edntese dentro do c\u00f3digo OpenCL, devem levar em conta as caracter\u00edsticas das arquiteturas dos dispositivos usados, pois isso interfere diretamente no desempenho. Entre alguns desses par\u00e2metros de s\u00edntese testados, foram o n\u00famero de passos no tempo e o tamanho das dimens\u00f5es de cada matriz, o que impacta diretamente no desempenho. O tamanho final \u00e9 de acordo com o alinhamento mais pr\u00f3ximo ao n\u00famero de pontos a serem processados, pois h\u00e1 diferen\u00e7as entre o tratamento de borda entre os dispositivos.\nOutro aspecto demostrado, \u00e9 o tamanho da janela mantida em mem\u00f3ria local, e principalmente, como ela \u00e9 atualizada, o que implica em uma imensa diferen\u00e7a no desempenho. Principalmente devido ao gargalo de acesso a mem\u00f3ria no pr\u00f3prio dispositivo.\nA otimiza\u00e7\u00e3o na s\u00edntese \u00e9 demostrada, pela a quantidade economizada de recurso do FPGA, que tem a l\u00f3gica necess\u00e1ria diminu\u00edda em 35,17% (Tabela 6). E o desempenho adquirido \u00e9 de 2,29 vezes melhor do que o c\u00f3digo n\u00e3o otimizado (Tabela 8) para o FPGA da Nallatech que utilizamos.\nPor fim, apresentamos um comparativo de desempenho em GigaPoints/sec relativos ao TDP estimado pelos respectivos fabricantes (Tabela 9 e Figura 16), como um \u00edndice indicativo da efici\u00eancia de pontos processados pelo consumo de energia.\nPor fim, o uso de uma linguagem com um alto n\u00edvel de abstra\u00e7\u00e3o como o OpenCL, e o conhecimento espec\u00edficos de algumas caracter\u00edsticas do hardware utilizado, permitem reduzir drasticamente o tempo e a dificuldade na implementa\u00e7\u00e3o de sistemas, para obter um melhor desempenho usando FPGAs.\nRefer\u00eancias\nAltera. Altera - FPGA Stratix V Architecture. 2010. Dispon\u00edvel em:\n&lt;https://www.altera.com/products/fpga/stratix-series/stratix-v/features.html# Stratix-V-GX-FPGA-Overview>. Acesso em: 22 jan. 2016.\nAltera. Stratix V Device Handbook Volume 1: Device Interfaces and Integration. 2010. Dispon\u00edvel em:&lt;https://www.altera.com/en_US/pdfs/literature/hb/stratix-v/stx5_core. pdf>. Acesso em: 19 jan. 2016.\nALTERA SDK for OpenCL. Dispon\u00edvel em:&lt;http://www.altera.com/products/software/ opencl/opencl-index.html>. Acesso em: 06 mar. 2015.\nAMD - Advanced Micro Devices, Inc. Reference Guide - Southern Islands Series Instruction Set Architecture. 2012. Dispon\u00edvel em:&lt;http://developer.amd.com/wordpress/ media/2012/12/AMD_Southern_Islands_Instruction_Set_Architecture.pdf>. Acesso em: 19 jan. 2016.\nAnn Steffora Mutschler. Semiconductor Engineering Is EUV Making Progress? 2015. Dispon\u00edvel em:&lt;http://semiengineering.com/is-euv-making-progress/>. Acesso em: 09 jul. 2016.\nAQUISI\u00e7\u00e3O S\u00edsmica. 2016. Dispon\u00edvel em:&lt;http://www.uff.br/geofisica/index.php/ aquisicao-sismica>. Acesso em: 09 jul. 2016.\nCALANDRA, H. et al. Evaluation of successive CPUs/APUs/GPUs based on an OpenCL finite difference stencil. In: 2013 21st Euromicro International Conference on Parallel, Distributed, and Network-Based Processing. IEEE, 2013. p. 405-409. ISBN 978-1-4673-5321-2 978-0-7695-4939-2. Dispon\u00edvel em:&lt;http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6498582>.\nFU, H. et al. Scaling reverse time migration performance through reconfigurable dataflow engines. Micro, IEEE, v. 34, n. 1, p. 30-40, 2014. ISSN 0272-1732.\nGIEFERS, H. et al. Analyzing the energy-efficiency of sparse matrix multiplication on heterogeneous systems: A comparative study of GPU, xeon phi and FPGA. In: 2016 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS). IEEE, 2016. p. 46-56. Dispon\u00edvel em:&lt;http://ieeexplore.ieee.org/xpls/abs_all. jsp?arnumber=7482073> .\nGRAY, S. H. et al. Seismic migration problems and solutions. Geophysics, v. 66, n. 5, p. 1622-1640, 2001.\njanice m golda. EUV Lithography - Progress on the Journey to Manufacturing Magic -Technology@Intel. 2016. Dispon\u00edvel em:&lt;http://blogs.intel.com/technology/2016/02/ euv-progress/>. Acesso em: 09 jul. 2016.\nKHRONOS.ORG. OpenCL - The open standard for parallel programming of heterogeneous systems. 2015. Dispon\u00edvel em:&lt;https://www.khronos.org/opencl/>. Acesso em: 12 fev. 2015.\nKR\u00dcGER, J.-T. Green wave: A semi custom hardware architecture for reverse time migration. 2012. Dispon\u00edvel em:&lt;http://archiv.ub.uni-heidelberg.de/volltextserver/id/ eprint/13552>.\nLIMA, I. P. d. Implementa\u00e7\u00e3o do algoritmo (RTM) para processamento s\u00edsmico em arquiteturas n\u00e3o convencionais. Disserta\u00e7\u00e3o (Mestrado) \u2014 Universidade Federal do Rio Grande do Norte, 2014. Dispon\u00edvel em:&lt;http://repositorio.ufrn.br/handle/123456789/ 13004>.\nLIU, G. et al. 3d seismic reverse time migration on GPGPU. v. 59, p. 17-23, 2013. ISSN 00983004. Dispon\u00edvel em:&lt;http://linkinghub.elsevier.com/retrieve/pii/ S0098300413001519>.\nMEDEIROS, V. fastRTM: Um Ambiente Integrado para Desenvolvimento R\u00e1pido da Migra\u00e7\u00e3o Reversa no Tempo (RTM) em Plataformas FPGA de Alto Desempenho. Tese (Doutorado) \u2014 UFPE, 2013.\nMOORE\u2019S Law 40th Anniversary. 2016. Dispon\u00edvel em:&lt;http://www.intel.com/ pressroom/kits/events/moores_law_40th/index.htm>. Acesso em: 09 jul. 2016.\nNvidia. Whitepaper NVIDIA's Next Generation CUDA Compute Architecture: Fermi. 2010. Dispon\u00edvel em:&lt;http://www.nvidia.com/content/pdf/fermi_white_papers/nvidia_ fermi_compute_architecture_whitepaper.pdf>. Acesso em: 19 jan. 2016.\nOWAIDA, M. et al. Synthesis of platform architectures from OpenCL programs. In: Field-Programmable Custom Computing Machines (FCCM), 2011 IEEE 19th Annual International Symposium on. IEEE, 2011. p. 186-193. ISBN 978-1-61284-277-6. Dispon\u00edvel em:&lt;http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5771271>.\nPANETTA, J. et al. Computational characteristics of production seismic migration and its performance on novel processor architectures. In: Computer Architecture and High Performance Computing, 2007. SBAC-PAD 2007. 19th International Symposium on. [S.l.]: IEEE, 2007. p. 11-18.\nSHIN, J.; SHIN, C.; CALANDRA, H. Laplace-domain waveform modeling and inversion for the 3d acoustic-elastic coupled media. v. 129, p. 41-52, 2016. ISSN 09269851.\nDispon\u00edvel em:&lt;http://linkinghub.elsevier.com/retrieve/pii/S0926985116300805>.\nWEBER, R. et al. Comparing hardware accelerators in scientific applications:\nA case study. v. 22, n. 1, p. 58-68, 2011. ISSN 1045-9219. Dispon\u00edvel em:&lt;http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5482576>.\nAp\u00eandices\nA S\u00edntese OpenCL RTM 3D\nFigura 17 - S\u00edntese OpenCL RTM 3D - Qsys Board\nSystem Contents S3\tAddress Map Si\tInterconnect Requirements S3\t\nSystem: board Path: kernel-interface\n\tUse\tCo..\tName\tDescription\nfl\t0\t\t0 globaLiesetJn\tReset Bridge\n\t0\t\t0 pot ieset_counter\tACLSW Reset\nX\t0\t\t0 reset-contiollei global\tMerlin Reset Controller\nU\t0\t\t0 reset_controller_pcie\tMerlin Reset Controller\n\t0\t\t0 teset_contiollei_ddi3a\tMerlin Reset Controller\nz\t0\t\t0 reset_controller_ddi3b\tMerlin Reset Controller\nA.\t0\t\tE npor. export\tReset Bridge\nr^l\t0\t\tE pcie.ref\tClock Bridge\nL=J\t0\t\t\u25a1 pcie_reconfig\tTransceiver Reconfiguration Co...\nX\t0\t\t0 pde\tAvalon-MM Stratix V Hard IP for...\n\t0\t\t0 pipe_stage_host_ctrl\tAvalon-MM Pipeline Bridge\n\t0\t\t0 clock_cross dma to pcie\tAvalon-MM Clock Crossing Bridge\n\t0\t\t0 tempeiature_pll\tAltera PLL\n\t0\t\t0 temperature 0\tACL temperature sensor\n\t0\t\t0 kerneLdk\tClock Source\n\t0\t\t0 oQ ad kernel dk\tOpenCL Kernel Clock Generator\n\t0\t\t0 oQ kernel interface\tOpenCL Kernel Interface\n\t0\t\t0 OQ diiia.O\tOpenCL SGDMA Controller\n\t0\t\t\u25a1 oQ acl_memory_bank_dividei_0\tOpenCL Memory Bank Divider\n\t0\t\t\u25a1 pipe_stage_ddr3a_iface\tAvalon-MM Pipeline Bridge\n\t0\t\t0 dock_cross_dma_to_ddr3a\tAvalon-MM Clock Crossing Bridge\n\t0\t\t0 pipe_stage_ddr3a_diinm\tAvalon-MM Pipeline Bridge\n\t0\t\t0lfl ddr3a\tDDR3 SDRAM Controller with Un..\n\t0\t\t0 pipe_stage_ddr3b_dimm\tAvalon-MM Pipeline Bridge\n\t0\t\t0 ddr 3b\tDDR3SDRAM Controller with Un...\n\t0\t\t0 clock_cross kernel mem 0\tAvalon-MM Clock Crossing Bridge\n\t0\t\t0 clock_cioss kernel mem 1\tAvalon-MM Clock Crossing Bridge\n\t0\t\t0 uniphy_status_O\tACL Uniphv status to AVS\n\t0\t\tE version_id_0\tACL Version ID Component\n\t0\t\tE onchip.memory.O\tOn-Chip Memory (RAM or ROM)\n\t0\t\tE i2<Lopencoies_ucd\tI2C Master (opencores.org)\n\t0\t\tE pipe_stage_ufm_path\tAvalon-MM Pipeline Bridge\n\t0\t\t0 i2<Lopencores_ufm\tI2C Master (opencores.org)\n\t0\t\t0 pipe_stage_tinp431c_path\tAvalon-MM Pipeline Bridge\n\t0\t\t0 i2copencoies_tmp431c\tI2C Master (opencores org)\n\t0\t\t0 pfl flash req\tPIO (Parallel I/O)\n\t0\t\t0 pfl_flash_gtnt\tPIO (Parallel I/O)\n\t0\t\t0 pipe stage host flash\tAvalon-MM Pipeline Bridge\n\t0\t\t0 pipe stage flash path\tAvalon-MM Pipeline Bridge\n\t0\t\t0 oQ genetic_tiistate controller 0\tGeneric Tri-State Controller\n\t0\t\tE tiistate_conduit_biidge_0\tTri-State Conduit Bridge\nFigura 18 - S\u00edntese OpenCL RTM 3D - Qsys Kernel System\nFonte: Autor.\nFigura 19 - S\u00edntese OpenCL RTM 3D - Qsys System\nFonte: Autor.\nFigura 20 - S\u00edntese OpenCL RTM 3D\n|top|system:system_inst|system_kemel_system:kemel_systeni|rtm3d_system:rtm3d_system|rtm3d_top_wrapper:rtm3d\n63% of total design. 69163 Estimated ALUTs Used. 88935 Dedicated logic registers\n1 Child:\nsystem_inst|kernel_sys\u00bbem I run 3d_system| rtmSd| kernel\nI B C\u00f3digo RTM 3D OpenCL\nB.1 C\u00f3digo OpenCL - FPGA - Arquivo rtm3d_config.h\n1\n2\t// Specifies the RADIUS of the stencil\n3\t// For an order-k stencil, RADIUS = k / 2\n4\t#define RADIUS 2\nB.2 C\u00f3digo OpenCL - FPGA - Arquivo rtm3d.cl\ni\t# include\t\" . ./host/inc/rtm3d_config.h\"\n2\t\t\n3\t# d e f i ne\tDIMX 180\n4\t# d e f i ne\tDIMY 180\n5\t\t\n6\t# d e f i ne\tPAR POINTS 6\n7\n8\n9 __attribute__((task))\n10\tkernel void rtm3d(global float * restrict out,\t\nii\tglobal float * restrict ppf ,\t\n12\tglobal float * restrict cpf_in ,\t\n13\tglobal const float * restrict vel,\t\n14\tconstant float *coeff,\t\n15\tconst int dimx , const int dimy , const\tint dimz) {\n16\t\t\n17\tfloat taps [2 * RADIUS * DIMX * DIMY +\tPAR_POINTS] ;\n18\t\t\n19\t#pragma unroll\t\n20\tfor (int i = 0; i &lt;2 * RADIUS * DIMX\t* DIMY + PAR_POINTS\n\t; i++) {\t\n21\ttaps [i]\t= 0;\t\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n}\nint x\t= 0, y = 0, xtile\t=\t0, ytile = 0,\tztile\t= 0;\ndo {\t\t\t\t\t\n\t#pragma unroll\t\t\t\t\n\tfor (int i = 0;\ti\t&lt;2 * RADIUS\t* DIMX\t* DIMY; i\n\t++) {\t\t\t\t\n\ttaps[i]\t=\ttaps [i + PAR_\tPOINTS]\tJ\n\t}int inOffset =\tztile * dimx *\t\tdi my +\t(y + ytile)\n\t* dimx + (x\t+\txtile);\t\t\n#pragma unroll\nfor (int i = 0; i &lt;PAR_POINTS; i++) {\nif (inOffset + i >= 0 &amp;&amp; inOffset + i &lt;dimx * dimy * dimz) {\ntaps [2 * RADIUS * DIMX * DIMY + i ] = cpf_in[inOffset + i];\n}\n}\nint xoutput = x + xtile , youtput = y + ytile , zoutput = ztile - RADIUS;\nint outOffset = zoutput * dimx * dimy + youtput * dimx + xoutput ;\nfloat value[PAR_POINTS];\n#pragma unroll\nfor (int j = 0; j &lt;PAR_POINTS; j++) { value [j] = coeff [0] * taps[RADIUS * DIMX\n* DIMY + j];\n#pragma unroll 2\nfor (int i = 1; i&lt;= RADIUS; i++) {\nvalue [j] += coeff [i] * taps[( RADIUS - i) * DIMX * DIMY + j];\nvalue [j] += coeff [i] * taps[( RADIUS + i) * DIMX * DIMY + j];\nvalue\t[j]\t+=\tcoeff [i] * taps [DIMX\n*\t(RADIUS\t\t* DIMY - i) + j];\nvalue\t[j]\t+=\tcoeff[i] * taps[DIMX\n*\t(RADIUS\t\t* DIMY + i) + j];\nvalue\t[j]\t+=\tcoeff[i] * taps[\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n\tRADIUS *\tDIMX * DIMY - i + j];\n\tvalue [j] +=\tcoeff[i] * taps[\n\tRADIUS *\tDIMX * DIMY + i + j];\n}\t\t\n//taps==cpf\nvalue [j] = 2.0f * taps[RADIUS * DIMX * DIMY + j] + (vel [outOffset + j] * value [j ] - ppf[outOffset+ j]);\n}\n#pragma unroll\nfor (int i = 0; i &lt;PAR_POINTS; i++) {\nbool haloX = ((xoutput + i &lt;RADIUS) ||\t(\nxoutput + i >= dimx - RADIUS));\nbool haloY = ((youtput &lt;RADIUS) ||\t(\nyoutput >= dimy - RADIUS));\nbool haloZ = ((zoutput >= 0 &amp;&amp; zoutput &lt;RADIUS) || (zoutput >= dimz - RADIUS));\nif ((xtile + i)> = RADIUS &amp;&amp; (xtile + i)&lt;\n(DIMX - RADIUS) &amp;&amp; xoutput + i &lt;dimx\n- RADIUS &amp;&amp;\nytile >= RADIUS &amp;&amp; ytile &lt;(DIMY\n- RADIUS) &amp;&amp; youtput &lt;dimy -\nRADIUS &amp;&amp;\nztile >= 2 * RADIUS &amp;&amp; ztile&lt;\ndimz) {\nout [outOffset + i] = value[i];\n} else if ((haloX || haloY || haloZ) &amp;&amp;\nztile >= RADIUS &amp;&amp; xoutput + i &lt;dimx &amp;&amp; youtput &lt;dimy ) {\nout [outOffset + i] = taps[RADIUS\n* DIMX * DIMY + i];\n}\n}\nxtile = xtile &lt;DIMX - PAR_POINTS ? xtile + PAR_POINTS : 0;\nytile = xtile == 0 ? ytile &lt;DIMY - 1 ? ytile + 1\n79\n80\n81\n82\n83\n84\n85\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n: 0 : ytile;\nztile = xtile == 0 &amp;&amp; ytile == 0 ? ztile &lt;dimz +\nRADIUS - 1 ? ztile +1:0: ztile;\nbool intile = (xtile != 0\t|| ytile != 0\t|| ztile\n!= 0) ;\nx = intile ? x : x &lt;dimx - DIMX ? x + DIMX - 2 * RADIUS : 0;\ny = intile ?y:x==0?y+ DIMY - 2 * RADIUS y;\n} while (y &lt;dimy - 2 * RADIUS);\n}\nB.3 C\u00f3digo OpenCL - GPU - Arquivo rtm3d.cl\nconstant const float const coeff [3] = {-90, 16,\t-1};\nkernel void rtm3d(__global float *\noutput ,\n{\nconst\n__global\t\tconst flo\tat * const\tinput ,\n__global\t\tconst flo\tat * const\tvel ,\nconst\ti nt\tdi mx ,\t\t\nconst\ti nt\tdi my ,\t\t\nconst\ti nt\tdi mz ,\t\t\nconst\ti nt\tpadding)\t\t\nbool\tvalid = true;\t\t\t\nconst\ti nt\tgtidx =\tget_global\t_id (0) ;\nconst\ti nt\tgtidy =\tget_global\t_id(1);\nconst\ti nt\tltidx =\tget_local_\tid(0);\nconst\ti nt\tltidy =\tget_local_\tid(1);\nconst\ti nt\tworkx =\tget_local_\tsize (0)\nconst\ti nt\tworky =\tget_local_\tsize (1)\nlocal float tile [MAXWORKY + 2 * RADIUS][MAXWORKX + 2 *\nRADIUS];\nconst int stride_y = dimx + 2 * RADIUS;\nconst int stride_z = stride_y * (dimy + 2 * RADIUS);\nint inputindex = 0; int outputindex = 0;\ninputindex += RADIUS * stride_y + RADIUS + padding;\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\ninputindex += gtidy *\t\tstride_y + gtidx;\nfloat\tinfront [RADiUS] ;\t\nfloat\tbehind[RADiUS];\t\nfloat\tcurrent;\t\nfloat\tcurrentVel;\t\nfloat\toutputVal;\t\nconst\tint tx = ltidx +\tRADiUS ;\nconst\tint ty = ltidy +\tRADiUS ;\nif (gtidx >= dimx) valid = false;\nif (gtidy >= dimy) valid = false;\nfor\t(int i = RADiUS - 2 ; i >= 0 ; i--)\n\tbehind [i]\t= input[inputindex]; inputindex += stride_z;\n}\ncurrent = input [inputindex]; outputindex = inputindex; inputindex += stride_z;\nfor (int i = 0 ; i &lt;RADIUS ; i++) infront [i]\t= input [inputindex];\ninputindex += stride_z;\n}\n// Step through the xy-planes\nfor (int iz = 0\t; iz &lt;dimz ;\tiz++)\n// Advance the slice (move the thread - front) for (int i = RADiUS - 1 ; i > 0 ; i--) behind [i] = behind [i - 1];\nbehind [0]\t= current;\ncurrent = infront [0] ;\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\nfor (int i = 0 ; i &lt;RADIUS - 1 ; i++) infront [i]\t= infront [i + 1];\ninfront[RADIUS - 1] = input[inputindex];\ninputindex += stride_z;\noutputindex += stride_z;\ncurrentVel = vel[outputindex]; outputVal = output[outputindex];\nbarrier(CLK_LOCAL_MEM_FENCE);\n// Update the data slice in the local tile\n// Halo above &amp; below\nif (ltidy &lt;RADiUS)\ntile [ltidy][tx]\t= input [\noutputindex - RADiUS * stride_y];\ntile[ltidy + worky + RADiUS][tx] = input [ outputindex + worky * stride_y];\n}\n// Halo left &amp; right\nif (ltidx &lt;radius)\ntile[ty][ltidx]\t= input [\noutputindex - RADiUS];\ntile[ty][ltidx + workx + RADiUS] = input [ outputindex + workx];\n}\ntile[ty][tx] = current;\nbarrier(CLK_LOCAL_MEM_FENCE);\n// Compute the output value\nfloat value = coeff [0]\t* current;\n#pragma unroll RADiUS\nfor (int i = 1 ; i&lt;= RADiUS ; i++)\nvalue += coeff [i] * (infront [i-1] + behind[i-1] + tile[ty - i][tx] + tile[ ty + i] [tx] + tile [ty] [tx - i] + tile [ ty] [tx + i]);\n104\n105\n106\n107\n108\n109\n110\n111\n112\n}\nvalue = 2.0f * current + (currentVel * value -outputVal);\n// Store the output value if (valid) output [outputIndex] = value;\n}\n}\nImagens Resultantes\nFigura 21 - Modelagem RTM 3D - Dim. 356 - 100 Steps\nFigura 22 - Modelagem RTM 3D - Dim. 356 - 100 Steps / Pontos\nFigura 23 - Modelagem RTM 3D - Dim. 356 - 300 Steps / Pontos\nFigura 24 - Modelagem RTM 3D - Dim. 356 - 500 Steps / Pontos"}]}}}