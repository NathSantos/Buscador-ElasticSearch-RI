{"add": {"doc": {"field": [{"@name": "docid", "#text": "BR-TU.09962"}, {"@name": "filename", "#text": "14995_TCC_Alessandra%20Ribeiro.pdf"}, {"@name": "filetype", "#text": "PDF"}, {"@name": "text", "#text": "UNIVERSIDADE FEDERAL FLUMINENSE\nESCOLA DE ENGENHARIA DEPARTAMENTO DE ENGENHARIA QU\u00cdMICA E DE PETR\u00d3LEO\nALESSANDRA RIBEIRO SILVA\n\u201cESTUDO PRELIMINAR DA APLICA\u00c7\u00c3O DE REDES NEURONAIS NO SISTEMA DE CONTROLE DE TEMPERATURA EM UMA PLANTA DID\u00c1TICA\u201d\n\u201cESTUDO PRELIMINAR DA APLICA\u00c7\u00c3O DE REDES NEURONAIS NO SISTEMA DE CONTROLE DE TEMPERATURA EM UMA PLANTA DID\u00c1TICA\u201d\nProjeto Final apresentado ao Curso de Gradua\u00e7\u00e3o em Engenharia Qu\u00edmica, oferecido pelo departamento de Engenharia Qu\u00edmica e de Petr\u00f3leo da Escola de Engenharia da Universidade Federal Fluminense, como requisito parcial para obten\u00e7\u00e3o do Grau de Engenheiro Qu\u00edmico.\nORIENTADORES:\nProU. Ninoska Isabel Bojorge Ramirez\nProf. Alvaro Jos\u00e9 Boareto Mendes\nFicha Catalogr\u00e1fica elaborada pela Biblioteca da Escola de Engenharia e Instituto de Computa\u00e7\u00e3o da UFF\nS586 Silva, Alessandra Ribeiro\nEstudo preliminar da aplica\u00e7\u00e3o de redes neuronais no sistema de controle de temperatura em uma planta did\u00e1tica / Alessandra Ribeiro Silva. -- Niter\u00f3i, RJ : [s.n.], 2015.\n79 f\nTrabalho (Conclus\u00e3o de Curso) - Departamento de Engenharia Qu\u00edmica e de Petr\u00f3leo, Universidade Federal Fluminense, 2015.\nOrientadores: Ninoska Isabel Bojorge Ramirez, \u00c1lvaro Jos\u00e9 Boareto Mendes.\n1. Controle de processo qu\u00edmico. 2. Intelig\u00eancia artificial. 3. Rede neuronal artificial. I. T\u00edtulo.\nCDD 660.281\n\u201cESTUDO PRELIMINAR DA APLICA\u00c7\u00c3O DE REDES NEURONAIS NO SISTEMA DE CONTROLE DE TEMPERATURA EM UMA PLANTA DID\u00c1TICA\u201d\nProjeto Final apresentado ao Curso de Gradua\u00e7\u00e3o em Engenharia Qu\u00edmica, oferecido pelo departamento de Engenharia Qu\u00edmica e de Petr\u00f3leo, da Escola de Engenharia, da Universidade Federal Fluminense, como requisito parcial para obten\u00e7\u00e3o do Grau em Engenharia Qu\u00edmica.\nAprovado em 9 de julho de 2015.\n\u25a007/\n_ \u201e_____________ &lt;*_____________________________\nProf$. \u00c1lvaro Jos\u00e9 Boarj\u00e9to Mendes, D.Sc.  \nOrientador\nProf3. Andrea Valdman, D^c. DEQ-UFRJ.\nToda a\u00e7\u00e3o humana, quer se torne positiva ou negativa, precisa depender de motiva\u00e7\u00e3o.\nDalai Lama\niii\nAGRADECIMENTOS\nAo meu irm\u00e3o Raphael Ribeiro Silva, Anna Luiza Ribeiro Soares Carvalho, Izabela Ribeiro Soares e Daniel da Silva, que sempre estiveram presentes, me incentivando a alavancar o sucesso.\nAos meus amigos, pelos grandes momentos compartilhados.\nAos professores da gradua\u00e7\u00e3o, pelo incentivo na busca do conhecimento, contribuindo para a minha forma\u00e7\u00e3o.\n\u00c0 orientadora e amiga, D. Sc. Ninoska Isabel Bojorge Ramirez, que desde o come\u00e7o da inicia\u00e7\u00e3o cient\u00edfica confiou a mim a possibilidade do desenvolvimento deste projeto, me orientando e conduzindo com muita dedica\u00e7\u00e3o.\nAo co-orientador D. Sc. \u00c1lvaro Jos\u00e9 Boareto Mendes, pela grande contribui\u00e7\u00e3o e disponibilidade no desenvolvimento do trabalho.\nCom certeza todas essas pessoas tornaram a realiza\u00e7\u00e3o deste trabalho uma tarefa prazerosa.\nRESUMO\nN\u00e3o obstante, os processos, no geral, apresentam caracter\u00edsticas fortemente n\u00e3o lineares, o que torna a modelagem e equacionamento do sistema mais dif\u00edcil de ser realizado.\nSendo assim, o descrito trabalho prop\u00f5e a modelagem do controle de temperatura de uma planta did\u00e1tica - PD3 - atrav\u00e9s do uso de redes neuronais artificiais.\nO treinamento das redes \u00e9 obtido atrav\u00e9s de dados experimentais, e ao final, s\u00e3o discutidos os par\u00e2metros e dados estat\u00edsticos da rede final, a fim de verificar a viabilidade do seu uso no sistema em estudo, isto \u00e9, se a rede neuronal artificial apresentou alta representatividade dos valores obtidos da planta.\nPalavras-Chave: controle autom\u00e1tico de processos; intelig\u00eancia artificial; processos subsimb\u00f3licos; redes neuronais artificiais; RNA; planta did\u00e1tica PD3.\nABSTRACT\nThe automatic process control systems have great importance, being applied in industrial and scientific fields. Such importance is due to the need to use increasingly effective controllers that provide adjustment of the variables automatically, without human intervention.\nHowever, the processes, in general, exhibit highly non linear characteristics, which makes the modeling and equating of the system more difficult to be performed.\nThus, the described work proposes the modeling of the temperature control of a didactic plant - PD3 - through the use of artificial neural networks.\nThe training of the networks is obtained through experimental data and, at the end, the parameters and statistical data of the final network are discussed in order to check the feasibility of their use in the test system, that is, if the artificial neural network showed high representation of the values of the plant.\nKey-Words: automated control process; artificial intelligent; subsymbolic process; artificial neural networks; ANN; didactic plant PD3.\nSUM\u00c1RIO\nCap\u00edtulo 1 INTRODU\u00c7\u00c3O E OBJETIVOS..........................................15\n1.1\tIntrodu\u00e7\u00e3o...........................................................15\n1.2\tObjetivos............................................................16\n1.2.1\tObjetivo Geral............................................16\n1.2.2\tObjetivos Espec\u00edficos.....................................17\n1.3\tOrganiza\u00e7\u00e3o do texto.................................................17\nCap\u00edtulo 2 REVIS\u00c3O BIBLIOGR\u00c1FICA...........................................19\n2.1\tControle de Processos................................................19\n2.2\tVari\u00e1veis Significativas de Controle................................20\n2.3\tEstrat\u00e9gias Convencionais de Controle Industrial....................21\n2.3.1\tEstrat\u00e9gias de Controle por Realimenta\u00e7\u00e3o (Feedback)......21\n2.3.2\tEstrat\u00e9gia de Controle Antecipat\u00f3rio (Feedforward)........23\n2.3.3\tEstrat\u00e9gia de Controle em Cascata.........................24\n2.4\tEstrat\u00e9gias Avan\u00e7adas de Controle Industrial........................26\n2.4.1\tControle Robusto..........................................26\n2.4.2\tControle Adaptativo.......................................27\n2.4.3\tControle Inteligente......................................28\n2.5\tModelagem Matem\u00e1tica de Processos.................................. 28\n2.6\tRedes Neuronais - Neur\u00f4nio Biol\u00f3gico................................30\n2.7\tRedes Neuronais Artificiais.........................................31\n2.8\tModelagem atrav\u00e9s de Rede Neuronal Artificial (RNA).................33\n2.8.1\tArquitetura e Equacionamento dos Modelos Neuronais........33\n2.8.2\tTipos de RNA..............................................37\n2.8.3\tDesenvolvimento das Redes Neuronais Artificiais...........38\nCap\u00edtulo 3 METODOLOGIA.................................................... 42\n3.1\tDescri\u00e7\u00e3o da planta.................................... 42\n3.1.1\tPlanta e Equipamentos.....................................42\nvii\n3.1.2\tSistema Supervis\u00f3rio........................................47\n3.1.3\tObjeto de Estudo............................................48\n3.2\tColeta de Dados.......................................................49\n3.3\tTreinamento da RNA....................................................51\nCap\u00edtulo 4\tRESULTADOS E DISCUSS\u00c3O............................................55\n4.1\tObten\u00e7\u00e3o dos Dados Experimentais.......................................55\n4.2\tTreinamento da RNA com Todas as Vari\u00e1veis de Entrada..................59\n4.2.1\tAn\u00e1lises de Desempenho......................................60\n4.2.2\tDados Preditos pela RNA versus Dados Observados.............61\n4.2.3\tCompara\u00e7\u00e3o entre os Dados Experimentais e os Dados Preditos.62\n4.2.4\tAn\u00e1lise dos Dados Estat\u00edsticos..............................63\n4.2.5\tAn\u00e1lise de Sensibilidade....................................64\n4.3\tCompara\u00e7\u00e3o de desempenho das melhores RNA's...........................65\n4.3.1\tAn\u00e1lises de Desempenho......................................67\n4.3.2\tDados Preditos versus Dados Observado.......................68\n4.3.3\tCompara\u00e7\u00e3o entre os Dados Experimentais e os Dados Preditos.69\n4.3.4\tAn\u00e1lise dos Dados Estat\u00edsticos..............................69\n4.3.5\tAn\u00e1lise de Sensibilidade....................................70\n4.3.6\tAn\u00e1lise Final...............................................70\nCap\u00edtulo 5 CONCLUS\u00d5ES........................................................72\n5.1\tPerspectivas e Sugest\u00f5es para Trabalhos Futuros........................73\nAP\u00caNDICE A - PAR\u00c2METROS DA RNA FINAL.........................................77\nLISTA DE ABREVIATURAS E SIGLAS\nCLP\tControlador L\u00f3gico Program\u00e1vel\nFB\tEstrat\u00e9gia de controle feedback\nFBC\tControle por realimenta\u00e7\u00e3o\nFF\tEstrat\u00e9gia de controle feedforward\nFFCDYN\tControle antecipat\u00f3rio din\u00e2mico\nFFCSS\tControle antecipat\u00f3rio em estado estacion\u00e1rio\nFIT-31\tTransmissor indicador da vaz\u00e3o de \u00e1gua no tanque de aquecimento\nFIT-32\tTransmissor indicador da vaz\u00e3o de \u00e1gua no tanque de mistura\nFY-31\tConversor de sinal para a v\u00e1lvula de \u00e1gua quente\nFY-32\tConversor de sinal para a v\u00e1lvula de \u00e1gua fria\nIA\tIntelig\u00eancia Artificial (Artificial Intelligence) = AI\nLIT-31\tTransmissor indicador do n\u00edvel de \u00e1gua no tanque de aquecimento\nMIMO\tMultiple-Input and Multiple-Output\nMLP\tPerceptron de M\u00faltiplas Camadas (Multilayer Perceptron)\nOPE\tOLE for Process Control\nPD3\tPlanta Did\u00e1tica 3, da SMAR\nPT-100\tSensor de temperatura do tipo termo resist\u00eancia\nRBF\tRede de Fun\u00e7\u00e3o de Base Radial (Radial Bases Function)\nRNA\tRede Neuronal Artificial (Artificial Neural Network) = ANN\nSANN\tStatistica Automated Neural Networks\nSCADA\tSupervisory Control And Data Acquisition\nSP\tSetpoint\nT-31 D\tTemperatura desejada para a \u00e1gua no Tanque-31 (\u00b0C)\nT-31 MV\tVari\u00e1vel manipulada, diretamente ligada \u00e0 resist\u00eancia do Tanque-31 (%)\nTanque-30\tTanque reservat\u00f3rio, presente na planta PD3\nTanque-31\tTanque de aquecimento, presente na planta PD3\nTanque-32\tTanque de mistura, presente na planta PD3\nTIC-31\tControlador da temperatura do tanque de aquecimento (\u00b0C)\nTIC-32\tControlador da temperatura do tanque de mistura\nT-30\tTemperatura do tanque reservat\u00f3rio (\u00b0C)\nTIT-31\tTransmissor indicador da temperatura de \u00e1gua no tanque de aquecimento\nTIT-32\tTransmissor indicador da temperatura de \u00e1gua no tanque de mistura\nTY-31\tCorrente para modular a pot\u00eancia de sa\u00edda do conversor est\u00e1tico (mA)\nVC\tVari\u00e1vel controlada\nVM\tVari\u00e1vel manipulada\n\tLISTA DE S\u00cdMBOLOS\na\tEntrada l\u00edquida de um neur\u00f4nio\nU[\tSinal de entrada do jesimo neur\u00f4nio\nbi\tSinal de sa\u00edda do jesimo neur\u00f4nio\nCk\tValor calculado para o neur\u00f4nio k, na camada de sa\u00edda\ndk\tValor desejado (sa\u00edda)\nE\tErro quadr\u00e1tico\ni\tEntrada da sinapse no neur\u00f4nio\nj\tNeur\u00f4nio em an\u00e1lise\nQ31\tVaz\u00e3o volum\u00e9trica da malha 31 (L/h)\nWji\tPeso da conex\u00e3o de entrada i no neur\u00f4nio j\nX\tVetor de entrada dos neur\u00f4nios para a fun\u00e7\u00e3o gaussiana\nXj\tTotal de ativa\u00e7\u00e3o do jesimo neur\u00f4nio\nLISTA DE S\u00cdMBOLOS GREGOS\nek\tVetor do erro de sa\u00edda\np.\tVetor de pesos de entrada para a fun\u00e7\u00e3o gaussiana\ntfj\tConstante linear de proporcionalidade do neur\u00f4nio j\na\tPropaga\u00e7\u00e3o da RBF\n0j\tPar\u00e2metro externo (\u201cbias\u2019\u201d)\nLISTA DE FIGURAS\nFigura 2.5 - Diagrama de blocos da estrat\u00e9gia de controle em cascata...............25\nFigura 2.6 - Resposta de controle de realimenta\u00e7\u00e3o e em cascata a uma varia\u00e7\u00e3o de -25\u00b0C na temperatura de alimenta\u00e7\u00e3o para o aquecedor........................................25\nFigura 2.7 - Diagrama de blocos de um sistema de controle robusto..................26\nFigura 2.8 - Diagrama de blocos de um sistema de controle adaptativo direto........27\nFigura 2.9 - Diagrama de blocos de um sistema de controle adaptativo indireto (ou auto ajust\u00e1vel).........................................................................27\nFigura 2.10 - Neur\u00f4nio biol\u00f3gico...................................................30\nFigura 2.11. Conex\u00f5es entre os neur\u00f4nios...........................................34\nFigura 2.12 - Modelo de RNA multicamadas (MLP - Multilayer Perceptron).............34\nFigura 2.13 Estrutura do j\u00e9simo neur\u00f4nio...........................................35\nFigura 2.14 - Esquema de funcionamento do treinamento com os subconjuntos de dados para treinamento e para teste......................................................41\nFigura 3.1 - Planta Did\u00e1tica PD3 da SMAR...........................................43\nFigura 3.2 - Diagrama P&amp;ID da planta PD3, com indica\u00e7\u00e3o do fluxo realizado pela \u00e1gua nos experimentos.......................................................................44\nFigura 3.3 - Sin\u00f3tico da planta PD3................................................48\nFigura 3.4 - Dados experimentais trabalhados pela m\u00e1scara desenvolvida para o sistema. 51\nFigura 3.5 - Estrutura da RNA estudada.............................................52\nFigura 4.1 - Experimento realizado sem recircula\u00e7\u00e3o de \u00e1gua quente no sistema......55\nFigura 4.2 -\tSequ\u00eancia de dados\texperimentais\tda temperatura da \u00e1gua no Tanque-31..56\nFigura 4.3 -\tSequ\u00eancia de dados\texperimentais\tda temperatura da \u00e1gua no Tanque-30..57\nFigura 4.4 -\tSequ\u00eancia de dados\texperimentais\tdas vari\u00e1veis T-31 MV e TY-31........57\nFigura 4.5 -\tSequ\u00eancia de dados\texperimentais\tda vaz\u00e3o no Tanque-31................58\nFigura 4.6 - Sequ\u00eancia de dados experimentais do n\u00edvel da \u00e1gua no Tanque-31........58\nFigura 4.7 - Esquema de entrada e sa\u00edda utilizado no treinamento da RNA............59\nFigura 4.8 - Histograma de distribui\u00e7\u00e3o dos res\u00edduos...............................61\nxii\nFigura 4.9 - Dados preditos pela RNA vs. dados observados.......................62\nFigura 4.10 - Temperatura do Tanque-31 versus sequ\u00eancia de dados: compara\u00e7\u00e3o dos dados\npreditos pela RNA com os dados experimentais....................................63\nFigura 4.11 - Estrutura utilizada no 2\u00b0 Treinamento da RNA......................66\nFigura 4.12- Estrutura utilizada no 3\u00b0 Treinamento da RNA.......................66\nFigura 4.13 - Gr\u00e1fico de probabilidade para compara\u00e7\u00e3o dos dados preditos em cada\ntreinamento versus dados observados.............................................68\nFigura 4.14 - Temperatura do Tanque-31 versus sequ\u00eancia de dados. Compara\u00e7\u00e3o dos dados\npreditos em cada treinamento com os dados experimentais.........................69\nLISTA DE TABELAS\nTabela 2.1 - Fun\u00e7\u00f5es de ativa\u00e7\u00e3o utilizadas para treinamento das redes neuronais artificiais, no programa Statistica 12.0.............................................................36\nTabela 3.1 - Testes experimentais para representa\u00e7\u00e3o do sistema e treinamento da RNA. 49\nTabela 4.1 - Cinco melhores redes treinadas com seis vari\u00e1veis de entrada e uma vari\u00e1vel de sa\u00edda...................................................................................60\nTabela 4.2 - Estat\u00edstica da regress\u00e3o para a rede neuronal artificial para a vari\u00e1vel de sa\u00edda (MLP 6-23-1)............................................................................63\nTabela 4.3 - An\u00e1lise de sensibilidade do treinamento realizado com seis vari\u00e1veis de entrada. ....................................................................................... 64 Tabela 4.4 - Cinco melhores redes obtidas no treinamento 2, com cinco vari\u00e1veis na camada de entrada..............................................................................67\nTabela 4.5 - Cinco melhores redes obtidas no treinamento 3, com cinco vari\u00e1veis na camada de entrada..............................................................................67\nTabela 4.6 - Compara\u00e7\u00e3o dos desempenhos das RNA selecionadas em cada treinamento. 68 Tabela 4.7 - Dados estat\u00edsticos das redes treinadas.....................................70\nTabela 4.8 - Compara\u00e7\u00e3o entre as an\u00e1lises de sensibilidade para as tr\u00eas diferentes estruturas de RNA treinadas........................................................................70\nTabela A.1 - Pesos e \"bias\" de cada conex\u00e3o da rede MLP 6-23-1..........................77\nCap\u00edtulo 1 INTRODU\u00c7\u00c3O E OBJETIVOS\nNo presente cap\u00edtulo se pleiteia a necessidade de implementa\u00e7\u00e3o de estruturas cada vez mais sofisticadas, para a identifica\u00e7\u00e3o e controle de processos complexos. Devido \u00e0 caracter\u00edstica n\u00e3o linear dos processos operacionais, essas estruturas devem ser capazes de modelar a din\u00e2mica do sistema e controlar as varia\u00e7\u00f5es ocorridas na regi\u00e3o de opera\u00e7\u00e3o da planta.\nSendo assim, d\u00e1-se \u00eanfase no estudo para aplica\u00e7\u00e3o de Redes Neuronais Artificiais em um sistema de controle autom\u00e1tico de temperatura, conforme descrito nas pr\u00f3ximas se\u00e7\u00f5es.\n1.1\tIntrodu\u00e7\u00e3o\nSegundo Smith e Corripio (2008) os processos s\u00e3o din\u00e2micos por natureza, havendo a necessidade de realizar o controle de suas vari\u00e1veis, uma vez que altera\u00e7\u00f5es sempre ocorrem. Diversos estudos s\u00e3o propostos a fim de obter sistemas mais \u00e1geis que, consequentemente, proporcionem melhorias e redu\u00e7\u00f5es de custo (SMITH e CORRIPIO, 2008; SEBORG, EDGAR, et al., 2010; LUYBEN, 1986). A aplica\u00e7\u00e3o dos estudos tem sido fortemente utilizada em sistemas industriais, cada vez mais complexos.\nEm concord\u00e2ncia, Seborg, et al. (2010) afirmam que sistemas de controle de processos v\u00eam sendo desenvolvidos para diferentes \u00e1reas de atua\u00e7\u00e3o, tanto industriais como cient\u00edficas. O objetivo \u00e9 tornar o processo produtivo autom\u00e1tico, com aumento de confiabilidade e versatilidade, resultando em opera\u00e7\u00f5es mais simples e econ\u00f4micas.\nPara se implementar a automa\u00e7\u00e3o de um sistema \u00e9 necess\u00e1rio ter uma vis\u00e3o global do processo a ser automatizado, associando aos princ\u00edpios da eletr\u00f4nica, os sistemas computacionais, as restri\u00e7\u00f5es mec\u00e2nicas das unidades operacionais e os elementos de controle. O sistema de automa\u00e7\u00e3o \u00e9 completo quando toda linha de produ\u00e7\u00e3o funciona do in\u00edcio ao fim sem a interven\u00e7\u00e3o humana, agindo apenas pela a\u00e7\u00e3o das pr\u00f3prias m\u00e1quinas e estrat\u00e9gias de controle. As etapas para desenvolver um controle autom\u00e1tico podem ser resumidas da seguinte forma: inicia-se com a modelagem matem\u00e1tica do processo, a partir do qual se analisa o comportamento din\u00e2mico da planta e ent\u00e3o se projeta um controlador que far\u00e1 o sistema evoluir da forma desejada, al\u00e9m de se adaptar \u00e0s mudan\u00e7as dos elementos sob controle.\nPor\u00e9m, h\u00e1 tr\u00eas grandes problemas na implementa\u00e7\u00e3o de sistemas comerciais de controle de processos qu\u00edmicos: o comportamento n\u00e3o linear do processo, restri\u00e7\u00f5es f\u00edsicas das unidades operacionais, dos sensores e elementos de controle, e ainda seus comportamentos din\u00e2micos. Devido \u00e0 complexidade de problemas de controle n\u00e3o linear, torna-se necess\u00e1rio, no geral, a aplica\u00e7\u00e3o de v\u00e1rios procedimentos computacionais ou emprego de aproxima\u00e7\u00f5es para a sua solu\u00e7\u00e3o. Uma s\u00e9rie de m\u00e9todos baseados em redes neuronais artificiais tem sido sugerida para problemas de controle \u00f3timo, onde o objetivo \u00e9 minimizar uma fun\u00e7\u00e3o objetivo do controle (AHMED, 2014).\nDe forma a superar as dificuldades no desenvolvimento de modelos fenomenol\u00f3gicos, est\u00e3o sendo utilizados modelos emp\u00edricos baseados em redes neuronais artificiais, tanto para fins de modelagem e otimiza\u00e7\u00e3o de processos, quanto para o projeto de estrat\u00e9gias de controle. Destaca-se que as redes neuronais artificiais (RNA) t\u00eam encontrado grande aplica\u00e7\u00e3o para a identifica\u00e7\u00e3o e modelagem de sistemas n\u00e3o lineares. Como um todo, verifica-se tamb\u00e9m o crescimento das aplica\u00e7\u00f5es de RNA, em diversas \u00e1reas da ci\u00eancia e Engenharia, que buscam, atrav\u00e9s da intelig\u00eancia artificial, desenvolver sistemas computacionais inteligentes, que simulem o comportamento do c\u00e9rebro humano ao resolver determinadas tarefas (BAUGHMAN e LIU, 1995).\nAs RNA s\u00e3o treinadas para cada sistema e s\u00e3o compostas por neur\u00f4nios estruturados no interior de uma rede e interligados entre si, por onde passam os sinais, com seus respectivos pesos. Estes neur\u00f4nios atuam independentemente e em forma paralela, o que permite que suas respostas sejam simult\u00e2neas. Na sequ\u00eancia, as respostas s\u00e3o combinadas mediante alguma fun\u00e7\u00e3o, para que possa se obter os sinais de sa\u00edda e modelar matematicamente o sistema (HAYKIN, 2001).\nNeste trabalho se prop\u00f5e a aplica\u00e7\u00e3o de redes neuronais artificiais para a modelagem do sistema de controle autom\u00e1tico de temperatura de um tanque presente no processo de uma unidade did\u00e1tica da SMAR (PD3 - Planta Did\u00e1tica 3).\n1.2\tObjetivos\n1.2.1\tObjetivo Geral\nO exposto trabalho tem como objetivo aplicar a metodologia de redes neuronais artificiais para representa\u00e7\u00e3o de sistemas de controle autom\u00e1tico de processos, a partir do estudo da din\u00e2mica do sistema.\n1.2.2\tObjetivos Espec\u00edficos\n\u2022\testudar a din\u00e2mica de controle autom\u00e1tico de temperatura de um tanque da planta PD3 da SMAR;\n\u2022\tobter dados experimentais do sistema, considerando diferentes cen\u00e1rios;\n\u2022\ttreinar redes neuronais artificiais empregando os dados experimentais para representa\u00e7\u00e3o do sistema em estudo;\n\u2022\tavaliar os par\u00e2metros (pesos e \u201cbias\u2019\u201d) e os dados estat\u00edsticos das redes treinadas, para defini\u00e7\u00e3o da melhor rede.\n1.3\tOrganiza\u00e7\u00e3o do texto\nConforme supracitado, a necessidade de implementa\u00e7\u00e3o de controles avan\u00e7ados de processos, devido \u00e0 complexidade dos sistemas e forte intera\u00e7\u00e3o entre as vari\u00e1veis, motiva o desenvolvimento do presente trabalho. Assim, para facilitar a apresenta\u00e7\u00e3o das discuss\u00f5es, o documento est\u00e1 dividido em cinco cap\u00edtulos, conforme abaixo.\nNeste Cap\u00edtulo 1 - Introdu\u00e7\u00e3o e Objetivos, os estudos foram apresentados e contextualizados. S\u00e3o apresentados tamb\u00e9m os objetivos e a linha estrutural do trabalho.\nNo Cap\u00edtulo 2 - Revis\u00e3o Bibliogr\u00e1fica, ser\u00e3o apresentados conceitos de controle autom\u00e1tico de processos, descritos na literatura, com propostas de aplica\u00e7\u00e3o de estrat\u00e9gias de controle fundamentadas em modelos neuronais. Assim, ao longo do cap\u00edtulo ser\u00e3o explorados conceitos e aplica\u00e7\u00f5es das redes neuronais artificiais (modelos mais usados em aplica\u00e7\u00f5es cient\u00edficas e tecnol\u00f3gicas), al\u00e9m das vantagens e limita\u00e7\u00f5es da ferramenta proposta (RNA).\nNo Cap\u00edtulo 3 - Metodologia, ser\u00e1 descrita a metodologia da an\u00e1lise experimental adotada no trabalho, utilizando como base de estudo a planta did\u00e1tica (PD3) da SMAR para coleta de dados experimentais e posterior aplica\u00e7\u00e3o de RNA atrav\u00e9s do software Statistica\u00ae (StatSoft, vers\u00e3o 12.0), a fim de treinar as redes com base no sistema de monitoramento e controle de temperatura.\nLogo no Cap\u00edtulo 4 - Resultados e Discuss\u00e3o, ser\u00e3o apresentados e discutidos os resultados do estudo realizado, visando obter a melhor rede que representasse o sistema em estudo.\nFinalmente, no Cap\u00edtulo 5 - Conclus\u00e3o, ser\u00e3o apresentadas as conclus\u00f5es dos resultados obtidos e recomenda\u00e7\u00f5es para futuras aplica\u00e7\u00f5es das redes neuronais artificiais em sistemas de controle.\nNo Ap\u00eandice ser\u00e3o apresentados os par\u00e2metros (pesos e \u201cbias\u201d) da rede final, dispostos a partir de tabela.\nCap\u00edtulo 2 REVIS\u00c3O BIBLIOGRAFICA\nNeste cap\u00edtulo s\u00e3o destacados termos de controle de processos importantes para o estudo em an\u00e1lise. Na sequ\u00eancia do cap\u00edtulo, descreve-se uma revis\u00e3o sobre redes neuronais artificiais, abrangendo conceitua\u00e7\u00e3o, propriedades e aplica\u00e7\u00f5es industriais, al\u00e9m de descrever alguns algoritmos de treinamento, com objetivo de detalhar a proposta de controle a ser trabalhada nos cap\u00edtulos subsequentes e argumentar sua motiva\u00e7\u00e3o.\nSalientam-se tamb\u00e9m os fundamentos e os m\u00e9todos para a modelagem e treinamento das redes.\n2.1\tControle de Processos\nO estudo de controle autom\u00e1tico de processos \u00e9 de fundamental import\u00e2ncia, tendo em vista que os processos s\u00e3o din\u00e2micos por natureza, resultando em altera\u00e7\u00f5es que necessitam ser ajustadas (SMITH e CORRIPIO, 2008).\nEsta \u00e1rea apresentou grande evolu\u00e7\u00e3o ao longo do tempo, conforme ser\u00e1 descrito nos pr\u00f3ximos t\u00f3picos (CPDEE, 2002).\nOs primeiros sistemas de controle foram desenvolvidos no final do s\u00e9culo 19, a fim de automatizar as linhas de montagem da \u00e9poca. Estes dispositivos foram desenvolvidos para a execu\u00e7\u00e3o de cada tarefa e apresentavam natureza mec\u00e2nica.\nA partir dos anos 20 os estudos de controle de processos se tornaram mais complexos devido \u00e0 substitui\u00e7\u00e3o dos dispositivos mec\u00e2nicos por rel\u00e9s e contadores.\nEm rela\u00e7\u00e3o ao controle autom\u00e1tico de processos qu\u00edmicos, Luyben (1986) destaca que seu uso foi consolidado na d\u00e9cada de 60, quando engenheiros qu\u00edmicos adaptaram os estudos j\u00e1 realizados nos campos de aeron\u00e1utica e de eletricidade \u00e0s plantas industriais.\nNa sequ\u00eancia, com o desenvolvimento de computadores comerciais para fins de controle por programa\u00e7\u00e3o, ao in\u00edcio dos anos 70, foi realizada a compara\u00e7\u00e3o destes sistemas com as interliga\u00e7\u00f5es el\u00e9tricas. Durante este per\u00edodo, desenvolveu-se tamb\u00e9m o Controlador L\u00f3gico Program\u00e1vel (CLP), para suprir a ind\u00fastria automobil\u00edstica norte-americana. Este controlador \u00e9 disposto ao longo das linhas do processo.\nAtualmente, o sistema de supervis\u00e3o e controle mais utilizado em ind\u00fastrias \u00e9 o SCADA (Supervisory Control And Data Acquisition), com monitores automatizados, ligados ao processo, que proporcionam agilidade na corre\u00e7\u00e3o de desvios.\n2.2\tVari\u00e1veis Significativas de Controle\nPara o desenvolvimento de sistemas de controle de processos \u00e9 necess\u00e1rio compreender a classifica\u00e7\u00e3o das vari\u00e1veis significativas.\nDe come\u00e7o, as vari\u00e1veis s\u00e3o separadas pela sua contribui\u00e7\u00e3o no processo. Neste caso, existem as vari\u00e1veis de entrada (inputs) e as vari\u00e1veis de sa\u00edda (outputs).\nPara o projeto e a an\u00e1lise de sistemas de controle, \u00e9 conveniente dividir as vari\u00e1veis de entrada em vari\u00e1veis manipuladas (VM), que s\u00e3o ajustadas para manter o sistema conforme desejado, e vari\u00e1veis de perturba\u00e7\u00e3o, que s\u00e3o determinadas pelo ambiente externo (SEBORG, EDGAR, et al., 2010). Enquanto que as vari\u00e1veis de sa\u00edda se referem \u00e0s vari\u00e1veis de processo (ou vari\u00e1veis controladas, VC), relacionadas ao fluxo de sa\u00edda ou condi\u00e7\u00f5es dentro de uma unidade operacional.\nSegundo Smith e Corripio (2008) o objetivo do controle de processos \u00e9 manter a vari\u00e1vel controlada em um determinado valor desejado (setpoint, SP), independente das perturba\u00e7\u00f5es ocorridas no sistema (dist\u00farbios).\nO sistema de controle pode estar sendo operado de forma manual (o controlador est\u00e1 desconectado do sistema, e para isso \u00e9 necess\u00e1rio que o operador efetue as altera\u00e7\u00f5es na vari\u00e1vel manipulada) ou de forma autom\u00e1tica (o controlador realiza a an\u00e1lise das vari\u00e1veis e envia a a\u00e7\u00e3o \u00e0 vari\u00e1vel manupulada).\nConforme sugerido por Seborg, etal. (2010), na sua forma ideal, um sistema de controle deve satisfazer os crit\u00e9rios de desempenho, tais como: a malha fechada do processo tem que ser est\u00e1vel; os efeitos de perturba\u00e7\u00f5es devem ser minimizados; as respostas para mudan\u00e7as de setpoint devem ser r\u00e1pidas; as a\u00e7\u00f5es de controle excessivas devem ser evitadas; o sistema deve ser robusto em rela\u00e7\u00e3o a erros de modelagem e altera\u00e7\u00f5es nas condi\u00e7\u00f5es de processo.\n2.3\tEstrat\u00e9gias Convencionais de Controle Industrial\nExistem diversas estrat\u00e9gias de controle indicadas na literatura. As mesmas s\u00e3o aplicadas a fim de obter um sistema com controle adequado das vari\u00e1veis.\nNas pr\u00f3ximas se\u00e7\u00f5es ser\u00e3o apresentados os tipos de estrat\u00e9gias mais comumente utilizados nas ind\u00fastrias de processos, qu\u00edmica e bioqu\u00edmica.\n2.3.1\tEstrat\u00e9gias de Controle por Realimenta\u00e7\u00e3o (Feedback)\nO controle autom\u00e1tico de processos por realimenta\u00e7\u00e3o consiste basicamente em uma opera\u00e7\u00e3o de \u201ctentativa e erro\u201d, no qual tem como objetivo, manter a vari\u00e1vel controlada no ponto desejado (setpoint, SP).\nA partir de uma malha fechada, a altera\u00e7\u00e3o efetuada pelo sistema de controle \u00e9 monitorada de forma din\u00e2mica, minimizando os erros em regime estacion\u00e1rio.\nSmith e Corripio (2008) descrevem esta malha de controle como a mais utilizada nas ind\u00fastrias de processo, devido \u00e0 simplicidade e por atender aos requisitos de seguran\u00e7a, qualidade do produto e raz\u00e3o de produ\u00e7\u00e3o.\nN\u00e3o obstante, estes autores ressaltam tamb\u00e9m que este sistema trabalha com corre\u00e7\u00e3o dos dados finais, sendo necess\u00e1rio que o dist\u00farbio efetuado ao in\u00edcio se propague por todo o sistema, para que ent\u00e3o o controlador possa dar prosseguimento \u00e0 corre\u00e7\u00e3o. Assim, esta estrat\u00e9gia de controle pode n\u00e3o ser vantajosa, dependendo da necessidade do tempo de resposta do sistema. Para entendimento desta estrat\u00e9gia de controle, segue a Figura 2.1, como exemplo.\nFigura 2.1 - Esquema do controle de temperatura em tanque de mistura. Fonte: Bojorge Ram\u00edrez (2012).\nO esquema refere-se ao controle autom\u00e1tico da temperatura de um tanque de mistura. Inicialmente a temperatura do sistema \u00e9 medida atrav\u00e9s de um sensor em contato com o processo (Etapa 1). Para este exemplo, pode-se destacar os seguintes dispositivos para desempenho desta fun\u00e7\u00e3o: termopar, termo resist\u00eancia, termistor, etc.\nNa sequ\u00eancia, o sinal gerado pelo sensor \u00e9 enviado a um transmissor, que o converte em um sinal padr\u00e3o e transmite ao controlador (Etapa 2). Em geral, o transmissor encontra-se fisicamente acoplado ao sensor. Este par \u00e9 denominado Transdutor.\nNo controlador (Etapa 3), o sinal \u00e9 analisado e comparado com o valor desejado (neste exemplo, a temperatura). Esta compara\u00e7\u00e3o \u00e9 feita pela diferen\u00e7a entre os valores, sendo denominada erro.\nAo final, a partir do valor encontrado para o erro, o controlador envia um sinal para o elemento final de controle, ou atuador (neste caso, v\u00e1lvula de entrada de vapor), para corre\u00e7\u00e3o da temperatura (Etapa 4).\nNo exemplo abordado, para cada altera\u00e7\u00e3o efetuada pelo atuador \u00e9 realizada uma nova compara\u00e7\u00e3o dos dados reais com os desejados, uma vez que esta altera\u00e7\u00e3o dever\u00e1 afetar a nova medi\u00e7\u00e3o do sensor (estrat\u00e9gia de feedback).\nA Figura 2.2 apresenta o diagrama de blocos da estrat\u00e9gia de controle feedback.\nFigura 2.2 - Diagrama de blocos da estrat\u00e9gia de controle realimentado.\nTendo em vista que a estrat\u00e9gia de controle por realimenta\u00e7\u00e3o necessita que o dist\u00farbio se propague ao longo do sistema, para que ent\u00e3o o controlador possa atuar, o sistema trabalha com desvios tempor\u00e1rios. Por\u00e9m, Smith e Corripio (2008) destacam que apesar de muitos processos permitirem este desvio, em muitos outros o desvio precisa ser minimizado. Para isto, existe a possibilidade de implementa\u00e7\u00e3o de outras estrat\u00e9gias de controle, que auxiliem o\ncontrole por realimenta\u00e7\u00e3o (como por exemplo o controle antecipat\u00f3rio e o controle em cascata, descritos nas pr\u00f3ximas se\u00e7\u00f5es).\nCabe ressaltar que em todas as estrat\u00e9gias de controle as seguintes a\u00e7\u00f5es s\u00e3o realizadas (SMITH e CORRIPIO, 2008):\n\u2022\tMedi\u00e7\u00e3o da vari\u00e1vel controlada;\n\u2022\tDecis\u00e3o, com base na diferen\u00e7a entre o valor desejado e o valor obtido na medi\u00e7\u00e3o;\n\u2022\tA\u00e7\u00e3o, a fim de minimizar o erro calculado no item anterior.\n\u00c9 importante destacar tamb\u00e9m que a planta em estudo (PD3), da SMAR, realiza o controle automatizado das vari\u00e1veis press\u00e3o, vaz\u00e3o e temperatura, utilizando as tr\u00eas malhas de controle citadas no texto (antecipat\u00f3rio, realimenta\u00e7\u00e3o negativa e em cascata).\n2.3.2\tEstrat\u00e9gia de Controle Antecipat\u00f3rio (Feedforward)\nA estrat\u00e9gia de controle antecipat\u00f3rio (feedforward) refere-se a forma de compensa\u00e7\u00e3o dos dist\u00farbios antes dos mesmos afetarem a vari\u00e1vel controlada. Para isso, \u00e9 necess\u00e1rio conhecer as caracter\u00edsticas do estado estacion\u00e1rio e da din\u00e2mica do processo.\nA Figura 2.3 apresenta o diagrama de blocos da estrat\u00e9gia de controle antecipat\u00f3rio.\nFigura 2.3 - Diagrama de blocos da estrat\u00e9gia de controle antecipat\u00f3rio (FB - estrat\u00e9gia de controle feedback e FF - estrat\u00e9gia de controle Feedforward).\nSmith e Corripio (2008) definem esta forma de controle como sendo uma estrat\u00e9gia \u201cproativa\u201d, pois caso as medi\u00e7\u00f5es ocorram de forma eficaz e a a\u00e7\u00e3o de ajuste for realizada\ncorretamente, a vari\u00e1vel controlada poder\u00e1 n\u00e3o ser afetada, permanecendo pr\u00f3xima ao ponto fixo (valor desejado).\nA Figura 2.4 demonstra, como exemplo, a compara\u00e7\u00e3o entre as estrat\u00e9gias de controle por realimenta\u00e7\u00e3o (FBC) e antecipat\u00f3rio (estado estacion\u00e1rio: FFCSS; din\u00e2mico: FFCDYN) utilizados em um processo de mistura (SMITH e CORRIPIO, 2008).\nFigura 2.4 - Respostas de alimenta\u00e7\u00e3o e realimenta\u00e7\u00e3o para um sistema de mistura.\nFonte: Smith e Corripio (2008).\nPode-se verificar que, para este exemplo, o uso do controle feedforward apresentou uma resposta consideravelmente mais r\u00e1pida que o controle feedback.\nPor\u00e9m, \u00e9 importante destacar que a implementa\u00e7\u00e3o e a opera\u00e7\u00e3o do controle antecipat\u00f3rio necessitam de uma quantidade significativa de engenharia e treinamento (SMITH e CORRIPIO, 2008), e portanto n\u00e3o \u00e9 muito utilizada, ao se comparar com o controle de realimenta\u00e7\u00e3o (mais simples).\n2.3.3\tEstrat\u00e9gia de Controle em Cascata\nO controle em cascata consiste no uso de duas ou mais malhas de controle por realimenta\u00e7\u00e3o, que afetam umas \u00e0s outras. O uso mais comum refere-se ao de duas malhas (malha prim\u00e1ria e secund\u00e1ria), sendo que a malha secund\u00e1ria \u00e9 determinada como sendo aquela que responder\u00e1 mais rapidamente \u00e0s varia\u00e7\u00f5es do dist\u00farbio, tendo em vista que a mesma est\u00e1 ligada diretamente ao atuador (SMITH e CORRIPIO, 2008).\nEsta estrat\u00e9gia de controle \u00e9 utilizada quando ocorrem muitas perturba\u00e7\u00f5es no sistema, sendo necess\u00e1rio que haja uma monitora\u00e7\u00e3o mais rigorosa.\nA Figura 2.5 apresenta o diagrama de blocos para a estrat\u00e9gia de controle em cascata.\nFigura 2.5 - Diagrama de blocos da estrat\u00e9gia de controle em cascata.\nSmith e Corripio (2008) compararam as respostas dos controles de realimenta\u00e7\u00e3o e em cascata para um processo no qual houve a varia\u00e7\u00e3o de -25\u00b0C da temperatura de entrada do reagente (vide Figura 2.6).\nFigura 2.6 - Resposta de controle de realimenta\u00e7\u00e3o e em cascata a uma varia\u00e7\u00e3o de -25\u00b0C na temperatura de alimenta\u00e7\u00e3o para o aquecedor.\nFonte: Smith e Corripio (2008).\n2.4\tEstrat\u00e9gias Avan\u00e7adas de Controle Industrial\nSegundo Seborg, et al. (2010) o aumento da complexidade de alguns processos gerou a necessidade de implementa\u00e7\u00e3o de sistemas de controles industriais mais eficientes. Esta complexidade relatada ocorre, principalmente, devido aos sistemas com perfis n\u00e3o lineares, que acarretam em resultados n\u00e3o satisfat\u00f3rios para o uso de controles convencionais.\nSendo assim, foram desenvolvidas estrat\u00e9gias avan\u00e7adas de controle, conforme apresentado nas pr\u00f3ximas se\u00e7\u00f5es.\n2.4.1\tControle Robusto\nLuque (2007) classifica o controle robusto como uma estrat\u00e9gia de controle desenvolvida para atuar, garantindo a estabilidade e atendimento \u00f3timo, apesar de incertezas presentes na representa\u00e7\u00e3o do modelo da planta. Este m\u00e9todo (presente no ramo de pesquisa desde o final dos anos 70) realiza a\u00e7\u00f5es de controle feedback, tendo em vista sistemas MIMO (\u201cMultiple Imputs andMultiple Output\u201d), com m\u00faltiplas entradas e sa\u00eddas.\nSegundo Trofino (2000) esta forma de controle tamb\u00e9m minimiza os efeitos de perturba\u00e7\u00f5es externas, como por exemplo, ru\u00eddos e mudan\u00e7as de temperatura.\nA Figura 2.7 apresenta o diagrama de blocos deste modelo.\nFigura 2.7 - Diagrama de blocos de um sistema de controle robusto.\n2.4.2\tControle Adaptativo\nSegundo Lages (2007) o controle adaptativo apresenta duas abordagens: direta, cujos par\u00e2metros do controlador s\u00e3o ajustados diretamente em fun\u00e7\u00e3o da sa\u00edda do processo (vide Figura 2.8) e indireta (ou auto ajust\u00e1vel), que considera que os par\u00e2metros do processo sejam conhecidos, assim, o ajuste do controlador \u00e9 realizado a partir do c\u00e1lculo entre os par\u00e2metros estimados e os conhecidos (vide Figura 2.9).\nFigura 2.8 - Diagrama de blocos de um sistema de controle adaptativo direto.\n2.4.3\tControle Inteligente\nSegundo De Ara\u00fajo (2004) o controle inteligente foi desenvolvido para a atua\u00e7\u00e3o em sistemas que n\u00e3o apresentam modelos matem\u00e1ticos bem conhecidos e/ ou cuja aplica\u00e7\u00e3o requer o uso de controladores com representa\u00e7\u00f5es diferentes da l\u00f3gica cl\u00e1ssica.\nEste m\u00e9todo deve ser capaz de realizar o aprendizado de forma autom\u00e1tica, elaborar o planejamento do controle atrav\u00e9s da classifica\u00e7\u00e3o das informa\u00e7\u00f5es que caracterizam o sistema, e apresentar mecanismo de tomada de decis\u00e3o.\nComo exemplo desta estrat\u00e9gia de controle pode-se destacar a l\u00f3gica Fuzzy (ou nebulosa) e as redes neuronais artificiais (DE ARA\u00daJO, 2004).\nSeborg, et al. (2010) descrevem a l\u00f3gica Fuzzy como uma t\u00e9cnica de controle feedback que utiliza dados qualitativos, ao inv\u00e9s de dados quantitativos, dispostos atrav\u00e9s de regras. Caneppele e Seraphim (2010) exemplificam o uso desta t\u00e9cnica em seu estudo para simula\u00e7\u00e3o de um controle inteligente em um sistema h\u00edbrido de gera\u00e7\u00e3o de energia el\u00e9trica, utilizando as energias solar-fotovoltaica e e\u00f3lica. Neste estudo foi verificado que a l\u00f3gica Fuzzy possibilitou o controle e gerenciamento do sistema, pois possibilitava a modelagem e manipula\u00e7\u00e3o de dados naturais \u00e0 linguagem humana, atrav\u00e9s da estipula\u00e7\u00e3o de regras.\nEm contraste, as redes neuronais artificiais, conforme descrito previamente neste trabalho, constituem um modelo emp\u00edrico para modelagem de sistemas n\u00e3o lineares, que utilizam como base dados quantitativos para treinamento. Al\u00e9m de descrever a din\u00e2mica do processo estudado, a RNA pode ser utilizada como sensor em sistemas de detec\u00e7\u00e3o de falha e diagn\u00f3stico e como componente auxiliar \u00e0 estrat\u00e9gia de controle adaptativo, a partir da previs\u00e3o de comportamentos do sistema, devido ao modelo emp\u00edrico desenvolvido (DE ARA\u00daJO, 2004).\n2.5\tModelagem Matem\u00e1tica de Processos\nA modelagem matem\u00e1tica de um processo consiste na obten\u00e7\u00e3o da equa\u00e7\u00e3o caracter\u00edstica do sistema (SMITH e CORRIPIO, 2008).\nUsualmente os modelos s\u00e3o determinados atrav\u00e9s da realiza\u00e7\u00e3o de balan\u00e7os de massa e balan\u00e7os de energia para o objeto em estudo. Neste contexto, quanto mais vari\u00e1veis existirem no sistema, mais complexo ser\u00e1 o modelo matem\u00e1tico a ser desenvolvido. Al\u00e9m disso, quando o sistema possui uma grande quantidade de vari\u00e1veis, pode levar a depend\u00eancia param\u00e9trica em fun\u00e7\u00e3o da redu\u00e7\u00e3o do n\u00famero de graus de liberdade. Isso torna mais complexa a solu\u00e7\u00e3o\nN\u00e3o obstante, a maioria dos processos qu\u00edmicos apresentam fatores que dificultam a modelagem, devido \u00e0s caracter\u00edsticas como n\u00e3o linearidade, presen\u00e7a de tempo morto e exist\u00eancia de par\u00e2metros que variam com o tempo. Aliado a essas dificuldades intr\u00ednsecas ao processo tem-se, ainda, os crit\u00e9rios econ\u00f4micos da produ\u00e7\u00e3o de determinado produto com menor custo e elevada qualidade. Esses fatores t\u00eam contribu\u00eddo para que as ind\u00fastrias optem por novas estrat\u00e9gias de controle, tal como o controle preditivo e o controle adaptativo, pois controladores convencionais a par\u00e2metros constantes, apresentam desempenho limitado (FERRARI, 2010). Seborg, et al. (2010) ressaltam que o controle preditivo baseia-se na determina\u00e7\u00e3o das sequ\u00eancias adotadas pela estrat\u00e9gia de controle durante a medi\u00e7\u00e3o dos valores reais para a predi\u00e7\u00e3o dos valores futuros de sa\u00edda.\nNa maioria dos processos industriais o uso dos procedimentos de projeto de controladores preditivos apresentam dificuldades, pois dependem da modelagem matem\u00e1tica do processo que, em muitos casos, n\u00e3o \u00e9 simples ou apresenta problemas no quesito da incorpora\u00e7\u00e3o de dados dispon\u00edveis, a partir do conhecimento de especialistas. Nestes casos, t\u00e9cnicas de identifica\u00e7\u00e3o baseadas em redes neuronais artificiais t\u00eam sido aplicadas. Por causa da habilidade de aproximar fun\u00e7\u00f5es complexas, a RNA tem sido explorada como modelo de processos qu\u00edmicos (HAYKIN, 2001). A vantagem principal deste modelo \u00e9 que pode ser sintetizado sem conhecimento detalhado do processo em quest\u00e3o, atuando apenas ap\u00f3s a apresenta\u00e7\u00e3o de informa\u00e7\u00f5es caracter\u00edsticas do processo em particular. Esta propriedade \u00e9 comum a uma grande classe de modelos funcionais, conhecidos como modelos n\u00e3o-param\u00e9tricos, que incluem RNA e s\u00e9rie de Fourier, por exemplo. Por\u00e9m, a grande dificuldade da utiliza\u00e7\u00e3o de uma RNA \u00e9 devido \u00e0 necessidade de um conjunto relativamente grande de dados de entrada/sa\u00edda do processo, para seu treinamento, que nem sempre est\u00e3o dispon\u00edveis ou pass\u00edveis de obten\u00e7\u00e3o.\nRNA t\u00eam sido aplicadas a um n\u00famero crescente de problemas do mundo real de consider\u00e1vel complexidade. Sua vantagem mais importante \u00e9 na resolu\u00e7\u00e3o de problemas que n\u00e3o t\u00eam uma solu\u00e7\u00e3o algor\u00edtmica ou para os quais a solu\u00e7\u00e3o algor\u00edtmica \u00e9 demasiadamente complexa para ser determinada. Assim a RNA \u00e9 capaz de aprender e generalizar a partir de\nalguns exemplos espec\u00edficos, reconhecendo os padr\u00f5es e caracter\u00edsticas do sinal mesmo na presen\u00e7a de ru\u00eddo (BAUGHMAN e LIU, 1995).\nDado que o escopo deste trabalho finda o uso de redes neuronais artificiais em sistemas de controle autom\u00e1tico de processos, as pr\u00f3ximas se\u00e7\u00f5es t\u00eam como objetivo abordar os conceitos desta \u00e1rea (RNA).\n2.6\tRedes Neuronais - Neur\u00f4nio Biol\u00f3gico\nO c\u00e9rebro humano \u00e9 considerado como um dos mais complexos processadores, sendo constitu\u00eddo de aproximadamente 10 bilh\u00f5es de neur\u00f4nios, respons\u00e1veis pelo processamento das fun\u00e7\u00f5es e movimenta\u00e7\u00f5es do organismo (HAYKIN, 2001).\nO neur\u00f4nio biol\u00f3gico \u00e9 composto pelas seguintes se\u00e7\u00f5es (vide Figura 2.10): corpo celular; dendritos; ax\u00f4nio e suas termina\u00e7\u00f5es. Segundo Haykin (2001), os dendritos recebem as informa\u00e7\u00f5es de entrada (ou est\u00edmulos) de outros neur\u00f4nios, atrav\u00e9s de impulsos nervosos, e conduzem essas informa\u00e7\u00f5es at\u00e9 o corpo celular. Nesta etapa a informa\u00e7\u00e3o \u00e9 processada e um segundo impulso (com a a\u00e7\u00e3o) flui do corpo celular para o ax\u00f4nio. Caso este esteja conectado com outro neur\u00f4nio, a informa\u00e7\u00e3o ser\u00e1 repassada.\nRessalta-se que os locais de contato entre os neur\u00f4nios s\u00e3o denominados de sinapse, enquanto que o conjunto total dos neur\u00f4nios \u00e9 classificado como rede neuronal.\nFigura 2.10 - Neur\u00f4nio biol\u00f3gico.\nFonte: StatSoft (2015).\nSendo assim, pesquisadores apresentaram interesse em simular o comportamento das redes biol\u00f3gicas a fim de utiliz\u00e1-las na modelagem de sistemas complexos. Deste modo foi desenvolvido o conceito de redes neuronais artificiais, conforme descrito nas pr\u00f3ximas se\u00e7\u00f5es.\n2.1\tRedes Neuronais Artificiais\nAs redes neuronais artificiais (RNA), tamb\u00e9m conhecidas como \u201credes neurais\u201d, resultaram de estudos sobre intelig\u00eancia artificial (IA). Segundo Barr e Feigenbaum (1981), o objetivo da IA \u00e9 desenvolver sistemas computacionais inteligentes, que simulem o comportamento do c\u00e9rebro humano ao resolver determinadas tarefas. Pode-se destacar as seguintes tecnologias como as principais no ramo da IA: sistemas especialistas, sistemas de l\u00f3gica \u201cFuzzy\u201d e redes neuronais artificiais (VERDUIN, 1995; CROWE e VASSILIADIS, 1995 apud BAUGHMAN e LIU, 1995).\nOs sistemas especialistas realizam processamentos macrosc\u00f3picos e simb\u00f3licos, atrav\u00e9s de dados n\u00e3o num\u00e9ricos (ou nomes). J\u00e1 os sistemas de l\u00f3gica \u201cFuzzy\u201d objetivam a quantifica\u00e7\u00e3o de sistemas baseados em regras, isto \u00e9, apresentam como racioc\u00ednio a utiliza\u00e7\u00e3o de representa\u00e7\u00f5es qualitativas aproximadas em quantitativas. Por outro lado, as redes neuronais artificiais realizam processamentos subsimb\u00f3licos, caracterizados por itera\u00e7\u00f5es microsc\u00f3picas que eventualmente se manifestam como macrosc\u00f3picas (BAUGHMAN e LIU, 1995).\nEm concord\u00e2ncia, Haykin (2001) define RNA como uma \u201cm\u00e1quina\u201d projetada para modelar a forma na qual o c\u00e9rebro humano trabalha, sendo estruturada a partir de unidades de processamento (neur\u00f4nios) maci\u00e7os, paralelamente distribu\u00eddos na rede. A aprendizagem da rede \u00e9 feita pelos neur\u00f4nios, que s\u00e3o capazes de processar os sinais.\nUma caracter\u00edstica marcante da RNA \u00e9 a sua total independ\u00eancia da natureza fenomenol\u00f3gica do processo a ser abordado (modelo \u201ccaixa preta\u201d), de modo que tal abordagem torna-se interessante quando as rela\u00e7\u00f5es entre as vari\u00e1veis de um determinado fen\u00f4meno s\u00e3o muito complexas (BENITEZ, CASTRO e REQUENA, 1997).\nNeste contexto, Haykin (2001) aponta os seguintes beneficios das redes neuronais artificiais: n\u00e3o linearidade; mapeamento de entrada e sa\u00edda; adaptabilidade; uniformidade de an\u00e1lise e projeto; analogia neurobiol\u00f3gica, dentre outros.\nEm complemento, Baughman e Liu (1995) apresentam como vantagens das RNA: informa\u00e7\u00e3o distribu\u00edda atrav\u00e9s dos neur\u00f4nios; habilidade de aprendizado; melhor adequa\u00e7\u00e3o para o processamento de dados ruidosos, incompletos ou inconsistentes.\nBaughman e Liu (1995) destacam tamb\u00e9m as seguintes limita\u00e7\u00f5es do uso de redes neuronais artificiais: longos tempos de treinamento; necessidade de grande quantidade de dados para treinamento da RNA; sem garantia de resultados \u00f3timos; sem garantia de 100% de confiabilidade.\nApesar das limita\u00e7\u00f5es acima, o uso de RNA tem apresentado grande destaque em diversas \u00e1reas, tais como, ci\u00eancias e engenharias, uma vez que consegue resolver problemas cujas solu\u00e7\u00f5es anal\u00edticas n\u00e3o s\u00e3o poss\u00edveis (BAUGHMAN e LIU, 1995).\nRibeiro (2013) avaliou em seu trabalho a qualidade de imagens emitidas por sat\u00e9lites, em duas \u00e1reas diferentes no Paran\u00e1, atrav\u00e9s de m\u00e9todo de classifica\u00e7\u00e3o por redes neuronais artificiais. As redes foram treinadas a partir de m\u00e9todo quantitativo e proporcionaram adequa\u00e7\u00e3o ao estudo, tendo em vista que ao simular as atividades humanas apresentaram objetividade e agilidade.\nBoareto Mendes (2005) destacou em seu trabalho a import\u00e2ncia do desenvolvimento de modelos matem\u00e1ticos com alta representa\u00e7\u00e3o para o comportamento de processos fermentativos. Assim, partindo de um modelo proposto anteriormente na literatura para a representa\u00e7\u00e3o da produ\u00e7\u00e3o de lipase por Candida rugosa, Boareto Mendes (2005) estudou o desenvolvimento de um modelo h\u00edbrido-neuronal/fenomenol\u00f3gico que representasse o processo com efici\u00eancia, uma vez que o anterior apresentou baixa representa\u00e7\u00e3o para a atividade lipol\u00edtica. Ao final do estudo constatou que o novo modelo, utilizando rede neuronal artificial, obteve alta efici\u00eancia e adequa\u00e7\u00e3o ao processo em estudo.\nEm similaridade Rosa e Luz (2012) destacaram em seu trabalho a import\u00e2ncia do uso de m\u00e9todos matem\u00e1ticos para a simula\u00e7\u00e3o de processos qu\u00edmicos, tendo em vista a simplicidade para alterar os dados, sem a necessidade de modificar as vari\u00e1veis durante o processo, muitas vezes dif\u00edcil. O artigo em quest\u00e3o teve como objetivo simular o processo de moagem seletiva de mesclas bin\u00e1rias atrav\u00e9s do uso de redes neuronais artificiais, observando as propor\u00e7\u00f5es dos componentes e o tempo de processamento. Embora tenham apontado que a maioria dos trabalhos da literatura utilizam modelos de balan\u00e7o populacional, os autores utilizaram as RNA na busca da simplifica\u00e7\u00e3o e da otimiza\u00e7\u00e3o do processo.\nLinhares, J\u00fanior e Ara\u00fajo (2007) estudaram a aplica\u00e7\u00e3o da RNA para identificar a fra\u00e7\u00e3o molar de pentano na composi\u00e7\u00e3o do GLP, a partir de vari\u00e1veis secund\u00e1rias da planta. Tendo em vista o processo de separa\u00e7\u00e3o do GLP da gasolina natural, atrav\u00e9s de uma debutanizadora simulada, os autores destacaram a import\u00e2ncia do controle de qualidade do GLP, uma vez que durante a separa\u00e7\u00e3o, parte de pentanos podem contaminar o g\u00e1s. Neste caso o uso das redes neuronais artificiais teve como objetivo, tamb\u00e9m, apresentar solu\u00e7\u00f5es alternativas ao uso de cromat\u00f3grafos para a identifica\u00e7\u00e3o da fra\u00e7\u00e3o molar, devido aos longos tempos de medi\u00e7\u00e3o e altos custos.\nAndrade, et al. (2010) descreveram em seu trabalho o uso de redes neuronais artificiais para modelar o processo de produ\u00e7\u00e3o de \u00e1cido succ\u00ednio por via fermentativa, utilizando a cepa Actinobacillus succinogenes. A pesquisa teve como objetivo, testar o uso de mat\u00e9rias-primas renov\u00e1veis para obten\u00e7\u00e3o do \u00e1cido, pois o processo de s\u00edntese qu\u00edmica atual consiste na utiliza\u00e7\u00e3o de produtos n\u00e3o renov\u00e1veis, caros e poluentes.\nFerrari (2010) desenvolveu em seu trabalho a sintonia dos controladores de n\u00edvel de uma planta com tr\u00eas tanques acoplados. Para isso, o autor comparou os m\u00e9todos tradicionais de sintonia de controladoes (Ziegler-Nichols) com o m\u00e9todo de redes neuronais artificiais e verificou que apesar da sintonia pela RNA apresentar respostas mais lentas, seu desempenho foi superior aos m\u00e9todos tradicionais.\n2.8 Modelagem atrav\u00e9s de Rede Neuronal Artificial (RNA)\nConforme citado anteriormente, a RNA \u00e9 composta por neur\u00f4nios, capazes de processar os sinais, sendo que estes s\u00e3o enviados com pesos.\nSegundo Haykin (2001), uma vez que a rede esteja desenvolvida, o processo de aprendizagem dever\u00e1 ocorrer a partir dos ajustes dos pesos sin\u00e1pticos, referentes aos sinais de entrada e sa\u00edda dos neur\u00f4nios.\nAssim, nas pr\u00f3ximas se\u00e7\u00f5es ser\u00e3o descritas as informa\u00e7\u00f5es necess\u00e1rias para a modelagem de redes neuronais artificiais, tais como, sua arquitetura e m\u00e9todos de treinamento.\n2.8.1\tArquitetura e Equacionamento dos Modelos Neuronais\nAs redes neuronais artificiais s\u00e3o compostas por neur\u00f4nios, interconectados entre si atrav\u00e9s de uma rede. Baughman e Liu (1995) apontam a exist\u00eancia de tr\u00eas poss\u00edveis conex\u00f5es (vide Figura 2.11): conex\u00e3o na mesma camada, conex\u00e3o entre camadas e conex\u00e3o recorrente.\n\t\u2022 \u2022 \u2022\t\u2022 \u2022 \u2022\n* \u2022 f\to-chd\t0^0\nO 0'0\to\"oo\t0 o(\u00f2\na) Conex\u00e3o na mesma\tb) Conex\u00e3o entre\tc) Conex\u00e3o\ncamada\tCamadas\trecorrente\nFigura 2.11. Conex\u00f5es entre os neur\u00f4nios.\n\u00c9 importante destacar que a conex\u00e3o entre camadas \u00e9 a mais utilizada, sendo dividida em \u201cfeedforward\u201d e \u201cfeedback\u201d, cujas aplica\u00e7\u00f5es s\u00e3o, respectivamente, treinar a RNA para determinar a sa\u00edda atrav\u00e9s dos sinais de entrada e desenvolver a RNA para treinar a si pr\u00f3pria (BAUGHMAN e LIU, 1995).\nA Figura 2.12 demonstra a estrutura mais utilizada para descrever o modelo de redes neuronais artificiais: uma camada de entrada, uma camada escondida e uma camada de sa\u00edda, interligadas atrav\u00e9s de uma conex\u00e3o \u201cfeedforward\u201d.\nCamada\t\u201e\t,\tCamada\nCamada\t,\nde\tde\n_ x ,\tEscondida\t_ ,.\nEntrada\tSa\u00edda\nFigura 2.12 - Modelo de RNA multicamadas (MLP - Multilayer Perceptron).\nAtrav\u00e9s desta estrutura, a camada de entrada recebe uma informa\u00e7\u00e3o externa e envia, atrav\u00e9s da rede, para a camada escondida. Nesta camada \u00e9 desenvolvida a an\u00e1lise e resolu\u00e7\u00e3o do problema, sem a disponibiliza\u00e7\u00e3o dos passos (etapa onde a maior parte do processamento \u00e9 realizada). Na sequ\u00eancia, a informa\u00e7\u00e3o final \u00e9 repassada \u00e0 camada de sa\u00edda, que envia o resultado ao meio externo (BAUGHMAN e LIU, 1995).\nPara fins de modelagem de redes neuronais artificiais, Haykin (2001) define o neur\u00f4nio individual como uma unidade de processamento de informa\u00e7\u00e3o, com fundamental import\u00e2ncia para o estudo de RNA, fazendo-se necess\u00e1rio conhecer o seu modelo. A Figura 2.13 apresenta a estrutura do jesimo neur\u00f4nio.\nf(xj)\n^71.\nFigura 2.13 Estrutura do jesimo neur\u00f4nio.\nEste modelo \u00e9 constitu\u00eddo por sinais de entrada (at), dispostos atrav\u00e9s de vetores, que s\u00e3o multiplicados por seus respectivos pesos individuais (wjt), considerando-se i como a entrada da sinapse no neur\u00f4nio j. Os \u00edndices multiplicados seguem para um somador que representa o total de ativa\u00e7\u00e3o de um neur\u00f4nio (xj), no qual inclui-se o par\u00e2metro externo 0j (bias), cujo efeito \u00e9 de aumentar ou diminuir a entrada l\u00edquida da fun\u00e7\u00e3o de ativa\u00e7\u00e3o. Na sequ\u00eancia \u00e9 realizada uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o,\tcuja sa\u00edda \u00e9 representada por bj.\nEm termos matem\u00e1ticos, a ativa\u00e7\u00e3o do neur\u00f4nio pode ser descrita na Equa\u00e7\u00e3o 2.1:\nn\nTotal de ativa\u00e7\u00e3o = x.\n(wji.ai) - 6j\n(2.1)\ni=i\nE a fun\u00e7\u00e3o de transfer\u00eancia na Equa\u00e7\u00e3o 2.2:\nf(xj) = f(wJi. ai - ei) = f\t(wii. a\u00d2 - ei\n(2.2)\nPara determinar a forma de /(*/), pode-se utilizar diversas fun\u00e7\u00f5es. Neste trabalho foram consideradas as fun\u00e7\u00f5es dispon\u00edveis no programa utilizado para o treinamento da RNA (vide Tabela 2.1).\nTabela 2.1 - Fun\u00e7\u00f5es de ativa\u00e7\u00e3o utilizadas para treinamento das redes neuronais artificiais, no programa Statistica 12.0.\nFun\u00e7\u00e3o\tEqua\u00e7\u00e3o\tRange\nIdentidade\ta\t(-ot,+ot)\nLog\u00edstica\t1 1+e\u201c\t(0,1)\nTangente Hiperb\u00f3lica\tea\u2014e~a ea+e~a\t(-1,+1)\nExponencial\te\u2014a\t(0,+ot)\nSeno\tsen(a)\t(0,1)\nSoftmax\texp(aj) Sexp(az)\t(0,1)\nGaussiana\ti\tr(x\u2014u)2' -^=exp \t\u2014 \u2022J2n\u00e3 \u2018 . 2<z2 .\t\nOnde \u201ca\u201d refere-se \u00e0 entrada l\u00edquida de um neur\u00f4nio (no caso da MLP a soma ponderada dos neur\u00f4nios). Para a fun\u00e7\u00e3o gaussiana, \u201cx\u201d representa o vetor de entrada dos neur\u00f4nios, \u201cp\u201d o vetor de pesos de entrada e \u201co\u201d a propaga\u00e7\u00e3o das Rede de Fun\u00e7\u00e3o de Base Radial (RBF, abordada na se\u00e7\u00e3o 2.3.2).\n\u00c9 importante destacar que as redes neuronais artificiais operam conforme \u201cajuste de reta\u201d e podem ser substitu\u00eddas por modelos emp\u00edricos matem\u00e1ticos, dependendo da sua aplica\u00e7\u00e3o. A RNA possui melhor capacidade de filtro e trabalha com informa\u00e7\u00f5es paralelas, divididas entre os n\u00f3s. Assim, n\u00e3o apresenta grande depend\u00eancia em um n\u00f3, como por exemplo, outros modelos emp\u00edricos apresentam para as vari\u00e1veis independentes (BAUGHMAN &amp; LIU, 1995).\nEm rela\u00e7\u00e3o \u00e0s demais vantagens do uso de RNA em compara\u00e7\u00e3o com outros modelos emp\u00edricos, Baughman e Liu (1995) ressaltam tamb\u00e9m a capacidade adaptativa com possibilidade de ajustes atrav\u00e9s de novos treinamentos e melhor reconhecimento de padr\u00f5es, devido ao sistema MIMO (\u201cMultiple-Input and Multiple-Output\u201d - entradas e sa\u00eddas m\u00faltiplas).\n2.8.2\tTipos de RNA\nExiste uma variedade de tipos de redes neuronais artificiais estudados atualmente, desde os mais simples at\u00e9 os mais complexos. A seguir s\u00e3o demonstrados os modelos mais utilizados na literatura:\n\u2022\tPerceptrons de Camada \u00danica: forma mais simples de uma RNA, para o qual foi desenvolvido o primeiro algoritmo de treinamento. Segundo Haykin (2001) este modelo \u00e9 utilizado para a classifica\u00e7\u00e3o de padr\u00f5es \u201clinearmente separ\u00e1veis\u201d (padr\u00f5es que se encontram em lados opostos de um hiperplano).\n\u2022\tPerceptrons de M\u00faltiplas Camadas (Multilayer Perceptron, MLP): tipo de RNA mais comumente utilizado, concentrando-se em redes do tipofeedforward, com algoritmo backpropagation.\n\u2022\tRedes de Fun\u00e7\u00e3o de Base Radial (RBF): tipo de RNA bastante utilizado, ap\u00f3s a MLP, apresentando como principal diferen\u00e7a a forma de treinamento. Enquanto na MLP o treinamento ocorre em um est\u00e1gio, a RBF \u00e9 treinada em dois est\u00e1gios (no primeiro ocorre a modelagem da distribui\u00e7\u00e3o de probabilidade dos dados de entrada, enquanto que no segundo o aprendizado do par entrada-sa\u00edda fornecido). Outro fator de diferen\u00e7a \u00e9 que na RBF os \u201cbias\u201d s\u00e3o somados apenas aos neur\u00f4nios da camada de sa\u00edda.\nSegundo StatSoft (2015) a RBF proporciona, geralmente, erros menores e uma converg\u00eancia mais r\u00e1pida que as redes MLP, por\u00e9m esta \u00faltima rede apresenta capacidade de generaliza\u00e7\u00e3o superior.\nHaykin (2001) complementa que a RBF projeta a RNA a partir da aproxima\u00e7\u00e3o no ajuste de curva em um espa\u00e7o de alta dimensionalidade. Isto \u00e9, verificou-se que processos de classifica\u00e7\u00e3o de padr\u00f5es dispostos em um espa\u00e7o com alta dimens\u00e3o apresentam maiores probabilidades de serem linearmente separ\u00e1veis, do que se estivessem em baixas dimens\u00f5es. Assim, a dimens\u00e3o da RBF normalmente \u00e9 mais alta que de uma MLP, sendo que este fator \u00e9 ajustado no aumento do n\u00famero de neur\u00f4nios na camada escondida, o que resulta no aumento de par\u00e2metros do sistema (pesos e \u201cbias\u201d).\n2.8.3\tDesenvolvimento das Redes Neuronais Artificiais\nPara o desenvolvimento da RNA deve-se primeiramente realizar a coleta dos dados experimentais, separando-os em dois conjuntos, sendo um para treinamento e outro para teste. Esta etapa \u00e9 de fundamental import\u00e2ncia e ir\u00e1 definir o desempenho da rede.\nA partir dos conjuntos determinados ocorre o treinamento das redes. Para isto faz-se necess\u00e1rio estabelecer o processo de aprendizagem das redes neuronais artificiais. Este processo \u00e9 classificado conforme relacionamento da RNA com o ambiente (STATSOFT, 2015):\n\u2022\tAprendizado supervisionado: apresenta em sua estrutura um \u201cprofessor\u201d ou \u201cinstrutor\u201d que correlaciona os dados de sa\u00edda da RNA com a sa\u00edda desejada (resultado previamente conhecido) e realiza ajustes nos pesos entre os neur\u00f4nios, a fim de minimizar os erros at\u00e9 um crit\u00e9rio aceit\u00e1vel.\n\u2022\tAprendizado n\u00e3o supervisionado: neste processo de aprendizagem n\u00e3o existe uma sa\u00edda conhecida para compara\u00e7\u00e3o. Os ajustes dos pesos entre os neur\u00f4nios s\u00e3o realizados automaticamente atrav\u00e9s de classifica\u00e7\u00f5es dos padr\u00f5es de entrada, em grupos.\nAp\u00f3s definido o m\u00e9todo de aprendizado ocorre o treinamento da rede a partir da apresenta\u00e7\u00e3o dos dados selecionados de entrada, com suas respectivas sa\u00eddas, para que a RNA possa aprender com este par e assim realizar os ajustes dos pesos entre as conex\u00f5es para obter resultados pr\u00f3ximos ao real.\n\u00c9 importante destacar que o algoritmo mais utilizado atualmente para ensino da rede \u00e9 o backpropagation, que consiste em um aprendizado supervisionado, isto \u00e9, a partir dos erros calculados entre os valores de sa\u00edda das redes neuronais artificiais com o valor desejado, este algoritmo realiza o ajuste dos pesos entre as camadas atrav\u00e9s da retropropaga\u00e7\u00e3o do erro encontrado, para cada itera\u00e7\u00e3o (HAYKIN, 2001).\nO objetivo do treinamento por retropropaga\u00e7\u00e3o \u00e9 ajustar os pesos e \u201cbias\u201d da rede, modificando-os at\u00e9 que a aplica\u00e7\u00e3o de um conjunto de entradas produza a sa\u00edda da rede que corresponda \u00e0s sa\u00eddas desejadas ou alvos. Para isso, apresentam-se muitos exemplos de dados hist\u00f3ricos \u00e0 RNA. Treinar a rede, neste caso, corresponde a minimizar a fun\u00e7\u00e3o objetivo n\u00e3o linear que d\u00e1 o erro entre as sa\u00eddas \u201cs\u201d - preditas pela rede - e as sa\u00eddas alvos \u201ct\u201d para Np padr\u00f5es em fun\u00e7\u00e3o dos pesos e \u201cbias\u201d, que s\u00e3o as vari\u00e1veis independentes de otimiza\u00e7\u00e3o. A fundamenta\u00e7\u00e3o matem\u00e1tica do m\u00e9todo encontra-se descrita em diversas refer\u00eancias\n(BAUGHMAN e LIU, 1995; HAYKIN, 2001; DE SOUZA JR., 1993). Nesse mesmo sentido, Fonseca (1998) descreve a metodologia da t\u00e9cnica de treinamento por retropropaga\u00e7\u00e3o, abordando os conceitos e, do ponto de vista de otimiza\u00e7\u00e3o, a fun\u00e7\u00e3o objetivo com a condi\u00e7\u00e3o necess\u00e1ria para o m\u00ednimo, al\u00e9m de variantes do m\u00e9todo.\nPara o c\u00e1lculo dos erros, Baughman e Liu (1995) apontam a utiliza\u00e7\u00e3o da Equa\u00e7\u00e3o 2.3, para cada neur\u00f4nio.\nek = dk \u2014 ck\t(2.3)\nOnde (kconsiste no erro da sa\u00edda (representado por um vetor), dk representa a sa\u00edda desejada (valor conhecido e pr\u00e9-determinado) e ck \u00e9 o valor de sa\u00edda calculado para o neur\u00f4nio k, na camada de sa\u00edda.\nEm seguida, \u00e9 calculado o erro quadr\u00e1tico atrav\u00e9s da Equa\u00e7\u00e3o 2.4.\nE = ^ek= ^(dk \u2014 ck)2\t(2.4)\nk\tk\nConhecido o valor de E, pode-se ent\u00e3o determinar a varia\u00e7\u00e3o do peso para a conex\u00e3o i do j\u00e9simo neur\u00f4nio, conforme descrito na Equa\u00e7\u00e3o 2.5.\n\u00e0wtj = ^j.at.E\t(2.5)\nOnde \u00e9 a constante linear de proporcionalidade do neur\u00f4nio j (normalmente 0 &lt;<&lt;1) e a! consiste na entrada i do neur\u00f4nio j.\nVale ressaltar que para se utilizar o algoritmo de backpropagation \u00e9 necess\u00e1rio que a rede neuronal artificial seja um perceptron, isto \u00e9, a conex\u00e3o utilizada deve ser apenas entre camadas e feedforward.\nBaughman e Liu (1995) descrevem tamb\u00e9m os seguintes algoritmos para ensino da RNA:\n\u2022 Treinamento por refor\u00e7o: trata-se de uma forma de aprendizagem simples, classificada como \u201cseletivamente supervisionada\u201d. Enquanto o algoritmo de backpropagation utiliza um vetor para classifica\u00e7\u00e3o dos erros na sa\u00edda, o\ntreinamento por refor\u00e7o utiliza apenas um valor de erro, que representa toda a performance da rede neuronal artificial.\n\u2022\tTreinamento estoc\u00e1stico: utiliza dados estat\u00edsticos para ajustar os pesos entre os neur\u00f4nios.\n\u2022\tRedes neuronais pr\u00e9-determinadas: conforme o nome, s\u00e3o utilizadas redes neuronais artificiais cujas conex\u00f5es e pesos s\u00e3o conhecidos. Dado ao conhecimento pr\u00e9-determinado, este algoritmo apresenta como vantagem a rapidez em rela\u00e7\u00e3o aos demais.\n\u2022\tTreinamento Hebbiano: o ajuste dos pesos \u00e9 realizado atrav\u00e9s de correla\u00e7\u00e3o entre os dois neur\u00f4nios associados.\nO tempo gasto em treinamento varia em rela\u00e7\u00e3o ao sistema em an\u00e1lise, sendo que para o algoritmo de backpropagation o crit\u00e9rio de parada n\u00e3o \u00e9 bem definido. Neste caso utiliza-se, normalmente, um n\u00famero de ciclos pr\u00e9-definidos.\nAp\u00f3s o treinamento da rede, ocorre a fase de teste (verifica\u00e7\u00e3o da performance da rede neuronal artificial estabelecida), a partir das seguintes etapas (BAUGHMAN e LIU, 1995):\n\u2022\tEtapa de recorda\u00e7\u00e3o (recall step): s\u00e3o enviados dados de entrada, cujas sa\u00eddas s\u00e3o conhecidas pela rede, para observa\u00e7\u00e3o dos valores gerados.\n\u2022\tEtapa de generaliza\u00e7\u00e3o (generalization step): s\u00e3o enviados dados de entrada, cujas sa\u00eddas s\u00e3o conhecidas pelo observador, por\u00e9m desconhecidas pela rede, a fim de verificar os erros obtidos entre os valores preditos versus os valores observados. Esta \u00faltima etapa tem como objetivo obter valores m\u00ednimos de erro.\nA Figura 2.14 demonstra, como exemplo, uma curva de processo t\u00edpico de aprendizado de uma rede neuronal artificial.\nFigura 2.14 - Esquema de funcionamento do treinamento com os subconjuntos de dados para treinamento e para teste.\nFonte: Adaptado de Baughman e Liu (1995).\nPode-se verificar que, para ambas as etapas, \u00e9 importante que se utilize uma grande quantidade de padr\u00f5es no treinamento para que as respostas do sistema sejam eficazes. O crit\u00e9rio de parada \u00e9 adotado quando o erro de teste aumentar, apesar de erro treinamento diminuir.\nFinalmente, \u00e9 realizada a an\u00e1lise da RNA treinada com rela\u00e7\u00e3o ao sistema de estudo, para verificar o seu desempenho.\nCap\u00edtulo 3 METODOLOGIA\nNeste cap\u00edtulo \u00e9 descrita a planta piloto e a metodologia utilizada nos testes experimentais realizados na unidade experimental. Descreve-se tamb\u00e9m a metodologia da coleta dos dados para o treinamento das redes neuronais artificiais, que constituem o sistema de estudo.\n3.1\tDescri\u00e7\u00e3o da planta\n3.1.1\tPlanta e Equipamentos\nO equipamento utilizado como objeto de estudo \u00e9 a Planta Did\u00e1tica da SMAR\u00ae, que consiste de um arranjo compacto de diversas malhas de controle, utilizando as instrumenta\u00e7\u00f5es e ferramentas de configura\u00e7\u00e3o desenvolvidas para aplica\u00e7\u00e3o em controles industriais. Tal configura\u00e7\u00e3o permite ao usu\u00e1rio atuar na modifica\u00e7\u00e3o de valores e registros internos, atrav\u00e9s de simula\u00e7\u00f5es reais (BOTTO e CASSIOLATO, 2012).\nA planta em an\u00e1lise neste trabalho \u00e9 a PD3 Fieldbus, adquirida atrav\u00e9s de projeto de aux\u00edlio a pesquisa da FAPERJ (E-26 110.861/2011). A Planta PD3 consiste de processo cont\u00ednuo, composta basicamente de tr\u00eas tanques cil\u00edndricos, cinco transmissores Fieldbus, duas bombas de partida direta, duas v\u00e1lvulas autom\u00e1ticas de controle, uma resist\u00eancia de imers\u00e3o, um painel de opera\u00e7\u00e3o local e um CLP (modelo LC700, SMAR). A princ\u00edpio este equipamento n\u00e3o tem como objetivo a produ\u00e7\u00e3o de nenhum tipo de produto, sendo puramente experimental. O seu funcionamento, consiste basicamente na circula\u00e7\u00e3o de l\u00edquido atrav\u00e9s dos tanques, podendo existir estrat\u00e9gias diferentes de atua\u00e7\u00e3o sobre estes. A planta possui um tanque central, ou tanque reservat\u00f3rio, que tem a fun\u00e7\u00e3o de estocar o l\u00edquido que ser\u00e1 enviado para os demais tanques, n\u00e3o existindo nenhum dispositivo de controle e automa\u00e7\u00e3o. O transporte do l\u00edquido para os demais tanques (tanque de aquecimento e de mistura) \u00e9 realizado por duas bombas, dispostas em paralelo, cujas vaz\u00f5es s\u00e3o manipuladas por v\u00e1lvulas autom\u00e1ticas, dispostas na entrada dos tanques. Ao longo das tubula\u00e7\u00f5es e nos tanques, existem ainda alguns transdutores que s\u00e3o respons\u00e1veis por monitorar a vaz\u00e3o, o n\u00edvel e a temperatura, conforme manual da planta did\u00e1tica (SMAR).\nA Figura 3.1 apresenta a planta PD3, em estudo.\nFigura 3.1 - Planta Did\u00e1tica PD3 da SMAR.\nO sistema da planta \u00e9 dividido em dois setores (setor 31 e setor 32), sendo que a primeira constitui no tanque de aquecimento e os equipamentos auxiliares, enquanto que a segunda representa o tanque de mistura e seus equipamentos auxiliares. No descrito trabalho ser\u00e3o utilizadas nomenclaturas referentes a cada malha, conforme apresentado no diagrama P&amp;ID da Figura 3.2. Para fins de estudo, o tanque reservat\u00f3rio foi denominado como setor 30.\nFigura 3.2 - Diagrama P&amp;ID da planta PD3, com indica\u00e7\u00e3o do fluxo realizado pela \u00e1gua nos experimentos.\nFonte: Adaptado de manual da planta did\u00e1tica (SMAR).\nA seguir s\u00e3o apresentados com maiores detalhes a instrumenta\u00e7\u00e3o e software da planta:\n\u2022\tPlataforma de Controle e Automa\u00e7\u00e3o de Processos, atrav\u00e9s do System 302. Dentre esta plataforma, a esta\u00e7\u00e3o de trabalho mais comumente utilizada \u00e9 o Process View, que oferece os seguintes pacotes:\n\u2756\tGraphworkX32: respons\u00e1vel pela visualiza\u00e7\u00e3o do processo.\n\u2756\tAlarmWorkX32: respons\u00e1vel pela aquisi\u00e7\u00e3o e gerenciamento dos alarmes.\n\u2756\tTrendWorkX32: respons\u00e1vel pela aquisi\u00e7\u00e3o e gerenciamento de tend\u00eancia (real e hist\u00f3rica).\n\u2022\t1 tanque fechado de aquecimento, com 25 litros, presente na malha 31 (Tanque-31), onde a \u00e1gua do sistema \u00e9 aquecida, atrav\u00e9s da resist\u00eancia de imers\u00e3o.\n\u2022\t1 tanque de mistura, tamb\u00e9m fechado e com 25 litros, presente na malha 32 (Tanque-32), onde ocorre a mistura do l\u00edquido aquecido no Tanque-31 com a \u00e1gua fria proveniente do tanque reservat\u00f3rio.\n\u2022\t1 tanque reservat\u00f3rio aberto, com 60 cent\u00edmetros de di\u00e2metro e aproximadamente 26 cent\u00edmetros de altura m\u00e1xima da \u00e1gua. Assim sendo, apresenta um volume total de 73,5 litros.\n\u2022\t2 bombas hidr\u00e1ulicas que promovem a circula\u00e7\u00e3o de l\u00edquido pelas tubula\u00e7\u00f5es da planta. Consistem de moto-bombas centr\u00edfugas que possuem alto rendimento e possibilitam a eleva\u00e7\u00e3o do fluido bombeado at\u00e9 70 metros, sendo acionadas por motor de indu\u00e7\u00e3o do tipo fechado e auto-ventilado (monof\u00e1sico: 220 Vac -60Hz).\n\u2022\t2 v\u00e1lvulas autom\u00e1ticas de controle do tipo globo, pneum\u00e1ticas, com di\u00e2metro de 0,5 polegadas, que s\u00e3o respons\u00e1veis pelo controle do fluxo de l\u00edquido na planta.\n\u2022\t2 rot\u00e2metros, constitu\u00eddos de tubos de vidro c\u00f4nico, que permitem a indica\u00e7\u00e3o instant\u00e2nea das vaz\u00f5es volum\u00e9tricas de \u00e1gua que saem das respectivas bombas e seguem para os tanques de aquecimento e de mistura.\n\u2022\t1 chave de n\u00edvel, presente no Tanque-31, respons\u00e1vel por detectar quando o n\u00edvel de \u00e1gua est\u00e1 baixo. Caso seja detectado, a chave de n\u00edvel enviar\u00e1 um comando ao painel de controle, para inibir a pot\u00eancia transferida para a resist\u00eancia. Este equipamento atua atrav\u00e9s do princ\u00edpio de condutividade e\nimpede a queima das resist\u00eancias contidas no tanque, uma vez que estas atuam em imers\u00e3o.\n\u2022\t1 conversor est\u00e1tico, respons\u00e1vel por alimentar as resist\u00eancias el\u00e9tricas presentes no Tanque-31. Apresenta como benef\u00edcios: precis\u00e3o, limita\u00e7\u00e3o por fator de demanda, aumento da vida \u00fatil das resist\u00eancias e redu\u00e7\u00e3o do consumo de energia.\n\u2022\t2 resist\u00eancias de imers\u00e3o, presentes no Tanque-31, respons\u00e1veis pelo aquecimento do l\u00edquido do tanque. Ambas possuem pot\u00eancia de 2100 W x 220V.\n\u2022\t1 termostato, respons\u00e1vel por enviar um sinal que iniba o conversor est\u00e1tico quando a temperatura do Tanque-31 atingir o limite m\u00e1ximo informado.\n\u2022\t1 sensor de temperatura PT-100, respons\u00e1vel pela medi\u00e7\u00e3o da temperatura no Tanque-31, fundamentada na varia\u00e7\u00e3o da resist\u00eancia el\u00e9trica de um condutor met\u00e1lico em fun\u00e7\u00e3o da temperatura.\n\u2022\t1 sensor de temperatura do tipo termopar J, respons\u00e1vel pela medi\u00e7\u00e3o da temperatura no Tanque-32.\n\u2022\t3 transmissores de press\u00e3o diferencial Foundation Fieldbus, que realizam a medi\u00e7\u00e3o da press\u00e3o por c\u00e9lula capacitativa, utilizando um microprocessador em seus circuitos eletr\u00f4nicos.\nAs Tags utilizadas s\u00e3o:\n\u2756\tFIT-31: transmissor indicador da vaz\u00e3o de alimenta\u00e7\u00e3o no tanque de aquecimento;\n\u2756\tFIT-32: transmissor indicador da vaz\u00e3o de alimenta\u00e7\u00e3o no tanque de mistura;\n\u2756\tLIT-31: transmissor indicador do n\u00edvel de \u00e1gua no tanque de aquecimento.\n\u2022\t2 transmissores de temperatura Foundation Fielbus, capazes de aceitar o uso de sensores que gerem resist\u00eancia ou milivoltagem, al\u00e9m das medi\u00e7\u00f5es de temperatura por termoresist\u00eancias ou termopares.\nAs Tag\u2019s utilizadas s\u00e3o:\n\u2756\tTIT-31: transmissor indicador da temperatura no tanque de aquecimento;\n\u2756\tTIT-32: transmissor indicador da temperatura no tanque de mistura.\n\u2022\t2 posicionadores de v\u00e1lvula Foundation Fieldbus, respons\u00e1veis pela ativa\u00e7\u00e3o nas v\u00e1lvulas de controle pneum\u00e1ticas, atrav\u00e9s da produ\u00e7\u00e3o de press\u00e3o de sa\u00edda requerida para o posicionamento, conforme o sinal Fieldbus de entrada.\nAs Tags utilizadas s\u00e3o:\n\u2756\tFY-31: conversor de sinal para a v\u00e1lvula de \u00e1gua quente;\n\u2756\tFY-32: conversor de sinal para a v\u00e1lvula de \u00e1gua fria.\n\u2022\t1 conversor Foundation Fieldbus, que converte um sinal Fieldbus em um sinal de 4 a 20 mA.\nA Tag utilizada \u00e9:\n\u2756\tTY-31: corrente para modular a pot\u00eancia de sa\u00edda do conversor est\u00e1tico.\n\u2022\t2 controladores de temperatura, indicados pelas seguintes Tag\u2019s:\n\u2756\tTIC-31: controlador da temperatura do tanque de aquecimento;\n\u2756\tTIC-32: controlador da temperatura do tanque de mistura.\n\u2022\tTubula\u00e7\u00e3o, conex\u00f5es, parafusos e porcas em estruturas de a\u00e7o inox AISI-304. A planta apresenta tamb\u00e9m v\u00e1lvulas manuais esferas em a\u00e7o inox CF8.\n3.1.2\tSistema Supervis\u00f3rio\nSegundo Gaushell (1987) os sistemas supervis\u00f3nos foram implementados a fim de capturar e armazenar as informa\u00e7\u00f5es do processo em um banco de dados. A partir deste sistema \u00e9 apresentada a interface homem/m\u00e1quina atrav\u00e9s de uma tela configurada ao processo em an\u00e1lise, facilitando o monitoramento e o controle das vari\u00e1veis, com r\u00e1pida a\u00e7\u00e3o pelo usu\u00e1rio.\nA interface dos dados experimentais com o computador ocorre atrav\u00e9s da interliga\u00e7\u00e3o de ambos a partir de um controlador l\u00f3gico program\u00e1vel (CLP).\nEm rela\u00e7\u00e3o \u00e0 planta PD3, deve-se ressaltar que o sistema supervis\u00f3rio \u00e9 constitu\u00eddo pelo padr\u00e3o OPC Foundation e pelo sistema SCADA, isto \u00e9, apresenta uma interface de aplica\u00e7\u00f5es mais eficiente (OPC, OLE for Process Control) com o controle e aquisi\u00e7\u00e3o dos dados em tempo real (SCADA, Supervisory Control And Data Acquisition).\nA Figura 3.3 apresenta o sin\u00f3tico da Planta PD3.\nFigura 3.3 - Sin\u00f3tico da planta PD3.\nFonte: manual da planta did\u00e1tica (SMAR).\n3.1.3\tObjeto de Estudo\nNo presente trabalho estudou-se o sistema de aquecimento do Tanque-31, da planta PD3, conforme especificado anteriormente na Figura 3.2.\nA partir deste esquema verifica-se que a temperatura do Tanque-31 \u00e9 afetada por diversos fatores: n\u00edvel de \u00e1gua no tanque; vaz\u00e3o volum\u00e9trica de \u00e1gua na linha; efeito da vari\u00e1vel manipulada; valor determinado como setpoint; temperatura de entrada (temperatura do tanque reservat\u00f3rio) e efeito da resist\u00eancia de imers\u00e3o. Outro fator que tamb\u00e9m afeta est\u00e1 relacionado ao calor dissipado pela bomba, durante o seu funcionamento nas corridas experimentais.\nAssim sendo, \u00e9 not\u00e1vel a complexidade para modelar o sistema em estudo (tendo como objetivo a sintonia dos controladores), devido \u00e0s caracter\u00edsticas n\u00e3o lineares do controle do processo. Braga, Carvalho e Ludermir (2011) apontam que os m\u00e9todos cl\u00e1ssicos utilizados na modelagem de sistemas n\u00e3o lineares apresentam efici\u00eancia, por\u00e9m podem n\u00e3o retrat\u00e1-los de forma fidedigna. Estes m\u00e9todos tamb\u00e9m tornam-se demasiadamente complexos ao se considerar um grande n\u00famero de vari\u00e1veis de entrada. Em contrapartida, as redes neuronais artificiais s\u00e3o consideradas ferramentas bastante apropriadas para tal uso, tendo em vista a sua grande capacidade para descrever processos complexos.\nDesta forma, neste estudo utilizou-se para modelagem matem\u00e1tica a t\u00e9cnica de RNA.\n3.2\tColeta de Dados\nA fim de obter dados representativos do objeto em estudo, optou-se pela realiza\u00e7\u00e3o de testes atrav\u00e9s da modifica\u00e7\u00e3o da vaz\u00e3o de entrada no tanque de aquecimento (FIT-31) e da temperatura desejada na malha de controle 31. Neste caso, a coleta de dados foi realizada nas condi\u00e7\u00f5es descritas nos pr\u00f3ximos t\u00f3picos.\nO fluido utilizado para an\u00e1lise foi a \u00e1gua, considerando as temperaturas desejadas (T-31 D) iguais a 40, 50 e 60\u00b0C. Cada temperatura foi testada para as seguintes vaz\u00f5es da malha 31: 400, 600 e 800 L/h. Estas vaz\u00f5es foram ajustadas atrav\u00e9s da posi\u00e7\u00e3o de abertura da v\u00e1lvula de alimenta\u00e7\u00e3o do tanque de aquecimento. Sendo assim, foram realizados 9 experimentos, conforme representados na Tabela 3.1.\nTabela 3.1 - Testes experimentais para representa\u00e7\u00e3o do sistema e treinamento da RNA.\nN\u00b0 Experimento\tFIT-31 (L/h)\tT-31 D (\u00b0C)\n1\t400\t40\n2\t600\t40\n3\t800\t40\n4\t400\t50\n5\t600\t50\n6\t800\t50\n7\t400\t60\n8\t600\t60\n9\t800\t60\nA fim de descrever o sistema, a malha de controle n\u00e3o foi utilizada, isto \u00e9, utilizou-se a linha de by-pass para a alimenta\u00e7\u00e3o da \u00e1gua no Tanque-31, enquanto que a linha da v\u00e1lvula de controle estava fechada. Na Figura 3.2 (apresentada previamente) pode-se verificar uma ilustra\u00e7\u00e3o na qual as linhas destacadas representam o caminho realizado pela \u00e1gua durante os experimentos. \u00c9 importante ressaltar que a varia\u00e7\u00e3o da corrente el\u00e9trica para alimenta\u00e7\u00e3o da resist\u00eancia alocada no Tanque-31 tamb\u00e9m foi realizada manualmente.\nInicialmente realizou-se o aquecimento da \u00e1gua no Tanque-31 sem que houvesse retorno da \u00e1gua quente para o sistema. Na sequ\u00eancia os demais experimentos foram realizados fazendo com que a \u00e1gua aquecida no Tanque-31 retornasse ao Tanque Reservat\u00f3rio.\nRealizou-se a coleta de dados de todas as vari\u00e1veis medidas pela planta PD3, referentes \u00e0 malha 31. Sendo assim, as vari\u00e1veis consideradas foram:\n\u2022\tT-31 D (\u00b0C): temperatura desejada para a \u00e1gua no Tanque-31.\n\u2022\tT-31 MV (%): vari\u00e1vel manipulada, diretamente ligada \u00e0 resist\u00eancia do Tanque-31.\n\u2022\tTY-31 (mA): corrente para modular a pot\u00eancia de sa\u00edda do conversor est\u00e1tico. Apresenta valores entre 4 a 20 mA, equivalentes a 0 e 100%, respectivamente.\n\u2022\tTIT-31 (\u00b0C): temperatura real do Tanque-31.\n\u2022\tFY-31 (%): conversor de sinal para a v\u00e1lvula de alimenta\u00e7\u00e3o do Tanque-31.\n\u2022\tLIT-31 (%): indicador do percentual de n\u00edvel de \u00e1gua no Tanque-31.\n\u2022\tFIT-31 (L/h): vaz\u00e3o volum\u00e9trica de \u00e1gua na malha 31.\n\u2022\tT-30: temperatura no tanque reservat\u00f3rio. Esta medida n\u00e3o \u00e9 realizada pela planta PD3, sendo assim, a medi\u00e7\u00e3o ocorreu pontualmente, a cada 10 minutos, a partir de um termopar K offline. Ao final, como as varia\u00e7\u00f5es foram pequenas, interpolou-se os valores para a obten\u00e7\u00e3o das temperaturas durante todos os tempos da coleta de dados na planta.\nCada experimento teve dura\u00e7\u00e3o de 2 horas, pois verificou-se que este tempo era eficaz para que o sistema pudesse atingir o novo estado estacion\u00e1rio nas temperaturas estabelecidas.\nO tempo de coleta dos dados experimentais foi realizado a cada 10 segundos, a fim de obter grande quantidade de dados, para serem utilizados no treinamento das redes neuronais artificiais. Outro fator a ser ressaltado \u00e9 que a coleta dos dados foi obtida atrav\u00e9s do sistema supervis\u00f3rio da planta, no qual gerou arquivos em .CSV. A base de dados foi tratada a partir de uma m\u00e1scara desenvolvida previamente para a planta (MELAZZI, SILVA e RAMIREZ, 2015), obtendo os dados separados para cada intervalo do tempo de coleta (vide Figura 3.4).\n\tTIC-31\tT-31 SP\tT-31 MV\tTIC-32\tTY-31\tLI-31\tFY-31\tFY-32\tFI-31\tFI-32\tLL-31\t1\n\t\t\t\t\t\t\t\t\t\t\t\n\tGood 1\tGood\tGood\tGood\t1 Good 1\t1 Good 1\t1 Good 1\t1 Good 1\t1 Good 1\tGood 1\tGood |\nTempo (hh:mmss)\tTempo (min}\tTIC-31 (\u00bbQ\tT-31 SP (T)\tT 31 MV (%}\tTIC-32 (*\u20ac}\tTY-31 (mA}\tLI-31 {%}\tFY-31 (%)\tFY-32 {%}\tFI-31 (L/h)\tFi-32 {iyr>}\tLL 31\n1508:27\t0,00\t24,04\t10,00\t0,00\t24,16\t4,00\t111,40\t0,00\t0,00\t406,67\t0,00\t405,52\n15:08:40\t0,21\t24,05\t10,00\t0,00\t24,16\t4,00\t111,44\t0,00\t0,00\t405,67\t0,00\t405,38\n1508:52\t0,41\t24,05\t60,00\t100,00\t24,15\t20,00\t111,43\t0,00\t0,00\t405,55\t0,00\t406,38\n15:09:04\t0,52\t24,05\t60,00\t100,00\t24,15\t20,00\t111,42\t0,00\t0,00\t404,45\t0,00\t404,65\n1509:17\t0,82\t24,08\t60,00\t100,00\t24,20\t20,00\t111,39\t0,00\t0,00\t408,38\t0,00\t405,14\n1509:30\t1,05\t24,82\t60,00\t100,00\t24,34\t20,00\t111,39\t0,00\t0,00\t406,40\t0,00\t405,30\n1509:42\t1,25\t25,24\t60,00\t100,00\t24,53\t20,00\t111,36\t0,00\t0,00\t404,20\t0,00\t405,71\n150955\t1,46\t25,66\t60,00\t100,00\t25,22\t20,00\t111,31\t0,00\t0,00\t402,58\t0,00\t405,09\n15:1007\t1,66\t26,06\t60,00\t100,00\t25,33\t20,00\t111,31\t0,00\t0,00\t403,33\t0,00\t403,93\n15:10:19\t1,87\t26,81\t60,00\t100,00\t25,48\t20,00\t111,27\t0,00\t0,00\t404,45\t0,00\t403,57\n15:10:32\t2,08\t27,92\t60,00\t100,00\t25,65\t20,00\t111,27\t0,00\t0,00\t404,20\t0,00\t405,04\n15:10:44\t2,28\t27,85\t60,00\t100,00\t25,89\t20,00\t111,25\t0,00\t0,00\t404,44\t0,00\t403,24\n15:1057\t2,51\t28,47\t60,00\t100,00\t26,50\t20,00\t111,22\t0,00\t0,00\t403,21\t0,00\t404,57\n15:11:10\t2,71\t28,92\t60,00\t100,00\t26,65\t20,00\t111,20\t0,00\t0,00\t404,19\t0,00\t404,69\n15:11:22\t2,92\t28,91\t60,00\t100,00\t26,78\t20,00\t111,20\t0,00\t0,00\t404,56\t0,00\t404,31\n15:11:35\t3,12\t28,87\t60,00\t100,00\t27,02\t20,00\t111,17\t0,00\t0,00\t403,57\t0,00\t403,95\n15:11:47\t3,33\t28,86\t60,00\t100,00\t27,25\t20,00\t111,16\t0,00\t0,00\t405,18\t0,00\t404,63\n15:1159\t3,53\t28,99\t60,00\t100,00\t28,00\t20,00\t111,13\t0,00\t0,00\t406,17\t0,00\t404,74\n15:12:12\t3,74\t29,36\t60,00\t100,00\t28,08\t20,00\t111,09\t0,00\t0,00\t406,42\t0,00\t404,22\n15:12:24\t3,95\t30,11\t60,00\t100,00\t28,22\t20,00\t111,09\t0,00\t0,00\t405,82\t0,00\t404,24\n15:12:37\t4,17\t29,74\t60,00\t100,00\t28,42\t20,00\t111,09\t0,00\t0,00\t404,95\t0,00\t403,64\nFigura 3.4 - Dados experimentais trabalhados pela m\u00e1scara desenvolvida para o sistema.\nAo final, foram obtidos 5.193 dados individuais para as vari\u00e1veis TIC-31, T-31 SP, T-31 MV, TY-31, LI-31 e FI-31, em fun\u00e7\u00e3o dos tempos de coleta.\nUma vez que os dados de T-30 foram medidos offline a cada 10 minutos, obteve-se 117 dados experimentais. Para obter maior quantidade de dados, foi necess\u00e1rio realizar a interpola\u00e7\u00e3o para este conjunto de dados em intervalos de 10 segundos. Assim, foram gerados 5.193, distribu\u00eddas nos mesmos intervalos de tempo das demais vari\u00e1veis empregadas para o treinamento da RNA.\n3.3\tTreinamento da RNA\nComo o objeto de estudo estava relacionado \u00e0 temperatura do Tanque-31, estudou-se, atrav\u00e9s de RNA, a correla\u00e7\u00e3o das vari\u00e1veis de entrada com a temperatura final (vari\u00e1vel de sa\u00edda). Este estudo ser\u00e1 abordado no pr\u00f3ximo cap\u00edtulo, no qual ser\u00e1 discutida tamb\u00e9m a import\u00e2ncia de cada vari\u00e1vel no modelo de rede final.\nO treinamento das redes neuronais artificiais foi efetuado no pacote STATISTICA AUTOMATED NEURAL NETWORK (SANN) do software Statistica\u00ae 12.0 da (STATSOFT, INC., 2013).\nA Figura 3.5 apresenta os dados experimentais que foram considerados, inicialmente, para o treinamento das redes neuronais artificiais.\nFigura 3.5 - Estrutura da RNA estudada.\nOs dados de entrada e de sa\u00edda foram analisados por regress\u00e3o, sendo este m\u00e9todo comumente utilizado para a previs\u00e3o de uma ou mais vari\u00e1veis cont\u00ednuas com um conjunto de entradas (STATSOFT, 2015). Foram realizados diversos treinamentos a fim de obter a melhor rede, sendo que em cada, foram treinadas 500 redes, considerando as arquiteturas dispon\u00edveis pelo programa (Perceptron de M\u00faltiplas Camadas, ou MLP e Fun\u00e7\u00e3o de Bases Radiais, ou RBF) e todas as fun\u00e7\u00f5es de ativa\u00e7\u00e3o para a camada escondida e a camada de sa\u00edda (Identidade, Log\u00edstica, Tangente Hiperb\u00f3lica, Exponencial e Seno). Destas redes treinadas foram retidas as cinco melhores para an\u00e1lise.\nEm rela\u00e7\u00e3o ao n\u00famero de neur\u00f4nios na camada escondida, utilizou-se a faixa de 3 a 25 neur\u00f4nios para a MLP (aumentando o padr\u00e3o pr\u00e9-estabelecido pelo programa) e 21 a 30 neur\u00f4nios para a RBF (valor pr\u00e9-estabelecido pelo programa). Segundo o tutorial do STATISTICA 12.0, o aumento do n\u00famero de neur\u00f4nios presentes na camada escondida aumenta o poder da modelagem da rede neuronal artificial, sendo adequado para casos onde existe grande n\u00famero de dados. Por\u00e9m, n\u00e3o se deve aumentar em demasia este n\u00famero, pois acarreta o aumento do n\u00famero de par\u00e2metros (pesos e \u201cbias\u201d), levando \u00e0 redu\u00e7\u00e3o do n\u00famero de graus de liberdade do sistema. Tal procedimento torna o treinamento mais lento, propiciando a ocorr\u00eancia do fen\u00f4meno denominado overfitting (sobretreinamento). Segundo De Souza Jr. (1993) o sobretreinamento ocorre quando a RNA perde a capacidade de generaliza\u00e7\u00e3o de novos dados, apesar de tornarem-se h\u00e1beis para representar o sistema.\nPara evitar o overfitting, o SANN (Statistica Automated Neural Networks) utiliza uma amostra de teste, que auxilia no treinamento. Desta forma, os conjuntos de dados podem ser historicamente divididos em tr\u00eas subconjuntos de dados: treinamento, teste e valida\u00e7\u00e3o; sendo a propor\u00e7\u00e3o de 14:3:3 (70%:15%:15%). Essa propor\u00e7\u00e3o para delinear os subconjuntos de dados constitui-se a condi\u00e7\u00e3o padr\u00e3o apresentada pela vers\u00e3o 12 do programa Statistica, empregada neste trabalho. De Souza Jr. (2003) e Baughman e Liu (1995), propuseram tamb\u00e9m a alternativa de divis\u00e3o dos subconjuntos de treinamento e teste na propor\u00e7\u00e3o de 3:1. Analogamente, para a sele\u00e7\u00e3o dos subconjuntos de dados de treinamento/teste/valida\u00e7\u00e3o, poder-se-ia utilizar as propor\u00e7\u00f5es 50%:25%:25% ou 2:1:1.\nInicialmente foram realizados alguns testes empregando a sele\u00e7\u00e3o dos subconjuntos de dados de treinamento/teste/valida\u00e7\u00e3o, todavia n\u00e3o foram obtidos resultados satisfat\u00f3rios. Assim, considerou-se a quantidade de dados hist\u00f3ricos dispon\u00edvel relativamente pequena para o treinamento e n\u00e3o foi selecionado o subconjunto de dados para valida\u00e7\u00e3o. A propor\u00e7\u00e3o do subconjunto de dados para treinamento/teste usada foi 4:1.\nO crit\u00e9rio de parada do treinamento est\u00e1 relacionado ao c\u00e1lculo dos erros de treinamento e de teste (vide Cap\u00edtulo 2). Estes valores determinam o desempenho da rede e s\u00e3o calculados pelo m\u00e9todo dos m\u00ednimos quadrados (vide Cap\u00edtulo 2, se\u00e7\u00e3o 2.3.3), ao final de cada itera\u00e7\u00e3o. Assim, enquanto os erros diminuem, o treinamento prossegue. N\u00e3o obstante, caso os erros n\u00e3o se alterem, diz-se que a solu\u00e7\u00e3o foi atingida, e assim o SANN finaliza o treinamento. Outro crit\u00e9rio de parada \u00e9 quando o erro de teste permanece constante, ou aumente, mesmo que o erro de treinamento diminua, pois esta condi\u00e7\u00e3o \u00e9 indicativa de sobretreinamento (overfitting). O fen\u00f4meno de overfitting torna a RNA h\u00e1bil para representar os dados de treinamento, todavia perde a capacidade de generaliza\u00e7\u00e3o para novos dados (DE SOUZA JR., 1993).\nPara avalia\u00e7\u00e3o do desempenho da RNA, o SANN cont\u00e9m em seu pacote alguns crit\u00e9rios estat\u00edsticos, dentre os quais foram empregados: valores dos pesos e \u201cbias\u201d de cada conex\u00e3o, dados estat\u00edsticos, an\u00e1lise de sensibilidade, gr\u00e1ficos dos res\u00edduos e dados preditos pela rede x dados experimentais.\n\u00c9 importante destacar tamb\u00e9m a possibilidade de avaliar a contribui\u00e7\u00e3o de cada vari\u00e1vel de entrada da rede a partir da an\u00e1lise de sensibilidade. Baughman e Liu (1995) apontam que esta an\u00e1lise classifica cada vari\u00e1vel a partir de um n\u00famero de RATIO. Quanto maior for o valor, maior a contribui\u00e7\u00e3o desta vari\u00e1vel de entrada para o treinamento da rede. Caso este valor seja menor ou igual a 1, indica a possibilidade da rede apresentar melhor performance sem a inser\u00e7\u00e3o dessa vari\u00e1vel na camada de entrada.\nO RATIO \u00e9 definido como a raz\u00e3o de sensibilidades, sendo calculado pela raz\u00e3o do erro global da rede, calculado para o valor m\u00e9dio dos dados antecessores e o erro global calculado para o valor real do dado (BOARETO MENDES, 2005).\nAssim, as redes neuronais artificiais foram treinadas inicialmente utilizando todo o conjunto de vari\u00e1veis de entrada dispon\u00edveis. Na sequ\u00eancia, procedeu-se o teste de sensibilidade (RATIO) para avaliar quais das vari\u00e1veis apresentaram baixa contribui\u00e7\u00e3o no treinamento, removendo-as uma a uma at\u00e9 convergir para a melhor condi\u00e7\u00e3o de treinamento.\nNo pr\u00f3ximo cap\u00edtulo os resultados ser\u00e3o apresentados e discutidos.\nCap\u00edtulo 4 RESULTADOS E DISCUSS\u00c3O\nNeste cap\u00edtulo s\u00e3o apresentados os resultados obtidos no emprego de metodologia destinada \u00e0 obten\u00e7\u00e3o da RNA que melhor representa o processo. De in\u00edcio apresenta-se a rede neuronal artificial treinada, considerando todas as vari\u00e1veis de entrada. Na sequ\u00eancia s\u00e3o avaliadas novas redes, cujos treinamentos foram realizados retirando-se da camada de entrada os dados com baixas contribui\u00e7\u00f5es. Ao final s\u00e3o discutidos os testes estat\u00edsticos referentes \u00e0 RNA de melhor performance, visando a avalia\u00e7\u00e3o do desempenho da mesma.\n4.1\tObten\u00e7\u00e3o dos Dados Experimentais\nConforme descrito no cap\u00edtulo anterior, foi realizado um primeiro experimento considerando o aquecimento da \u00e1gua no Tanque-31 sem recircula\u00e7\u00e3o, ou seja, sem o retorno do fluxo aquecido para o Tanque reservat\u00f3rio. N\u00e3o obstante, verificou-se n\u00e3o ser poss\u00edvel realizar este experimento, uma vez que a planta PD3 n\u00e3o teve capacidade para aquecer o fluido at\u00e9 a temperatura definida como a desejada (40\u00b0C) com alimenta\u00e7\u00e3o cont\u00ednua de \u00e1gua fria.\nA Figura 4.1 apresenta o perfil din\u00e2mico de troca t\u00e9rmica do experimento com alimenta\u00e7\u00e3o cont\u00ednua do fluido frio, sem recircula\u00e7\u00e3o.\nAssim sendo, os demais experimentos foram efetuados com recircula\u00e7\u00e3o de \u00e1gua quente na planta (sistema fechado).\nA Figura 4.2 apresenta os valores de temperatura da \u00e1gua no Tanque-31, obtidos experimentalmente, dispostos na sequ\u00eancia de dados de cada experimento.\nFigura 4.2 - Sequ\u00eancia de dados experimentais da temperatura da \u00e1gua no Tanque-31.\nOs demais valores experimentais s\u00e3o demonstrados atrav\u00e9s da sequ\u00eancia de dados nas Figuras 4.3 (T-30), 4.4 (T-31 MV e TY-31), 4.5 (FIT-31) e 4.6 (LIT-31).\nFigura 4.3 - Sequ\u00eancia de dados experimentais da temperatura da \u00e1gua no Tanque-30.\nTY-31 (mAJ\nSequ\u00eancia de Dados\n---T-31 MV(%) e TY-31 (mA)\nFigura 4.5 - Sequ\u00eancia de dados experimentais da vaz\u00e3o no Tanque-31.\nFigura 4.6 - Sequ\u00eancia de dados experimentais do n\u00edvel da \u00e1gua no Tanque-31.\nNa sequ\u00eancia estes valores foram utilizados para o treinamento das redes neuronais artificiais, conforme ser\u00e1 descrita na pr\u00f3xima se\u00e7\u00e3o.\n4.2\tTreinamento da RNA com Todas as Vari\u00e1veis de Entrada\nConforme descrito previamente, o treinamento da RNA ocorreu no programa STATISTICA (vers\u00e3o 12).\nInicialmente foi realizado o treinamento utilizando os dados experimentais de todas as vari\u00e1veis selecionadas para a malha 31.\nNa Figura 4.7 est\u00e3o esquematizadas as vari\u00e1veis de entrada e de sa\u00edda.\nFigura 4.7 - Esquema de entrada e sa\u00edda utilizado no treinamento da RNA.\nA rede estruturada apresenta 6 neur\u00f4nios na camada da entrada e 1 neur\u00f4nio na camada de sa\u00edda, correspondentes \u00e0s vari\u00e1veis do sistema. Atrav\u00e9s do treinamento foi determinado o n\u00famero de neur\u00f4nios na camada escondida e estimados os pesos e \u201cbias\u201d de cada conex\u00e3o.\nEm fun\u00e7\u00e3o da quantidade de dados dispon\u00edveis para o treinamento das redes neuronais artificiais n\u00e3o foi adequado utilizar o subconjunto de dados de valida\u00e7\u00e3o, uma vez que interferiu negativamente no treinamento da RNA (altos erros obtidos e baixas performances).\nAssim, tendo em vista a quantidade de dados experimentais e a falta de dados extras para a execu\u00e7\u00e3o da RNA, foram realizados diversos treinamentos sem utilizar a amostra de valida\u00e7\u00e3o. Nas pr\u00f3ximas se\u00e7\u00f5es ser\u00e3o apresentadas as redes e ser\u00e3o utilizadas t\u00e9cnicas estat\u00edsticas no sentido de confirmar a capacidade preditiva da rede neuronal artificial que constitui o sistema.\n4.2.1\tAn\u00e1lises de Desempenho\nAo final do treinamento foram retidas as cinco melhores redes, apresentadas na Tabela\n4.1.\nTabela 4.1 - Cinco melhores redes treinadas com seis vari\u00e1veis de entrada e uma vari\u00e1vel de sa\u00edda.\nN\u00b0\tRNA\tPerformance\t\tErro\t\tFun\u00e7\u00e3o de Ativa\u00e7\u00e3o: Camada Escondida/ Camada de Sa\u00edda\n\t\tTreinamento\tTeste\tTreinamento\tTeste\t\n1\tMLP 6-21-1\t0,999186\t0,999129\t0,068867\t0,077443\tLog\u00edstica/ Tangente Hiperb\u00f3lica\n2\tMLP 6-24-1\t0,999209\t0,999214\t0,066907\t0,069952\tLog\u00edstica/ Tangente Hiperb\u00f3lica\n3\tMLP 6-23-1\t0,999233\t0,999259\t0,064914\t0,065847\tExponencial/ Log\u00edstica\n4\tMLP 6-21-1\t0,999223\t0,999247\t0,065703\t0,067009\tTangente Hiperb\u00f3lica/ Identidade\n5\tMLP 6-23-1\t0,999194\t0,999152\t0,068192\t0,075398\tLog\u00edstica/ Exponencial\nUm ponto de destaque \u00e9 que das 500 redes treinadas, apenas as arquiteturas MLP se destacaram entre as melhores selecionadas, demonstrando que esta arquitetura descreve melhor o sistema. Haykin (2001) comprova este ponto ao citar que a MLP \u00e9 comumente utilizada para problemas de regress\u00e3o, enquanto que a RBF \u00e9 utilizada para problemas de classifica\u00e7\u00e3o de padr\u00f5es.\nNo treinamento descrito acima verificou-se tamb\u00e9m que a terceira rede (MLP 6-23-1) apresentou melhor resultado que as demais, uma vez que esta possui o menor erro de teste. Este fator \u00e9 utilizado para identificar o melhor desempenho, pois \u00e9 obtido a partir da avalia\u00e7\u00e3o dos dados n\u00e3o utilizados para o treinamento das redes, ou seja, n\u00e3o est\u00e3o envolvidos no ajuste dos pesos e \u201c\u00bfzas\u201d.\nOutro fator que deve ser considerado na escolha da melhor rede s\u00e3o as performances de treinamento e de teste. O tutorial do STATISTICA 12.0 descreve a performance como sendo o coeficiente de correla\u00e7\u00e3o entre os valores preditos pela rede e os valores observados (reais). Estes coeficientes apresentam valores entre -1 e +1, sendo que, normalmente, os valores pr\u00f3ximos a +1 indicam o melhor ajuste. Por\u00e9m, uma vez que os dados iniciais apresentam, no geral, uma quantidade de ru\u00eddos, os coeficientes de performance de treinamento podem estar elevados, mas apresentando baixas performances nas amostras de teste. Sendo assim, para\nrealizar a escolha da melhor rede deve-se avaliar tanto as performances de treinamento e de teste, quanto os erros de teste.\nPara este caso, verificou-se que a rede selecionada apresentou os melhores valores em rela\u00e7\u00e3o a estes crit\u00e9rios estat\u00edsticos discutidos.\nNesta rede MLP 6-23-1, foi utilizada a arquitetura Perceptron de M\u00faltiplas Camadas (MLP), sendo constitu\u00edda por 6 neur\u00f4nios na camada de entrada, 23 neur\u00f4nios na camada escondida e 1 neur\u00f4nio na camada de sa\u00edda.\nVerifica-se tamb\u00e9m que a fun\u00e7\u00e3o de ativa\u00e7\u00e3o utilizada na camada escondida foi a exponencial, enquanto que a fun\u00e7\u00e3o na camada de sa\u00edda foi a log\u00edstica.\nSendo assim, como a RNA MLP 6-23-1 apresentou o melhor desempenho dentre as demais, ser\u00e3o realizadas an\u00e1lises complementares para validar a sua adequa\u00e7\u00e3o na representa\u00e7\u00e3o do sistema em estudo.\n4.2.2\tDados Preditos pela RNA versus Dados Observados\nInicialmente avaliou-se a distribui\u00e7\u00e3o dos res\u00edduos de rede, ou seja, a diferen\u00e7a entre os valores preditos versus os valores observados. Na Figura 4.8 verificou-se que a distribui\u00e7\u00e3o dos res\u00edduos se aproximam de uma distribui\u00e7\u00e3o normal, o que significa que a rede representou adequa\u00e7\u00e3o estat\u00edstica ao ru\u00eddo.\nFigura 4.8 - Histograma de distribui\u00e7\u00e3o dos res\u00edduos.\nMontgomery e Runger (2013) complementam que a distribui\u00e7\u00e3o normal constitui em um modelo razo\u00e1vel de medidas da resist\u00eancia \u00e0 compress\u00e3o, apresentando discernimento acerca da popula\u00e7\u00e3o.\nNa sequ\u00eancia avaliou-se a dispers\u00e3o dos valores preditos pela RNA em rela\u00e7\u00e3o aos valores observados (reais). A Figura 4.9 apresenta o gr\u00e1fico gerado para esta avalia\u00e7\u00e3o.\nFigura 4.9 - Dados preditos pela RNA vs. dados observados.\nUma vez que os pontos est\u00e3o distribu\u00eddos pr\u00f3ximos da linha de ajuste, observou-se que os dados experimentais apresentaram alta correla\u00e7\u00e3o com os dados preditos (MONTGOMERY e RUNGER, 2013). Sendo assim, p\u00f4de-se afirmar que a rede neuronal artificial representou com signific\u00e2ncia estat\u00edstica os dados experimentais.\n4.2.3\tCompara\u00e7\u00e3o entre os Dados Experimentais e os Dados Preditos\nA Figura 4.10 apresenta o gr\u00e1fico da compara\u00e7\u00e3o dos dados preditos pela rede com os dados observados, durante a etapa de treinamento.\n65\n60\nO\nTIT-31 Observado (\u00b0C)\nTIT-31 Predito pela Rede (\u00b0C)\n55\n50\n45\n40\n,<B\n35\n30\n25\n20\nSequ\u00eancia de Dados\n1\t339\t670 1015 1359 1710 2055 2384 2735 3097 3443 3817 4158 4502 4866\nFigura 4.10 - Temperatura do Tanque-31 versus sequ\u00eancia de dados: compara\u00e7\u00e3o dos dados preditos pela RNA com os dados experimentais.\nConforme discutido na an\u00e1lise anterior, a rede selecionada apresentou alta capacidade de representa\u00e7\u00e3o do sistema. Tal constata\u00e7\u00e3o tamb\u00e9m foi demonstrada pela Figura 4.14, onde os dados preditos pela rede apresentaram valores bem pr\u00f3ximos aos valores observados, com pequenos desvios.\n4.2.4\tAn\u00e1lise dos Dados Estat\u00edsticos\nA estat\u00edstica da regress\u00e3o do treinamento da rede MLP 6-23-1 \u00e9 apresentada na Tabela\n2.\nTabela 4.2 - Estat\u00edstica da regress\u00e3o para a rede neuronal artificial para a vari\u00e1vel de sa\u00edda\n(MLP 6-23-1).\t\n\tTIC-31 (\u00b0C)\nM\u00e9dia dos dados (p)\t46,2913\nDesvio padr\u00e3o dos dados (o)\t9,24774\nSegundo Montgomery e Runger (2013), o desvio padr\u00e3o dos dados deve ser pelo menos uma ordem de grandeza menor que a sua m\u00e9dia. Adotando esta afirmativa e analisando a tabela anterior, verifica-se que os dados utilizados no treinamento da rede MLP 6-23-1 apresentam desvios um pouco acima do proposto. Entretanto, constatou-se, atrav\u00e9s das outras an\u00e1lises estat\u00edsticas, que a rede neuronal artificial atende \u00e0s caracter\u00edsticas do processo.\n4.2.5\tAn\u00e1lise de Sensibilidade\nConforme descrito previamente \u00e9 poss\u00edvel identificar a import\u00e2ncia relativa das vari\u00e1veis utilizadas na camada de entrada da RNA, atrav\u00e9s da an\u00e1lise de sensibilidade (BAUGHMAN e LIU, 1995).\nO SANN realiza a an\u00e1lise testando como as taxas de erro se comportam quando as vari\u00e1veis de entrada s\u00e3o submetidas a altera\u00e7\u00f5es. Ao final cada vari\u00e1vel \u00e9 classificada com um valor de RATIO. O valor de RATIO igual ou menor que 1, indica que a vari\u00e1vel n\u00e3o contribuiu significativamente para o treinamento da rede. Em contraste, quanto maior for o valor do RATIO, maior ser\u00e1 a contribui\u00e7\u00e3o desta vari\u00e1vel (BAUGHMAN e LIU, 1995).\nSendo assim, a Tabela 4.3 apresenta os valores obtidos para a an\u00e1lise de sensibilidade das cinco melhores redes retidas.\nTabela 4.3 - An\u00e1lise de sensibilidade do treinamento realizado com seis vari\u00e1veis de entrada.\nN\u00b0\tRNA\tT-30 (\u00b0C)\tLIT-31 (%)\tFIT-31 (L/h)\tT-31 MV (%)\tT-31 D (\u00b0C)\tTY-31 (mA)\n1\tMLP 6-21-1\t404,337\t111,7951\t131,4336\t91,5114\t22,958\t50,897\n2\tMLP 6-24-1\t658,163\t123,8733\t99,8096\t77,7228\t69,7755\t75,6335\n3\tMLP 6-23-1\t225,007\t457,3643\t171,5892\t29,8795\t78,5247\t32,556\n4\tMLP 6-21-1\t270,339\t265,7626\t163,2288\t246,166\t81,9651\t98,1524\n5\tMLP 6-23-1\t6560,092\t165,7333\t102,8749\t36,2281\t47,9758\t40,3463\n-\tM\u00e9dia\t1623,588\t224,9057\t133,7872\t96,3016\t60,2398\t59,517\nVerificou-se que apesar dos dados apresentaram RATIO acima de 1, algumas vari\u00e1veis apresentaram valores bem menores em rela\u00e7\u00e3o a outras.\nAo se analisar a m\u00e9dia, percebeu-se que a corrente para modular a pot\u00eancia de sa\u00edda do conversor est\u00e1tico (TY-31) apresentou menor influ\u00eancia dentre as demais vari\u00e1veis, enquanto\nque ao se analisar a melhor rede (terceira), verificou-se que a vari\u00e1vel manipulada (T-31 MV) obteve menor resultado.\nLogo, foram realizados novos treinamentos, retirando os dados com menores RATIO (TY-31 e T-31 MV) a fim de verificar se as novas redes apresentariam menores erros de teste, isto \u00e9, apresentam melhor modelagem em rela\u00e7\u00e3o ao sistema.\nEm cada treinamento foram adotados ajustes mais espec\u00edficos, para que n\u00e3o fossem gastos tempos com treinamentos de redes de baixas performances. Logo, foram treinadas 200 redes, considerando apenas as arquiteturas MLP, com 11 a 25 neur\u00f4nios na camada escondida, com fun\u00e7\u00e3o de ativa\u00e7\u00e3o exponencial para a camada escondida e fun\u00e7\u00e3o de ativa\u00e7\u00e3o log\u00edstica para a camada sa\u00edda.\nNa pr\u00f3xima ser\u00e3o discutidos os resultados dos novos treinamentos, atrav\u00e9s da compara\u00e7\u00e3o dos modelos finais.\n4.3\tCompara\u00e7\u00e3o de desempenho das melhores RNA\u2019s\nNesta etapa foram realizados dois novos treinamentos a fim de comparar o desempenho das melhores redes de cada treinamento.\nSendo assim, os treinamentos foram classificados conforme abaixo:\n\u2022\tTreinamento 1: treinamento inicial, incluindo todos os dados experimentais das 6 vari\u00e1veis de entrada definidas para o processo em estudo. Este modelo foi discutido na Se\u00e7\u00e3o 4.2.\n\u2022\tTreinamento 2: treinamento realizado sem considerar a vari\u00e1vel manipulada (T-31 MV) na camada de entrada (vide Figura 4.11).\nFigura 4.11 - Estrutura utilizada no 2\u00b0 Treinamento da RNA.\n\u2022 Treinamento 3: treinamento realizado sem considerar a corrente para modular a pot\u00eancia de sa\u00edda do conversor est\u00e1tico (TY-31) na camada de entrada (vide Figura 4.12).\nFigura 4.12- Estrutura utilizada no 3\u00b0 Treinamento da RNA.\nA fim de facilitar o entendimento, estas nomenclaturas foram adotadas nas an\u00e1lises seguintes.\n4.3.1\tAn\u00e1lises de Desempenho\nAs cinco melhores redes retidas nos treinamentos 2 e 3 s\u00e3o apresentadas na Tabela 4.4 e na Tabela 4.5, respectivamente.\nTabela 4.4 - Cinco melhores redes obtidas no treinamento 2, com cinco vari\u00e1veis na camada de entrada.\nN\u00b0\tRNA (Treinamento 2)\tPerformance\t\tErro\t\n\t\tTreinamento\tTeste\tTreinamento\tTeste\n1\tMLP 5-23-1\t0,999273\t0,999244\t0,061542\t0,067186\n2\tMLP 5-23-1\t0,999205\t0,999222\t0,067256\t0,069174\n3\tMLP 5-17-1\t0,99926\t0,99923\t0,06262\t0,068425\n4\tMLP 5-23-1\t0,999195\t0,999224\t0,068104\t0,06899\n5\tMLP 5-25-1\t0,999236\t0,999255\t0,064649\t0,066232\nTabela 4.5 - Cinco melhores redes obtidas no treinamento 3, com cinco vari\u00e1veis na camada de entrada.\nN\u00b0\tRNA (Treinamento 3)\tPerformance\t\tErro\t\n\t\tTreinamento\tTeste\tTreinamento\tTeste\n1\tMLP 5-25-1\t0,999312\t0,999273\t0,058293\t0,064551\n2\tMLP 5-23-1\t0,999283\t0,999302\t0,060699\t0,06211\n3\tMLP 5-25-1\t0,999313\t0,999319\t0,058125\t0,060593\n4\tMLP 5-24-1\t0,999303\t0,999308\t0,058961\t0,06153\n5\tMLP 5-23-1\t0,999345\t0,999347\t0,055409\t0,058086\nAssim, as melhores redes obtidas em cada treinamento foram avaliadas segundo o m\u00e9todo de sele\u00e7\u00e3o definido e utilizado anteriormente (redes que possuem os maiores valores de performance de treinamento e de teste e o menor valor de erro de teste). Logo, a Tabela 4.6 compara as melhores redes obtidas em cada treinamento, as quais s\u00e3o provenientes das Tabelas\n4.4\te 4.5.\nRessalta-se que as fun\u00e7\u00f5es de ativa\u00e7\u00e3o do treinamento 2 e 3 s\u00e3o as mesmas da rede MLP 6-23-1, selecionada no treinamento 1 (exponencial para a camada escondida e log\u00edstica para a camada de sa\u00edda).\nTabela 4.6 - Compara\u00e7\u00e3o dos desempenhos das RNA selecionadas em cada treinamento.\nTreinamento\tRNA\tPerformance\t\tErro\t\n\t\tTreinamento\tTeste\tTreinamento\tTeste\n1\tMLP 6-23-1\t0,999233\t0,999259\t0,064914\t0,06584700\n2\tMLP 5-25-1\t0,999236\t0,999255\t0,064649\t0,06623200\n3\tMLP 5-23-1\t0,999345\t0,999347\t0,055409\t0,05808600\nComparando as melhores redes neuronais artificiais obtidas em cada treinamento (treinamentos 1, 2 e 3), verificou-se que a RNA obtida no treinamento 3 (MLP 5-23-1) apresentou melhor desempenho em rela\u00e7\u00e3o ao apresentado pelas demais.\nEsta an\u00e1lise comprovou que ao utilizar a estrutura da rede sem a vari\u00e1vel TY-31 na camada de entrada, obteve-se rede com melhor capacidade preditiva, como pode ser visualizado comparando as Tabelas 4.1, 4.4 e 4.5.\n4.3.2\tDados Preditos versus Dados Observado\nA Figura 4.13 apresenta os valores preditos em cada treinamento versus os valores observados (reais).\nFigura 4.13 - Gr\u00e1fico de probabilidade para compara\u00e7\u00e3o dos dados preditos em cada treinamento versus dados observados.\n4.3.3\tCompara\u00e7\u00e3o entre os Dados Experimentais e os Dados Preditos\nA Figura 4.14 apresenta a compara\u00e7\u00e3o entre os valores preditos em cada rede com os valores observados, em cada sequ\u00eancia de dados.\nFigura 4.14 - Temperatura do Tanque-31 versus sequ\u00eancia de dados. Compara\u00e7\u00e3o dos dados preditos em cada treinamento com os dados experimentais.\nNota-se que o desempenho das redes foi similar, n\u00e3o sendo notada a diferen\u00e7a graficamente. Neste caso, as tr\u00eas redes neuronais artificiais apresentaram alta capacidade de representa\u00e7\u00e3o do sistema.\n4.3.4\tAn\u00e1lise dos Dados Estat\u00edsticos\nA Tabela 4.7 apresenta os dados estat\u00edsticos de cada rede treinada. Percebeu-se que os valores de m\u00e9dia dos dados e desvio padr\u00e3o dos dados s\u00e3o iguais, at\u00e9 a casa decimal fornecida pelo programa.\nTabela 4.7 - Dados estat\u00edsticos das redes treinadas.\nTreinamento\tRNA\tM\u00e9dia dos Dados\tDesvio Padr\u00e3o dos Dados\n1\tMLP 6-23-1\t46,29127479\t9,24774329\n2\tMLP 5-25-1\t46,29127479\t9,24774329\n3\tMLP 5-23-1\t46,29127479\t9,24774329\n4.3.5\tAn\u00e1lise de Sensibilidade\nA an\u00e1lise de sensibilidade obtida para as tr\u00eas redes est\u00e1 representada na Tabela 4.8.\nTabela 4.8 - Compara\u00e7\u00e3o entre as an\u00e1lises de sensibilidade para as tr\u00eas diferentes estruturas de RNA treinadas.\nTreinamento\tRNA\tT-30 (\u00b0C)\tLIT-31 (%)\tFIT-31 (L/h)\tT-31 MV (%)\tT-31 D (\u00b0C)\tTY-31 (mA)\n1\tMLP 6-23-1\t225,01\t457,36\t171,59\t29,88\t78,525\t32,556\n2\tMLP 5-25-1\t279,14\t150,89\t137,34\t-\t219,07\t174,472\n3\tMLP 5-23-1\t469,37\t222,62\t152,25\t232,5\t89,805\t-\nEm rela\u00e7\u00e3o \u00e0 tabela acima verificou-se que ap\u00f3s a realiza\u00e7\u00e3o dos novos treinamentos, os valores calculados de RATIO para cada vari\u00e1vel foram diferentes do primeiro treinamento. Ao analisar os treinamentos 2 e 3 verificou-se que todos os valores de RATIO s\u00e3o altos, sendo assim, n\u00e3o existe a necessidade de realiza\u00e7\u00e3o de um novo treinamento, pois todas as vari\u00e1veis apresentaram grande import\u00e2ncia na rede final.\n4.3.6\tAn\u00e1lise Final\nA RNA que melhor representou o processo de estudo apresentou 5 neur\u00f4nios na camada de entrada (T-31 D, T-31 MV, T-30, LIT-31 e FIT-31), 23 neur\u00f4nios na camada escondida e 1 neur\u00f4nio na camada de sa\u00edda (TIT-31).\nA rede apresenta arquitetura de Perceptron de M\u00faltiplas Camadas (MLP), com performance de treinamento igual a 0,999345 e erro de teste igual a 0,058086. Ressalta-se que a fun\u00e7\u00e3o de ativa\u00e7\u00e3o da camada escondida constituiu da exponencial, enquanto a fun\u00e7\u00e3o log\u00edstica referiu-se a camada de sa\u00edda.\nDado ao grande n\u00famero de conex\u00f5es, os pesos e \u201cbias\u2019\u201d de cada s\u00e3o demonstrados na Tabela A.1, do Ap\u00eandice A.\nCap\u00edtulo 5 CONCLUS\u00d5ES\nAs caracter\u00edsticas n\u00e3o lineares, presentes em diversos processos industriais, acarretam a necessidade de implementa\u00e7\u00e3o de estruturas de controle de processos cada vez mais sofisticadas. Uma variedade de m\u00e9todos cl\u00e1ssicos para an\u00e1lise e s\u00edntese de controladores n\u00e3o lineares existem para uma classe espec\u00edfica de sistemas, como exemplo as t\u00e9cnicas de lineariza\u00e7\u00e3o e fun\u00e7\u00f5es descritivas. Entretanto, devido \u00e0 vasta diversidade de sistemas n\u00e3o lineares torna-se fundamental a ado\u00e7\u00e3o de sistemas computacionais para a realiza\u00e7\u00e3o da modelagem dos processos.\nNesta linha de abordagem, v\u00e1rias pesquisas na literatura estudam a aplica\u00e7\u00e3o de redes neuronais artificiais para a modelagem de sistemas complexos. Do ponto de vista da teoria de modelagem e controle de processos, a habilidade das redes neuronais artificiais em lidar com sistemas n\u00e3o lineares \u00e9, talvez, a mais significativa.\nNeste trabalho, avaliou-se a implementa\u00e7\u00e3o de redes neuronais artificiais na representa\u00e7\u00e3o do sistema de controle autom\u00e1tico de temperatura de um tanque, localizado na planta did\u00e1tica PD3 da SMAR.\nEstudou-se a din\u00e2mica do processo, atrav\u00e9s da obten\u00e7\u00e3o de todos os dados experimentais medidos na planta, em diferentes cen\u00e1rios. Posteriormente foram realizados os treinamentos das redes neuronais artificiais. Com base nos par\u00e2metros e dados estat\u00edsticos de cada rede treinada, verificou-se que a RNA com melhor desempenho apresentou alta capacidade para representar o processo em estudo.\nSendo assim, constatou-se a adequa\u00e7\u00e3o da proposi\u00e7\u00e3o de metodologia de intelig\u00eancia artificial baseada em sistemas subsimb\u00f3licos para estrutura\u00e7\u00e3o do modelo destinado \u00e0 representa\u00e7\u00e3o do comportamento din\u00e2mico da planta did\u00e1tica PD3. Mesmo necessitando de utiliza\u00e7\u00e3o de grande quantidade de dados experimentais, a RNA selecionada apresenta confian\u00e7a estat\u00edstica adequada para ser aplicada em malha de controle a ser implementada no processo.\n5.1\tPerspectivas e Sugest\u00f5es para Trabalhos Futuros\nInicialmente sugere-se obter novos conjuntos de dados experimentais para validar a rede neuronal artificial treinada e realizar novos treinamentos, considerando outras condi\u00e7\u00f5es operacionais da planta did\u00e1tica PD3.\nEm concord\u00e2ncia, partindo dos resultados obtidos no presente trabalho e tendo em vista que a rede neuronal artificial obtida gera uma equa\u00e7\u00e3o caracter\u00edstica do sistema, prop\u00f5e-se sequenciar este estudo a partir da aplica\u00e7\u00e3o de m\u00e9todos matem\u00e1ticos para obten\u00e7\u00e3o de par\u00e2metros de sintonia do controlador, que dever\u00e3o ser adotados no sistema de controle de temperatura do Tanque-31. Assim, ser\u00e1 poss\u00edvel avaliar o desempenho de uma estrat\u00e9gia de controle baseada na modelagem neuronal e ponderar a prefer\u00eancia do m\u00e9todo de sintonia, a partir da compara\u00e7\u00e3o com os m\u00e9todos cl\u00e1ssicos.\nSugere-se tamb\u00e9m a realiza\u00e7\u00e3o do treinamento de novas redes neuronais artificiais empregando outros programas, para compara\u00e7\u00e3o. O MATLAB e o SCILAB, por exemplo, fornecem fun\u00e7\u00f5es e aplicativos para a modelagem de sistemas n\u00e3o lineares complexos.\nREFER\u00caNCIAS BIBLIOGR\u00c1FICAS\nAHMED, D. F. Artificial Neural Network Control of Chemical Processes. Eng. &amp; Tech. Journal, v. 32, 2014.\nANDRADE, F. D. et al. Redes Neurais Artificiais Aplicadas para o Estudo da Produ\u00e7\u00e3o de \u00c1cido Succ\u00ednico via Processo Fermentativo. Joa\u00e7aba, 10, jan./ dez. 2010. 27-42.\nBARR, A.; FEIGENBAUM, E. A. The Handbook of Artificial Intelligence. Los Altos: William Kaufmann, INC, 1981. Disponivel em:&lt;https://archive.org/stream/handbookofartific 01barr#page/6/mode/2up>. Acesso em: 18 abr. 2015.\nBAUGHMAN, D. R.; LIU, Y. A. Neural Networks in Bioprocessing and Chemical Engineering. San Diego: Academic Press, INC, 1995.\nBOTTO, L.; CASSIOLATO, C. Quebrando o muro que separa a empresa da escola. SMAR Did\u00e1tica, 2012. Disponivel em:&lt;http://www.smar.com/brasil/artigo-tecnico/smar-didatica>. Acesso em: 04 abr. 2015.\nBRAGA, A. D. P.; CARVALHO, A. P. D. L. F. D.; LUDERMIR, T. B. Redes Neurais Artificiais: Teoria e Aplica\u00e7\u00f5es. 2a. ed. Rio de Janeiro: LTC, 2011.\nCANEPPELE, F. L.; SERAPHIM, O. J. Aplica\u00e7\u00e3o da Teoria Fuzzy no Controle de Sistemas de Gera\u00e7\u00e3o de Energias Alternativas. Energia na Agricultura, Botucatu, v. 25, p. 24-41, 2010. Disponivel em:&lt;http://revistas.fca.unesp.br/index.php/energia/article/view/64/45>. Acesso em: 20 jun. 2015.\nCPDEE. Evolu\u00e7\u00e3o dos Sistemas de Controle, 2002. Disponivel em:&lt;http://www.cpdee.ufmg.br/~seixas/PaginaII/Download/DownloadFiles/HistoriaControlador es.PDF>. Acesso em: 21 abr. 2015.\nDE ARA\u00daJO, F. M. U. Controle Inteligente. Universidade Federal do Rio Grande do Norte. Natal. 2004.\nDE SOUZA JR., M. B. Redes Neuronais Multicamadas Aplicadas a Modelagem e Controle de Processos Qu\u00edmicos. Universidade Federal do Rio de Janeiro. Rio de Janeiro. 1993.\nFERRARI, A. C. K. Controlador PID Sintonizado por Redes Neurais Artificiais. Universidade Federal do Paran\u00e1. Curitiba, p. 63. 2010.\nFONSECA, E. F. Controle preditivo baseado em redes neurais de fermenta\u00e7\u00e3o alco\u00f3lica cont\u00ednua. Universidade Federal de Pernambuco. Recife. 1998.\nGAUSHELL, D. J. Supervisory Control and Data Aquisition. [S.l.]: Proceedings of the IEEE, v. 75, 1987.\nHAYKIN, S. Redes Neurais - Princ\u00edpios e Pr\u00e1ticas. 2a. ed. Porto Alegre: Bookman, 2001. LAGES, W. F. Controle Adaptativo de Sistemas Estoc\u00e1sticos. Universidade Federal do Rio Grande do Sul. Rio Grande do Sul. 2007.\nLINHARES, L. L. S.; J\u00daNIOR, J. M. A.; ARA\u00daJO, F. M. U. Redes Neurais Artificiais para Identifica\u00e7\u00e3o da Fra\u00e7\u00e3o Molar de Pentano na Composi\u00e7\u00e3o do GLP, Natal, 2007.\nLUQUE, J. C. C. Controle Robusto Multivari\u00e1vel para um Ve\u00edculo Submers\u00edvel Aut\u00f4nomo. Universidade de S\u00e3o Paulo. S\u00e3o Paulo. 2007.\nLUYBEN, W. L. Simple method for tuning SISO controllers in multivariable systems. Industrial &amp; Engineering Chemistry Process Design and Development, 25, n. 3, 1986. 654660.\nMELAZZI, F. A.; SILVA, A. R.; RAMIREZ, N. I. B. Sistema de Migra\u00e7\u00e3o de Dados para o Controle de Processos. Universidade Federal Fluminense. Niter\u00f3i. 2015.\nMENDES, A. J. B. Modelagem h\u00edbrido-neuronal da produ\u00e7\u00e3o de lipase por Candida rugosa. Universidade Federal do Rio de Janeiro. Rio de Janeiro. 2005.\nMONTGOMERY, D. C.; RUNGER, G. C. Estat\u00edstica Aplicada e Probabilidade para Engenheiros. 5a. ed. Rio de Janeiro: LTC - Livros T\u00e9cnicos e Cient\u00edficos Editora Ltda, 2013.\nRAMIREZ, N. I. B. Professores UFF. Controle de Processos - EQ, 2012. Disponivel em:&lt;http://www.professores.uff.br/controledeprocessos-eq/>. Acesso em: 11 Abr. 2015.\nRIBEIRO, S. R. A. Compara\u00e7\u00e3o entre Classifica\u00e7\u00f5es com Rede Neural Artificial em Diferentes \u00c1reas de Estudo. Mercator : Revista de Geografia da UFC, Fortaleza, 12, jan./ abr. 2013. 159-168. Disponivel em:&lt;http://www.mercator.ufc.br/index.php/mercator/article/viewFile/64 3/461>. Acesso em: 25 abr. 2015.\nROSA, G. M.; LUZ, J. A. M. D. Simula\u00e7\u00e3o de Moagem Mista por Rede Neural Artificial. Rem: Revista Escola de Minas, Ouro Preto, 65, abr./ jun. 2012. 247-256. Disponivel em:&lt;http: //www.scielo.br /scielo.php?pid=S0370-44672012000200014 &amp;script= sci_arttext>. Acesso em: 25 abr. 2015.\nSEBORG, D. E. et al. Process Dynamics and Control. 3a. ed. [S.l.]: Wiley, 2010.\nSMAR. Manual da Planta Did\u00e1tica - PD3. [S.l.].\nSMITH, C. A.; CORRIPIO, A. B. Princ\u00edpios e Pr\u00e1tica do Controle Autom\u00e1tico de Processo. 3a. ed. [S.l.]: LTC, 2008.\nSTATSOFT. Redes Neurais. [S.l.]. 2015. Curso de Redes Neurais Artificiais.\nSTATSOFT, INC. STATISTICA V. 12. [S.l.]: [s.n.], 2013.\nTROFINO, A. Controle Robusto. Universidade Federal de Santa Catarina. Florian\u00f3polis. 2000.\nVIEIRA, R. C.; ROISENBERG, M. Redes Neurais Artificiais: Um Breve Tutorial, Florian\u00f3polis.\nAP\u00caNDICE A - PAR\u00c2METROS DA RNA FINAL\nA Tabela A.1 apresenta os par\u00e2metros (pesos e \u201cbias\u201d) de cada conex\u00e3o da rede MLP 5-23-1. Onde \u201chidden neuron\u201d constitui o neur\u00f4nio na camada escondida e \u201cinput bias\u201d o \u201cbias\u201d aplicado em cada neur\u00f4nios.\nTabela A.1 - Pesos e \"bias\" de cada conex\u00e3o da rede MLP 6-23-1.\nConex\u00f5es da MPL 5-23-1\tPesos\tConex\u00f5es da MPL 5-23-1\tPesos\nT-31 SP (\u00b0C) - hidden neuron 1\t9,14\tT-31 MV (%) - hidden neuron 17\t1,23\nT-31 MV (%) - hidden neuron 1\t-10,46\tLI-31 (%) - hidden neuron 17\t-18,26\nLI-31 (%) - hidden neuron 1\t-12,35\tFI-31 (L/h) - hidden neuron 17\t3,80\nFI-31 (L/h) - hidden neuron 1\t-4,37\tT-30 (\u00b0C) - hidden neuron 17\t9,59\nT-30 (\u00b0C) - hidden neuron 1\t-8,00\tT-31 SP (\u00b0C) - hidden neuron 18\t-0,35\nT-31 SP (\u00b0C) - hidden neuron 2\t-6,59\tT-31 MV (%) - hidden neuron 18\t0,22\nT-31 MV (%) - hidden neuron 2\t-1,19\tLI-31 (%) - hidden neuron 18\t-0,61\nLI-31 (%) - hidden neuron 2\t-0,09\tFI-31 (L/h) - hidden neuron 18\t0,51\nFI-31 (L/h) - hidden neuron 2\t-5,09\tT-30 (\u00b0C) - hidden neuron 18\t-2,00\nT-30 (\u00b0C) - hidden neuron 2\t-1,03\tT-31 SP (\u00b0C) - hidden neuron 19\t-15,36\nT-31 SP (\u00b0C) - hidden neuron 3\t-7,46\tT-31 MV (%) - hidden neuron 19\t1,00\nT-31 MV (%) - hidden neuron 3\t-5,20\tLI-31 (%) - hidden neuron 19\t-8,56\nLI-31 (%) - hidden neuron 3\t1,08\tFI-31 (L/h) - hidden neuron 19\t-3,91\nFI-31 (L/h) - hidden neuron 3\t-10,83\tT-30 (\u00b0C) - hidden neuron 19\t-9,59\nT-30 (\u00b0C) - hidden neuron 3\t3,69\tT-31 SP (\u00b0C) - hidden neuron 20\t4,26\nT-31 SP (\u00b0C) - hidden neuron 4\t7,40\tT-31 MV (%) - hidden neuron 20\t1,74\nT-31 MV (%) - hidden neuron 4\t6,58\tLI-31 (%) - hidden neuron 20\t0,95\nLI-31 (%) - hidden neuron 4\t1,12\tFI-31 (L/h) - hidden neuron 20\t-6,09\nFI-31 (L/h) - hidden neuron 4\t-5,19\tT-30 (\u00b0C) - hidden neuron 20\t1,74\nT-30 (\u00b0C) - hidden neuron 4\t2,28\tT-31 SP (\u00b0C) - hidden neuron 21\t1,00\nT-31 SP (\u00b0C) - hidden neuron 5\t7,59\tT-31 MV (%) - hidden neuron 21\t-4,73\nT-31 MV (%) - hidden neuron 5\t-9,82\tLI-31 (%) - hidden neuron 21\t-13,21\nLI-31 (%) - hidden neuron 5\t-30,71\tFI-31 (L/h) - hidden neuron 21\t-6,94\nFI-31 (L/h) - hidden neuron 5\t7,93\tT-30 (\u00b0C) - hidden neuron 21\t1,38\nConex\u00f5es da MPL 5-23-1\tPesos\tConex\u00f5es da MPL 5-23-1\tPesos\nT-30 (\u00b0C) - hidden neuron 5\t-15,39\tT-31 SP (\u00b0C) - hidden neuron 22\t-16,42\nT-31 SP (\u00b0C) - hidden neuron 6\t-4,61\tT-31 MV (%) - hidden neuron 22\t1,05\nT-31 MV (%) - hidden neuron 6\t0,75\tLI-31 (%) - hidden neuron 22\t-6,92\nLI-31 (%) - hidden neuron 6\t-2,32\tFI-31 (L/h) - hidden neuron 22\t-1,98\nFI-31 (L/h) - hidden neuron 6\t-0,03\tT-30 (\u00b0C) - hidden neuron 22\t2,02\nT-30 (\u00b0C) - hidden neuron 6\t9,38\tT-31 SP (\u00b0C) - hidden neuron 23\t0,47\nT-31 SP (\u00b0C) - hidden neuron 7\t-13,41\tT-31 MV (%) - hidden neuron 23\t0,13\nT-31 MV (%) - hidden neuron 7\t1,12\tLI-31 (%) - hidden neuron 23\t4,15\nLI-31 (%) - hidden neuron 7\t-3,89\tFI-31 (L/h) - hidden neuron 23\t-15,92\nFI-31 (L/h) - hidden neuron 7\t0,21\tT-30 (\u00b0C) - hidden neuron 23\t4,32\nT-30 (\u00b0C) - hidden neuron 7\t12,88\tinput bias - hidden neuron 1\t1,28\nT-31 SP (\u00b0C) - hidden neuron 8\t-11,34\tinput bias - hidden neuron 2\t3,69\nT-31 MV (%) - hidden neuron 8\t0,46\tinput bias - hidden neuron 3\t3,86\nLI-31 (%) - hidden neuron 8\t-2,60\tinput bias - hidden neuron 4\t-15,89\nFI-31 (L/h) - hidden neuron 8\t-5,74\tinput bias - hidden neuron 5\t10,06\nT-30 (\u00b0C) - hidden neuron 8\t-4,26\tinput bias - hidden neuron 6\t-4,64\nT-31 SP (\u00b0C) - hidden neuron 9\t-4,31\tinput bias - hidden neuron 7\t6,55\nT-31 MV (%) - hidden neuron 9\t1,33\tinput bias - hidden neuron 8\t10,91\nLI-31 (%) - hidden neuron 9\t-5,82\tinput bias - hidden neuron 9\t6,62\nFI-31 (L/h) - hidden neuron 9\t0,48\tinput bias - hidden neuron 10\t-3,55\nT-30 (\u00b0C) - hidden neuron 9\t-4,67\tinput bias - hidden neuron 11\t-0,62\nT-31 SP (\u00b0C) - hidden neuron 10\t-1,04\tinput bias - hidden neuron 12\t-1,41\nT-31 MV (%) - hidden neuron 10\t-2,32\tinput bias - hidden neuron 13\t1,08\nLI-31 (%) - hidden neuron 10\t2,17\tinput bias - hidden neuron 14\t3,39\nFI-31 (L/h) - hidden neuron 10\t-0,04\tinput bias - hidden neuron 15\t11,64\nT-30 (\u00b0C) - hidden neuron 10\t-3,67\tinput bias - hidden neuron 16\t8,10\nT-31 SP (\u00b0C) - hidden neuron 11\t-0,01\tinput bias - hidden neuron 17\t12,74\nT-31 MV (%) - hidden neuron 11\t0,15\tinput bias - hidden neuron 18\t3,34\nLI-31 (%) - hidden neuron 11\t-0,03\tinput bias - hidden neuron 19\t16,40\nFI-31 (L/h) - hidden neuron 11\t0,21\tinput bias - hidden neuron 20\t-3,88\nConex\u00f5es da MPL 5-23-1\tPesos\tConex\u00f5es da MPL 5-23-1\tPesos\nT-30 (\u00b0C) - hidden neuron 11\t0,93\tinput bias - hidden neuron 21\t-5,96\nT-31 SP (\u00b0C) - hidden neuron 12\t3,64\tinput bias - hidden neuron 22\t8,74\nT-31 MV (%) - hidden neuron 12\t-9,25\tinput bias - hidden neuron 23\t-7,08\nLI-31 (%) - hidden neuron 12\t-17,35\thidden neuron 1 - TIC-31 (\u00b0C)\t-0,06\nFI-31 (L/h) - hidden neuron 12\t-1,91\thidden neuron 2 - TIC-31 (\u00b0C)\t-2,63\nT-30 (\u00b0C) - hidden neuron 12\t-8,05\thidden neuron 3 - TIC-31 (\u00b0C)\t0,12\nT-31 SP (\u00b0C) - hidden neuron 13\t-5,73\thidden neuron 4 - TIC-31 (\u00b0C)\t1,97\nT-31 MV (%) - hidden neuron 13\t0,49\thidden neuron 5 - TIC-31 (\u00b0C)\t0,03\nLI-31 (%) - hidden neuron 13\t3,95\thidden neuron 6 - TIC-31 (\u00b0C)\t3,34\nFI-31 (L/h) - hidden neuron 13\t-8,95\thidden neuron 7 - TIC-31 (\u00b0C)\t-0,01\nT-30 (\u00b0C) - hidden neuron 13\t0,47\thidden neuron 8 - TIC-31 (\u00b0C)\t1,38\nT-31 SP (\u00b0C) - hidden neuron 14\t-2,38\thidden neuron 9 - TIC-31 (\u00b0C)\t0,26\nT-31 MV (%) - hidden neuron 14\t-0,51\thidden neuron 10 - TIC-31 (\u00b0C)\t-6,84\nLI-31 (%) - hidden neuron 14\t-0,54\thidden neuron 11 - TIC-31 (\u00b0C)\t1,43\nFI-31 (L/h) - hidden neuron 14\t-0,41\thidden neuron 12 - TIC-31 (\u00b0C)\t9,11\nT-30 (\u00b0C) - hidden neuron 14\t-32,74\thidden neuron 13 - TIC-31 (\u00b0C)\t-1,71\nT-31 SP (\u00b0C) - hidden neuron 15\t-16,59\thidden neuron 14 - TIC-31 (\u00b0C)\t-5,13\nT-31 MV (%) - hidden neuron 15\t-2,49\thidden neuron 15 - TIC-31 (\u00b0C)\t-4,81\nLI-31 (%) - hidden neuron 15\t0,04\thidden neuron 16 - TIC-31 (\u00b0C)\t1,77\nFI-31 (L/h) - hidden neuron 15\t-0,74\thidden neuron 17 - TIC-31 (\u00b0C)\t0,15\nT-30 (\u00b0C) - hidden neuron 15\t-14,20\thidden neuron 18 - TIC-31 (\u00b0C)\t-0,12\nT-31 SP (\u00b0C) - hidden neuron 16\t-3,98\thidden neuron 19 - TIC-31 (\u00b0C)\t-2,90\nT-31 MV (%) - hidden neuron 16\t-4,06\thidden neuron 20 - TIC-31 (\u00b0C)\t-0,05\nLI-31 (%) - hidden neuron 16\t0,60\thidden neuron 21 - TIC-31 (\u00b0C)\t2,07\nFI-31 (L/h) - hidden neuron 16\t-6,06\thidden neuron 22 - TIC-31 (\u00b0C)\t-6,40\nT-30 (\u00b0C) - hidden neuron 16\t-25,37\thidden neuron 23 - TIC-31 (\u00b0C)\t9,00\nT-31 SP (\u00b0C) - hidden neuron 17\t-20,15\thidden bias - TIC-31 (\u00b0C)\t-0,35"}]}}}